@inproceedings{10.1145/3245385,
author = {Churchill, Elizabeth and Subramanian, Sririam},
title = {Session Details: Keynote Address},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245385},
doi = {10.1145/3245385},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371666,
author = {Isbister, Katherine},
title = {How to Stop Being a Buzzkill: Designing Yamove!, A Mobile Tech Mash-up to Truly Augment Social Play},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371666},
doi = {10.1145/2371664.2371666},
abstract = {Most technology-supported dance games result in gameplay that looks very different than what we know as social dancing. For that matter, most 'social' games can involve a lot of solo staring at screens. Our lab re-examined the role of technology in supporting the dance experience, working with indie game developers and dancers to understand how to truly augment instead of override the joyful social and physical qualities of dancing together. Along the way, we learned some valuable lessons about how to reframe the conceptualization and development of mobile apps meant to augment everyday social experience. In this talk, I'll share these insights, toward opening your eyes as you tackle these kinds of design and development challenges in next-generation mobile applications.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {1–4},
numpages = {4},
keywords = {augmented social interaction, social game play, indie game development, movement-based interaction, social dance},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3245386,
author = {Alexander, Jason and Irani, Pourang},
title = {Session Details: Posters},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245386},
doi = {10.1145/3245386},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371668,
author = {Fortmann, Jutta and Pielot, Martin and Mittelsdorf, Marco and B\"{u}scher, Martin and Trienen, Stefan and Boll, Susanne},
title = {PaceGuard: Improving Running Cadence by Real-Time Auditory Feedback},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371668},
doi = {10.1145/2371664.2371668},
abstract = {This paper presents PaceGuard, a mobile phone-based system which supports runners in keeping their cadence by auditory feedback. Experts have reported that maintaining the cadence is a prominent challenge for many running beginners and less experienced runners. However, this is important to make the exercise healthy and effort-saving, and to avoid discomfort like side stitches. PaceGuard automatically determines a suitable target cadence on the basis of the measured accelerometer data of the first 150 seconds of a run. Then this cadence as the guideline is constantly signaled to the runner via rhythmic pulse beats, defined as beats per minute. On the basis of previous studies [5], we assume runners will adapt their cadence to the presented pulse beats and thus will run more consistently compared to running without the auditory feedback of PaceGuard. Our pilot study results encourage this assumption.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {5–10},
numpages = {6},
keywords = {running cadence, mobile training assistant, auditory feedback},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371669,
author = {Wolf, Katrin and McGee-Lennon, Marilyn and Brewster, Stephen},
title = {A Study of On-Device Gestures},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371669},
doi = {10.1145/2371664.2371669},
abstract = {Regardless of how gestural phone interaction (like pinching on a touch screen for content zooming) is implemented in almost any mobile device; there are still no design guidelines for gestural control. These should be designed with respect to ergonomics and hand anatomy. There are many human-side aspects to take care of when designing gestures. We evaluate gestures regarding the ergonomic aspects while interacting with mobile devices and present ergonomic requirements of finger gestures on the back and side of a vertically and as well as horizontally hand-held phone, such as dragging and lifting fingers from the surface. The results suggest that drag and lift gestures have the potential to be executed one-handed while using the phone and that certain device configurations may be accessed seamlessly with that type of gesture control.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {11–16},
numpages = {6},
keywords = {gesture, probe., around device, back-of-device},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371670,
author = {Hamilton, Iain and Imperatore, Gennaro and Dunlop, Mark D. and Rowe, David and Hewitt, Allan},
title = {Walk2Build: A GPS Game for Mobile Exergaming with City Visualization},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371670},
doi = {10.1145/2371664.2371670},
abstract = {In recent years public health has become of great concern, in particular the personal and national economic burden resulting from increasingly sedentary lifestyles. Sedentary lifestyles are particularly serious for young people who are badly affected by obesity problems that impact on their current and future lives. In an effort to tackle this problem games designers are designing games aimed at motivating people to take part in physical activities and have coined the term exergaming. This poster presents a mobile exergaming application developed in Android Java and HTML 5 targeting under-active teenagers and young adults. The objective is to encourage users to increase walking by an incremental number of steps each week. This is visualized as an isometric virtual town on a web browser (with rewards for achieving targets) and published on Facebook to exploit social networking in supporting users. This poster will examine the motivation behind our game, design decisions, our prototype and concludes with future plans.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {17–22},
numpages = {6},
keywords = {mobile support, exercise, healthy lifestyle},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371671,
author = {Dunlop, Mark D. and Durga, Naveen and Motaparti, Sunil and Dona, Prima and Medapuram, Varun},
title = {QWERTH: An Optimized Semi-Ambiguous Keyboard Design},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371671},
doi = {10.1145/2371664.2371671},
abstract = {Mobile phone keyboards can be categorized as unambiguous (one key per letter) or ambiguous (multiple letters per key). In this poster we present QWERTH: a semi-ambiguous keyboard for English in which we have grouped keys together that are less likely to cause prediction problems, while keeping some other keys unique. This has allowed us to increase keys to 1/5 screen width instead of 1/10 while maintaining a near-QWERTY layout. A prototype keyboard built on the OpenAdaptxt text entry engine, results from initial user studies and future study plans are discussed.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {23–28},
numpages = {6},
keywords = {semi-ambiguous entry, text entry, keyboard layouts},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371672,
author = {Costa, Pedro Maur\'{\i}cio and Pitt, Jeremy and Vieira, Jo\~{a}o G. and Galv\~{a}o, Teresa and Falc\~{a}o e Cunha, Jo\~{a}o},
title = {Investigating Mobile Quality of Experience in Public Transport},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371672},
doi = {10.1145/2371664.2371672},
abstract = {In recent years, mass adoption of increasingly powerful mobile devices and ubiquitous communication networks have paved the way to smart environments. Such environments allow for the collection of user and environment data with the final goal to improve users' experience. In this context a number of opportunities and challenges are presented to Human Computer Interaction. This poster explores Quality of Experience, a subjective aspect of interaction, informally defined as the degree to which a system meets users' expectations. Furthermore, a mobile application was developed for the collection of user and environment data and delivery of personalised services in the context of Public Transport. This application will be used in a real-world environment, to further investigate the factors that have an influence on User eXperience, as well as the delivery of relevant services with the potential to enhance users' journeys while in transit.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {29–34},
numpages = {6},
keywords = {quality of experience, user experience, mobile cloud computing, service design},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371673,
author = {Suzuki, Genta and Klemmer, Scott},
title = {TeleTorchlight: Remote Pointing and Annotation Using a Mobile Camera Projector},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371673},
doi = {10.1145/2371664.2371673},
abstract = {Remote support for physical tasks often takes a longer time and involves more mistakes than on-site support. The reason for this is that it is difficult for remote supporters to know what happened at the site and show how to operate briefly. In this paper, we propose a remote support system named TeleTorchlight that works between a tablet and a mobile camera projector unit. The system expands traditional voice chat based remote support by providing a method to draw instructions to physical object directly from remote supporters. On-site workers can easily understand instructions from remote supporters and can efficiently learn tasks using our system. Remote supporters also provide instructions showing where to operate and how to operate.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {35–40},
numpages = {6},
keywords = {telecommunication, mobile, augmented reality, projector, camera, telecollaboration},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371674,
author = {Torrez Riley, Jessica},
title = {A Look at Spectator Technology: Location-Based Services and Mobile Habits of Collegiate Sports Fans},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371674},
doi = {10.1145/2371664.2371674},
abstract = {This paper looks at the potential for mobile technology that targets sports spectators. Preliminary survey results from 83 college sports fans suggest the current usage of mobile technology, like location-based services, when attending games. Findings offer insight as to the expectations and concerns of fans and inform the design for a social, local mobile application.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {41–46},
numpages = {6},
keywords = {college sports, spectators, second-screen, location-based services, mobile social interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371675,
author = {Hagan, Margaret and Zhang, Nan and Kaye, Joseph 'Jofish'},
title = {Safe Mathare: A Mobile System for Women's Safe Commutes in the Slums},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371675},
doi = {10.1145/2371664.2371675},
abstract = {The spread of mobile phone usage to slum areas raises the possibility of using mobile technology to address problems facing the poorest of the world's poor. We present a case study of Safe Mathare, a design project aimed at improving women's safety in Nairobi, Kenya. Safe Mathare provides community patrols with basic smartphone technology to help women commute safely through a slum neighborhood during dusk and dawn hours. The project started as a prototype developed in a university course and has found willing partners with local NGOs and government. During its pilot phase, it has run into many challenges in particular around the issue of vigilantism. This paper explores the development and implementation of Safe Mathare, raising the questions of whether and how design can leverage technology to build a social network for security.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {47–52},
numpages = {6},
keywords = {mobiles, ict4d, kenya, commuting, security, safety},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371676,
author = {Lee, Jae Yeol and Kim, Min Seok and Seo, Dong Woo and Lee, Sang Min and Kim, Jae Sung},
title = {Smart and Space-Aware Interactions Using Smartphones in a Shared Space},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371676},
doi = {10.1145/2371664.2371676},
abstract = {This paper presents a smart and space-aware interaction(S2Interaction) technique using smartphones for co-located and collaborative interaction in a shared space. S2Interaction enables to interact with digital contents in a shared display or public space by spatially tracking multiple smartphones with a depth camera, KinectTM. Since the proposed approach detects the relative location of the smartphone with respect to the shared space without attaching any sensors, it provides very effective and natural interactions for local space exploration and collaboration, and it is also robust in most collaboration environments under low illumination condition.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {53–58},
numpages = {6},
keywords = {smartphone, space awareness, user interaction, collaboration, kinect},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371677,
author = {Milanova, Veselina and Mandl, Thomas and K\"{o}lle, Ralph},
title = {Design for Emotion: A Case Study},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371677},
doi = {10.1145/2371664.2371677},
abstract = {Increasing the potential of mobile applications to elicit positive emotions can help overcome the prevalent ephemerality of such applications. The current paper addresses the possibilities to support the elicitation of favorable emotions during the development process of mobile applications. It provides a short overview of the theoretical background of emotion research and design to subsequently present an experiential study, focused on the design of positive emotional resonance for an iPhone ride sharing service in terms of desire, satisfaction and fascination.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {59–64},
numpages = {6},
keywords = {emotional design, mobile design, user experience},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371678,
author = {Linnell, Natalie and Bareiss, Ray and Pantic, Kristoffer},
title = {A Wizard of Oz Tool for Android},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371678},
doi = {10.1145/2371664.2371678},
abstract = {Although mobile-based prototyping platforms are numerous, there are currently no tools that support Wizard of Oz interactions on Android. This paper describes a Wizard of Oz prototyping system for Android, via which a designer can enhance digitally generated mock-ups or scanned-in paper sketches with interactive widgets and automated screen transitions. Screen transitions can be based on user action such as a button presses, triggered manually by an experimenter observing from a laptop or triggered based on the user's location or the time. We have integrated scenario-based user testing, a context in which Wizard of Oz testing is often used, by providing support for location- and time-based display of videos and screens in the prototype. It is our hope that this system will find wider use in the design community.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {65–70},
numpages = {6},
keywords = {android, ubiquitous computing, wizard of oz, context aware, prototyping tools},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371679,
author = {White, Brent-Kaan},
title = {Visualizing Mobile Design Pattern Relationships},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371679},
doi = {10.1145/2371664.2371679},
abstract = {This paper describes the process of creating a design pattern management interface for a collection of mobile design patterns. The need to communicate how patterns are interrelated and work together to create solutions motivated the creation of this interface. Currently, most design pattern collections are presented in alphabetical lists. The Oracle Mobile User Experience team approach is to communicate relationships visually by highlighting and connecting related patterns. Before the team designed the interface, we first analyzed common relationships between patterns and created a pattern language map. Next, we organized the patterns into conceptual design categories. Last, we designed a pattern management interface that enables users to browse patterns and visualize their relationships.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {71–76},
numpages = {6},
keywords = {pattern languages, design patterns, mobile design, pattern tools},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371680,
author = {Lee, Hyunjoeng and Lee, Bhoram and Park, Joonah},
title = {Force Code: A New Interaction Technique Using Tangential Force Input},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371680},
doi = {10.1145/2371664.2371680},
abstract = {This paper presents a new interaction technique for pass code inputting in a handheld device. This method adopts a tangential force to unlock the device instead of touch passwords or drawing patterns that require looking at the display. A user can grasp a mobile phone and apply pressure onto the display surface without having to look at the display. A tangential-force-based interface is implemented for a smart phone. The interface is devised to receive four directional force inputs: up, down, left, and right. The feasibility of the proposed method was evaluated, and it was found that a 92% success ratio can be achieved.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {77–82},
numpages = {6},
keywords = {mobile interaction, force-based interface, input device},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371681,
author = {Niida, Sumaru and Uemura, Satoshi and Ano, Shigehiro},
title = {User Study of the Subjective Quality of Mobile Streaming Service},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371681},
doi = {10.1145/2371664.2371681},
abstract = {The number of smartphone users has increased markedly in recent years. They enjoy multimedia services, such as video streaming, unconstrained by time and place. However, mobile streaming services require a high throughput, and may have an impact on network capacity. The control of service quality is important from both the perspective of user experience and network quality. However, the quality of a video service has mainly been evaluated by examining the picture quality. It is less common to use a network design viewpoint to evaluate video streaming services. In this paper, we discuss the subjective quality of streaming video on mobile terminals. The main contribution of this paper is to quantitatively show the relation between the overall satisfaction, network quality and picture quality, based on the results of the user study.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {83–88},
numpages = {6},
keywords = {user experience, resolution, service quality, human-centered design: waiting time, mobile streaming},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371682,
author = {Lee, Sang-su and Lim, Youn-kyung and Lee, Kun-Pyo},
title = {Exploring the Effects of Size on Deformable User Interfaces},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371682},
doi = {10.1145/2371664.2371682},
abstract = {Deformable user interfaces have received increasing attention in recent HCI research. However, the effect of device size on deformable user interfaces has not been studied yet. This study is aimed to investigate how the size of a deformable device affects users' interaction behavior and preferences. We observed users interacting with deformable mockup displays of two different sizes. Overall, 36 participants provided 769 user-defined gestures for 11 basic commands. We compared and discussed users' preferences toward two different sizes of deformable devices. We also covered user-defined gestures and patterns of use for each device size. As a preliminary study for understanding form factors for designing deformable user interfaces, this study clearly show that the device size is an important factor to consider when designing mobile devices which can be deformed.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {89–94},
numpages = {6},
keywords = {organic user interface, deformable user interface, user interface, flexible display},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371683,
author = {Marques, Diogo and Duarte, Lu\'{\i}s and Carri\c{c}o, Lu\'{\i}s},
title = {Privacy and Secrecy in Ubiquitous Text Messaging},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371683},
doi = {10.1145/2371664.2371683},
abstract = {This paper presents a study on privacy and secrecy requirements that users feel while in the presence of other people. They are viewed as issues of a social activity and pertain to the desire that the content of messages or the act of writing or reading them is not perceived by others. We assess the needs for privacy according to the message's themes and acquaintance type with the recipient. We also present and discuss our findings considering user strategies in coping with the required privacy using both a quantitative and a qualitative approach. The study results show clearly the need to consider those requirements in the design of messaging applications for mobile devices. Circa 50% of the messages analyzed required privacy on the act of writing/reading. The reasons are multifaceted and vary according to the addressees and the content type reaching 70% for specific cases. We close the paper, with a proposal of a personal, multimodal and inconspicuous communication framework, which not only allows users to define their vocabulary, but also entry and output methods from a range of different modalities.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {95–100},
numpages = {6},
keywords = {text messaging, privacy, inconspicuousness, ubiquity},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371684,
author = {Henze, Niels and Boll, Susanne},
title = {Camera-Based Mobile Interaction Techniques for Physical Objects},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371684},
doi = {10.1145/2371664.2371684},
abstract = {A number of mobile applications enable users to take photos of physical objects to receive related information and services. Commercial implementations such as Google Goggles use a Point &amp; Shoot interaction technique that requires to explicitly taking a photo to trigger the object recognition. In this paper we investigate alternative interaction techniques to receive information about physical objects. For the study we try to rule out all aspects but the basic interaction. We compare Point &amp; Shoot with two other techniques to access information about music CDs and show that using handheld Augmented Reality is preferred by users and leads to a lower perceived task load. Our findings confirm that research and development effort towards handheld Augmented Reality is well invested.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {101–106},
numpages = {6},
keywords = {music, augmented reality, handheld augmented reality, mobile phone, cd, mobile interaction, image analysis},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371685,
author = {Sieger, Hanul and M\"{o}ller, Sebastian},
title = {Gender Differences in the Perception of Security of Mobile Phones},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371685},
doi = {10.1145/2371664.2371685},
abstract = {In this paper we describe observed gender differences in the perception of security of mobile phones, especially on authentication and payment-related features and application on smartphones. The data was gathered in a focus group, two surveys and an experiment during November 2009 and September 2011. The data shows significant differences in perceived security and future use of security-related features and applications.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {107–112},
numpages = {6},
keywords = {gender, perceived security, mobile phone},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371686,
author = {Wechsung, Ina and Jepsen, Kathrin and Burkhardt, Felix and K\"{o}hler, Annerose and Schleicher, Robert},
title = {View from a Distance: Comparing Online and Retrospective Ux-Evaluations},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371686},
doi = {10.1145/2371664.2371686},
abstract = {This paper reports the results of an explorative field study investigating if and how remembered UX evaluations differ from evaluations collected during usage. Results show that while quantitative ratings are similar, qualitative data differs: Comments assessed during usage were less detailed but contained more affective evaluations compared to the retrospective remarks.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {113–118},
numpages = {6},
keywords = {user experience, methodology, field study, evaluation},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371687,
author = {Winkler, Christian and Hutflesz, Patrick and Holzmann, Clemens and Rukzio, Enrico},
title = {Wall Play: A Novel Wall/Floor Interaction Concept for Mobile Projected Gaming},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371687},
doi = {10.1145/2371664.2371687},
abstract = {Currently we see the emergence of the first commercial projector phones. Besides the standard use case of projecting media content, they are also promising as a platform for new types of mobile gaming. In this paper, we present a novel interaction concept for mobile projected gaming which leverages specifically a wall and the floor in the environment to provide a new type of semi-realistic augmented gaming. Moreover, we present a preliminary bowling game prototype.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {119–124},
numpages = {6},
keywords = {concept, mobile, projector phone, gaming, projection},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371688,
author = {Hwang, Jihye and Ji, Yeounggwang and Kim, Eun Yi},
title = {Monocular Vision-Based Collision Avoidance System},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371688},
doi = {10.1145/2371664.2371688},
abstract = {For the elderly people who have a low vision to safely navigate in unknown environments, the system should be developed to recognize where the obstacles in the scene are. In this paper, we present a vision system for obstacle detection, and implemented it on the Smartphone that provides real-time feedback to the user. In addition, various obstacles are localized using online background model, then viable paths to avoid them are determined by neural network-based classifier. Finally, the recognized results are verbally notified to the user through a visual interface. To demonstrate the effectiveness of the proposed method, it was tested on real indoors and outdoors with several environmental factors such as illumination type and complex structures. Then the results demonstrated the effectiveness of the proposed method.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {125–130},
numpages = {6},
keywords = {obstacle detection, visual interface, multiple disabled people, elderly people},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371689,
author = {Fan, Mingming and Patterson, Donald and Shi, Yuanchun},
title = {When Camera Meets Accelerometer: A Novel Way for 3d Interaction of Mobile Phone},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371689},
doi = {10.1145/2371664.2371689},
abstract = {Performing real-time 3D motion interaction with a mobile phone is useful for extending interaction out of a limited screen. However, current phone motion detection approaches, which use only camera or accelerometer, have limitations in recognizing versatile 3D motions simultaneously. In this paper we present a real-time approach designed for 3D tasks by holding and moving a phone equipped with both a camera and an accelerometer. By analyzing both motion features from image frames and changes of accelerometer data simultaneously, our approach can naturally distinguish translation and rotation of a mobile phone. In a pilot user study, we demonstrated our design requires low learning effort and has high accuracy. Since it does not require any outside infrastructure, our approach can be applied to any phone with a camera and an accelerometer. Our main contribution is giving mobile phone users 3D interaction ability by exploiting hand translation and rotation.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {131–136},
numpages = {6},
keywords = {accelerometer, camera, fusion, real-time 3d motion, weak classifiers, mobile phone},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371690,
author = {Kheiravar, Salma and Lasserre, Patricia and Campbell, Robert},
title = {A Mobile Application for Collaborative Learning},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371690},
doi = {10.1145/2371664.2371690},
abstract = {Group work in classroom settings is an efficient approach used by many professors to provide a higher level of engagement [3]. Unfortunately, the classroom arrangement is often detrimental to group exercises in which every group member should participate equally. When a group includes more than 3 participants, students are often spread on one or two rows. This configuration makes communication and participation difficult for the students on the extremities. It also limits students from one of the two rows to feel engaged as soon as the exercise requires a specific orientation for the work to be done (such as reading or writing a program). This study explores the use of a touch screen mobile platform such as the iPAD for facilitating students' collaboration. The objective of the platform is to ease interaction among students by enabling students who are not in close proximity to each other to be active participants and work collaboratively. The current prototype allows a group of students to solve a problem individually or collaboratively on their own tablet devices. The finished software will be evaluated for its efficacy as a collaborative tool with on-line groups, as well as in-class groups.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {137–142},
numpages = {6},
keywords = {mobile learning, team based learning, real-time collaborative educational software},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371691,
author = {Schulze, Katrin and Kroemker, Heidi},
title = {Extracting User Experience Centered Product Requirements for Mobile Social Media Applications},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371691},
doi = {10.1145/2371664.2371691},
abstract = {This paper introduces a structured approach to extract user experience centered product requirements based on a framework that aims at linking user needs regarding mobile social media with product quality. By means of a user study with the mobile sharing service LiveShare by Cooliris we derived general guidelines and clear recommendations for product requirements.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {143–148},
numpages = {6},
keywords = {usability, mobile social media, application experiences, product requirements, user needs, user experience},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3245387,
author = {Shamma, David Ayman and Nelson, Les and Olwal, Alex},
title = {Session Details: Demos and Space Challenges},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245387},
doi = {10.1145/3245387},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371693,
author = {Gauglitz, Steffen and Lee, Cha and Turk, Matthew and H\"{o}llerer, Tobias},
title = {A Prototype Setup to Integrate the Physical Environment into Mobile Remote Collaboration},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371693},
doi = {10.1145/2371664.2371693},
abstract = {In the accompanying paper [1], we describe a framework and prototype implementation for unobtrusive mobile remote collaboration on tasks that involve the physical environment. Our system uses model-free, markerless visual tracking to facilitate decoupled, live updated views of the environment and world-stabilized annotations while supporting a moving camera and unknown, unprepared environments. We conducted a user study with 48 participants to evaluate our concept. In this demo, we will present our system prototype and the setup used in the user study: a remote expert instructs a local user to operate a mock-up airplane. Users will be able to try out our interface as well as the two interfaces used as baseline in the study.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {149–150},
numpages = {2},
keywords = {user study, video-mediated communication, telecollaboration, markerless visual tracking, augmented reality},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371694,
author = {Szymczak, Delphine and Rassmus-Gr\"{o}hn, Kirsten and Magnusson, Charlotte and Hedvall, Per-Olof},
title = {Demonstration of an Audio-Tactile Tourist Guide},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371694},
doi = {10.1145/2371664.2371694},
abstract = {An audio-tactile interactive tourist guide is demonstrated, including the possibility to be guided to points of interest. In contrast with the key-hole like experience of on-screen augmented reality, this guide makes use of the non-visual modalities to create a more immersive augmented experience. Sound windows from the past and verbal historical information complement discrete tactile guidance along a trail.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {151–152},
numpages = {2},
keywords = {multimodal, non-visual, inclusive, augmented reality, navigation},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371695,
author = {Liu, Jie and Xu, Wenchang and Shi, Yuanchun},
title = {AutoWeb: Automatic Classification of Mobile Web Pages for Revisitation},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371695},
doi = {10.1145/2371664.2371695},
abstract = {Revisitation in mobile Web browsers takes more time than that in desktop browsers due to the limitations of mobile phones. In this paper, we propose AutoWeb, a novel approach to speed up revisitation in mobile Web browsing. In AutoWeb, opened Web pages are automatically classified into different groups based on their contents. Users can more quickly revisit an opened Web page by narrowing down search scope into a group of pages that share the same topic. We evaluated the classification accuracy and the accuracy is 92.4%. Three experiments were conducted to investigate revisitation performance in three specific tasks. Results show AutoWeb can save significant time for revisitation by 29.5%, especially for long time Web browsing, and that it improves overall mobile Web revisitation experience. We also compare automatic classification with other revisitation methods.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {153–154},
numpages = {2},
keywords = {revisitation, mobile web, automatic classification},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371696,
author = {Southern, Caleb and Clawson, James and Frey, Brian and Abowd, Gregory and Romero, Mario},
title = {Braille Touch: Mobile Touchscreen Text Entry for the Visually Impaired},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371696},
doi = {10.1145/2371664.2371696},
abstract = {We present a demonstration of BrailleTouch, an accessible keyboard for blind users on a touchscreen smartphone (see Figure 1). Based on the standard Perkins Brailler, BrailleTouch implements a six-key chorded braille soft keyboard [1]. We will briefly introduce audience members to the braille code, and then allow them to hold the BrailleTouch prototype and enter text, with the aid of a visual chart of the braille alphabet.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {155–156},
numpages = {2},
keywords = {chording, blindness, text entry, gestures, mobile devices, touchscreens, multi-touch interaction, accessibility},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371697,
author = {Feij\'{o} Filho, Jackson and Prata, Wilson and Valle, Thiago},
title = {Breath Mobile: A Low-Cost Software-Based Breathing Controlled Mobile Phone Interface},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371697},
doi = {10.1145/2371664.2371697},
abstract = {This work proposes the use of a low-cost software based breathing interface for mobile phones as an alternative interaction technology for people with motor disabilities. It attempts to explore the processing of the audio from the microphone in mobile phones to trigger and launch software events. A proof of concept of this work is demonstrated by the implementation and experimentation of a mobile application prototype that enables users to perform a basic operation on the phone, such as calling, through "puffing" interaction.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {157–160},
numpages = {4},
keywords = {breathing, mobile, accessibility, alternative hci},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371698,
author = {Kim, Seon Joo and Ng, Hongwei and Winkler, Stefan and Song, Peng and Fu, Chi-Wing},
title = {Brush-and-Drag: A Multi-Touch Interface for Photo Triaging},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371698},
doi = {10.1145/2371664.2371698},
abstract = {Due to the convenience of digital photography, people often end up with multiple shots of the same scene with only slight variations. We propose an easy-to-use brush-and-drag interface, helping them to interactively explore and compare this type of photos on a tablet computer. First, we mark an area of interest on a photo with our finger(s). Next, our segmentation engine will automatically segment corresponding image elements among the photos, which we can then drag across a single screen to compare side-by-side. This can be followed by a series of simple finger gestures applied to the image elements (representing the photos) to rank, select favorites for sharing, or discard unwanted photos.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {161–162},
numpages = {2},
keywords = {digital photo collections, user interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371699,
author = {Chang, Tzuwen and Yu, Neng-Hao and Tsai, Sung-Sheng and Chen, Mike Y. and Hung, Yi-Ping},
title = {Clip-on Gadgets: Expandable Tactile Controls for Multi-Touch Devices},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371699},
doi = {10.1145/2371664.2371699},
abstract = {Virtual keyboards and controls, commonly used on mobile multi-touch devices, occlude content of interest and do not provide tactile feedback. Clip-on Gadgets solve these issues by extending the interaction area of multi-touch devices with physical controllers. Clip-on Gadgets use only conductive materials to map user input on the controllers to touch points on the edges of screens; therefore, they are battery-free, lightweight, and low-cost. In addition, they can be used in combination with multi-touch gestures. We present two hardware designs and a software toolkit, which enable users to simply attach Clip-on Gadgets to an edge of a device and start interacting with it.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {163–166},
numpages = {4},
keywords = {mobile devices, physical controllers, toolkit, multi-touch, tangible, tactile input},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371700,
author = {Burigat, Stefano and Chittaro, Luca and Vianello, Andrea},
title = {A System for Interactive Visualization of Off-Screen Objects on Mobile Devices},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371700},
doi = {10.1145/2371664.2371700},
abstract = {Overview+Detail and Wedge have been proposed in the literature as effective approaches to resolve the off-screen objects problem on mobile devices. However, they have been studied with a small number of off-screen objects and (in most studies) with static scenarios, in which users did not have to perform any navigation activity. In this demo, we show improved versions of Wedge and Overview+Detail which are specifically aimed at simplifying their use in dynamic scenarios that involve large numbers of off-screen objects.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {167–168},
numpages = {2},
keywords = {overview+detail, wedge, map navigation, visualization, off-screen objects, mobile devices, peripheral awareness},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371701,
author = {Frias-Martinez, Vanessa and Virseda, Jesus and Gomero, Aldo},
title = {EducaMovil: A Mobile Learning Tool for Low-Income Schools},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371701},
doi = {10.1145/2371664.2371701},
abstract = {This paper describes EducaMovil, a tool to develop quiz-based mobile games for Java-enabled feature phones. The tool has two main components: a PC application that allows teachers to create educational contents, and a mobile game for students to learn while playing anytime, anywhere. EducaMovil works on feature phones and constitutes an affordable solution for low-income schools.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {169–172},
numpages = {4},
keywords = {learning gains, mobile games, low-income schools},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371702,
author = {Thomason, Jesse and Wang, Jingtao},
title = {Exploring Multi-Dimensional Data on Mobile Devices with Single Hand Motion and Orientation Gestures},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371702},
doi = {10.1145/2371664.2371702},
abstract = {ScatterDice Mobile (SDM) is a novel visualization system that leverages embodied motion and orientation gestures for intuitive and effective exploration of multi-dimensional data on mobile devices. Inspired by Elmqivist et al's recent work, SDM uses the gyroscope sensor available on mobile devices to establish an orientation aware "dice rolling" metaphor for browsing scatterplot matrix visualizations mapped to a cube on mainstream mobile devices without any hardware modification. SDM has the potential for applications that require prompt access and exploration of large scale, multi-dimensional data on mobile devices anytime, anywhere.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {173–176},
numpages = {4},
keywords = {scatterplot, gesture, smart phones, motion sensing, visualization, mobile devices, gyroscope},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371703,
author = {Manabe, Hiroyuki and Fukumoto, Masaaki},
title = {Headphone Taps: A Simple Technique to Add Input Function to Regular Headphones},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371703},
doi = {10.1145/2371664.2371703},
abstract = {A simple technique which changes regular headphones into input-and-output devices is proposed. It detects headphone taps and also captures user's voice. Two prototypes are implemented. Users can control music players and have phone conversation via their favorite headphones without attaching external switches or microphones. We confirm that they work well with many headphones in various environments.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {177–180},
numpages = {4},
keywords = {tap, wearable, headphones, input device},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371704,
author = {Ketabdar, Hamed and Chang, Hengwei and Moghadam, Peyman and Roshandel, Mehran and Naderi, Babak},
title = {MagiGuitar: A Guitar That is Played in Air!},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371704},
doi = {10.1145/2371664.2371704},
abstract = {In this work we present MagiGuitar - a guitar music performance application played in air on iPhone 3GS using a magnet! Users can play the mobile guitar application by moving a permanent magnet around a mobile device embedding a compass sensor (magnetometer). The touch less magnetic music performance technique allows users to play the mobile guitar application using highly intuitive hand gestures in the form of strumming action similar to a real guitar but in air. The proposed technique provides higher degree of flexibility for music performance, as the interaction space is extended to 3D space around the device. This allows users to play music in mobile devices using more natural, comfortable and flexible hand gestures as done with real instruments.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {181–184},
numpages = {4},
keywords = {magnet, mobile devices, digital music instruments, magnetic interaction, compass sensor (magnetometer)},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371705,
author = {Ketabdar, Hamed and Moghadam, Peyman and Naderi, Babak and Roshandel, Mehran},
title = {Magnetic Signatures in Air for Mobile Devices},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371705},
doi = {10.1145/2371664.2371705},
abstract = {Recently, a new authentication method based on 3D signatures created in air is proposed for mobile devices [4]. The 3D signature is created in air using a properly shaped magnet (a rod or ring) taken in hand. It is based on influencing compass sensor embedded in the new generation of mobile devices. In this paper, we present implementation of this technology on a mobile device (iPhone 3GS). It can demonstrate authentication process using a gesture in the from of a 3D signature freely created in the space around the device by a magnet held in hand. Movement of the magnet in the from of a signature produces a temporal change in the magnetic field sensed by the embedded compass sensor, and can be used as a basis for authentication. As magnetic signatures are performed in 3D space, they can provide a wider choice for authentication, and they can not be easily hardcopied.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {185–188},
numpages = {4},
keywords = {mobile devices, user authentication, magnetic field, embedded compass (magnetometer), 3d magnetic signature},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371706,
author = {Pfleging, Bastian and Alt, Florian and Schmidt, Albrecht},
title = {Meaningful Melodies: Personal Sonification of Text Messages for Mobile Devices},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371706},
doi = {10.1145/2371664.2371706},
abstract = {Mobile phones offer great potential for personalization. Besides apps and background images, ringtones are the major form of personalization. They are most often used to have a personal sound for incoming texts and calls. Furthermore, ringtones are used to identify the caller or sender of a message. In parts, this function is utilitarian (e.g., caller identification without looking at the phone) but it is also a form of self-expression (e.g., favorite tune as standard ringtone). We investigate how audio can be used to convey richer information. In this demo we show how sonifications of SMS can be used to encode information about the sender's identity as well as the content and intention of a message based on flexible, user-generated mappings. We present a platform that allows arbitrary mappings to be managed and apps to be connected in order to create a sonification of any message. Using a background app on Android, we show the utility of the approach for mobile devices.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {189–192},
numpages = {4},
keywords = {sonification, rich audible information, text messages},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371707,
author = {Edge, Darren and Fitchett, Stephen and Whitney, Michael and Landay, James},
title = {MemReflex: Adaptive Flashcards for Mobile Microlearning},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371707},
doi = {10.1145/2371664.2371707},
abstract = {Flashcard systems typically help students learn facts (e.g., definitions, names, and dates), relying on intense initial memoriztion with subsequent tests delayed up to days later. This approach does not exploit the short, sparse, and mobile opportunities for microlearning throughout the day, nor does it support learners who need the motivation that comes from successful study sessions. In contrast, our MemReflex system of adaptive flashcards gives fast-feedback by retesting new items in quick succession, dynamically scheduling future tests according to a model of the learner's memory. Full details can be found in the paper [1].},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {193–194},
numpages = {2},
keywords = {adaptive systems, mobile flashcards, language learning},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371708,
author = {Back, Maribeth and Liew, Bee and Dunnigan, Anthony and Vaughan, James},
title = {Mobile Monitoring and Control System for a Food Industry Development Laboratory},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371708},
doi = {10.1145/2371664.2371708},
abstract = {In this demonstration we will show a mobile remote control and monitoring application for a recipe development laboratory at a local chocolate production company. In collaboration with TCHO, a chocolate maker in San Francisco, we built a mobile Web app designed to allow chocolate makers to control their laboratory's machines. Sensor data is imported into the app from each machine in the lab. The mobile Web app is used for control, monitoring, and collaboration. We have tested and deployed this system at the real-world factory and it is now in daily use. This project is designed as part of a research exploration into enhanced collaboration in industrial settings between physically remote people and places, e.g. factories in China with clients in the US.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {195–198},
numpages = {4},
keywords = {laboratory instrumentation, industrial control systems, mobile collaboration, remote monitoring, smart laboratory},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371709,
author = {Cohen, Michael},
title = {POI Poi: Point-of-Interest Poi for Multimodal Tethered Whirling},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371709},
doi = {10.1145/2371664.2371709},
abstract = {We have built haptic interfaces featuring smartphones that use magnetometer-derived orientation sensing to modulate virtual displays. Embedding such devices into swinging a ordances allows a "poi"-style interface, whirling tethered devices, for a novel interaction technique. Dynamic twirling can be used to control multimodal displays - including positions of sources &amp; sinks in spatial sound, subjects (avatars) &amp; objects in virtual environments, and object movies ("turnos") &amp; panoramas ("panos") in image-based renderings. This "practically panoramic" multimodal interface can be enjoyed in an appropriate spot as location-based entertainment, locative media for cross-platform, "mobile ambient" experience.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {199–202},
numpages = {4},
keywords = {cross-platform "ambient mobile" interface, multimodal, situated panorama, locative, practically panoramic interface},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371710,
author = {Willis, Karl D.D. and Poupyrev, Ivan and Hudson, Scott and Mahler, Moshe},
title = {SideBySide: Multi-User Gestural Interaction with Handheld Projectors},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371710},
doi = {10.1145/2371664.2371710},
abstract = {SideBySide is a system designed for ad-hoc multi-user interaction with handheld projectors. SideBySide does not require instrumentation of the environment and can be used almost anywhere. This paper examines the diverse ways that children interact with SideBySide when playing interactive games. Observations from a preliminary user study are presented along with quantitative evaluation of the SideBySide tracking approach.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {203–206},
numpages = {4},
keywords = {projector games, infrared projector, pico projector, handheld projector, multi-user interaction, children, characters},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371711,
author = {Boring, Sebastian and Ledo, David and Chen, Xiang 'Anthony' and Marquardt, Nicolai and Tang, Anthony and Greenberg, Saul},
title = {The Fat Thumb: Using the Thumb's Contact Size for Single-Handed Mobile Interaction},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371711},
doi = {10.1145/2371664.2371711},
abstract = {Modern mobile devices allow a rich set of multi-finger interactions that combine modes into a single fluid act. Such gestures may require the use of both hands: one holding the device while the other is interacting. While on the go, however, only one hand may be available to both hold the device and interact with it. In this demo, we present the Fat Thumb interaction technique, which uses the thumb's contact size as a form of simulated pressure. We present how this can be used, for example, to integrate panning and zooming into a single interaction. Contact size determines the mode (i.e., panning with a small size, zooming with a large one), while thumb movement performs the selected mode.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {207–208},
numpages = {2},
keywords = {mobile device, touch-screen, single-handed interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371712,
author = {Kulik, Alexander and Dittrich, Jan and Froehlich, Bernd},
title = {The Hold-and-Move Gesture for Multi-Touch Interfaces},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371712},
doi = {10.1145/2371664.2371712},
abstract = {We present the hold-and-move interaction technique [2], which uses an implicit input differentiation based on Guiard's "left-hand precedence in action" principle [1]. Hold-and-move associates the first contact point with the background and thus motion input from a single finger always controls panning. In order to manipulate individual items, the background must be held with the first finger. A second finger may then select an individual item and move it in relation to the background. In addition, the first finger may perform panning of the background and clutching while the second finger holds on to the selected item.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {209–210},
numpages = {2},
keywords = {hold-and-move, dwell times, multi-touch},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371713,
author = {Wilson, Graham and Brewster, Stephen and Halvey, Martin and Hughes, Stephen},
title = {Tempera-Tour, Hot Apps, Cool Widgets: Thermal Feedback for Mobile Devices},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371713},
doi = {10.1145/2371664.2371713},
abstract = {Thermal stimulation is a rich, emotive and salient feedback channel that is suitable for mobile HCI. It can act as an alternative non-visual notification channel for mobile situations that are too bumpy or noisy for vibrotactile and audio feedback. It can augment both visual and non-visual feedback to add an extra richness to the interaction experience. In addition, thermal output is entirely private, so it is suitable for quiet environments or when secrecy is important. This demonstration will consist of some example applications which highlight a variety of uses. We show an application titled "Tempera-tour", where environmental temperatures from around the world can be felt. We also show thermal augmentation of visual and audio media as a means of influencing hedonic experience. Finally we show simple thermal widgets, such as a thermal progress bar, ambient notifications and thermal availability information. This demo accompanies the paper "Thermal Icons: Evaluating Structured Thermal Feedback for Mobile Interaction".},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {211–212},
numpages = {2},
keywords = {thermal feedback, mobile interaction, non-visual feedback},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371714,
author = {Alexander, Jason and Lucero, Andr\'{e}s and Subramanian, Sriram},
title = {Tilt Display Demonstration: A Display Surface with Multi-Axis Tilt &amp; Actuation},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371714},
doi = {10.1145/2371664.2371714},
abstract = {This demonstration accompanies a full paper accepted into MobileHCI '12 [1]. We demonstrate a new type of actuatable display, called a Tilt Display, that provides visual feedback combined with multi-axis tilting and vertical actuation. Its ability to physically mutate provides users with an additional information channel that facilitates a range of new applications including collaboration and tangible entertainment while enhancing familiar applications such as terrain modelling by allowing 3D scenes to be rendered in a physical-3D manner.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {213–214},
numpages = {2},
keywords = {actuated displays, nonplanar surface interaction, physical actuation, tilt displays},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371715,
author = {Edge, Darren and Cheng, Kai-Yin and Whitney, Michael and Qian, Yao and Yan, Zhijie and Soong, Frank},
title = {Tip Tap Tones: Mobile Microtraining of Mandarin Sounds},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371715},
doi = {10.1145/2371664.2371715},
abstract = {Learning a second language is hard, especially when the learner's brain must be retrained to identify sounds not present in his or her native language. It also requires regular practice, but many learners struggle to find the time and motivation. Our solution is to break down the challenge of mastering a foreign sound system into minute-long episodes of "microtraining" delivered through mobile gaming. We present the example of Tip Tap Tones - a mobile game with the purpose of helping learners acquire the tonal sound system of Mandarin Chinese. Full details can be found in the paper [1].},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {215–216},
numpages = {2},
keywords = {mobile gaming, language learning, microtraining},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371716,
author = {Lamont, Stuart and Bowman, Richard and Williamson, John and Rath, Matthias and Murray-Smith, Roderick and Padgett, Miles},
title = {Touching the Micron: Tactile Interactions with an Optical Tweezer},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371716},
doi = {10.1145/2371664.2371716},
abstract = {A tablet interface for manipulating microscopic particles is augmented with vibrotactile and audio feedback.The feedback is generated using a novel real-time synthesis library based on approximations to physical processes, and is efficient enough to run on mobile devices, despite their limited computational power. The feedback design and usability testing was done with a realistic simulator on appropriate tasks, allowing users to control objects more rapidly, with fewer errors and applying more consistent forces. The feedback makes the interaction more tangible, giving the user more awareness of changes in the characteristics of the optical tweezers as the number of optical traps changes.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {217–218},
numpages = {2},
keywords = {tactile feedback, real-time synthesis, optical tweezers},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371717,
author = {Chang, Yung-Ju and Hung, Pei-Yao and Newman, Mark},
title = {TraceViz: "Brushing" for Location Based Services},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371717},
doi = {10.1145/2371664.2371717},
abstract = {The popularization of Location Based Services (LBS) has created new challenges for interaction designers in validating the design of their applications. Existing tools designed to play back GPS location traces data streams have shown potential for testing LBS applications and for supporting rapid and reflective prototyping. However, selecting a useful set of location traces from among a large collection remains a difficult task. In this paper, we present TraceViz, the first system that is aimed specifically at supporting LBS designers in exploring, filtering, and selecting location traces. TraceViz employs dynamic queries and "brushing" to allow LBS designers to flexibly adjust their trajectory filter criteria to find location traces of interest. An evaluation performed with eight LBS designers and developers indicates that TraceViz is helpful for rapidly locating useful traces and also highlights areas for future improvement.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {219–220},
numpages = {2},
keywords = {capture and playback, direct manipulation, design tools, information visualization, location-based services},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371718,
author = {Reitz, Katharina and Stockhausen, Claudia and Kr\"{o}mker, Detlef},
title = {Zone of Impulse: Physiological Data Enhanced Gaming},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371718},
doi = {10.1145/2371664.2371718},
abstract = {Zone of Impulse is a fast-paced multiplayer action game, playable on mobile devices. By wearing sensors on the chest and palm the player's emotional state is integrated into gameplay. The processed physiological signals provide the basis for adaptation of several game elements. This creates a more personalized gaming experience and provides additional input modalities to an otherwise "casual" game.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {221–224},
numpages = {4},
keywords = {adaptation, mobile games, biofeedback, gameplay},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3245388,
author = {Eslambolchila, Parisa and Ashbrook, Daniel},
title = {Session Details: Workshops},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245388},
doi = {10.1145/3245388},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371720,
author = {de Sa, Marco and Churchill, Elizabeth F.},
title = {Mobile Augmented Reality: Design, Prototyping and Evaluation},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371720},
doi = {10.1145/2371664.2371720},
abstract = {Mobile devices have increasing computational power. Their sophistication in terms of network access, content rendering and interactivity, and data gathering is growing. Sensors such as microphones, cameras, gyroscopes, and accelerometers are routinely available and devices are enhanced with a various output modalities from visual to sound to vibroctactile. It is thus already possible for us as designers and developers to enhance the way people encounter content, create and experience content and express themselves. With improved access to Internet data service, including location-based services, we are able to build applications and services that profoundly shift the way people interact with their local environment--there are many opportunities to augment, enhance and transform people's experience of physical reality. This workshop will address emerging design techniques for Mobile Augmented Reality (MAR) applications. We invite designers, developers, users and evaluators of augmented and mobile augmented reality applications and/or those interested in augmented location-based services to submit papers that consider the opportunities and challenges of designing effective, engaging and usable augmented reality services and applications for mobile devices.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {225–228},
numpages = {4},
keywords = {mobile devices, design, hci, augmented reality},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371721,
author = {Gon\c{c}alves, Daniel and Carri\c{c}o, Luis and Magnusson, Charlotte},
title = {Second Mobile Accessibility Workshop},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371721},
doi = {10.1145/2371664.2371721},
abstract = {In this document we propose the creation of the Second Mobile Accessibility Workshop at MobileHCI 2012. Mobile Accessibility is an area that has grown both in importance and number of researchers in recent years. After a successful first edition at Interact 2011, we propose to once again bring together researcher and practitioners in a fruitful workshop, leading to synergies and major developments in the area.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {229–232},
numpages = {4},
keywords = {accessibility, workshop, mobile accessibility},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371722,
author = {Sundstr\"{o}m, Petra and Wilfinger, David and Meschtscherjakov, Alexander and Tscheligi, Manfred and Schmidt, Albrecht and Juhlin, Oskar},
title = {The Car as an Arena for Gaming},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371722},
doi = {10.1145/2371664.2371722},
abstract = {This workshop will be about contextual gaming where the arena for gaming is the car, and the space inside and outside the car while driving. We aim to gather both practitioners and academics to work out the possibilities and challenges of this design space that to our experience has been slightly forgotten about since Juhlin and colleagues' excellent work on the Backseat Playground [1], [2].},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {233–236},
numpages = {4},
keywords = {automotive gaming},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371723,
author = {Alexander, Jason and Kildal, Johan and Hornbaek, Kasper and Aaltonen, Viljakaisa and Lucero, Andr\'{e}s and Subramanian, Sriram},
title = {Interaction with Deformable Displays},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371723},
doi = {10.1145/2371664.2371723},
abstract = {Technological developments in display technologies allow us to explore the design of mobile devices that extend beyond the rigid, flat screen surfaces with which we are familiar. The next generation mobile devices will instead include deformable displays that users can physically push, pull, bend or flex or have those actions performed by the device so that it physically mutates to better represent the on-screen content.This workshop is interested in all aspects of Deformable Displays: from the methods, materials and alternatives for the construction of such displays to the design of input techniques for such devices and how shape change can be used as an additional channel for output.This workshop will bring together product developers, interaction designers and academics to create a community around deformable displays. We will preview the state-of-the-art through case studies and identify key research themes in this area.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {237–240},
numpages = {4},
keywords = {display surfaces, shape-changing displays, deformable displays, interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371724,
author = {Poppinga, Benjamin and Cramer, Henriette and B\"{o}hmer, Matthias and Morrison, Alistair and Bentley, Frank and Henze, Niels and Rost, Mattias and Michahelles, Florian},
title = {Research in the Large 3.0: App Stores, Wide Distribution, and Big Data in MobileHCI Research},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371724},
doi = {10.1145/2371664.2371724},
abstract = {Mobile HCI studies are often conducted in a highly controlled environment and with a small convenient sample. The findings cannot always be generalized to the behaviour of real users in real contexts. In contrast, researchers recently started to use apps and other wide distribution channels as an apparatus for mobile HCI research. Publishing apps in mobile application stores and public APIs for mobile services enable researchers to study large samples in their 'natural habitat'. This workshop continues the successful Research in the Large workshop series held at UbiComp 2010 and 2011. Relevant topics include the design of large-scale studies, reaching target users, dealing with new types of evaluation data, and heterogeneous usage contexts. We seek ways to systematically collect, analyse and make sense of large datasets, potentially in real-time. The goal of this workshop is to provide a forum for researchers and developers from academia and industry to exchange experiences, insights and strategies for wide distribution of user studies towards large-scale mobile HCI research.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {241–244},
numpages = {4},
keywords = {app store, game, large-scale, mobile hci, user study},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371725,
author = {Church, Karen and Teevan, Jaime and Jones, Matt},
title = {Workshop on Mobility and Web Behaviors (MWB)},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371725},
doi = {10.1145/2371664.2371725},
abstract = {The goal of this workshop is to investigate the notion of mobility in the context of search and Web usage and to identify the most promising research directions with respect to enriching future mobility focused web services. In recent times, there has been a dramatic shift in what it means to be mobile. Mobile was traditionally associated with on-the-move, personal, portable and dynamic. While today, an increasing number of users are accessing the mobile Web in more stationary and familiar settings like at home and at work as well as in more social settings like in the presence of family and friends. Designing future mobile Web experiences requires a deeper understanding of these new information needs, behaviors and underlying motivations of mobile users.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {245–248},
numpages = {4},
keywords = {mobile web, user behavior, mobility, mobile search, web behavior, mobile computing},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371726,
author = {Swaminathan, Rahul and Rohs, Michael and \"{A}ngeslev\"{a}, Jussi},
title = {Mobile Vision (MobiVis): Vision-Based Applications and HCI},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371726},
doi = {10.1145/2371664.2371726},
abstract = {The explosion in smartphone and other mobile/hand-held devices' capabilities are increasingly being exploited to bring vision-based mobile applications to the user. Applications using technologies such as image recognition, augmented reality, amongst others are altering the way we interact with the world around us. This workshop aims to address the fundamental vision-based technologies that enable new interaction modalities and metaphors. It also addresses the exploration of new radical or experimental interactions as well as new design-oriented and social applications. The aim is to promote a discussion among researchers and practitioners working in the area of mobile HCI from the standpoint of computer vision as an enabling technology for new forms of mobile interaction, new application categories, and implications for user experience and design.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {249–250},
numpages = {2},
keywords = {augmented reality, computer vision, mobile, interaction, design, vision-based applications},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371727,
author = {Nanavati, Amit A. and Rajput, Nitendra and Rudnicky, Alexander and Turunen, Markku and Sandholm, Thomas and Munteanu, Cosmin and Penn, Gerald},
title = {SiMPE: 7th Workshop on Speech and Sound in Mobile and Pervasive Environments},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371727},
doi = {10.1145/2371664.2371727},
abstract = {The SiMPE workshop series started in 2006 [2] with the goal of enabling speech processing on mobile and embedded devices to meet the challenges of pervasive environments (such as noise) and leveraging the context they offer (such as location). SiMPE 2010 and 2011 brought together researchers from the speech and the HCI communities. Multimodality got more attention in SiMPE 2008 than it had received in the previous years. In SiMPE 2007, the focus was on developing regions. Speech User interaction in cars was a focus area in 2009.With SiMPE 2012, the 7th in the series, we hope to explore the area of speech along with sound. When using the mobile in an eyes-free manner, it is natural and convenient to hear about notifications and events. The arrival of an SMS has used a very simple sound based notification for a long time now. The technologies underlying speech processing and sound processing are quite different and these communities have been working mostly independent of each other. And yet, for multimodal interactions on the mobile, it is perhaps natural to ask whether and how speech and sound can be mixed and used more effectively and naturally.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {251–254},
numpages = {4},
keywords = {speech processing, sound, audio interaction, pervasive computing, mobile computing},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3245389,
author = {Bentley, Frank and Cramer, Henriette},
title = {Session Details: Panel},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245389},
doi = {10.1145/3245389},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371664.2371729,
author = {Kjeldskov, Jesper and Cheverst, Keith and de S\'{a}, Marco and Jones, Matt and Murray-Smith, Roderick},
title = {Research Methods in Mobile HCI: Trends and Opportunities},
year = {2012},
isbn = {9781450314435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371664.2371729},
doi = {10.1145/2371664.2371729},
abstract = {This panel addresses the past, present and future of mobile HCI research in terms of methods and focus. The panel takes its offset in a new literature survey following up from Kjeldskov and Graham's survey from Mobile HCI 2003 [6]. Based on this, and their own experiences, the panelists will outline and discuss their views on current methodological trends in mobile HCI research, and suggest and discuss what opportunities they see for responding to these trends and pushing the research field further forward.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services Companion},
pages = {255–260},
numpages = {6},
keywords = {literature survey, research purpose, research methods},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251533,
author = {Kaye, Joseph},
title = {Session Details: Patterns of Use},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251533},
doi = {10.1145/3251533},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371576,
author = {M\"{u}ller, Hendrik and Gove, Jennifer and Webb, John},
title = {Understanding Tablet Use: A Multi-Method Exploration},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371576},
doi = {10.1145/2371574.2371576},
abstract = {Tablet ownership has grown rapidly over the last year. While market research surveys have helped us understand the demographics of tablet ownership and provided early insights into usage, there is little comprehensive research available. This paper describes a multi-method research effort that employed written and video diaries, in-home interviews, and contextual inquiry observations to learn about tablet use across three locations in the US. Our research provides an in-depth picture of frequent tablet activities (e.g., checking emails, playing games, social networking), locations of use (e.g., couch, bed, table), and contextual factors (e.g., watching TV, eating, cooking). It also contributes an understanding of why and how people choose to use tablets. Popular activities for tablet use, such as media consumption, shopping, cooking, and productivity are also explored. The findings from our research provide design implications and opportunities for enriching the tablet experience, and agendas for future research.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {1–10},
numpages = {10},
keywords = {contextual inquiry, mobile devices, field interviews, diary study, video diary, user requirements, tablet},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371577,
author = {Rahmati, Ahmad and Tossell, Chad and Shepard, Clayton and Kortum, Philip and Zhong, Lin},
title = {Exploring IPhone Usage: The Influence of Socioeconomic Differences on Smartphone Adoption, Usage and Usability},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371577},
doi = {10.1145/2371574.2371577},
abstract = {Previous studies have found that smartphone users differ by orders of magnitude. We explore this variability to understand how users install and use native applications in ecologically-valid environments. A quasi-experimental approach is applied to compare how users in different socio-economic status (SES) groups adopt new smartphone technology along with how applications are installed and used. We present a longitudinal study of 34 iPhone 3GS users. 24 of these participants were chosen from two carefully selected SES groups who were otherwise similar and balanced. Usage data collected through an in-device programmable logger, as well as several structured interviews, identify similarities, differences, and trends, and highlight systematic differences in smartphone usage. A group of 10 lower SES participants were later recruited and confirm the influence of SES diversity on device usage. Among our findings are that a large number of applications were uninstalled, lower SES groups spent more money on applications and installed more applications overall, and the lowest SES group perceived the usability of their iPhones poorly in comparison to the other groups. We further discuss the primary reasons behind this low score, and suggest design implications to better support users across SES brackets.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {11–20},
numpages = {10},
keywords = {user study, diversity, ses, iphone, smartphones, applications, socioeconomic status, mobile},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371578,
author = {Carrascal, Juan Pablo and de Oliveira, Rodrigo and Cherubini, Mauro},
title = {A Note Paper on Note-Taking: Understanding Annotations of Mobile Phone Calls},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371578},
doi = {10.1145/2371574.2371578},
abstract = {Note-taking has been largely studied in contexts of work meetings. However, often people need to remember information exchanged in informal situations, such as during mobile phone conversations. In this paper we present a study conducted with 59 subjects who had their phone calls semi-automatically transcribed for later annotation. Analysis of the 621 calls and the subjects' annotation behavior revealed that phone recall is indeed a relevant user need. Furthermore, identifying patterns in phone calls such as numbers and names provide better indicators of annotation than variables related to the callers' profile, context of calls, or quality of service. Our findings suggest implications for the design of mobile phone annotation tools.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {21–24},
numpages = {4},
keywords = {mobile information, annotation, phone call, context},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371579,
author = {Stefanis, Vassilios and Plessas, Athanasios and Komninos, Andreas and Garofalakis, John},
title = {Patterns of Usage and Context in Interaction with Communication Support Applications in Mobile Devices},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371579},
doi = {10.1145/2371574.2371579},
abstract = {Contact lists are one of the most frequently used applications on mobile devices. Users are reluctant to delete or remove contacts from their repositories and as modern smartphones provide an unlimited contact list storage space, these become increasingly large, sometimes measuring several hundred entries. In this paper we present our findings from two experiments with user-subjective and quantitative data concerning the use of mobile contact lists. We examine the role that frequency and recency of usage plays in the determination of a contact's importance, with a view to aid the speed and efficacy of the information seeking and retrieval process during the use of the contact list application.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {25–34},
numpages = {10},
keywords = {mobile pim, contact lists, context awareness},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251534,
author = {Roudaut, Anne},
title = {Session Details: Touch Input},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251534},
doi = {10.1145/3251534},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371581,
author = {Stewart, Craig and Hoggan, Eve and Haverinen, Laura and Salamin, Hugues and Jacucci, Giulio},
title = {An Exploration of Inadvertent Variations in Mobile Pressure Input},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371581},
doi = {10.1145/2371574.2371581},
abstract = {This paper reports the results of an exploratory study into inadvertent grip pressure changes on mobile devices with a focus on the differences between static lab-based and mobile walking environments. The aim of this research is to inform the design of more robust pressure input techniques that can accommodate dynamic mobile usage. The results of the experiment show that there are significant differences in grip pressure in static and walking conditions with high levels of pressure variation in both. By combining the pressure data with accelerometer data, we show that grip pressure is closely related to user movement.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {35–38},
numpages = {4},
keywords = {mobile interaction, accidental triggers, pressure, implicit interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371582,
author = {Boring, Sebastian and Ledo, David and Chen, Xiang 'Anthony' and Marquardt, Nicolai and Tang, Anthony and Greenberg, Saul},
title = {The Fat Thumb: Using the Thumb's Contact Size for Single-Handed Mobile Interaction},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371582},
doi = {10.1145/2371574.2371582},
abstract = {Modern mobile devices allow a rich set of multi-finger interactions that combine modes into a single fluid act, for example, one finger for panning blending into a two-finger pinch gesture for zooming. Such gestures require the use of both hands: one holding the device while the other is interacting. While on the go, however, only one hand may be available to both hold the device and interact with it. This mostly limits interaction to a single-touch (i.e., the thumb), forcing users to switch between input modes explicitly. In this paper, we contribute the Fat Thumb interaction technique, which uses the thumb's contact size as a form of simulated pressure. This adds a degree of freedom, which can be used, for example, to integrate panning and zooming into a single interaction. Contact size determines the mode (i.e., panning with a small size, zooming with a large one), while thumb movement performs the selected mode. We discuss nuances of the Fat Thumb based on the thumb's limited operational range and motor skills when that hand holds the device. We compared Fat Thumb to three alternative techniques, where people had to precisely pan and zoom to a predefined region on a map and found that the Fat Thumb technique compared well to existing techniques.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {39–48},
numpages = {10},
keywords = {mobile device, single-handed interaction, touch-screen},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371583,
author = {Kulik, Alexander and Dittrich, Jan and Froehlich, Bernd},
title = {The Hold-and-Move Gesture for Multi-Touch Interfaces},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371583},
doi = {10.1145/2371574.2371583},
abstract = {We present the two-finger gesture hold-and-move as an alternative to the disruptive long-tap which utilizes dwell times for switching from panning to object dragging mode in touch interfaces. We make use of a second finger for object selection and manipulation while workspace panning is operated with the first finger. Since both operations can be performed simultaneously, the cumbersome and hard-to-control autoscrolling function is no longer needed when dragging an object beyond the currently visible viewport. Single-finger panning and pinch zooming still work as expected. A user study revealed that hold-and-move enables faster object dragging than the conventional dwell-time approach and that it is preferred by most users.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {49–58},
numpages = {10},
keywords = {manipulation, dwell times, multi-touch, navigation, hold-and-move},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371584,
author = {Kim, Seon Joo and Ng, Hongwei and Winkler, Stefan and Song, Peng and Fu, Chi-Wing},
title = {Brush-and-Drag: A Multi-Touch Interface for Photo Triaging},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371584},
doi = {10.1145/2371574.2371584},
abstract = {Due to the convenience of taking pictures with various digital cameras and mobile devices, people often end up with multiple shots of the same scene with only slight variations. To enhance photo triaging, which is a very common photowork activity, we propose an effective and easy-to-use brush-and-drag interface that allows the user to interactively explore and compare photos within a broader scene context. First, we brush to mark an area of interest on a photo with our finger(s); our tailored segmentation engine automatically determines corresponding image elements among the photos. Then, we can drag the segmented elements from different photos across the screen to explore them simultaneously, and further perform simple finger gestures to interactively rank photos, select favorites for sharing, or to remove unwanted ones. This novel interaction method was implemented on a consumer-level tablet computer and demonstrated to offer effective interactions in a user study.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {59–68},
numpages = {10},
keywords = {digital photo collections, user interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251535,
author = {Bentley, Frank and Cramer, Henriette},
title = {Session Details: Panel Discussion},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251535},
doi = {10.1145/3251535},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371586,
author = {Kjeldskov, Jesper and Paay, Jeni},
title = {A Longitudinal Review of Mobile HCI Research Methods},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371586},
doi = {10.1145/2371574.2371586},
abstract = {This paper revisits a research methods survey from 2003 and contrasts it with a survey from 2010. The motivation is to gain insight about how mobile HCI research has evolved over the last decade in terms of approaches and focus. The paper classifies 144 publications from 2009 published in 10 prominent outlets by their research methods and purpose. Comparing this to the survey for 2000-02 show that mobile HCI research has changed methodologically. From being almost exclusively driven by engineering and applied research, current mobile HCI is primarily empirically driven, involves a high number of field studies, and focus on evaluating and understanding, as well as engineering. It has also become increasingly multi-methodological, combining and diversifying methods from different disciplines. At the same time, new opportunities and challenges have emerged.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {69–78},
numpages = {10},
keywords = {research purpose, research methods, literature survey},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251536,
author = {Boring, Sebastian},
title = {Session Details: Off and around the Screen},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251536},
doi = {10.1145/3251536},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371588,
author = {Hossain, Zahid and Hasan, Khalad and Liang, Hai-Ning and Irani, Pourang},
title = {EdgeSplit: Facilitating the Selection of off-Screen Objects},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371588},
doi = {10.1145/2371574.2371588},
abstract = {Devices with small viewports (e.g., smartphones or GPS) result in interfaces where objects of interest can easily reside outside the view, into off-screen space. Researchers have addressed this challenge and have proposed visual cues to assist users in perceptually locating off-screen objects. However, little attention has been placed on methods for selecting the objects. Current designs of off-screen cues can result in overlaps that can make it difficult to use the cues as handles through which users can select the off-screen objects they represent. In this paper, we present EdgeSplit, a technique that facilitates both the visualization and selection of off-screen objects on small devices. EdgeSplit exploits the space around the device's borders to display proxies of off-screen objects and then partitions the border regions to allow for non-overlapping areas that make selection of objects easier. We present an effective algorithm that provides such partitioning and demonstrate the effectiveness of EdgeSplit for selecting off-screen objects.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {79–82},
numpages = {4},
keywords = {off-screen target selection, off-screen object visualization},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371589,
author = {Jones, Brett and Sodhi, Rajinder and Forsyth, David and Bailey, Brian and Maciocci, Giuliano},
title = {Around Device Interaction for Multiscale Navigation},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371589},
doi = {10.1145/2371574.2371589},
abstract = {In this paper we study the design space of free-space interactions for multiscale navigation afforded by mobile depth sensors. Such interactions will have a greater working volume, more fluid control and avoid screen occlusion effects intrinsic to touch screens. This work contributes the first study to show that mobile free-space interactions can be as good as touch. We also analyze sensor orientation and interaction volume usage, resulting in strong implications for how sensors should be placed on mobile devices. We describe a user study evaluating mobile free-space navigation techniques and the impacts of sensor orientation on user experience. Finally, we discuss guidelines for future mobile free-space interaction techniques and sensor design.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {83–92},
numpages = {10},
keywords = {pan and zoom, free-space interaction, depth sensor, around device interaction, multiscale navigation},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371590,
author = {Burigat, Stefano and Chittaro, Luca and Vianello, Andrea},
title = {Dynamic Visualization of Large Numbers of Off-Screen Objects on Mobile Devices: An Experimental Comparison of Wedge and Overview+detail},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371590},
doi = {10.1145/2371574.2371590},
abstract = {Overview+Detail [25] and Wedge [16] have been proposed in the literature as effective approaches to resolve the off-screen objects problem on mobile devices. However, they have been studied with a small number of off-screen objects and (in most studies) with static scenarios, in which users did not have to perform any navigation activity. In this paper, we propose improvements to Wedge and Overview+Detail which are specifically aimed at simplifying their use in dynamic scenarios that involve large numbers of off-screen objects. We compare the effectiveness of the two approaches in the considered scenario with a user study, whose results show that Overview+Detail allows users to be faster in searching for off-screen objects and more accurate in estimating their location.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {93–102},
numpages = {10},
keywords = {map navigation, mobile devices, wedge, peripheral awareness, visualization, off-screen objects, overview+detail},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371591,
author = {Hasan, Khalad and Yang, Xing-Dong and Liang, Hai-Ning and Irani, Pourang},
title = {How to Position the Cursor? An Exploration of Absolute and Relative Cursor Positioning for Back-of-Device Input},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371591},
doi = {10.1145/2371574.2371591},
abstract = {Observational studies indicate that most people use one hand to interact with their mobile devices. Interaction on the back-of-devices (BoD) has been proposed to enhance one-handed input for various tasks, including selection and gesturing. However, we do not possess a good understanding of some fundamental issues related to one-handed BoD input. In this paper, we attempt to fill this gap by conducting three studies. The first study explores suitable selection techniques; the second study investigates the performance and suitability of the two main modes of cursor movement: Relative and Absolute; and the last study examines solutions to the problem of reaching the lower part of the device. Our results indicate that for BoD interaction, relative input is more efficient and accurate for cursor positioning and target selection than absolute input. Based on these findings provide guidelines for designing BoD interactions for mobile devices.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {103–112},
numpages = {10},
keywords = {relative and absolute cursor positioning, back-of-device input, touch input, selection mechanism},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251537,
author = {Brumby, Duncan},
title = {Session Details: Trust and Privacy},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251537},
doi = {10.1145/3251537},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371593,
author = {Hillman, Serena and Neustaedter, Carman and Bowes, John and Antle, Alissa},
title = {Soft Trust and MCommerce Shopping Behaviours},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371593},
doi = {10.1145/2371574.2371593},
abstract = {Recently, there has been widespread growth of shopping and buying on mobile devices, termed mCommerce. With this comes a need to understand how to best design experiences for mobile shopping. To help address this, we conducted a diary and interview study with mCommerce shoppers who have already adopted the technology and shop on their mobile devices regularly. Our study explores typical mCommerce routines and behaviours along with issues of soft trust, given its long-term concern for eCommerce. Our results describe spontaneous purchasing and routine shopping behaviours where people gravitate to their mobile device even if a computer is nearby. We found that participants faced few trust issues because they had limited access to unknown companies. In addition, app marketplaces and recommendations from friends offered a form of brand protection. These findings suggest that companies can decrease trust issues by tying mCommerce designs to friend networks and known marketplaces. The caveat for shoppers, however, is that they can be easily lured into a potentially false sense of trust.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {113–122},
numpages = {10},
keywords = {mobile, commerce, trust, shopping},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371594,
author = {Krishnamoorthy, Shivsubramani and Agrawala, Ashok},
title = {Context-Aware, Technology Enabled Social Contribution for Public Safety Using M-Urgency},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371594},
doi = {10.1145/2371574.2371594},
abstract = {M-Urgency is a public safety system that (1) redefines how emergency calls are made to a Public Safety Answering Point (PSAP) like the 911 system and (2) is designed to be context-aware of the situation in which it is used. M-Urgency enables mobile users to stream live audio and video from their devices to local PSAP along with the audio stream, the real time location and the relevant context information, enabling appropriate and prompt service. This paper presents a new feature, incorporated in M-Urgency, that enables social contribution whereby users in the vicinity of an emergency event can help operation conducted by the emergency personnel through verbal/visual information useful to them or by providing assistance. Our experiments show a very positive response from the participant to the capabilities of our system. In this paper, we also discuss the social implications such as privacy and security for this system.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {123–132},
numpages = {10},
keywords = {m-urgency, social computing, context, context-aware, emergency system},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371595,
author = {Dahl, Yngve and Holb\o{}, Kristine},
title = {"There Are No Secrets Here!": Professional Stakeholders' Views on the Use of GPS for Tracking Dementia Patients},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371595},
doi = {10.1145/2371574.2371595},
abstract = {This paper investigates the attitudes of professional stakeholders involved in dementia care to GPS tracking of dementia patients. Data were gathered via focus groups that met in the context of a field experiment in which patients' spatial activities were tracked using GPS. Four main topics emerged: (1) different perspectives on the purpose of the measure; (2) privacy concerns and underlying premises for employing GPS technology in professional care, including; (3) knowledge about patients; and (4) routines for use.Our findings highlight the need to consider carefully which aspects of dementia patients' movements a GPS tracking system should provide to care workers, and how positioning information should be presented. We found that the level of detail required is intimately linked to the purpose of use. Positioning data that were regarded as being irrelevant for the immediate situation could be perceived as violations of patient privacy and damaging for the system's efficiency.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {133–142},
numpages = {10},
keywords = {autonomy, electronic tracking, privacy, dementia care, gps, awareness},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371596,
author = {Tholander, Jakob and St\r{a}hl, Anna and Jacobsson, Mattias and Schultz, Lisen and Borgstr\"{o}m, Sara and Normark, Maria and Kosmack-Vaara, Elsa},
title = {But i Don't Trust My Friends: Ecofriends -- an Application for Reflective Grocery Shopping},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371596},
doi = {10.1145/2371574.2371596},
abstract = {The Ecofriends application was designed to encourage people to reflect on their everyday grocery shopping from social and ecological perspectives. Ecofriends portrays the seasonality of various grocery products as being socially constructed, emphasizing subjective dimensions of what it means for a product to be in season, rather than attempting to communicate it as an established fact. It provides the user with unexpected information (news, weather, blog posts and tweets) about the place where the product was grown, and visualises how the product's popularity shifts throughout the year, among the user's friends, among chefs and other food experts, and the general public. Key findings from users' first encounters with the system are presented. In particular, we discuss aspects of trust, information fragments as catalysts, and how several of the participants were challenged by the system's portrayal of season.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {143–146},
numpages = {4},
keywords = {social construction, subjectivity, mobile interaction, sustainable interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251538,
author = {Holmquist, Lars Erik},
title = {Session Details: Body, Space and Motion},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251538},
doi = {10.1145/3251538},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371598,
author = {Negulescu, Matei and Ruiz, Jaime and Lank, Edward},
title = {A Recognition Safety Net: Bi-Level Threshold Recognition for Mobile Motion Gestures},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371598},
doi = {10.1145/2371574.2371598},
abstract = {Designers of motion gestures for mobile devices face the difficult challenge of building a recognizer that can separate gestural input from motion noise. A threshold value is often used to classify motion and effectively balances the rates of false positives and false negatives. We present a bi-level threshold recognition technique designed to lower the rate of recognition failures by accepting either a tightly thresholded gesture or two consecutive possible gestures recognized by a relaxed model. Evaluation of the technique demonstrates that the technique can aid in recognition for users who have trouble performing motion gestures. Lastly, we suggest the use of bi-level thresholding to scaffold the learning of gestures.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {147–150},
numpages = {4},
keywords = {safety net, bi-level thresholding, motion gestures},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371599,
author = {Chen, Xiang 'Anthony' and Marquardt, Nicolai and Tang, Anthony and Boring, Sebastian and Greenberg, Saul},
title = {Extending a Mobile Device's Interaction Space through Body-Centric Interaction},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371599},
doi = {10.1145/2371574.2371599},
abstract = {Modern mobile devices rely on the screen as a primary input modality. Yet the small screen real-estate limits interaction possibilities, motivating researchers to explore alternate input techniques. Within this arena, our goal is to develop Body-Centric Interaction with Mobile Devices: a class of input techniques that allow a person to position and orient her mobile device to navigate and manipulate digital content anchored in the space on and around the body. To achieve this goal, we explore such interaction in a bottom-up path of prototypes and implementations. From our experiences, as well as by examining related work, we discuss and present three recurring themes that characterize how these interactions can be realized. We illustrate how these themes can inform the design of Body-Centric Interactions by applying them to the design of a novel mobile browser application. Overall, we contribute a class of mobile input techniques where interactions are extended beyond the small screen, and are instead driven by a person's movement of the device on and around the body.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {151–160},
numpages = {10},
keywords = {body-centric interaction, mobile interaction, mobile device},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371600,
author = {Alexander, Jason and Lucero, Andr\'{e}s and Subramanian, Sriram},
title = {Tilt Displays: Designing Display Surfaces with Multi-Axis Tilting and Actuation},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371600},
doi = {10.1145/2371574.2371600},
abstract = {We present a new type of actuatable display, called Tilt Displays, that provide visual feedback combined with multi-axis tilting and vertical actuation. Their ability to physically mutate provides users with an additional information channel that facilitates a range of new applications including collaboration and tangible entertainment while enhancing familiar applications such as terrain modelling by allowing 3D scenes to be rendered in a physical-3D manner. Through a mobile 3x3 custom built prototype, we examine the design space around Tilt Displays, categorise output modalities and conduct two user studies. The first, an exploratory study examines users' initial impressions of Tilt Displays and probes potential interactions and uses. The second takes a quantitative approach to understand interaction possibilities with such displays, resulting in the production of two user-defined gesture sets: one for manipulating the surface of the Tilt Display, the second for conducting everyday interactions.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {161–170},
numpages = {10},
keywords = {tilt displays, actuated displays, physical actuation, non-planar surface interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371601,
author = {Cauchard, Jessica and L\"{o}chtefeld, Markus and Fraser, Mike and Kr\"{u}ger, Antonio and Subramanian, Sriram},
title = {M+pSpaces: Virtual Workspaces in the Spatially-Aware Mobile Environment},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371601},
doi = {10.1145/2371574.2371601},
abstract = {We introduce spatially-aware virtual workspaces for the mobile environment. The notion of virtual workspaces was initially conceived to alleviate mental workload in desktop environments with limited display real-estate. Using spatial properties of mobile devices, we translate this approach and illustrate that mobile virtual workspaces greatly improve task performance for mobile devices. In a first study, we compare our spatially-aware prototype (mSpaces) to existing context switching methods for navigating amongst multiple tasks in the mobile environment. We show that users are faster, make more accurate decisions and require less mental and physical effort when using spatially-aware prototypes. We furthermore prototype pSpaces and m+pSpaces, two spatially-aware systems equipped with pico-projectors as auxiliary displays to provide dual-display capability to the handheld device. A final study reveals advantages of each of the different configurations and functionalities when comparing all three prototypes. Drawing on these findings, we identify design considerations to create, manipulate and manage spatially-aware virtual workspaces in the mobile environment.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {171–180},
numpages = {10},
keywords = {m+pspaces, spatially-aware displays, pico-projectors, multidisplay environments, mobile virtual workspace},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251539,
author = {Cherubini, Mauro},
title = {Session Details: Understanding Use},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251539},
doi = {10.1145/3251539},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371603,
author = {Frohlich, David and Robinson, Simon and Eglinton, Kristen and Jones, Matt and Vartiainen, Elina},
title = {Creative Cameraphone Use in Rural Developing Regions},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371603},
doi = {10.1145/2371574.2371603},
abstract = {In this paper we consider the current and future use of cameraphones in the context of rural South Africa, where many people do not have access to the latest models and ICT infrastructure is poor. We report a new study of cameraphone use in this setting, and the design and testing of a novel application for creating rich multimedia narratives and materials. We argue for better creative media applications on mobile platforms in this region, and greater attention to their local use.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {181–190},
numpages = {10},
keywords = {mobile, storytelling, development, cameraphone},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371604,
author = {Liu, Jie and Xu, Wenchang and Shi, Yuanchun},
title = {AutoWeb: Automatic Classification of Mobile Web Pages for Revisitation},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371604},
doi = {10.1145/2371574.2371604},
abstract = {Revisitation in mobile Web browsers takes more time than that in desktop browsers due to the limitations of mobile phones. In this paper, we propose AutoWeb, a novel approach to speed up revisitation in mobile Web browsing. In AutoWeb, opened Web pages are automatically classified into different groups based on their contents. Users can more quickly revisit an opened Web page by narrowing down search scope into a group of pages that share the same topic. We evaluated the classification accuracy and the accuracy is 92.4%. Three experiments were conducted to investigate revisitation performance in three specific tasks. Results show AutoWeb can save significant time for revisitation by 29.5%, especially for long time Web browsing, and that it improves overall mobile Web revisitation experience. We also compare automatic classification with other revisitation methods.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {191–200},
numpages = {10},
keywords = {automatic classification, mobile web, revisitation},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371605,
author = {Lundstr\"{o}m, Anders and Bogdan, Cristian and Kis, Filip and Olsson, Ingvar and Fahl\'{e}n, Lennart},
title = {Enough Power to Move: Dimensions for Representing Energy Availability},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371605},
doi = {10.1145/2371574.2371605},
abstract = {Energy and design of energy-feedback are becoming increasingly important in the mobile HCI community. Our application area concerns electric vehicles, we thus depart from home and workplace appliances and address range and energy anxiety caused by short driving distance capabilities and long charging times in mobile settings. Meanwhile some research has been done on energy management of mobile devices, less has been done on mobility devices like electric vehicles. We explore this topic by letting conventional fuel car drivers reflect on their current driving habits through an exploration tool that we developed. Our results demonstrate three dimensions related to energy availability to consider for design of energy dependent mobility devices and provide explanations on how these dimensions could be utilize in our design through energy visualizations. With this we contributed not only by demonstrating aspects of energy availability and mobility, but also through opening up for new interesting possibilities and inquires in our and possibly other domains.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {201–210},
numpages = {10},
keywords = {energy availability, interaction design, energy, range anxiety, information visualization, mobility, electric vehicle, sustainability},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251540,
author = {Rohs, Michael},
title = {Session Details: Mobile Augmented Reality},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251540},
doi = {10.1145/3251540},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371607,
author = {Kaufmann, Bonifaz and Ahlstr\"{o}m, David},
title = {Revisiting Peephole Pointing: A Study of Target Acquisition with a Handheld Projector},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371607},
doi = {10.1145/2371574.2371607},
abstract = {Peephole pointing is a promising interaction technique for large workspaces that contain more information than can be appropriately displayed on a single screen. In peephole pointing a window to the virtual workspace is moved in space to reveal additional content. In 2008, two different models for peephole pointing were discussed. Cao, Li and Balakrishnan proposed a two-component model, whereas Rohs and Oulasvirta investigated a similar model, but concluded that Fitts' law is sufficient for predicting peephole pointing performance. We present a user study performed with a handheld projector showing that Cao et al.'s model only outperforms Fitts' law in prediction accuracy when different peephole sizes are used and users have no prior knowledge of target location. Nevertheless, Fitts' law succeeds under the conditions most likely to occur. Additionally, we show that target overshooting is a key characteristic of peephole pointing and present the implementation of an orientation aware handheld projector that enables peephole interaction without instrumenting the environment.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {211–220},
numpages = {10},
keywords = {modeling, pico projector, fitts' law, peephole pointing},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371608,
author = {de S\'{a}, Marco and Churchill, Elizabeth},
title = {Mobile Augmented Reality: Exploring Design and Prototyping Techniques},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371608},
doi = {10.1145/2371574.2371608},
abstract = {As mobile devices are enhanced with more sensors, powerful embedded cameras, and increased processing power and features, new user experiences become possible. A good example is the recent emergence of Augmented Reality (AR) applications that are designed for personal use while people are on-the-go. However, designing effective and usable AR experiences for mobile devices poses challenges for the design process. In this paper we outline reasons why simulating a compelling, mobile AR experience with sufficient veracity for effective formative design is a challenge, and present our work on prototyping and evaluation techniques for mobile AR. An experiment within the context of an ongoing design project (Friend Radar) is presented along with resulting findings and guidelines. We reflect on the benefits and drawbacks of low, mixed and high fidelity prototypes for mobile AR by framing them into a set of analytic categories extracted from the existing literature on prototyping and design.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {221–230},
numpages = {10},
keywords = {mobile hci augmented reality (ar), design process, mobile, design, service design, interview, prototyping, experiment, methodology},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371609,
author = {Grubert, Jens and Morrison, Ann and Munz, Helmut and Reitmayr, Gerhard},
title = {Playing It Real: Magic Lens and Static Peephole Interfaces for Games in a Public Space},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371609},
doi = {10.1145/2371574.2371609},
abstract = {Magic lens and static peephole interfaces are used in numerous consumer mobile phone applications such as Augmented Reality browsers, games or digital map applications in a variety of contexts including public spaces. Interface performance has been evaluated for various interaction tasks involving spatial relationships in a scene. However, interface usage outside laboratory conditions has not been considered in depth in the evaluation of these interfaces.We present findings about the usage of magic lens and static peephole interfaces for playing a find-and-select game in a public space and report on the reactions of the public audience to participants' interactions.Contrary to our expectations participants favored the magic lens over a static peephole interface despite tracking errors, fatigue and potentially conspicuous gestures. Most passersby did not pay attention to the participants and vice versa. A comparative laboratory experiment revealed only few differences in system usage.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {231–240},
numpages = {10},
keywords = {static peephole, magic lens, field trial, augmented reality},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371610,
author = {Gauglitz, Steffen and Lee, Cha and Turk, Matthew and H\"{o}llerer, Tobias},
title = {Integrating the Physical Environment into Mobile Remote Collaboration},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371610},
doi = {10.1145/2371574.2371610},
abstract = {We describe a framework and prototype implementation for unobtrusive mobile remote collaboration on tasks that involve the physical environment. Our system uses the Augmented Reality paradigm and model-free, markerless visual tracking to facilitate decoupled, live updated views of the environment and world-stabilized annotations while supporting a moving camera and unknown, unprepared environments. In order to evaluate our concept and prototype, we conducted a user study with 48 participants in which a remote expert instructed a local user to operate a mock-up airplane cockpit. Users performed significantly better with our prototype (40.8 tasks completed on average) as well as with static annotations (37.3) than without annotations (28.9). 79% of the users preferred our prototype despite noticeably imperfect tracking.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {241–250},
numpages = {10},
keywords = {markerless visual tracking, video-mediated communication, telecollaboration, user study, augmented reality},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251541,
author = {Rukzio, Enrico},
title = {Session Details: Understanding Touch},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251541},
doi = {10.1145/3251541},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371612,
author = {Azenkot, Shiri and Zhai, Shumin},
title = {Touch Behavior with Different Postures on Soft Smartphone Keyboards},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371612},
doi = {10.1145/2371574.2371612},
abstract = {Text entry on smartphones is far slower and more error-prone than on traditional desktop keyboards, despite sophisticated detection and auto-correct algorithms. To strengthen the empirical and modeling foundation of smartphone text input improvements, we explore touch behavior on soft QWERTY keyboards when used with two thumbs, an index finger, and one thumb. We collected text entry data from 32 participants in a lab study and describe touch accuracy and precision for different keys. We found that distinct patterns exist for input among the three hand postures, suggesting that keyboards should adapt to different postures. We also discovered that participants' touch precision was relatively high given typical key dimensions, but there were pronounced and consistent touch offsets that can be leveraged by keyboard algorithms to correct errors. We identify patterns in our empirical findings and discuss implications for design and improvements of soft keyboards.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {251–260},
numpages = {10},
keywords = {touch interfaces, mobile text entry},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371613,
author = {Xu, Wenchang and Liu, Jie and Yu, Chun and Shi, Yuanchun},
title = {Digging Unintentional Displacement for One-Handed Thumb Use on Touchscreen-Based Mobile Devices},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371613},
doi = {10.1145/2371574.2371613},
abstract = {There is usually an unaware screen distance between initial contact and final lift-off when users tap on touchscreen-based mobile devices with their fingers, which may affect users' target selection accuracy, gesture performance, etc. In this paper, we summarize such case as unintentional displacement and give its models under both static and dynamic scenarios. We then conducted two user studies to understand unintentional displacement for the widely-adopted one-handed thumb use on touchscreen-based mobile devices under both scenarios respectively. Our findings shed light on the following four questions: 1) what are the factors that affect unintentional displacement; 2) what is the distance range of the displacement; 3) how is the distance varying over time; 4) how are the unintentional points distributed around the initial contact point. These results not only explain certain touch inaccuracy, but also provide important reference for optimization and future design of UI components, gestures, input techniques, etc.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {261–270},
numpages = {10},
keywords = {touch screen, user study, thumb use, mobile device, unintentional displacement},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371614,
author = {Liu, Ying and Chen, Xiantao and Wang, Lingzhi and Zhang, Hequan and LI, Shen},
title = {PinyinPie: A Pie Menu Augmented Soft Keyboard for Chinese Pinyin Input Methods},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371614},
doi = {10.1145/2371574.2371614},
abstract = {Soft keyboard for Chinese pinyin input methods are rarely studied although it is one of the default methods on devices with touch screens. Via an analysis of the digraph frequency of the pinyin system, we discovered a unique characteristic of the pinyin system: only 10 Roman letters are needed for the subsequent characters in a pinyin syllable after the leading letter. Making use of this feature and existing knowledge on layout optimization of soft keyboard, pie menu and ShapeWriter, we designed a pie menu augmented keyboard. We conducted a user study to compare user performance to test if the pie menu can help to increase user performance with a working prototype. We found that after about 2 hours' use of the pie menu augmented quasi-QWERTY keyboard, users can reach a speed of 25 Chinese characters per minute with slightly lower error rate. Moreover, users can well remember the layout of the pie menu after about two hours' use of it.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {271–280},
numpages = {10},
keywords = {pinyin, chinese, soft keyboard, pie menu, text input},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251542,
author = {Bales, Elizabeth},
title = {Session Details: Multiplexing},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251542},
doi = {10.1145/3251542},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371616,
author = {Brumby, Duncan and Seyedi, Vahab},
title = {An Empirical Investigation into How Users Adapt to Mobile Phone Auto-Locks in a Multitask Setting},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371616},
doi = {10.1145/2371574.2371616},
abstract = {Auto-locks are a necessary feature on many modern day mobile devices, but can they sometimes have detrimental consequences? In this paper we investigate how auto-locks can affect behavior in a demanding multitasking scenario. A study is conducted in which participants had to enter text using a touch-screen interface while driving a simulated vehicle in a lab setting. Different auto-lock mechanisms were implemented on the secondary device, manipulating both the duration of the lockout threshold (i.e., the period of inactivity before the auto-lock was initiated) and the complexity of the unlock procedure (i.e., how easy it was for the user to unlock the device once it had locked). Results showed that lane-keeping performance on the primary driving task was worse when there was a shorter lockout threshold. The reason for this was two-fold: (1) participants took fewer long pauses between typing actions, so as to avoid being locked out of the device, and (2) when the device did lock, unlocking it took time and further distracted the driver. In support of this latter finding, we also found that a more complex unlock procedure, which required a pin code to be entered, resulted in worse lane-keeping performance than when the device could be unlocked by making a simple button press. These findings suggest that auto-locks can dissuade users from regularly interleaving attention between other ongoing activities. Designers should keep this in mind when incorporating auto-locks in mobile devices.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {281–290},
numpages = {10},
keywords = {driver distraction, driving, mobile phone use, multitasking},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371617,
author = {Leiva, Luis and B\"{o}hmer, Matthias and Gehring, Sven and Kr\"{u}ger, Antonio},
title = {Back to the App: The Costs of Mobile Application Interruptions},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371617},
doi = {10.1145/2371574.2371617},
abstract = {Smartphone users might be interrupted while interacting with an application, either by intended or unintended circumstances. In this paper, we report on a large-scale observational study that investigated mobile application interruptions in two scenarios: (1) intended back and forth switching between applications and (2) unintended interruptions caused by incoming phone calls. Our findings reveal that these interruptions rarely happen (at most 10% of the daily application usage), but when they do, they may introduce a significant overhead (can delay completion of a task by up to 4 times). We conclude with a discussion of the results, their limitations, and a series of implications for the design of mobile phones.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {291–294},
numpages = {4},
keywords = {task interleaving, large-scale study, interruptions, task deferral, application switching, resumption lags},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371618,
author = {Lim, Ji Jung and Feria, Cary},
title = {Visual Search on a Mobile Device While Walking},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371618},
doi = {10.1145/2371574.2371618},
abstract = {As smartphone usage increases, safety concerns have arisen. Previous research suggested cognitive impairments while using mobile devices in walking conditions. Mobile user interfaces that are designed in ways not to require users' full attention may mitigate the safety concerns. Primary focus of this research was on the perception process during visual search rather than the physical target selection by finger tapping, which most previous research focused on. The effects of object size, contrast, and target location on mobile devices while walking and standing were examined. A serial visual search using "T" and "L" shapes on a mobile device was conducted, which controlled for the physical target selection involvement. The results showed that walking, bigger object size, and the target position in the outer area of the mobile device display slowed the visual search reaction time. This suggests mobile interface improvement possibilities by proper object sizing and placement.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {295–304},
numpages = {10},
keywords = {walking, mobile interaction, mobile user interface, human factors, target acquisition, visual search},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371619,
author = {Alt, Florian and Sahami Shirazi, Alireza and Schmidt, Albrecht and Atterer, Richard},
title = {Bridging Waiting Times on Web Pages},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371619},
doi = {10.1145/2371574.2371619},
abstract = {High-speed Internet connectivity makes browsing a convenient task. However, there are many situations in which surfing the web is still slow due to limited bandwidth, slow servers, or complex queries. As a result, loading web pages can take several seconds, making (mobile) browsing cumbersome. We present an approach which makes use of the time spent on waiting for the next page, by bridging the wait with extra cached or preloaded content. We show how the content (e.g., news, Twitter) can be adapted to the user's interests and to the context of use, hence making mobile surfing more comfortable. We compare two approaches: in time-multiplex mode, the entire screen displays bridging content until the loading is finished. In space-multiplex mode, content is displayed alongside the requested content while it loads. We use an HTTP proxy to intercept requests and add JavaScript code, which allows the bridging content from websites of our choice to be inserted. The approach was evaluated with 15 participants, assessing suitable content and usability.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {305–308},
numpages = {4},
keywords = {mobile device, waiting time, www},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251543,
author = {Hoggan, Eve},
title = {Session Details: Non-Visual Interaction},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251543},
doi = {10.1145/3251543},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371621,
author = {Wilson, Graham and Brewster, Stephen and Halvey, Martin and Hughes, Stephen},
title = {Thermal Icons: Evaluating Structured Thermal Feedback for Mobile Interaction},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371621},
doi = {10.1145/2371574.2371621},
abstract = {This paper expands the repertoire of non-visual feedback for mobile interaction, established through Earcons and Tactons, by designing structured thermal cues for conveying information. Research into the use of thermal feedback for HCI has not looked beyond basic 'yes-no' detection of stimuli to the unique identification of those stimuli. We first designed thermal icons that varied along two parameters to convey two pieces of information. We also designed intramodal tactile icons, combining one thermal and one vibrotactile parameter, to test perception of different tactile cues and so evaluate the possibility of augmenting vibrotactile displays with thermal feedback. Thermal icons were identified with 82.8% accuracy, while intramodal icons had 96.9% accuracy, suggesting thermal icons are a viable means of conveying information in mobile HCI, for when audio and/or vibrotactile feedback is not suitable or desired.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {309–312},
numpages = {4},
keywords = {thermal feedback, non-visual feedback, mobile interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371622,
author = {Lamont, Stuart and Bowman, Richard and Rath, Matthias and Williamson, John and Murray-Smith, Roderick and Padgett, Miles},
title = {Touching the Micron: Tactile Interactions with an Optical Tweezer},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371622},
doi = {10.1145/2371574.2371622},
abstract = {A tablet interface for manipulating microscopic particles is augmented with vibrotactile and audio feedback. The feedback is generated using a novel real-time synthesis library based on approximations to physical processes, and is efficient enough to run on mobile devices, despite their limited computational power. The feedback design and usability testing was done with a realistic simulator on appropriate tasks, allowing users to control objects more rapidly, with fewer errors and applying more consistent forces. The feedback makes the interaction more tangible, giving the user more awareness of changes in the characteristics of the optical tweezers as the number of optical traps changes.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {313–316},
numpages = {4},
keywords = {real-time synthesis, tactile feedback, optical tweezers},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371623,
author = {Southern, Caleb and Clawson, James and Frey, Brian and Abowd, Gregory and Romero, Mario},
title = {An Evaluation of BrailleTouch: Mobile Touchscreen Text Entry for the Visually Impaired},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371623},
doi = {10.1145/2371574.2371623},
abstract = {We present the evaluation of BrailleTouch, an accessible keyboard for blind users on touchscreen smartphones. Based on the standard Perkins Brailler, BrailleTouch implements a six-key chorded braille soft keyboard. Eleven blind participants typed for 165 twenty-minute sessions on three mobile devices: 1) BrailleTouch on a smartphone; 2) a soft braille keyboard on a touchscreen tablet; and 3) a commercial braille keyboard with physical keys. Expert blind users averaged 23.2 words per minute (wpm) on the BrailleTouch smartphone. The fastest participant, a touchscreen novice, achieved 32.1 wpm during his first session. Overall, participants were able to transfer their existing braille typing skills to a touchscreen device within an hour of practice. We report the speed for braille text entry on three mobile devices, an in depth error analysis, and the lessons learned for the design and evaluation of accessible and eyes-free soft keyboards.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {317–326},
numpages = {10},
keywords = {chording, blindness, multi-touch interaction, mobile devices, accessibility, touchscreens, text entry, gestures},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371624,
author = {Pielot, Martin and Kazakova, Anastasia and Hesselmann, Tobias and Heuten, Wilko and Boll, Susanne},
title = {PocketMenu: Non-Visual Menus for Touch Screen Devices},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371624},
doi = {10.1145/2371574.2371624},
abstract = {We present PocketMenu, a menu optimized for non-visual, in-pocket interaction with menus on handheld devices with touch screens. By laying out menu items along the border of the touch screen its tactile features guide the interaction. Additional vibro-tactile feedback and speech allows identifying the individual menu items non-visually. In an experiment, we compared PocketMenu with iPhone's VoiceOver. Participants had to control an MP3 player while walking down a road with the device in the pocket. The results provide evidence that in the above context the PocketMenu outperforms VoiceOver in terms of completion time, selection errors, usability. Hence, it enables usage of touch screen apps in mobile contexts (e.g. walking, hiking, or skiing) and limited interaction spaces (e.g. device resting in a pocket).},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {327–330},
numpages = {4},
keywords = {input and interaction technologies, tactile &amp; haptic uis, handheld devices and mobile computing},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371625,
author = {Pietroszek, Krzysztof and Lank, Edward},
title = {Clicking Blindly: Using Spatial Correspondence to Select Targets in Multi-Device Environments},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371625},
doi = {10.1145/2371574.2371625},
abstract = {We propose spatial correspondence targeting to support interaction between devices in multi-device environments when network connectivity fails. In spatial correspondence targeting, for a given target on surface A, an end-user envisions the relative position of that target on surface B and interacts on surface B without any visual depiction of the target on surface B. The targeting task relies on human spatial visualization ability, i.e. the ability to relate the spatial position of objects on one display to their scale-invariant position on another display. We provide experimental evidence that demonstrates that users may be able to target up to 25 discrete targets using a smartphone screen even in the absence of a depiction of the target on the smartphone screen. We argue that the accuracy of spatial correspondence targeting is sufficient for the technique to have many practical applications.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {331–334},
numpages = {4},
keywords = {target acquisition, touchscreen interface, mobile human-computer interaction},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251544,
author = {Kjeldskov, Jesper},
title = {Session Details: Location},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251544},
doi = {10.1145/3251544},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371627,
author = {Szymczak, Delphine and Rassmus-Gr\"{o}hn, Kirsten and Magnusson, Charlotte and Hedvall, Per-Olof},
title = {A Real-World Study of an Audio-Tactile Tourist Guide},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371627},
doi = {10.1145/2371574.2371627},
abstract = {This paper reports on the in-context evaluation of an audio-tactile interactive tourist guide - one test was done in a medieval city center, and the other was done at an archaeological site. The activity theory framework was used as a perspective to guide design, field-study and analysis. The evaluation shows that the guide allows users to experience an augmented reality, while keeping the environment in focus (in contrast with the common key-hole like experience that on-screen augmented reality generates). The evaluation also confirms the usefulness of extending the vibrational feedback to convey also distance information as well as directional information.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {335–344},
numpages = {10},
keywords = {non-visual, inclusive, augmented reality, navigation, multimodal},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371628,
author = {Chang, Yung-Ju and Hung, Pei-Yao and Newman, Mark},
title = {TraceViz: "Brushing" for Location Based Services},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371628},
doi = {10.1145/2371574.2371628},
abstract = {The popularization of Location Based Services (LBS) has created new challenges for interaction designers in validating the design of their applications. Existing tools designed to play back GPS location traces data streams have shown potential for testing LBS applications and for supporting rapid and reflective prototyping. However, selecting a useful set of location traces from among a large collection remains a difficult task. In this paper, we present TraceViz, the first system that is aimed specifically at supporting LBS designers in exploring, filtering, and selecting location traces. TraceViz employs dynamic queries and "brushing" to allow LBS designers to flexibly adjust their trajectory filter criteria to find location traces of interest. An evaluation performed with eight LBS designers and developers indicates that TraceViz is helpful for rapidly locating useful traces and also highlights areas for future improvement.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {345–348},
numpages = {4},
keywords = {location-based services, information visualization, design tools, capture and playback, direct manipulation},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371629,
author = {Komninos, Andreas and Barrie, Peter and Stefanis, Vassilios and Plessas, Athanasios},
title = {Urban Exploration Using Audio Scents},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371629},
doi = {10.1145/2371574.2371629},
abstract = {We describe the design and evaluation of an audio-based mixed reality navigation system that uses the concept of audio scents for the implicit guidance of tourists and visitors of urban areas, as an alternative to turn-by-turn guidance systems. A field trial of our prototype uncovers great potential for this type of implicit navigation and is received positively by our participants. We discuss the technical implementation of our prototype, detailed findings from quantitative and subjective evaluation data gathered during the field trial and highlight possible strands for further research and development.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {349–358},
numpages = {10},
keywords = {urban environments, implicit navigation, audio mixed reality},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371630,
author = {Macvean, Andrew and Robertson, Judy},
title = {IFitQuest: A School Based Study of a Mobile Location-Aware Exergame for Adolescents},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371630},
doi = {10.1145/2371574.2371630},
abstract = {Exergames, games that encourage and facilitate physical exercise, are growing in popularity thanks to progressions in ubiquitous technologies. While initial findings have confirmed the potential of such games, little research has been done on systems which target the needs of adolescent children. In this paper we introduce iFitQuest, a mobile location-aware exergame designed with adolescent children in mind. In an attempt to understand how exergames can be used to target adolescent children, and whether they can be effective for this demographic, we outline the results of a school based field study conducted within a P.E. class. Through a detailed analysis of our results, we conclude that iFitQuest appeals to twelve to fifteen year olds and causes them to exercise at moderate to vigorous levels. However, in order to develop effective systems that can dynamically adapt to the adolescent users, further research into different categories of users' behavior is required.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {359–368},
numpages = {10},
keywords = {serious games for health, exergames, location-aware games},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371631,
author = {Pielot, Martin and Poppinga, Benjamin and Heuten, Wilko and Boll, Susanne},
title = {Tacticycle: Supporting Exploratory Bicycle Trips},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371631},
doi = {10.1145/2371574.2371631},
abstract = {Going on excursions to explore unfamiliar environments by bike is a popular activity in many places in this world. To investigate the nature of exploratory bicycle trips, we studied tourists on their excursions on a famous vacation island. We found that existing navigation systems are either not helpful or discourage exploration. We therefore propose Tacticycle, a conceptual prototype of a user interface for a bicycle navigation system. Relying on a minimal set of navigation cues, it helps staying oriented while supporting spontaneous navigation and exploration at the same time. In cooperation with a bike rental, we rented the Tacticycle prototype to tourists who took it on their actual excursions. The results show that they always felt oriented and encouraged to playfully explore the island, providing a rich, yet relaxed travel experience. On the basis of these findings, we argue that exploratory trips can be very well supported by providing minimal navigation cues only.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {369–378},
numpages = {10},
keywords = {tourists, exploration, handheld devices and mobile computing, navigation systems, tactile &amp; haptic uis, cycling},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251545,
author = {Lyons, Kent},
title = {Session Details: Collaboration and Sharing},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251545},
doi = {10.1145/3251545},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371633,
author = {Teevan, Jaime and Liebling, Daniel and Paradiso, Ann and Garcia Jurado Suarez, Carlos and von Veh, Curtis and Gehring, Darren},
title = {Displaying Mobile Feedback during a Presentation},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371633},
doi = {10.1145/2371574.2371633},
abstract = {Smartphone use in presentations is often seen as distracting to the audience and speaker. However, phones can encourage people participate more fully in what is going on around them and build stronger ties with their companions. In this paper, we describe a smartphone interface designed to help audience members engage fully in a presentation by providing real time mobile feedback. This feedback is then aggregated and reflected back to the group via a projected visualization, with notifications provided to the presenter and the audience on interesting feedback events. We deployed this system in a large enterprise meeting, and collected information about the attendees' experiences with it via surveys and interaction logs. Participants report that providing mobile feedback was convenient, helped them pay close attention to the presentation, and enabled them to feel connected with other audience members.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {379–382},
numpages = {4},
keywords = {mobile, meetings, presentations, feedback},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371634,
author = {Lucero, Andr\'{e}s and Holopainen, Jussi and Jokela, Tero},
title = {MobiComics: Collaborative Use of Mobile Phones and Large Displays for Public Expression},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371634},
doi = {10.1145/2371574.2371634},
abstract = {We explore shared collocated interactions with mobile phones and public displays in an indoor public place. We introduce MobiComics, an application that allows a group of collocated persons to flexibly create and edit comic strip panels using their mobile phones. The prototype supports ad hoc sharing of comic strip panels between people and onto two public displays by taking the spatial arrangement of people into account, measured with a radio tracking technology integrated in their mobile phones. MobiComics also includes game-like elements to foster social interaction between participants. Our evaluations show that people enjoyed creating panels collaboratively and sharing content using the proposed interaction techniques. The included game-like features positively influenced social interaction.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {383–392},
numpages = {10},
keywords = {handheld devices, collocated Interaction, public displays},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371635,
author = {Church, Karen and Cousin, Antony and Oliver, Nuria},
title = {I Wanted to Settle a Bet! Understanding Why and How People Use Mobile Search in Social Settings},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371635},
doi = {10.1145/2371574.2371635},
abstract = {Recent work in mobile computing has highlighted that conversations and social interactions have a significant impact on mobile Web and mobile search behaviours. To date, however, this social element has not been explored fully and little is known about why and how mobile users search for information in social settings. The goal of this work is to provide a deeper understanding of social mobile search behaviours so that we may improve future mobile search experiences that involve a social component. To this end we present the results of two studies: a survey involving almost 200 users and a two-week diary and follow-up interview study of 20 users. Our results extend past research in the mobile search space, by exploring the motivations, circumstances and experiences of using mobile search in social settings to satisfy group information needs. Our findings point to a number of open research challenges and implications for enriching the search experiences of mobile users.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {393–402},
numpages = {10},
keywords = {survey, search behaviour, diary study, shared mobile search, mobile search, collaborative search, social mobile search},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371636,
author = {Walton, Marion and Marsden, Gary and Ha\ss{}reiter, Silke and Allen, Sena},
title = {Degrees of Sharing: Proximate Media Sharing and Messaging by Young People in Khayelitsha},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371636},
doi = {10.1145/2371574.2371636},
abstract = {This paper explores the phone and mobile media sharing relationships of a group of young mobile phone users in Khayelitsha, South Africa. Intensive sharing took place within peer and intimate relationships, while resource sharing characterized relationships with a more extensive circle, including members of the older generation. Phones were kept open to others to avoid inferences of stinginess, disrespect, or secretiveness and the use of privacy features (such as passwords) was complicated by conflicts between an ethos of mutual support and the protection of individual property and privacy. Collocated phone use trumped online sharing but media on phones constituted public personae similar to social media 'profiles'. Proximate sharing within close relationships allowed social display, relationship-building and deference to authority. We suggest changes to current file-based interfaces for Bluetooth pairing, media 'galleries', and peer-to-peer text communication to better support such proximate exchanges of media and messaging.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {403–412},
numpages = {10},
keywords = {bluetooth, mobile media, privacy, security, mobile phone sharing, mobile photography},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371637,
author = {Pearson, Jennifer and Buchanan, George and Thimbleby, Harold},
title = {Investigating Collaborative Annotation on Slate Pcs},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371637},
doi = {10.1145/2371574.2371637},
abstract = {Mobile reading is becoming evermore popular with the introduction of eInk devices such as the Kindle, as well as the many reading applications available on slate PCs and cellular handsets. The portable nature and large storage capacity of these modern mobile devices is making reading a more technology orientated activity. One aspect of mobile reading that has been given surprisingly little attention is collective reading - which is a common activity with paper documents. We investigate the support of group reading using slate PCs, focussing on collective annotation. In the past, desktop PCs have proved inferior in many ways for reading, when compared to paper. Notably, user evaluations of our new system, BuddyBooks, demonstrate that the slate PC form factor can, in contrast, provide advantages for group reading. While annotation practices change with the new format, coordinating within the group can be improved when touch-interaction is carefully exploited.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {413–416},
numpages = {4},
keywords = {slate pcs, collaboration, annotation, documents},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/3251546,
author = {Dunlop, Mark},
title = {Session Details: Learning and Training},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251546},
doi = {10.1145/3251546},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
numpages = {1},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371639,
author = {Spelmezan, Daniel},
title = {An Investigation into the Use of Tactile Instructions in Snowboarding},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371639},
doi = {10.1145/2371574.2371639},
abstract = {In many sports, athletes are spatially separated from their coach while practicing an exercise. This spatial separation makes learning new skills arduous because the coach cannot give instructions or feedback on performance. We present the findings of an in the wild study that demonstrate the potential for teaching sport skills with realtime tactile instructions. We focused on snowboard training. Ten amateurs learned a riding technique with a wearable system that automatically provided tactile instructions during descents. These instructions were in sync with the movements of the snowboard and signaled how to move the body. We found that tactile instructions could help snowboarders to improve their skills. We report insights into the snowboarders' opinion and give recommendations for teaching sport skills with tactile instructions. Our findings help to identify the conditions under which tactile instructions can support athletes in sports training.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {417–426},
numpages = {10},
keywords = {sports training, snowboarding, vibrotactile feedback, motor skill learning, wearable computing, tactile instructions},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371640,
author = {Edge, Darren and Cheng, Kai-Yin and Whitney, Michael and Qian, Yao and Yan, Zhijie and Soong, Frank},
title = {Tip Tap Tones: Mobile Microtraining of Mandarin Sounds},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371640},
doi = {10.1145/2371574.2371640},
abstract = {Learning a second language is hard, especially when the learner's brain must be retrained to identify sounds not present in his or her native language. It also requires regular practice, but many learners struggle to find the time and motivation. Our solution is to break down the challenge of mastering a foreign sound system into minute-long episodes of "microtraining" delivered through mobile gaming. We present the example of Tip Tap Tones - a mobile game with the purpose of helping learners acquire the tonal sound system of Mandarin Chinese. In a 3-week, 12-user study of this system, we found that an average of 71 minutes' gameplay significantly improved tone identification by around 25%, regardless of whether the underlying sounds had been used to train tone perception. Overall, results suggest that mobile microtraining is an efficient, effective, and enjoyable way to master the sounds of Mandarin Chinese, with applications to other languages and domains.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {427–430},
numpages = {4},
keywords = {microtraining, mobile gaming, language learning},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371641,
author = {Edge, Darren and Fitchett, Stephen and Whitney, Michael and Landay, James},
title = {MemReflex: Adaptive Flashcards for Mobile Microlearning},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371641},
doi = {10.1145/2371574.2371641},
abstract = {Flashcard systems typically help students learn facts (e.g., definitions, names, and dates), relying on intense initial memoriztion with subsequent tests delayed up to days later. This approach does not exploit the short, sparse, and mobile opportunities for microlearning throughout the day, nor does it support learners who need the motivation that comes from successful study sessions. In contrast, our MemReflex system of adaptive flashcards gives fast-feedback by retesting new items in quick succession, dynamically scheduling future tests according to a model of the learner's memory. We evaluate MemReflex across three user studies. In the first two studies, we demonstrate its effectiveness for both audio and text modalities, even while walking and distracted. In the third study of second-language vocabulary learning, we show how MemReflex enhanced learner accuracy, confidence, and perceptions of control and success. Overall, the work suggests new directions for mobile microlearning and "micro activities" in general.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {431–440},
numpages = {10},
keywords = {language learning, mobile flashcards, adaptive systems},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

@inproceedings{10.1145/2371574.2371642,
author = {Frias-Martinez, Vanessa and Virseda, Jesus and Gomero, Aldo},
title = {Mobilizing Education: Evaluation of a Mobile Learning Tool in a Low-Income School},
year = {2012},
isbn = {9781450311052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371574.2371642},
doi = {10.1145/2371574.2371642},
abstract = {The pervasiveness of feature phones in emerging economies has contributed to the advent of mobile learning applications for low-income populations. However, many of these tools lack the proper evaluation required to understand their educational impact. In this paper, we extend the state of the art by presenting the evaluation of a game-based mobile learning tool in both formal and informal settings at a low-income school in Lima, Peru. We show that EducaMovil improves knowledge acquisition in the formal environment of a classroom. In addition, use of the tool in more informal settings such as school breaks enhances the level of knowledge, as long as there is continuous engagement over time. We also demonstrate that EducaMovil can be used as a paperless complement to homework. Finally, we provide teachers with a set of guidelines for a successful deployment of EducaMovil at their schools.},
booktitle = {Proceedings of the 14th International Conference on Human-Computer Interaction with Mobile Devices and Services},
pages = {441–450},
numpages = {10},
keywords = {learning gains, mobile games, low-income schools},
location = {San Francisco, California, USA},
series = {MobileHCI '12}
}

