@inproceedings{10.1145/1291233.1291235,
author = {Cemgil, A. Taylan},
title = {Bayesian Methods for Multimedia Signal Processing},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291235},
doi = {10.1145/1291233.1291235},
abstract = {In the last years, there have been a significant growth of multimedia information processing applications that employ ideas from statistical machine learning and probabilistic modeling. In this paradigm, multimedia data (music, audio, video, images, text, ...) are viewed as realizations from highly structured stochastic processes. Once a model is constructed, several interesting problems such as transcription, coding, classification, restoration, tracking, source separation or resynthesis etc. can be formulated as Bayesian inference problems. In this context, graphical models provide a "language" to construct models for quantification of prior knowledge. Unknown parameters in this specification are estimated by probabilistic inference. Often, however, the problem size poses an important challenge and in order to render the approach feasible, specialized inference methods need to be tailored to improve the computational speed and efficiency.The scope of the proposed tutorial is as follows: First, we will review the fundamentals of probabilistic models, with some focus on music, video and text data. Then, we will discuss the numerical techniques for inference in these models. In particular, we will review exact inference, approximate stochastic inference techniques such as Markov Chain Monte Carlo, Sequential Monte Carlo and deterministic (variational) inference techniques. Our ultimate aim is to provide a basic understanding of probabilistic modeling for multimedia processing, associated computational techniques and a roadmap such that information retrieval researchers new to the Bayesian approach can orient themselves in the relevant literature and understand the current state of the art.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1–2},
numpages = {2},
keywords = {multimedia signal processing, sequential monte carlo, factor graphs, graphical models, markov chain monte carlo, variational bayes, bayesian networks},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291236,
author = {Qu\'{e}not, Georges M.},
title = {Active Learning for Multimedia},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291236},
doi = {10.1145/1291233.1291236},
abstract = {Active learning improves the performance of classification or search systems by adding humans to the loop. It aims at optimizing the production of the class labels that are necessary for supervised learning. The proposed tutorial responds to a strong need for the integration of this technique in multimedia indexing and retrieval systems. It presents the basics of active learning and gives the necessary information for quickly and efficiently integrating it within a project. Several applications are considered, from relevance feedback to corpus annotation. Most illustrations are given in the context of the NIST benchmarks on video indexing and retrieval (TRECVID).},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {3},
numpages = {1},
keywords = {multimedia indexing, active learning},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291237,
author = {Shih, Timothy K.},
title = {Digital Inpainting: A Tutorial},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291237},
doi = {10.1145/1291233.1291237},
abstract = {Digital inpainting is an interesting research topic in multimedia computing and image processing since 2000. This tutorial will cover the most recent contributions in image inpainting / image completion, video inpainting, and 3-D surface completion. In the literature, the first intention of image inpainting was to remove damages portions of an aged photo, by completing the area with surrounding or global information. The techniques used include the analysis and usage of pixel properties in spatial and frequency domains. Furthermore, image inpainting techniques were used in object removal (or image completion) in photos. Several strategic algorithms were developed based on confidence values and priorities of using patches. The techniques used in still images were then extended to video inpainting, which need to consider temporal properties such as motion vectors. With a reasonable combination of object tracking and image completion, objects in video can be removed and possibly replaced. On the other hand, aged films contain two types of defects: spikes and lone vertical lines. These defects need to be precisely detected and removed to restore the original film. In addition, based on image completion techniques, incompleteness of scanning results of a 3-D scanner due to improper location or other reasons of a scanner can be completed.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {4–5},
numpages = {2},
keywords = {image completion, 3D surface inpainting, video inpainting, image inpainting},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291238,
author = {Casey, Michael A. and Kurth, Frank},
title = {Large Data Methods for Multimedia},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291238},
doi = {10.1145/1291233.1291238},
abstract = {This tutorial describes techniques essential for searching the large multimedia databases that are now common on the Internet. There are up to 10 million songs in commercial music catalogues and over 300 million images stored in online photo services such as Flickr. How can we find the music, videos or images we want? How can we organize such large collections: find duplicates, create links between similar documents, extract and annotate semantic structures from complex audiovisual documents? Conventional methods for handling large data sets, such as hashing, get us part of the way, but those methods may not straightforwardly be used for similarity-based matching and retrieval in audiovisual document collections. On the other hand, several elaborate methods from multimedia retrieval are available for semantic document analysis. Unfortunately, those methods generally do not scale for large data sets. Instead, new classes of algorithms combining the best of the two worlds of large data methods and semantic analysis are needed to handle large multimedia databases. Innovative methods such as locality sensitive hashing, which are based on randomized probes, are the new workhorses. This tutorial covers methods for multimedia retrieval on large document collections. Starting with audio retrieval, we describe both the theory (i.e., randomized algorithms for hashing) and the implementation details (how do you store hash values for millions of songs?). A special focus is on how to combine large data methods with semantically meaningful descriptors in order to facilitate efficient similarity-based retrieval. Besides audio, the tutorial also covers image, 3d motion and video retrieval.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {6–7},
numpages = {2},
keywords = {index-based multimedia retrieval, locality sensitive hashing, large data methods},
location = {Augsburg, Germany},
series = {MM '07}
}

@dataset{10.1145/review-1291233.1291238_R42707,
author = {Berkovich, Simon},
title = {Review ID:R42707 for DOI: 10.1145/1291233.1291238},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1291233.1291238_R42707}
}

@inproceedings{10.1145/1291233.1291239,
author = {Pereira, Fernando},
title = {MPEG Multimedia Standards: Evolution and Future Developments},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291239},
doi = {10.1145/1291233.1291239},
abstract = {Multimedia communications play a growing role in the every day's life of modern societies. Until recently, and except for broadcast television and radio, voice was still the sole communication mechanism. However, the diffusion of digital processing algorithms and hardware has brought images, music, and video into everyday life. The availability of open standards (such as JPEG, MPEG-X Audio and Video, H.26X) has had a major impact on this progression, notably due to the easy interoperability. Such standards have made the creation, and communication of (digital) data aimed at our most important senses, sight and hearing, simple, inexpensive and commonplace. With time, multimedia standards have addressed a growing set of fields from coding and metadata to rights management and content adaptation, following the increasing (functional and technical) complexity of multimedia applications.Since MPEG standards have played a key role in the progress of the multimedia landscape, this tutorial will provide an evolutional overview of MPEG standards, discussing and explaining why certain choices were made, and thus a certain vision of the multimedia world was followed. Moreover this tutorial will specifically address the most recent MPEG standards, notably MPEG-21, MPEG-4 AVC, SVC and MVC, and finally MPEG-A.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {8–9},
numpages = {2},
keywords = {data and metadata, multimedia standards, audiovisual data, interoperability},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291240,
author = {Scheible, J\"{o}rgen},
title = {Mobile Phone Programming for Multimedia},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291240},
doi = {10.1145/1291233.1291240},
abstract = {This compact hands-on tutorial introduces a novel way of creative mobile phone programming for multi-media that is easy to learn and fun. It was created in 2006 by the author of this paper and was published as a free online tutorial at http://www.mobilenin.com/pys60/menu.htm. Pedagogically fine-tuned, it teaches the programming of a large set of mobile phone features including camera, sound, video, messaging, telephony, location, Bluetooth, graphics, Wi-fi, GPS and networking. The problem in the past has been that developing applications on the mobile platform was time consuming and required a steep learning curve. Also, mobile platforms have often been closed or were too restricted. Mobile Python, also known as 'Python for S60' (PyS60) offers a crucial turning point here. It provides a Python execution environment for the mobile phone. It is developed by Nokia Research as an Open Source Project. This tutorial uses PyS60 in combination with a set of code examples, turning it into a ready working toolkit. It allows developing mobile applications even by novice programmers, artists and people from the creative communities. In a matter of days, people can build powerful applications based on their own ideas and contribute to the mobile space. This tutorial has been taught in more than 40 occasions in academia and industry and in more than 17 countries during the last 2 years. Among these are Yahoo Research Berkeley, Nokia, NTU Taiwan, MIT and Stanford University.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {12–13},
numpages = {2},
keywords = {mobile python, tutorial, PyS60, python for S60},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291241,
author = {Jaimes, Alejandro and Sebe, Nicu},
title = {Human-Centered Multimedia Systems: Tutorial Overview},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291241},
doi = {10.1145/1291233.1291241},
abstract = {Human-Centered Computing (HCC) is a set of methodologies that apply to any field that uses computers, in any form, in applications in which humans directly interact with devices or systems that use computer technologies. This tutorial takes a holistic view on the research issues and applications of Human-Centered Multimedia Systems focusing on three main areas: (1)multimodal interaction: visual (body, gaze, gesture) and audio (emotion)analysis; (2) image databases, indexing, and retrieval: context modeling, cultural issues, and machine learning for user-centric approaches; (3)multimedia data: conceptual analysis at different levels (feature, cognitive, and affective). This paper gives a brief overview of the areas covered in the tutorial.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {14–15},
numpages = {2},
keywords = {multimodal interaction, human-centered computing, human-computer interfaces, multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258964,
author = {Leinhart, Rainer},
title = {Session Details: Keynote Presentation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258964},
doi = {10.1145/3258964},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291243,
author = {Wahlster, Wolfgang},
title = {Smartweb: Multimodal Web Services on the Road},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291243},
doi = {10.1145/1291233.1291243},
abstract = {SmartWeb provides a context-aware user interface to web
services, so that it can support the mobile user in different
roles, e.g.&nbsp;as a car driver, a motorbiker, or a pedestrian. It
provides a symmetric multimodal dialogue system [2] combining
speech, gesture, haptic and video input with speech, haptic, video
and acoustic output. It goes beyond traditional keyword search
engines like Google by delivering higher quality results that are
adapted to the mobile user's current task and situation. In mobile
situations, users don't want to deal with hypertext lists of
retrieved webpages, but simply want an answer to their query. If a
desperate driver with a crying and acutely ill child on the
backseat asks SmartWeb "Who is the closest paediatrician?" he needs
just the name and address of the doctor. Based on SmartWeb's
ability to combine various web services, the driver can then ask
SmartWeb a follow-up question about route guidance to the doctor's
practice. One of the innovative features of SmartWeb is that the
user can specify whether he wants a textual or pictorial answer, a
video clip or a sound file as a query result.SmartWeb [1] provides not only an open-domain question answering
machine but a multimodal web service interface for coherent
dialogue, where questions and commands are interpreted according to
the context of the previous conversation. For example, if the
driver of our Mercedes-Benz R-Class test car asks SmartWeb "Where
is the closest Italian restaurant", it will access a web service to
find an appropriate restaurant and show its location on a digital
map presented on the large dashboard display. The user may continue
his dialog with a command like "Please guide me there with a
refuelling stop at the lowest price gas station". In this case,
SmartWeb combines a navigation service with a special web service
that finds low gas prices. SmartWeb includes plan-based composition
methods for semantic web services, so that complex tasks can be
carried out for the mobile user.One version of SmartWeb has been deployed on a BMW motorbike
R1200RT, using a swivel with force feedback integrated in the
handle bar. Similar to the control knob known from the iDrive
interface of BMW automobiles, the biker can rotate the swivel or
push it right or left in order to browse through menus or select
items displayed by SmartWeb on the large high-resolution screen in
the middle of the cockpit. In combination with these pointing
actions, the biker can use speech input over the microphone
integrated in a Bluetooth helmet to interact with SmartWeb. The
multimodal dialogue system combines visual displays with speech and
earcons over the speakers integrated in the helmet and haptic force
feedback for output generation. For example, the biker can ask for
weather forecasts along his planned route. SmartWeb accesses
location-based web services via the bike's 3G wireless connection
to retrieve the relevant weather forecasts. In addition, SmartWeb
exploits ad-hoc Wifi connections for vehicle-to-vehicle
communication based on a local danger warning ontology so that the
motorbike driver can be informed of a danger ahead by a car in
front of him. For example, a car detecting a large wedge of water
under its wheels will pass the information wirelessly to the bike
following it and SmartWeb will generate the warning "Attention!
Risk of aquaplaning 100 meters ahead" using the GPS coordinates of
both vehicles to compute the distance to the upcoming dangerous
area. Another distinguishing feature of SmartWeb is the generation
of adaptive multimodal presentations taking into account the
predicted cognitive load of the biker depending on the driving
speed and other factors.This keynote presents the anatomy of SmartWeb, its
ontology-based information extraction and web service composition
technology and explains the distinguishing features of its
multimodal dialogue and answer engine.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {16},
numpages = {1},
keywords = {vehicle-to-vehicle communication, multimodal web services, in-car spoken dialogue system},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258965,
author = {Hanjalic, Alan},
title = {Session Details: Best Papers Session},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258965},
doi = {10.1145/3258965},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291245,
author = {Qi, Guo-Jun and Hua, Xian-Sheng and Rui, Yong and Tang, Jinhui and Mei, Tao and Zhang, Hong-Jiang},
title = {Correlative Multi-Label Video Annotation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291245},
doi = {10.1145/1291233.1291245},
abstract = {Automatically annotating concepts for video is a key to semantic-level video browsing, search and navigation. The research on this topic evolved through two paradigms. The first paradigm used binary classification to detect each individual concept in a concept set. It achieved only limited success, as it did not model the inherent correlation between concepts, e.g., urban and building. The second paradigm added a second step on top of the individual concept detectors to fuse multiple concepts. However, its performance varies because the errors incurred in the first detection step can propagate to the second fusion step and therefore degrade the overall performance. To address the above issues, we propose a third paradigm which simultaneously classifies concepts and models correlations between them in a single step by using a novel Correlative Multi-Label (CML) framework. We compare the performance between our proposed approach and the state-of-the-art approaches in the first and second paradigms on the widely used TRECVID data set. We report superior performance from the proposed approach.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {17–26},
numpages = {10},
keywords = {video annotation, concept correlation, multi-labeling},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291246,
author = {Gleicher, Michael L. and Liu, Feng},
title = {Re-Cinematography: Improving the Camera Dynamics of Casual Video},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291246},
doi = {10.1145/1291233.1291246},
abstract = {This paper presents an approach to post-processing casually captured videos to improve apparent camera movement. Re-cinematography transforms each frame of a video such that the video better follows cinematic conventions. The approach breaks videos into shorter segments. For segments of the source video where the camera is relatively static, re-cinematography uses image stabilization to make the result look locked-down. For segments with camera motions, camera paths are keyframed automatically and interpolated with matrix logarithms to give velocity-profiled movements that appear intentional and directed. The approach automatically balances the tradeoff between motion smoothness and distortion to the original imagery. Results from our prototype show improvements to poor quality home videos.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {27–36},
numpages = {10},
keywords = {cinematography, casual video, image stabilization},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291247,
author = {Zhu, Xiaoqing and Agrawal, Piyush and Pal Singh, Jatinder and Alpcan, Tansu and Girod, Bernd},
title = {Rate Allocation for Multi-User Video Streaming over Heterogenous Access Networks},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291247},
doi = {10.1145/1291233.1291247},
abstract = {Contemporary wireless devices integrate multiple networking technologies, such as cellular, WiMax and IEEE 802.11a/b/g, as alternative means of accessing the Internet. Efficient utilization of available bandwidth over heterogeneous access networks is important, especially for media streaming applications with high data rates and stringent delay requirements. In this work we consider the problem of rate allocation among multiple video streaming sessions sharing multiple access networks. We develop and evaluate an analytical framework for optimal video rate allocation, based on observed available bit rate (ABR) and round trip time (RTT) over each access network, as well as the video distortion-rate (DR) characteristics. The rate allocation is formulated as a convex optimization problem that minimizes the sum of expected distortion of all video streams. We then present a distributed approximation of the optimization, which enables autonomous rate allocation at each device in a media- and network-aware fashion. Performance of the proposed allocation scheme is compared against robust rate control based on H∞ optimal control and two heuristic schemes employing TCP style additive-increase-multiplicative-decrease (AIMD) principles. Wesimulate in NS-2 [1] simultaneous streaming of multiple high-definition(HD) video streams over multiple access networks, using ABR and RTT traces collected on Ethernet, IEEE 802.11g, and IEEE 802.11b networks deployed in a corporate environment. In comparison with heuristic AIMD-based schemes, rate allocation from both the media-aware convex optimization scheme and H∞ optimal control benefit from proactive avoidance of network congestion, and can reduce the average packet loss ratio from 27% to below 2%, while improving the average received video quality by 3.3 - 4.5 dB in PSNR.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {37–46},
numpages = {10},
keywords = {heterogeneous access networks, distributed rate allocation, video streaming},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291248,
author = {Chen, Yinpeng and Xu, Weiwei and Sundaram, Hari and Rikakis, Thanassis and Liu, Sheng-Min},
title = {Media Adaptation Framework in Biofeedback System for Stroke Patient Rehabilitation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291248},
doi = {10.1145/1291233.1291248},
abstract = {In this paper, we present a media adaptation framework for an immersive biofeedback system for stroke patient rehabilitation. In our biofeedback system, media adaptation refers to changes in audio/visual feedback as well as changes in physical environment. Effective media adaptation frameworks help patients recover generative plans for arm movement with potential for significantly shortened therapeutic time. The media adaptation problem has significant challenges - (a) high dimensionality of adaptation parameter space (b) variability in the patient performance across and within sessions(c) the actual rehabilitation plan is typically a non first-order Markov process, making the learning task hard.Our key insight is to understand media adaptation as a real-time feedback control problem. We use a mixture-of-experts based Dynamic Decision Network (DDN) for online media adaptation. We train DDN mixtures per patient, per session. The mixture models address two basic questions - (a) given a specific adaptation suggested by the domain expert, predict patient performance and (b) given an expected performance, determine optimal adaptation decision. The questions are answered through an optimality criterion based search on DDN models trained in previous sessions. We have also developed new validation metrics and have very good results for both questions on actual stroke rehabilitation data.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {47–57},
numpages = {11},
keywords = {biofeedback, media adaptation, dynamic decision network, mixture of experts},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258966,
author = {Natsev, Apostol},
title = {Session Details: Content 1 - Content Analysis Applications},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258966},
doi = {10.1145/3258966},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291250,
author = {Zhu, Guangyu and Huang, Qingming and Xu, Changsheng and Rui, Yong and Jiang, Shuqiang and Gao, Wen and Yao, Hongxun},
title = {Trajectory Based Event Tactics Analysis in Broadcast Sports Video},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291250},
doi = {10.1145/1291233.1291250},
abstract = {Most of existing approaches on event detection in sports video are general audience oriented. The extracted events are then presented to the audience without further analysis. However, professionals, such as soccer coaches, are more interested in the tactics used in the events. In this paper, we present a novel approach to extract tactic information from the goal event in broadcast soccer video and present the goal event in a tactic mode to the coaches and sports professionals. We first extract goal events with far-view shots based on analysis and alignment of web-casting text and broadcast video. For a detected goal event, we employ a multi-object detection and tracking algorithm to obtain the players and ball trajectories in the shot. Compared with existing work, we proposed an effective tactic representation called aggregate trajectory which is constructed based on multiple trajectories using a novel analysis of temporal-spatial interaction among the players and the ball. The interactive relationship with play region information and hypothesis testing for trajectory temporal-spatial distribution are exploited to analyze the tactic patterns in a hierarchical coarse-to-fine framework. The experimental results on the data of FIFA World Cup 2006 are promising and demonstrate our approach is effective.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {58–67},
numpages = {10},
keywords = {event detection, trajectory analysis, broadcast video, tactics analysis, object tracking},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291251,
author = {Arifin, Sutjipto and Cheung, Peter Y. K.},
title = {A Computation Method for Video Segmentation Utilizing the Pleasure-Arousal-Dominance Emotional Information},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291251},
doi = {10.1145/1291233.1291251},
abstract = {Extracting video structures is important for video indexing and navigation in large digital video archives. It is usually achieved by video segmentation algorithms. Little research efforts has been invested on segmentation solutions that utilize the video's emotional content. These solutions not only have the potential of providing better performances than existing segmentation methods, but are also able to provide a more natural video segmentation with which viewers can associate with. The development of an affect-based segmentation solution faces many challenges, such as the dynamic and time evolving nature of a video's emotional content. This paper introduces a novel computation method for affect-based video segmentation. It is designed based on the Pleasure-Arousal-Dominance (P-A-D) emotion model[18], which in principle can represent a large number of emotions. This method consists of a P-A-D estimation stage and a segmentation stage. A P-A-D estimator based on the Dynamic Bayesian Networks (DBNs) is proposed for the first stage. A clustering-based algorithm that utilizes the video's P-A-D information is proposed for the second stage. Experimental results demonstrate the feasibility of the method.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {68–77},
numpages = {10},
keywords = {affective video content analysis, video segmentation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291252,
author = {Gloe, Thomas and Kirchner, Matthias and Winkler, Antje and B\"{o}hme, Rainer},
title = {Can We Trust Digital Image Forensics?},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291252},
doi = {10.1145/1291233.1291252},
abstract = {Compared to the prominent role digital images play in nowadays multimedia society, research in the field of image authenticity is still in its infancy. Only recently, research on digital image forensics has gained attention by addressing tamper detection and image source identification. However, most publications in this emerging field still lack rigorous discussions of robustness against strategic counterfeiters, who anticipate the existence of forensic techniques. As a result, the question of trustworthiness of digital image forensics arises. This work will take a closer look at two state-of-the-art forensic methods and proposes two counter-techniques; one to perform resampling operations undetectably and another one to forge traces of image origin. Implications for future image forensic systems will be discussed.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {78–86},
numpages = {9},
keywords = {tamper detection, digital image forensics, tamper hiding, image source identification},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258967,
author = {Rutledge, Lloyd},
title = {Session Details: Applications 1 - Enhancing User Experiences},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258967},
doi = {10.1145/3258967},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291254,
author = {Knoche, Hendrik and Papaleo, Marco and Sasse, M. Angela and Vanelli-Coralli, Alessandro},
title = {The Kindest Cut: Enhancing the User Experience of Mobile Tv through Adequate Zooming},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291254},
doi = {10.1145/1291233.1291254},
abstract = {The growing market of Mobile TV requires automated adaptation of standard TV footage to small size displays. Especially extreme long shots (XLS) depicting distant objects can spoil the user experience, e.g. in soccer content. Automated zooming schemes can improve the visual experience if the resulting footage meets user expectations in terms of the visual detail and quality but does not omit valuable context information. Current zooming schemes are ignorant of beneficial zoom ranges for a given target size when applied to standard definition TV footage. In two experiments 84 participants were able to switch between original and zoom enhanced soccer footage at three sizes - from 320x240 (QVGA) down to 176x144 (QCIF). Eye tracking and subjective ratings showed that zoom factors between 1.14 and 1.33 were preferred for all sizes. Interviews revealed that a zoom factor of 1.6 was too high for QVGA content due to low perceived video quality, but beneficial for QCIF size. The optimal zoom depended on the target display size. We include a function to compute the optimal zoom for XLS depending on the target device size. It can be applied in automatic content adaptation schemes and should stimulate further research on the requirements of different shot types in video coding.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {87–96},
numpages = {10},
keywords = {multimedia content enhancement, mobile tv, mobile devices, zooming, user experience, eye-tracking, video},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291255,
author = {El-Alfy, Hazem and Jacobs, David and Davis, Larry},
title = {Multi-Scale Video Cropping},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291255},
doi = {10.1145/1291233.1291255},
abstract = {We consider the problem of cropping surveillance videos. This process chooses a trajectory that a small sub-window can take through the video, selecting the most important parts of the video for display on a smaller monitor. We model the information content of the video simply, by whether the image changes at each pixel. Then we show that we can find the globally optimal trajectory for a cropping window by using a shortest path algorithm. In practice, we can speed up this process without affecting the results, by stitching together trajectories computed over short intervals. This also reduces system latency. We then show that we can use a second shortest path formulation to find good cuts from one trajectory to another, improving coverage of interesting events in the video. We describe additional techniques to improve the quality and efficiency of the algorithm, and show results on surveillance videos.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {97–106},
numpages = {10},
keywords = {video cropping, surveillance, shortest path algorithm},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291256,
author = {Bossi, Annalisa and Gaggi, Ombretta},
title = {Enriching SMIL with Assertions for Temporal Validation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291256},
doi = {10.1145/1291233.1291256},
abstract = {In this paper we define a formal semantics for the language SMIL which can be used in a number of applications. First of all, we propose a computer aided authoring system which include a Semantic Validator Module for the evaluation of the temporal consistency of the resulting multimedia presentation. If any temporal conflict is found, the system returns to the user a message pointing out the tag which contains the error and its motivation. This helps the user to correct the error. We also introduce a notion of equivalence for SMIL tags which is useful to find a candidate for substitution in the development of complex multimedia structure, for example in the context adaptation process.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {107–116},
numpages = {10},
keywords = {consistency checking, SMIL, authoring},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258968,
author = {Mayer-Patel, Ketan},
title = {Session Details: Systems 1 - Streaming},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258968},
doi = {10.1145/3258968},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291258,
author = {Choe, Yung Ryn and Schuff, Derek L. and Dyaberi, Jagadeesh M. and Pai, Vijay S.},
title = {Improving VoD Server Efficiency with Bittorrent},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291258},
doi = {10.1145/1291233.1291258},
abstract = {This paper presents and evaluates Toast, a scalable Video-on-Demand (VoD)streaming system that combines the popular BitTorrent peer-to-peer (P2P)file-transfer technology with a simple dedicated streaming server to decrease server load and increase client transfer speed. Toast includes a modified version of BitTorrent that supports streaming data delivery and that communicates with a VoD server when the desired data cannot be delivered in real-time by other peers.The results show that the default BitTorrent download strategy is not well-suited to the VoD environment because it fetches pieces of the desired video from other peers without regard to when those pieces will actually be needed by the media viewer. Instead, strategies should favor downloading pieces of content that will be needed earlier, decreasing the chances that the clients will be forced to get the data directly from the VoD server. Such strategies allow Toast to operate much more efficiently than simple unicast distribution, reducing data transfer demands by up to 70-90% if clients remain in the system as seeds after viewing their content. Toast thus extends the aggregate throughput capability of a VoD service, offloading work from the server onto the P2P network in a scalable and demand-driven fashion.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {117–126},
numpages = {10},
keywords = {experimental systems, peer-to-peer, BitTorrent, video-on-demand, multimedia streaming},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291259,
author = {Liu, Yong},
title = {On the Minimum Delay Peer-to-Peer Video Streaming: How Realtime Can It Be?},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291259},
doi = {10.1145/1291233.1291259},
abstract = {P2P systems exploit the uploading bandwidth of individual peers to distribute content at low server cost. While the P2P bandwidth sharing design is very efficient for bandwidth sensitive applications, it imposes a fundamental performance constraint for delay sensitive applications: the uploading bandwidth of a peer cannot be utilized to upload a piece of content until it completes the download of that content. This constraint sets up a limit on how fast a piece of content can be disseminated to all peers in a P2P system. In this paper, we theoretically study the impact of this inherent delay constraint and derive the minimum delay bounds for realtime P2P streaming systems. We show that the bandwidth heterogeneity among peers can be exploited to significantly improve the delay performance of all peers. We further propose a simple snow-ball streaming algorithm to approach the minimum delay bound in realtime P2P video streaming. Our analysis suggests that the proposed algorithm has better delay performance and more robust than existing tree-based streaming solutions. Insights brought forth by our study can be used to guide the design of new P2P systems with shorter startup delays.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {127–136},
numpages = {10},
keywords = {delay bound, realtime, peer-to-peer streaming},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291260,
author = {Sat, Batu and Wah, Benjamin W.},
title = {Playout Scheduling and Loss-Concealments in Voip for Optimizing Conversational Voice Communication Quality},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291260},
doi = {10.1145/1291233.1291260},
abstract = {In this paper, we present new adaptive playout scheduling (POS) and loss concealment (LC) schemes for delivering high and consistent conversational voice communication quality (CVCQ) perceived by users in real-time VoIP systems. We first characterize the delay and loss conditions of an IP network and a human conversation in a VoIP system. We then identify the attributes that affect the human perception of CVCQ, which include listening-only speech quality (LOSQ), conversational interactivity (CI), and conversational efficiency (CE). We investigate their trade-offs with respect to system-controllable mouth-to-ear delays (MEDs) and the amount of redundant piggybacking. Finally, we evaluate our adaptive POS and redundancy-based LC schemes by packet traces collected in the PlanetLab.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {137–146},
numpages = {10},
keywords = {multimedia communication, just noticeable difference, perceptual conversational quality, voice over IP},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258969,
author = {Ma, Wei-Ying},
title = {Session Details: Demo Session 1},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258969},
doi = {10.1145/3258969},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291262,
author = {Popescu, Adrian and Mo\"{e}llic, Pierre Alain},
title = {OLIVE: A Conceptual Web Image Search Engine},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291262},
doi = {10.1145/1291233.1291262},
abstract = {In this paper we describe Olive, a concept based image search engine implemented using the WordNet nouns hierarchy. The system reformulates textual queries and performs an on the fly search for Google images corresponding to leaf nodes that are found under the currently demanded term. The retrieved pictures are rendered in a conceptually structured fashion and semantically related queries are presented to the user. In addition, a content based search in conceptually controlled neighborhoods is proposed.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {147–148},
numpages = {2},
keywords = {Google, CBIR, wordnet, ontology, conceptual image retrieval},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291263,
author = {Kroon, Bart and Boughorbel, Sabri and Hanjalic, Alan},
title = {Person-Based Search in Videos},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291263},
doi = {10.1145/1291233.1291263},
abstract = {This technical demo is build around a system we developed to automatically match persons within a video sequence. The persons are clustered by face similarity and shot information. The demo is a video editing tool with a "person query" option to show only that part of the sequence that features one of the selected actors. The demo is targeted for narrative content: series and movies, and shows the ability of the underlying person matching algorithm to operate well in a general (unconstrained) case.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {149},
numpages = {1},
keywords = {face clustering, person retrieval, face matching, person matching},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291264,
author = {Naci, Suphi Umut and Hanjalic, Alan},
title = {Intelligent Browsing of Concert Videos},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291264},
doi = {10.1145/1291233.1291264},
abstract = {The MultimediaN concert-video browser demonstrates a video interaction environment for efficiently browsing the live performance records in the pop, rock and other music concerts. The underlying automatic analyzer extracts the instrumental solos and applause sections in the concert videos and also the level of excitement along the performances. The extracted information is provided to the user via a web-based interface to let them enjoy a much more advanced experience of browsing through the concerts. Taking the unorganized structure of the concerts and the desire for non-sequential access to the content, our system is a step-forward to make large concert video databases accessible. The demo system also allows us to exhibit the power and robustness of our algorithms that are able to perform well in a highly heterogeneous and noisy context of music concerts.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {150–151},
numpages = {2},
keywords = {intelligent browsing, concert video analysis, audio analysis},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291265,
author = {D\"{o}rk, Marian and N\"{u}rnberger, Andreas and Mart\'{\i}n, Javier Velasco},
title = {Atomique: A Photo Repository for Decentralized and Distributed Photo Sharing on the Web},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291265},
doi = {10.1145/1291233.1291265},
abstract = {Photo sharing sites such as Flickr [3] and Fotolog [4] allow users to publish, organize, and explore photos in a community context combining sharing, annotation, and conversation. However, most hosted communities have architectural and institutional shortcomings due to their usually centralized nature. Users have little or no control over the community's policies, functionality, or appearance. The social data, such as contacts, comments, and group activity, are locked within a community, while it is usually not possible to interact with users from other communities.In this work we introduce Atomique a Web-based software enabling decentralized photo sharing by using open data formats and protocols from the blogosphere, i.e., RSS and Trackback, allowing exchange and discussion of photos in decentralized groups.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {152–153},
numpages = {2},
keywords = {WWW, photo sharing, digital photographs, social networks},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291266,
author = {Lecca, Michela and Messelodi, Stefano and Andreatta, Claudio},
title = {An Object Recognition System for Automatic Image Annotation and Browsing of Object Catalogs},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291266},
doi = {10.1145/1291233.1291266},
abstract = {The MEMORI system automatically detects and recognizes rescaled and/or rotated versions of objects from a database within digital color images with cluttered background. This paper describes the system's architecture and the methods implemented within, and its use as a tool for the automatic annotation and browsing of digital images of web furniture catalogs.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {154–155},
numpages = {2},
keywords = {image annotation, content-based image retrieval, object recognition, image database browsing},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291267,
author = {Srebrny, Piotr and Skevik, Karl-Andr\'{e} and Goebel, Vera and Plagemann, Thomas},
title = {Demo SPP: A Demonstrator for a Scalable P2p Vod Infrastructure},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291267},
doi = {10.1145/1291233.1291267},
abstract = {The Streaming Peer-to-Peer Protocol (SPP) architecture is a hybrid P2P system for interactive Video-on-Demand Streaming. We aim to demonstrate key issues of SPP, i.e., peer selection and incentive management. Through real live demonstration on PlanetLab and through simulated scenarios of interest in NS2, the audience will be able to judge the resulting perceptual Quality-of-Service (QoS) on a large screen connected to a set-top box. Furthermore, we plan to visualize what is happening inside SPP on a Laptop.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {156–157},
numpages = {2},
keywords = {VoD, P2P, demonstration, streaming},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291268,
author = {Neuschmied, Helmut and Trichet, Remi and Merialdo, Berard},
title = {Fast Annotation of Video Objects for Interactive TV},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291268},
doi = {10.1145/1291233.1291268},
abstract = {In this demonstration, we present the Annotation Tool that is being developed in the porTiVity project to annotate video objects for Interactive Television programs. This tool includes various video processing components to structure and speed-up the annotation process, such as shot segmentation, key-frame extraction, object tracking and object redetection. A specific feature is that the tool includes a preprocessing phase where a quantity of information is precomputed, so that the annotation itself can be done quite rapidly.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {158–159},
numpages = {2},
keywords = {real-time application, video annotation tool, generic object tracker, object re-detection},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291269,
author = {Goh, Hanlin and Li, Yiqun and Lim, Joo-Hwee},
title = {An Image-Based Outdoor Place Recognition and Information Retrieval System},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291269},
doi = {10.1145/1291233.1291269},
abstract = {In image-based place recognition, an image is used to deduce the location of the viewer during image acquisition. The identified place can subsequently be used to provide additional information to the user. This demonstration paper briefly describes a system that performs image-based place recognition on outdoor images, made possible by viewer-centric data sampling and local feature-based scene identification. It also explains our proposed demonstration that displays the recognized place on a map and provides information of amenities in its vicinity.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {160–161},
numpages = {2},
keywords = {information retrieval, scene identification, place recognition},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291270,
author = {Ide, Ichiro and Kinoshita, Tomoyoshi and Takahashi, Tomokazu and Satoh, Shin'ichi and Murase, Hiroshi},
title = {MediaWalker: A Video Archive Explorer Based on Time-Series Semantic Structure},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291270},
doi = {10.1145/1291233.1291270},
abstract = {We introduce a video browsing interface 'mediaWalker' that lets users explore a news video archive based on a time-series semantic structure; the 'topic thread' structure. The interface lets users efficiently track up and down the development of news in an archive with more than 1,000 hours of video.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {162–163},
numpages = {2},
keywords = {topic tracking, news video},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291271,
author = {Shen, Heng Tao and Zhou, Xiaofang and Huang, Zi and Shao, Jie},
title = {Statistical Summarization of Content Features for Fast Near-Duplicate Video Detection},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291271},
doi = {10.1145/1291233.1291271},
abstract = {This paper outlines a system for detecting near-duplicate videos based on a novel summarization of content features for each clip. It captures the dominating content and content changing trends of a video, so this representation is very compact and effective. Unlike traditional frame-to-frame comparisons that involve quadratic computational complexity, the similarity measure of our method is only linear in dimensionality of feature space and independent of video length. To further improve the search efficiency for very large video databases, an effective indexing structure is deployed to significantly reduce the number of videos for comparison. This demo shows that our system can accurately find near-duplicates from a collection of tens of thousands of video clips extremely fast.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {164–165},
numpages = {2},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291272,
author = {Sanyal, Subhajit and Sengamedu, Srinivasan H.},
title = {LogoSeeker: A System for Detecting and Matching Logos in Natural Images},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291272},
doi = {10.1145/1291233.1291272},
abstract = {The dominant advertising model on the Internet is based on matching search keywords or web page content to ads. The matching is based on text content. There is an explosion of media content on the Internet. Matching based on image content has not taken off on the Internet despite the huge popularity of sites like flickr.com. In this demo, we show we can adapt techniques from image matching to enable a logo-based advertisement matching system for photo sharing sites like Flickr. Logo detection is based on detection and matching of salient points.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {166–167},
numpages = {2},
keywords = {logo matching, key-point matching, logo detection},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258970,
author = {Smeaton, Alan},
title = {Session Details: Content 2 - Video Structuring},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258970},
doi = {10.1145/3258970},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291274,
author = {Wu, Xiao and Hauptmann, Alexander G. and Ngo, Chong-Wah},
title = {Novelty Detection for Cross-Lingual News Stories with Visual Duplicates and Speech Transcripts},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291274},
doi = {10.1145/1291233.1291274},
abstract = {An overwhelming volume of news videos from different channels and languages is available today, which demands automatic management of this abundant information. To effectively search, retrieve, browse and track cross-lingual news stories, a news story similarity measure plays a critical role in assessing the novelty and redundancy among them. In this paper, we explore the novelty and redundancy detection with visual duplicates and speech transcripts for cross-lingual news stories. News stories are represented by a sequence of keyframes in the visual track and a set of words extracted from speech transcript in the audio track. A major difference to pure text documents is that the number of keyframes in one story is relatively small compared to the number of words and there exist a large number of non-near duplicate keyframes. These features make the behavior of similarity measures different compared to traditional textual collections. Furthermore, the textual features and visual features complement each other for news stories. They can be further combined to boost the performance. Experiments on the TRECVID-2005 cross-lingual news video corpus show that approaches on textual features and visual features demonstrate different performance, and measures on visual features are quite effective. Overall, the cosine distance on keyframes is still a robust measure. Language models built on visual features demonstrate promising performance. The fusion of textual and visual features improves overall performance.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {168–177},
numpages = {10},
keywords = {similarity measure, near-duplicate keyframes, language model, cross-lingual information retrieval, news videos, novelty and redundancy detection, multimodality},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291275,
author = {Li, Shan and Lee, Moon-Chuen},
title = {Efficient Spatiotemporal-Attention-Driven Shot Matching},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291275},
doi = {10.1145/1291233.1291275},
abstract = {As human attention is an effective mechanism for information prioritizing and selecting, it provides a practical approach for intelligent shot similarity matching. In this paper, we propose an attention-driven video interpretation method using an efficient spatiotemporal attention detection framework. The motion attention detection in most existing methods is unstable and computationally expensive. Avoiding calculating motion explicitly, the proposed framework generates motion saliency using the rank deficiency of grayscale gradient tensors. To address an ill-posed weight determination problem, an adaptive fusion method is proposed for motion and spatial saliency integration by highlighting the more reliable saliency maps. An attention-drive matching strategy is proposed by converting attention values to importance factors, which subsequently boost the attended regions in region-based shot matching. A global feature-based matching strategy is also included the attention-driven strategy, to address cases where visual attention detection is less applicable. Experiment results demonstrate the advantages of the proposed method in similarity matching.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {178–187},
numpages = {10},
keywords = {motion saliency, focus of attention, shot similarity},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291276,
author = {Yang, Jun and Yan, Rong and Hauptmann, Alexander G.},
title = {Cross-Domain Video Concept Detection Using Adaptive Svms},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291276},
doi = {10.1145/1291233.1291276},
abstract = {Many multimedia applications can benefit from techniques for adapting existing classifiers to data with different distributions. One example is cross-domain video concept detection which aims to adapt concept classifiers across various video domains. In this paper, we explore two key problems for classifier adaptation: (1) how to transform existing classifier(s) into an effective classifier for a new dataset that only has a limited number of labeled examples, and (2) how to select the best existing classifier(s) for adaptation. For the first problem, we propose Adaptive Support Vector Machines (A-SVMs) as a general method to adapt one or more existing classifiers of any type to the new dataset. It aims to learn the "delta function" between the original and adapted classifier using an objective function similar to SVMs. For the second problem, we estimate the performance of each existing classifier on the sparsely-labeled new dataset by analyzing its score distribution and other meta features, and select the classifiers with the best estimated performance. The proposed method outperforms several baseline and competing methods in terms of classification accuracy and efficiency in cross-domain concept detection in the TRECVID corpus.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {188–197},
numpages = {10},
keywords = {cross-domain video concept detection, classifier adaptation, adaptive SVMs},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258971,
author = {Erol, Berna},
title = {Session Details: Applications 2 - Browsing and Searching Video},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258971},
doi = {10.1145/3258971},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291278,
author = {Neo, Shi-Yong and Ran, Yuanyuan and Goh, Hai-Kiat and Zheng, Yantao and Chua, Tat-Seng and Li, Jintao},
title = {The Use of Topic Evolution to Help Users Browse and Find Answers in News Video Corpus},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291278},
doi = {10.1145/1291233.1291278},
abstract = {Earlier research in news video has been focusing mainly on improving retrieval accuracies given the limited amount of extractable video semantics. In this paper, we propose an enhancement to news video searching by leveraging extractable video semantics coupled with relevant external information resources to support event-based analysis; leading to discovery of topic hierarchy for browsing key events and supporting question answering (QA). We introduce topic browsing based on news structures obtained through hierarchical clustering and threading, with emphasis on interesting events determined by measuring the amount of "web activities" on these events on Blog sites. For QA, we employ extensive query analysis to obtain various query features in addition to the topic hierarchical structures to answer both context-oriented and visual-oriented questions. Our main contributions includes: (a) combining multimodal event information extracted from news video, web news articles and news blogs to support event analysis, (b) introducing topic evolution browsing based on users' interest and (c) extending QA on top of topic hierarchy to handle various types of specialized video queries. Experiments performed on 70 hours of multilingual news from TRECVID 2005 dataset shows that the proposed approach is effective and appealing to users.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {198–207},
numpages = {10},
keywords = {video analysis, event evolution, video question answering},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291279,
author = {Liu, Jingjing and Lai, Wei and Hua, Xian-Sheng and Huang, Yalou and Li, Shipeng},
title = {Video Search Re-Ranking via Multi-Graph Propagation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291279},
doi = {10.1145/1291233.1291279},
abstract = {This paper1 is concerned with the problem of multimodal fusion in video search. First, we employ an object-sensitive approach to query analysis to improve the baseline result of text-based video search. Then, we propose a PageRank-like graph-based approach to text-based search result re-ranking. To better exploit the underlying relationship between video shots, the proposed re-ranking scheme simultaneously leverages textual relevancy, semantic concept relevancy, and low-level-feature-based visual similarity. In this PageRank-like scheme, we construct a set of graphs with the video shots as vertexes, and the conceptual and visual similarity between video shots as "hyperlinks". A modified topic-sensitive PageRank algorithm is then applied on these graphs to propagate the relevance scores through all related video shots. Experimental results verify the effectiveness of the graph-based propagation approach combined with the object-sensitive query analysis approach, which brings significant improvement to the baseline of text-based video search. Our experimental analysis also indicates that the proposed re-ranking method is highly generic and independent of different query classes, training data, and human interference.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {208–217},
numpages = {10},
keywords = {query analysis, multi-graph propagation, object-sensitive, re-ranking, multimodal fusion, video search, pagerank algorithm},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291280,
author = {Wu, Xiao and Hauptmann, Alexander G. and Ngo, Chong-Wah},
title = {Practical Elimination of Near-Duplicates from Web Video Search},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291280},
doi = {10.1145/1291233.1291280},
abstract = {Current web video search results rely exclusively on text keywords or user-supplied tags. A search on typical popular video often returns many duplicate and near-duplicate videos in the top results. This paper outlines ways to cluster and filter out the near-duplicate video using a hierarchical approach. Initial triage is performed using fast signatures derived from color histograms. Only when a video cannot be clearly classified as novel or near-duplicate using global signatures, we apply a more expensive local feature based near-duplicate detection which provides very accurate duplicate analysis through more costly computation. The results of 24 queries in a data set of 12,790 videos retrieved from Google, Yahoo! and YouTube show that this hierarchical approach can dramatically reduce redundant video displayed to the user in the top result set, at relatively small computational cost.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {218–227},
numpages = {10},
keywords = {web video, multimodality, similarity measure, filtering, novelty and redundancy detection, copy setection, near-duplicates},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258972,
author = {Sebe, Nicu},
title = {Session Details: HCI 1 - New Media Interaction},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258972},
doi = {10.1145/3258972},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291282,
author = {Koh, Eunyee and Kerne, Andruid and Webb, Andrew and Damaraju, Sashikanth and Sturdivant, David},
title = {Generating Views of the Buzz: Browsing Popular Media and Authoring Using Mixed-Initiative Composition},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291282},
doi = {10.1145/1291233.1291282},
abstract = {combinFormation's mixed-initiative composition space enables system agents and humans to engage in processes of finding relevant information, and forming and authoring collections. Previously, the system was developed and utilized to support information discovery. The efficacy of the system for supporting creativity has been established in some contexts.We present combinFormation as a tool for browsing popular media and authoring personal collections. Yahoo Buzz is an popular media collection of top search queries, categorized into genres such as actors, music and sports. Existing interfaces limit the human participant to only viewing results of a single search at any given time. This paper presents a new system structure which interleaves multiple searches concurrently in a round-robin manner, enabling participants to concurrently explore and connect diverse result sets, which, in aggregate, may consist of hundreds of documents. The mixed-initiative composition space serves as a media interface for combining search results and authoring personal collections. Evaluation using the Buzz demonstrated participants ability to browse more diverse information using combinFormation than with a typical browser. They experienced browsing and authoring as easier and more entertaining. Results have implications for a broad range of use contexts in which combined views of the results of multiple searches need to be authored, including research scenarios, as well as popular media.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {228–237},
numpages = {10},
keywords = {search interfaces, exploratory search, information discovery, information recombination, personal collections},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291283,
author = {Roussel, Nicolas and Gueddana, Sofiane},
title = {Beyond "beyond Being There": Towards Multiscale Communication Systems},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291283},
doi = {10.1145/1291233.1291283},
abstract = {Forty years after AT&amp;T's Picturephone, video is still mainly considered as a way to enhance audio communication in an attempt to reproduce face-to-face conditions. In a 1992 paper, Hollan and Stornetta argued that we should develop communication tools that go beyond being there. In this paper, we discuss two different interpretations of their analysis. We then propose the concept of multiscale communication as an alternative approach for motivating telecommunication research, an approach that aims at creating systems that support a variable degree of engagement, smooth transitions between degrees and integration with other media. Finally, we present three video systems from which the multiscale communication concept emerged and that partly illustrate it.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {238–246},
numpages = {9},
keywords = {coordination, video-mediated communication, collaboration, computer-mediated communication, multiscale communication, communication},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291284,
author = {H\"{u}rst, Wolfgang and G\"{o}tz, Georg and Welte, Martina},
title = {Interactive Video Browsing on Mobile Devices},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291284},
doi = {10.1145/1291233.1291284},
abstract = {Today, videos can be replayed on modern handheld devices, such as multimedia cellphones and personal digital assistants (PDAs), due to significant improvements in their processing power. However, screen size remains a limiting resource making it hard, if not impossible to adapt common approaches for video browsing to such mobile devices. In this paper we propose a new interface for the pen-based navigation of videos on PDAs and multimedia cellphones. Our solution - called the MobileZoomSlider - enables users to intuitively skim a video along the timeline on different granularity levels. In addition, it allows for continuous manipulation of replay speed for browsing purposes. Both interaction concepts are seamlessly integrated into the overall interface, thus taking optimum advantage of the limited screen space. Our claims are verified with a first evaluation which proves the suitability of the overall concept.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {247–256},
numpages = {10},
keywords = {interface design, video browsing, handheld devices, pen-based computing, interaction, navigation, mobile computing},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258973,
author = {Laganier, Julien},
title = {Session Details: Short Papers Poster Session 1 - Content Analysis},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258973},
doi = {10.1145/3258973},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291286,
author = {Kim, Hansung and Sakamoto, Ryuuki and Kitahara, Itaru and Toriyama, Tomoji and Kogure, Kiyoshi},
title = {Reliability-Based 3D Reconstruction in Real Environment},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291286},
doi = {10.1145/1291233.1291286},
abstract = {We present a practical 3D reconstruction method that guarantees robust visual hull construction in real environments where segmentation errors and occlusion exist. The proposed method consists of foreground extraction and reliability-based shape-from-silhouette, and they are connected by the intra-/inter-silhouette reliabilities. In foreground extraction, all regions are classified into four categories based on their intra-reliabilities. Then the reliability-based shape-from-silhouette technique reconstructs a visual hull by carving a 3D space based on the intra-/inter-silhouette reliabilities. The proposed method provides a reliable visual hull in real environments without much increment of the system complexity compared with conventional systems.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {257–260},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291287,
author = {Vinciarelli, Alessandro and Favre, Sarah},
title = {Broadcast News Story Segmentation Using Social Network Analysis and Hidden Markov Models},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291287},
doi = {10.1145/1291233.1291287},
abstract = {This paper presents an approach for the segmentation of broadcast news into stories. The main novelty of this work is that the segmentation process does not take into account the content of the news, i.e. what is said, but rather the structure of the social relationships between the persons that in the news are involved. The main rationale behind such an approach is that people interacting with each other are likely to talk about the same topics, thus social relationships are likely to be correlated to stories. The approach is based on Social Network Analysis (for the representation of social relationships) and Hidden Markov Models (for the mapping of social relationships into stories). The experiments are performed over 26 hours of radio news and the results show that a fully automatic process achieves a purity higher than 0.75.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {261–264},
numpages = {4},
keywords = {story segmentation, hidden markov models, social network analysis, broadcast news},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291288,
author = {Hou, Xiaodi and Zhang, Liqing},
title = {Color Conceptualization},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291288},
doi = {10.1145/1291233.1291288},
abstract = {In this paper, we propose a method to manipulate colors of an image. Based on a library of natural color images, our system evolves several prototypes of color distribution of the library, which we call "color concepts". By applying these color concepts on an input image, a user can easily change the mood of image colors in a global manner. Our results of photographs and paintings indicate that this method is capable of high-quality color manipulations.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {265–268},
numpages = {4},
keywords = {scene analysis, color concept, color transfer},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291289,
author = {Liu, Jing and Li, Zhiwei and Li, Mingjing and Lu, Hanqing and Ma, Songde},
title = {Human Behaviour Consistent Relevance Feedback Model for Image Retrieval},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291289},
doi = {10.1145/1291233.1291289},
abstract = {Due to the well known semantic gap, content based image retrieval is a difficult problem. To bridge it, relevance feedback as an effective solution has been extensively studied in literatures. However, existing methods follow a single-line searching philosophy, which may lead to a local optimum in search space. To address the problem, we propose a human behavior consistent relevance feedback model for image retrieval in this paper. Simulating human behaviors, the proposed model enable the user to perform relevance feedback in three manners: Follow up, Go back, and Restart. Each manner is a way for the user to provide the system with his or her opinions about search results. The accumulated feedback information can be used to refine the user query and regulate the similarity metric. We adopt the graph ranking algorithm to model the retrieval process. Experiments conducted on standard Corel dataset and Pascal VOC 2006 dataset demonstrate the effectiveness of the proposed mechanism.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {269–272},
numpages = {4},
keywords = {image retrieval, graph ranking, relevance feedback},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291290,
author = {Zhang, Hong and Zhuang, Yueting and Wu, Fei},
title = {Cross-Modal Correlation Learning for Clustering on Image-Audio Dataset},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291290},
doi = {10.1145/1291233.1291290},
abstract = {It is interesting and challenging to explore correlations between different datasets and utilize such correlations for the clustering on these datasets. Cross-modal correlation between images and audios can help identify images (or audios) of certain semantics. However, the heterogeneous problem makes it difficult to learn cross-modal correlation between visual and auditory features. In this paper, we analyze canonical correlation between feature matrices of images and audios during subspace mapping; then we design correlation-based similarity reinforcement for images and audios; thirdly we implement image clustering and audio clustering with affinity propagation. Experiment results on image-audio dataset are encouraging and show that the performance of our approach is effective. We give an interesting application of querying images by audio examples.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {273–276},
numpages = {4},
keywords = {similarity reinforcement, clustering, cross-modal correlation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291291,
author = {Yuan, Jinhui and Li, Jianmin and Zhang, Bo},
title = {Gradual Transition Detection with Conditional Random Fields},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291291},
doi = {10.1145/1291233.1291291},
abstract = {In this paper, we view gradual transition detection as a sequence labeling problem and propose to use Conditional Random Fields (CRFs) for this purpose. CRFs is a state-of-the-art sequence labeling approach. It provides a unified way to integrate various useful clues to form a decision system. Moreover, it has principled way for parameter estimation and inference. Compared to rule-based approaches, gradual transition detection with CRFs requires fewer human interactions while designing the system. The experiments on TRECVID platform show that CRFs can achieve comparable performance to that of the state-of-the-art approaches.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {277–280},
numpages = {4},
keywords = {conditional random fields, gradual transition detection},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291292,
author = {Zhang, Ziming and Chan, Syin and Chia, Liang-Tien},
title = {Image Classification Using Tensor Representation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291292},
doi = {10.1145/1291233.1291292},
abstract = {We propose a new approach to exploit the different discriminability of image features at different scales simultaneously. By modifying the Bag-of-words model, we represent an image as a matrix whose elements are the occurrences of a set of codewords within different scale ranges. In this way, we can represent an image collection using a 3rd-order tensor. Then a new classification method, tensor-pLSA, which is an extension of Probabilistic Latent Semantic Analysis (pLSA), is introduced to classify these images based on this tensor representation. Finally, we compare the tensor representation with the original matrix representation to show the effectiveness of our approach.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {281–284},
numpages = {4},
keywords = {image classification, tensor representation, tensor-pLSA},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291293,
author = {Wang, Dong and Li, Xirong and Li, Jianmin and Zhang, Bo},
title = {The Importance of Query-Concept-Mapping for Automatic Video Retrieval},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291293},
doi = {10.1145/1291233.1291293},
abstract = {A new video retrieval paradigm of query-by-concept emerges recently. However, it remains unclear how to exploit the detected concepts in retrieval given a multimedia query. In this paper, we point out that it is important to map the query to a few relevant concepts instead of search with all concepts. In addition, we show that solving this problem through both text and image inputs are effective for search, and it is possible to determine the number of related concepts by a language modeling approach. Experimental evidence is obtained on the automatic search task of TRECVID 2006 using a large lexicon of 311 learned semantic concept detectors.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {285–288},
numpages = {4},
keywords = {automatic video retrieval, query-concept-mapping},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291294,
author = {Yuan, Junsong and Wang, Wei and Meng, Jingjing and Wu, Ying and Li, Dongge},
title = {Mining Repetitive Clips through Finding Continuous Paths},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291294},
doi = {10.1145/1291233.1291294},
abstract = {Automatically discovering repetitive clips from large video database is a challenging problem due to the enormous computational cost involved in exploring the huge solution space. Without any a priori knowledge of the contents, lengths and total number of the repetitive clips, we need to discover all of them in the video database. To address the large computational cost, we propose a novel method which translates repetitive clip mining to the continuous path finding problem in a matching trellis, where sequence matching can be accelerated by taking advantage of the temporal redundancies in the videos. By applying the locality sensitive hashing (LSH) for efficient similarity query and the proposed continuous path finding algorithm, our method is of only quadratic complexity of the database size. Experiments conducted on a 10.5-hour TRECVID news dataset have shown the effectiveness, which can discover repetitive clips of various lengths and contents in only 25 minutes, with features extracted off-line.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {289–292},
numpages = {4},
keywords = {video data mining, repetitive pattern discovery},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291295,
author = {Luan, Huan-Bo and Neo, Shi-Yong and Goh, Hai-Kiat and Zhang, Yong-Dong and Lin, Shou-Xun and Chua, Tat-Seng},
title = {Segregated Feedback with Performance-Based Adaptive Sampling for Interactive News Video Retrieval},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291295},
doi = {10.1145/1291233.1291295},
abstract = {Existing video research incorporates the use of relevance feedback based on user-dependent interpretations to improve the retrieval results. In this paper, we segregate the process of relevance feedback into 2 distinct facets: (a) recall-directed feedback; and (b) precision-directed feedback. The recall-directed facet employs general features such as text and high level features (HLFs) to maximize efficiency and recall during feedback, making it very suitable for large corpuses. The precision-directed facet on the other hand uses many other multimodal features in an active learning environment for improved accuracy. Combined with a performance-based adaptive sampling strategy, this process continuously re-ranks a subset of instances as the user annotates. Experiments done using TRECVID 2006 dataset show that our approach is efficient and effective.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {293–296},
numpages = {4},
keywords = {relevance feedback, news video retrieval, active learning},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291296,
author = {Tang, Jinhui and Hua, Xian-Sheng and Qi, Guo-Jun and Wu, Xiuqing},
title = {Typicality Ranking via Semi-Supervised Multiple-Instance Learning},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291296},
doi = {10.1145/1291233.1291296},
abstract = {Most of the existing methods for natural scene categorization only consider whether a sample is relevant or irrelevant to a particular concept. However, for the samples relevant to a certain concept, their typicalities or relevancy scores to the concept generally are different. Typicality measure should be taken into account to make the categorization results more consistent with human's perception. In this paper, we propose a novel typicality ranking scheme for categorizing natural scenes through a two-stage semi-supervised multiple-instance learning method. The first stage infers the typicalities of the underlying positive instances (i.e., regions in images) in the training dataset and the second one predicts the typicality of each bag (i.e., image) in a semi-supervised manner. Compared to existing typicality ranking approaches, the main advantages of the proposed method lie in twofold. First, it only needs image-level labels instead of region-level ones in the training stage. Second, it is fully automated and no human feedback is required. Experiments conducted on a COREL image dataset demonstrate the effectiveness of the proposed approach.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {297–300},
numpages = {4},
keywords = {natural scene categorization, multiple-instance learning, typicality ranking, semi-supervised learning},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291297,
author = {Lu, Yijuan and Cohen, Ira and Zhou, Xiang Sean and Tian, Qi},
title = {Feature Selection Using Principal Feature Analysis},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291297},
doi = {10.1145/1291233.1291297},
abstract = {Dimensionality reduction of a feature set is a common preprocessing step used for pattern recognition and classification applications. Principal Component Analysis (PCA) is one of the popular methods used, and can be shown to be optimal using different optimality criteria. However, it has the disadvantage that measurements from all the original features are used in the projection to the lower dimensional space. This paper proposes a novel method for dimensionality reduction of a feature set by choosing a subset of the original features that contains most of the essential information, using the same criteria as PCA. We call this method Principal Feature Analysis (PFA). The proposed method is successfully applied for choosing the principal features in face tracking and content-based image retrieval (CBIR) problems. Automated annotation of digital pictures has been a highly challenging problem for computer scientists since the invention of computers. The capability of annotating pictures by computers can lead to breakthroughs in a wide range of applications including Web image search, online picture-sharing communities, and scientific experiments. In our work, by advancing statistical modeling and optimization techniques, we can train computers about hundreds of semantic concepts using example pictures from each concept. The ALIPR (Automatic Linguistic Indexing of Pictures - Real Time) system of fully automatic and high speed annotation for online pictures has been constructed. Thousands of pictures from an Internet photo-sharing site, unrelated to the source of those pictures used in the training process, have been tested. The experimental results show that a single computer processor can suggest annotation terms in real-time and with good accuracy.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {301–304},
numpages = {4},
keywords = {principal component analysis, discriminant analysis, feature extraction, feature selection},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291298,
author = {Liu, Huiying and Jiang, Shuqiang and Huang, Qingming and Xu, Changsheng and Gao, Wen},
title = {Region-Based Visual Attention Analysis with Its Application in Image Browsing on Small Displays},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291298},
doi = {10.1145/1291233.1291298},
abstract = {Visual attention has been a hot research point for many years and many new applications are emerging especially for wireless multimedia services. In this paper a novel region-based visual attention is proposed to detect the Regions of Interest (ROI) of images. In the proposed method, density based image segmentation is first performed by regarding region as the perceptive unit, which makes the model robust to the scale of ROIs and contains more perceptive information. To generate region saliency map to detect ROI, global effect and contextual difference are covered in the form of distance factor and adjacency factor respectively. Since different ROIs may have different importance for different purposes, a ROI ranking algorithm is designed for browsing large images on small displays. Experimental results and evaluation reveal that our method works effectively to detect ROIs from images and the users are satisfied with the browsing sequence on small displays.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {305–308},
numpages = {4},
keywords = {image adaptation, visual attention, ROI ranking},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291299,
author = {Nwe, Tin Lay and Li, Haizhou},
title = {Singing Voice Detection Using Perceptually-Motivated Features},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291299},
doi = {10.1145/1291233.1291299},
abstract = {Perceptual features are motivated by human perception of sounds. In this paper, several perceptually-motivated features such as harmonic, vibrato and timbre are studied to detect singing voice segments in a song. In addition, singing formant and attack-decay envelope of the sound are also studied for acoustic feature formulation. The cepstral coefficients which reflect the timbre characteristics are formulated by combining information from harmonic content, vibrato, singing formant and attack-decay envelope of the sound. Bandpass filters that spread according to the octave frequency scale are used to extract vibrato and harmonic information. Several experiments are conducted using a database that includes 84 popular songs from commercially available CD recordings. The experiments show that the proposed feature formulation methods are effective.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {309–312},
numpages = {4},
keywords = {vibrato, singing formant, timbre, harmonic, singing voice},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291300,
author = {Chen, Yanhua and Rege, Manjeet and Dong, Ming and Fotouhi, Farshad},
title = {Deriving Semantics for Image Clustering from Accumulated User Feedbacks},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291300},
doi = {10.1145/1291233.1291300},
abstract = {Image clustering solely based on visual features without any knowledge or background information suffers from the problem of semantic gap. In this paper, we propose SS-NMF: a semi-supervised non-negative matrix factorization framework for image clustering. Accumulated relevance feedback in a CBIR system is treated as user provided supervision for guiding the image clustering. We consider the set of positive images in the feedback as constraints on the clustering specifying that the images "must" be clustered together. Similarly, negative images provide constraints specifying that they "cannot" be clustered along with the positive images. Through an iterative algorithm, we perform symmetric tri-factorization of the image-image similarity matrix to infer the clustering. Theoretically, we prove the correctness of SS-NMF by showing that the algorithm is guaranteed to converge. Through experiments conducted on general purpose image datasets, we demonstrate the superior performance of SS-NMF for clustering images effectively.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {313–316},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291301,
author = {Rege, Manjeet and Dong, Ming and Hua, Jing},
title = {Clustering Web Images with Multi-Modal Features},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291301},
doi = {10.1145/1291233.1291301},
abstract = {Web image clustering has drawn significant attention in the research community recently. However, not much work has been done in using multi-modal information for clustering Web images. In this paper, we address the problem of Web image clustering by simultaneous integration of visual and textual features from a graph partitioning perspective. In particular, we modelled visual features, images, and words from the surrounding text of the images using a tripartite graph. This graph is actually considered as a fusion of two bipartite graphs that are partitioned simultaneously by the proposed Consistent Isoperimetric High-order Co-clustering(CIHC) framework. Although a similar approach has been adopted before, the main contribution of this work lies in the computational efficiency, quality in Web image clustering and scalability to large image repositories that CIHC is able to achieve. We demonstrate this through experimental results performed on real Web images.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {317–320},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291302,
author = {Chen, Shifeng and Li, Zhenguo and Liu, Jianzhuang and Tang, Xiaoou},
title = {Image Matting Using Linear Optimization},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291302},
doi = {10.1145/1291233.1291302},
abstract = {An image can be assumed to be a composite of the foreground and the background. The foreground and the background of each pixel are linearly combined in terms of this pixel's foreground opacity (called alpha). Image matting is the process of estimating the foreground, the background and the alpha for each pixel. In this paper, we transform the ill-posed image matting problem into two over-determined linear optimization problems by introducing two medium variables and imposing smoothness constraints. Closed form solutions can be obtained from the two problems. Extensive experimental results indicate that our algorithm can generate high-quality matting results.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {321–324},
numpages = {4},
keywords = {image matting, closed form solution, linear optimization},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291303,
author = {Wang, Meng and Mei, Tao and Yuan, Xun and Song, Yan and Dai, Li-Rong},
title = {Video Annotation by Graph-Based Learning with Neighborhood Similarity},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291303},
doi = {10.1145/1291233.1291303},
abstract = {Graph-based semi-supervised learning methods have been proven effective in tackling the difficulty of training data insufficiency in many practical applications such as video annotation. These methods are all based on an assumption that the labels of similar samples are close. However, as a crucial factor of these algorithms, the estimation of pairwise similarity has not been sufficiently studied. Usually, the similarity of two samples is estimated based on the Euclidean distance between them. But we will show that similarities are not merely related to distances but also related to the structures around the samples. It is shown that distance-based similarity measure may lead to high classification error rates even on several simple datasets. In this paper we propose a novel neighborhood similarity measure, which simultaneously takes into account both thse distance between samples and the difference between the structures around the corresponding samples. Experiments on synthetic dataset and TRECVID benchmark demonstrate that the neighborhood similarity is superior to existing distance based similarity.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {325–328},
numpages = {4},
keywords = {semi-supervised learning, video annotation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291304,
author = {Cui, Jingyu and Zhang, Changshui},
title = {Combining Stroke-Based and Selection-Based Relevance Feedback for Content-Based Image Retrieval},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291304},
doi = {10.1145/1291233.1291304},
abstract = {We propose a flexible interaction mechanism for CBIR by enabling relevance feedback inside images through drawling strokes. User's interest is obtained from an easy-to-use user interface, and fused seamlessly with traditional feedback information in a semi-supervised learning framework. Retrieval performance is boosted due to more precise description of the query concept. Region segmentation is also improved based on the collected strokes, and further enhances the retrieval precision. We implement our system Flexible Image Search Tool (FIST) based on the ideas above. Experiments on two real world data sets demonstrate the effectiveness of our approach.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {329–332},
numpages = {4},
keywords = {image retrieval interface, segmentation, stroke-based image retrieval, relevance feedback},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291305,
author = {Fleischman, Michael and Roy, Brandon and Roy, Deb},
title = {Temporal Feature Induction for Baseball Highlight Classification},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291305},
doi = {10.1145/1291233.1291305},
abstract = {Most approaches to highlight classification in the sports domain exploit only limited temporal information. This paper presents a method, called temporal feature induction, which automatically mines complex temporal information from raw video for use in highlight classification. The method exploits techniques from temporal data mining to discover a codebook of temporal patterns that encode long distance dependencies and duration information. Preliminary experiments show that using such induced temporal features significantly improves performance of a baseball highlight classification system.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {333–336},
numpages = {4},
keywords = {sports video, highlight classification, temporal data mining, baseball, discriminative models},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291306,
author = {Han, Jungong and Farin, Dirk and de With, Peter H. N.},
title = {A Real-Time Augmented-Reality System for Sports Broadcast Video Enhancement},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291306},
doi = {10.1145/1291233.1291306},
abstract = {This paper presents a new augmented-reality system designed to generate visual enhancements for TV broadcasted court-net sports. A probabilistic method based on the Expectation Maximization (EM) procedure is utilized to find the optimal feature points, thereby enabling the automatic acquisition of the camera parameters from the TV image with high accuracy. A virtual camera derived from the original camera, helps to synthesize a variety of virtual scenes, such as the scene from the viewpoint of a player, depending on the intention of the user. To preserve the visual nature of the original human motion, the player's shape and texture are extracted from the real video and texture-mapped onto the virtual video. The system was tested over a set of court-net sports videos containing tennis, badminton and volleyball and demonstrated promising results.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {337–340},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291307,
author = {Shi, Rui and Lee, Chin-Hui and Chua, Tat-Seng},
title = {Enhancing Image Annotation by Integrating Concept Ontology and Text-Based Bayesian Learning Model},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291307},
doi = {10.1145/1291233.1291307},
abstract = {Automatic image annotation (AIA) has been a hot research topic in recent years since it can be used to support concept-based image retrieval. However, most existing AIA models depend heavily on the availability of a large number of labeled training samples, which require significant human labeling efforts. In this paper, we propose a novel learning framework which integrates text-based Bayesian model (TBM) and concept ontology to effectively expand the training set of each concept class without the need of additional human labeling efforts or collecting additional training images from other data sources. The basic idea lies in exploiting the text information from training set to provide additional effective annotations for training images so that training data for each concept class can be augmented. In this study we employ Bayesian Hierarchical Multinomial Mixture Models (BHMMMs) as our baseline AIA model. By combining additional annotations obtained from TBM into each concept class in the training phase, the performance of BHMMMs can be significantly improved on Corel image dataset with 263 testing concepts as compared to the state-of-the-art AIA models under the same experimental configurations.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {341–344},
numpages = {4},
keywords = {MAP, MLE, automatic image annotation, mixture model},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291308,
author = {Zha, Zheng-Jun and Mei, Tao and Hua, Xian-Sheng and Qi, Guo-Jun and Wang, Zengfu},
title = {Refining Video Annotation by Exploiting Pairwise Concurrent Relation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291308},
doi = {10.1145/1291233.1291308},
abstract = {Video annotation is a promising and essential step for content-based video search and retrieval. Most of the state-of-the-art video annotation approaches detect multiple semantic concepts in an isolated manner, which neglect the fact that video concepts are usually correlated in semantic nature. In this paper, we propose to refine video annotation by leveraging the pairwise concurrent relation among video concepts. Such concurrent relation is explicitly modeled by a concurrent matrix and then a propagation strategy is adopted to refine the annotations. Through spreading the scores of all related concepts to each other iteratively, the detection results approach stable and optimal. In contrast with existing concept fusion methods, the proposed approach is computationally more efficient and easy to implement, not requiring to construct any contextual model. Furthermore, we show its intuitive connection with the PageRank algorithm. We conduct the experiments on TRECVID 2005 corpus and report superior performance compared to existing key approaches.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {345–348},
numpages = {4},
keywords = {video annotation, pairwise concurrent relation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291309,
author = {Gu, Zhiwei and Mei, Tao and Hua, Xian-Sheng and Tang, Jinhui and Wu, Xiuqing},
title = {Multi-Layer Multi-Instance Kernel for Video Concept Detection},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291309},
doi = {10.1145/1291233.1291309},
abstract = {In video concept detection, most existing methods have not well studied the intrinsic hierarchical structure of video content. However, unlike flat attribute-value data used in many existing methods, video is essentially a structured media with multi-layer representation. For example, a video can be represented by a hierarchical structure including, from large to small, shot, key-frame, and region. Moreover, it fits the typical Multi-Instance (MI) setting in which the "bag-instance" correspondence is embedded among contiguous layers. We call such multi-layer structure and the "bag-instance" relation embedded in the structure as Multi-Layer Multi-Instance (MLMI) setting in this paper. We formulate video concept detection as an MLMI learning problem in which a rooted tree with MLMI nature embedded is devised to represent a video segment. Furthermore, by fusing the information from different layers, we construct a novel MLMI kernel to measure the similarities between the instances in the same and different layers. In contrast to traditional MI learning, both the Multi-Layer structure and Multi-Instance relations are leveraged simultaneously in the proposed kernel. We applied MLMI kernel to concept detection task on TRECVID 2005 corpus and reported superior performance (+25% in Mean Average Precision) to standard Support Vector Machine based approaches.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {349–352},
numpages = {4},
keywords = {video concept detection, multi-layer multi-instance learning, kernel machine},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291310,
author = {Rodriguez, Mikel D. and Shah, Mubarak},
title = {Detecting and Segmenting Humans in Crowded Scenes},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291310},
doi = {10.1145/1291233.1291310},
abstract = {We describe an approach for detecting and segmenting humans with extensive posture articulations in crowded video sequences. In our method we learn a set of mean posture clusters, and a codebook of local shape distributions for humans in various postures. Detection proceeds in two stages: first instances of the codebook entries cast votes for locations of humans in the video and their respective postures. Subsequently, consistent hypotheses are found as maxima within a voting space. The segmentation of humans in the scene is initialized by the corresponding posture clusters and contours are evolved to obtain precise and consistent segmentations.Our experimental results indicate that the framework provides a simple yet effective means for aggregating local and global shape-based cues. The proposed method is capable of detecting and segmenting humans in crowded scenes as they perform a diverse set of activities and undergo a wide range of articulations within different contexts.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {353–356},
numpages = {4},
keywords = {human detection, segmentation, object recognition},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291311,
author = {Scovanner, Paul and Ali, Saad and Shah, Mubarak},
title = {A 3-Dimensional Sift Descriptor and Its Application to Action Recognition},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291311},
doi = {10.1145/1291233.1291311},
abstract = {In this paper we introduce a 3-dimensional (3D) SIFT descriptor for video or 3D imagery such as MRI data. We also show how this new descriptor is able to better represent the 3D nature of video data in the application of action recognition. This paper will show how 3D SIFT is able to outperform previously used description methods in an elegant and efficient manner. We use a bag of words approach to represent videos, and present a method to discover relationships between spatio-temporal words in order to better describe the video data.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {357–360},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258974,
author = {Rist, Thomas},
title = {Session Details: Live Arts Exhibition},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258974},
doi = {10.1145/3258974},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291313,
author = {Katsumoto, Yuichiro and Inakage, Masa},
title = {Amagatana},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291313},
doi = {10.1145/1291233.1291313},
abstract = {In this paper, we propose Amagatana (the name means "rainy sword" in Japanese), which is a mystical sword for enjoying the blithe feeling after the rain. Amagatana seems to be just a plastic umbrella. However, it makes a sound of swords clashing in response to the player's swing. Amagatana also gives us the consciousness "What is your reality is not everybody's reality".},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {361–362},
numpages = {2},
keywords = {sword, umbrella, sound, interaction},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291314,
author = {Lasserre, Gregory and met den Ancxt, Anais},
title = {SpherAleas: Tridimensional Interactive / Sound / Image Installation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291314},
doi = {10.1145/1291233.1291314},
abstract = {In this paper we describe the art installation SpherAleas.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {363–364},
numpages = {2},
keywords = {audiovisual, sound and image installation, interaction, experience, multimedia art},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291315,
author = {Hsu, Su-Chu and Lin, Jin-Yao and Chen, Carven and Chen, Ying-Chung and Lin, Jiun-Shian and Chang, Keng-Hau},
title = {One Million Heartbeats},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291315},
doi = {10.1145/1291233.1291315},
abstract = {We explore possibilities for applying wireless sensor networks (WSN) in interactive art. One Million Heartbeats, our interactive artwork, uses a ZigBee wireless sensor network, bio-feedback sensors, video projection, sculpture, and a weblog. It depicts the struggle between twin fetuses in the "world" of a mother's womb, and many people interpret it as commentary on political or social events. We will collect one million "heartbeats" from participants - the behaviors of our participants determine the characteristics of the fetuses and the experience of the mother. Participant comments become part of the piece. This artwork explores collective social behavior. We believe that this piece shows a new medium for interactive art: ubiquitous wireless sensor networks.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {365–366},
numpages = {2},
keywords = {interactive art, social behavior, zigbee, wireless sensor network},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291316,
author = {Tomida, Tomohisa and Ueki, Atsuro and Inakage, Masa},
title = {MiXer: The Communication Entertainment Content by Using "Entrainment Phenomenon" and "Bio-Feedback"},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291316},
doi = {10.1145/1291233.1291316},
abstract = {We suggest a new communication entertainment content to create a nonverbal connecting in communication by using human physical information. The "miXer" we produce is a content of attraction type for two people by applying medical discovery such "bio-feedback" and "entrainment phenomenon". In the "miXer" it senses a physical information and feed back them in the information like visualization, sound, and vibration we can recognize, so you can enjoy an unprecedented communication in this fantastic space.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {367–368},
numpages = {2},
keywords = {communication, physical information, bio-feedback},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291317,
author = {Oreggia, Eleonora Maria Irene and Galliani, Silvano},
title = {The Ball in the Hole},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291317},
doi = {10.1145/1291233.1291317},
abstract = {"The Ball in The Hole" is an interactive video installation, running on GPL homemade software, which uses the principle of tele-presence.Two rooms are showing a projected mirror, where the user can see and recognize himself. On the floor there is a spiral, containing a luminescent ball. When the user grabs the ball, spontaneously attempting to play with it, the projected mirror will start erasing, showing the other room. The ball, as an interface, will act on the video as an eraser on a pencil drawing. The two rooms / spaces are symmetrical.After the complete erasure of the image, the mirror will show the remote room only. At this point the game flips: the ball, rubber and pencil at the same time, gets the capability to erase the other person / space / video. Therefore this deletion of the Otherness corresponds to the redrawing of the Self. You draw as much as you erase, in a direct proportion.The process continues endlessly rendering the installation a social happening where the user becomes the main character of an improvised performance.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {369–370},
numpages = {2},
keywords = {technology, multimedia arts, interaction, culture},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291318,
author = {Endo, Takumi},
title = {TypeTrace},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291318},
doi = {10.1145/1291233.1291318},
abstract = {TypeTrace is an interactive application that records all the keyboard strokes you make, similar to Spyware. The application plays back the writing along a timeline just like a movie.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {371–372},
numpages = {2},
keywords = {typing, media art, installation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291319,
author = {Haaslahti, Hanna and Heikkil\"{a}, Seppo},
title = {Space of Two Categories, Interactive Installation with Shadow Projection},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291319},
doi = {10.1145/1291233.1291319},
abstract = {Space of two categories connects wievers emotionally with their own childhood. Each person entering the installation space creates a human-shaped view to the world of a little girl with their own shadows. The shadows act as gateways to another temporal state, which is illuminated inside shadows, normally dark and void. The installation deals with the relationship of childhood and adulthood as different states of human body; how our childhood exists inside our aging and transforming body and how those memories are stored into our bodies.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {373–374},
numpages = {2},
keywords = {augmented space, interaction, phenomenology},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291320,
author = {Levy, Vincent},
title = {GHOST(s)},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291320},
doi = {10.1145/1291233.1291320},
abstract = {"Ghost(s)" is a poetic video-computer installation. It is like a mirror, but some one which would wait before displaying your image. If you stand easy, maybe you could see some ghost(s) inhabited in it: local ghosts from the place, or ghosts from my personal universe.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {375–376},
numpages = {2},
keywords = {interactive, installation, digital art, behaviour},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291321,
author = {Wright, Alexa and Linney, Alf and Evans, Alun and Lincoln, Mike},
title = {Conversation Piece: A Speech-Based Interactive Art Installation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291321},
doi = {10.1145/1291233.1291321},
abstract = {In this paper we present Conversation Piece, an interactive audio installation that can hold conversations with up to three people at any one time. Conceived as an artwork that explores the boundaries between virtual and 'real world' experience, Conversation Piece incorporates a number of speech technologies. This paper describes the installation and gives an account of the technologies employed in its realization.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {377–378},
numpages = {2},
keywords = {interactive arts, human-machine interaction, speech technology, spoken dialogue systems},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291322,
author = {Woolford, Kirk A.},
title = {Will.0.W1sp},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291322},
doi = {10.1145/1291233.1291322},
abstract = {Will.0.W1sp is an interactive installation exploring our ability to recognise human motion without human form. It uses particle systems to create characters or "whisps" with their own drifting, flowing movement, but which also follow digitised human movements. The central point of the environment is a 2x6m curved screen allowing the whisps to be projected at human scale while giving them enough to space to move and avoid visitors through the use of a combination of video tracking and motion sensors. The installation systems perform realtime motion analysis both on the prerecorded motion capture sequences and the movement of the audience to determine how to route the particles across the scene. The motion vectors are simultaneously fed to an audio system to create sound flowing in synch with the imagery. Will.0.w1sp invites visitors to chase after virtual, intangible characters which continually scatter and reform just beyond their reach.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {379–380},
numpages = {2},
keywords = {granular synthesis, particle flow, interaction, particle system, motion capture},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258975,
author = {Amir, Arnon},
title = {Session Details: Keynote Presentations},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258975},
doi = {10.1145/3258975},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291324,
author = {Fageth, Reiner},
title = {Applied Image Science: From Consumers' Digital Files to Tangible Products},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291324},
doi = {10.1145/1291233.1291324},
abstract = {The market for picture capturing devices is booming and as a result, household penetration is increasing rapidly. In the traditional analogue market, prints from processed film were the only, albeit a very convenient, way of sharing and archiving memories in albums or in the famous shoebox. Nowadays innovative developments have given rise to new ways to view, share and archive images.Image taking habits are also changing. People are afraid of not "capturing the moment" and nowadays pressing the shutter is not directly linked to costs as was the case with silver halide photography. This behaviour seems to be convenient but can result in a dilemma for the consumer. This paper presents tools designed to help the consumer overcome the time-consuming image selection process while turning the chore of selecting the images for prints or of placing them automatically into a photo book into a fun experience.The digital files processed by these tool originate from various sources. These files are transferred into a production process either in a modified or in their original state. The device origin might be a high resolution SLR camera or a low resolution mobile phone camera. The customer expects all of these images, regardless of source, to be printed in the perfect quality he is accustomed to from analog film processing. Customers often expect an even higher standard of quality due to the elevated retail price of DSCs. Digital photo services also offer the customer the option of a simple order process, enabling them to order various image formats which cannot be printed on a single machine. Therefore color management and the enhancement tools used on different types of machines play a very important role, especially with regard to online photo services which also offer products which do not necessarily have to be printed on light-sensitive photo paper, e.g. calendars, greeting cards, etc. These products are printed using different technologies e.g. digital printers such as the hp Indigo or Xerox machines. The customer expects to receive both prints and personalized photo creations in exactly the same quality.This paper will also describe how non-virtual products from pictures taken by digital devices can be implemented in the wholesale industry, regardless of image resolution and source, in order to fulfill the consumers' requirements (delivery time and quality). The goal when selling these products is convenience and quality of the whole industrially finished product.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {381},
numpages = {1},
keywords = {image science, digital photography, color management, wholesale photo finishing},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291325,
author = {Manske, Knut and Leidig, Torsten and Heuser, Lutz},
title = {The Workplace of the Future},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291325},
doi = {10.1145/1291233.1291325},
abstract = {The workplace of the future will support the user to cope with a flexible change of multiple processes and tasks. The actual work context is observed by the system and this will be utilized to support the user with relevant information as well as recommendations to proceed in his work. Interaction channels and presentation means are chosen adaptively; needed knowledge and information is provided pro-actively and in direct context of the work performed. The user will have tightly integrated direct access to different services by mesh up techniques. He will collaborate via informal social networks provided by various Web 2.0 services (e.g., forums, weblogs, wikis, and Xing). Domain experts will be identified automatically through an expert finder which is driven by social mining and advanced machine learning technologies. The user will be able to change the system by the use of end-user development facilities to adapt his working environment to his actual needs and specific environments. These methodologies and technologies have been investigated in a varying depth in the research community. However, only a proper combination will lead to the desired user experience. Knowing about the (business) processes the user is involved in supports this and will form the workplace of the future significantly. Business processes are not necessarily IT-based or IT-supported.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {382},
numpages = {1},
keywords = {workplace, context awareness, service oriented architecture, knowledge transfer, model-based development, end-user development, expert finder},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258976,
author = {Sundaram, Hari},
title = {Session Details: Content 3 - Multimedia Model Learning},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258976},
doi = {10.1145/3258976},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291327,
author = {Shibata, Tomohide and Kato, Norio and Kurohashi, Sadao},
title = {Automatic Object Model Acquisition and Object Recognition by Integrating Linguistic and Visual Information},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291327},
doi = {10.1145/1291233.1291327},
abstract = {In order to make the best use of multimedia contents effectively, the crucial point is the structural analysis of the contents, in which several media processing techniques, including image, audio and text analyses, should be integrated. To understand utterances in videos in accordance with the scene, it is essential to recognize what object appears in the videos. In this paper, we focus on Japanese cooking TV videos, and propose a method for acquiring object models of foods in an unsupervised manner and performing object recognition based on the acquired object models. First, a topic of each video segment is identified based on HMMs to obtain good examples for the object model acquisition. After that, close-up images are extracted from image sequences, and an attention region on the close-up image is determined. Then, an important word is extracted as a keyword from utterances around the close-up image, and is made correspond to the close-up image. By collecting a set of close-up image and keyword from a large amount of videos, object models are acquired. After acquiring the object models, object recognition is performed based on the acquired object models and linguistic information. We conducted experiments on two kinds of cooking TV programs. We acquired the object models of around 100 foods with an accuracy 77.8%. The F measure of object recognition was 0.727.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {383–392},
numpages = {10},
keywords = {object model acquisition, video indexing, object recognition},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291328,
author = {Datta, Ritendra and Joshi, Dhiraj and Li, Jia and Wang, James Z.},
title = {Tagging over Time: Real-World Image Annotation by Lightweight Meta-Learning},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291328},
doi = {10.1145/1291233.1291328},
abstract = {Automatic image annotation has been a hot-pursuit among multimedia researchers of late. Modest performance guarantees and limited adaptability often restrict its applicability to real-world settings. We propose tagging over time (T/T) to push the technology toward real-world applicability. Of particular interest are online systems that receive user-provided images and feedback over time, with user focus possibly changing and evolving. The T/T framework consists of a principled probabilistic approach to meta-learning, which acts as a go-between for a 'black-box' annotation system and the users. Inspired by inductive transfer, the approach attempts to harness available information, including the black-box model's performance, the image representations, and the WordNet ontology. Being computationally 'lightweight', this meta-learner efficiently re-trains over time, to improve and/or adapt to changes. The black-box annotation model is not required to be re-trained, allowing computationally intensive algorithms to be used. We experiment with standard image datasets and real-world data streams, using two existing annotation systems as black-boxes. Both batch and online annotation settings are experimented with. It is observed that the addition of this meta-learning layer produces much improved results that outperform best-known results. For the online setting, the T/T approach produces progressively better annotation with time, significantly outperforming the black-box as well as the static form of the meta-learner, on real-world data.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {393–402},
numpages = {10},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291329,
author = {Cai, Deng and He, Xiaofei and Han, Jiawei},
title = {Spectral Regression: A Unified Subspace Learning Framework for Content-Based Image Retrieval},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291329},
doi = {10.1145/1291233.1291329},
abstract = {Relevance feedback is a well established and effective framework for narrowing down the gap between low-level visual features and high-level semantic concepts in content-based image retrieval. In most of traditional implementations of relevance feedback, a distance metric or a classifier is usually learned from user's provided negative and positive examples. However, due to the limitation of the user's feedbacks and the high dimensionality of the feature space, one is often confront with the issue of the curse of the dimensionality. Recently, several researchers have considered manifold ways to address this issue, such as Locality Preserving Projections, Augmented Relation Embedding, and Semantic Subspace Projection. In this paper, by using techniques from spectral graph embedding and regression, we propose a unified framework, called spectral regression, for learning an image subspace. This framework facilitates the analysis of the differences and connections between the algorithms mentioned above. And more crucially, it provides much faster computation and therefore makes the retrieval system capable of responding to the user's query more efficiently.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {403–412},
numpages = {10},
keywords = {spectral regression, subspace learning, dimensionality reduction, manifold learning, relevance feedback, image retrieval},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258977,
author = {Karahalios, Karrie},
title = {Session Details: Applications 3 - You're Being Watched},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258977},
doi = {10.1145/3258977},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291331,
author = {Greenhill, Stewart and Venkatesh, Svetha},
title = {Distributed Query Processing for Mobile Surveillance},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291331},
doi = {10.1145/1291233.1291331},
abstract = {Addressing core issues in mobile surveillance, we present an architecture for querying and retrieving distributed, semi-permanent multi-modal data through challenged networks with limited connectivity. The system provides a rich set of queries for spatio-temporal querying in a surveillance context, and uses the network availability to provide best quality of service. It incrementally and adaptively refines the query, using data already retrieved that exists on static platforms and on-demand data that it requests from mobile platforms. We demonstrate the system using a real surveillance system on a mobile 20 bus transport network coupled with static bus depot infrastructure. In addition, we show the robustness of the system in handling different conditions in the underlying infrastructure by running simulations on a real, but historic dataset collected in an offline manner.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {413–422},
numpages = {10},
keywords = {video indexing, virtual observer, mobile surveillance, visibility query, distributed query processing, spatial query},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291332,
author = {Girgensohn, Andreas and Kimber, Don and Vaughan, Jim and Yang, Tao and Shipman, Frank and Turner, Thea and Rieffel, Eleanor and Wilcox, Lynn and Chen, Francine and Dunnigan, Tony},
title = {DOTS: Support for Effective Video Surveillance},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291332},
doi = {10.1145/1291233.1291332},
abstract = {DOTS (Dynamic Object Tracking System) is an indoor, real-time, multi-camera surveillance system, deployed in a real office setting. DOTS combines video analysis and user interface components to enable security personnel to effectively monitor views of interest and to perform tasks such as tracking a person. The video analysis component performs feature-level foreground segmentation with reliable results even under complex conditions. It incorporates an efficient greedy-search approach for tracking multiple people through occlusion and combines results from individual cameras into multi-camera trajectories. The user interface draws the users. attention to important events that are indexed for easy reference at a later time. Different views within the user interface provide spatial information for easier navigation. Our system, with over twenty video cameras installed in hallways and other public spaces in our office building, has been in constant use for almost a year.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {423–432},
numpages = {10},
keywords = {video surveillance, multiple video streams, security cameras, person tracking},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291333,
author = {Zheng, Jiang Yu and Sinha, Shivank},
title = {Line Cameras for Monitoring and Surveillance Sensor Networks},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291333},
doi = {10.1145/1291233.1291333},
abstract = {A linear CCD sensor reads temporal data from a CCD array continuously and forms a 2D image profile. Compared to most of the sensors in the current sensor networks that output temporal signals, it delivers more information such as color, shape, and event of a flowing scene. On the other hand, it abstracts passing objects in the profile without heavy computation and transmits much less data than a video. This paper revisits the capabilities of the sensors in data processing, compression, and streaming in the framework of wireless sensor network. We focus on several unsolved issues such as sensor setting, shape analysis, robust object extraction, and real time background adapting to ensure long-term sensing and visual data collection via networks. All the developed algorithms are executed in constant complexity for reducing the sensor and network burden. A sustainable visual sensor network can thus be established in a large area to monitor passing objects and people for surveillance, traffic assessment, invasion alarming, etc.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {433–442},
numpages = {10},
keywords = {target counting, transmission, image projection, surveillance, sensor networks, background adapting, line sensor},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258978,
author = {Nack, Frank},
title = {Session Details: Arts Session 1 - Pieces in Art},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258978},
doi = {10.1145/3258978},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291335,
author = {Leslie, Liza and Chua, Tat-Seng and Ramesh, Jain},
title = {Annotation of Paintings with High-Level Semantic Concepts Using Transductive Inference and Ontology-Based Concept Disambiguation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291335},
doi = {10.1145/1291233.1291335},
abstract = {Domain-specific knowledge of paintings defines a wide range of concepts for annotation and flexible retrieval of paintings. In this work, we employ the ontology of artistic concepts that includes visual (or atomic) concepts at the intermediate level and high-level concepts at the application level. Visual-level color and brushwork concepts are widely used by art historians to analyze paintings and serve as cues for annotating high-level concepts such as the artist names, painting styles and art periods for paintings. In this research we combine the color and brushwork concepts with low-level features and utilize the transductive inference framework to annotate high-level concepts to the image blocks. In order to resolve conflicting assignments of high-level concepts, we further employ the ontology-based concept disambiguation method and generate image-level annotations. This method performs global optimization of the block-level annotations using the linear constraints extracted from domain knowledge. Our experiments on annotating high-level concepts demonstrate that: a) the use of visual-level concepts significantly improves the accuracy as compared to using low-level features only; and b) the proposed transductive inference framework out-performs the conventional baseline methods and c) the proposed ontology-based disambiguation method generates superior results for several annotation scenarios.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {443–452},
numpages = {10},
keywords = {paintings, concepts ontology, transductive inference, multi-expert, ontology-based disambiguation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258979,
author = {Naphade, Milind},
title = {Session Details: Demo Session 2},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258979},
doi = {10.1145/3258979},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291337,
author = {Xue, Chengkun and Li, Liqun and Yang, Feng and Wang, Patricia P. and Wang, Tao and Zhang, Yimin and Sun, Yankui},
title = {Automated Home Video Editing: A Multi-Core Solution},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291337},
doi = {10.1145/1291233.1291337},
abstract = {In the field of automated home video editing, exploring the dependence relations between who (character) and where (scene) makes great sense to end-users for content selection. However, such techniques have not been well developed in real applications due to their computational intensity. The emerging multi-core architectures provide an opportunity to speed up those compute expensive algorithms if shift from serial thinking to parallelism. This demonstration presents a scalable parallel system for home video editing. In a realtime processing speed, the system analyzes how many characters and scenes are captured and provides end-users with flexible preference customization. Through kernel module optimization and data-level parallelization, evaluations on a real 8-core machine indicates a near linear speed up could be achieved along with the increasing number of cores.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {453–454},
numpages = {2},
keywords = {multi-core, workload analysis, character-scene association, home video editing},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291338,
author = {Sengamedu, Srinivasan H. and Sawant, Neela and Wadhwa, Smita},
title = {VADeo: Video Advertising System},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291338},
doi = {10.1145/1291233.1291338},
abstract = {vADeo is a next-generation video ad system that analyzes the video to find appropriate scene changes where ads can be inserted. The context of each ad insertion point is determined through high-level analysis of the surrounding video segment thereby making ads contextual. Further vADeo implements two novelties on the player side - ad book-marking and delayed interaction - which encourage ad clicks without disrupting the video viewing experience.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {455–456},
numpages = {2},
keywords = {delayed interactivity, in-stream ad insertion, bookmarking, contextual ads},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291339,
author = {Xu, Weiwei and Sundaram, Hari},
title = {Information Dense Summaries for Review of Patient Performance in Biofeedback Rehabilitation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291339},
doi = {10.1145/1291233.1291339},
abstract = {In this paper, we present a novel visual design for information dense summaries of patient data with applications in biofeedback rehabilitation. The problem is important in review of large medical datasets where the clinicians require that both summary and all the performance details be shown at the same time. There are two main ideas (a) Summarizing data along the conceptual facets (accuracy / flow / openness) and the temporal facets (session / set / trial) in the biofeedback therapy. The conceptual facets represent key information needed by the experts to review patient performance. (b) Effectively present the data trends and the details in context of the entire performance. The summary incorporates ideas from graphic design and reveals the performance data at two time scales.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {457–458},
numpages = {2},
keywords = {multimedia, summarization, stroke rehabilitation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291340,
author = {Yuan, Yu and Yan, Rong and Li, Huoding and Liu, Xing and Xu, Sheng},
title = {High Definition H.264 Decoding on Cell Broadband Engine},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291340},
doi = {10.1145/1291233.1291340},
abstract = {This demo showcases high definition H.264 decoding capability of Cell Broadband Engine processor.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {459–460},
numpages = {2},
keywords = {H.264, multi-core, decoding, cell},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291341,
author = {Liu, Xueliang and Mei, Tao and Hua, Xian-Sheng and Yang, Bo and Zhou, He-Qin},
title = {Video Collage},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291341},
doi = {10.1145/1291233.1291341},
abstract = {In this work, we present Video Collage system, which automatically constructs a compact and visually appealing synthesized collage from a video sequence for efficient video browsing. Given a video, Video Collage is able to select the most representative images, extract salient regions of interest (ROI) from these images and resize ROI according to their saliencies, and seamlessly arrange them on a given canvas while preserving the temporal structure of video content. Furthermore, Video Collage provides a novel user interface that enables users to browse video content in a variety of more efficient ways in contrast to many existing approaches to video browsing.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {461–462},
numpages = {2},
keywords = {video collage, video content analysis, video presentation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291342,
author = {Mei, Tao and Yang, Linjun and Hua, Xian-Sheng and Wei, Hao and Li, Shipeng},
title = {VideoSense: A Contextual Video Advertising System},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291342},
doi = {10.1145/1291233.1291342},
abstract = {This demonstration presents a novel contextual advertising platform for online video service, called VideoSense. Unlike most current video-oriented sites that only display a video ad at the beginning or the end of a video, VideoSense aims to embed more contextually relevant ads at less intrusive positions within the video stream. Given an online video, VideoSense is able to detect a set of candidate ad insertion points based on content analysis, select a list of relevant candidate ads ranked according to textual relevance, and find the best match between insertion points and ads which maximizes the overall multimodal relevance. The effectiveness of VideoSense supporting contextually relevant and less intrusive advertising is validated by the user studies conducted on a variety of online video documents.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {463–464},
numpages = {2},
keywords = {ad insertion point detection, online video advertising},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291343,
author = {Liu, Jingjing and Huang, Yalou and Li, Dong and Wu, Fanghao and Li, Bin},
title = {DJ DreamFactory},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291343},
doi = {10.1145/1291233.1291343},
abstract = {DJ DreamFactory is a web-based integrated platform for interactive broadcasting over the Internet. In DJ DreamFactory, users are able to set up Internet-based broadcasting stations with minimal effort. Audience not only can receive broadcasting programs from multiple stations through this unified platform, but can also "talk" and "write" to the broadcasters as well as to other audience via real-time text and/or audio interactions.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {465–466},
numpages = {2},
keywords = {system design, network broadcasting, demonstration, interactive broadcasting},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291344,
author = {Li, Xirong and Wang, Xin-Jing and Wang, Changhu and Zhang, Lei},
title = {SBIA: Search-Based Image Annotation by Leveraging Web-Scale Images},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291344},
doi = {10.1145/1291233.1291344},
abstract = {In this technical demonstration, we showcase the SBIA system - a search-based image annotation system. At the heart of the system lies a very large-scale image search engine which indexed three million Web images and supports both text and visual queries. Given an image (with initial annotations), SBIA first finds semantically/visually similar images via the search engine, and then mines representative keywords from the retrieved images. These keywords, after annotation rejection and relevance ranking, are finally used to annotate the query image.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {467–468},
numpages = {2},
keywords = {rejection, image annotation, search, clustering},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291345,
author = {Han, Byeong-jun and Hwang, Eenjun and Rho, Seungmin and Kim, Minkoo},
title = {M-MUSICS: Mobile Content-Based Music Retrieval System},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291345},
doi = {10.1145/1291233.1291345},
abstract = {Accurate voice humming transcription and efficient indexing schemes are essential for a large-scale humming-based music retrieval system. Although many researches have been done to develop such schemes, their performances are not still satisfactory. In our previous works, we proposed (i) a new voice query transcription scheme [4], (ii) a popularity-adaptive indexing structure called FAI [6] for fast retrieval, and (iii) a semi-supervised relevance feedback and query reformulation scheme based on a genetic algorithm [7] in order to improve retrieval efficiency. In this demonstration, we extend our efforts to a mobile environment and develop a prototype mobile music retrieval system called M-MUSICS. Our focus in this implementation includes versatile user interface for easy querying and browsing on a typical mobile device such as PDA phone and satisfactory performance in a wireless mobile environment. We report some of the results.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {469–470},
numpages = {2},
keywords = {relevance feedback, content-based music retrieval, mobile platform, query by humming},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291346,
author = {Dadason, Kristleifur and Lejsek, Herwig and \'{A}smundsson, Fridrik and J\'{o}nsson, Bj\"{o}rn and Amsaleg, Laurent},
title = {Videntifier: Identifying Pirated Videos in Real-Time},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291346},
doi = {10.1145/1291233.1291346},
abstract = {With the proliferation of high-speed internet access and the availability of cheap secondary storage, movie piracy has become a major problem. This demonstration paper describes the Eff2 Videntifier, a content-based system for large-scale automatic copyright enforcement of videos. The paper briefly describes the database and image processing techniques underlying the system. It also describes our proposed demonstration, which realistically simulate scenarios of copyright violations of movies.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {471–472},
numpages = {2},
keywords = {copyright protection, video retrieval, nv-tree},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291347,
author = {Fleischman, Michael and Evans, Humberto and Roy, Deb},
title = {Unsupervised Content-Based Indexing for Sports Video Retrieval},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291347},
doi = {10.1145/1291233.1291347},
abstract = {This demonstration presents an interface to a corpus of broadcast baseball games that have been indexed using an unsupervised content-based method introduced here. The method uses the concept of a grounded language model to motivate a framework in which video is searched using natural language with no reliance on predetermined concepts or hand labeled events. The interface demonstrates the effectiveness of the technique and the ease of use it affords the user.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {473–474},
numpages = {2},
keywords = {grounded language models, sports video, video retrieval},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291348,
author = {H\"{o}lbling, G\"{u}nther and Rabl, Tilmann and Kosch, Harald},
title = {Intertainment},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291348},
doi = {10.1145/1291233.1291348},
abstract = {Traditional TV provides only a very passive experience. Recent trends suggest that users would be interested in taking a more active role while watching TV. This demo paper presents the interactive television (iTV) platform, which offers a solution in giving the TV-audience a chance of active participation. The iTV platform enriches TV with additional content and interactivity, making it more attractive for the audience. In order to support multi-user and personalized access to the iTV services mobile devices are used. To provide an easy way to offer and use services an ad-hoc service architecture - the Universal Plug and Play (UPnP) architecture - has been used.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {475–476},
numpages = {2},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258980,
author = {Nack, Frank},
title = {Session Details: Short Papers Poster Session 2 - Arts, Content, Applications},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258980},
doi = {10.1145/3258980},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291350,
author = {Jacquemin, Christian and Planes, Bertrand and Ajaj, Rami},
title = {Shadow Casting for Soft and Engaging Immersion in Augmented Virtuality Artworks},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291350},
doi = {10.1145/1291233.1291350},
abstract = {Two immersive art installations that involve virtual shadows for better engagement of the viewers are presented. One installation is a stereo film enhanced with a 3D reconstructed mesh for shadow projection, and the other one is a virtual 3D model with texture compositing and transparency. The hardware and software components are chosen for an economical but efficient rendering with standard computer and video equipments.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {477–480},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291351,
author = {Giles, Thierry and Marienek, Michael and Willis, Katharine S. and Geelhaar, Jens},
title = {Hide&amp;SEEK: Sharing Cultural Knowledge},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291351},
doi = {10.1145/1291233.1291351},
abstract = {In this paper, we describe the project; Hide&amp;SEEK, which creates opportunities for cultural knowledge transfer through a street game experience. The game narrative is based on the concept of sharing place-based knowledge where participants assume the role of either Guest or Host of the story. The Host creates a personalized adventure route through a known space and publishes it to a specific person. The Guest then has the opportunity to explore an unknown place through an unraveling of a series of clues, which lead them through a particular spatial experience. The treasure at the end of the game is not a material reward but rather the construction of a shared social experience; the exploration and revealing of a place known to the Host and initially unknown to the Guest developing as a valuable artifact in the memory of both game participants.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {481–484},
numpages = {4},
keywords = {street game, narrative, experiential mapping, landmarking, social networking},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291352,
author = {Levisohn, Aaron M.},
title = {The Body as a Medium: Reassessing the Role of Kinesthetic Awareness in Interactive Applications},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291352},
doi = {10.1145/1291233.1291352},
abstract = {The popularity of Nintendo's Wii is indicative of a fundamental change in the relationship between humans and computers. After decades of subservience to the keyboard and mouse, there is now a reawakening of our kinesthetic and proprioceptive senses. In this paper I am suggesting that the body be understood not merely as the controller of multimedia systems, but as a component within these systems and as a unique medium unto itself. I will demonstrate an application of this idea by describing a mixed reality system that was constructed to assist with the exploration of proprioceptive and kinesthetic awareness. The paper also includes a review of the informal experiments that I conducted using this system to explore possible kinesthetic and proprioceptive illusions.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {485–488},
numpages = {4},
keywords = {tangible interface, kinesthetic awareness, proprioceptive illusion, bodily awareness},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291353,
author = {D'Souza, Daryl and Ciesielski, Vic and Berry, Marsha and Trist, Karen},
title = {Generation of Self-Referential Animated Photomosaics},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291353},
doi = {10.1145/1291233.1291353},
abstract = {We describe the implementation of an art installation that generates animated photomosaics of the viewer. Photomosaics are target images composed of smaller images known as tiles. When a photomosaic is viewed from afar the detail of the tiles is lost and the target image is evident. Up close, the opposite occurs: the detail of the tiles is evident and the target image is lost. Our system uses a photo of the viewer as the target and miniatures of the viewer's face as tiles. Evolutionary search is used to find the best selection and arrangement of tiles. Each newly found best image is then used as the frame of a movie. The resulting animations start from a random arrangement of tiles and gradually the viewer's face emerges and is clearly visible, and then gradually de-materialises into a random pattern.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {489–492},
numpages = {4},
keywords = {evolutionary search, genetic algorithm},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291354,
author = {Bruy\`{e}re, Hugues and Giles, Thierry},
title = {Performative Surface: Double Sided Interaction},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291354},
doi = {10.1145/1291233.1291354},
abstract = {This paper introduces a framework which we label "performative surface" focusing on the performative relations that occur between co-located individuals mediated by an interface. The goal of this interface is to emphasize the intensity of interaction by way of a two side responsive surface. The paper describes both the conceptual and technological parts of this framework, compares it to existing applications, and presents examples from two produced installation prototypes.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {493–496},
numpages = {4},
keywords = {HCI, performative surface, co-presence, interactivity, haptic interface, augmented reality, computer vision},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291355,
author = {Rankovic, Milos},
title = {Aesthetic Selection of Naked Genes},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291355},
doi = {10.1145/1291233.1291355},
abstract = {The problem of genetic representation in (creative) evolutionary systems that aspire to taking part in cultural production is reformulated in the more general terms of the necessary structuring of the search space. Cumulative (aesthetic) selection of "naked genes" is discussed as an alternative approach whereby no germ-line/somatic-line distinction is explicitly implemented. The feasibility of this approach is illustrated on a computer application ASNakedGene, which therefore allows evolutionary runs to be seeded by arbitrary sets of digital (or digitised) images and generates variation through direct operation on the arrays of pixel values (as opposed to "genetic" representations of them).},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {497–500},
numpages = {4},
keywords = {genetic representation, creativity, naked gene, aesthetic selection},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291356,
author = {Prasad, Archana and Blagsvedt, Sean Olin and Toyama, Kentaro},
title = {SMSBlogging: Blog-on-the-Street Public Art Project},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291356},
doi = {10.1145/1291233.1291356},
abstract = {In this paper we describe the experimental set-up and execution of a public art project. The aim was to explore the use of SMSBlogging for the purpose of community building and creative self-expression. We also discuss the results from this experiment and show our findings from six blog-on-the-street art acts in Bangalore, India, that introduce SMSBlogging technology in an iterative design process.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {501–504},
numpages = {4},
keywords = {public forums, performance art, art, creative self-expression, SMS, public art, blogging, communities},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291357,
author = {Janzen, Ryan E. and Mann, Steve},
title = {Arrays of Water Jets as User Interfaces: Detection and Estimation of Flow by Listening to Turbulence Signatures Using Hydrophones},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291357},
doi = {10.1145/1291233.1291357},
abstract = {The hydraulophone is a fun-to-play self-cleaning keyboard instrument in which each key is a water jet. Many hydraulophones are already equipped with an array of underwater microphones (hydrophones), to pick up the turbulent sound from water inside musical sounding mechanisms under each water jet. Accordingly, we propose to make greater use of the sound of the water flow.We propose to extract more detailed information about flow and the obstruction of flow, based on sound alone. Beyond musical instruments, if further developed, this framework could have extensive applications in flow sensing for fuel lines in vehicles and for fresh water lines in buildings.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {505–508},
numpages = {4},
keywords = {hydraulophones, water jet, fluid user-interfaces, poiseuille},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291358,
author = {Morrison, Ann J. and Mitchell, Peta and Brereton, Margot},
title = {The Lens of Ludic Engagement: Evaluating Participation in Interactive Art Installations},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291358},
doi = {10.1145/1291233.1291358},
abstract = {Designers and artists have integrated recent advances in interactive, tangible and ubiquitous computing technologies to create new forms of interactive environments in the domains of work, recreation, culture and leisure. Many designs of technology systems begin with the workplace in mind, and with function, ease of use, and efficiency high on the list of priorities. [1] These priorities do not fit well with works designed for an interactive art environment, where the aims are many, and where the focus on utility and functionality is to support a playful, ambiguous or even experimental experience for the participants. To evaluate such works requires an integration of art-criticism techniques with more recent Human Computer Interaction (HCI) methods, and an understanding of the different nature of engagement in these environments. This paper begins a process of mapping a set of priorities for amplifying engagement in interactive art installations. I first define the concept of ludic engagement and its usefulness as a lens for both design and evaluation in these settings. I then detail two fieldwork evaluations I conducted within two exhibitions of interactive artworks, and discuss their outcomes and the future directions of this research.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {509–512},
numpages = {4},
keywords = {installations, ludic engagement, HCI, interactive artwork, interaction design, artist perspective, evaluation, feedback},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291359,
author = {Meyer, Marek and Hannappel, Alexander and Rensing, Christoph and Steinmetz, Ralf},
title = {Automatic Classification of Didactic Functions of E-Learning Resources},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291359},
doi = {10.1145/1291233.1291359},
abstract = {Re-use of digital resources is an important issue in e-Learning scenarios, because only intensive re-use can make e-Learning cost efficient. Besides reusing whole courses, authors often desire to re-use fine grained parts of courses for creating new Learning Resources. The granularity which appears to be most promising for this kind of re-use is the level of information objects. Information objects each have a dedicated didactic function; a set of information objects with different didactic functions are combined into Learning Objects. This paper analyzes how didactic functions of existing information objects can be automatically classified using machine learning technology. The results of such classification methods on a set of Learning Resources from medical science are discussed.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {513–516},
numpages = {4},
keywords = {metadata, learning object, e-learning, didactic classification, information object},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291360,
author = {Ting, Huang and Chen, Shifeng and Liu, Jianzhuang and Tang, Xiaoou},
title = {Image Inpainting by Global Structure and Texture Propagation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291360},
doi = {10.1145/1291233.1291360},
abstract = {Image inpainting is a technique to repair damaged images or modify images in a non-detectable form. In this paper, a novel global algorithm for region filling is proposed for image inpainting. After removing objects from an image, our approach fills the regions using patches taken from the image. The filling process is formulated as an energy minimization problem by Markov random fields (MRFs) and the belief propagation (BP) is utilized to solve the problem. Our energy function includes structure and texture information obtained from the image. One challenge in using BP is that its computational complexity is the square of the number of label candidates. To reduce the large number of label candidates, we present a coarse-to-fine scheme where two BPs run with much smaller numbers of label candidates instead of one BP running with a large number of label candidates. Experimental results demonstrate the excellent performance of our algorithm over other related algorithms.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {517–520},
numpages = {4},
keywords = {inpainting, markov random fields, image completion, belief propagation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291361,
author = {Zhang, Bingjun and Zhu, Jia and Wang, Ye and Leow, Wee Kheng},
title = {Visual Analysis of Fingering for Pedagogical Violin Transcription},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291361},
doi = {10.1145/1291233.1291361},
abstract = {Automatic music transcription, in spite of decades of research, remains a challenging research problem. The traditional audio-only approach has yet to achieve a satisfactory performance for any computer-aided pedagogical system. Inspired by the high correlation between violin playing techniques (fingering, bowing) and the played acoustic notes, this paper presents a first attempt in visual analysis of violin fingering to compensate for the difficulties in audio-only music transcription. This is achieved by a robust multiple finger tracking algorithm and a string detection method that extract press, release, and fingertip position from the fingering video and automatically translate the fingering information into the played acoustic note, i.e., onset, offset, and pitches. Experimental results reveal high correctness in multiple finger tracking and string detection, thus paving the way for an improved audio-visual violin transcription system.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {521–524},
numpages = {4},
keywords = {multiple finger tracking, violin fingering chart, automatic note inference, music transcription},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291362,
author = {Hu, Yiqun and Rajan, Deepu and Chia, Liang-Tien},
title = {Scale Adaptive Visual Attention Detection by Subspace Analysis},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291362},
doi = {10.1145/1291233.1291362},
abstract = {We describe a method to extract visual attention regions in images by robust subspace analysis from simple feature like intensity endowed with scale adaptivity in order to represent textured areas in an image. The scale adaptive descriptor is mapped onto clusters in linear spaces. A new subspace estimation algorithm based on the Generalized Principal Component Analysis (GPCA) is proposed to estimate multiple linear subspaces. The visual attention of each region is calculated using a new region attention measure that considers feature contrast and spatial geometric properties. Compared with existing visual attention detection methods, the proposed method directly measures global visual attention at the region level as opposed to pixel level.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {525–528},
numpages = {4},
keywords = {scale-selection, GPCA, visual attention},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291363,
author = {Pham, Nam Trung and Huang, Weimin and Ong, S. H.},
title = {Tracking Multiple Speakers Using CPHD Filter},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291363},
doi = {10.1145/1291233.1291363},
abstract = {In this paper, we present an efficient method for tracking multiple speakers in a reverberant environment. The proposed method is based on the cardinalized probability hypothesis density (CPHD) filter. Because the CPHD filter can handle a large amount of clutter measurements, our method has a high reliability when tracking multiple speakers. Simulation experiments are presented to demonstrate the performance of the proposed method.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {529–532},
numpages = {4},
keywords = {speaker tracking, TDOA, random finite set, CPHD filter},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291364,
author = {Datta, Ritendra and Li, Jia and Wang, James Z.},
title = {Learning the Consensus on Visual Quality for Next-Generation Image Management},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291364},
doi = {10.1145/1291233.1291364},
abstract = {While personal and community-based image collections grow by the day, the demand for novel photo management capabilities grows with it. Recent research has shown that it is possible to learn the consensus on visual quality measures such as aesthetics with a moderate degree of success. Here, we seek to push this performance to more realistic levels and use it to (a) help select high-quality pictures from collections, and (b) eliminate low-quality ones, introducing appropriate performance metrics in each case. To achieve this, we propose a sequential arrangement of a weighted linear least squares regressor and a naive Bayes' classifier, applied to a set of visual features previously found useful for quality prediction. Experiments on real-world data for these tasks show promising performance, with significant improvements over a previously proposed SVM-based method.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {533–536},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291365,
author = {Zhang, Yuanhai and Huangfu, Wei and Li, Kaihui and Xu, Changqiao},
title = {A Refined Rate Allocation Scheme with Adaptive Playback Adjustment for Robust Hd Video Stream Transmission},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291365},
doi = {10.1145/1291233.1291365},
abstract = {In this paper, we present a practical end-to-end video transmission system with refined rate allocation at the server and adaptive playback adjustment at the client that enables High Definition (HD) video streaming via bandwidth-constraint IP network. A transmission rate is determined by a rate control algorithm which employs the Program Clock References (PCR) embedded in the video streams to regulate the transmission rate in a refined way and thus reduce the client buffer requirement. An over-boundary playback adjustment mechanism based on Proportional-Integra (PI) controller is performed at the receiver to maximize the visual quality of the displayed video according to the receiver buffer occupancy. We test our system with Standard Definition Television (SDTV) and High Definition Television (HDTV) traces, and find that our proposed algorithm can reduce overflow and underflow of sender and receiver buffer, and achieve better video quality and quality smoothness than traditional rate control algorithms.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {537–540},
numpages = {4},
keywords = {VBR video streaming, adaptive transmission rate, HD, PCR, proportional-integra controller},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291366,
author = {Liu, Jingjing and Huang, Yalou and Li, Dong and Wu, Fanghao and Li, Bin},
title = {A Web-Based Aggregated Platform for User-Contributed Interactive Media Broadcasting},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291366},
doi = {10.1145/1291233.1291366},
abstract = {In this paper, we present a web-based aggregated platform, DJ DreamFactory, which enables average users to effortlessly participate in and contribute to interactive media broadcasting over the Internet. The platform overcomes several shortcomings of existing Internet-based broadcasting systems, such as inconvenience in channel surfing and content browsing due to the scattering and isolating of broadcasting stations, difficulties in setting up a broadcasting station, lack of communications between broadcasters and audience, and little support for personalized experience. The proposed platform facilitates users' media access by seamlessly aggregating sporadic broadcasting stations run by individual hosts, and enables a virtual community where grassroots users can contribute to media broadcasting, sharing, organizing and annotating through social networking. In addition, it supports real-time multimodal interaction between audience and hosts, provides customized services for both broadcasters and audience, supports personalized media experiences by mining and managing audience's preferences, and facilitates the organization of unstructured media data collections as well as collective human intelligence on the Web.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {541–544},
numpages = {4},
keywords = {interactive broadcasting, internet broadcasting, system design},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291367,
author = {Shrstha, Prarthana and Barbieri, Mauro and Weda, Hans},
title = {Synchronization of Multi-Camera Video Recordings Based on Audio},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291367},
doi = {10.1145/1291233.1291367},
abstract = {An increasing number of people regularly capture video in social occasions like weddings, parties and holiday trips. As a result, multiple video recordings are made from a single event providing different view angles and wider coverage. This gives an opportunity to produce a desired video summary from the event, combining the videos with the most favorable views from multiple recordings. In order to mix contents from different cameras, the recordings require very precise synchronization in time. This task is very tedious and presently done manually. We present two methods to synchronize multiple videos based on the identical audio content present in the recordings. The first method utilizes audio-classification and the synchronization between two recordings is determined by correlating the audio classes. The second method uses audio-fingerprints to represent the recorded audio. The synchronization is determined by fingerprint matches between the different recordings. The experimental results show that the audio-classification method requires recordings, at least a couple of minutes long, with large temporal overlap to determine the synchronization point. The method using audio-fingerprints requires at least 3 second long overlapping audio and resulted inperfect synchronization in all the examined cases.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {545–548},
numpages = {4},
keywords = {audio classification, video synchronization, audio fingerprinting},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291368,
author = {Li, Yiqun and Lim, Joo Hwee},
title = {Outdoor Place Recognition Using Compact Local Descriptors and Multiple Queries with User Verification},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291368},
doi = {10.1145/1291233.1291368},
abstract = {In this paper, we propose a novel method to model outdoor places with compact local descriptors extracted from images taken around geographical places. Region-based and clustering-based methods are used to reduce the number of feature vectors to represent the natural scene images. A Multiple Queries with User Verification (MQUV) scheme is proposed to improve the recognition accuracy and the system reliability. In our application, a mobile phone camera is used to take images around a place and send them back to the server to get relevant information about the place. The MQUV scheme calculates the maximum confidence level of all top 5 matching places and returns the best matching result to the user together with a typical sample image of the recognized place for the user's visual verification. User is suggested to take more images if the system is not confident enough to provide a result. The user can also make one's own decision by visually matching the returned image with the scenery of the place. Experimental results show that the number of feature vectors is significantly reduced with the compact place modeling and the recognition accuracy is improved with the MQUV scheme.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {549–552},
numpages = {4},
keywords = {object recognition, image classification, scene recognition, place recognition, clustering, feature reduction},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291369,
author = {Cai, Rui and Zhang, Chao and Wang, Chong and Zhang, Lei and Ma, Wei-Ying},
title = {MusicSense: Contextual Music Recommendation Using Emotional Allocation Modeling},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291369},
doi = {10.1145/1291233.1291369},
abstract = {In this paper, we present a novel contextual music recommendation approach, MusicSense, to automatically suggest music when users read Web documents such as Weblogs. MusicSense matches music to a document's content, in terms of the emotions expressed by both the document and the music songs. To achieve this, we propose a generative model - Emotional Allocation Modeling - in which a collection of word terms is considered as generated with a mixture of emotions. This model also integrates knowledge discovering from a Web-scale corpus and guidance from psychological studies of emotion. Music songs are also described using textual information extracted from their meta-data and relevant Web pages. Thus, both music songs and Web documents can be characterized as distributions over the emotion mixtures through the emotional allocation modeling. For a given document, the songs with the most matched emotion distributions are finally selected as the recommendations. Preliminary experiments on Weblogs show promising results on both emotion allocation and music recommendation.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {553–556},
numpages = {4},
keywords = {emotional allocation modeling, contextual music recommendation, MusicSense, moods},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291370,
author = {Hwang, Amy and Ahern, Shane and King, Simon and Naaman, Mor and Nair, Rahul and Yang, Jeannie},
title = {Zurfer: Mobile Multimedia Access in Spatial, Social and Topical Context},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291370},
doi = {10.1145/1291233.1291370},
abstract = {What happens when you can access all the world's media, but the access is constrained by screen size, bandwidth, attention, and battery life? We present a novel mobile context-aware software prototype that enables access to images on the go. Our prototype utilizes the channel metaphor to give users contextual access to media of interest according to key dimensions: spatial, social, and topical.Our experimental prototype attempts to be playful and simple to use, yet provide powerful and comprehensive media access. A temporally-driven sorting scheme for media items allows quick and easy access to items of interest in any dimension. For ad-hoc tasks, we extend the application with keyword search to deliver the long tail of media and images.Elements of social interaction and communication around the photographs are built into the mobile application, to increase user engagement. The application utilizes Flickr.com as an image and social-network data source, but could easily be extended to support other websites and media formats.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {557–560},
numpages = {4},
keywords = {mobile, context-aware, photo browsing, location-based},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291371,
author = {Aoki, Masaki and Masuda, Ken and Matsuda, Hiroyoshi and Takiguchi, Tetsuya and Ariki, Yasuo},
title = {Voice Activity Detection by Lip Shape Tracking Using EBGM},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291371},
doi = {10.1145/1291233.1291371},
abstract = {We propose a voice activity detection of a target speaker (driver) in a car by integrating lip movement and acoustic processing. To prevent the wrong detection caused by nontarget speakers using only acoustic processing, the proposed system extracts the lip movement of the target speaker by measuring the lip aspect ratio. An infrared camera is used to cope with the change of lighting environment. In order to extract the lip from gray scale images, Elastic Bunch Graph Matching is employed. Experimental results showed the proposed system improved the precision rate in the voice activity detection by approximately 40% compared to the method using only acoustic processing in a car.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {561–564},
numpages = {4},
keywords = {voice activity detection, lip shape extraction, elastic bunch graph matching},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291372,
author = {Yavlinsky, Alexei and Heesch, Daniel},
title = {An Online System for Gathering Image Similarity Judgements},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291372},
doi = {10.1145/1291233.1291372},
abstract = {We describe an online application that allows users to provide similarity judgements whilst browsing a collection of 60,000 photographs. One immediate goal is to modify the initial browsing structure in response to the feedback. We thus suggest a long-term relevance feedback technique that integrates user information over multiple sessions. The principal role of the system, however, is that of a tool for acquiring a rich dataset of similarity relationships between images which we plan to make available to the community and which can be used for training and evaluation purposes. Two particular ways of how to use the data will be described in detail.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {565–568},
numpages = {4},
keywords = {relevance feedback, image similarity, NNk networks},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291373,
author = {Singh, Rahul and Hsu, Ya-Wen},
title = {Analysis of Usage Patterns in Experiential Multiple Perspective Web Search},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291373},
doi = {10.1145/1291233.1291373},
abstract = {With the rapid growth in the volume, complexity, and heterogeneity of information in the World Wide Web (WWW), the role of user-data interaction paradigms is becoming increasingly critical to the success of web-based information retrieval and assimilation. Currently, the paucity of mature paradigms in this problem area contrasts sharply with the advances in design of search techniques that allow indexing large volumes of information and efficiently executing keyword-based search. State of the art research in mediating user-data interactions over large information repositories such as the WWW has seen the proposition of techniques such as page categorization, page summarization, content-based page clustering, as well as algorithms for recognizing semantic correlations between web-pages having heterogeneous content and supporting experiential and unified interactions across them. In this context, a key challenge involves studying and analyzing user behaviors and usage patterns in such information interaction frameworks. In this paper, we present a study that investigates this issue by analyzing both quantitatively and qualitatively how users interact, query, explore, and assimilate information in such an environment. We also investigate how efficacious such interaction paradigms are as compared to the standard approach of presenting results by ordering them in terms of page rank. Results from our investigation provide important insights into user behavior in heterogeneous information organization and interaction frameworks and will be valuable in further development of information presentation, querying, and interaction techniques.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {569–572},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291374,
author = {Cheng, Roger and Nahrstedt, Klara},
title = {Empirical Study of 3D Video Source Coding for Autostereoscopic Displays},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291374},
doi = {10.1145/1291233.1291374},
abstract = {The recent commercial availability of autostereoscopic displays has led to a rise in interest in 3D video. The need to store and transmit 3D video has created some interesting challenges. 3D video contains both color and depth information, and should be treated differently from 2D video for optimal results. This paper explores ideas for efficient 3D video source coding, tests these ideas in a human subject test with 27 subjects, and analyzes and discusses the results. It is concluded that for the specific display and codec used, 3D video file sizes can be reduced to about one-quarter of their original sizes without significant degradation in quality.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {573–576},
numpages = {4},
keywords = {souce coding, applied psychology, 3D video, video quality, autostereoscopic display, ACM proceedings},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291375,
author = {Wang, Tao and Gao, Yue and Wang, Patricia P. and Li, Eric and Hu, Wei and Zhang, Yimin and Yong, Junhai},
title = {Video Summarization by Redundancy Removing and Content Ranking},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291375},
doi = {10.1145/1291233.1291375},
abstract = {In order to help the user to grasp the long video content quickly, this paper proposes a novel video summarization approach based on redundancy removal and content ranking. By video parsing and cast indexing, the approach first constructs a story board to let user know about the main scenes and the main actors in the video. Then it generates a "story-constraint summary" by key frame clustering and repetitive segment detection. To shorten the video summary length to a target length, our approach constructs a "time-constraint summary" by important factor based content ranking. Extensive experiments are carried out on TV series, movies, and cartoons. Good results demonstrate the effectiveness of the proposed method.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {577–580},
numpages = {4},
keywords = {video summarization, key frame clustering, content ranking, scene segmentation, cast indexing, repetitive segment detection},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291376,
author = {Ahmed, Dewan Tanvir and Shirmohammadi, Shervin and Oliveira, Jauvane},
title = {Improving Gaming Experience in Zonal MMOGs},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291376},
doi = {10.1145/1291233.1291376},
abstract = {Synchronous communication is a primary concern for multi-user virtual environments like Massively Multiplayer Online Games (MMOGs). Most of the MMOGs offer discrete view for the avatars and follow logical zone layout for easy state management. The avatar movement, from one logical zone to another, causes reorganization at the P2P overlay structure. Its recurrent nature along with unintelligent zone crossing approaches eventually hampers synchronous communication. In this paper, we present performance enhancement mechanisms to reduce P2P overlay reorganization penalties based on avatars' physical characteristics. Avatars' unpredictable movement around the zone boundaries also incur repeated connections and disconnections either among the zone masters or among the multiple peers in the overlay networks. Interest driven zone crossing, dynamic shared region between adjacent zones, and clustering of the entities based on their attributes significantly alleviates these problems and also provides continuous view and seamless region crossing to players. The technical contribution of this paper is to present the effectiveness of object clustering mechanism and interest driven zone crossing with dynamic shared region between each adjacent zones to enhance the gaming experience of MMOG players or users of other types of networked virtual environments (VE).},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {581–584},
numpages = {4},
keywords = {group communication, MMOG, area of interest management},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258981,
author = {Li, Dongge},
title = {Session Details: Content 4 - Image Annotation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258981},
doi = {10.1145/3258981},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291378,
author = {Rui, Xiaoguang and Li, Mingjing and Li, Zhiwei and Ma, Wei-Ying and Yu, Nenghai},
title = {Bipartite Graph Reinforcement Model for Web Image Annotation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291378},
doi = {10.1145/1291233.1291378},
abstract = {Automatic image annotation is an effective way for managing and retrieving abundant images on the internet. In this paper, a bipartite graph reinforcement model (BGRM) is proposed for web image annotation. Given a web image, a set of candidate annotations is extracted from its surrounding text and other textual information in the hosting web page. As this set is often incomplete, it is extended to include more potentially relevant annotations by searching and mining a large-scale image database. All candidates are modeled as a bipartite graph. Then a reinforcement algorithm is performed on the bipartite graph to re-rank the candidates. Only those with the highest ranking scores are reserved as the final annotations. Experimental results on real web images demonstrate the effectiveness of the proposed model.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {585–594},
numpages = {10},
keywords = {automatic image annotation, bipartite graph model},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291379,
author = {Yuan, Jinhui and Li, Jianmin and Zhang, Bo},
title = {Exploiting Spatial Context Constraints for Automatic Image Region Annotation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291379},
doi = {10.1145/1291233.1291379},
abstract = {In this paper we conduct a relatively complete study on how to exploit spatial context constraints for automated image region annotation. We present a straight forward method to regularize the segmented regions into 2D lattice layout, so that simple grid-structure graphical models can be employed to characterize the spatial dependencies. We show how to represent the spatial context constraints in various graphical models and also present the related learning and inference algorithms. Different from most of the existing work, we specifically investigate how to combine the classification performance of discriminative learning and the representation capability of graphical models. To reliably evaluate the proposed approaches, we create a moderate scale image set with region-level ground truth. The experimental results show that (i) spatial context constraints indeed help for accurate region annotation, (ii) the approaches combining the merits of discriminative learning and context constraints perform best, (iii) image retrieval can benefit from accurate region-level annotation.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {595–604},
numpages = {10},
keywords = {image region annotation, graphical model, spatial context},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291380,
author = {Liu, Jing and Wang, Bin and Li, Mingjing and Li, Zhiwei and Ma, Weiying and Lu, Hanqing and Ma, Songde},
title = {Dual Cross-Media Relevance Model for Image Annotation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291380},
doi = {10.1145/1291233.1291380},
abstract = {Image annotation has been an active research topic in recent years due to its potential impact on both image understanding and web image retrieval. Existing relevance-model-based methods perform image annotation by maximizing the joint probability of images and words, which is calculated by the expectation over training images. However, the semantic gap and the dependence on training data restrict their performance and scalability. In this paper, a dual cross-media relevance model (DCMRM) is proposed for automatic image annotation, which estimates the joint probability by the expectation over words in a pre-defined lexicon. DCMRM involves two kinds of critical relations in image annotation. One is the word-to-image relation and the other is the word-to-word relation. Both relations can be estimated by using search techniques on the web data as well as available training data. Experiments conducted on the Corel dataset and a web image dataset demonstrate the effectiveness of the proposed model.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {605–614},
numpages = {10},
keywords = {word correlation, image retrieval, relevance model, image annotation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258982,
author = {Xie, Lexing},
title = {Session Details: Brave New Topics Session 1},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258982},
doi = {10.1145/3258982},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291382,
author = {Zunjarwad, Amit and Sundaram, Hari and Xie, Lexing},
title = {Contextual Wisdom: Social Relations and Correlations for Multimedia Event Annotation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291382},
doi = {10.1145/1291233.1291382},
abstract = {This work deals with the problem of event annotation in social networks. The problem is made difficult due to variability of semantics and due to scarcity of labeled data. Events refer to real-world phenomena that occur at a specific time and place, and media and text tags are treated as facets of the event metadata. We are proposing a novel mechanism for event annotation by leveraging related sources (other annotators) in a social network. Our approach exploits event concept similarity, concept co-occurrence and annotator trust. We compute concept similarity measures across all facets. These measures are then used to compute event-event and user-user activity correlation. We compute inter-facet concept co-occurrence statistics from the annotations by each user. The annotator trust is determined by first requesting the trusted annotators (seeds) from each user and then propagating the trust amongst the social network using the biased PageRank algorithm. For a specific media instance to be annotated, we start the process from an initial query vector and the optimal recommendations are determined by using a coupling strategy between the global similarity matrix, and the trust weighted global co-occurrence matrix. The coupling links the common shared knowledge (similarity between concepts) that exists within the social network with trusted and personalized observations (concept co-occurrences). Our initial experiments on annotated everyday events are promising and show substantial gains against traditional SVM based techniques.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {615–624},
numpages = {10},
keywords = {multimedia, event annotation, context, content management, social networks, images},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291383,
author = {Mayer-Patel, Ketan},
title = {Systems Challenges of Media Collectives Supporting Media Collectives with Adaptive MDC},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291383},
doi = {10.1145/1291233.1291383},
abstract = {With the rise of social networking as an on-line paradigm, we are also witnessing the birth of unstructured, unmanaged, "media collectives" in which hundreds, thousands, or even millions of users create, share, tag, link, and reuse media objects (i.e., pictures, audio, and video). The level of redundancy and repurposing within these collectives is reasonably high. For example, the same video clip (or portions of it) may appear in a variety of different contexts and formats. This redundancy and diversity serve to preserve popular media objects in a completely decentralized and unmanaged manner as a result of individuals optimizing for their own interests and goals. On the other end of the spectrum, however, is a long heavy-tail of media objects which may in fact be the only copy of its kind in the entire world. This paper addresses some of the systems issues which may be at play in dealing with such an extremely bimodal distribution and speculates that there may be opportunities to leverage these media collectives while preserving the autonomy of individual users in order to increase efficient use of networking and storage resources as well as providing richer capabilities to those who participate. The main idea behind our approach is to view adaptation through the lens of multiple description coding in order to expose coding structure and compactly specify how different versions of the same media object relate to each other.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {625–630},
numpages = {6},
keywords = {multiple description coding, adaptation, media collectives},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291384,
author = {Kennedy, Lyndon and Naaman, Mor and Ahern, Shane and Nair, Rahul and Rattenbury, Tye},
title = {How Flickr Helps Us Make Sense of the World: Context and Content in Community-Contributed Media Collections},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291384},
doi = {10.1145/1291233.1291384},
abstract = {The advent of media-sharing sites like Flickr and YouTube has drastically increased the volume of community-contributed multimedia resources available on the web. These collections have a previously unimagined depth and breadth, and have generated new opportunities - and new challenges - to multimedia research. How do we analyze, understand and extract patterns from these new collections? How can we use these unstructured, unrestricted community contributions of media (and annotation) to generate "knowledge".As a test case, we study Flickr - a popular photo sharing website. Flickr supports photo, time and location metadata, as well as a light-weight annotation model. We extract information from this dataset using two different approaches. First, we employ a location-driven approach to generate aggregate knowledge in the form of "representative tags" for arbitrary areas in the world. Second, we use a tag-driven approach to automatically extract place and event semantics for Flickr tags, based on each tag's metadata patterns.With the patterns we extract from tags and metadata, vision algorithms can be employed with greater precision. In particular, we demonstrate a location-tag-vision-based approach to retrieving images of geography-related landmarks and features from the Flickr dataset. The results suggest that community-contributed media and annotation can enhance and improve our access to multimedia resources - and our understanding of the world.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {631–640},
numpages = {10},
keywords = {photo collections, social media, geo-referenced photographs},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291385,
author = {Boll, Susanne and Sandhaus, Philipp and Scherp, Ansgar and Westermann, Utz},
title = {Semantics, Content, and Structure of Many for the Creation of Personal Photo Albums},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291385},
doi = {10.1145/1291233.1291385},
abstract = {Photos are often a means to remember personal events, and the creation of photo albums is the attempt to preserve our memories in a nice book. For a long time people have been creating such photo albums on the basis of prints from analog photos arranged in an album book with scissors and glue and annotated with comments and captions - a tedious task which in these days is getting support by authoring tools and digitally mastered photo books. Relying on the content of others such as printed travel guides, news papers, leaflets, but also friends and family the personal content often has been enriched, enhanced, and completed. This is the starting point of our work: with digital photography and the increasing amount of content-based and contextual metadata of personal photos we can now use this metadata to actually support the targeted and semi-automatic inclusion of interesting, related information from content of others, e.g., from Web 2.0 communities, and offer and add it at the right spot in the personal album. In this paper, we show how photo album creation can benefit from leveraging information learned from many users in regard of the album's content, structure, and semantics.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {641–650},
numpages = {10},
keywords = {Web 2.0, multimedia semantics, personal photo collections, photo album authoring, photo annotation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258983,
author = {Jaimes, Alejandro},
title = {Session Details: HCI 2 - Interfaces to Smart Spaces},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258983},
doi = {10.1145/3258983},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291387,
author = {Cavazza, Marc and Lugrin, Jean-Luc and Pizzi, David and Charles, Fred},
title = {Madame Bovary on the Holodeck: Immersive Interactive Storytelling},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291387},
doi = {10.1145/1291233.1291387},
abstract = {In this paper, we describe a small-scale, yet complete, integration of a real-time immersive interactive storytelling system. While significant progress has been achieved in recent years on the individual component technologies of interactive storytelling, the main objective of this work is to investigate the concept of interactive storytelling in a fully immersive context. We describe each individual component of immersive interactive storytelling from a technical perspective. We have used a commercial game engine as a development environment, supporting real-time visualisation as well as the inclusion of Artificial Intelligence components controlling virtual actors. This visualisation engine has been ported to an immersive setting using dedicated software and hardware supporting real-time stereoscopic visualisation. The hardware platform is built around a 4-sided CAVE-like immersive display operated by a PC-cluster. The interactive storytelling engine is constituted by a planning system based on characters motivations and emotional states. The user can interact with the virtual world using multimodal interaction. We illustrate the system's behaviour on the implementation of excerpts from Madame Bovary, a classic XIXth century novel, and demonstrate the ability for the user to play the role of one of the characters and influence the unfolding of the story by his actions.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {651–660},
numpages = {10},
keywords = {interactive storytelling, multimodal interfaces, virtual actors, virtual reality},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291388,
author = {Bernardin, Keni and Stiefelhagen, Rainer},
title = {Audio-Visual Multi-Person Tracking and Identification for Smart Environments},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291388},
doi = {10.1145/1291233.1291388},
abstract = {This paper presents a novel system for the automatic and unobtrusive tracking and identification of multiple persons in an indoor environment. Information from several fixed cameras is fused in a particle filter framework to simultaneously track multiple occupants. A set of steerable fuzzy-controlled pan-tilt-zoom cameras serves to smoothly track persons of interest and opportunistically capture facial close-ups for face identification. In parallel, speech segmentation, sound source localization and speaker identification are performed using several far-field microphones and arrays. The information coming asynchronously and sporadically from several sources, such as track updates and spatio-temporally localized visual and acoustic identification cues, is fused at higher level to gradually refine the global scene model and increase the system's confidence in the set of recognized identities. The system has been trained on a small set of users' faces and/or voices and showed good performance in natural meeting scenarios at quickly acquiring their identities and complementing the ID information missing in single modalities.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {661–670},
numpages = {10},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291389,
author = {Moncrieff, Simon and Venkatesh, Svetha and West, Geoff},
title = {Privacy and the Access of Information in a Smart House Environment},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291389},
doi = {10.1145/1291233.1291389},
abstract = {In this paper we present a framework for addressing privacy issues raised by the monitoring of assisted living smart house environments. In home environments, the conflict between the goals of the surveillance, and the private nature of the home, raises the issue of occupant privacy. This issue needs to be addressed if applications are to be accepted by the occupant. We identify four key properties required for the design of privacy sensitive ubiquitous computing applications. Subsequently, we develop a dynamic and flexible method for implementing privacy measures through controlling access to data, and an interface to provide feedback to the occupant, enabling them to control the implemented privacy measures. We form a generic framework for implementing privacy sensitive ubiquitous computing applications based on previous applications within the field. This framework was then extended and used to develop a specific framework for a privacy sensitive smart house. The approach proposed in the framework dynamically applies privacy measures to multi-modal data according to the situation, or context, of the environment. We further test an implementation of the privacy measures, and detail methods to implement feedback and control. The approach aims to decrease the invasiveness of the surveillance, while retaining the purpose of the assisted living environment.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {671–680},
numpages = {10},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258984,
author = {Jaimes, Alejandro},
title = {Session Details: Arts Session 2 - Art Pieces},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258984},
doi = {10.1145/3258984},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291391,
author = {Wright, Alexa and Evans, Alun and Linney, Alf and Lincoln, Mike},
title = {The Listening Room: A Speech-Based Interactive Art Installation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291391},
doi = {10.1145/1291233.1291391},
abstract = {In this paper we will present The Listening Room, an interactive audio installation that holds more or less meaningful conversations with up to three people at any one time. Conceived as an artwork that explores the boundaries between virtual and 'real world' experience, The Listening Room incorporates a number of speech technologies. This paper will give an account of the conceptual framework for The Listening Room and will describe the technologies employed in its realisation. To give context to the ideas behind The Listening Room we will describe the work with reference to two previous interactive works by the authors - Face Value(2000) and Alter Ego (2005).},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {681–690},
numpages = {10},
keywords = {interactive arts, speech technology, spoken dialogue systems, human machine interaction},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291392,
author = {Woolford, Kirk A. and Guedes, Carlos},
title = {Particulate Matters: Generating Particle Flows from Human Movement},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291392},
doi = {10.1145/1291233.1291392},
abstract = {This paper describes methods used to construct an interactive installation using human motion to animate both a visual and aural particle system. It outlines the rotoscoping, meta-motion processing, aural and visual rendering systems. It goes into detailed explanation of the "particle flow" systems which lend form to the virtual characters. The paper finishes with a description of the tracking system and "inverse interaction", used by the installation.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {691–696},
numpages = {6},
keywords = {granular synthesis, motion capture, rotoscope, inverse interaction, particle system, particle flow},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258985,
author = {Bailey, Brian},
title = {Session Details: Applications 4 - Helping End Users},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258985},
doi = {10.1145/3258985},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291394,
author = {Chu, Chung-Hua and Yang, De-Nian and Chen, Ming-Syan},
title = {Image Stablization for 2D Barcode in Handheld Devices},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291394},
doi = {10.1145/1291233.1291394},
abstract = {With the ubiquitous of cellular phones, mobile applications with 2D barcodes have drawn a lot of attentions in recent years. However, the previous works for extracting 2D barcodes from an image do not consider the distortion resulted from camera shake. Moreover, the previous works for extracting 2D barcodes from an image do not take a complex background into account. In this paper, therefore, we propose an efficient and effective algorithm to extract 2D barcode from a complex background in a camera-shaken image. Compared with previous approaches, our algorithm outperforms in not only smaller running time but also higher accuracy of the barcode recognition.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {697–706},
numpages = {10},
keywords = {camera-shaken image, 2D barcode, complex background, QR code},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291395,
author = {Christel, Michael G.},
title = {Establishing the Utility of Non-Text Search for News Video Retrieval with Real World Users},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291395},
doi = {10.1145/1291233.1291395},
abstract = {TRECVID participants have enjoyed consistent success using storyboard interfaces for shot-based retrieval, as measured by TRECVID interactive search mean average precision (MAP). However, much is lost by only looking at MAP, and especially by neglecting to bring in representatives of the target user communities to conduct such tasks. This paper reports on the use of within-subjects experiments to reduce subject variability and emphasize the examination of specific video search interface features for their effectiveness in interactive retrieval and user satisfaction. A series of experiments is surveyed to illustrate the gradual realization of getting non-experts to utilize non-textual query features through interface adjustments. Notably, the paper explores the use of the search system by government intelligence analysts, concluding that a variety of search methods are useful for news video retrieval and lead to improved satisfaction. This community, dominated by text search system expertise but still new to video and image search, performed better with and favored a system with image and concept query capabilities over an exclusive text-search system. The user study also found that sports topics mean nothing for this user community and tens of relevant shots collected into the answer set are considered enough to satisfy the information need. Lessons learned from these user interactions are reported, with recommendations on both interface improvements for video retrieval systems and enhancing the ecological validity of video retrieval interface evaluations.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {707–716},
numpages = {10},
keywords = {interactive video retrieval, TRECVID analysis, user studies},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258986,
author = {Griwodz, Carsten},
title = {Session Details: Systems 2 - Adaptation &amp; Scalability},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258986},
doi = {10.1145/3258986},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291397,
author = {Qin, Min and Zimmermann, Roger},
title = {Improving Mobile Ad-Hoc Streaming Performance through Adaptive Layer Selection with Scalable Video Coding},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291397},
doi = {10.1145/1291233.1291397},
abstract = {Numerous types of mobile devices are now popular with end users, who increasingly use them to carry multimedia content on the go. As wireless connectivity is integrated into many handheld devices, streaming multimedia content among mobile ad-hoc peers is becoming a popular application. In this paper, we first introduce a mathematical model for calculating the probability of successfully streaming a multimedia object between two mobile ad-hoc peers. Unlike previous techniques that assume a constant wireless bandwidth or fixed node location, our work supports the 802.11 Auto-Rate Fallback scheme along with two popular mobility models: the random waypoint and the random walk mobility model. When delivery of the whole video content is of crucial importance, we introduce a novel streaming strategy to improve the probability of successfully streaming a video sequence based on our proposed mathematical model. This strategy takes advantage of the Scalable Video Coding scheme to adaptively select the number of enhancement layers to be streamed to the receiver. Simulation results show that our strategy can improve the probability to stream a media object by a maximum of 60% while keeping the video quality relatively high.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {717–726},
numpages = {10},
keywords = {mobility models, streaming, mobile ad-hoc networks, scalable video coding, link availability},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291398,
author = {Alsmirat, Mohammad A. and Al-Hadrusi, Musab and Sarhan, Nabil J.},
title = {Analysis of Waiting-Time Predictability in Scalable Media Streaming},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291398},
doi = {10.1145/1291233.1291398},
abstract = {Providing video streaming users with expected waiting times enhances their perceived quality-of-service (QoS) and encourages them to wait. In the absence of any waiting-time feedback, users are more likely to defect because of the uncertainty as to when they will start to receive services. In this paper, we analyze waiting-time predictability in scalable video streaming. We present three prediction schemes and study their effectiveness when applied with various stream merging techniques and scheduling policies. The results demonstrate that the waiting time can be predicted accurately, especially when enhanced cost-based scheduling is applied. The combination of waiting-time prediction and cost-based scheduling leads to outstanding performance benefits.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {727–736},
numpages = {10},
keywords = {video streaming, time-of-service guarantees, stream merging, scheduling, waiting-time prediction},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291399,
author = {Cheng, Wei and Ooi, Wei Tsang and Mondet, Sebastien and Grigoras, Romulus and Morin, G\'{e}raldine},
title = {An Analytical Model for Progressive Mesh Streaming},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291399},
doi = {10.1145/1291233.1291399},
abstract = {3D triangular mesh is becoming an increasingly important data type for networked applications such as digital museums, online games, and virtual worlds. In these applications, a multi-resolution representation is typically desired for streaming large 3D meshes, allowing for incremental rendering at the viewers while data is still being transmitted. Such progressive coding, however, introduces dependencies between data. This paper quantitatively analyzes the effects of such dependency on the intermediate decoded mesh quality when the progressive mesh is transmitted over a lossy network, by modeling the distribution of decoding time as a function of mesh properties and network parameters. To illustrate the usefulness of our analytical model, we describe three of its applications. First, we show how it can be used to analytically compute the expected decoded mesh quality. Second, we study two extreme cases of dependency in progressive mesh and show that the effect of dependencies on decoded mesh quality diminishes with time. Finally, based on the model, we propose a packetization strategy that improves the decoded mesh quality during the initial stage of streaming.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {737–746},
numpages = {10},
keywords = {progressive meshes, streaming, packetization, 3D data},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258987,
author = {Boll, Susanne},
title = {Session Details: Short Papers Poster Session 3 - Systems &amp; Applications},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258987},
doi = {10.1145/3258987},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291401,
author = {Kim, Wonki and Jin, Soonjong and Jeong, Jechang},
title = {An Efficient Intra Deinterlacing Algorithm with Gradient Detection and Window Matching},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291401},
doi = {10.1145/1291233.1291401},
abstract = {This paper presents a novel intra deinterlacing algorithm (NID) based on content adaptive interpolation. The NID consists of three steps: pre-processing, content classification, and content adaptive interpolation. There are also three main interpolation methods in our proposed NID, i.e. modified edge-based line averaging (M-ELA), gradient directed interpolation (GDI), and window matching method (WMM). Each proposed method shows different performances according to spatial local features. Therefore, we analyze the local region feature using the gradient detection and classify each missing pixel into four categories. And then, based on the classification result, a different de-interlacing algorithm is activated in order to obtain the best performance. Experimental results demonstrate that the NID method performs better than previous techniques.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {747–750},
numpages = {4},
keywords = {deinterlacing, interpolation, gradient detection, window matching},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291402,
author = {Garbas, Jens-Uwe and Fecker, Ulrich and Kaup, Andr\'{e}},
title = {Wavelet-Based Multi-View Video Coding with Full Scalability and Illumination Compensation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291402},
doi = {10.1145/1291233.1291402},
abstract = {A wavelet-based approach to scalable multi-view video coding (MVC) is examined in this paper. A 4-D wavelet transform is used to decorrelate the multi-view video data temporally, view-directionally, and spatially for efficient compression. Motion compensated temporal filtering (MCTF) is applied to each video sequence of each camera to exploit temporal correlation and inter-view dependencies are exploited with disparity compensated view filtering (DCVF). Together with a 2-D spatial wavelet transform the 4-D wavelet transform is constituted. The open-loop structure of the decomposition, together with embedded quantization and coding, allows for the construction of a bitstream which is fully scalable in temporal, view-directional, spatial and quality dimension. Results for scalable decoding in all dimensions are given, as well as comparisons to simulcast coding and state-of-the-art non-scalable multi-view video coding. Further, a significant coding gain is shown when the sequences are pre-processed with an algorithm for cross-view illumination compensation based on histogram matching.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {751–754},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291403,
author = {Song, Minseok},
title = {Energy-Aware Data Prefetching for Multi-Speed Disks in Video Servers},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291403},
doi = {10.1145/1291233.1291403},
abstract = {Energy consumption is an important issue in data centers, and disks use a significant proportion of the total energy. A promising approach to reducing disk energy consumption is to use multi-speed disks with lower rotational speeds. But changing the speed requires a significant time, which reduces the number of viable opportunities to decrease the disk speed. We propose a new energy-aware data prefetching scheme for multi-speed disks in video servers. We start by examining the power and performance characteristics of multi-speed disks. We then analyze the disk bandwidth and buffer requirements needed for jitter-free speed transitions and propose a new data prefetching scheme to extend the time that disks stay at low speed. The effectiveness of the proposed scheme is evaluated through simulations.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {755–758},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291404,
author = {Zhang, Jing and Liu, Guizhong},
title = {Hyperspectral Images Lossless Compression by a Novel Three-Dimensional Wavelet Coding},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291404},
doi = {10.1145/1291233.1291404},
abstract = {In this paper, we present a 3D hyperspectral images lossless compression algorithm, which is based on the asymmetric 3D quincunx structured wavelet transform (A3D-QWT) and the adaptive classification coding. A3D-QWT is a simpler 3D transform compared to the classical asymmetric 3D pyramidal wavelet structure (A3D-DWT) with nearly equal entropy; furthermore the spectral correlation after this quincunx structured transform is higher, which is useful to the adaptive classification coding. The adaptive classification coding can make full use of not only the spatial correlation but also the spectral correlation characteristics of hyperspectral images. Experiments show that our method is capable of providing a higher compression performance for hyperspectral images.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {759–762},
numpages = {4},
keywords = {lossless compression, hyperspectral images, asymmetric 3D quincunx structured wavelet transform, adaptive classification coding},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291405,
author = {L\'{o}pez-Fuentes, Francisco A. and Steinbach, Eckehard},
title = {Hierarchical Collaborative Multicast},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291405},
doi = {10.1145/1291233.1291405},
abstract = {In this paper, we propose and evaluate a novel solution for delay sensitive one-to-many content distribution in P2P networks based on hierarchical clustering. Our delivery scheme involves cooperation among the participating peers. The source splits the content into variable size blocks and sends the blocks to a subset of peers. All peers redistribute parts of the content to other peers. Our approach adopts a tree structure as the global structure to achieve scalability, while fully connected small clusters based on proximity are built in each hierarchical level of the tree, taking advantage of the higher transmission capacities among neighboring peers. Every peer contributes its upload capacity to the system by being a forwarding peer within a cluster. Our evaluation made on PlanetLab shows that our proposal achieves a good performance, short delivery time and scalability.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {763–766},
numpages = {4},
keywords = {application layer multicast, collaboration, hierarchy, peer-to-peer systems},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291406,
author = {Wu, Wanmin and Yang, Zhenyu and Nahrstedt, Klara and Kurillo, Gregorij and Bajcsy, Ruzena},
title = {Towards Multi-Site Collaboration in Tele-Immersive Environments},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291406},
doi = {10.1145/1291233.1291406},
abstract = {Tele-immersion is emerging as a new medium that creates 3D photorealistic, immersive, and interactive experience between geographically dispersed users. However, most existing tele-immersive systems can only support two-way collaboration. In this paper we propose a multi-layer framework and a new data dissemination protocol to support multi-site collaboration. The problem context is unique as multiple remote sites participate in an interactive tele-immersive session, where each site has multiple correlated 3D video streams to send (later referred as multi-stream/multi-site environments). The key challenge is to disseminate such large number of 3D live video streams among these sites subject to the bandwidth and latency constraints while satisfying QoS guarantees in visual quality. Among our findings is that the simple randomized algorithm outperforms many other static algorithms in the unique context. Moreover, the streams generated from one site have high semantic correlation, because often cameras at one site are shooting the same scene, only from different angles. We exploit the stream correlation in the multicast protocol to minimize the level of loss.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {767–770},
numpages = {4},
keywords = {overlay, tele-immersion, multicast},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291407,
author = {Espeland, H\r{a}vard and Lunde, Carl Henrik and Stensland, H\r{a}kon Kvale and Griwodz, Carsten and Halvorsen, P\r{a}l},
title = {Transparent Protocol Translation for Streaming},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291407},
doi = {10.1145/1291233.1291407},
abstract = {The transport of streaming media data over TCP is hindered by TCP's probing behavior that results in the rapid reduction and slow recovery of the packet rates. On the other side, UDP has been criticized for being unfair against TCP connections, and it is therefore often blocked out in the access networks. In this paper, we try to benefit from a combined approach using a proxy that transparently performs transport protocol translation. We translate HTTP requests by the client transparently into RTSP requests, and translate the corresponding RTP/UDP/AVP stream into the corresponding HTTP response. This enables the server to use UDP on the server side and TCP on the client side. This is beneficial for the server side that scales to a higher load when it doesn't have to deal with TCP. On the client side, streaming over TCP has the advantage that connections can be established from the client side, and data streams are passed through firewalls. Preliminary tests demonstrate that our protocol translation delivers a smoother stream compared to HTTP-streaming where the TCP bandwidth oscillates heavily.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {771–774},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291408,
author = {Chattopadhyay, Siddhartha and Ramaswamy, Lakshmish and Bhandarkar, Suchendra M.},
title = {A Framework for Encoding and Caching of Video for Quality Adaptive Progressive Download},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291408},
doi = {10.1145/1291233.1291408},
abstract = {Progressive download of multimedia objects over the Internet (e.g. www.youtube.com), where the video is downloaded and viewed during the download process, has become an increasingly popular alternative to multimedia streaming. Due to the fluctuating bandwidth and latency of the Internet, progressive download is often not fast enough, often resulting in intermittent stalling of the video. In this paper, we first propose a variation of the existing MPEG Fine Grained Scalability (FGS) profile to create a layered video representation that is suitable for progressive download in an environment characterized by varying bitrate. We also propose an efficient caching scheme that is specifically tailored for the proposed layered video representation. The proposed layered version of the Greedy-Dual-Size cache replacement policy is shown to reduce the latency observed by the client during progressive download of video in a varying bitrate environment. Experimental results demonstrate that the proposed caching scheme improves the latency of progressive video downloads as well as the server efficiency.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {775–778},
numpages = {4},
keywords = {progressive download, layered video caching, layered greedy dual size},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291409,
author = {Serbinski, Adam and Abhari, Abdolreza},
title = {Improving the Delivery of Multimedia Embedded in Web Pages},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291409},
doi = {10.1145/1291233.1291409},
abstract = {The purpose of this work is to reduce the delivery time for the initial portion of multimedia objects over HTTP protocol. The multimedia files we consider are those embedded in web pages. By prefetching embedded media from server to client, we are able to overcome the effects of network latency.We implement prefetching in a custom built HTTP server capable of anticipating future requests from the client, and delivering data without it explicitly being requested. To allow the client to receive files not requested, we use a custom built proxy, to run on the client system. Our custom server and proxy implement modifications to the HTTP protocol to allow multiple files to be delivered in a single transmission.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {779–782},
numpages = {4},
keywords = {web multimedia, network Latency, prefetching, embedded objects},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291410,
author = {Lan, Xuguang and Zheng, Nanning and Xue, Jianru and Wu, Xiaoguang and Gao, Bin},
title = {A Peer-to-Peer Architecture for Efficient Live Scalable Media Streaming on Internet},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291410},
doi = {10.1145/1291233.1291410},
abstract = {This paper presents a manageable overlay network architecture SVCP2P for live scalable media streaming. Every peer in SVCP2P periodically exchanges data availability information with one of distributed central servers which act as the centralized index for storing peer list, program list and buffer information of peers. An efficient scheduling algorithm is proposed, which achieves real-time and continuous transmission of the scalable streaming. There are three characteristics of this architecture: 1) easy management; 2) efficient to heterogeneous network because of the scalable media streaming adapting to the heterogeneous demand; and 3) robust and resilient. We have examined the SVCP2P which has been implemented based on the IP Internet over LAN, and the results demonstrate the efficiency of SVCP2P.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {783–786},
numpages = {4},
keywords = {live media streaming, scalable video coding, P2P, heterogeneous network},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291411,
author = {Huang, Yicheng and Tran, An Vu and Wang, Ye},
title = {A Compressed Domain Distortion Measure for Fast Video Transcoding},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291411},
doi = {10.1145/1291233.1291411},
abstract = {Video applications on different mobile devices are becoming increasingly popular. It is an attractive alternative to transcode a high quality non-scalable video bitstream to match constraints (such as bandwidth or processing power) of different platforms with a similar functionality as a scalable video format. In principle, such a transcoder can reduce either the bit per frame (bpf) or the frame per second (fps) of the original bitstream to meet a particular constraint. In the case that multiple candidates with different combinations of bpf and fps satisfy the constraint, an objective video quality measure is needed for the transcoder to choose the candidate with the overall best quality considering both the spatial quality (reflected by bpf) and the temporal quality (reflected by fps). Conventional measures, such as PSNR and MSE operate in the pixel-domain, require full decoding of both the original and candidate video bitstreams and are computationally very expensive. This drawback renders them unsuitable for real-time transcoding applications. To solve this problem, we propose a Mean Compressed Domain Error (MCDE) to predict the quality of the transcoded video. Experimental results show that the proposed MCDE can predict video quality accurately with a negligible computational complexity in comparison with the conventional MSE/PSNR.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {787–790},
numpages = {4},
keywords = {mean compressed domain error, video transcoding},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291412,
author = {Al-Hadrusi, Musab and Sarhan, Nabil J.},
title = {Scalable Delivery and Pricing of Streaming Media with Advertisements},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291412},
doi = {10.1145/1291233.1291412},
abstract = {This paper presents a delivery framework for streaming media with advertisements and an associated pricing model. The delivery model combines the benefits of periodic broadcasting and stream merging. The advertisements' revenues are used to subsidize the price of the media content. The pricing is determined based on the total ads' viewing time. Moreover, this paper presents three modified scheduling policies that are well suited to the proposed delivery framework and analyzes their effectiveness through simulation.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {791–794},
numpages = {4},
keywords = {pricing, periodic broadcasting, media streaming, scheduling, stream merging},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291413,
author = {Wun, Simon and Yong, Chern-Han and Chan, Ti-Eu},
title = {Musical Extrapolation of Speech with Auto-DJ},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291413},
doi = {10.1145/1291233.1291413},
abstract = {In recent years, personalized mobile phone ringtones have been in growing demand. This paper describes auto-DJ, which uses the phone owners' voices in software DJ's performances for creating their own personalized ringtones, with a focus on its scratched sound synthesis module. Scratching is the primary technique for playing the turntable as a musical instrument - making "new" sounds from records by changing the rate of playing them with hand movements. A scratched sound synthesizer turns sound clips into scratches, each of which comprises one or more strokes. We synthesize them by resampling using pitch deviation envelopes which are derived from those matched for original scratched sounds. Our score representation allows musicians to describe scratches, strokes, and their acoustic characteristics in a musical and concise notation. The scratched sound synthesizer currently produces three types of scratches. Despite the small repertoire, we have successfully created realistic and expressive performances.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {795–798},
numpages = {4},
keywords = {musical signal processing, scratching, sound synthesis},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291414,
author = {Li, Yongfeng and Ong, Kenneth},
title = {Optimized Cache Management for Scalable Video Streaming},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291414},
doi = {10.1145/1291233.1291414},
abstract = {Media proxy caching is an efficient method to provide instant access to multiple video objects in video streaming system. Research efforts in this area are not sufficient due to the possible huge number of heterogeneous requests to scalable encoded video objects. In this paper, we propose an optimized caching scheme for scalable video objects so that both transmission cost and access latency are minimized. A multi-objective optimization model is developed and the corresponding algorithms are designed. Our evaluation results show that compared with other caching methods, proposed scheme can achieve a significant reduction in transmission cost with even a small proxy cache size.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {799–802},
numpages = {4},
keywords = {media communication, caching scheme, scalability, optimization},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291415,
author = {de Silva, Gamhewage C. and Yamasaki, Toshihiko and Aizawa, Kiyoharu},
title = {Spatial Querying for Retrieval of Locomotion Patterns in Smart Environments},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291415},
doi = {10.1145/1291233.1291415},
abstract = {A system for retrieving video sequences created by tracking humans in a smart environment, by using spatial queries, is presented. Sketches made on a graphical user interface using a pointing device are used as the means of entering multiple types of queries. After preprocessing and coordinate system conversion, the sketches are analyzed to identify the type of the query. Directional search algorithms based on the minimum distance between points is applied for finding the best matches to the sketch. The results are ranked according to the similarity and presented to the user. The results of an initial evaluation are reported. The paper concludes with an outline of possible future directions.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {803–806},
numpages = {4},
keywords = {smart environments, spatial queries, floor sensors, video retrieval, locomotion patterns},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291416,
author = {Zhao, Gangqiang and Chen, Ling and Song, Jie and Chen, Gencai},
title = {Large Head Movement Tracking Using Sift-Based Registration},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291416},
doi = {10.1145/1291233.1291416},
abstract = {Although there exists dozens of vision based 3D head tracking methods, none of them considers the problem of large motion, especially the movement along the Z axis. In this paper we propose a novel tracking method to handle this problem by using Scale Invariant Feature Transform (SIFT) based registration algorithm. Salient SIFT features are first detected and tracked between two images, and then the 3D points corresponding to these features are obtained from a stereo camera. With these 3D points, a registration algorithm in a RANSAC framework is employed to detect the outliers and estimate the head pose. Performance evaluation shows an accurate pose recovery (3° RMS) when the head has large motion, even with movement along the Z axis was about 150 cm.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {807–810},
numpages = {4},
keywords = {large motion, registration, head track, SIFT},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291417,
author = {de Rooij, Ork and Snoek, Cees G. M. and Worring, Marcel},
title = {Query on Demand Video Browsing},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291417},
doi = {10.1145/1291233.1291417},
abstract = {This paper describes a novel method for browsing a large collection of news video by linking various forms of related video fragments together as threads. Each thread contains a sequence of shots with high feature-based similarity. Two interfaces are designed which use threads as the basis for browsing. One interface shows a minimal set of threads, and the other as many as possible. Both interfaces are evaluated in the TRECVID interactive retrieval task, where they ranked among the best interactive retrieval systems currently available. The results indicate that the use of threads in interactive video search is very beneficial. We have found that in general the query result and the timeline are the most important threads. However, having several additional threads allow a user to find unique results which cannot easily be found by using query results and time alone.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {811–814},
numpages = {4},
keywords = {semantic threads, conceptual similarity, video retrieval, interactive search, multi dimensional browsing},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291418,
author = {Flora, Glenn R. and Zheng, Jiang Y.},
title = {Adjusting Route Panoramas with Condensed Image Slices},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291418},
doi = {10.1145/1291233.1291418},
abstract = {Route panorama (RP) has become an image medium to archive and visualize cityscapes along streets. Collecting data from a sampling line of a video camera mounted on a moving vehicle, the route panorama may suffer from the vehicle shaking and varying speeds due to uneven roads and busy traffic respectively. These may jitter the route panorama and change object widths. To produce a high quality route panorama, we extract spatial-temporal information in the video volume and rectify the route panorama. In this paper, we propose two condensed image slices to record traces of horizontal and vertical scenes during the vehicle motion. Instead of matching video frames that requires cost computation and large storage, we track the feature traces in the condensed image slices to remove jitter and adjust the local length of route panoramas. The method is effective and efficient in acquiring and rectifying long distance route panoramas.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {815–818},
numpages = {4},
keywords = {image representation, video stabilization, media editing, camera motion, route panorama},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291419,
author = {Erol, Berna and Graham, Jamey and Hull, Jonathan J. and Hart, Peter E.},
title = {A Modern Day Video Flip-Book: Creating a Printable Representation from Time-Based Media},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291419},
doi = {10.1145/1291233.1291419},
abstract = {In this paper, we describe a method for storing an entire video, animation sequence, or any other media type, on paper. The method is based on printing a key frame from a video on paper along with a barcode that encodes the motion information and other auxiliary information in MPEG-4 format. Unlike other video barcode systems in the prior art, a barcode in our system does not contain a link to the video clip; instead it contains motion information. A client device applies the motion information to an image of the video key frame to obtain full motion video. Therefore, the paper document is a self contained representation of a video clip and access to a server is not required. We modified an MPEG-4 [1] encoder and decoder to implement the video flip-book encoder and decoder. Experiments show that it is possible to encode several seconds of video on paper using our method. This is sufficient to create small animations for some printed materials such as video greeting cards and children's books.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {819–822},
numpages = {4},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291420,
author = {Farin, Dirk and Effelsberg, Wolfgang and de With, Peter H. N.},
title = {Floor-Plan Reconstruction from Panoramic Images},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291420},
doi = {10.1145/1291233.1291420},
abstract = {The capturing of panoramic 360° images has become a popular photographic technique. While a panoramic image gives an impressive view of the environment, many people have difficulties to understand the spatial scene arrangement from this flat image. In this paper, we present a new visualization technique for panoramic images based on a coarse reconstruction of the indoor environment, in which the panorama was captured. Applications of this are, for example, real-estate or hotel advertising, featuring virtual tours through the apartment. We use a semi-automatic reconstruction process, in which the user marks the room corners in the panoramic images. These can be translated into viewing-angle measurements, from which our algorithms can compute the exact sizes of the walls, based on a pre-defined geometric model.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {823–826},
numpages = {4},
keywords = {3D scene reconstruction, panoramic images},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291421,
author = {Nichols, Nathan and Liu, Jiahui and Pardo, Bryan and Hammond, Kristian and Birnbaum, Larry},
title = {Learning to Gesture: Applying Appropriate Animations to Spoken Text},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291421},
doi = {10.1145/1291233.1291421},
abstract = {We propose a machine learning system that learns to choose human gestures to accompany novel text. The system is trained on scripts comprised of speech and animations that were hand-coded by professional animators and shipped in video games. We treat this as a text-classification problem, classifying speech as corresponding with specific classes of gestures. We have built and tested two separate classifiers. The first is trained simply on the frequencies of different animations in the corpus. The second extracts text features from each script, and maps these features to the gestures that accompany the script. We have experimented with using a number of features of the text, including n-grams, emotional valence of the text, and parts-of-speech. Using a na\"{\i}ve Bayes classifier, the system learns to associate these features with appropriate classes of gestures. Once trained, the system can be given novel text for which it will attempt to assign appropriate gestures. We examine the performance of the two classifiers by using n-fold cross-validation over our training data, as well as two user studies of subjective evaluation of the results. Although there are many possible applications of automated gesture assignment, we hope to apply this technique to a system that produces an automated news show.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {827–830},
numpages = {4},
keywords = {gestures, animation, na\"{\i}ve bayes, machine learning},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291422,
author = {Baraldi, Stefano and Del Bimbo, Alberto and Landucci, Lea and Torpei, Nicola and Cafini, Omar and Farella, Elisabetta and Pieracci, Augusto and Benini, Luca},
title = {Introducing Tangerine: A Tangible Interactive Natural Environment},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291422},
doi = {10.1145/1291233.1291422},
abstract = {In this paper we describe TANGerINE, a tangible tabletop environment in which users can interact with digital contents manipulating tangible smart objects. Such objects provide continuous data about their status through the embedded wireless sensors, while an overhead computer vision module tracks their position and orientation. Merging sensing data, the system is able to detect a richer language of gestures and manipulations both on the tabletop and in its surroundings, enabling for a more expressive interaction language across different contexts.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {831–834},
numpages = {4},
keywords = {natural interaction, HCI, smart object, tabletop, TUI, wireless sensor node},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291423,
author = {Hung, Hayley and Jayagopi, Dinesh and Yeo, Chuohao and Friedland, Gerald and Ba, Sileye and Odobez, Jean-Marc and Ramchandran, Kannan and Mirghafori, Nikki and Gatica-Perez, Daniel},
title = {Using Audio and Video Features to Classify the Most Dominant Person in a Group Meeting},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291423},
doi = {10.1145/1291233.1291423},
abstract = {The automated extraction of semantically meaningful information from multi-modal data is becoming increasingly necessary due to the escalation of captured data for archival. A novel area of multi-modal data labelling, which has received relatively little attention, is the automatic estimation of the most dominant person in a group meeting. In this paper, we provide a framework for detecting dominance in group meetings using different audio and video cues. We show that by using a simple model for dominance estimation we can obtain promising results.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {835–838},
numpages = {4},
keywords = {dominance modelling, audio-visual feature extraction, meetings, data annotation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291424,
author = {Li, Cheng-Te and Shan, Man-Kwan},
title = {Emotion-Based Impressionism Slideshow with Automatic Music Accompaniment},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291424},
doi = {10.1145/1291233.1291424},
abstract = {In this paper, we propose the emotion-based Impressionism slideshow system with automatic music accompaniment. While conventional image slideshow systems accompany images with music manually, our proposed approach explores the affective content of painting to automatically recommend music based on emotions. This is achieved by association discovery between painting features and emotions, and between emotions and music features respectively. To generate more harmonic Impressionism presentation, a linear arrangement method is proposed based on modified traveling salesman algorithm. Moreover, some animation effects and synchronization issues for affective content of Impressionism fine arts are considered. Experimental result shows our emotion-based accompaniment brings better browsing experience of aesthetics.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {839–842},
numpages = {4},
keywords = {music accompaniment, association discovery, slideshow},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291425,
author = {Xu, Weiwei and Sundaram, Hari},
title = {Information Dense Summaries for Review of Patient Performance in Biofeedback Rehabilitation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291425},
doi = {10.1145/1291233.1291425},
abstract = {In this paper, we present a novel visual design for information dense summaries of patient data with applications in biofeedback rehabilitation. The problem is important in review of large medical datasets where the clinicians require that both summary and all the performance details be shown at the same time. There are two main ideas (a) Summarizing data along the conceptual facets (accuracy / flow / openness) and the temporal facets (session / set / trial) in the biofeedback therapy. The conceptual facets represent key information needed by the experts to review patient performance. (b) Effectively present the data trends and the details in context of the entire performance. The summary incorporates ideas from graphic design and reveals the performance data at two time scales. Our preliminary user study is promising with some significant results. They indicate that our visual summaries are useful, functional and promote inquiry.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {843–846},
numpages = {4},
keywords = {stroke rehabilitation, multimedia, summarization},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291426,
author = {Yi, Jian and Peng, Yuxin and Xiao, Jianguo},
title = {Color-Based Clustering for Text Detection and Extraction in Image},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291426},
doi = {10.1145/1291233.1291426},
abstract = {This paper proposes a new approach for the text detection and extraction in image. The novelty of our approach mainly lies in the color-based clustering into two phases: In text detection phase, we consider jointly the two significant features of text regions in image: homogeneous color and sharp edges, and color-based clustering is employed to decompose the color edge map of image into several edge maps, which makes the text detection of image more accurate. In text extraction phase, on one hand, for effective text recognition, we consider the color difference between the text and background in image, and color-based clustering is utilized to remove image noise. Another hand, for effective binarization of text region, instead of performing binarization in a constant color plane as in the existing methods, our approach can adaptively select the best color plane according to the text contrast difference among color planes for binarization. Experimental results show our approach is better than the existing methods.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {847–850},
numpages = {4},
keywords = {color-based clustering, text extraction, text detection},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291428,
author = {Etoh, Minoru},
title = {Insights into Future Mobile Multimedia Applications},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291428},
doi = {10.1145/1291233.1291428},
abstract = {In the last five years, mobile network applications have been characterized by the following multimedia applications: e-mail, web browsing, games, video-clip &amp; music download, and multimedia mail. Those are early applications, in the emerging 3G mobile network era, ported from "fixed-line" Internet. Thus, those mobile applications have been considered as a degraded version of Internet applications due to limitation of available bandwidth, latency, connection reliability and I/O device capability, where cellphones are also considered as miniature portable PCs. Borrowing many ideas from Internet, however, the mobile infrastructure has brought a highly-personalized popular communication culture that was never seen before.When looking forward the next five years, we may have a different story, where mobile network QoS is catching up and cell-phone is becoming an information hub in our daily life. What we are seeing with the mobile Internet evolution are (1) enhanced multimedia applications enabled by broadband and low-latency wireless networks, and (2) ubiquitous mobile applications enabled by cellphone peripherals together with connection ubiquity. The former network enhancement is just an extension but can be a great enabler of VGA-size 10MB video clips, music content download, and VoIP, and graphical SNS. The latter peripheral enhancement will be an extremely fertile incubation environment for new and innovative killer applications. That definitely differentiates mobile Internet from fixed-line Internet. As shown in the figure, a cellphone is now being equipped with many I/O devices. Captured environment with motion sensor, GPS, health care devices, microphones, and CCD cameras may interact with application servers via Internet. Thus content delivery, interaction with contents, and e-commerce are going to be associated with real environments that will bring us context-aware capability. Several examples are selected from the above areas for presentation.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {851},
numpages = {1},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258988,
author = {Xu, Changsheng},
title = {Session Details: Content 5 - Video Annotation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258988},
doi = {10.1145/3258988},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291430,
author = {Tang, Jinhui and Hua, Xian-Sheng and Qi, Guo-Jun and Wang, Meng and Mei, Tao and Wu, Xiuqing},
title = {Structure-Sensitive Manifold Ranking for Video Concept Detection},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291430},
doi = {10.1145/1291233.1291430},
abstract = {Pairwise similarity of samples is an essential factor in graph propagation based semi-supervised learning methods. Usually it is estimated based on Euclidean distance. However, the structural assumption, which is a basic assumption in these methods, has not been taken into consideration in the normal pairwise similarity measure. In this paper, we propose a novel graph-based learning approach, named Structure-Sensitive Manifold Ranking (SSMR),based on a structure-sensitive similarity measure. Instead of using distance only, SSMR takes local distribution differences into account to more accurately measure pairwise similarity. Furthermore, we show that SSMR can also be deduced from a partial differential equation based anisotropic diffusion. Experiments conducted on the TRECVID dataset show that this approach significantly outperforms existing graph-based semi-supervised learning methods for video semantic concept detection.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {852–861},
numpages = {10},
keywords = {manifold ranking, semi-supervised learning, video concept detection},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291431,
author = {Wang, Meng and Hua, Xian-Sheng and Yuan, Xun and Song, Yan and Dai, Li-Rong},
title = {Optimizing Multi-Graph Learning: Towards a Unified Video Annotation Scheme},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291431},
doi = {10.1145/1291233.1291431},
abstract = {Learning based semantic video annotation is a promising approach for enabling content-based video search. However, severe difficulties, such as insufficiency of training data and curse of dimensionality, are frequently encountered. This paper proposes a novel unified scheme, Optimized Multi-Graph-based Semi-Supervised Learning (OMG-SSL), to simultaneously attack these difficulties. Instead of only using a single graph, OMG-SSL integrates multiple graphs into a regularization and optimization framework to sufficiently explore their complementary nature. We then show that various crucial factors in video annotation, including multiple modalities, multiple distance metrics, and temporal consistency, in fact all correspond to different correlations among samples, and hence they can be represented by different graphs. Therefore, OMG-SSL is able to simultaneously deal with these factors within a unified framework. Experiments on the TRECVID benchmark demonstrate the effectiveness of our proposed approach.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {862–871},
numpages = {10},
keywords = {video annotation, multimodal fusion, semi-supervised learning},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291432,
author = {Gao, Sheng and Lim, Joo-Hwee and Sun, Qibin},
title = {An Integrated Statistical Model for Multimedia Evidence Combination},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291432},
doi = {10.1145/1291233.1291432},
abstract = {Given the rich content-based features of multimedia (e.g., visual, text, or audio) and the development of various approaches to automatic detectors (e.g., SVM, Adaboost, HMM or GMM, etc), can we find an efficient approach to combine these evidences? In the paper, we address this issue by proposing an Integrated Statistical Model (ISM) to combine diverse evidences extracted from the domain knowledge of detectors, the intrinsic structure of modality distribution and inter-concept associations. The ISM provides a unified framework for evidence fusion, having the following unique advantages: 1) the intrinsic modes in the modality distribution are discovered and modeled by a generative model; 2) each mode is a partial description of structure of the modality and the mode configuration, i.e. a set of modes, and is a new representation of the document content; 3) mode discrimination is automatically learned; 4) prior knowledge such as detector correlations and inter-concept relations can be explicitly described and integrated. More importantly, an efficient pseudo-EM algorithm is realized for training the statistical model. The learning algorithm relaxes the computational cost due to the normalized factor and latent variables in the graphical model. We evaluate system performance of our multimedia semantic concept detection with the TRECVID 2005 development dataset, in terms of efficiency and capacity. Our experimental results demonstrate that the ISM fusion outperforms the SVM based discriminative fusion method.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {872–881},
numpages = {10},
keywords = {evidence fusion, semantic concept detection, model-based fusion, average precision},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258989,
author = {Prabhakaran, Balakrishnan},
title = {Session Details: Applications 5 - Smart Media Environments},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258989},
doi = {10.1145/3258989},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291434,
author = {Yang, Zhenyu and Wu, Wanmin and Nahrstedt, Klara and Kurillo, Gregorij and Bajcsy, Ruzena},
title = {ViewCast: View Dissemination and Management for Multi-Party 3d Tele-Immersive Environments},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291434},
doi = {10.1145/1291233.1291434},
abstract = {Real-time distributed multi-party/multi-stream systems are becoming more popular in many areas such as 3D tele-immersion, multi-camera conferencing and security surveillance. However, the construction of such systems in large scale is impeded by the huge demand of computing and networking resources and the lack of a simple yet powerful networking model to handle interconnection, scalability and quality of service (QoS) guarantees. We make two main contributions in the paper: (1) we propose a novel generalized ViewCast model for multi-party/multi-stream video-mediated systems that fills the gap between high-level user interest and low level per-stream management, and (2) we demonstrate the ViewCast model by applying it to the multi-party 3D Tele-Immersive (3DTI) collaboration among geographically dispersed users. More specifically, we show how the ViewCast model is used in supporting stream data dissemination, coordination and QoS management among multiple 3D tele-immersive environments. We present our experimental results in both real implementation and simulation to show that our ViewCast-based solution achieves high efficiency, scalability, and quality in supporting multi-party 3DTI collaboration.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {882–891},
numpages = {10},
keywords = {distributed application, 3D tele-immersion, network protocols, multicast, coordination, adaptation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291435,
author = {Williams, Adam and Ganesan, Deepak and Hanson, Allen},
title = {Aging in Place: Fall Detection and Localization in a Distributed Smart Camera Network},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291435},
doi = {10.1145/1291233.1291435},
abstract = {This paper presents the design, implementation and evaluation of a distributed network of smart cameras whose function is to detect and localize falls, an important application in elderly living environments. A network of overlapping smart cameras uses a decentralized procedure for computing inter-image homographies that allows the location of a fall to be reported in 2D world coordinates by calibrating only one camera. Also, we propose a joint routing and homography transformation scheme for multi-hop localization that yields localization errors of less than 2 feet using very low resolution images. Our goal is to demonstrate that such a distributed low-power system can perform adequately in this and related applications. A prototype implementation is given for low-power Agilent/UCLA Cyclops cameras running on the Crossbow MICAz platform. We demonstrate the effectiveness of the fall detection as well as the precision of the localization using a simulation of our sample implementation.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {892–901},
numpages = {10},
keywords = {technology and aging, activity recognition, distributed sensor networks, camera sensors},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291436,
author = {Wei, Yong and Bhandarkar, Suchendra M. and Li, Kang},
title = {Video Personalization in Resource-Constrained Multimedia Environments},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291436},
doi = {10.1145/1291233.1291436},
abstract = {Multimedia data, especially video data, is being increasingly transmitted to, transmitted from and viewed on mobile devices such as PDA's, laptop PCs, pocket PCs and cell phones. One of the natural limitations of these multimedia-capable, mobile devices is that they are constrained by their battery power capacity, viewing time limit, amount of data received, and in many situations, by available network bandwidth connecting these devices with video servers. The video server is typically also constrained by its computing power and connection bandwidth. In order to provide a resource-constrained mobile client with its desired video content, it is necessary to adapt or personalize the video content while simultaneously satisfying the aforementioned constraints. Also, in order to limit the client-experienced latency, it is necessary to perform client request aggregation on the server end. To this end, a video personalization strategy is proposed to provide mobile, resource-constrained clients with personalized video content that is most relevant to the client's request while simultaneously satisfying multiple client-side system-level resource constraints. A client request aggregation strategy is also proposed to cluster client requests with similar video content preferences and similar client-side resource constraints such that the number of requests the server needs to process and the client-experienced latency are both reduced.The primary contributions of the paper are (1) the formulation and implementation of a Multiple-choice Multi-dimensional Knapsack Problem (MMKP)-based video personalization strategy; and (2) the design and implementation of a multi-stage clustering-based client request aggregation strategy. Experimental results comparing the proposed MMKP-based video personalization strategy to existing 0/1 Knapsack Problem (0/1KP)-based and the Fractional Knapsack Problem (FKP)-based video personalization strategies are presented. It is observed that (1) the proposed MMKP-based personalization strategy includes more relevant video content in response to the client's request compared to the existing 0/1KP-based and FKP-based personalization strategies; and (2) in contrast to the 0/1KP-based and FKP-based personalization strategies which can satisfy only a single client-side constraint at a time, the proposed MMKP-based personalization strategy is shown to be capable of satisfying simultaneously multiple client-side resource constraints. Experimental results comparing the client-experienced latency with and without the proposed client request aggregation strategy are also presented. It is shown that the proposed client request aggregation strategy significantly reduces the mean client-experienced latency without significant reduction in the average relevance value of the video content delivered in response to the client's request.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {902–911},
numpages = {10},
keywords = {multiple-choice multi-dimensional knapsack problem, video personalization, request aggregation, video summarization},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258990,
author = {Nack, Frank},
title = {Session Details: Arts Session 3 - Fluid Art},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258990},
doi = {10.1145/3258990},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291438,
author = {Mann, Steve and Janzen, Ryan E.},
title = {Fluid Samplers: Sampling Music Keyboards Having Fluidly Continuous Action and Sound, without Being Electrophones},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291438},
doi = {10.1145/1291233.1291438},
abstract = {Present-day sampling music keyboards are electronic instruments that fall under the last (5th) category of the Hornbostel Sachs musical instrument classification scheme. Conversely, we first propose an entirely acoustic/mechanical mellotron-like sampling keyboard instrument that neither uses nor involves electricity in any way. Instrument voice/voicing is changed by replacing mechanical storage media similar to Edison phonograph cylinders, gramophone disks, or vinyl records that were commonly used from 1870 to 1980. We next propose a fluid version of our instrument in which hydraulic (water) action is used to fluidly index into the mechanically stored samples, again, without the use of electrical components. Finally, we present a computerized version of our instrument in which digital signal processing is used to obtain fluidly continuous control of musical sampling from a hydraulic keyboard in which each key is a water jet. The final result gives rise to new musically expressive capabilities for continuously flowing manipulation of music samples. Moreover, we propose versions of the computerized instrument that derive the initial sound source from the water itself, such that the instrument is not an electrophone.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {912–921},
numpages = {10},
keywords = {tangible user interfaces, fluid sampling, water-based immersive multimedia, hydraulophones, fluid user-interfaces, interactive art},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291439,
author = {Valle, Andrea and Lombardo, Vincenzo and Vogel, Hairi},
title = {Alternating from 1 to x and Vice Versa},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291439},
doi = {10.1145/1291233.1291439},
abstract = {Alighiero Boetti is one of the most representative contemporary Italian artist and his opus is raising a constantly growing international interest. Many of his works can be realized on very different supports and make use of algorithmic procedures. This paper presents a concert-performance for piano, five video projectors, real-time audio-video processing, an interactive chessboard, and involves a pianist, a "director" and two "players". The multimedia event is directly related to a series of works by Boetti featuring a grid-filling algorithm which has been implemented by the artist on a huge variety of planar supports through many collective projects. In this sense, the event is intended to be another possible realization of the original work exploiting a multimodal support, i.e. including sound (music and audio processing) and emphasizing the generative process defined by Boetti's algorithm through interactivity. An analysis of a corpus of 50 realized Boetti's works - all based on the same algorithm - has been conducted in order to define meaningful mapping strategies from the visual domain to music and audio-video processing. The project makes use of a networked systems for real time DSP which is controlled by wooden cubes on an interactive chessboard.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {922–931},
numpages = {10},
keywords = {multimedia applications, multimodal control interfaces, algorithmic composition, interactivity, conceptual art},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291440,
author = {Mann, Steve and Janzen, Ryan E. and Lo, Raymond and Fung, James},
title = {Non-Electrophonic Cyborg Instruments: Playing on Everyday Things as If the Whole World Were One Giant Musical Instrument},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291440},
doi = {10.1145/1291233.1291440},
abstract = {We introduce a new musical instrument in which computation is used to modify acoustically generated sounds. The acoustically generated sounds originate from real physical objects in the user's environment. These sounds are picked up by one or more microphones connected to a camera phone which filters the sounds using filters whose coefficients change in response to subject matter present in view of the camera. In one example, a row of 12 image processing zones is presented such that sounds originating from real world objects in the first zone are mapped to the first note on a musical scale, sounds originating from the second zone are mapped to the second note of the musical scale, and so on. Thus a user can hit a cement wall or sidewalk, or the ground, and the camera phone will transform the resulting sound (e.g. a dull "thud") into a desired sound, such as the sound of tubular bells, chimes, or the like. Note that the instrument is not an electronic instrument (i.e. not an Electrophone in the Hornbostel Sachs sense) because the sound originates acoustically and is merely filtered toward the desired note. This plays upon the acoustic qualities and physicality of the originating media. For example, if we strike the ground abruptly, the sound resembles that of a bell being hit abruptly. If we rub the ground, the sound resembles that of rubbing a bell. We can scrape the ground in various ways to obtain various sounds that differ depending on which of the camera's zones we're in, as well as the physical properties of the ground itself. These experiences can be shared across "cyborgspace" to effectively blur the boundary between the real and virtual worlds. We present an aquatic instrument that plays upon jets of water, where it is the filter coefficients of the transform that are shared. This allows both users to play the instrument in the jets of water of different public fountains but still experience the same musical qualities of the instrument, and share the physical experience of playing in a fountain despite geographic distances.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {932–941},
numpages = {10},
keywords = {frolic, frolicious, fluid-user-interfaces, FUNtain™, tangible user interfaces, interactive art, hydraulophones, fluid sampling, cyborgfountain™, harmelody, cyborg, cyberfountain™, waterborg, urbeach, water-based immersive multimedia, aquaborg, urban beach, harmellotron},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258991,
author = {Ooi, Wei Tsang},
title = {Session Details: Systems 3 - Computing Complexity},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258991},
doi = {10.1145/3258991},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291442,
author = {Muta, Hidemasa and Doi, Munehiro and Nakano, Hiroki and Mori, Yumi},
title = {Multilevel Parallelization on the Cell/B.E. for a Motion JPEG 2000 Encoding Server},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291442},
doi = {10.1145/1291233.1291442},
abstract = {The Cell Broadband Engine (Cell/B.E.) is a novel multi-core microprocessor designed to provide high-performance processing capabilities for a wide range of applications. In this paper, we describe the world's first JPEG 2000 and Motion JPEG 2000 encoder on Cell/B.E. Novel parallelization techniques for a Motion JPEG 2000 encoder that unleash the performance of the Cell/B.E. are proposed. Our Motion JPEG 2000 encoder consists of multiple video frame encoding servers on a cluster system for high-level parallelization. Each video frame encoding server runs on a heterogeneous multi-core Cell/B.E. processor, and utilizes its 8 Synergistic Processor Elements (SPEs) for low-level parallelization of the time consuming parts of the JPEG 2000 encoding process, such as the wavelet transform, the bit modeling, and the arithmetic coding. The effectiveness of high-level parallelization by the cluster system is also described, not only for the parallel encoding, but also for scalable performance improvement for real-time encoding and future enhancements. We developed all of the code from scratch for effective multilevel parallelization. Our results show that the Cell/B.E. is extremely efficient for this workload compared with commercially available processors, and thus we conclude that the Cell/B.E. is quite suitable for encoding next generation large pixel formats, such as 4K/2K-Digital Cinema.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {942–951},
numpages = {10},
keywords = {parallelization, motion JPEG 2000, cell broadband engine},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291443,
author = {Huang, Yicheng and Tran, An Vu and Wang, Ye},
title = {A Workload Prediction Model for Decoding Mpeg Video and Its Application to Workload-Scalable Transcoding},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291443},
doi = {10.1145/1291233.1291443},
abstract = {Multimedia playback is restricted by the processing power of mobile devices, and in particular, the playback quality can be degraded due to insufficient processing power. To address this problem, we propose a new workload-scalable transcoding scheme which converts a pre-recorded video bitstream into a new video bitstream that satisfies the device's workload constraint, while keeping the transcoding distortion minimal. The key of this proposed transcoding scheme lies on a new workload prediction model, which is fast, accurate and is generic enough to apply to different video formats, decoder implementations and target platforms. The main contributions of this paper include 1) a workload prediction model for decoding MPEG video based on an offline bitstream analysis method; 2) a transcoding scheme that uses the proposed model to control the decoding workload on the target device. To facilitate our transcoding scheme, we have proposed a compressed domain distortion measure (CDDM) that takes effects from both frames per second (fps) and bits per frame (bpf) into consideration. CDDM ensures the transcoded video bitstream to have the best playback quality given the device's workload constraint. Both the workload prediction model and the transcoding scheme are evaluated experimentally.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {952–961},
numpages = {10},
keywords = {CDDM, workload prediction model, video transcoding, mobile},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291444,
author = {Ivanov, Yuri V. and Bleakley, C. J.},
title = {Dynamic Complexity Scaling for Real-Time H.264/AVC Video Encoding},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291444},
doi = {10.1145/1291233.1291444},
abstract = {The H.264 video encoding standard can achieve high coding efficiency at the expense of high computational complexity. Typically, real-time software implementation requires omission of most optional encoding tools leading to significantly reduced coding efficiency. This paper proposes a novel method for real-time H.264 encoding based on dynamic control of the encoding parameters to meet real-time constraints while minimizing coding efficiency loss. Experimental results show that the method provides up to 19% lower bit rate than conventional real-time encoding using fixed parameters with the same visual quality. The method allows real-time 30fps QCIF encoding on a Pentium IV with similar coding efficiency to full search baseline profile encoding.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {962–970},
numpages = {9},
keywords = {H.264, fast mode decision, complexity scaling, real-time video encoding},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258992,
author = {Worring, Marcel},
title = {Session Details: Content 6 - Video Search},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258992},
doi = {10.1145/3258992},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291446,
author = {Hsu, Winston H. and Kennedy, Lyndon S. and Chang, Shih-Fu},
title = {Video Search Reranking through Random Walk over Document-Level Context Graph},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291446},
doi = {10.1145/1291233.1291446},
abstract = {Multimedia search over distributed sources often result in recurrent images or videos which are manifested beyond the textual modality. To exploit such contextual patterns and keep the simplicity of the keyword-based search, we propose novel reranking methods to leverage the recurrent patterns to improve the initial text search results. The approach, context reranking, is formulated as a random walk problem along the context graph, where video stories are nodes and the edges between them are weighted by multimodal contextual similarities. The random walk is biased with the preference towards stories with higher initial text search scores - a principled way to consider both initial text search results and their implicit contextual relationships. When evaluated on TRECVID 2005 video benchmark, the proposed approach can improve retrieval on the average up to 32% relative to the baseline text search method in terms of story-level Mean Average Precision. In the people-related queries, which usually have recurrent coverage across news sources, we can have up to 40% relative improvement. Most of all, the proposed method does not require any additional input from users (e.g., example images), or complex search models for special queries (e.g., named person search).},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {971–980},
numpages = {10},
keywords = {multimodal fusion, video search, power method},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291447,
author = {Wei, Xiao-Yong and Ngo, Chong-Wah},
title = {Ontology-Enriched Semantic Space for Video Search},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291447},
doi = {10.1145/1291233.1291447},
abstract = {Multimedia-based ontology construction and reasoning have recently been recognized as two important issues in video search, particularly for bridging semantic gap. The lack of coincidence between low-level features and user expectation makes concept-based ontology reasoning an attractive mid-level framework for interpreting high-level semantics. In this paper, we propose a novel model, namely ontology-enriched semantic space (OSS), to provide a computable platform for modeling and reasoning concepts in a linear space. OSS enlightens the possibility of answering conceptual questions such as a high coverage of semantic space with minimal set of concepts, and the set of concepts to be developed for video search. More importantly, the query-to-concept mapping can be more reasonably conducted by guaranteeing the uniform and consistent comparison of concept scores for video search. We explore OSS for several tasks including concept-based video search, word sense disambiguation and multi-modality fusion. Our empirical findings show that OSS is a feasible solution to timely issues such as the measurement of concept combination and query-concept dependent fusion.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {981–990},
numpages = {10},
keywords = {ontology, concept-based video search, semantic space},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291448,
author = {Natsev, Apostol (Paul) and Haubold, Alexander and Te\v{s}i\'{c}, Jelena and Xie, Lexing and Yan, Rong},
title = {Semantic Concept-Based Query Expansion and Re-Ranking for Multimedia Retrieval},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291448},
doi = {10.1145/1291233.1291448},
abstract = {We study the problem of semantic concept-based query expansion and re-ranking for multimedia retrieval. In particular, we explore the utility of a fixed lexicon of visual semantic concepts for automatic multimedia retrieval and re-ranking purposes. In this paper, we propose several new approaches for query expansion, in which textual keywords, visual examples, or initial retrieval results are analyzed to identify the most relevant visual concepts for the given query. These concepts are then used to generate additional query results and/or to re-rank an existing set of results. We develop both lexical and statistical approaches for text query expansion, as well as content-based approaches for visual query expansion. In addition, we study several other recently proposed methods for concept-based query expansion. In total, we compare 7 different approaches for expanding queries with visual semantic concepts. They are evaluated using a large video corpus and 39 concept detectors from the TRECVID-2006 video retrieval benchmark. We observe consistent improvement over the baselines for all 7 approaches, leading to an overall performance gain of 77% relative to a text retrieval baseline, and a 31% improvement relative to a state-of-the-art multimodal retrieval baseline.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {991–1000},
numpages = {10},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258996,
author = {Natsev, Apostol},
title = {Session Details: Open Source Software Competition},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258996},
doi = {10.1145/3258996},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291450,
author = {Serrano, Manuel},
title = {Programming Web Multimedia Applications with Hop},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291450},
doi = {10.1145/1291233.1291450},
abstract = {HOP is a new execution platform for running interactive and multimedia applications on the Web. It is aimed at executing applications such as Web agendas, Web galleries, Web music players, etc. HOP consists of: i) a new programming language specially designed for addressing the distributed aspects of Web programming, ii) a rich set of libraries for dealing with music files, sounds, pictures, photographs, etc., iii) a full-fledged Web server for executing the server-side components of the applications.In this paper we illustrate HOP's skills for programming multimedia applications in two examples. We show that, with 50 lines of code, an operational photograph gallery can be implemented and we show that with approximatively 30 lines of code an operational podcast receiver can be built.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1001–1004},
numpages = {4},
keywords = {web programming, functionnal programming},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291451,
author = {Aubert, Olivier and Pri\'{e}, Yannick},
title = {Advene: An Open-Source Framework for Integrating and Visualising Audiovisual Metadata},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291451},
doi = {10.1145/1291233.1291451},
abstract = {The open-source Advene prototype offers a framework for integrating and visualising audiovisual metadata. It allows users to define by themselves, according to their specific tasks, the structure of the metadata as well as the different ways in which it should be visualised. By storing metadata and visualisation specifications independently from the audiovisual document, it allows to share analyses and comments on any audiovisual document. Its open nature and simple principles make it an ideal testbed for experimentation with new audiovisual metadata interaction modalities.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1005–1008},
numpages = {4},
keywords = {audiovisual information visualisation, advene, time and synchronisation, document template, hypervideo, annotation, sharing},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291452,
author = {Le Feuvre, Jean and Concolato, Cyril and Moissinac, Jean-Claude},
title = {GPAC: Open Source Multimedia Framework},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291452},
doi = {10.1145/1291233.1291452},
abstract = {GPAC is a multimedia framework for research and academic purposes in different aspects of multimedia, with a focus on presentation technologies (graphics, animation and interactivity). The project started in 2003 with the initial goal to develop from scratch, in ANSI C, clean software compliant to the MPEG-4 Systems standard, a small and flexible alternative to the MPEG-4 reference software. Since then, the project has evolved into an advanced multimedia player, a multimedia packager and several servers. The project is intended to a wide audience ranging from end-users or content creators with development skills who want to experiment the new standards for interactive technologies or want to convert files for mobile devices, to developers who need players and/or server for multimedia streaming applications.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1009–1012},
numpages = {4},
keywords = {interactivity, Multimedia, broadcasting, VRML, streaming, X3D, MPEG-4, SVG},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291453,
author = {Balci, Koray and Not, Elena and Zancanaro, Massimo and Pianesi, Fabio},
title = {Xface Open Source Project and Smil-Agent Scripting Language for Creating and Animating Embodied Conversational Agents},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291453},
doi = {10.1145/1291233.1291453},
abstract = {Xface is a set of open source tools for creation of embodied conversational agents (ECAs) using MPEG4 and keyframe based rendering driven by SMIL-Agent scripting language. Xface Toolkit, coupled with SMIL-Agent scripting serves as a full 3D facial animation authoring package. Xface project is initiated by Cognitive and Communication Technologies (TCC) division of FBK-irst (formerly ITC-irst). The toolkit is written in ANSI C++, and is open source and platform independent.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1013–1016},
numpages = {4},
keywords = {scripting, embodied conversational agents, open source, MPEG4 facial animation, SMIL, 3D talking heads},
location = {Augsburg, Germany},
series = {MM '07}
}

@dataset{10.1145/review-1291233.1291453_R42833,
author = {Ab\'{a}solo, Mar\'{\i}a Jose},
title = {Review ID:R42833 for DOI: 10.1145/1291233.1291453},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1291233.1291453_R42833}
}

@inproceedings{10.1145/3258997,
author = {Plagemann, Thomas and Goebel, Vera},
title = {Session Details: Doctoral Symposium},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258997},
doi = {10.1145/3258997},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291455,
author = {Popescu, Adrian},
title = {Large Scale Semantic Structures for Image Retrieval},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291455},
doi = {10.1145/1291233.1291455},
abstract = {In this paper, we describe our midterm PhD work that focuses on role of large scale semantic resources in image retrieval. Current Internet picture search engines are based on a raw processing of the text associated to the images and this leads to an important degree of imprecision in the results sets, to an unstructured presentation of the answers and to poor interactivity options. The introduction of semantic layers in the retrieval frameworks may enhance the quality of results obtained with existing systems. One of the main challenges in the field is to develop architectures that include semantics and fit the requirements of real-life applications, like the Internet search engines, and this challenge constitutes a central point in our approach. The expected outcome of our approach is building picture search applications that better fit users' expectances.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1017–1019},
numpages = {3},
keywords = {web, CBIR, ontology, wordnet},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291456,
author = {B\"{u}rger, Tobias},
title = {Realizing Multimedia Processes by Combining Intelligent Content and Semantic Web Services},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291456},
doi = {10.1145/1291233.1291456},
abstract = {This paper provides an outline of my doctoral thesis work whose aim is to develop a reference model for Intelligent Content and a methodology on how properties of Intelligent Content Objects and functionality of Semantic Web Services can be combined in order to enable media-rich and content-oriented processes. This thesis will especially try to show how having community- and business-oriented aspects attached to content enable the automation of content adaptation, integration or enrichment through the use of semantic technologies.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1020–1022},
numpages = {3},
keywords = {automated media production, multimedia semantics, semantic web services, intelligent content modeling},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291457,
author = {Richard, Bertrand},
title = {Active Reading of Audiovisual Documents},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291457},
doi = {10.1145/1291233.1291457},
abstract = {Active reading is a process in which the reader analyses, and re-uses the object of his reading. The first step of this activity, annotating, is currently well addressed by lots of software. However, organizing annotations or building hypervideos from annotations is currently not well supported. In this paper, we describe our work about active reading of audiovisual documents. We present our analysis of active reading as an activity and we propose a model of schemas for active reading, to organize annotations and easily structure the knowledge of the reader to help him build hypervideos.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1023–1025},
numpages = {3},
keywords = {knowledge structures, hypervideo, annotation, active reading, hypermedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258993,
author = {Nahrstedt, Klara},
title = {Session Details: Systems 4 - Coding Support},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258993},
doi = {10.1145/3258993},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291459,
author = {Krishnan, Srinivas and Mayer-Patel, Ketan},
title = {A Utility-Driven Framework for Loss and Encoding Aware Video Adaptation},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291459},
doi = {10.1145/1291233.1291459},
abstract = {We present a framework for multidimensional utility-driven adaptation for multi-stream video applications. A notable driving application is 3D tele-immersion. Our framework directly models the utility of video frames as well as representation dependencies that arise from differential encoding. The problem of evaluating past and future data utility in the presence of packet loss is specifically addressed and two possible approaches are described. One relies on reliability semantics of the underlying transport-level protocol in order to optimize encoding relationships. The other folds the decision to retransmit packets known to be lost into the utility framework. We quantitatively demonstrate the ability of both approaches to increase performance of a prototype application and show that the second approach is generally superior.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1026–1035},
numpages = {10},
keywords = {utility-based adaptation, multi-stream adaptation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291460,
author = {Chattopadhyay, Siddhartha and Bhandarkar, Suchendra M. and Li, Kang},
title = {Ligne-Claire Video Encoding for Power Constrained Mobile Environments},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291460},
doi = {10.1145/1291233.1291460},
abstract = {Digital video playback on mobile devices is fast becoming widespread and popular. Since mobile devices are typically resource constrained in terms of network bandwidth, battery power and available screen resolution, it is often necessary to formulate special encoding techniques in order to optimize power consumption during video streaming and playback. The existing H.264 standard is popular for video encoding on mobile devices, since it results in a low-bitrate video with visual clarity that is adequate for video playback on mobile devices. However, due to the complexity of the H.264 representation, the video decoding procedure is typically computationally intensive. In this paper, we propose a novel lossy video representation termed as Ligne-Claire (LC) video. LC videos are obtained via graphics overlay of outlines or silhouettes of objects in the video over an approximated texture video. Since the playback of LC video is typically meant for mobile devices, the visual quality of video is adequate for most mobile applications wherein the semantic content of the video can be characterized by object shapes and approximate texture information. Experimental results presented in the paper demonstrate that the proposed lossy LC video encoding scheme results in power savings of 50% or more during video playback compared to standard H.264-encoded videos, of similar video file size. In order to evaluate the visual quality of the LC video, we compare the performance of LC videos with H.264-encoded videos in the context of some typical computer vision tasks. Our results indicate that the performance of the computer vision algorithms on these videos is similar. This fact, coupled with subjective evaluation, and the resulting significant power savings, indicates that the proposed LC representation can be used effectively to encode video for power-constrained mobile devices.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1036–1045},
numpages = {10},
keywords = {video encoding for mobile devices, power aware video encoding, generative video modeling},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291461,
author = {Zwicker, Matthias and Yea, Sehoon and Vetro, Anthony and Forlines, Clifton and Matusik, Wojciech and Pfister, Hanspeter},
title = {Display Pre-Filtering for Multi-View Video Compression},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291461},
doi = {10.1145/1291233.1291461},
abstract = {Multi-view 3D displays are preferable to other stereoscopic display technologies because they provide autostereoscopic viewing from any viewpoint without special glasses. However, they require a large number of pixels to achieve high image quality. Therefore, data compression is a major issue for this approach. In this paper, we present a framework for efficient compression of multi-view video streams for multi-view 3D displays. Our goal is to optimize image quality without increasing the required data bandwidth. We achieve this by taking into account a precise notion of the multi-dimensional display bandwidth. The display bandwidth implies that scene elements that appear at a given distance from the display become increasingly blurry as the distance grows. Our main contribution is to enhance conventional multi-view compression pipelines with an additional pre-filtering step that bandlimits the multi-view signal to the display bandwidth. This imposes a shallow depth of field on the input images, thereby removing high frequency content. We show that this pre-filtering step leads to increased image quality compared to state-of-the-art multi-view coding at equal bitrate. We present results of an extensive user study that corroborate the benefits of our approach. Our work suggests that display pre-filtering will be a fundamental component in signal processing for 3D displays, and that any multi-view compression scheme will benefit from our pre-filtering technique.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1046–1053},
numpages = {8},
keywords = {3D displays, antialiasing, multi-view compression},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258994,
author = {Chua, Tat-Seng},
title = {Session Details: Towards the next Plateau - Innovative Multimedia Research beyond TRECVID},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258994},
doi = {10.1145/3258994},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291463,
author = {Chua, Tat-Seng},
title = {Towards the next Plateau: Innovative Multimedia Research beyond Trecvid},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291463},
doi = {10.1145/1291233.1291463},
abstract = {The content track in ACM Multimedia 2007 will for the first time, feature close to 50% of papers related to TRECVID [1]. There are more TRECVID papers in the other tracks too. A large number of accepted papers also focus on various enhanced machine learning (ML) algorithms. While TRECVID provides a large scale structured dataset for systematic research, and machine learning framework offers a principled way to handle large scale unstructured multimodal data, it is generally felt that there should be more beyond TRECVID and ML. For example, the conference seems to have little representation in a number of key emerging areas like web search, (harnessing) social intelligence, personal media management, mobile and Internet applications, multimedia advertising, and human computer interactions. Part of the positive development of TRECVID is that we now have reasonably realistic large-scale datasets from which to empirically verify many of our algorithms/techniques. However, it offers only one facet of multimedia application and there are many interesting areas and issues that should also be considered. Moreover, reviewers are now looking for complete papers that have large scale testing. This means that areas that do not have large datasets will likely not be acceptable in the conference. A related problem is that many new idea papers, that tend to address new areas with non-formal datasets, will suffer the same fate.This panel will address these issues. In particular, the panel will discuss: • Are we having too many TRECVID type papers, at the expense of other emerging areas? • What new emerging areas of multimedia research we should be targeting?" • How to encourage papers in these emerging areas of research and applications? • How to leverage users in the loop, through social networking and user generated contents etc, to setup large test sets in important emerging areas? • How to ensure that more new idea papers are presented at future conferences.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1054},
numpages = {1},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258998,
author = {Goebel, Vera},
title = {Session Details: Applications 6 - Querying and Recommending Media},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258998},
doi = {10.1145/3258998},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291465,
author = {Cui, Bin and Liu, Ling and Pu, Calton and Shen, Jialie and Tan, Kian-Lee},
title = {QueST: Querying Music Databases by Acoustic and Textual Features},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291465},
doi = {10.1145/1291233.1291465},
abstract = {With continued growth of music content available on the Internet, music information retrieval has attracted increasing attention. An important challenge for music searching is its ability to support both keyword and content based queries efficiently and with high precision. In this paper, we present a music query system - QueST (Query by acouStic and Textual features) to support both keyword and content based retrieval in large music databases. QueST has two distinct features. First, it provides new index schemes that can efficiently handle various queries within a uniform architecture. Concretely, we propose a hybrid structure consisting of Inverted file and Signature file to support keyword search. For content based query, we introduce the notion of similarity to capture various music semantics like melody and genre. We extract acoustic features from a music object, and map it to multiple high-dimension spaces with respect to the similarity notion using PCA and RBF neural network. Second, we design a result fusion scheme, called the Quick Threshold Algorithm, to speed up the processing of complex queries involving both textual and multiple acoustic features. Our experimental results show that QueST offers higher accuracy and efficiency compared to existing algorithms.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1055–1064},
numpages = {10},
keywords = {similarity notion, music, acoustic feature, textual feature, search},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291466,
author = {Cai, Rui and Zhang, Chao and Zhang, Lei and Ma, Wei-Ying},
title = {Scalable Music Recommendation by Search},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291466},
doi = {10.1145/1291233.1291466},
abstract = {The growth of music resources on personal devices and Internet radio has increased the need for music recommendations. In this paper, aiming at providing an efficient and general solution, we present a search-based solution for scalable music recommendations. In this solution a music piece is first transformed to a music signature sequence in which each signature characterizes the timbre of a local music clip. Based on such signatures, a scale-sensitive method is then proposed to index the music pieces for similarity search, using the locality sensitive hashing (LSH). The scale-sensitive method can numerically find the appropriate parameters for indexing various scales of music collections, and thus can guarantee a proper number of nearest neighbors are found in search. In the recommendation stage, representative signatures from snippets of a seed piece are extracted as query terms, to retrieve pieces with similar melodies for suggestions. We also design a relevance-ranking function to sort the search results, based on the criteria that include matching ratio, temporal order, term weight, and matching confidence. Finally, with the search results, we propose a strategy to generate a dynamic playlist which can automatically expand with time. Evaluations of several music collections at various scales showed that our approach achieves encouraging results in terms of recommendation satisfaction and system scalability.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1065–1074},
numpages = {10},
keywords = {music snippet, music signature, content-based music search, locality sensitive hashing (LSH), automated playlist generation, scalable music recommendation},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291467,
author = {Mei, Tao and Hua, Xian-Sheng and Yang, Linjun and Li, Shipeng},
title = {VideoSense: Towards Effective Online Video Advertising},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291467},
doi = {10.1145/1291233.1291467},
abstract = {With Internet delivery of video content surging to an unprecedented level, online video advertising is becoming increasingly pervasive. In this paper, we present a novel advertising system for online video service called VideoSense, which automatically associates the most relevant video ads with online videos and seamlessly inserts the ads at the most appropriate positions within each individual video. Unlike most current video-oriented sites that only display a video ad at the beginning or the end of a video, VideoSense aims to embed more contextually relevant ads at less intrusive positions within the video stream. Given an online video, VideoSense is able to detect a set of candidate ad insertion points based on content discontinuity and attractiveness, select a list of relevant candidate ads ranked according to global textual relevance, and compute local visual-aural relevance between each pair of insertion points and ads. To support contextually relevant and less intrusive advertising, the ads are expected to be inserted at the positions with highest discontinuity and lowest attractiveness, while the overall global and local relevance is maximized. We formulate this task as a nonlinear 0-1 integer programming problem and embed these rules as constraints. The experiments have proved the effectiveness of VideoSense for online video advertising.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1075–1084},
numpages = {10},
keywords = {less intrusiveness, online video advertising, contextual relevance},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/3258995,
author = {Haenselmann, Thomas},
title = {Session Details: Video Program},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258995},
doi = {10.1145/3258995},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291469,
author = {Sheppard, R. and Wu, W. and Yang, Z. and Nahrstedt, K. and Wymore, L. and Kurillo, G. and Bajcsy, R. and Mezur, K.},
title = {New Digital Options in Geographically Distributed Dance Collaborations with TEEVE: Tele-Immersive Environments for Everybody},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291469},
doi = {10.1145/1291233.1291469},
abstract = {The study of 3D Tele-immersion impact on remote collaborative work represents a very interesting and challenging research topic. In this paper, we introduce the latest accomplishments of TEEVE research which merges computer science with dance choreography. This collaborative research model is ideal for creative, interdisciplinary problem solving. TEEVE offers an entirely new interface for dance choreography as a creative tool and alternative performance venue.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1085–1086},
numpages = {2},
keywords = {3-D tele-immersive environment, collaboration, dance},
location = {Augsburg, Germany},
series = {MM '07}
}

@inproceedings{10.1145/1291233.1291470,
author = {Lai, Jui-Hsin and Chien, Shao-Yi},
title = {Tennis Video 2.0: A New Framework of Sport Video Applications},
year = {2007},
isbn = {9781595937025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291233.1291470},
doi = {10.1145/1291233.1291470},
abstract = {This video demo presents a new framework of sport video applications called as Tennis Video 2.0. The proposed information extraction scheme retrieves the temporal structure of a video and separates the video foreground and background objects into different layers. With the structure and layer information, the new multimedia is generated. Contrary to the conventional video contents, the proposed new multimedia enables users to generate their own contents and feedback requests to the video players for more interaction. Users even can share their created contents with friends in different transmission bandwidth with considering the semantic.},
booktitle = {Proceedings of the 15th ACM International Conference on Multimedia},
pages = {1087–1088},
numpages = {2},
keywords = {video analysis, tennis video, sport video application},
location = {Augsburg, Germany},
series = {MM '07}
}

