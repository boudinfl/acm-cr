@inproceedings{10.1145/1027527.1027530,
author = {He, Xiaofei},
title = {Incremental Semi-Supervised Subspace Learning for Image Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027530},
doi = {10.1145/1027527.1027530},
abstract = {Subspace learning techniques are widespread in pattern recognition research. They include Principal Component Analysis (PCA), Locality Preserving Projection (LPP), etc. These techniques are generally unsupervised which allows them to model data in the absence of labels or categories. In relevance feedback driven image retrieval system, the user provided information can be used to better describe the intrinsic semantic relationships between images. In this paper, we propose a semi-supervised subspace learning algorithm which incrementally learns an adaptive subspace by preserving the semantic structure of the image space, based on user interactions in a relevance feedback driven query-by-example system. Our algorithm is capable of accumulating knowledge from users, which could result in new feature representations for images in the database so that the system's future retrieval performance can be enhanced. Experiments on a large collection of images have shown the effectiveness and efficiency of our proposed algorithm.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {2–8},
numpages = {7},
keywords = {image retrieval, subspace learning, locality preserving projections, linear discriminat analysis, principal component analysis, relevance feedback},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027531,
author = {He, Jingrui and Li, Mingjing and Zhang, Hong-Jiang and Tong, Hanghang and Zhang, Changshui},
title = {Manifold-Ranking Based Image Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027531},
doi = {10.1145/1027527.1027531},
abstract = {In this paper, we propose a novel transductive learning framework named manifold-ranking based image retrieval (MRBIR). Given a query image, MRBIR first makes use of a manifold ranking algorithm to explore the relationship among all the data points in the feature space, and then measures relevance between the query and all the images in the database accordingly, which is different from traditional similarity metrics based on pair-wise distance. In relevance feedback, if only positive examples are available, they are added to the query set to improve the retrieval result; if examples of both labels can be obtained, MRBIR discriminately spreads the ranking scores of positive and negative examples, considering the asymmetry between these two types of images. Furthermore, three active learning methods are incorporated into MRBIR, which select images in each round of relevance feedback according to different principles, aiming to maximally improve the ranking result. Experimental results on a general-purpose image database show that MRBIR attains a significant improvement over existing systems from all aspects.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {9–16},
numpages = {8},
keywords = {manifold ranking, active learning, relevance feedback, image retrieval},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027532,
author = {He, Xiaofei and Ma, Wei-Ying and Zhang, Hong-Jiang},
title = {Learning an Image Manifold for Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027532},
doi = {10.1145/1027527.1027532},
abstract = {We consider the problem of learning a mapping function from low-level feature space to high-level semantic space. Under the assumption that the data lie on a submanifold embedded in a high dimensional Euclidean space, we propose a relevance feedback scheme which is naturally conducted only on the image manifold in question rather than the total ambient space. While images are typically represented by feature vectors in Rn, the natural distance is often different from the distance induced by the ambient space Rn. The geodesic distances on manifold are used to measure the similarities between images. However, when the number of data points is small, it is hard to discover the intrinsic manifold structure. Based on user interactions in a relevance feedback driven query-by-example system, the intrinsic similarities between images can be accurately estimated. We then develop an algorithmic framework to approximate the optimal mapping function by a Radial Basis Function (RBF) neural network. The semantics of a new image can be inferred by the RBF neural network. Experimental results show that our approach is effective in improving the performance of content-based image retrieval systems.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {17–23},
numpages = {7},
keywords = {manifold learning, semantic space, riemannian structure, dimensionality reduction, image retrieval},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027533,
author = {Hoi, Chu-Hong and Lyu, Michael R.},
title = {A Novel Log-Based Relevance Feedback Technique in Content-Based Image Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027533},
doi = {10.1145/1027527.1027533},
abstract = {Relevance feedback has been proposed as an important technique to boost the retrieval performance in content-based image retrieval (CBIR). However, since there exists a semantic gap between low-level features and high-level semantic concepts in CBIR, typical relevance feedback techniques need to perform a lot of rounds of feedback for achieving satisfactory results. These procedures are time-consuming and may make the users bored in the retrieval tasks. For a long-term study purpose in CBIR, we notice that the users' feedback logs can be available and employed for helping the retrieval tasks in CBIR systems. In this paper, we propose a novel scheme to study the log-based relevance feedback (LRF) technique for improving retrieval performance and reducing the semantic gap in CBIR. In order to effectively incorporate the users' feedback logs, we propose a modified support vector machine (SVM) technique called soft label support vector machine (SLSVM) to construct the LRF algorithm in CBIR. We conduct extensive experiments to evaluate the performance of our proposed algorithm. Compared with the typical approach using query expansion (QEX) technique, we demonstrate that our proposed scheme can significantly improve the retrieval performance of semantic image retrieval from detailed experiments.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {24–31},
numpages = {8},
keywords = {support vector machines, relevance feedback, content-based image retrieval, users logs},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027535,
author = {Wang, Jinjun and Xu, Changsheng and Chng, Engsiong and Wah, Kongwah and Tian, Qi},
title = {Automatic Replay Generation for Soccer Video Broadcasting},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027535},
doi = {10.1145/1027527.1027535},
abstract = {While most current approaches for sports video analysis are based on broadcast video, in this paper, we present a novel approach for highlight detection and automatic replay generation for soccer videos taken by the main camera. This research is important as current soccer highlight detection and replay generation from a live game is a labor-intensive process. A robust multi-level, multi-model event detection framework is proposed to detect the event and event boundaries from the video taken by the main camera. This framework explores the possible analysis cues, using a mid-level representation to bridge the gap between low-level features and high-level events. The event detection results and mid-level representation are used to generate replays which are automatically inserted into the video. Experimental results are promising and found to be comparable with those generated by broadcast professionals.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {32–39},
numpages = {8},
keywords = {sports video analysis, event detection, replay, broadcast},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027536,
author = {Appan, Preetha and Sundaram, Hari},
title = {Networked Multimedia Event Exploration},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027536},
doi = {10.1145/1027527.1027536},
abstract = {This paper describes a novel, interactive multimodal framework that enables a network of friends to effectively visualize and browse a shared image collection. The framework is very useful for geographically disconnected friends to share experiences. Our solution involves three components - (a) an event model, (b) three new spatio-temporal event exploration schemes, and (c) a novel technique for summarizing the user interaction. We develop a simple multimedia event model, that additionally incorporates the idea of user viewpoints. We also develop new dissimilarity measures between events, that additionally incorporate user context. We develop three, task driven, event exploration environments - (a) spatio-temporal evolution, (b) event cones and (c) viewpoint centric interaction. An original contribution of this paper is to summarize the user-interaction using an interactive framework. We conjecture that an interactive summary serves to recall the original content better, than a static image-based summary. Our user studies indicate that the exploratory environment performs very well.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {40–47},
numpages = {8},
keywords = {summarization, events, networked media, browser},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027537,
author = {Wickramasuriya, Jehan and Datt, Mahesh and Mehrotra, Sharad and Venkatasubramanian, Nalini},
title = {Privacy Protecting Data Collection in Media Spaces},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027537},
doi = {10.1145/1027527.1027537},
abstract = {Around the world as both crime and technology become more prevalent, officials find themselves relying more and more on video surveillance as a cure-all in the name of public safety. Used properly, video cameras help expose wrongdoing but typically come at the cost of privacy to those not involved in any maleficent activity. What if we could design intelligent systems that are more selective in what video they capture, and focus on anomalous events while protecting the privacy of authorized personnel? This paper proposes a novel way of combining sensor technology with traditional video surveillance in building a privacy protecting framework that exploits the strengths of these modalities and complements their individual limitations. Our fully functional system utilizes off the shelf sensor hardware (i.e. RFID, motion detection) for localization, and combines this with a XML-based policy framework for access control to determine violations within the space. This information is fused with video surveillance streams in order to make decisions about how to display the individuals being surveilled. To achieve this, we have implemented several video masking techniques that correspond to varying user privacy levels. These results were achievable in real-time at acceptable frame rates, while meeting our requirements for privacy preservation.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {48–55},
numpages = {8},
keywords = {video surveillance, access control, privacy},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027538,
author = {Zhu, Qiang and Wu, Ching-Tung and Cheng, Kwang-Ting and Wu, Yi-Leh},
title = {An Adaptive Skin Model and Its Application to Objectionable Image Filtering},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027538},
doi = {10.1145/1027527.1027538},
abstract = {We propose an adaptive skin-detection method, which allows modelling and detection of the true skin-color pixels with significantly higher accuracy and flexibility than previous methods. In principle, the proposed approach follows a two-step process. For a given image, we first perform a rough skin classification using a generic skin-model which defines the Skin-Similar space. The Skin-Similar space often contains many non-skin pixels due to the inevitable overlap in the color space between skin pixels and some non-skin pixels under the generic skin-model. The objective of the second step is to reduce the false-positive rate by analyzing the image under consideration. Specifically, in the second step, a Gaussian Mixture Model (GMM), specific to the image under consideration and refined from its Skin-Similar space, is derived using the standard Expectation-Maximization (EM) algorithm. We then use a Support Vector Machine (SVM) classifier to identify the skin Gaussian from the trained GMM by incorporating spatial and shape information of the skin pixels. Moreover, we examine how the improvement on skin detection by this adaptive skin-model impacts the detection accuracy in the application of Objectionable Image Filtering. We further propose a two-level classification scheme based on hierarchical bagging to improve the accuracy. Results of extensive experiments on large databases demonstrate the effectiveness and benefits of our adaptive skin-model.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {56–63},
numpages = {8},
keywords = {gaussian mixture model, SVM, objectionable image filtering, skin detection, expectation maximization},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027540,
author = {Galantay, Roderick and Torpus, Jan and Engeli, Maia},
title = {"living-Room": Interactive, Space-Oriented Augmented Reality},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027540},
doi = {10.1145/1027527.1027540},
abstract = {living-room is an augmented reality (AR) installation developed to study interactive, space-oriented AR-scenarios. The installation consists of the living-room box, a room that is three by three meters, as well as hardware and software components to record the user's view and enhance it synthetically. Four scenarios have been realized and analyzed regarding the aspects 'Real and Virtual', 'Interaction' and 'Scenography'. A survey with visitors has been conducted and plans for the next phase of the project developed. living-room is a new kind of media and our focus is to develop design principles for this environment and to identify its "essential properties" [7].},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {64–71},
numpages = {8},
keywords = {augmented reality, art installation, design research},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027541,
author = {Sparacino, Flavia},
title = {Scenographies of the Past and Museums of the Future: From the Wunderkammer to Body-Driven Interactive Narrative Spaces},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027541},
doi = {10.1145/1027527.1027541},
abstract = {This paper offers an overview and discussion of the numerous innovative technological solutions adopted for the exhibit: "Puccini Set Designer" ("La Scena di Puccini"), organized with the support and collaboration of Milan's renown La Scala opera theater. The exhibition used a wide range of state-of-the-art technologies to convey most effectively to the audience Puccini's work as set designer. For the co-presence and coordinated use of several technologies that transform the visitor from passive spectator to orchestrator of the museum experience, it marks a step towards the "museum of the future". A true innovator in opera set design, Giacomo Puccini broke new ground through the use of both modern technologies - such as electric stage lighting - and a narrative structure closer to the audience of his day. Similarly, drawing inspiration from the Puccinian set, this exhibition reinterprets the museum space as an exquisitely scenic place where lighting, choreography, narrative rhythm, costumes and colors are produced with the aid of state-of-the-art technologies. The museum space enhanced by these new narrative tools based on innovative technologies resembles a stage set where the main characters are the objects themselves, a set complete with special effects and stage tricks expressly designed to delight the spectator, and keep his interest alive.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {72–79},
numpages = {8},
keywords = {interactive museums, museum of the future, experience design, interactive technology, exhibit design, interactive narrative spaces},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027542,
author = {Cavazza, Marc and Lugrin, Jean-Luc and Hartley, Simon and Libardi, Paolo and Barnes, Matthew J. and Le Bras, Mikael and Le Renard, Marc and Bec, Louis and Nandi, Alok},
title = {New Ways of Worldmaking: The <i>Alterne</i> Platform for VR Art},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027542},
doi = {10.1145/1027527.1027542},
abstract = {We introduce a novel approach to the creation of Virtual Reality Art installations, which supports the design of alternative worlds, in which laws of Physics can be redefined to induce new user experiences. To implement this concept of "Alternative Reality", we have used Artificial Intelligence techniques to support the definition of the virtual environment behaviour, an approach inspired by Qualitative Reasoning systems. Besides the redefinition of physical laws, we have developed mechanisms for eliciting causal relations between events, as causality plays an important part in users' perception of virtual worlds. Our pilot installation is a CAVETM-like system incorporating a state-of-the-art computer game engine as visualisation software, which has-been ported to this immersive display. The event-based system underlying the game engine is used to bypass the native Physics engine and replace it with our Alternative Reality software. A first prototype has been fully implemented, the Alternative Reality modules totaling over 100,000 lines of C++ code. We present early results obtained with this approach, illustrated with examples taken from two artistic briefs, developed by digital artists associated to this research.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {80–87},
numpages = {8},
keywords = {digital arts, causality, qualitative physics, intelligent virtual environments},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027544,
author = {Nahrstedt, Klara and Balke, Wolf-Tilo},
title = {A Taxonomy for Multimedia Service Composition},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027544},
doi = {10.1145/1027527.1027544},
abstract = {The realization of multimedia systems still heavily relies on building monolithic systems that need to be reengineered for every change in the application and little of which can be reused in subsequent developments even for similar applications. Hence, building complex large scale multimedia systems is still a difficult and challenging problem. Service-based architectures, like researched in the Web community, form a possible solution to this problem: The service-based paradigm decomposes complex tasks into smaller independent entities (e.g. Web services), and then supports a flexible service composition in a variety of ways. However, due to the characteristics of multimedia applications and rich semantic structure of multimedia data and workflows, a direct application of Web-based research results is still difficult. The reason is that Web service frameworks cannot yet cope with the complexity of multimedia applications and their metadata. In this paper, we describe a basic taxonomy for the composition of services to support complex multimedia workflows. We will investigate in detail the necessary steps and methodology for multimedia service compositions and apply our taxonomy to different service composition instances. We will illustrate all composition instances within our taxonomy with case studies and point to possible techniques for the composition problem.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {88–95},
numpages = {8},
keywords = {service-oriented architectures, multimedia service composition},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027545,
author = {Xu, Dongyan and Jiang, Xuxian},
title = {Towards an Integrated Multimedia Service Hosting Overlay},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027545},
doi = {10.1145/1027527.1027545},
abstract = {With the proliferation of multimedia data sources on the Internet, we envision an increasing demand for value-added and function-rich multimedia services that transport, process, and analyze multimedia data on behalf of end users. More importantly, multimedia services are expected to be easily accessible and composable by users. In this paper, we propose MSODA, a service-oriented platform that hosts a wide spectrum of media services provided by different parties. From the user's point of view, MSODA is a shared "market" for media service access and composition. For a media service provider, MSODA creates a virtual dedicated environment for service deployment and management. Finally, the underlying MSODA middleware performs the key functions of service composition, configuration, and mapping for users. We discuss key challenges in the design of MSODA and present preliminary results towards its full realization.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {96–103},
numpages = {8},
keywords = {hosting, virtualization, composition, media service},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027546,
author = {Wagner, Matthias and Kellerer, Wolfgang},
title = {Web Services Selection for Distributed Composition of Multimedia Content},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027546},
doi = {10.1145/1027527.1027546},
abstract = {Growing numbers of pervasive devices are gaining access to the Internet. However, much of the existing rich multimedia content cannot be handled by mobile client devices with limited communication, processing, storage and display capabilities. In this paper, we propose new ways to enhance the universal access to multimedia content through Web Services and Semantic Web concepts. A semantic-based personalized delivery concept is drafted that makes use of these emerging technologies together with rather classical multimedia transcoding ideas. Instead of large, monolithic portal applications designed for multi-purpose adaptation and a single-source delivery, we propose to shift multimedia adaptation functionality to a portfolio of adequately selected Web Services. Web Services accessible through standard interfaces that allow for multimedia format conversion and composition can allow for a more flexible, application-independent adaptation and thus ease multimedia service provisioning essentially.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {104–107},
numpages = {4},
keywords = {service composition, multimedia, web services, semantic web},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027547,
author = {Lakshminarayanan, Karthik and Stoica, Ion and Wehrle, Klaus},
title = {Support for Service Composition in <i>I3</i>},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027547},
doi = {10.1145/1027527.1027547},
abstract = {We consider the problem of service composition in a wide area network, where an end-user can send its packets through intermediate processing points (middleboxes) which can perform a variety of services. Example of such services are filtering, intrusion detection, anonymization, transcoding, and caching. In this paper, we argue that the Internet Indirection Infrastructure (i3)--an overlay network architecture that enables users to locate services and control the path followed by their packets--provides a natural platform for service composition. We discuss the challenges in implementing service compositions on top of i3, and suggest several approaches to address these challenges.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {108–111},
numpages = {4},
keywords = {internet, service composition, indirection},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027549,
author = {Maddage, Namunu C. and Xu, Changsheng and Kankanhalli, Mohan S. and Shao, Xi},
title = {Content-Based Music Structure Analysis with Applications to Music Semantics Understanding},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027549},
doi = {10.1145/1027527.1027549},
abstract = {In this paper, we present a novel approach for music structure analysis. A new segmentation method, beat space segmentation, is proposed and used for music chord detection and vocal/instrumental boundary detection. The wrongly detected chords in the chord pattern sequence and the misclassified vocal/instrumental frames are corrected using heuristics derived from the domain knowledge of music composition. Melody-based similarity regions are detected by matching sub-chord patterns using dynamic programming. The vocal content of the melody-based similarity regions is further analyzed to detect the content-based similarity regions. Based on melody-based and content-based similarity regions, the music structure is identified. Experimental results are encouraging and indicate that the performance of the proposed approach is superior to that of the existing methods. We believe that music structure analysis can greatly help music semantics understanding which can aid music transcription, summarization, retrieval and streaming.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {112–119},
numpages = {8},
keywords = {verse, instrumental, chord, music structure, content-based similarity region, vocal, melody-based similarity region, chorus},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027550,
author = {Suga, Yoshiharu and Kosugi, Naoko and Morimoto, Masashi},
title = {Real-Time Background Music Monitoring Based on Content-Based Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027550},
doi = {10.1145/1027527.1027550},
abstract = {In this paper, we describe music monitoring in TV broadcasting based on content-based retrieval. A part of audio signals is sequentially extracted from TV broadcasting as a retrieval key, and a music DB that stores a great number of musical pieces is retrieved by this key based on content-based retrieval, and a musical piece is identified sequentially. In this way, we are able to carry out music monitoring. There are three necessary requirements important for realization of the music monitoring. They are robustness against non-stationary noise, real-time processing of large-scale music DB retrieval, and high granularity of the retrieval key. As a method of realizing robustness against non-stationary noise, we propose a partially similar retrieval method which improves retrieval accuracy by using the moment in which no superfluous noise is produced during the existence of non-stationary noise. In order to realize real-time processing of large-scale music DB retrieval, we adopt a coarse-to-fine strategy, and propose a spectral peaks hashing method which performs high-speed refining by using hashing. To calculate a hash value in this hashing, frequency channel numbers of the spectral peaks are used. In order to realize high granularity of the retrieval key, it is necessary to solve the problem of retrieval accuracy degradation associated with heightening the granularity. To improve this accuracy, we propose a detection-by-continuity method which uses music continuity. Moreover, by using music continuity to correct the starting point and the terminal point of a musical piece in TV broadcasting, the retrieval accuracy is improved further. In order to evaluate the effectiveness of the proposed methods, we performed experiments using a music DB which stores over 28,000 musical pieces (over 1800 hours) and TV broadcasting audio signals containing music and background music (BGM). The granularity of the retrieval key was set at about 0.5 seconds. Through these experiments, We verified that music monitoring was possible for over 90% of the total time of music and BGM used in TV broadcasting, and that real-time processing was possible.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {120–127},
numpages = {8},
keywords = {hashing, spectral peaks, non-stationary noise, content-based retrieval, music continuity, monitoring},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027551,
author = {Typke, Rainer and Veltkamp, Remco C. and Wiering, Frans},
title = {Searching Notated Polyphonic Music Using Transportation Distances},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027551},
doi = {10.1145/1027527.1027551},
abstract = {We present a method for searching databases of symbolically represented polyphonic music that exploits advantages of transportation distances such as continuity and partial matching in the pitch dimension. By segmenting queries and database documents, we also gain partial matching in the time dimension. Thus, we can find short queries in long database documents, and have a method more robust against pitch and tempo fluctuations in the queries or database documents than we would with transportation distances alone.We compare our method with three algorithms from the C-Brahms project by Lemstr\"{o}m et al. and with PROMS by Clausen et al. and find that our method is more generally usable, retrieves a higher number of relevant documents than all three compared algorithms, and that it is faster than C-Brahms. This is the first comparative study of these algorithms involving a large database with about half a million of documents.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {128–135},
numpages = {8},
keywords = {polyphonic matching, melodic similarity, Earth mover's distance, proportional transportation distance},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027553,
author = {Tao, Shu and Gu\'{e}rin, Roch},
title = {Application-Specific Path Switching: A Case Study for Streaming Video},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027553},
doi = {10.1145/1027527.1027553},
abstract = {The focus of this paper is on improving the quality of streaming video transmitted over the Internet. The approach we investigate assumes the availability of multiple paths between the source and the destination, and dynamically selects the best one. Although this is not a new concept, our contribution is in estimating the "goodness" of a path from the perspective of the video stream, instead of relying only on raw network performance measures. The paper starts by showing that the use of raw network performance data to control path switching decisions can often result in poor choices from an application perspective, and then proceeds to develop a practical approach for evaluating, in real-time, the performance of different paths in terms of video quality. Those estimates are used to continuously select the path that yields the best possible transmission conditions for video streaming applications. We demonstrate the feasibility and performance of the scheme through experiments involving different types of videos.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {136–143},
numpages = {8},
keywords = {path switching, streaming video, quality},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027554,
author = {Wang, Ye and Huang, Wendong and Korhonen, Jari},
title = {A Framework for Robust and Scalable Audio Streaming},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027554},
doi = {10.1145/1027527.1027554},
abstract = {We propose a framework to achieve bandwidth efficient, error robust and bitrate scalable audio streaming. Our approach is compatible with most audio compression format. The main contributions of this paper include: 1) the proposal of a Multi-Stage Interleaving (MSI) strategy which translates packet loss into loss of separate frequency components that are less perceptually significant; and 2) the design of a Layered Unequal-Sized Packetization (LUSP) scheme which enables bitrate scalability and prioritized packet transmission. The combination of the proposed MSI and LUSP allows the use of a set of simple yet effective methods of error concealment in the compressed domain. Our approach offers significant advantages over existing methods in terms of memory consumption (a savings of over 40 times in the sample MP3 implementation), and computational complexity, which are critical issues for battery-powered small devices.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {144–151},
numpages = {8},
keywords = {scalability, layered unequal-sized packetization (LUSP), multi-stage interleaving (MSI), streaming, compressed domain processing, robustness},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027555,
author = {Huang, Cheng and Janakiraman, Ramaprabhu and Xu, Lihao},
title = {Loss-Resilient on-Demand Media Streaming Using Priority Encoding},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027555},
doi = {10.1145/1027527.1027555},
abstract = {A novel solution to the reliable multicast problem is the "digital fountain" approach, in which data is encoded with an erasure protection code before transmission, and receivers can recover the original data after receiving enough distinct encoded data. This solution, however, is not desirable for streaming media schemes in which it is preferable for parts of a movie to be available for consumption before the entire movie is received. Earlier work has proposed the use of Unequal Error Protection (UEP) codes, which permit some parts of the movie to be recovered before others. Unfortunately, a straightforward implementation of this solution can incur prohibitive coding complexity.We outline an on-demand media streaming scheme involving a combination of segmentation and rateless encoding. Our solution reduces the coding complexity to feasible levels, while guaranteeing the least bandwidth consumption for a given playout delay and number of segments. We propose an efficient algorithm to find the optimal segmentation for single-layered and multi-layered transmissions, and analyze its performance under network packet loss. Through analysis, numerical examples, and simulations, we demonstrate the feasibility and performance of the proposed scheme.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {152–159},
numpages = {8},
keywords = {priority encoding transmission, fountain codes, multicast, video-on-demand, loss resilience},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027557,
author = {Ryu, Eun-Seok and Yoo, Chuck},
title = {An Approach to Interactive Media System for Mobile Devices},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027557},
doi = {10.1145/1027527.1027557},
abstract = {The interactive system which interacts human with computer has been recognized as one direction of computer development for a long time. For example, in cinema, a person gets information he wants or plays the media data while moving by using a mobile device. As the development of this system, we designed and implemented the system interacts with users in a small terminal. Our study has three categories. The first category is the development of new interactive media markup language (IML) for the writing interactive media data. The second category is the IML translator which translates IML into the best form to be played on mobile device. And the third category is the <i>IM player</i>, which plays the transferred media data and interacts with user. IML was designed for controlling vector graphics and general media objects in detail and supporting synchronization. Also, it was designed to be operated in small mobile device as well as desktop PC or set-top box which has high CPU performance. The player, implemented finally, is operated on PDA (HP iPAQ) and plays the multimedia data consist of vector graphics (OpenGL), H.264 and AAC etc. according to the choice of user. This system can be used in the ways of interactive cinema and interactive game, and can substitute new interactive web services for existing web services.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {160–161},
numpages = {2},
keywords = {IML, mobile device, interactive media},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027558,
author = {Jiang, Ning and Ho, Yao H. and Hua, Kien A.},
title = {Range Multicast Routers for Large-Scale Deployment of Multimedia Application},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027558},
doi = {10.1145/1027527.1027558},
abstract = {In this paper, we present the Range Multicast protocol and the implemented prototype. We propose to demonstrate the system at the 2004 ACM Multimedia Conference.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {162–163},
numpages = {2},
keywords = {multimedia communication, overlay multicast, video on demand, VCR-like interactivity},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027559,
author = {Wold Eide, Viktor S. and Eliassen, Frank and Michaelsen, J\o{}rgen Andreas},
title = {Exploiting Content-Based Networking for Video Streaming},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027559},
doi = {10.1145/1027527.1027559},
abstract = {This technical demonstration shows that content-based networking is a promising technology for multireceiver video streaming. Each video receiver is provided with fine grained selectivity along different video dimensions, such as region of interest, quality, colors, and temporal resolution. Efficient delivery is maintained, in terms of network utilization and processing requirements. A prototype demonstrates the feasibility of this approach and is available as open source.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {164–165},
numpages = {2},
keywords = {scalable video, content-based networking, distributed content-based publish subscribe systems, coding, layered video, fine granularity video streaming},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027560,
author = {Reti, Tommo and Sarvas, Risto},
title = {<i>DiMaS</i>: Distributing Multimedia on Peer-to-Peer File Sharing Networks},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027560},
doi = {10.1145/1027527.1027560},
abstract = {This demonstration presents the Digital Content Distribution Management System (DiMaS). DiMaS proves as a concept that it is possible to make a system for multimedia producing communities to publish their work on highly popular P2P networks, and importantly, the system enables producers to insert content metadata, to manage intellectual property and usage rights, and to charge for the consumption. All this can be done without introducing another new content or metadata file format and a dedicated client application to read the format.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {166–167},
numpages = {2},
keywords = {metadata, wireless, multimedia, decentralized, peer-to-peer},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027561,
author = {Parker, Conrad and Pang, Andr\'{e} and Pfeiffer, Silvia},
title = {Demonstrating a Video and Audio Web},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027561},
doi = {10.1145/1027527.1027561},
abstract = {This demonstration introduces the <i>Annodex</i> set of technologies, which enable the creation of Webs of audio and video resources integrated into the searching and surfing infrastructure of the World Wide Web. The demonstration covers the live creation of Annodex content and thus of Webs of video and audio, the setup of a Web server to distribute Annodex resources, the use of a Web browser to hyperlink between clips of Annodex resources, and the use of a Web search engine in which media clips can be searched through text queries.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {168–169},
numpages = {2},
keywords = {annodex, continuous media web, CMML},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027562,
author = {Van Every, Shawn},
title = {Interactive Tele-Journalism: Low Cost, Live, Interactive Television News Production},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027562},
doi = {10.1145/1027527.1027562},
abstract = {The rise of the internet and the increasing availability of low cost means to create digital media have created an environment and an appetite in the audience for meaningful interaction with mass media. Television news is an area that holds great potential for community based programming and can be made to allow the audience a direct role in the production of such programming.The focus of this project has been to develop a working prototype of a system to support the live production of low cost, community orientated, interactive television news programs in which the audience has direct and immediate influence over the programming.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {170–171},
numpages = {2},
keywords = {television, DIY, multimedia, interactive television, tele-presence, media, streaming media, event, news, community, social software, networking},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027563,
author = {HUA, Xian-Sheng and LU, Lie and ZHANG, Hong-Jiang},
title = {P-Karaoke: Personalized Karaoke System},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027563},
doi = {10.1145/1027527.1027563},
abstract = {In this demonstration, a personalized Karaoke system, <i>P-Karaoke</i>, is proposed. In the P-Karaoke system, personal home videos and photographs, which are automatically selected from users' multimedia database according to their content, users' preferences or music, are utilized as the background videos of the Karaoke. The selected video clips, photographs, music and lyrics are well aligned to compose a Karaoke video, connecting by specific content-based transitions.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {172–173},
numpages = {2},
keywords = {video editing, video content analysis, music content analysis},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027564,
author = {Wu, Huahui and Claypool, Mark and Kinicki, Robert},
title = {Demonstration of Adjusting Forward Error Correction with Quality Scaling for TCP-Friendly Streaming MPEG},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027564},
doi = {10.1145/1027527.1027564},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {174–175},
numpages = {2},
keywords = {TCP-friendly, forward error correction, video quality, streaming MPEG},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027565,
author = {Zhao, Frank and Liu, Qiong},
title = {A Web Based Multi-Display Presentation System},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027565},
doi = {10.1145/1027527.1027565},
abstract = {In this demonstration, we are going to illustrate how to give a presentation using multiple displays connected to the Internet.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {176–177},
numpages = {2},
keywords = {device control, rich media presentation, multimedia venues, presentation authoring, computer assisted presentation authoring},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027566,
author = {Scherp, Ansgar and Boll, Susanne},
title = {Generic Support for Personalized Mobile Multimedia Tourist Applications},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027566},
doi = {10.1145/1027527.1027566},
abstract = {Mobile applications such as mobile tourist guides that provide tourists with location-based information today mostly aim to adapt the multimedia content to the different end user devices. More and more, these applications also exploit positioning information like GPS to guide the user on the trip. What is still lacking, however, is a <i>personalization</i> of the content to the interests and preferences of the individual tourist and the characteristics of the used end device. However, such a personalization increases the application's complexity since every individual alternatives have to be considered and implemented. To provide substantial support for the development of personalized (mobile) multimedia applications, we developed a domain independent software framework for an efficient and cost-effective development of personalized mobile multimedia applications. We illustrate the framework in the specific domain of personalized mobile tourist information.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {178–179},
numpages = {2},
keywords = {personalized multimedia, travel and tourism, multimedia presentation generation, mobile multimedia},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027567,
author = {Freeman, Jason},
title = {N.A.G.: Network Auralization for Gnutella},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027567},
doi = {10.1145/1027527.1027567},
abstract = {N.A.G. (Network Auralization for Gnutella) is interactive software art designed to actively involve a lay public without musical training in a creative musical experience. Users enter search keywords, and the software looks for matching music files on the Gnutella peer-to-peer file-sharing network. As it downloads music, it plays an audio collage whose structure is based on the relative download rates of the files.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {180–181},
numpages = {2},
keywords = {sonification, Java, auralization, peer to peer, music, audio, software art, file sharing, MP3, remix, Gnutella},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027568,
author = {Easterly, Douglas},
title = {Bio-Fi: Inverse Biotelemetry Projects},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027568},
doi = {10.1145/1027527.1027568},
abstract = {Bio-Fi is a collection of art projects undertaken by S.W.A.M.P. (Studies of Work Atmospheres and Mass Production), collaborative art projects by Douglas Easterly and Matt Kenyon. S.W.A.M.P. projects attempt to find creative expression within elements of culture that are inherently counter-creative. The Bio-Fi series utilizes physical computing technology to access patterns and relationships surrounding a corporation, that couldn't be seen using any other medium. The field of 'biotelemetry' researches ways of gathering vital physiological data from living organisms through transponders (worn or implanted), which relay information to remote hardware [1]. With all biotelemetric applications, it is integral that the transponder-bearing subject is a synecdoche for its larger social group. In this respect, Bio-Fi projects are a sort of 'inverse-biotelemetry'. Test subjects are not released into a natural environment, but trapped within a synthetic environment whose conditions are tempered by various systems of information: Wi-Fi signals are like water, information mined from the internet is food, and electronic pulses become sunlight.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {182–183},
numpages = {2},
keywords = {inverse biotelemetry, physical computing, art, economics},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027569,
author = {Singer, Eric and Feddersen, Jeff},
title = {LEMUR: Robotic Musical Instruments},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027569},
doi = {10.1145/1027527.1027569},
abstract = {This paper describes the work of LEMUR, a collective of artists and technologists developing robotic musical instruments.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {184–185},
numpages = {2},
keywords = {robotics, instruments, music, MIDI},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027570,
author = {Black, August},
title = {Userradio},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027570},
doi = {10.1145/1027527.1027570},
abstract = {Userradio mixes the new technologies of personal communication with "old" broadcast radio technology. It is a set of tools for collaborative networked audio production, where an unlimited number of individuals can mix multiple channels of audio simultaneously and together from anywhere on-line using a standard flash-capable browser. The audio output of the application is broadcast on terrestrial FM radio and the users are ideally within the broadcast diameter.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {186–187},
numpages = {2},
keywords = {streaming media, broadcasting, art, software, radio},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027572,
author = {Davis, Marc and King, Simon and Good, Nathan and Sarvas, Risto},
title = {From Context to Content: Leveraging Context to Infer Media Metadata},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027572},
doi = {10.1145/1027527.1027572},
abstract = {The recent popularity of mobile camera phones allows for new opportunities to gather important metadata at the point of capture. This paper describes a method for generating metadata for photos using spatial, temporal, and social context. We describe a system we implemented for inferring location information for pictures taken with camera phones and its performance evaluation. We propose that leveraging contextual metadata at the point of capture can address the problems of the semantic and sensory gaps. In particular, combining and sharing spatial, temporal, and social contextual metadata from a given user and across users allows us to make inferences about media content.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {188–195},
numpages = {8},
keywords = {contextual metadata, wireless multimedia applications, context-to-content inference, location-based services, mobile camera phones, content-based image retrieval},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027573,
author = {Naaman, Mor and Harada, Susumu and Wang, QianYing and Garcia-Molina, Hector and Paepcke, Andreas},
title = {Context Data in Geo-Referenced Digital Photo Collections},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027573},
doi = {10.1145/1027527.1027573},
abstract = {Given time and location information about digital photographs we can automatically generate an abundance of related contextual metadata, using off-the-shelf and Web-based data sources. Among these are the local daylight status and weather conditions at the time and place a photo was taken. This metadata has the potential of serving as memory cues and filters when browsing photo collections, especially as these collections grow into the tens of thousands and span dozens of years.We describe the contextual metadata that we automatically assemble for a photograph, given time and location, as well as a browser interface that utilizes that metadata. We then present the results of a user study and a survey that together expose which categories of contextual metadata are most useful for recalling and finding photographs. We identify among still unavailable metadata categories those that are most promising to develop next.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {196–203},
numpages = {8},
keywords = {photo collections, geo-referenced digital photos, context},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027574,
author = {Haase, Kenneth},
title = {Context for Semantic Metadata},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027574},
doi = {10.1145/1027527.1027574},
abstract = {This article argues for the growing importance of quality metadata and the equation of that quality with precision and semantic grounding. Such semantic grounding requires metadata that derives from intentional human intervention as well as mechanistic measurement of content media. In both cases, one chief problem in the automatic generation of semantic metadata is ambiguity leading to the overgeneration of inaccurate annotations. We look at a particular richly annotated image collection to show how context dramatically reduces the problem of ambiguity over this particular corpus. In particular, we consider both the abstract measurement of "contextual ambiguity" over the collection and the application of a particular disambiguation algorithm to synthesized keyword searches across the selection.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {204–211},
numpages = {8},
keywords = {metadata, disambiguation, context, information retrieval, multimedia databases},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027576,
author = {Wang, Ye and Kan, Min-Yen and Nwe, Tin Lay and Shenoy, Arun and Yin, Jun},
title = {LyricAlly: Automatic Synchronization of Acoustic Musical Signals and Textual Lyrics},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027576},
doi = {10.1145/1027527.1027576},
abstract = {We present a prototype that automatically aligns acoustic musical signals with their corresponding textual lyrics, in a manner similar to manually-aligned karaoke. We tackle this problem using a multimodal approach, where the appropriate pairing of audio and text processing helps create a more accurate system. Our audio processing technique uses a combination of top-down and bottom-up approaches, combining the strength of low-level audio features and high-level musical knowledge to determine the hierarchical rhythm structure, singing voice and chorus sections in the musical audio. Text processing is also employed to approximate the length of the sung passages using the textual lyrics. Results show an average error of less than one bar for per-line alignment of the lyrics on a test bed of 20 songs (sampled from CD audio and carefully selected for variety). We perform holistic and per-component testing and analysis and outline steps for further development.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {212–219},
numpages = {8},
keywords = {music knowledge, vocal detection, karaoke, audio/text synergy, lyric alignment},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027577,
author = {Komogortsev, Oleg and Khan, Javed},
title = {Predictive Perceptual Compression for Real Time Video Communication},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027577},
doi = {10.1145/1027527.1027577},
abstract = {Approximately 2 degrees in our 140 degree vision span has sharp vision. Many researchers have been fascinated by the idea of eye-tracking integrated perceptual compression of an image or video, yet any practical system has yet to emerge. The unique challenge presented by real time perceptual video streaming is how to handle the fast nature of the human eye and provide its integration with computationally intensive video transcoding scheme. The delay introduced by video transmission in the network presents a difficulty. This delay creates a problem when we try to use information about eye movements for perceptual encoding. In this paper we discuss a new approach to the eye-tracker based video compression. Rather than relying on the point of gaze, this novel scheme tracks a vicinity of interest and offers a prediction mechanism for eye movements. The described system compensates the interim eye movements between the sampling and actual coding. The proposed scheme can be applied to a large variety of today's video compression standards. We have developed an eye gaze-aware MPEG-2 transcoder that can perceptually re-encode a live video stream in real time. The experiments we have conducted illustrate the substantial impact this integrated prediction method has on perceptual video compression and bit-rate reduction.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {220–227},
numpages = {8},
keywords = {video transcoding, perceptual compression},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027578,
author = {Xue, Qi and Ganz, Aura},
title = {Proportional Service Differentiation in Wireless LANs Using Spacing-Based Channel Occupancy Regulation},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027578},
doi = {10.1145/1027527.1027578},
abstract = {In this paper, we propose Spacing-based Channel Occupancy Regulation (SCORE) MAC protocol that provides <i>proportional service differentiation</i> in terms of normalized throughput in wireless LANs. As shown by our system model and simulation study, SCORE provides consistent, scalable and adjustable proportional differentiation for any network size, any service class distribution, any node data rate and any packet size. Compared to state-of-the-art prioritized service differentiation schemes like Enhanced Distributed Coordination Function, SCORE can quantitatively control the channel sharing between different service classes with significant performance gain in terms of higher network throughput and lower packet collision probability.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {228–235},
numpages = {8},
keywords = {multimedia support, channel occupancy, wireless LANs, proportional service differentiation, medium access control},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027580,
author = {Yin, Lijun and Loi, Johnny and Xiong, Wei},
title = {Facial Expression Representation and Recognition Based on Texture Augmentation and Topographic Masking},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027580},
doi = {10.1145/1027527.1027580},
abstract = {The variation of facial texture and surface due to the change of expression is an important cue for analyzing and modeling facial expressions. In this paper, we propose a new approach to represent the facial expression by using a so-called topographic feature. In order to capture the variation of facial surface structure, facial textures are processed by increasing the resolution. The topographical structure of human face is analyzed based on the resolution-enhanced textures. We investigate the relationship between the facial expression and its topographic features, and propose to represent the facial expression by the topographic labels. The detected topographic facial surface and the expressive regions reflect the status of facial skin movement. Based on the observation that the facial texture and its topographic features change along with facial expressions, we compare the disparity of these features between the neutral face and the expressive face to distinguish a number of universal expressions. The experiment demonstrates the feasibility of the proposed approach for facial expression representation and recognition.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {236–239},
numpages = {4},
keywords = {super resolution, feature labeling, facial expression},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027581,
author = {Gllavata, Julinda and Ewerth, Ralph and Freisleben, Bernd},
title = {Tracking Text in MPEG Videos},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027581},
doi = {10.1145/1027527.1027581},
abstract = {Tracking superimposed text moving across several frames of a video is relevant for exploiting its temporal occurrence for effective video content indexing and retrieval. In this paper, an approach is presented that automatically detects, localizes and tracks text appearing in videos. The proposed approach consists of two steps: (1) unsupervised text detection and localization in each Nth frame to monitor new text events, i.e. text appearing in a video for the first time; (2) text tracking within a group of pictures (GOP) using MPEG motion vector information extracted directly from the compressed video stream. Comparative experimental results for a set of videos are presented to show the benefits of our approach.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {240–243},
numpages = {4},
keywords = {MPEG motion vectors, content-based video indexing and retrieval, text tracking in videos, text detection and localization},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027582,
author = {Drumm, Helge},
title = {MPEG-4 Based Real-Time Shadows},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027582},
doi = {10.1145/1027527.1027582},
abstract = {Authors who create interactive 3D-applications mostly suffer under the absences of an easy real-time shadow creation. Even new description languages like MPEG-4 do not support any shadow descriptions as yet. The general lack of existing shadow description possibilities was the inspiration of our research work.We present a novel approach, which enables a simple, flexible and universal solution for the shadow description and management with scene graph based applications.We introduce a new theory we call the "Theory of Shadow Relationships", where shadows are represented by relationships formed by several syntactical and semantical descriptions. The result is a basis for the shadow description itself and the shadow management. The visual rendering of shadows is independent of our solution. The results of our research are used for the development of a new MPEG-4 tool - the "Shadow Node". We show the use of the "Theory of Shadow Relationships" compliant to the MPEG-4 standard.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {244–247},
numpages = {4},
keywords = {shadow, relationship, scene graph, MPEG-4},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027583,
author = {Uysal, Mutlu and Yarman-Vural, Fatos},
title = {A Content Based Image Retrieval System Based on the Fuzzy ARTMAP Architecture},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027583},
doi = {10.1145/1027527.1027583},
abstract = {This study deals with designing a flexible feature space for Content Based Image retrieval Systems (CBIR). For this purpose, initially, a large variety of features are extracted from the regions of the pre-segmented images. Then, the feature set of each object class is learned using the Fuzzy Art Map Architecture, by identifying the weights of each feature for each object class.In the querying phase, trained set of feature weights are used to find the label of each object class. This task is achieved by combining the regions in the images and computing the maximum membership value for the compound regions, which correspond to a possible object class.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {248–251},
numpages = {4},
keywords = {region-based object retrieval, fuzzy ARTMAP, CBIR},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027584,
author = {Cooper, Matthew},
title = {Video Segmentation Combining Similarity Analysis and Classification},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027584},
doi = {10.1145/1027527.1027584},
abstract = {In this paper, we compare several recent approaches to video segmentation using pairwise similarity. We first review and contrast the approaches within the common framework of similarity analysis and kernel correlation. We then combine these approaches with non-parametric supervised classification for shot boundary detection. Finally, we discuss comparative experimental results using the 2002 TRECVID shot boundary detection test collection.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {252–255},
numpages = {4},
keywords = {temporal media indexing and segmentation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027585,
author = {Yu, Xinguo and Leong, Hon Wai and Xu, Changsheng and Tian, Qi},
title = {A Robust and Accumulator-Free Ellipse Hough Transform},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027585},
doi = {10.1145/1027527.1027585},
abstract = {The ellipse Hough transform (EHT) is a widely-used technique. Most of the previous modifications to the standard EHT improved either the voting procedure that computes the absolute measure function (AMF) or the peak detection of the AMF. However, existing EHTs are not robust for detecting partial slightly-oblique ellipses. This paper presents a Robust and Accumulator-Free Ellipse Hough Transform (RAF-EHT), an improved EHT that is robust even for partial slightly-oblique ellipses. Our RAF-EHT is based on two main ideas, namely, (1) an improved measure function (IMF) for handling the partiality and the obliqueness of ellipses, (2) a new accumulator-free computation scheme for finding the top k peaks of the IMF, without complex peak detection. Experimental results show that the RAF-EHT is more robust than the existing EHTs in detecting the partial slightly-oblique ellipses. In addition, the RAF-EHT needs only a little memory because it is accumulator-free.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {256–259},
numpages = {4},
keywords = {hough transform, accumulator-free, measure function, ellipse},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027586,
author = {Yu, Xinguo and Yan, Xin and Hay, Tze Sen and Leong, Hon Wai},
title = {3D Reconstruction and Enrichment of Broadcast Soccer Video},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027586},
doi = {10.1145/1027527.1027586},
abstract = {Recently, it has become a new trend to reconstruct sports video for various purposes. This paper presents a 3D reconstruction and enrichment system that not only reconstructs broadcast soccer video but also enriches reconstructed video with music and illustrations of the video contents. The system can reconstruct not only the goalmouth scene but also the midfield scene, which cannot be reconstructed by the existing systems. To quickly find the feature points for calibrating the camera, we propose a fast algorithm to detect the lines in the goalmouth scene and use the algorithm proposed in our previous papers to detect the partial ellipses in the midfield scene. The reconstruction is conducted on several video sequences of two scenes. The reconstructed videos eliminate the ball deformation and unnecessary camera changes through smoothing the camera parameters. This system also serves as an experimental system for our project that reconstructs the on-going soccer game in real time.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {260–263},
numpages = {4},
keywords = {calibration, 3D reconstruction, video enrichment, soccer video},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027587,
author = {Li, Ying and Dorai, Chitra},
title = {Analyzing Discussion Scene Contents in Instructional Videos},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027587},
doi = {10.1145/1027527.1027587},
abstract = {This paper describes our current effort on analyzing the contents of discussion scenes in instructional videos based on a clustering technique. Specifically, given a discussion scene pre-detected from an education or training video, we first apply a mode-based clustering approach to group all speech segments into an optimal number of clusters where each cluster contains speech from one speaker; we then analyze the discussion patterns in the scene, and subsequently classify it into either a 2-speaker or multi-speaker discussion. Encouraging classification results have been achieved on 122 discussion scenes detected from five IBM MicroMBA videos. Moreover, we have also observed fairly good performance on the speaker clustering scheme, which demonstrates the superiority of the proposed clustering approach. Undoubtedly, the discussion scene information output from this analysis scheme would facilitate the content browsing, searching and understanding of instructional videos.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {264–267},
numpages = {4},
keywords = {discussion scene, instructional video content analysis, discussion pattern detection, e-learning, speaker clustering},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027588,
author = {Coldefy, F. and Bouthemy, P.},
title = {Unsupervised Soccer Video Abstraction Based on Pitch, Dominant Color and Camera Motion Analysis},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027588},
doi = {10.1145/1027527.1027588},
abstract = {We present a soccer video abstraction method based on the analysis of the audio and video streams. This method could be applied to other sports as rugby or american football. The main contribution of this paper is the design of an unsupervised summarization method, and more specifically, the introduction of an efficient detector of excited speech segments. An excited commentary is supposed to correspond to an interesting moment of the game. It is simultaneously characterized by an increase of the pitch (or fundamental frequency) within the voiced segments and an increase of the energy supported by the harmonics of the pitch. The pitch is estimated from the autocorrelation function and its local increases are detected from a multiresolution technique. We introduce a specific energy measure for the voiced segments. A statistical analysis of the energy measures is performed to detect the most excited parts of the speech. A deterministic combination of excited speech detection, dominant color identification and camera motion analysis is then performed in order to discriminate between excited speech sequences of the game and excited speech sequences in commercials or in studio shots included in the processed TV programs.The method presented here does not need any learning stage. It has been tested on seven soccer videos for a total duration of almost 20 hours.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {268–271},
numpages = {4},
keywords = {video summarization, non verbal speech classification},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027589,
author = {Nair, Rahul},
title = {Calculation of an Aggregated Level of Interest Function for Recorded Events},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027589},
doi = {10.1145/1027527.1027589},
abstract = {As recording technology becomes pervasive there is a dramatic increase in the number of events being recorded in multimedia. The challenge now facing users is to quickly view the recorded content in the least amount of time. While there are several methods to analyze video based on ambient noise, scene changes, slide transitions, etc..., these techniques merely find features in the recording, they do not reveal which sections are important.This paper presents a method to calculate a Level Of Interest (LOI) function for an event by aggregating bookmarks made by the event attendees. The findings of a preliminary evaluation of the LOI function are also presented along with the design of an LOI based video browser.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {272–275},
numpages = {4},
keywords = {level of interest, skimming, video browsing, bookmark aggregation, visualization, multimedia},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027590,
author = {Yang, Xianfeng and Tian, Qi and Chang, Ee-Chien},
title = {A Color Fingerprint of Video Shot for Content Identification},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027590},
doi = {10.1145/1027527.1027590},
abstract = {In this paper we propose a novel space-time color feature representation for video shot and apply it to content identification. In this representation the shot is cut into <i>k</i> equal size segments, and each segment is represented by a blending image formed through averaging the pixels' values of each frame in this segment along time direction. Each blending image is then divided into equal size blocks, and two color patterns named major and minor colors among mean R,G,B are extracted for each block. Hence each shot can be represented by a fixed-length string. The experiment shows this representation is not only robust to image quality reduction, frame size and frame rate change, but also to color distortion such as brightness/contrast adjustment. We also give a video similarity measure based on this color feature to identify shot chunks. We conducted experiment on 100 video clips, and quite low error rates can be achieved when identifying small size shot chunks with significant color distortion. From the experiment we believe that this color feature is a compact and robust representation for video content, and effective for content identification.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {276–279},
numpages = {4},
keywords = {shot representation, color fingerprint, video content identification},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027591,
author = {Sood, Saurabh and Krishnamurthy, Ashok},
title = {A Robust On-the-Fly Pitch (OTFP) Estimation Algorithm},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027591},
doi = {10.1145/1027527.1027591},
abstract = {Pitch detection or fundamental frequency (f<inf>0</inf>) estimation is a classical research topic and has been extensively studied for many years. Pitch estimation by embedding speech signal into multiple state-space dimensions is a relatively recent technique. Also YIN pitch detection algorithm [1] has been cited recently as an improvement over other standard pitch estimation algorithms. In this paper an attempt is made to present a unifying view on some of these existing and seemingly disparate techniques. The unified view enables the development of robust formulations of some existing definitions and also helps to interpret the limitations of the classical/existing approaches in use. Application of the idea for a robust On-the-Fly pitch (OTFP) detection is demonstrated and comparison with robust YIN pitch detector has yielded encouraging results. The On-The-Fly imposes a constraint that pitch or aperiodicity estimates from past or future speech frames are not to be used at a post processing stage and OTFP outperforms the YIN estimator with this constraint.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {280–283},
numpages = {4},
keywords = {dimensionality reduction, phase-state embedding, speech, audio, fundamental frequency, pitch estimation, YIN, state-space embedding},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027592,
author = {Kwon, Kee-Koo and Im, Sung-Ho and Lim, Dong-Sun},
title = {Picture Quality Improvement in MPEG-4 Video Coding Using Simple Adaptive Filter},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027592},
doi = {10.1145/1027527.1027592},
abstract = {In this paper, we propose a novel post-filtering algorithm with low computational complexity that improves the visual quality of decoded images using block boundary classification and simple adaptive filter (SAF). At first, each block boundary is classified into smooth or complex sub-region. And for smooth-smooth sub-regions, the existence of blocking artifacts is determined using blocky strength. Simple adaptive filtering is processed in each block boundary. The proposed method processes adaptively, that is, a nonlinear 1-D 8-tap filter is applied to smooth-smooth sub-regions with blocking artifacts, and for smooth-complex or complex-smooth sub-regions, a nonlinear 1-D variant filter is applied to block boundary pixels so as to reduce the blocking and ringing artifacts. And for complex-complex sub-regions, a nonlinear 1-D 2-tap filter is only applied to adjust two block boundary pixels so as to preserve the image details. Experimental results show that the proposed algorithm produced better results than those of the conventional algorithms both subjective and objective viewpoints.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {284–287},
numpages = {4},
keywords = {deblocking, video coding, deringing, MPEG-4},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027593,
author = {Liu, Che-Bin and Ahuja, Narendra},
title = {Motion Based Retrieval of Dynamic Objects in Videos},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027593},
doi = {10.1145/1027527.1027593},
abstract = {Most existing video retrieval systems use low-level visual features such as color histogram, shape, texture, or motion. In this paper, we explore the use of higher-level motion representation for video retrieval of dynamic objects. We use three motion representations, which together can retrieve a large variety of motion patterns. Our approach works on top of a tracking unit and assumes that each dynamic object has been tracked and circumscribed in a minimal bounding box in each video frame. We represent the motion attributes of each object in terms of changes in the image context of its circumscribing box. The changes are described via motion templates [4], self-similarity plots [3], and image dynamics [9]. Initially, defined criteria of the retrieval process are interactively refined using relevance feedback from the user. Experimental results demonstrate the use of the proposed motion models in retrieving objects undergoing complex motion.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {288–291},
numpages = {4},
keywords = {motion analysis, content-based video retrieval},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027594,
author = {Jiang, Shuqiang and Ye, Qixiang and Gao, Wen and Huang, Tiejun},
title = {A New Method to Segment Playfield and Its Applications in Match Analysis in Sports Video},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027594},
doi = {10.1145/1027527.1027594},
abstract = {With the growing popularity of digitized sports video, automatic analysis of them need be processed to facilitate semantic summarization and retrieval. Playfield plays the fundamental role in automatically analyzing many sports programs. Many semantic clues could be inferred from the results of playfield segmentation. In this paper, a novel playfield segmentation method based on Gaussian mixture models (GMMs) is proposed. Firstly, training pixels are automatically sampled from frames. Then, by supposing that field pixels are the dominant components in most of the video frames, we build the GMMs of the field pixels and use these models to detect playfield pixels. Finally region-growing operation is employed to segment the playfield regions from the background. Experimental results show that the proposed method is robust to various sports videos even for very poor grass field conditions. Based on the results of playfield segmentation, match situation analysis is investigated, which is also desired for sports professionals and longtime fanners. The results are encouraging.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {292–295},
numpages = {4},
keywords = {GMMs, region growing, sports video, match analysis},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027595,
author = {Shimamura, Jun and Arakawa, Kenichi},
title = {Location-Aware Projection with Robust 3-D Viewing Point Detection and Fast Image Deformation},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027595},
doi = {10.1145/1027527.1027595},
abstract = {This paper describes a novel approach to the construction of a projector-based augmented reality environment. The approach is based on capturing the dynamic changes of surfaces and projecting the images within a large real environment using a system that includes a laser range finder and a projector, whose optical axes are integrated by mirrors. The proposed method offers two distinct advances: (1) robust 3-D viewing point detection from consecutive range images, and (2) fast view-driven image generation and presentation with view frustum clipping to measured surfaces. A prototype system is shown to confirm the feasibility of the method; it generates view-driven images to suit the user's viewing position that are then projected within dynamic real environment, in real-time.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {296–299},
numpages = {4},
keywords = {perceptual user detection, projector-based augmented reality, image deformation, ubiquitous},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027596,
author = {Chen, Gao and Zhang, Yong-dong and Lin, Shou-xun and Dai, Feng},
title = {Efficient Block Size Selection for MPEG-2 to H.264 Transcoding},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027596},
doi = {10.1145/1027527.1027596},
abstract = {In this paper, an efficient block size mode selection algorithm for the variable-sizes block-matching (VSBM) in the MPEG-2 to H.264 transcoding is presented. Depending on leveraging the available motion information carried by the MPEG-2 bit-streams, the proposed algorithm is used to determine which one of the 16x16, 16x8, 8x16, and 8x8 block size modes should be used for each macroblock (MB). The simulation results show that the performance of the proposed algorithm is close to that of a cascaded pixel-domain transcoder (CPDT) when all the seven block size modes are enabled and the exhaustively full search method is used to determine the best block size modes. The whole transcoding time can be efficiently reduced by 22% on the average while the bit rate is slightly increased (2.9%).},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {300–303},
numpages = {4},
keywords = {video transcoding, MPEG-2, mode decision, H.264},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027597,
author = {Liu, Zheng and Li, Xue and Dong, Zhaoyang},
title = {Enhancing Security of Frequency Domain Video Encryption},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027597},
doi = {10.1145/1027527.1027597},
abstract = {A potential security problem in frequency domain video encryption is that some trivial information such as the distribution of DCT coefficients may leak out secret. To illuminate this problem, we performed a successful attack on video using the distribution information of DCT coefficients. Then, according to the weak points discovered, a novel video encryption algorithm, working on run-length coded data, is proposed. It has amended identified security problems, while preserving high efficiency and the adaptability to cooperate with compression schemes.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {304–307},
numpages = {4},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027598,
author = {Leung, Tat-Wan and Ngo, Chong-Wah},
title = {Indexing and Matching of Polyphonic Songs for Query-by-Singing System},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027598},
doi = {10.1145/1027527.1027598},
abstract = {This paper investigates the issues in polyphonic popular song retrieval. The problems that we consider include singing voice extraction, melodic curve representation, and database indexing. Initially, polyphonic songs are decomposed into singing voices and instruments sounds in both time and frequency domains based on SVM and ICA. The extracted singing voices are represented as two melodic curves that model the statistical mean and neighborhood similarity of notes. To speed up the matching between songs and query, we further adopt proportional transportation distance to index the songs as vantage point trees. Encouraging results have been obtained through experiments.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {308–311},
numpages = {4},
keywords = {ICA, proportional transportation distance, melodic curve},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027599,
author = {Yi, Haoran and Rajan, Deepu and Chia, Liang-Tien},
title = {Automatic Extraction of Motion Trajectories in Compressed Sports Videos},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027599},
doi = {10.1145/1027527.1027599},
abstract = {This paper presents an algorithm for automatically extracting significant motion trajectories in sports videos. Our approach consists of four stages: global motion estimation, motion blob detection, trajectory evolution and trajectory refinement. Global motion is estimated from the motion vectors in the compressed video using an iterative algorithm with robust outlier rejection. A statistical hypothesis test is carried out within the Block Rejection Map(<i>BRM</i>), which is the by-product of the global motion estimation, for the detection of motion blobs. Trajectory evolution is the process in which the motion blobs are either appended to an existing trajectory or are considered to be the beginning of a new trajectory based on its distance to an adaptive trajectory description. Finally, the extracted motion trajectories are refined using a Kalman filter. Experimental results on both indoor and outdoor sports videos demonstrate the effectiveness and efficiency of the proposed method.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {312–315},
numpages = {4},
keywords = {MPEG-7, motion descriptors, motion trajectory, Kalman filter},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027600,
author = {Ng, Jamie and Rajaraman, Kanagasabai and Altman, Edward},
title = {Mining Emergent Structures from Mixed Media For Content Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027600},
doi = {10.1145/1027527.1027600},
abstract = {In this paper we present a novel approach for retrieval of thematic video content from mixed media. Based on the principles of conceptual blending, information from different media is mined for emergent structures from mixed media. We have built a system, called OntoMedia, to test the efficacy of this approach over traditional methods for media retrieval. The system employs an ontology as a unified indexing scheme for associated text documents for the mixed media content. By applying graph theoretic path finding operations to the ontology to process queries for video content, we show that the system is able to synchronize information from multiple media sources and retrieve semantically related content across media types. A trial experiment was carried out using mixed media courseware from the Singapore-MIT Alliance (SMA) distance education course. Results showed that information retrieval along a path performs significantly better than keyword-based and ontology-focused searches.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {316–319},
numpages = {4},
keywords = {unified indexing, video retrieval, mixed media mining, ontology},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027601,
author = {Wu, Jun and Hua, Xian-Sheng and Zhang, Hong-Jiang and Zhang, Bo},
title = {An Online-Optimized Incremental Learning Framework for Video Semantic Classification},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027601},
doi = {10.1145/1027527.1027601},
abstract = {This paper considers the problems of feature variation and concept uncertainty in typical learning-based video semantic classification schemes. We proposed a new online semantic classification framework, termed OOIL (for Online-Optimized Incremental Learning), in which two sets of optimized classification models, local and global, are online trained by sufficiently exploiting both local and global statistic characteristics of videos. The global models are pre-trained on a relatively small set of pre-labeled samples. And the local models are optimized for the under-test video or video segment by checking a small portion of unlabeled samples in this video, while they are also applied to incrementally update the global models. Experiments have illustrated promising results on simulated data as well as real sports videos.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {320–323},
numpages = {4},
keywords = {video semantic classification, incremental learning, video analysis, concept drifting},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027602,
author = {Nwe, Tin Lay and Shenoy, Arun and Wang, Ye},
title = {Singing Voice Detection in Popular Music},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027602},
doi = {10.1145/1027527.1027602},
abstract = {We propose a novel technique for the automatic classification of vocal and non-vocal regions in an acoustic musical signal. Our technique uses a combination of harmonic content attenuation using higher level musical knowledge of key followed by sub-band energy processing to obtain features from the musical audio signal. We employ a Multi-Model Hidden Markov Model (MM-HMM) classifier for vocal and non-vocal classification that utilizes song structure information to create multiple models as opposed to conventional HMM training methods that employ only one model for each class. A statistical hypothesis testing approach followed by an automatic bootstrapping process is employed to further improve the accuracy of classification. An experimental evaluation on a database of 20 popular songs shows the validity of the proposed approach with an average classification accuracy of 86.7%.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {324–327},
numpages = {4},
keywords = {bootstrapping, HMM, singing voice, song structure},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027603,
author = {Duan, Ling-Yu and Xu, Min and Tian, Qi and Xu, Chang-Sheng},
title = {Nonparametric Motion Model with Applications to Camera Motion Pattern Classification},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027603},
doi = {10.1145/1027527.1027603},
abstract = {Motion information is a powerful cue for visual perception. In the context of video indexing and retrieval, motion content serves as a useful source for compact video representation. There has been a lot of literature about parametric motion models. However, it is hard to secure a proper parametric assumption in a wide range of video scenarios. Diverse camera shots and frequent occurrences of bad optical flow estimation motivate us to develop nonparametric motion models. In this paper, we employ the mean shift procedure to propose a novel nonparametric motion representation. With this compact representation, various motion characterization tasks can be achieved by machine learning. Such a learning mechanism can not only capture the domain-independent parametric constraints, but also acquire the domain-dependent knowledge to tolerate the influence of bad dense optical flow vectors or block-based MPEG motion vector fields (MVF). The proposed nonparametric motion model has been applied to camera motion pattern classification on 23191 MVF extracted from MPEG-7 dataset.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {328–331},
numpages = {4},
keywords = {mean shift, camera motion, nonparametric motion analysis},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027604,
author = {Dyaberi, Vidyarani M. and Sundaram, Hari and James, Jodi and Qian, Gang},
title = {Phrase Structure Detection in Dance},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027604},
doi = {10.1145/1027527.1027604},
abstract = {This paper deals with phrase structure detection in contemporary western dance. Phrases are a sequence of movements that exist at a higher semantic abstraction than gestures. The problem is important since phrasal structure in dance, plays a key role in communicating meaning. We detect two fundamental dance structures - ABA and the Rondo, as they form the basis for more complex movement sequences. There are two key ideas in our work - (a) the use of a topological framework for deterministic structure detection and (b) novel phrasal distance metrics. The topological graph formulation succinctly captures the domain knowledge about the structure. We show how an objective function can be constructed given the topology. The minimization of this function yields the phrasal structure and phrase boundaries. The distance incorporates both movement and hierarchical body structure. The results are excellent with low median error of 7% (ABA) and 15% (Rondo).},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {332–335},
numpages = {4},
keywords = {topological graph, phrase, structure, dance},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027605,
author = {Jin, Wanjun and Shi, Rui and Chua, Tat-Seng},
title = {A Semi-Na\"{\i}ve Bayesian Method Incorporating Clustering with Pair-Wise Constraints for Auto Image Annotation},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027605},
doi = {10.1145/1027527.1027605},
abstract = {We propose a novel approach for auto image annotation. In our approach, we first perform the segmentation of images into regions, followed by clustering of regions, before learning the relationship between concepts and region clusters using the set of training images with pre-assigned concepts. The main focus of this paper is two-fold. First, in the learning stage, we perform clustering of regions into region clusters by incorporating pair-wise constraints which are derived by considering the language model underlying the annotations assigned to training images. Second, in the annotation stage, we employ a semi-na\"{\i}ve Bayes model to compute the posterior probability of concepts given the region clusters. Experiment results show that our proposed system utilizing these two strategies outperforms the state-of-the-art techniques in annotating large image collection.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {336–339},
numpages = {4},
keywords = {semi-supervised clustering, image annotation, semi-na\"{\i}ve Bayes, pair-wise constraint},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027606,
author = {Hu, Yiqun and Chia, Liang-Tien and Rajan, Deepu},
title = {Region-of-Interest Based Image Resolution Adaptation for MPEG-21 Digital Item},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027606},
doi = {10.1145/1027527.1027606},
abstract = {The upcoming MPEG-21 standard proposes a general framework for augmented use of multimedia services in different network environments, for various users with various terminal devices. In the context of image adaptation, terminals with different screen size limitation require the multimedia adaptation engine to adapt image resources intelligently. Saliency map based visual attention analysis provides some intelligence for finding the attention area within the image. In this paper, we improved the standard MPEG-21 metadata driven adaptation engine by using enhanced saliency map based visual attention model which provides a mean to intelligently adapt JPEG2000 image resolution for different terminal devices with varying screen size according to human visual attention.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {340–343},
numpages = {4},
keywords = {MPEG-21, saliency map, intelligent resolution, image adaptation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027607,
author = {Li, Na and Bu, Jiajun and Chen, Chun},
title = {A Reversible Color Transform for 16-Bit-Color Picture Coding},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027607},
doi = {10.1145/1027527.1027607},
abstract = {This paper proposes a reversible color transform for 16-bit-color (hicolor) picture coding. The work is motivated by the increasing needs of multimedia applications on low-end devices such as mobile phones and PDAs. They have limited resources and up to 16-bit displays. Current image/video coding systems can hardly manage this case effectively. To enhance coding efficiency on this condition, a reversible color transform customized for hicolor systems is derived from Y'CrCb and JPEG2000 Reversible Component Transformation (RCT). The transform proves simple but highly-decorrelating, and able to reduce the computation time of decoding. Comparison experiment demonstrates the effectiveness of this transform with equal or even higher coding efficiency on low-end devices with 16-bit display mode.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {344–347},
numpages = {4},
keywords = {low-end, picture coding, coding efficiency, hicolor image, 16-bit color, reversible color transform},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027608,
author = {Monay, Florent and Gatica-Perez, Daniel},
title = {PLSA-Based Image Auto-Annotation: Constraining the Latent Space},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027608},
doi = {10.1145/1027527.1027608},
abstract = {We address the problem of unsupervised image auto-annotation with probabilistic latent space models. Unlike most previous works, which build latent space representations assuming equal relevance for the text and visual modalities, we propose a new way of modeling multi-modal co-occurrences, constraining the definition of the latent space to ensure its consistency in semantic terms (words), while retaining the ability to jointly model visual information. The concept is implemented by a linked pair of Probabilistic Latent Semantic Analysis (PLSA) models. On a 16000-image collection, we show with extensive experiments that our approach significantly outperforms previous joint models.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {348–351},
numpages = {4},
keywords = {automatic annotation of images, semantic indexing, PLSA},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027609,
author = {Paraskevi, Tzouveli and Klimis, Ntalianis and Stefanos, Kollias},
title = {Security of Human Video Objects by Incorporating a Chaos-Based Feedback Cryptographic Scheme},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027609},
doi = {10.1145/1027527.1027609},
abstract = {Security of multimedia files attracts more and more attention and many encryption methods have been proposed in literature. However most cryptographic systems deal with multimedia files as binary large objects, without taking into consideration regions of semantic information. These regions may need better protection or can be the only regions that need protection, depending on the specific application. Towards this direction, in this paper we propose a human video object encryption system based on the chaotic logistic map. Initially face regions are efficiently detected and afterwards body regions are extracted, using geometric information of the location of face regions. Next the pixels of extracted human video objects are encrypted using an iterative cipher module, which is based on a feedback mechanism responsible for mixing the current encryption parameters with encrypted information of the previous step. The system presents robustness against known cryptanalytic attacks, and can save us a great amount of computational resources and time devoted for encrypting the whole contents of a multimedia file.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {352–355},
numpages = {4},
keywords = {logistic map, face and body detection, chaos, human video objects, cryptographic systems},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027610,
author = {Wang, Yuhang and Makedon, Fillia and Chakrabarti, Amit},
title = {R*-Histograms: Efficient Representation of Spatial Relations between Objects of Arbitrary Topology},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027610},
doi = {10.1145/1027527.1027610},
abstract = {Representation of relative spatial relations between objects is often required in many multimedia database applications because spatial relations between objects in an image convey important information about the image. Quantitative representation of spatial relations taking into account shape, size, orientation and distance is often required. The R-Histogram is such a quantitative representation of spatial relations between two objects. However, this method only considers pixels on the object boundary, assuming that the objects are homeomorphic to a 2-ball. For objects with more complicated topology, we propose in this paper the R*-Histogram, a new extension to the R-Histogram. The R*-Histogram generalizes the R-Histogram by taking into account all the pixels in the objects. We also introduce an efficient O(kN log N) time algorithm to compute the R*-Histogram, which is asymptotically faster than the original O(N<sup>2</sup>) time algorithm for the R-Histogram even when k=O(n). Here, N=n<sup>2</sup> denotes the number of pixels in the processed n x n image and k is the number of different directions considered. The effectiveness of the R*-Histogram is evaluated empirically with a Query By Example (QBE) system on a database of 2000 synthetic images containing objects with complicated shape and topology. Experiments have shown that the similarly search results match human intuition very well.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {356–359},
numpages = {4},
keywords = {spatial relations, efficient algorithms, similarity search, R*-Histogram, image retrieval},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027611,
author = {Yin, Lijun and Weiss, Kenny},
title = {Generating 3D Views of Facial Expressions from Frontal Face Video Based on Topographic Analysis},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027611},
doi = {10.1145/1027527.1027611},
abstract = {In this paper, we report our newly developed 3D face modeling system with arbitrary expressions in a high level of detail using the topographic analysis and mesh instantiation process. Given a sequence of images of facial expressions at frontal views, we automatically generate 3D expressions at arbitrary views. Our face modeling system consists of two major components: facial surface representation using topographic analysis and generic model individualization based on labeled surface features and surface curvatures. The realism of the generated individual model is demonstrated through 3D views of facial expressions in videos. This work targets the accurate modeling of face and face expression for human computer interaction and 3D face recognition.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {360–363},
numpages = {4},
keywords = {facial expression, face modeling, feature analysis},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027612,
author = {Li, Tao and Ogihara, Mitsunori},
title = {Music Artist Style Identification by Semi-Supervised Learning from Both Lyrics and Content},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027612},
doi = {10.1145/1027527.1027612},
abstract = {Efficient and intelligent music information retrieval is a very important topic of the 21st century. With the ultimate goal of building personal music information retrieval systems, this paper studies the problem of identifying "similar" artists using both lyrics and acoustic data. The approach for using a small set of labeled samples for the seed labeling to build classifiers that improve themselves using unlabeled data is presented. This approach is tested on a data set consisting of 43 artists and 56 albums using artist similarity provided by All Music Guide. Experimental results show that using such an approach the accuracy of artist similarity classifiers can be significantly improved and that artist similarity can be efficiently identified.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {364–367},
numpages = {4},
keywords = {lyrics, semi-supervised learning, artist style},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027613,
author = {Yang, Meng and Wildemuth, Barbara M. and Marchionini, Gary},
title = {The Relative Effectiveness of Concept-Based versus Content-Based Video Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027613},
doi = {10.1145/1027527.1027613},
abstract = {Three video search systems were compared in the interactive search task at the TRECVID 2003 workshop: a <i>text-only</i> system, which searched video shots through transcripts; a <i>features-only</i> system, which searched video shots through 16 video content features (e.g., airplanes and people); and a <i>combined</i> system, which searched through both transcripts and content features. 36 participants each completed 12 video search tasks. The hypothesis that the combined system would perform better than both the text-only and the features-only systems was not supported, and large topic effects were found. Further analysis showed that concept-based video retrieval worked best for <i>specific</i> topics, whereas the hybrid retrieval techniques which combine both concept- and content-based video retrieval showed some advantage when searching for <i>generic</i> topics. The results have implications for topic/task analysis for video retrieval research, and also for the implementation of hybrid video retrieval systems.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {368–371},
numpages = {4},
keywords = {hybrid video retrieval, TRECVID, user study},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027614,
author = {Shyu, Mei-Ling and Chen, Shu-Ching and Chen, Min and Zhang, Chengcui},
title = {Affinity Relation Discovery in Image Database Clustering and Content-Based Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027614},
doi = {10.1145/1027527.1027614},
abstract = {In this paper, we propose a unified framework, called <i>Markov Model Mediator</i> (MMM), to facilitate image database clustering and to improve the query performance. The structure of the MMM framework consists of two hierarchical levels: local MMMs and integrated MMMs, which model the affinity relations among the images within a single image database and within a set of image databases, respectively, via an effective data mining process. The effectiveness and efficiency of the MMM framework for database clustering and image retrieval are demonstrated over a set of image databases which contain various numbers of images with different dimensions and concept categories.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {372–375},
numpages = {4},
keywords = {image database clustering, content-based image retrieval, markov model mediators (MMMs)},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027615,
author = {De Smet, Patrick and Rooms, Filip and Luong, Hi\^{e}p Quang and Philips, Wilfried},
title = {Do Not Zero-Pute: An Efficient Homespun MPEG-Audio Layer II Decoding and Optimization Strategy},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027615},
doi = {10.1145/1027527.1027615},
abstract = {In this paper we point out that the general principle "do not compute what you do not need to compute" can be applied easily and successfully within a MPEG audio decoding strategy. More specifically, we will discuss the problem of eliminating costly computation cycles being wasted at processing useless zero-valued data. Hence, the title: "do not zero-pute". At first, this may all sound somewhat obvious or trivial. Indeed, this can be true in many cases, but experience gathered in various teaching related projects during several academic years has also lead us to believe the opposite. Moreover, a survey of the existing literature quickly reveals that the approach discussed below has not been investigated and documented properly. Although we will only illustrate our optimization approach by discussing the MPEG-audio layer II decoding process in detail, we hope the reader will be able to apply, extend, and implement the basic principles presented here within many other applications.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {376–379},
numpages = {4},
keywords = {optimized decoder, MPEG audio},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027617,
author = {Wu, Yongdong and Bao, Feng},
title = {Collusion Attack on a Multi-Key Secure Video Proxy Scheme},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027617},
doi = {10.1145/1027527.1027617},
abstract = {In ACM Multimedia'2002, a video proxy scheme was proposed for secure video delivery. In the scheme, a video is cached in proxies in encrypted form so that it remains non-disclosed even if the proxies are compromised. The proxies re-encrypt the video before its distribution, and different clients would receive different keys for the protected video. In this paper we present a security analysis on the scheme and show that the scheme is subject to collusion attack. Two or more clients working together can find out video server's secret keys and hence compromise the system. The countermeasure to the collusion attack is presented.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {380–383},
numpages = {4},
keywords = {collusion attack},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027618,
author = {Parker, J. R. and Chung, Keith},
title = {Index-Frame Audio Transmission},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027618},
doi = {10.1145/1027527.1027618},
abstract = {Sending audio data over a computer network consumes a large amount of bandwidth, and so compression strategies are regularly built into audio file formats and transmission software. In some environments, the basic nature of the sound does not change significantly; for example, phone lines deal frequently with voice transmission. By matching input audio blocks against those in a table, we can transmit the table indices only, and audio can be synthesized at the receiving end by simple table look-up. This has a number of potentially interesting applications.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {384–387},
numpages = {4},
keywords = {multimedia, audio transmission, encryption, audio synthesis, compression},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027619,
author = {Li, Frederick W.B. and Li, Lewis W.F. and Lau, Rynson W.H.},
title = {Supporting Continuous Consistency in Multiplayer Online Games},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027619},
doi = {10.1145/1027527.1027619},
abstract = {Multiplayer online games have become very popular in recent years. However, they generally suffer from network latency problem. If a player changes its states, it will take some time before the changes are reflected to other concurrent players. This significantly affects the interactivity of the game. Sometimes, it may even cause disputes among the players. In this paper, we present a continuous consistency control mechanism to support collaborative game applications. Specifically, we propose a relaxed consistency control model for continuous events. Based on this model, we have developed a method to provide a global-wise continuous synchronization on the states of dynamic game objects presented among concurrent game players. We show the performance of the proposed method through some experiments.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {388–391},
numpages = {4},
keywords = {distributed synchronization, collaborative gaming, distributed virtual environments, consistency control},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027620,
author = {Kanda, Toshikatsu and Shimamura, Kazunori},
title = {Application of Packet Assembly Technology to Digital Video and VoIP},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027620},
doi = {10.1145/1027527.1027620},
abstract = {The Internet is composed of many kinds of networks and the networks are composed of network nodes such as routers. Routers use processor power for forwarding each packet with any size. At that time, node processor would be a bottleneck in respect to the high throughput if there would be too many packets to forward. Then, authors propose the packet assembly method. This aims to decrease the number of packets for the reduction of processor load, based on the fact that there are many packets much smaller than maximum transferable unit in backbone network.For the examination of the packet assembly, authors conducted two experiments. One is the experiment that conducts the packet assembly method for the traffic of digital video, and it provides the comparison of the image of digital video forwarded via routers without packet assembly with the one with packet assembly, and transition of edge router load and core router load. The other is the experiment that conducts the packet assembly method for the traffic of VoIP, and investigated about the influence on PSQM score, latency, and jitter.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {392–395},
numpages = {4},
keywords = {load reduction, performance improvement, packet assembly},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027621,
author = {Jin, Shudong},
title = {Replication of Partitioned Media Streams in Wireless Ad Hoc Networks},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027621},
doi = {10.1145/1027527.1027621},
abstract = {Media streaming in wireless ad hoc networks is challenging due to the stringent resource restrictions and the decentralized architecture. To support long and high-quality streams, one viable approach is <i>divide-and-conquer</i>. A media stream is partitioned into segments, and then the segments are replicated in a network and served in a peer-to-peer fashion. It alleviates resource requirements on light-weight devices, improves load balancing, and provides an opportunity for fine-grain replication, among others. This paper describes a peer-to-peer service model using this approach, and in particular, studies replication strategies for the segments. We exploit topological properties of the underlying networks, and exploit correlation of streaming access. Several strategies are described and evaluated. A novel strategy uses adaptive and selective replication. It infers end-host clustering from hop-distance, and selectively replicates media segments to avoid starving any of them. Preliminary simulation study demonstrates its effectiveness in minimizing the cost to discover and retrieve media data.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {396–399},
numpages = {4},
keywords = {topology, data replication, multimedia streaming},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027622,
author = {Liu, Tiecheng and Choudary, Chekuri},
title = {Real-Time Content Analysis and Adaptive Transmission of Lecture Videos for Mobile Applications},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027622},
doi = {10.1145/1027527.1027622},
abstract = {With the popularity of e-learning systems, there is an increasing demand on effectively utilizing instructional videos to augment distance learning experiences. This paper addresses some special issues in processing and streaming lecture videos, and provides a new approach for real-time content analysis and adaptive transmission of these videos over wireless networks. A content-based analysis method and a buffer-based model are provided to detect content regions and to select content significant key frames, and an adaptive feedback control scheme is applied to transmit properly compressed key frames to accommodate dynamically changing bandwidths in wireless environments, with consideration of the limitations of resolution and computing capability of mobile devices. We demonstrate the effectiveness and scalability of our system in experimental results of adaptive transmission of instructional videos over 802.11b wireless networks to mobile devices.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {400–403},
numpages = {4},
keywords = {e-learning, wireless communications, educational videos, video streaming, content analysis},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027623,
author = {Majumdar, Abhik and Wang, Jiajun and Ramchandran, Kannan},
title = {Drift Reduction in Predictive Video Transmission Using a Distributed Source Coded Side-Channel},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027623},
doi = {10.1145/1027527.1027623},
abstract = {Predictive video codecs such as MPEG and H.26x are very susceptible to prediction mismatch between encoder and decoder or "drift" when there are packet losses, leading to a significant reduction in the decoded quality. In this paper, we propose a method to reduce the drift in these codecs by sending extra information over a side-channel. Using principles from distributed source coding, we send another description of the video sequence (at a lower rate) over the side-channel which can correct for errors in the decoded frame and thereby mitigate the drift. Simulation results using our techniques show significant gains in performance over conventional error protection schemes such as Forward Error Correction codes under reasonable latency constraints.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {404–407},
numpages = {4},
keywords = {drift reduction, distributed source coding, side-channel},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027624,
author = {Atrey, Pradeep K. and Kankanhalli, Mohan S.},
title = {Probability Fusion for Correlated Multimedia Streams},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027624},
doi = {10.1145/1027527.1027624},
abstract = {The fusion of multiple correlated observations of a multimedia system is a research problem arising in many multimedia applications. In this paper, we propose a novel framework for the probabilistic fusion of correlated multimedia observations. Assuming that each of the media stream has a priori probability of achieving the goal and their underlying correlations are known, our framework fuses the individual probabilities using the quantitative correlation based on a Bayesian approach. The simulation results show that fewer highly-positively-correlated observations better achieve a specified goal when compared to the use of a larger number of observations with low correlation.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {408–411},
numpages = {4},
keywords = {information fusion, experiential sampling, correlated probability},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027625,
author = {Ye, Song and Makedon, Fillia},
title = {Collaboration-Aware Peer-to-Peer Media Streaming},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027625},
doi = {10.1145/1027527.1027625},
abstract = {Peer-to-Peer(P2P) media streaming has emerged as a promising solution to media streaming in large distributed systems such as the Internet. Several P2P media streaming solutions have been proposed by researchers, however they all implicitly assume peers are collaborative, thus they suffer from the selfish peers that are not willing to collaborate. In this paper we introduce an incentive mechanism to urge selfish peers to behave collaboratively. It combines the traditional reputation-based approach and an online streaming behavior monitoring scheme. Our preliminary results show that the overall performance achieved by collaborative peers do not suffer from the existence of non-collaborative peers. The incentive mechanism is orthogonal to the existing media streaming solutions and can be integrated into them.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {412–415},
numpages = {4},
keywords = {media streaming, collaboration, reputation, peer-to-peer},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027626,
author = {Garudadri, Harinath and Sagetong, Phoom and Nanda, Sanjiv},
title = {Video Transport over Wireless Networks},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027626},
doi = {10.1145/1027527.1027626},
abstract = {In this paper, we propose an efficient scheme to transport video over wireless networks, specifically cdma2000® 1x. Speech transmission over cdma2000® uses a variable rate voice coder (vocoder) over a channel with multiple fixed rates. We apply these ideas to compressed video transmission over wireless IP networks. Explicit Bit Rate (EBR) video compression is designed to match the video encoder output to a set of fixed channel rates. We show that in comparison with VBR video transmission over a fixed rate wireless channel, EBR video transmission provides improved error resilience, reduced latency and improved efficiency.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {416–419},
numpages = {4},
keywords = {error resilience, constant bitrate, H.264, video compression, variable bitrate, VoIP, MPEG-4},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027627,
author = {Liu, Tiecheng and Nelakuditi, Srihari},
title = {Disruption-Tolerant Content-Aware Video Streaming},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027627},
doi = {10.1145/1027527.1027627},
abstract = {Communication between a pair of nodes in the network may get disrupted due to failures of links/nodes resulting in zero effective bandwidth between them during the recovery period. It has been observed that such disruptions are not too uncommon and may last from tens of seconds to minutes. Even an occasional such disruption can drastically degrade the viewing experience of a participant in a video streaming session particularly when a sequence of frames central to the story are lost during the disruption. The conventional approach of prefetching video frames and patching lost ones with retransmissions is not always viable when disruptions are localized and experienced only by a few among many receivers. Error spreading approaches that distribute the losses across the video work well only when the disruptions are quite short. As a better alternative, we propose a disruption-tolerant content-aware video streaming approach that combines the techniques of content summarization and error spreading to enhance viewers experience even when the disruptions are long. We introduce the notion of "substitutable content summary frames" and provide a method to select these frames and also their transmission order to mitigate the impact of a disruption. In the event of a disruption, the already received summary frames are played by the client during disruption and near normal playback is resumed after the disruption. We evaluate our approach and demonstrate that it provides acceptable viewing experience with minimal startup latency and client buffer.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {420–423},
numpages = {4},
keywords = {disruption-tolerant streaming, video key frames, video streaming, network disruption},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027629,
author = {Zou, Fuhao and Lu, Zhengding and Ling, Hefei},
title = {A Multiple Watermarking Algorithm Based on CDMA Technique},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027629},
doi = {10.1145/1027527.1027629},
abstract = {This paper proposes a multiple watermarking algorithm based on code division multiple access (CDMA) technique. Before the watermark embedded, each user uses his private key as a seed to generate an address code which is subjected to pseudorandom noise distribution. Each watermark is modulated into a carrier signal with its corresponding address code. And then these carrier signals are added to host media (e.g. image, video and audio). During watermark detection, using the same address code, each user extracts his watermark from the detected media via calculating the correlation coefficient between address code and watermarked vector of the detected media. Each user can embed and extract his watermark independently, regardless of others. The experimental results show that this scheme can embed and extract watermarks independently for each user and is capable for multiple watermarking.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {424–427},
numpages = {4},
keywords = {code division multiple access, address code, multiple watermarking, correlation coefficient},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027630,
author = {Hu, Shiyan},
title = {Key-Dependant Decomposition Based Image Watermarking},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027630},
doi = {10.1145/1027527.1027630},
abstract = {In this paper, we propose a novel image watermarking algorithm, which is based on the scheme where the watermark is embedded into projection of an image onto the secret set of key-dependant basis functions. We propose a key-dependant image decomposition method, which involves solving a bottleneck hamiltonian path problem by an ant colony optimization technique. Combined with the decomposition technique, the original scheme is significantly improved on the aspects of speed, capacity and security. In particular, our algorithm usually shortens the running time of the original scheme by a factor of several hundred.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {428–431},
numpages = {4},
keywords = {image watermarking, key-dependant decomposition},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027631,
author = {Chen, Shu-Ching and Shyu, Mei-Ling and Zhao, Na},
title = {SMARXO: Towards Secured Multimedia Applications by Adopting RBAC, XML and Object-Relational Database},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027631},
doi = {10.1145/1027527.1027631},
abstract = {In this paper, a framework named SMARXO is proposed to address the security issues in multimedia applications by adopting RBAC (Role-Based Access Control), XML, and Object-Relational Databases. Compared with the other existing security models or projects, SMARXO can deal with more intricate situations. First, the image object-level security and video scene/shot-level security can be easily achieved. Second, the temporal constrains and IP address restrictions are modeled for the access control purpose. Finally, XML queries can be performed such that the administrators can proficiently retrieve useful information from the security roles and policies.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {432–435},
numpages = {4},
keywords = {XML, multimedia security, object-relational databases, role-based access control (RBAC)},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027632,
author = {Wang, Xin-Jing and Ma, Wei-Ying and He, Qi-Cai and Li, Xing},
title = {Grouping Web Image Search Result},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027632},
doi = {10.1145/1027527.1027632},
abstract = {In this paper, we propose a Web image search result organizing method to facilitate user browsing. We formalize this problem as a salient image region pattern extraction problem. Given the images returned by Web search engine, we first segment the images into homogeneous regions and quantize the environmental regions into image codewords. The salient codeword "phrases" are then extracted and ranked based on a regression model learned from human labeled training data. According to the salient "phrases", images are assigned to different clusters, with the one nearest to the centroid as the entry for the corresponding cluster. Satisfying experimental results show the effectiveness of our proposed method.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {436–439},
numpages = {4},
keywords = {image clustering, regression analysis, search result organization, image representation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027633,
author = {Solon, Anthony and McKevitt, Paul and Curran, Kevin},
title = {Mobile MultiModal Presentation},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027633},
doi = {10.1145/1027527.1027633},
abstract = {This paper presents the latest research into a mobile intelligent multimedia presentation system called TeleMorph which can dynamically generate a multimedia presentation using output modalities that are determined by the bandwidth available on a mobile device's wireless connection. To demonstrate the effectiveness of this research TeleTuras, a tourist information guide will implement the solution provided by TeleMorph, thus demonstrating its effectiveness. This paper highlights issues surrounding such a system &amp; introduces the architecture.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {440–443},
numpages = {4},
keywords = {HCI, bandwidth determined multimodal presentation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027634,
author = {DAIGO, Shinji and OZAWA, Shinji},
title = {Automatic Pan Control System for Broadcasting Ball Games Based on Audience's Face Direction},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027634},
doi = {10.1145/1027527.1027634},
abstract = {We propose an automatic pan control system for broadcasting ball games by tracking face direction of audience. Presuming that the audience's face is directed to a notable play, we can shoot a broadcasting video by controlling the camera toward the audience's face direction. In our method, a court sensor which detects rough region where players exist is used in addition to the face sensor in order to obtain higher accuracy. Based on these sensors, the broadcasting video is generated by cylindrical mosaicing off-line. We conducted objective and subjective evaluation experiments and the result shows that our approach is better than previously proposed methods in respect of stable tracking and easy watching. Conclusively our method is as effective as the optimum camerawork.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {444–447},
numpages = {4},
keywords = {automatic shooting, template matching, face direction, cylindrical panoramas},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027635,
author = {Zheng, Jiang Yu and Zhou, Yu},
title = {Scene Tunnels for Seamless Virtual Tour},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027635},
doi = {10.1145/1027527.1027635},
abstract = {This paper proposes a visual representation named scene tunnel to archive and visualize urban scenes for Internet based virtual tour. We scan cityscapes using multiple cameras on a vehicle that moves along streets, and generate scene archive more complete than a route panorama. The scene tunnel can cover high architectures and various object aspects. It contains much less data than video, which is suitable for image transmission and rendering over the Internet. It has a uniformed resolution along the camera path and provides continuous views for virtual traversing of a real city. We have developed image acquisition methods from slit setting, view scanning, to image integration. We have also achieved city visualization with scene tunnels on the Internet by transforming view, streaming data, and providing interactions.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {448–451},
numpages = {4},
keywords = {navigation, scene representation, scene tunnel, visualization, route panorama, internet media},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027636,
author = {Shah-Hosseini, Amin and Knapp, Gerald M.},
title = {Learning Image Semantics from Users Relevance Feedback},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027636},
doi = {10.1145/1027527.1027636},
abstract = {In this paper, a learning method is proposed to improve the retrieval process in image databases. This method uses the search transaction logs in the system and user relevance feedback scores to create a semantic space of the image database. The semantic space includes many semantic classes and all the images in the database are clustered to these classes with different membership values. The sparsity problem in the transaction logs data is solved by filling the missing values by an estimation based on the image contents and image similarities. A Fuzzy clustering algorithm is developed to create the semantic classes and find image memberships in the classes.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {452–455},
numpages = {4},
keywords = {clustering with missing values, image semantics, image retrieval},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027637,
author = {Lopez-Gulliver, Roberto and Tochigi, Hiroko and Sato, Tomohiro and Suzuki, Masami and Hagita, Norihiro},
title = {SenseWeb: Collaborative Image Classification in a Multi-User Interaction Environment},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027637},
doi = {10.1145/1027527.1027637},
abstract = {The SenseWeb system is a multi-user interactive information environment. Aimed at supporting the sharing of experiences and collaboration among multiple users allowing them to simultaneously interact with digital multimedia elements by using their bare hands. By sharing a common information space on a large screen, users can cooperatively search, filter, classify and interact with multimedia data in a natural and intuitive way. This paper introduces the system as well as preliminary experiment results to assess its effectiveness as a simultaneous multi-user interaction environment in collaborative image classification tasks. Results confirm our expectations of improvements in task completion time, ease of use and user satisfaction over multi-user but one-at-the-time interaction scenarios.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {456–459},
numpages = {4},
keywords = {multi-user, collaborative interaction, touch-based interface, large screen display},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027638,
author = {Adams, Brett and Venkatesh, Svetha},
title = {Director in Your Pocket: Holistic Help for the Hapless Home Videographer},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027638},
doi = {10.1145/1027527.1027638},
abstract = {We present a new aspect of our ongoing research aimed at providing technology for the amateur home videographer. We aim to enable the production of quality video presentations that are well structured and use the expressive properties of the medium to full effect, regardless of the technical or artistic abilities of the user. This task requires that help be given to the user at or before capture time. We use a PDA platform to deliver 3d visualizations of <i>shot directives</i>, instructions to the user about the type of footage to capture, and discuss issues connected with realizing high-level representations in concrete first person animations. Additionally, we discuss the mechanism for mating that metadata with captured footage and implementation issues.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {460–463},
numpages = {4},
keywords = {video editing, video analysis, narrative structure, media aesthetics, home movies, cinematography, PDA},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027639,
author = {Tao, Dacheng and Liu, Hao and Tang, Xiaoou},
title = {K-BOX: A Query-by-Singing Based Music Retrieval System},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027639},
doi = {10.1145/1027527.1027639},
abstract = {In this paper, we present an efficient query-by-singing based musical retrieval system. We first combine multiple Support Vector Machines by classifier committee learning to segment the sentences from a song automatically. Many new methods in manipulating Mel-Frequency Cepstral Coefficient (MFCC) matrix are studied and compared for optimal feature selection. Experiments show that the 3rd coefficient is the most relevant to music comparison out of 13 coefficients and the proposed simplified MFCC feature is able to achieve a reasonable trade-off between accuracy and efficiency. To improve system efficiency, we re-organize the database by a new two-stage clustering scheme in both time space and feature space. We combine K-means algorithm and dynamic time wrapping similarity measurement for feature space clustering. We also propose a new method for model-selection of K-means algorithm. Experiments show that the proposed approach can achieve more than 30 percent increase in accuracy while speed up more than 16 times in average query time.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {464–467},
numpages = {4},
keywords = {music segmentation, music retrieval, music clustering, MFCC},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027640,
author = {Siu, Angus M.K. and Lau, Rynson W.H.},
title = {Image-Based Modeling and Rendering with Geometric Proxy},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027640},
doi = {10.1145/1027527.1027640},
abstract = {In this paper, we present an image-based method to recover a geometric proxy and generate novel views. We use an integrated modeling and rendering approach to deal with the difficulty of modeling, and reduce the sampling rate. Our system is based on two novel techniques. First, we propose the <i>Adaptive Mesh Segmentation</i> (AMS) technique for recovering geometric proxy of a scene environment. Second, we propose the <i>Trifocal Morphing</i> technique for efficient rendering with the geometric proxy, which can handle non-matched regions of the scene. Our method allows images to be sparsely captured and thus highly reduces the manual image acquisition effort as well as the data size.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {468–471},
numpages = {4},
keywords = {image-based methods, image-based modeling, 3D reconstruction, geometric proxy, image-based rendering},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027641,
author = {HUA, Xian-Sheng and LU, Lie and ZHANG, Hong-Jiang},
title = {Automatic Music Video Generation Based on Temporal Pattern Analysis},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027641},
doi = {10.1145/1027527.1027641},
abstract = {Music video (MV) is a short film meant to present a visual representation of a popular music song. In this paper, we present a system that automatically generates MV-like videos from personal home videos based on observations that generally there are obvious repetitive visual and aural patterns in MVs. Based on a set of video and music analysis algorithms, the automatic music video (AMV) generation system automatically extracts temporal structures of the video and music, as well as repetitive patterns in the music. And then, according to the structure and patterns, a set of highlight segments from the raw home video footage are selected, aiming at matching the visual content with the aural structure and pattern. And last, the output music video is rendered by connecting the selected highlight video segments with appropriate transition effects, accompanied with the music. Experiments show that the results are compelling and promising.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {472–475},
numpages = {4},
keywords = {video content analysis, music analysis, music video, video editing, optimization, video segmentation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027642,
author = {Yin, Jun and Dhanik, Ankur and Hsu, David and Wang, Ye},
title = {The Creation of a Music-Driven Digital Violinist},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027642},
doi = {10.1145/1027527.1027642},
abstract = {This paper describes an initial attempt on a music-driven digital violinist (MDV) system, which automatically generates animation of a violinist based on violin music. MDV first analyzes the input audio signal and transcribes it into music notes. Next it uses the notes to synthesize the animated video of a violinist. Tests on the prototype system show that it achieves adequate visual realism and near real-time performance.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {476–479},
numpages = {4},
keywords = {inverse kinematics, animation, music transcription},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027643,
author = {Pang, Andr\'{e} and Parker, Conrad and Pfeiffer, Silvia},
title = {Challenges of Networked Media: Integrating the Navigational Features of Browsing Histories and Media Playlists into a Media Browser},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027643},
doi = {10.1145/1027527.1027643},
abstract = {One of the goals of the Continuous Media Web project<sup>1</sup> is to integrate digital media with the World Wide Web: media documents can hyperlink to and from other documents in the same way that HTML pages do. The dual capabilities of hyperlinking (1) to other documents while viewing a media clip, and (2) into precise time intervals in a media clip, enable greatly improved user interaction with media. We discuss the idea of a novel <i>media browser</i> application, which merges the concept of a traditional media player that presents video and audio to the user, with a Web browser that provides hyperlinking and navigation between networked (media) documents. The particular issue we address in this article concerns the primary navigational features: a media player relies on a <i>playlist</i> while a Web browser uses a <i>browsing history</i> for navigation. We discuss design and user interface issues that arise when integrating these two navigational features in a media browser.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {480–483},
numpages = {4},
keywords = {continuous media web, annodex, media browser, playlist, browsing history},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027644,
author = {Ikeda, Hitoshi and Maeda, Masahiro and Kato, Noriji and Kashimura, Hirotsugu},
title = {Classification of Human Actions Using Face and Hands Detection},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027644},
doi = {10.1145/1027527.1027644},
abstract = {In this paper, we describe a novel classification technique that separates video scenes, like office work tasks, into several scenes according to each task. Even if the difference of as a whole image frame by frame in each task is small, the difference of worker's movement is quite big due to the position of face and hands according to each task. In addition, the worker has the tendency to turn his/her face to look at the particular objects of individual tasks like PC, a document, and so on. Then, we decide to separate tasks based on face position, face angle in depth, and hand positions. For comparison of frames in a video, we use the Maharanobis distance to measure the difference of multivariate data that consist of face coordinates, face angle in depth, and coordinates of both hands. For the separation of tasks by the Maharanobis distance of an each frame, we use the hierarchical clustering method to classify frames in a video according to each task. For the robust detection of both hands, we use color-based method that searches hand areas using face color. Although the color of hands changes corresponding to the lighting conditions, the color of hands should be very similar to that of the face in an office. Therefore, even when the lighting condition changes, our color-based hand detection method does not need any adjustment to the change. We apply this classification technique to separate office work video into individual sets of task scenes. As a result, our technique shows better task separation performance than the histogram-based boundary detection technique.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {484–487},
numpages = {4},
keywords = {classification, hand detection, face detection, video, hierarchical clustering},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027645,
author = {H\"{u}rst, Wolfgang and Lauer, Tobias and G\"{o}tz, Georg},
title = {Interactive Manipulation of Replay Speed While Listening to Speech Recordings},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027645},
doi = {10.1145/1027527.1027645},
abstract = {Today's interfaces for time-scaled audio replay have limitations especially regarding highly interactive tasks such as skimming and searching, which require quick temporary speed changes. Motivated by this shortcoming, we introduce a new interaction technique for speech skimming based on the so called rubber-band metaphor. We propose an "elastic" audio slider which is especially useful for temporary manipulation of replay speed and which integrates seamlessly into standard interface designs. The feasibility of this concept is proven by an initial user study.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {488–491},
numpages = {4},
keywords = {speech skimming, speech interfaces, UI metaphors, time-scaled speech replay, multimedia interaction, elastic interfaces},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027646,
author = {Bulterman, Dick C.A. and Jansen, Jack and Kleanthous, Kleanthis and Blom, Kees and Benden, Daniel},
title = {Ambulant: A Fast, Multi-Platform Open Source SMIL Player},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027646},
doi = {10.1145/1027527.1027646},
abstract = {This paper provides an overview of the Ambulant Open SMIL player. Unlike other SMIL implementations, the Ambulant Player is a reconfigureable SMIL engine that can be customized for use as an experimental media player core. The Ambulant Player is a reference SMIL engine that can be integrated in a wide variety of media player projects. This paper starts with an overview of our motivations for creating a new SMIL engine, then discusses the architecture of the Ambulant Core (including the scalability and custom integration features of the player). We close with a discussion of our implementation experiences with Ambulant instances for Windows, Mac and Linux versions for desktop and PDA devices.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {492–495},
numpages = {4},
keywords = {player, demos, SMIL, open-source},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027647,
author = {Singh, Rahul and Knickmeyer, Rachel and Gupta, Punit and Jain, Ramesh},
title = {Designing Experiential Environments for Management of Personal Multimedia},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027647},
doi = {10.1145/1027527.1027647},
abstract = {With the increasing ubiquity of sensors and computational resources, it is becoming easier and increasingly common for people to electronically record, photographs, text, audio, and video gathered over their lifetime. Assimilating and taking advantage of such data requires recognition of its multimedia nature, development of data models that can represent semantics across different media, representation of complex relationships in the data (such as spatio-temporal, causal, or evolutionary), and finally, development of paradigms to mediate user-media interactions. There is currently a paucity of theoretical frameworks and implementations that allow management of diverse and rich multimedia data collections in context of the aforementioned requirements. This paper presents our research in designing an experiential Multimedia Electronic Chronicle system that addresses many of these issues in the concrete context of personal multimedia information. Central to our approach is the characterization and organization of media using the concept of an "event" for unified modeling and indexing. The event-based unified multimedia model underlies the experiential user interface, which supports direct interactions with the data within a unified presentation-exploration-query environment. In this environment, explicit facilities to model space and time aid in exploration and querying as well as in representation and reasoning with dynamic relationships in the data. Experimental and comparative studies demonstrate the promise of this research.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {496–499},
numpages = {4},
keywords = {unified multimedia modeling, experiential computing, personal media, UI metaphors},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027648,
author = {Wei, Xiaozhou and Yin, Lijun and Zhu, Zhiwei and Ji, Qiang},
title = {Avatar-Mediated Face Tracking and Lip Reading for Human Computer Interaction},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027648},
doi = {10.1145/1027527.1027648},
abstract = {Advanced human computer interaction requires automatic reading of human face in order to make the computer interact with human in the same way as human-to-human communication. We developed an automatic face tracking and lip reading system through a 3D face avatar to facilitate HCI applications in speech learning, emotional state monitoring, and non-verbal human computer interface design. The system implements a novel active face feature tracking algorithm with an uncalibrated camera. The 3D face pose is estimated and tracked by a Kalman filter-based matching process with a dynamic face model updating and constraint. The obtained facial motion parameters are transferred to an individualized 3D face avatar. As a result, a person's lip shape or expressions can be cloned to the animated 3D face avatar, by which all lip shapes from the same speech of different subjects can be easily compared and measured. This real time system targets the automatic facial expression analysis and synthesis for the next generation of HCI design.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {500–503},
numpages = {4},
keywords = {avatar, lip reading, animation, face tracking},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027649,
author = {M\"{a}kel\"{a}, Wille and Reunanen, Markku and Takala, Tapio},
title = {Possibilities and Limitations of Immersive Free-Hand Expression: A Case Study with Professional Artists},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027649},
doi = {10.1145/1027527.1027649},
abstract = {We have studied the usability and artistic potential of an immersive 3D painting system in its early state. The system allows one to draw lines, meshes and particle clouds using a one-hand wand in a virtual room with stereoscopic display. In its more mature state the software will allow for two-handed interaction with new interaction devices. Ten professional artists participated for two days each in a test, performing both given tasks and free artistic sketching. Their experiences were collected through observation and interviews. At this stage, we found that common technical limitations of virtual environments, such as latency and tracking inaccuracy as well as clumsiness of the hardware devices, may considerably hinder handicraft work. On the other hand, every single participant felt that immersion offers new potential for artistic expression and was definitely willing to continue in the second phase of the test later this year.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {504–507},
numpages = {4},
keywords = {free-hand drawing, fine arts, immersive environments, virtual reality},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027650,
author = {Quack, Till and M\"{o}nich, Ullrich and Thiele, Lars and Manjunath, B. S.},
title = {Cortina: A System for Large-Scale, Content-Based Web Image Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027650},
doi = {10.1145/1027527.1027650},
abstract = {Recent advances in processing and networking capabilities of computers have led to an accumulation of immense amounts of multimedia data such as images. One of the largest repositories for such data is the World Wide Web (WWW). We present Cortina, a large-scale image retrieval system for the WWW. It handles over 3 million images to date. The system retrieves images based on visual features and collateral text. We show that a search process which consists of an initial query-by-keyword or query-by-image and followed by relevance feedback on the visual appearance of the results is possible for large-scale data sets. We also show that it is superior to the pure text retrieval commonly used in large-scale systems. Semantic relationships in the data are explored and exploited by data mining, and multiple feature spaces are included in the search process.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {508–511},
numpages = {4},
keywords = {online, large-scale, association rules, web image retrieval, clustering, MPEG-7, WWW, semantics, relevance feedback},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027651,
author = {Adamczyk, Piotr D.},
title = {Seeing Sounds: Exploring Musical Social Networks},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027651},
doi = {10.1145/1027527.1027651},
abstract = {Information gathering from multimedia retrieval systems is aided by effective visualization, but the degree to which visualization is effective depends in part on the way the context of the results is presented. When relationships represent media rich connections, static visualization alone may not be enough. This work explores how to represent context and utilize multimedia to convey a more accurate sense of search results. As a representative case, we explore various presentations of social networks formed by expert opinions of musical artist similarity. Our work extends research in information visualization and music retrieval to create a multimedia search experience. Three interactive presentation styles are used; graph-based 2D, Desktop 3D (VRML), and CAVE (immersive Virtual Reality). Visual models are augmented with spatial audio in 3D, and hyperlinks to sound files in 2D. Results of a preliminary user study of these styles are discussed along with implications for recommender system design.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {512–515},
numpages = {4},
keywords = {information use, social networks, auralization, recommendation systems, spatial audio, music, sonification},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027652,
author = {Sabbir, Ali and Ravindran, Kaliappa},
title = {User-Assisted Tools for Concurrency Control in Distributed Multimedia Collaborations},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027652},
doi = {10.1145/1027527.1027652},
abstract = {In a distributed collaborative application, a key requirement is that all users see the same copy of a shared window object at any given point in time (WYSIWIS). In this paper, we study 'user-assisted causal ordering' of messages as the basis for achieving WYSIWIS. The approach requires specifying the synchronization constraints on accessing shared window objects in the form of an order in which messages need to be processed and object state updated. The specifications are made available to the window subsystem based on the user-level knowledge about the actions on objects and the current (shared) object state. In contrast with the current approaches employing transaction models, our approach allows flexibility in the programming of collaboration-style applications, and offers increased levels of concurrency.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {516–519},
numpages = {4},
keywords = {window consistency, user-level asynchrony, ordering of actions, shared window systems},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027654,
author = {Polli, Andrea},
title = {DATAREADER: A Tool for Art and Science Collaborations},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027654},
doi = {10.1145/1027527.1027654},
abstract = {This paper describes the background and process involved in the creation of 'datareader' a new custom Max/MSP object designed for artists to more easily work with scientific data. This project grew out of several years of developing software using existing Max/MSP objects to create artworks that translate data to sound (sonification), including a system for performing sound with eye movements and systems for sonifying neural data and data from a highly detailed weather model.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {520–523},
numpages = {4},
keywords = {climatology, meteorology, databases, sonification, eye-tracking, art},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027655,
author = {Birchfield, David},
title = {Composing the Digital Rainstick},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027655},
doi = {10.1145/1027527.1027655},
abstract = {This paper describes work on a composed instrument, the digital rainstick. The instrument is an acoustic rainstick that is augmented by five sensors that send real time performance data to the computer. A generative mechanism creates sound outputs that extend the sonic and expressive means of the rainstick, while collaborating with the performer to generate a compelling musical form that unfolds over the duration of the piece. The design and implementation of the hardware and software tools are first described, followed by a discussion of the results of this work.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {524–527},
numpages = {4},
keywords = {composed instruments, audio synthesis, HCI, music, feedback, performance, sound, musical expression, sensors},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027656,
author = {Varnik, Kristjan and Freeman, Jason and Ramakrishnan, C.},
title = {Tools Used While Developing Auracle: A Voice-Controlled Networked Instrument},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027656},
doi = {10.1145/1027527.1027656},
abstract = {Auracle is a networked sound instrument controlled by the voice. Users jam together over the Internet using only a microphone. Throughout the development process, the authors experimented with different approaches to interpreting vocal input and facilitating user interaction. This paper outlines some of the tools used to implement and evaluate those ideas, simulate the wide range of activities of Auracle users, and facilitate the development process.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {528–531},
numpages = {4},
keywords = {voice controlled synthesis, auracle, network and control, Max/MSP, wire, interactive music systems, open sound control, SuperCollider, transjam, JSyn, Java},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027657,
author = {Peng, Lina and Candan, K. Selcuk and Ryu, Kyung D. and Chatha, Karamvir S. and Sundaram, Hari},
title = {ARIA: An Adaptive and Programmable Media-Flow Architecture for Interactive Arts},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027657},
doi = {10.1145/1027527.1027657},
abstract = {We are developing an adaptive and programmable media-flow ARchitecture for Interactive Arts (ARIA) to enable real-time control of audio, video, and lighting on an intelligent stage. The intelligent stage is being equipped with a matrix of floor sensors for object localization, microphone arrays for sound localization, beam forming and motion capture system. ARIA system provides an interface for specifying intended mappings of the sensory inputs to audio-visual responses. Based on the specifications, the sensory inputs are streamed, filtered and fused, actuate a controllable projection system, sound surround and lighting system. The actuated responses take place in real-time and satisfy QoS requirements in live performance. In this paper, we present the ARIA quality-adaptive architecture. We model the basic information unit as a data object with a meta-data header and object payload streamed between nodes in the system and use a directed acyclic network to model media stream processing. We define performance metrics for the output precision, resource consumption, and end-to-end delay. The filters and fusion operators are being implemented by quality aware signal processing algorithms. The proper node behavior is chosen at runtime to achieve the QoS requirements and adapt to input object properties. For this purpose, ARIA utilizes a two-phase approach: static pre-optimization and dynamic run-time adaptation.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {532–535},
numpages = {4},
keywords = {interactive, tools for creating multimedia art, multi-model art},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027658,
author = {Shamma, David A. and Owsley, Sara and Bradshaw, Shannon and Hammond, Kristian J.},
title = {Using Web Frequency within Multi-Media Exhibitions},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027658},
doi = {10.1145/1027527.1027658},
abstract = {In this article, we explore the structure of the web as an indicator of popular culture and its use in multi-media exhibits. In a series of art and technology installations, the software agency needs to keep 'grounded' to what people can readily understand. We administered a survey to understand how people perceived word and phrase obscurity related with frequency information gathered from a popular Web search engine. We found the frequency data gathered from the engine closely matched judgments gathered from people. The results of this study point to the new applications of the WWW in art and multi-media exhibits as an indicator of popular culture.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {536–539},
numpages = {4},
keywords = {world wide web, culture, network arts, software agents, media arts},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027660,
author = {Fan, Jianping and Gao, Yuli and Luo, Hangzai},
title = {Multi-Level Annotation of Natural Scenes Using Dominant Image Components and Semantic Concepts},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027660},
doi = {10.1145/1027527.1027660},
abstract = {Automatic image annotation is a promising solution to enable semantic image retrieval via keywords. In this paper, we propose a multi-level approach to annotate the semantics of <b><i>natural scenes</i></b> by using both the dominant image components (salient objects) and the relevant semantic concepts. To achieve automatic image annotation at the content level, we use salient objects as the dominant image components for image content representation and feature extraction. To support automatic image annotation at the concept level, a novel image classification technique is developed to map the images into the most relevant semantic image concepts. In addition, Support Vector Machine (SVM) classifiers are used to learn the detection functions for the pre-defined salient objects and finite mixture models are used for semantic concept interpretation and modeling. An <b><i>adaptive EM algorithm</i></b> has been proposed to determine the optimal model structure and model parameters simultaneously. We have also demonstrated that our algorithms are very effective to enable multi-level annotation of <b><i>natural scenes</i></b> in a large-scale image dataset.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {540–547},
numpages = {8},
keywords = {salient objects, adaptive EM algorithm, automatic image annotation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027661,
author = {Yan, Rong and Yang, Jun and Hauptmann, Alexander G.},
title = {Learning Query-Class Dependent Weights in Automatic Video Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027661},
doi = {10.1145/1027527.1027661},
abstract = {Combining retrieval results from multiple modalities plays a crucial role for video retrieval systems, especially for automatic video retrieval systems without any user feedback and query expansion. However, most of current systems only utilize query independent combination or rely on explicit user weighting. In this work, we propose using query-class dependent weights within a hierarchial mixture-of-expert framework to combine multiple retrieval results. We first classify each user query into one of the four predefined categories and then aggregate the retrieval results with query-class associated weights, which can be learned from the development data efficiently and generalized to the unseen queries easily. Our experimental results demonstrate that the performance with query-class dependent weights can considerably surpass that with the query independent weights.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {548–555},
numpages = {8},
keywords = {learning, query class, video retrieval, modality fusion},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027662,
author = {Oshima, Chika and Nishimoto, Kazushi and Suzuki, Masami},
title = {Family Ensemble: A Collaborative Musical Edutainment System for Children and Parents},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027662},
doi = {10.1145/1027527.1027662},
abstract = {In this paper we propose a collaborative musical edutainment system named "Family Ensemble" (FE). FE allows a parent and his/her child to readily enjoy ensembles together at home, in this case, a piano duo, even if the parent has little or no experience in playing a musical instrument. FE makes it easier for the parent to correctly perform given melodies along with his/her child's performance, using a score-tracking algorithm that can cope with the particular errors commonly made by beginners, i.e., children. By supporting the parent, FE prompts the child to practice the musical instrument more willingly. In experiments, we confirmed that FE can facilitate the playing of duos by pre-instrumental performers and beginners. Furthermore, we found, during a joint practice using FE, that some subjects discussed musical ideas that they could not have talked about without the system. Thus, not only does FE encourage children to willingly practice the piano but it also allows even pre-instrumental performers and beginners to aim for richer musical expression and a deeper understanding and appreciation of music.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {556–563},
numpages = {8},
keywords = {music edutainment, piano duo, score tracking, support system, beginner},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027664,
author = {Goh, King-Shy and Chang, Edward Y. and Lai, Wei-Cheng},
title = {Multimodal Concept-Dependent Active Learning for Image Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027664},
doi = {10.1145/1027527.1027664},
abstract = {It has been established that active learning is effective for learning complex, subjective query concepts for image retrieval. However, active learning has been applied in a concept independent way, (i.e., the kernel-parameters and the sampling strategy are identically chosen) for learning query concepts of differing <i>complexity</i>. In this work, we first characterize a concept's complexity using three measures: <i>hit-rate</i>, <i>isolation</i> and <i>diversity</i>. We then propose a multimodal learning approach that uses images' semantic labels to guide a <i>concept-dependent</i>, <i>active-learning</i> process. Based on the complexity of a concept, we make intelligent adjustments to the sampling strategy and the sampling pool from which images are to be selected and labeled, to improve concept learnability. Our empirical study on a $300$K-image dataset shows that concept-dependent learning is highly effective for image-retrieval accuracy.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {564–571},
numpages = {8},
keywords = {image retrieval, support vector machines, relevance feedback, active learning},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027665,
author = {Wu, Yi and Chang, Edward Y. and Chang, Kevin Chen-Chuan and Smith, John R.},
title = {Optimal Multimodal Fusion for Multimedia Data Analysis},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027665},
doi = {10.1145/1027527.1027665},
abstract = {Considerable research has been devoted to utilizing multimodal features for better understanding multimedia data. However, two core research issues have not yet been adequately addressed. First, given a set of features extracted from multiple media sources (e.g., extracted from the visual, audio, and caption track of videos), how do we determine the best modalities? Second, once a set of modalities has been identified, how do we best fuse them to map to semantics? In this paper, we propose a two-step approach. The first step finds <i>statistically independent modalities</i> from raw features. In the second step, we use <i>super-kernel fusion</i> to determine the optimal combination of individual modalities. We carefully analyze the tradeoffs between three design factors that affect fusion performance: <i>modality independence</i>, <i>curse of dimensionality</i>, and <i>fusion-model complexity</i>. Through analytical and empirical studies, we demonstrate that our two-step approach, which achieves a careful balance of the three design factors, can improve class-prediction accuracy over traditional techniques.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {572–579},
numpages = {8},
keywords = {multimodal fusion, super-kernel fusion, independent analysis, modality independence, curse of dimensionality},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027666,
author = {Yang, Jun and Hauptmann, Alexander G.},
title = {Naming Every Individual in News Video Monologues},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027666},
doi = {10.1145/1027527.1027666},
abstract = {Naming every individual person appearing in broadcast news videos with names detected from the video transcript leads to better access of the news video content. In this paper, we approach this challenging problem with a statistical learning method. Two categories of information extracted from multiple video modalities have been explored, namely <i>features</i>, which help distinguish the true name of every person, as well as <i>constraints</i>, which reveal the relationships among the names of different persons. The person-naming problem is formulated into a learning framework which predicts the most likely name for each person based on the features, and refines the predictions using the constraints. Experiments conducted on ABC World New Tonight and CNN Headline News videos demonstrate that this approach outperforms a non-learning alternative by a large amount.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {580–587},
numpages = {8},
keywords = {person naming, multi-modality, machine learning, equivalence constraint, broadcast news video},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027668,
author = {Ahn, Baik-Song and Sohn, Sung-Hoon and Kim, Chei-Yol and Cha, Gyu-Il and Baek, Yun-Cheol and Jung, Sung-In and Kim, Myung-Joon},
title = {Implementation and Evaluation of EXT3NS Multimedia File System},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027668},
doi = {10.1145/1027527.1027668},
abstract = {The EXT3NS is a scalable file system designed to handle video streaming workload in large-scale on-demand streaming services. It is based on a special H/W device, called Network-Storage card (NS card), which aims at accelerating streaming operation by shortening the data path from storage device to network interface. The design objective of EXT3NS is to minimize the delay and the delay variance of I/O request in the sequential workload on NS card. Metadata structure, file organization, metadata structure, unit of storage, etc. are elaborately tailored to achieve this objective. Further, EXT3NS provides the standard API's to read and write files in storage unit of NS card. The streaming server utilizes it to gain high disk I/O bandwidth, to avoid unnecessary memory copies on the data path from disk to network, and to alleviates CPU's burden by offloading parts of network protocol processing, The EXT3NS is a full functional file system based on the popular EXT3. The performance measurements on our prototype video server show obvious performance improvements. Specifically, we obtain better results from file system benchmark program, and obtain performance improvements in disk read and network transmission, which leads to overall streaming performance increase. Especially, the streaming server shows much less server's CPU utilization and less fluctuation of client bit rate, hence more reliable streaming service is possible.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {588–595},
numpages = {8},
keywords = {streaming, video server, file system, multimedia},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027669,
author = {Ott, David E. and Mayer-Patel, Ketan},
title = {Coordinated Multi-Streaming for 3D Tele-Immersion},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027669},
doi = {10.1145/1027527.1027669},
abstract = {This paper looks at the problem of multi-streaming in 3D tele-immersion and describes how a protocol architecture called CP (for Coordination Protocol) can be used to coordinate video frame transport between application clusters. CP provides application endpoints with information about current network conditions, and an open architecture for implementing application-specific coordination schemes. The scheme described in this paper apportions available bandwidth among flows such that frame transport synchrony, important for 3D reconstruction performance, is significantly enhanced.Results demonstrating the effectiveness of CP in increasing multi-stream coordination, while at the same time maintaining aggregate congestion responsiveness, are obtained from a FreeBSD/Linux implementation and a live experimental network. Results underscore the importance of consistency in network information across flows for realizing dramatic improvements in frame arrival synchrony.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {596–603},
numpages = {8},
keywords = {distributed applications, flow coordination, network protocols},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027670,
author = {Ishibashi, Yutaka and Kanbara, Takeshi and Tasaka, Shuji},
title = {Inter-Stream Synchronization between Haptic Media and Voice in Collaborative Virtual Environments},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027670},
doi = {10.1145/1027527.1027670},
abstract = {This paper addresses an inter-stream synchronization issue between haptic media and voice in networked virtual environments. The paper proposes a media synchronization algorithm for the two types of media stream by enhancing the virtual-time rendering (VTR) algorithm, which the authors previously proposed. The new algorithm employs two types of error range in order to keep high quality of intra-stream synchronization at the expense of slight deterioration in the inter-stream synchronization quality. One is the imperceptible range of inter-stream synchronization error, and the other is the allowable range of the error. If the error is beyond the allowable range, the algorithm tries to reduce the error gradually until the error becomes within the imperceptible range. Otherwise, it accepts the error. By carrying out an experiment in which two users do collaborative work with haptic media and voice in a virtual space, we demonstrate the effectiveness of the algorithm quantitatively.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {604–611},
numpages = {8},
keywords = {media synchronization, collaborative virtual environments, haptic media, voice},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027671,
author = {Gotz, David and Mayer-Patel, Ketan},
title = {A General Framework for Multidimensional Adaptation},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027671},
doi = {10.1145/1027527.1027671},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {612–619},
numpages = {8},
keywords = {adaptation, multimedia},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027673,
author = {Mann, Steve},
title = {"Sousveillance": Inverse Surveillance in Multimedia Imaging},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027673},
doi = {10.1145/1027527.1027673},
abstract = {This is a personal narrative that began 30 years ago as a childhood hobby, of wearing and implanting various sensors, effectors, and multimedia computation in order to re-define personal space and modify sensory perception computationally. This work involved the creation of various computational seeing aids that evolved into a new kind of visual art, using multimedia cyborglogs. Becoming at one with the machine, the author was able to explore a new humanity at the nexus of cyberspace and the real world. The author presents what was discovered accidentally, as a result of facing "cyborg discrimination". In particular, over the past 30 years, peer discrimination has decreased, while institutional and organized discrimination has intensified. Most notably, it was discovered that cyborg discrimination was most intense in establishments having the most surveillance. Rather than avoid such establishments, the author was able to explore and capture unique aspects to understand surveillance in new ways. The word <i>sur-veillance</i> denotes a God's eye view from on high (i.e. French for "to watch from above"). An inverse, called sous-veillance (French for "to watch from below") explores what happens when cameras move from lamp posts and ceilings down to eye level. Finally, it is suggested that new personal multimedia technologies, like mass-produced wearable cameraphones, can be used as tools for artists to explore "equiveillance" by shifting this equilibrium between surveillance and sousveillance with inverse/reverse/accountability/recountability/continuability of continuous sur/sousveillance.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {620–627},
numpages = {8},
keywords = {surveillance, eyetap, inverse surveillance, weblog, cyborglog, equiveillance, sousveillance, computer mediated reality},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027674,
author = {Boyd, Jeffrey E. and Hushlak, Gerald and Jacob, Christian J.},
title = {SwarmArt: Interactive Art from Swarm Intelligence},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027674},
doi = {10.1145/1027527.1027674},
abstract = {This paper describes <i>SwarmArt</i>, a collaborative project between computer science and art, which resulted in two installations of interactive art that incorporates swarm intelligence. We describe the scientific context of the artwork, technical details of the video system, through which user interaction is controlled, and the realization of the swarm-based simulations, which were projected onto a large screen. Finally, we explain and illustrate our two recent SwarmArt installations in a Calgary gallery.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {628–635},
numpages = {8},
keywords = {swarm dynamics, video information server, emergence, art installation, swarm intelligence, swarm art, interaction through video},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027675,
author = {Yoshida, Shunsuke and Kurumisawa, Jun and Noma, Haruo and Tetsutani, Nobuji and Hosaka, Kenichi},
title = {Sumi-Nagashi: Creation of New Style Media Art with Haptic Digital Colors},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027675},
doi = {10.1145/1027527.1027675},
abstract = {This installation provides painters with a method for feeling attributes of digital colors and a fluid canvas. When a user of this installation moves the stylus paintbrush over the digital canvas, he/she senses the "weight of the colors" through the brush. For example, the user experiences dark colors as heavy in weight and light colors as light in weight. Complex painting is expressed as a mixed tactile sensation using a new desk-style force feedback system called the "Proactive Desk." Other existing digital painting systems that use haptic cues usually aim to be physically and visually correct. In this approach, however, we invested effort in enhancing the relationship between digital colors as a virtual material and the sense of touch. Additionally, we took the importance of co-located drawing work space for creative tasks into account. We believe that this experience will arouse new inspiration and give digital painters the opportunity to experience again how important touch is for creativity in art.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {636–643},
numpages = {8},
keywords = {virtual reality, haptic feedback, media art, digital painting},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027676,
author = {Cabello-Miguel, Tony and Fern\'{a}ndez-Barracel, Oscar and Garc\'{\i}a-Panyella, Oscar},
title = {IGlue.v3: An Electronics Metaphor for Multimedia Technologies Integration},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027676},
doi = {10.1145/1027527.1027676},
abstract = {The iGlue Project is a set of tools meant for the integration of different multimedia technologies in creative applications like multimedia installations or live audiovisual shows.Inspired by the way of working used in electronics, similar concepts are developed in a visual environment to interactively build applications out of components, wires and circuits. This approach enhances the entire R&amp;D workflow, providing for application prototyping, empirical experimentation, collaborative work, software recycling and simplified maintenance.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {644–651},
numpages = {8},
keywords = {interactive development, application modeling, electronics UI metaphor, component system, multimedia technologies integration, collaborative work},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027678,
author = {Smeaton, Alan F. and Over, Paul and Kraaij, Wessel},
title = {TRECVID: Evaluating the Effectiveness of Information Retrieval Tasks on Digital Video},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027678},
doi = {10.1145/1027527.1027678},
abstract = {TRECVID is an annual exercise which encourages research in information retrieval from digital video by providing a large video test collection, uniform scoring procedures, and a forum for organizations interested in comparing their results. TRECVID benchmarking covers both interactive and manual searching by end users, as well as the benchmarking of some supporting technologies including shot boundary detection, extraction of some semantic features, and the automatic segmentation of TV news broadcasts into non-overlapping news stories. TRECVID has a broad range of over 40 participating groups from across the world and as it is now (2004) in its 4th annual cycle it is opportune to stand back and look at the lessons we have learned from the cumulative activity. In this paper we shall present a brief and high-level overview of the TRECVID activity covering the data, the benchmarked tasks, the overall results obtained by groups to date and an overview of the approaches taken by selective groups in some tasks. While progress from one year to the next cannot be measured directly because of the changing nature of the video data we have been using, we shall present a summary of the lessons we have learned from TRECVID and include some pointers on what we feel are the most important of these lessons.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {652–655},
numpages = {4},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027679,
author = {Chua, Tat-Seng and Chang, Shih-Fu and Chaisorn, Lekha and Hsu, Winston},
title = {Story Boundary Detection in Large Broadcast News Video Archives: Techniques, Experience and Trends},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027679},
doi = {10.1145/1027527.1027679},
abstract = {The segmentation of news video into story units is an important step towards effective processing and management of large news video archives. In the story segmentation task in TRECVID 2003, a wide variety of techniques were employed by many research groups to segment over 120-hour of news video. The techniques employed range from simple anchor person detector to soisticated machine learning models based on HMM and Maximum Entropy (ME) approaches. The general results indicate that the judicious use of multi-modality features coupled with rigorous machine learning models could produce effective solutions. This paper presents the algorithms and experience learned in TRECVID evaluations. It also points the way towards the development of scalable technology to process large news video corpuses.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {656–659},
numpages = {4},
keywords = {story segmentation, machine learning techniques, news video},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027680,
author = {Naphade, Milind R. and Smith, John R.},
title = {On the Detection of Semantic Concepts at TRECVID},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027680},
doi = {10.1145/1027527.1027680},
abstract = {Semantic multimedia management is necessary for the effective and widespread utilization of multimedia repositories and realizing the potential that lies untapped in the rich multimodal information content. This challenge has driven researchers to devise new algorithms and systems that enable automatic or semi-automatic tagging of large scale multimedia content with rich semantics. An emerging research area is the detection of a predetermined set of semantic concepts that can act as semantic filters and aid in search, and manipulation. The NIST TRECVID benchmark has responded by creating a task that has evaluated the performance of concept detection. Within the scope of this benchmark task, this paper studies trends in the emerging concept detection systems, architectures and algorithms. It also analyzes strategies that have yielded reasonable success, and challenges and gaps that lie ahead.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {660–667},
numpages = {8},
keywords = {average precision, NIST TRECVID benchmark, semantic concept detection},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027681,
author = {Hauptmann, Alexander G. and Christel, Michael G.},
title = {Successful Approaches in the TREC Video Retrieval Evaluations},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027681},
doi = {10.1145/1027527.1027681},
abstract = {This paper reviews successful approaches in evaluations of video retrieval over the last three years. The task involves the search and retrieval of shots from MPEG digitized video recordings using a combination of automatic speech, image and video analysis and information retrieval technologies. The search evaluations are grouped into interactive (with a human in the loop) and non-interactive (where the human merely enters the query into the system) submissions. Most non-interactive search approaches have relied extensively on text retrieval, and only recently have image-based features contributed reliably to improved search performance. Interactive approaches have substantially outperformed all non-interactive approaches, with most systems relying heavily on the user's ability to refine queries and reject spurious answers. We will examine both the successful automatic search approaches and the user interface techniques that have enabled high performance video retrieval.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {668–675},
numpages = {8},
keywords = {video retrieval, search, TRECVID, information retrieval benchmarks},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027683,
author = {Yang, Sheng and Lee, Chao-Hua and Kuo, C.-C. Jay},
title = {Optimized Mesh and Texture Multiplexing for Progressive Textured Model Transmission},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027683},
doi = {10.1145/1027527.1027683},
abstract = {An optimized scheme of multiplexing coded mesh and texture data to facilitate progressive transmission of 3D textured models is proposed in this work. The mesh and texture data of a 3D textured model are fed into their respective compression modules and represented by a series of levels of details. Then, for a given viewpoint, a rate-distortion surface can be generated based on the multiplexing of mesh and texture data in different details. The distortion is calculated by measuring the visual quality of rendered images. Furthermore, an optimal path over the rate-distortion surface is determined by the steepest descent algorithm. When the mesh and texture data streams are transmitted in a certain ratio along the optimal path, it is guaranteed that the rendered images have the best visual quality perceived from the given viewpoint. To deal with an arbitrary viewpoint, we propose a hierarchical sampling algorithm so that the optimal path can be interpolated from finite sampling points. Experimental results demonstrate that the proposed method can provide the best visual quality of a 3D textured model for any observation point at any bit rate.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {676–683},
numpages = {8},
keywords = {rate-distortion surface, progressive transmission, mesh-texture multiplexing},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027684,
author = {Tian, Dihong and AlRegib, Ghassan},
title = {FQM: A Fast Quality Measure for Efficient Transmission of Textured 3D Models},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027684},
doi = {10.1145/1027527.1027684},
abstract = {In this paper, we propose an efficient transmission method to stream textured 3D models. We develop a bit-allocation algorithm that distributes the bit budget between the geometry and the mapped texture to maximize the quality of the model displayed on the client's screen. Both the geometry and the texture are progressively and independently compressed. The resolutions for the geometry and the texture are selected to maximize the quality for a given bitrate. We further propose a novel and fast quality measure (FQM) to quantify the perceptual fidelity of the simplified model. Experimental results demonstrate the effectiveness of the proposed bit-allocation algorithm using FQM. For example, when the bit budget is 10KB, the quality of the <sc>Zebra</sc> model is improved by 15% using the proposed method compared to distributing the bit budget equally between the geometry and the texture.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {684–691},
numpages = {8},
keywords = {3D model, bit-allocation, quality measure, geometry, texture},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027685,
author = {Ichida, Hiroyasu and Itoh, Yuichi and Kitamura, Yoshifumi and Kishino, Fumio},
title = {Interactive Retrieval of 3D Shape Models Using Physical Objects},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027685},
doi = {10.1145/1027527.1027685},
abstract = {We present a novel method for interactive retrieval of 3D shapes using ysical objects. Our method is based on simple ysical 3D interaction with a set of tangible blocks. As the user connects blocks, the system automatically recognizes the shape of the constructed ysical structure and picks similar 3D shape models from a preset model database, in real time. Our system fully supports interactive retrieval of 3D shape models in an extremely simple fashion, which is completely non-verbal and cross-cultural. These advantages make it an ideal interface for inexperienced users, previously barred from many applications that include 3D shape retrieval tasks.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {692–699},
numpages = {8},
keywords = {physical object, retrieval system, 3D shape model, Voxel data},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027686,
author = {Kim, Duck Hoon and Yun, Il Dong and Lee, Sang Uk},
title = {A Comparative Study on Attributed Relational Gra Matching Algorithms for Perceptual 3-D Shape Descriptor in MPEG-7},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027686},
doi = {10.1145/1027527.1027686},
abstract = {Nowadays, the demand on user-friendly querying interface such as query-by-sketch and query-by-editing is an important issue in the content-based retrieval system for 3-D object database. Especially in MPEG-7, P3DS (Perceptual 3-D Shape) descriptor has been developed in order to provide the user-friendly querying, which can not be covered by an existing international standard for description and browsing of 3-D object database. Since the P3DS descriptor is based on the part-based representation of 3-D object, it is a kind of attributed relational gra (ARG) so that the ARG matching algorithm naturally follows as the core procedure for the similarity matching of the P3DS descriptor. In this paper, given a P3DS database from the corresponding 3-D object database, we bring focus into investigating the pros and cons of the target ARG matching algorithms. In order to demonstrate the objective evidence of our conclusion, we have conducted the experiments based on the database of 480 3-D objects with 33 categories in terms of the bull's eye performance, average normalized modified retrieval rate, and <i>precision/recall</i> curve.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {700–707},
numpages = {8},
keywords = {performance evaluation, perceptual 3-D shape descriptor, attributed relational gra generation and matching, mpeg-7},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027688,
author = {Hua, Xian-Sheng and Lu, Lie and Zhang, Hong-Jiang},
title = {Automatically Converting Photographic Series into Video},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027688},
doi = {10.1145/1027527.1027688},
abstract = {In this paper, we proposed a novel way to browse a series of otogras, which can be regarded as a system exploring the new medium between otogra and video. The scheme exploits the rich content embedded in a single otogra and otograic series. Based on studying the process of a viewer's attention variation on objects or regions of an image, a otogra can be converted into a motion clip. A system named <i>oto2Video</i> was developed to automatically convert a otograic series into a video by simulating camera motions, set to incidental music of the user's choice. For a selected otograic series, an appropriate set of <i>key-frames</i> are determined for each otogra based on soisticated content analytical results. Then camera motion pattern (both the <i>key-frame sequencing</i> scheme and <i>trajectory/speed control</i> strategy) is selected for each otogra to generate a corresponding motion otogra clip. And last, the final output video is rendered by connecting a series of motion otogra clips with specific transitions based on the content of the images on either side, as well as each motion otogra clip is aligned with the selected incidental music based on music content analysis.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {708–715},
numpages = {8},
keywords = {attention detection, image content analysis, image clustering, face detection, audio segmentation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027689,
author = {Zhang, Lei and Hu, Yuxiao and Li, Mingjing and Ma, Weiying and Zhang, Hongjiang},
title = {Efficient Propagation for Face Annotation in Family Albums},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027689},
doi = {10.1145/1027527.1027689},
abstract = {In this paper, we propose and investigate a new user scenario for face annotation, in which users are allowed to multi-select a group of otogras and assign names to these otogras. The system will then attempt to propagate names from otogra level to face level, i.e. to infer the correspondence between name and face. Given the face similarity measure which combines methodologies from face recognition and content-based image retrieval, we formulate name propagation as an optimization problem. We define the objective function as the sum of similarities between each pair of faces of the same individual in different otogras, and propose an iterative optimization algorithm to infer the optimal correspondence. To make the propagation result reliable, a reject scheme is adopted to reject those with low confidence scores. Furthermore, we investigate the combination and alternation of browsing mode for propagation and viewer mode for annotation, so that each mode can benefit from additional inputs from the other mode. The experimental evaluation has been conducted within a typical family album of over one thousand otogras and the results show that the proposed approach is effective and efficient in automated face annotation in family albums.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {716–723},
numpages = {8},
keywords = {propagation, content-based image retrieval, face recognition, face annotation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027690,
author = {Sarvas, Risto and Viikari, Mikko and Pesonen, Juha and Nevanlinna, Hanno},
title = {MobShare: Controlled and Immediate Sharing of Mobile Images},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027690},
doi = {10.1145/1027527.1027690},
abstract = {In this paper we describe the design and implementation of a mobile one picture sharing system <i>MobShare</i> that enables immediate, controlled, and organized sharing of mobile pictures, and the browsing, combining, and discussion of the shared pictures. The design combines research on otogray, personal image management, mobile one camera use, mobile picture publishing, and an interview study we conducted on mobile one camera users. The system is based on a client-server architecture and uses current mobile one and web technology. The implementation describes novel solutions in immediate sharing of mobile images to an organized web album, and in providing full control over with whom the images are shared. Also, we describe new ways of promoting discussion in sharing images and enabling the combination and comparison of personal and shared pictures. The system proves that the designed solutions can be implemented with current technology and provides novel approaches to general issues in sharing digital images.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {724–731},
numpages = {8},
keywords = {multimedia tools, digital image management, camera ones, wireless multimedia applications},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027691,
author = {Christel, Michael and Moraveji, Neema},
title = {Finding the Right Shots: Assessing Usability and Performance of a Digital Video Library Interface},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027691},
doi = {10.1145/1027527.1027691},
abstract = {The authors developed a system in which visually dense displays of thumbnail imagery in storyboard views are used for shot-based video retrieval. The views allow for effective retrieval, as evidenced by the success achieved by expert users with the system in interactive query for NIST TRECVID 2002 and 2003. This paper demonstrates that novice users also achieve comparatively high retrieval performance with these views using the TRECVID 2003 benchmarks. Through an analysis of the user interaction logs, heuristic evaluation, and think-aloud protocol, the usability of the video information retrieval system is appraised with respect to shot-based retrieval. Design implications are presented based on these TRECVID usability evaluations regarding efficient, effective information retrieval interfaces to locate visual information from video corpora.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {732–739},
numpages = {8},
keywords = {video retrieval, storyboard, TRECVID},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027693,
author = {Ronfard, Remi},
title = {Reading Movies: An Integrated DVD Player for Browsing Movies and Their Scripts},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027693},
doi = {10.1145/1027527.1027693},
abstract = {We have built over the last few years an integrated browser and query interface for watching a movie synchronized with its script. The system is demonstrated with the movie 'The Wizard of Oz', which was fully synchronized with its script using automated tools described elsewhere. Searchable textual descriptions and synchronization metadata (hyperlinks) are generated dynamically on the server side. Video content navigation runs in a DVD player embedded in a web browser on the client side. Thus, the owner of the DVD can connect to our site and view, search and navigate the movie shot by shot.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {740–741},
numpages = {2},
keywords = {media aesthetics, internet, film analysis, semantic video indexing, computers in education},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027694,
author = {H\"{u}rst, Wolfgang and G\"{o}tz, Georg and Jarvers, Philipp},
title = {Advanced User Interfaces for Dynamic Video Browsing},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027694},
doi = {10.1145/1027527.1027694},
abstract = {In this demonstration we present three interface designs which enable users to visually browse video data by moving a slider thumb along the timeline. In such a case, scrolling granularity is usually limited because of the fixed length of the corresponding slider. In contrast, our interaction designs enable users to skim the data at different granularity levels by providing the possibility to continuously change the slider's scale, by using a nonlinear scale, and by enabling interactive manipulation of the scrolling speed, respectively.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {742–743},
numpages = {2},
keywords = {multimedia user interfaces and interaction, advanced interface design, dynamic video browsing},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027695,
author = {King, Ross and Popitsch, Niko and Westermann, Utz},
title = {METIS: A Flexible Database Foundation for Unified Media Management},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027695},
doi = {10.1145/1027527.1027695},
abstract = {Current multimedia database systems largely focus on specific media types and/or application domains. This paper gives a sketch of METIS, a database solution for the unified management of any kind of digital media, characterized by profound customizability for domain or application needs. The system core is based on an expressive data model that can be adapted to any scheme for media management, description, and classification desired, and can accommodate arbitrary query operators, similarity measures, and/or feature extraction algorithms. METIS is based on a persistence abstraction layer allowing the exchange of storage back-ends and includes a customizable web front-end for media management. Thereby, METIS establishes a common database foundation for a wide spectrum of multimedia applications.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {744–745},
numpages = {2},
keywords = {multimedia database systems, unified media management},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027696,
author = {Yan, Xin and Yu, Xinguo and Hay, Tze Sen},
title = {A 3D Reconstruction and Enrichment System for Broadcast Soccer Video},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027696},
doi = {10.1145/1027527.1027696},
abstract = {In this demonstration, we present a 3D reconstruction and enrichment system for broadcast soccer video to enhance the consumers' viewing experience. The system can reconstruct not only the goalmouth scene but also the midfield scene as well. Furthermore, the reconstructed video is enriched by music and illustrations of the video contents. In the reconstructed videos, we have eliminated the ball deformation and unnecessary camera changes though smoothing the camera parameters.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {746–747},
numpages = {2},
keywords = {calibration, soccer video, video enrichment, 3D reconstruction},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027697,
author = {Li, Zhi-Wei and Xie, Xing and Liu, Hao and Tang, Xiaoou and Li, Mingjing and Ma, Wei-Ying},
title = {Intuitive and Effective Interfaces for WWW Image Search Engines},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027697},
doi = {10.1145/1027527.1027697},
abstract = {Web image search engine has become an important tool to organize digital images on the Web. However, most commercial search engines still use a list presentation while little effort has been placed on improving their usability. How to present the image search results in a more intuitive and effective way is still an open question to be carefully studied. In this demo, we present iFind, a scalable Web image search engine, in which we integrated two kinds of search result browsing interfaces. User study results have proved that our interfaces are superior to traditional interfaces.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {748–749},
numpages = {2},
keywords = {web image retrieval, image clustering, user interface, image browsing},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027698,
author = {Balasubramanian, Vidhya and Venkatasubramanian, Nalini},
title = {GURU: A Multimedia Distance-Learning Framework for Users with Disabilities},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027698},
doi = {10.1145/1027527.1027698},
abstract = {GURU is a distance-learning environment that renders multimedia information to users with disabilities in an accessible manner. It is an implementation framework developed as part of an effort to provide accessible multimedia information to end users with perceptual (visual and auditory), cognitive or motor impairments. GURU is based on the MPEG-4 standard, and it modifies MP4 content and the presentation of the different objects in the scene dynamically based on users' visual, auditory and motor abilities. This paper briefly describes the implementation of the prototype framework and illustrates sample adaptations as implemented in this framework.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {750–751},
numpages = {2},
keywords = {adaptation, MPEG-4, multimedia, distance-learning, accessibility},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027699,
author = {Nagamine, Takeshi and Jaimes, Alejandro and Omura, Kengo and Hirata, Kazutaka},
title = {A Visuospatial Memory Cue System for Meeting Video Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027699},
doi = {10.1145/1027527.1027699},
abstract = {We present a system based on a new, memory-cue paradigm for retrieving meeting video scenes. The system graically represents important memory retrieval cues such as room layout, participant's faces and sitting positions, etc.. Queries are formulated dynamically: as the user graically manipulates the cues, the query results are shown. Our system (1) helps users easily express the <i>cues</i> they recall about a particular meeting; (2) helps users <i>remember</i> new cues for meeting video retrieval. We discuss the experiments that motivate this new approach, implementation, and future work.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {752–753},
numpages = {2},
keywords = {meeting video, dynamic query, memory-based retrieval},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027700,
author = {Duan, Ling-Yu and Xu, Min and Tian, Qi and Xu, Chang-Sheng},
title = {Nonparametric Motion Model},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027700},
doi = {10.1145/1027527.1027700},
abstract = {Motion information is a powerful cue for visual perception. In the context of video indexing and retrieval, motion content serves as a useful source for compact video representation. There has been a lot of literature about parametric motion models. However, it is hard to secure a proper parametric assumption in a wide range of video scenarios. Diverse camera shots and frequent occurrences of improper optical flow estimation or block matching motivate us to develop nonparametric motion models. In this demonstration, we present a novel nonparametric motion model. The unique features mainly include: 1) Instead of computationally expensive and vulnerable parametric regression our proposed model bases the motion characterization on the classification of motion patterns; 2) we employ machine learning to capture the knowledge of recognizing camera motion patterns from bad motion vector fields (MVF); and 3) with the mean shift filtering our proposed motion representation elegantly incorporates the spatial-range information for noise removal and discontinuity preserving smoothing of MVF. Promising results have been achieved on two tasks: 1) camera motion pattern recognition on 23191 MVFs and 2) recognition of the intensity of motion activity on 622 video segments culled from the MPEG-7 dataset.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {754–755},
numpages = {2},
keywords = {nonparametric motion analysis, mean shift, camera motion},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027701,
author = {Duan, Ling-Yu and Yuan, Jun-Song and Tian, Qi and Xu, Chang-Sheng},
title = {Fast and Robust Video Clip Search Using Index Structure},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027701},
doi = {10.1145/1027527.1027701},
abstract = {Content based retrieval of similar multimedia objects (e.g. images, text, and videos) is an important research issue in the field of multimedia database. In this demo, we present a fast and robust video clip searching system. This system consists of two major modules, namely, robust video representation and fast searching. Different from traditional key frame-based histogram methods, we employ the cumulative histogram to represent the ordinal features and color range features for a video segment. This representation provides a spatio-temporal description of the whole segment. Our experiment has shown it is effective for capturing the patterns of short video clips such as commercial, program lead in/out, flying logo in sports video, etc. In order to improve the performance in searching large video database, we introduce the index structure to deal with video search from the viewpoint of query processing (e.g. <i>K-NN query, Range query</i>, etc.) in high-dimensional spaces. Different query processing support different search tasks. In this demo, we employ the mrkd-tree index structure and the proposed video representation to fulfill fast and robust search of short video clips (i.e. news video lead-in/out, replay logo, commercial) in large video collections with the total length of 15 hours.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {756–757},
numpages = {2},
keywords = {index structure, mrkd-tree, video clip search, query processing},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027702,
author = {Xu, Min and Duan, Ling-Yu and Chia, Liang-Tien and Xu, Chang-sheng},
title = {Audio Keyword Generation for Sports Video Analysis},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027702},
doi = {10.1145/1027527.1027702},
abstract = {Semantic sports video analysis has attracted many research interests and audio cues have been shown to play an important role in semantics inference. To facilitate event detection using audio information, we have introduced the concept of audio keyword (e.g. <i>excited/plain commentator speech, excited/plain audience sound</i>, etc.) to describe the game-specific sound associated with an event. In our previous work, we have designed a hierarchical Support Vector Machine (SVM) classifier for audio keyword identification. However, there are two inherent weaknesses: 1) a frame-based SVM classifier does not incorporate any contextual information; 2) a robust recognizer relies on large amounts of training data in the case of different sports games videos. In this demo, we present a flexible Hidden Markov Model (HMM)-based audio keyword generation system. This is motivated by the successful story of applying HMM in speech recognition. Unlike the frame-based SVM classification followed by a major voting, our HMM-based system treats an audio keyword as a continuous time series data and employs hidden states transition to capture contexts. Moreover, our system introduces an adaptation mechanism to tune the initial HMM models (obtained from available training data) to improve performance by a small number of data from a new sports game video. Promising results has been demonstrated on the tennis, soccer and basketball videos with the total length of 2 hours.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {758–759},
numpages = {2},
keywords = {audio keywords, sports video, semantics, adaptive HMM},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027703,
author = {Luo, Hangzai and Fan, Jianping},
title = {Concept-Oriented Video Skimming via Semantic Video Classification},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027703},
doi = {10.1145/1027527.1027703},
abstract = {Effective video skimming requires a good understanding of the semantics of video contents. However, more existing systems for content-based video retrieval (CBVR) can only support low-level video analysis, but they have limited effectiveness on achieving semantic-sensitive video understanding. In this paper, we have developed a novel framework to achieve concept-oriented video skimming and it consists of three parts: (a) using salient objects for semantic-sensitive video content representation; (b) using finite mixture models for semantic video concept modeling and classification; (c) enabling concept-oriented video skimming via semantic video classification.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {760–761},
numpages = {2},
keywords = {semantic video classification, concept-oriented video skimming},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027704,
author = {Foote, Jonathan and Kimber, Don},
title = {Remote Interactive Graffiti},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027704},
doi = {10.1145/1027527.1027704},
abstract = {We present an installation that allows distributed internet participants to "draw" on a public scene using light. The iLight system is a camera/projector system designed for remote collaboration. Using a familiar digital drawing interface, remote users "draw" on a live video image of a real-life object or scene. Graics drawn by the user are then projected onto the scene, where they are visible in the camera image. Because camera distortions are corrected and the video is aligned with the image canvas, drawn graics appear exactly where desired. Thus the remote users may harmlessly mark a ysical object to serve their own their artistic and/or expressive needs. We also describe how local participants may interact with remote users through the projected images. Besides the intrinsic "neat factor" of action at a distance, this installation serves as an experiment in how multiple users from different locales and cultures can create a social space that interacts with a ysical one, as well as raising issues of free expression in a non-destructive context.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {762–763},
numpages = {2},
keywords = {remote collaboration, annotation, camera/projector systems, augmented reality},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027705,
author = {Batagelj, Borut and Solina, Franc and Peer, Peter},
title = {15 Seconds of Fame: An Interactive, Computer-Vision Based Art Installation},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027705},
doi = {10.1145/1027527.1027705},
abstract = {"15 seconds of fame" is an interactive installation which every 15 seconds generates a newpop-art portrait of a randomly selected person from the audience. The installation was inspired by Andy Warhol's ironical statement that "In the future everybody will be famous for 15 minutes". The installation detects human faces in digital images of people who are standing in front of the installation. Pop-art portraits are then generated from randomly chosen faces in the audience by applying randomlyselected filters. These portraits are shown in 15 second intervals on the flat-panel computer monitor which is framed as a painting. Electronic copies of each displayed portrait can be ordered by e-mail.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {764–765},
numpages = {2},
keywords = {face detection, color filters, computer vision application},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027706,
author = {Owsley, Sara and Shamma, David A. and Hammond, Kristian J. and Bradshaw, Shannon and Sood, Sanjay},
title = {The Association Engine: A Free Associative Digital Improviser},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027706},
doi = {10.1145/1027527.1027706},
abstract = {In this article, we present the Association Engine, a multimedia installation that explores the space of language and exposes connections between words by performing a series of improvisational games. It stands out from previous efforts in the realm of computers and theater as the agency has been empowered with a cultural understanding, more specifically, it uses the Web as a source of cultural reality.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {766–767},
numpages = {2},
keywords = {culture, software agents, network arts, media arts, world wide web},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027708,
author = {Halle, Michael W. and Kikinis, Ron},
title = {Flexible Frameworks for Medical Multimedia},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027708},
doi = {10.1145/1027527.1027708},
abstract = {The next generation of medical systems will integrate multimodality and multimedia data from a variety of sources to aid individual ysicians in providing the best treatment and care for their patients and to help researchers understand patterns of disease in collections of large databases. We promote a principle of maximum flexibility for the design of these systems to accommodate new developments in medical imaging and bioinformatics. We present several characteristics of flexible systems that support medical multimedia. We illustrate how these characteristics can be applied within diverse medical research and clinical therapy environments through two in-depth case studies. Within these examples, we describe how specific emerging technologies, including the semantic web and publish and subscribe networking, can enhance the flexibility of medical multimedia architectures.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {768–775},
numpages = {8},
keywords = {medical imaging, neurosurgery, segmentation, RDF, image guided therapy, multimedia, search, BIRN, feature extraction, ontologies, semantic web, publish and subscribe systems},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027709,
author = {Tagare, Hemant D. and Qian, Xiaoning and Fulbright, Robert K. and Long, Rodney and Antani, Sameer},
title = {Shape Based Retrieval in NHANES II},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027709},
doi = {10.1145/1027527.1027709},
abstract = {NHANES II is a nationally significant medical image database of spine x-ray images located at the National Library of Medicine. A key feature of spine disease in these images is the presence of osteoytes which are bony processes that alter the shape of vertebrae. Shapes of vertebrae are conveniently described in shape spaces which are non-linear manifolds. Indexing in such non-linear manifolds is an open problem. In this paper, we describe a technique of embedding shape manifolds in Euclidean spaces in a way that allows the use of classical indexing techniques for indexing shape. Application of this to the NHANES II database is also described.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {776–779},
numpages = {4},
keywords = {shape space, image databases, shape indexing},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027710,
author = {Syeda-Mahmood, Tanveer},
title = {Content-Based Retrieval in Gene Expression Databases},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027710},
doi = {10.1145/1027527.1027710},
abstract = {Research in the field of content-based retrieval has primarily focused on image, video an audio information. In this paper, we demonstrate content-based retrieval in a new data domain called gene expression data derive from gene chip images. In particular, we consider the problem of retrieving functionally similar genes from a database based on the pattern of variation of the expression of genes over time. Specifically, we model the time-varying gene expression patterns as curves, an analyze similarity between gene profiles by the relative amounts of twists an turns produce in a higher-imensional curve forme from the projection of the individual gene profiles. Scale-space analysis is use to detect the sharp twists an turns an their relative strength with respect to the component curves is estimated to form a shape similarity measure between gene profiles. The higher-dimensional curves also form prototypical escriptions of the individual gene profiles, serving as a way to index the database using clustering. Functionally similar genes are then identified using scale-space distance metric on the cluster prototypes.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {780–787},
numpages = {8},
keywords = {scale-space analysis, content-based retrieval, clustering, time-varying atabases},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027712,
author = {Schonberg, Daniel and Kirovski, Darko},
title = {Fingerprinting and Forensic Analysis of Multimedia},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027712},
doi = {10.1145/1027527.1027712},
abstract = {One of the prime reasons movie and music studios have ignored the Internet for open-networked multimedia content delivery, has been the lack of a technology that can support a secure digital rights management (DRM) system on a general purpose computer. The difficulty of building an effective multimedia DRM stems from the fact that traditional cryptograic primitives such as encryption or scrambling do not protect audio or video signals once they are played in plain-text. This fact, commonly referred to as "the analog hole," has been responsible for the popularity of multimedia file sharing which cannot be controlled, at least technically, by content's copyright owners.In this paper, we explore multimedia fingerprinting as an answer to "the analog hole" problem. We propose a new ase-shifted spread-spectrum fingerprinting paradigm particularly tailored for fast detection. Next, we present two techniques for fast maximum-likelihood audio and video synchronization designed to cope with typical de-synch attacks. We analyze the collusion resistance of a large class of spread-spectrum fingerprinting systems using a new, gradient attack. Surprisingly, we show that the collusion resistance of traditional spread-spectrum fingerprints is a small constant that does not depend on the object size.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {788–795},
numpages = {8},
keywords = {audio, collusion attack, forensic analysis, video, fingerprinting},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027713,
author = {Anderson, Richard and Hoyer, Crystal and Prince, Craig and Su, Jonathan and Videon, Fred and Wolfman, Steve},
title = {Speech, Ink, and Slides: The Interaction of Content Channels},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027713},
doi = {10.1145/1027527.1027713},
abstract = {In this paper, we report on an empirical exploration of digital ink and speech usage in lecture presentation. We studied the video archives of five Master's level Computer Science courses to understand how instructors use ink and speech together while lecturing, and to evaluate techniques for analyzing digital ink. Our interest in understanding how ink and speech are used together is to inform the development of future tools for supporting classroom presentation, distance education, and viewing of archived lectures. We want to make it easier to interact with electronic materials and to extract information from them. We want to provide an empirical basis for addressing challenging problems such as automatically generating full text transcripts of lectures, matching speaker audio with slide content, and recognizing the meaning of the instructor's ink. Our results include an evaluation of handwritten word recognition in the lecture domain, an approach for associating attentional marks with content, an analysis of linkage between speech and ink, and an application of recognition techniques to infer speaker actions.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {796–803},
numpages = {8},
keywords = {speech recognition, presentation, ink recognition, digital ink},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027714,
author = {Mekhaldi, Dalila and Lalanne, Denis and Ingold, Rolf},
title = {Thematic Segmentation of Meetings through Document/Speech Alignment},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027714},
doi = {10.1145/1027527.1027714},
abstract = {This article proposes a multimodal approach for segmenting meeting recordings. This bi-modal method takes advantages of the alignment of speech transcript with documents, in the context of meetings or lectures, where documents are discussed. The method first displays the alignment results as a set of nodes in a 2D space, where the two axes represent respectively the documents content and the speech transcript. The most connected regions in this graph are detected using a clustering method. The final clusters are then projected on the speech axis. Finally, the obtained sequence of segments is considered as the thematic structure of the speech transcript. In this article, we present our bi-modal method and compare it with two other mono-modal thematic segmentation methods.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {804–811},
numpages = {8},
keywords = {multimodal thematic alignment, meeting dialogs structuring, thematic segmentation, document analysis, multimedia information retrieval, clustering techniques},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027716,
author = {Wang, Ge and Cook, Perry},
title = {ChucK: A Programming Language for on-the-Fly, Real-Time Audio Synthesis and Multimedia},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027716},
doi = {10.1145/1027527.1027716},
abstract = {In this paper, we describe ChucK - a programming language and programming model for writing precisely timed, concurrent audio synthesis and multimedia programs. Precise concurrent audio programming has been an unsolved (and ill-defined) problem. ChucK provides a concurrent programming model that solves this problem and significantly enhances designing, developing, and reasoning about programs with complex audio timing. ChucK employs a novel <i>data-driven</i> timing mechanism and a related <i>time-based synchronization</i> model, both implemented in a virtual machine. We show how these features enable precise, concurrent audio programming and provide a high degree of programmability in writing real-time audio and multimedia programs. As an extension, programmers can use this model to write code <i>on-the-fly</i> -- while the program is running. These features provide a powerful programming tool for building and experimenting with complex audio synthesis and multimedia programs.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {812–815},
numpages = {4},
keywords = {real-time, concurrency, synchronization, compiler, programming language, signal processing, multimedia, audio synthesis, virtual machine},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027717,
author = {Eleftheriadis, Alexandros and Hong, Danny},
title = {Flavor: A Formal Language for Audio-Visual Object Representation},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027717},
doi = {10.1145/1027527.1027717},
abstract = {We present Flavor, a formal language for audio-visual object representation, that has been developed to describe any coded multimedia data in formats such as GIF, JPEG and MPEG. The language comes with a translator for generating C++/Java code from the Flavor description, and the generated code can include bitstream reading, writing and tracing methods. Since Version 5.0, the translator has been enhanced to also support XML. With the enhanced translator, the generated C++/Java code can include a method for producing XML documents that correspond to the bitstreams described by Flavor. The description can also be used to generate a corresponding XML schema. Additionally, a software tool for converting XML representation of multimedia data back into bitstream form is provided.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {816–819},
numpages = {4},
keywords = {XFlavor, flavor, media representation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027719,
author = {Duygulu, Pinar and Pan, Jia-Yu and Forsyth, David A.},
title = {Towards Auto-Documentary: Tracking the Evolution of News Stories},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027719},
doi = {10.1145/1027527.1027719},
abstract = {News videos constitute an important source of information for tracking and documenting important events. In these videos, news stories are often accompanied by short video shots that tend to be repeated during the course of the event. Automatic detection of such repetitions is essential for creating auto-documentaries, for alleviating the limitation of traditional textual topic detection methods. In this paper, we propose novel methods for detecting and tracking the evolution of news over time. The proposed method exploits both visual cues and textual information to summarize evolving news stories. Experiments are carried on the TREC-VID data set consisting of 120 hours of news videos from two different channels.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {820–827},
numpages = {8},
keywords = {graph-based multi-modal topic discovery, auto-documentary, matching logos, news video analysis, duplicate sequences},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027720,
author = {Jung, Byunghee and Kwak, Taeyeong and Song, Junehwa and Lee, Yoonjoon},
title = {Narrative Abstraction Model for Story-Oriented Video},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027720},
doi = {10.1145/1027527.1027720},
abstract = {TV program review services, especially drama review services, are one of the most popular video on demand services on the Web. In this paper, we propose a novel video abstraction model for a review service of story-oriented video such as dramas. In a drama review service, viewers want to understand the story in a short time and service providers want to provide video abstracts at minimum cost. The proposed model enables the automatic creation of a video abstract that still allows viewers to understand the overall story of the source video. Also, the model has a flexible structure so that the duration of an abstract can be adjusted depending on the requirements given by viewers. We get clues for human understanding of a story from scenario writing rules and editorial techniques which are popularly used in the process of video producing. We have implemented the proposed model and successfully applied it to several TV dramas.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {828–835},
numpages = {8},
keywords = {story-oriented, narrative structure, narrative abstraction, story understanding, film, video abstraction},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027721,
author = {Li, Chuanjun and Zhai, Peng and Zheng, Si-Qing and Prabhakaran, Balakrishnan},
title = {Segmentation and Recognition of Multi-Attribute Motion Sequences},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027721},
doi = {10.1145/1027527.1027721},
abstract = {In this work, we focus on fast and efficient recognition of motions in multi-attribute continuous motion sequences. 3D motion capture data, animation motion data, and sensor data from gesture sensing devices are examples of multi-attribute continuous motion sequences. These sequences have multiple attributes rather than only one attribute as time series data has. Motions can have different rates and durations, and the resulting data can thus have different lengths. Also, motion data can have noises due to transitions between successive motions. Hence, traditional distance measuring approaches used for time series data (such as Euclidean distances or dynamic time-warped distances) are not suitable for recognition in multi-attribute motion sequences. Hence, we have defined a similarity measure based on the analysis of singular value decomposition (SVD) properties of similar multi-attribute motions. A five-phase algorithm has then been proposed that gives good pruning power by exploiting the proximity of continuous motion data. We experimented this algorithm with data from different sources: 3D motion capture devices, animation motions, and CyberGlove gesture sensing device. These experiments show that our algorithm can segment and recognize long motion streams with high accuracy and in real time without knowing beforehand the number of motions in a stream.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {836–843},
numpages = {8},
keywords = {segmentation, gesture, pattern recognition, singular value decomposition, multi-attribute motion},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027723,
author = {Cao, Yu and Li, Dalei and Tavanapong, Wallapak and Oh, JungHwan and Wong, Johnny and de Groen, Piet C.},
title = {Parsing and Browsing Tools for Colonoscopy Videos},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027723},
doi = {10.1145/1027527.1027723},
abstract = {Colonoscopy is an important screening tool for colorectal cancer. During a colonoscopic procedure, a tiny video camera at the tip of the endoscope generates a video signal of the internal mucosa of the colon. The video data are displayed on a monitor for real-time analysis by the endoscopist. We call videos captured from colonoscopic procedures <i>colonoscopy videos</i>. Because these videos possess unique characteristics, new types of semantic units and parsing techniques are required. In this paper, we define new semantic units called <i>operation shots</i>, each is a segment of visual and audio data that correspond to a therapeutic or biopsy operation. We introduce a new spatio-temporal analysis technique to detect operation shots. Our experiments on colonoscopy videos demonstrate that the technique does not miss any meaningful operation shots and incurs a small number of false operation shots. Our prototype parsing software implements the operation shot detection technique along with our other techniques previously developed for colonoscopy videos. Our browsing tool enables users to quickly locate operation shots of interest. The proposed technique and software are useful (1) for post-procedure reviews and analyses for causes of complications due to biopsy or therapeutic operations, (2) for developing an effective content-based retrieval system for colonoscopy videos to facilitate endoscopic research and education, and (3) for development of a systematic approach to assess endoscopists' procedural skills.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {844–851},
numpages = {8},
keywords = {video segmentation, browsing, image and audio analysis},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027724,
author = {Wu, Wen and Chen, Xilin and Yang, Jie},
title = {Incremental Detection of Text on Road Signs from Video with Application to a Driving Assistant System},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027724},
doi = {10.1145/1027527.1027724},
abstract = {This paper proposes a fast and robust framework for incrementally detecting text on road signs from natural scene video. The new framework makes two main contributions. First, the framework applies a Divide-and-Conquer strategy to decompose the original task into two sub-tasks, that is, localization of road signs and detection of text. The algorithms for the two sub-tasks are smoothly incorporated into a unified framework through a real time tracking algorithm. Second, the framework provides a novel way for text detection from video by integrating 2D features in each video frame (e.g., color, edges, texture) with 3D information available in a video sequence (e.g., object structure). The feasibility of the proposed framework has been evaluated on the video sequences captured from a moving vehicle. The new framework can be applied to a driving assistant system and other tasks of text detection from video.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {852–859},
numpages = {8},
keywords = {incremental text detection, road sign, driving assistant system, natural scene video},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027725,
author = {Jouppi, Norman P. and Iyer, Subu and Thomas, Stan and Slayden, April},
title = {BiReality: Mutually-Immersive Telepresence},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027725},
doi = {10.1145/1027527.1027725},
abstract = {BiReality (a.k.a. Mutually-Immersive Telepresence) uses a teleoperated robotic surrogate to provide an immersive telepresence system for face-to-face interactions. Our goal is to recreate to the greatest extent practical, both for the user and the people at the remote location, the sensory experience relevant for face-to-face interactions of the user actually being in the remote location. Our system provides a 360-degree surround immersive audio and visual experience for both the user and remote participants, and streams eight 704x480 MPEG-2 coded videos totaling 20Mb/s. The system preserves gaze and eye contact, presents local and remote participants to each other at life size, and preserves the head height of the user at the remote location. Initial user experiences are presented.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {860–867},
numpages = {8},
keywords = {robotics, video conferencing, computer-supported collaborative work, spatial audio, audio conferencing, video mediated communication},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027727,
author = {Boll, Susanne and Bulterman, Dick and Jain, Ramesh and Chua, Tat-Seng and Lienhart, Rainer and Wilcox, Lynn and Davis, Marc and Venkatesh, Svetha},
title = {Between Context-Aware Media Capture and Multimedia Content Analysis: Where Do We Find the Promised Land?},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027727},
doi = {10.1145/1027527.1027727},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {868},
numpages = {1},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027729,
author = {Ke, Yan and Sukthankar, Rahul and Huston, Larry},
title = {An Efficient Parts-Based near-Duplicate and Sub-Image Retrieval System},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027729},
doi = {10.1145/1027527.1027729},
abstract = {We introduce a system for near-duplicate detection and sub-image retrieval. Such a system is useful for finding copyright violations and detecting forged images. We define near-duplicate as images altered with common transformations such as changing contrast, saturation, scaling, cropping, framing, etc. Our system builds a parts-based representation of images using <i>distinctive local descriptors</i> which give high quality matches even under severe transformations. To cope with the large number of features extracted from the images, we employ <i>locality-sensitive hashing</i> to index the local descriptors. This allows us to make approximate similarity queries that only examine a small fraction of the database. Although locality-sensitive hashing has excellent theoretical performance properties, a standard implementation would still be unacceptably slow for this application. We show that, by optimizing layout and access to the index data on disk, we can efficiently query indices containing millions of keypoints. Our system achieves near-perfect accuracy (100% precision at 99.85% recall) on the tests presented in Meng <i>et al.</i> [16], and consistently strong results on our own, significantly more challenging experiments. Query times are interactive even for collections of thousands of images.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {869–876},
numpages = {8},
keywords = {locality-sensitive hashing (LSH), near-duplicate image detection, local image descriptors, interest points, sub-image retrieval},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027730,
author = {Zhang, Dong-Qing and Chang, Shih-Fu},
title = {Detecting Image Near-Duplicate by Stochastic Attributed Relational Graph Matching with Learning},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027730},
doi = {10.1145/1027527.1027730},
abstract = {Detecting Image Near-Duplicate (IND) is an important problem in a variety of applications, such as copyright infringement detection and multimedia linking. Traditional image similarity models are often difficult to identify IND due to their inability to capture scene composition and semantics. We present a part-based image similarity measure derived from stochastic matching of Attributed Relational Graphs that represent the compositional parts and part relations of image scenes. Such a similarity model is fundamentally different from traditional approaches using low-level features or image alignment. The advantage of this model is its ability to accommodate spatial attributed relations and support supervised and unsupervised learning from training data. The experiments compare the presented model with several prior similarity models, such as color histogram, local edge descriptor, etc. The presented model outperforms the prior approaches with large margin.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {877–884},
numpages = {8},
keywords = {image near-duplicate detection, attributed relational graph matching, part-based image similarity measure},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027731,
author = {Zheng, Xin and Cai, Deng and He, Xiaofei and Ma, Wei-Ying and Lin, Xueyin},
title = {Locality Preserving Clustering for Image Database},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027731},
doi = {10.1145/1027527.1027731},
abstract = {It is important and challenging to make the growing image repositories easy to search and browse. Image clustering is a technique that helps in several ways, including image data preprocessing, user interface designing, and search result representation. Spectral clustering method has been one of the most promising clustering methods in the last few years, because it can cluster data with complex structure, and the (near) global optimum is guaranteed. However, existing spectral clustering algorithms, like Normalized Cut, are difficult to handle data points out of training set. In this paper, we propose a clustering algorithm named Locality Preserving Clustering (LPC), which shares many of the data representation properties of nonlinear spectral method. Yet LPC provides an explicit mapping function which is defined everywhere, both on training data points and testing points. Experimental results show that LPC is more accurate than both "direct Kmeans" and "PCA + Kmeans". We also show that LPC produces in general comparable results with Normalized Cut, yet is more efficient than Normalized Cut.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {885–891},
numpages = {7},
keywords = {locality preserving projections, spectral clustering, image clustering, locality preserving clustering},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027732,
author = {Jin, Rong and Chai, Joyce Y. and Si, Luo},
title = {Effective Automatic Image Annotation via a Coherent Language Model and Active Learning},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027732},
doi = {10.1145/1027527.1027732},
abstract = {Image annotations allow users to access a large image database with textual queries. There have been several studies on automatic image annotation utilizing machine learning techniques, which automatically learn statistical models from annotated images and apply them to generate annotations for unseen images. One common problem shared by most previous learning approaches for automatic image annotation is that each annotated word is predicated for an image independently from other annotated words. In this paper, we proposed a coherent language model for automatic image annotation that takes into account the word-to-word correlation by estimating a coherent language model for an image. This new approach has two important advantages: 1) it is able to automatically determine the annotation length to improve the accuracy of retrieval results, and 2) it can be used with active learning to significantly reduce the required number of annotated image examples. Empirical studies with Corel dataset are presented to show the effectiveness of the coherent language model for automatic image annotation.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {892–899},
numpages = {8},
keywords = {statistical models, image retrieval, image annotation, expectation-maximization algorithm},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027734,
author = {Gopalan, Kartik and Chiueh, Tzi-cker and Lin, Yow-Jian},
title = {Probabilistic Delay Guarantees Using Delay Distribution Measurement},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027734},
doi = {10.1145/1027527.1027734},
abstract = {Carriers increasingly differentiate their wide-area connectivity offerings by means of customized services, such as virtual private networks (VPN) with Quality of Service (QoS) guarantees, or QVPNs. The key challenge faced by carriers is to maximize the number of QVPNs admitted by exploiting the statistical multiplexing nature of input traffic. While existing measurement-based admission control algorithms utilize statistical multiplexing along the bandwidth dimension, they do not satisfactorily exploit statistical multiplexing along the <i>delay dimension</i> to guarantee <i>distinct per-QVPN delay bounds</i>. This paper presents Delay Distribution Measurement (DDM) based admission control algorithm, the first measurement-based approach that effectively exploits statistical multiplexing along the delay dimension. In other words, DDM exploits the well known fact that the actual delay experienced by most packets of a QVPN is usually far smaller than its worst-case delay bound requirement since multiple QVPNs rarely send traffic bursts at the same time. Additionally, DDM supports QVPNs with distinct probabilistic delay guarantees -- QVPNs that can tolerate more delay violations can reserve fewer resource than those that tolerate less, even though they require the same delay bound. A comprehensive performance evaluation using Voice over IP traces shows that, when compared to deterministic admission control, DDM can potentially increase the number of admitted QVPNs (and link utilization) by up to a factor of 3.0 even when the delay violation probability is as small as 10<sup>-5</sup>.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {900–907},
numpages = {8},
keywords = {measurement-based, admission control, statistical multiplexing},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027735,
author = {Wang, Bing and Kurose, Jim and Shenoy, Prashant and Towsley, Don},
title = {Multimedia Streaming via TCP: An Analytic Performance Study},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027735},
doi = {10.1145/1027527.1027735},
abstract = {TCP is widely used in commercial media streaming systems, with recent measurement studies indicating that a significant fraction of Internet streaming media is currently delivered over HTTP/TCP. These observations motivate us to develop analytic performance models to systematically investigate the performance of TCP for both live and stored media streaming. We validate our models via <i>ns</i> simulations and experiments conducted over the Internet. Our models provide guidelines indicating the circumstances under which TCP streaming leads to satisfactory performance, showing, for example, that TCP generally provides good streaming performance when the achievable TCP throughput is roughly twice the media bitrate, with only a few seconds of startup delay.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {908–915},
numpages = {8},
keywords = {performance modeling, multimedia streaming},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027736,
author = {Hassan, Mohamed and Atzori, Luigi and Krunz, Marwan},
title = {Video Transport over Wireless Channels: A Cycle-Based Approach for Rate Control},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027736},
doi = {10.1145/1027527.1027736},
abstract = {We propose a novel source-rate control scheme for streaming video over wireless channels. This scheme is designed to maximize the bit rate at the encoder while guaranteeing an upper bound on the probability of starvation at the playback buffer. Channel dynamics are captured using the Gilbert-Elliot model, with alternating <i>good</i> and <i>bad</i> periods. In contrast to previous approaches, rate control in our scheme is performed adaptively on a per-cycle basis, where a cycle consists of one good period and the ensuing bad period. The cycle-based approach has two advantages. First, it reduces the fluctuations in the source bit rate, ensuring smooth variations in video quality and avoiding the "saw" effect that is typically observed in frame-by-frame rate control. Second, it makes it possible to derive a closed-form expression for the starvation probability, which we use to determine the optimal source bit rates for the good and bad periods of the following cycle. Because of its low computational complexity, the proposed scheme is attractive for real-time video streaming. Simulations are carried out to assess the performance of the scheme and study the interactions among various system parameters.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {916–923},
numpages = {8},
keywords = {adaptive FEC, wireless channels, source rate control, channel-code optimization, playback buffer control},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027737,
author = {Yuan, Wanghong and Nahrstedt, Klara},
title = {Practical Voltage Scaling for Mobile Multimedia Devices},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027737},
doi = {10.1145/1027527.1027737},
abstract = {This paper presents the design, implementation, and evaluation of a <i>practical</i> voltage scaling (PDVS) algorithm for mobile devices primarily running multimedia applications. PDVS seeks to minimize the total energy of the whole device while meeting multimedia timing requirements. To do this, PDVS extends traditional real-time scheduling by deciding <i>what execution speed</i> in addition to when to execute what applications. PDVS makes these decisions based on the discrete speed levels of the CPU, the total power of the device at different speeds, and the probability distribution of CPU demand of multimedia applications. We have implemented PDVS in the Linux kernel and evaluated it on an HP laptop. Our experimental results show that PDVS saves energy substantially without affecting multimedia performance. It saves energy by 14.4% to 37.2% compared to scheduling algorithms without voltage scaling and by up to 10.4% compared to previous voltage scaling algorithms that assume an ideal CPU with continuous speeds and cubic power-speed relationship.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {924–931},
numpages = {8},
keywords = {mobile computing, multimedia, power management},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027739,
author = {Ashdown, Mark and Robinson, Peter},
title = {A Personal Projected Display},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027739},
doi = {10.1145/1027527.1027739},
abstract = {User interfaces using windows, keyboard and mouse have been in use for over 30 years, but only offer limited facilities to the user. Conventional displays are small, at least compared with a physical desk; conventional input devices restrict both manual expression and cognitive flexibility; remote collaboration is a poor shadow of sitting in the same room. We show how recent technological advances in large display devices and input devices can address these problems. The <i>Escritoire</i> is a desk-based interface using overlapping projectors to create a large display with a high resolution region in the centre for detailed work. Two pens provide bimanual input over the entire area, and an interface like physical paper addresses some of the affordances not provided by the conventional user interface. Multiple desks can be connected to allow remote collaboration. The system has been tested with single users and collaborating pairs.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {932–933},
numpages = {2},
keywords = {videoconferencing, projected displays, task space, pen input, person space, foveal display},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027740,
author = {Klante, Palle and Kr\"{o}sche, Jens and Ratt, Daniela and Boll, Susanne},
title = {First-Year Students' Paper Chase: A Mobile Location-Aware Multimedia Game},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027740},
doi = {10.1145/1027527.1027740},
abstract = {The latest achievements in the field of mobile networks and ubiquitous computing enable the integration and combination of technologies like Internet, Java, and multimedia in a new kind of application that employs distribution, wireless networking, localisation, and movement---mobile location-aware multimedia games. The approach presented is an innovative re-invention of a paper chase/scavenger hunt as a mobile location-aware game. The video demonstration illustrates the technical foundation and the system design of the mobile game. We also show the fun and the action of the game following some students when they play the game on our university campus.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {934–935},
numpages = {2},
keywords = {graphical user interface, physical navigation, geo-referenced multimedia, location-aware mobile games, auditory},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027741,
author = {Davis, Marc},
title = {Mobile Media Metadata: Metadata Creation System for Mobile Images},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027741},
doi = {10.1145/1027527.1027741},
abstract = {In the 2003, more camera phones were sold worldwide than digital cameras. With this new platform, we can leverage regularities in the spatio-temporal context and social community of media capture and use to infer media content. We created and deployed a "Mobile Media Metadata" (MMM) prototype on Nokia 3650 camera phones with 55 users that uses "context-to-content" inferencing, a shared metadata ontology, and user interaction at the point of capture to effectively infer media content annotations, specifically the semantic description of the location of the subject of users' photos.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {936–937},
numpages = {2},
keywords = {mobile camera phones, contextual metadata, wireless multimedia applications, content-based image retrieval, location-based services, context-to-content inference},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027742,
author = {Gurrin, Cathal and Lee, Hyowon and Smeaton, Alan F.},
title = {Fischl\'{a}r @ TRECVID2003: System Description},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027742},
doi = {10.1145/1027527.1027742},
abstract = {In this paper we give an outline of the Fischlar system developed to enable participation in the interactive search task within TRECVID 2003. TRECVID is an annual benchmarking exercise which measures the effectiveness of various video information retrieval tasks, including interactive retrieval. The accompanying video provides a usage scenario for our TRECVID2003 system which highlights how a user uses the system in order to perform retrieval of video shots.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {938–939},
numpages = {2},
keywords = {video libraries, video information retrieval, content browsing},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027743,
author = {Liu, Qiong and Zhao, Frank and Doherty, John and Kimber, Don},
title = {An EPIC Enhanced Meeting Environment},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027743},
doi = {10.1145/1027527.1027743},
abstract = {ePic is an integrated presentation authoring and playback system that makes it easy to use a wide range of devices installed in one or multiple multimedia venues.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {940–941},
numpages = {2},
keywords = {presentation authoring, computer assisted presentation authoring, multimedia venues, rich media presentation, device control},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027744,
author = {Walker, Joanna and Bluemm, Steffen and Haslett, Bill},
title = {The Evolving Oblique: The Embodiment of a Virtual Topology},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027744},
doi = {10.1145/1027527.1027744},
abstract = {The Evolving Oblique is an interactive video and sound installation that explores the spatialization of cinematic projection and the mediative role of the human body. Centered upon the theme of transformative nature, the installation re-contextualizes notions of landscape and architectural form into a new topology through the embodiment of the moving image.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {942–943},
numpages = {2},
keywords = {interactive installation, architecture, topology},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027746,
author = {Wang, Xin-Jing and Ma, Wei-Ying and Xue, Gui-Rong and Li, Xing},
title = {Multi-Model Similarity Propagation and Its Application for Web Image Retrieval},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027746},
doi = {10.1145/1027527.1027746},
abstract = {In this paper, we propose an iterative similarity propagation approach to explore the inter-relationships between Web images and their textual annotations for image retrieval. By considering Web images as one type of objects, their surrounding texts as another type, and constructing the links structure between them via webpage analysis, we can iteratively reinforce the similarities between images. The basic idea is that if two objects of the same type are both related to one object of another type, these two objects are similar; likewise, if two objects of the same type are related to two different, but similar objects of another type, then to some extent, these two objects are also similar. The goal of our method is to fully exploit the mutual reinforcement between images and their textual annotations. Our experiments based on 10,628 images crawled from the Web show that our proposed approach can significantly improve Web image retrieval performance.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {944–951},
numpages = {8},
keywords = {mutual reinforcement, mixture model, iterative similarity propagation, multimedia retrieval},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027747,
author = {Cai, Deng and He, Xiaofei and Li, Zhiwei and Ma, Wei-Ying and Wen, Ji-Rong},
title = {Hierarchical Clustering of WWW Image Search Results Using Visual, Textual and Link Information},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027747},
doi = {10.1145/1027527.1027747},
abstract = {We consider the problem of clustering Web image search results. Generally, the image search results returned by an image search engine contain multiple topics. Organizing the results into different semantic clusters facilitates users' browsing. In this paper, we propose a hierarchical clustering method using visual, textual and link analysis. By using a vision-based page segmentation algorithm, a web page is partitioned into blocks, and the textual and link information of an image can be accurately extracted from the block containing that image. By using block-level link analysis techniques, an image graph can be constructed. We then apply spectral techniques to find a Euclidean embedding of the images which respects the graph structure. Thus for each image, we have three kinds of representations, i.e. visual feature based representation, textual feature based representation and graph based representation. Using spectral clustering techniques, we can cluster the search results into different semantic clusters. An image search example illustrates the potential of these techniques.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {952–959},
numpages = {8},
keywords = {image clustering, spectral analysis, web image search, graph model, search result organization, link analysis, vision based page segmentation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027748,
author = {Feng, Huamin and Shi, Rui and Chua, Tat-Seng},
title = {A Bootstrapping Framework for Annotating and Retrieving WWW Images},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027748},
doi = {10.1145/1027527.1027748},
abstract = {Most current image retrieval systems and commercial search engines use mainly text annotations to index and retrieve WWW images. This research explores the use of machine learning approaches to automatically annotate WWW images based on a predefined list of concepts by fusing evidences from image contents and their associated HTML text. One major practical limitation of employing supervised machine learning approaches is that for effective learning, a large set of labeled training samples is needed. This is tedious and severely impedes the practical development of effective search techniques for WWW images, which are dynamic and fast-changing. As web-based images possess both intrinsic visual contents and text annotations, they provide a strong basis to bootstrap the learning process by adopting a co-training approach involving classifiers based on two orthogonal set of features -- visual and text. The idea of co-training is to start from a small set of labeled training samples, and successively annotate a larger set of unlabeled samples using the two orthogonal classifiers. We carry out experiments using a set of over 5,000 images acquired from the Web. We explore the use of different combinations of HTML text and visual representations. We find that our bootstrapping approach can achieve a performance comparable to that of the supervised learning approach with an F1 measure of over 54%. At the same time, it offers the added advantage of requiring only a small initial set of training samples.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {960–967},
numpages = {8},
keywords = {bootstrapping, co-training, WWW images, image annotation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027750,
author = {Boll, Susanne and Ahuja, Sudhir R. and Friebel, Dirk and Horowitz, Bradley and Raman, Neerja and Shankar, N. Sai},
title = {Where Are the Brave New Mobile Multimedia Applications?},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027750},
doi = {10.1145/1027527.1027750},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {968},
numpages = {1},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027752,
author = {Gotz, David},
title = {Supporting Adaptive Remote Access to Multiresolutional or Hierarchical Data for Large User Groups},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027752},
doi = {10.1145/1027527.1027752},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {969–970},
numpages = {2},
keywords = {adaptation, multimedia, remote data access, streaming},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027753,
author = {Bocconi, Stefano},
title = {Semantic-Aware Automatic Video Editing},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027753},
doi = {10.1145/1027527.1027753},
abstract = {One of the challenges of multimedia applications is to provide user-tailored access to information encoded in different media. Particularly, previous research has not yet fully explored how to automatically compose different video segments according to a communicative goal. We propose a rhetoric-based method to support the selection and automatic editing of user-requested content from video footage. The method is applied to the domain of video documentaries to create biased sequences about a user selected subject.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {971–972},
numpages = {2},
keywords = {video documentaries, media semantics, media rhetoric, automated video editing},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027754,
author = {Mekhaldi, Dalila and Lalanne, Denis},
title = {Thematic Alignment of Documents with Meeting Dialogs},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027754},
doi = {10.1145/1027527.1027754},
abstract = {The primary goal of this PhD thesis is to align printable documents with meetings' dialogs. This bi-modal alignment consists in bridging thematic links between documents' content and speech transcripts' content. An obvious application is a system that automatically link document parts with audio-video extracts of a meeting. Further, this bi-modal alignment is considered for thematically segmenting both meeting dialogs and documents discussed during this meeting.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {973–974},
numpages = {2},
keywords = {multimodal thematic alignment, meeting thematic segmentation},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027756,
author = {Cahill, Adrian J. and Sreenan, Cormac J.},
title = {An Efficient CDN Placement Algorithm for the Delivery of High-Quality TV Content},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027756},
doi = {10.1145/1027527.1027756},
abstract = {Personal Video Recorders (PVRs) such as TiVo have become very popular in recent years due to their ability to intelligently record TV content and make it accessible in an on-demand fashion to its users. Our research looks at providing a globally accessible storage architecture where all content broadcast over a period of time is available for streaming. Our architecture consists of idle ISP servers, that can be rented and released dynamically as the load requires. In this paper we focus on managing the resources required to provide TV on Demand (TVoD) system, and develop a cost function which examines the resources required to serve a client and identifies the optimal proxy to serve the client.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {975–976},
numpages = {2},
keywords = {P2P management, video on demand, resource management},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027757,
author = {Smith, Keir},
title = {From Transmission to Multiplicity: Interactive Art Installations as a Site for Research},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027757},
doi = {10.1145/1027527.1027757},
abstract = {Central Hypothesis: <i>The methods with which many contemporary interactive art installations are being designed, built and experienced is a model of multiplicity. Further, that the study of the multitudinous nature of this experience can inform our understanding of how people interact, in a computer interface mediated group situation, with both each other and the interface. The outcomes of which can, in turn, help improve how we design and build interfaces for collaborative interaction.</i> .This research, through a literature review, interviews with practitioners in the field and analysis of techniques and technologies the field employs, intends to show that this model of multiplicity, which I will call MMM (Multiple Modalities [for the Multitudes1]), is a common interactive installation art methodology. In which the single author is replaced by a group of collaborators, the single object is replaced by a multitude of objects and that, most importantly in this research, the single reader can be replaced by multitudinous collaborative viusers.The technology to build computer mediated collaborative interfaces is in its infancy. The human-computer interaction (HCI) community has vast experience with the single-user, single-interface situation, but precious little with multi-user interfaces, when those users are in same local space, using the same interface. It is the intention of the <i>in situ</i> study component of this thesis can be used, in conjunction with an appropriate literature review, to remedy this deficiency in our understanding.This research, employing a case study methodology, will investigate two works. <i>Conversations</i> a multimedia project currently being developed at the iCinema Centre and the <i>configurable</i>, experimental, interactive, multi-user same-site, installation <i>Socialising with Strangers</i> will be Then to help inform our understanding of group collaborative interaction. The technical infrastructure of <i>SwS</i> will include logging and recording software. A review of relevant research, as well as analysis of the data collected from <i>SwS</i>, <i>in situ</i>, will be combined to aid the generation of a set of guidelines for computer-mediated interactive systems for multiple locally situated viusers.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {977–978},
numpages = {2},
keywords = {interactive art, interaction and interface design, human factors, collaborative interfaces},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027759,
author = {Jaimes, Alejandro and Jennings, Pamela},
title = {ACM Multimedia Interactive Art Program: An Introduction to the Digital Boundaries Exhibition},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027759},
doi = {10.1145/1027527.1027759},
abstract = {The Digital Boundaries exhibition includes works that use multimedia to address issues of multiculturalism, identity, and awareness. By placing technology in new contexts to explore multimedia's impact on culture (and vice versa) we create a space for the discussion of new ideas and create an interdisciplinary impact by reinforcing a dialogue between the arts and multimedia communities. We discuss our motivation, the exhibition theme, the works selected, and their potential technical impact.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {979–980},
numpages = {2},
keywords = {arts research and practice, interactive art, culture, new media art, multimedia arts, technology},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027760,
author = {Wilson, Stephen},
title = {Traces of Culture: Searchbots Scour the Web Looking for Visual Information},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027760},
doi = {10.1145/1027527.1027760},
abstract = {<i>Traces of Culture</i> presents a series of real time interactive art events that use custom-crafted searchbots to investigate image search processes and the underlying compendium of visual information available on the World Wide Web.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {981–982},
numpages = {2},
keywords = {net art, visualization, interactive multimedia, searchbots},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027761,
author = {B\"{o}hlen, Marc and Rinker, J. T.},
title = {When Code is Content: Experiments with a Whistling Machine},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027761},
doi = {10.1145/1027527.1027761},
abstract = {The Universal Whistling Machine (U.W.M) senses the presence of people in its vicinity and attracts them with a signature whistle. Given a response whistle, U.W.M. counters with its own composition, based on a time-frequency analysis of the original.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {983–984},
numpages = {2},
keywords = {whistled languages, communication beyond language boundaries, whistle synthesis, situation design},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027762,
author = {Zu\~{n}iga, Ricardo Miranda},
title = {Vagamundo: A Migrant's Tale},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027762},
doi = {10.1145/1027527.1027762},
abstract = {Vagamundo is a mobile public art project and an online game. Through a mobile cart resembling an ice cream cart pedestrians are invited to play a video game that reflects the plight of illegal immigrants in New York City. Following an introduction -- Getting Across the Border, the player is challenged by various levels of social and cultural assimilation.Ideally, the project achieves two goals. First to present an interesting tableau that interrupts the given codes of public space as an unsuspecting pedestrian discovers a free videogame in an ice cream cart - a vehicle that represents an economic means to new immigrants. Secondly, Vagamundo places the player in the role of a new, undocumented immigrant to New York City, an experience that may cause one to consider what life is like for others. The "others" that the project concerns itself with is an impoverished immigrant subculture that goes highly unnoticed by main-stream media.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {985–986},
numpages = {2},
keywords = {digital art, Ricardo Miranda, interactive art, cantinflas, vagamundo, illegal immigrant, video game, public art},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027763,
author = {Tarrant, Patrick},
title = {Planet Usher: An Interactive Home Movie},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027763},
doi = {10.1145/1027527.1027763},
abstract = {<i>Planet Usher: An Interactive Home Movie</i> is a CD-Rom that draws inspiration and media from my brother's extensive home video archive; an archive that spans twenty years of family events and non-events [1]. What makes even the non-events remarkable, is the fact that my brother went from being a deaf man with a video camera, to a deaf-blind man with an extensive audio-visual archive he can no longer see, nor hear, due to the effects of Usher Syndrome. So <i>Planet Usher</i> offers an exploration of a sustained and enduring amateur practice. It is also a story about disability and the family as they emerge faultingly from the lost archive. And it is a confrontation with the frailties of memory and narrative as they come face to face with the vicissitudes of both interactivity and lived experience.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {987–988},
numpages = {2},
keywords = {home movies, interactive documentary, memory and narrative},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027764,
author = {Brown, Sheldon},
title = {Scalable City 0.7a},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027764},
doi = {10.1145/1027527.1027764},
abstract = {The Scalable City is a set of projects that explore the externalization of algorithmic approaches to urbanization that intersect with geographic, political, economic and aesthetic zones of conflict. Version 0.7a of the Scalable City is a multi-media exhibition consisting of various manifestations of landscape demarcation, personal embodiment and domicile transformations. Procedures governing the arrangement and operations of these discrete areas, are interchanged across domains - moving them from a more familiar basis to distorted and exaggerated extremes of patterns and juxtapositions. Through these processes, which reveal the procedural basis of the development of cultural forms, the mechanistic processes of social formation are highlighted. The forum for this version of the work is the US/Mexican border where collisions of cultural forms, political structures, economies and landscape are distinctly overt.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {989–990},
numpages = {2},
keywords = {montage, procedural form, installation, collage, multi-media, assemblage},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027765,
author = {Ireson, Brian},
title = {"Minions"},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027765},
doi = {10.1145/1027527.1027765},
abstract = {"Minions", an interactive audio/video installation dealing with the social impact and power of televised religious ideologies. Showcasing religious content from two major world civilizations, Christianity and Islam. Apparently diametrically opposed worldviews vie to control the hearts and minds of viewers; not only through the power of streaming images but the adherence to the "word" of the faithful as well. The viewer's presence triggers two series of megaphones (the Faithful) to increase the volume of what is being said in the video, attempting to entice new followers to the "cause". Considering that current lines of global conflict are following social lines, it is imperative to evaluate media content. Awareness of ideological saturating media content with the aim of to reinforcing current societal norms is vital.The viewer will the enter installation and stand between opposing projection screens and series of small megaphone forms. Ultrasonic sensors determine distance from center; this information is translated into volume control of the megaphones.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {991–992},
numpages = {2},
keywords = {prayer, christian, ultrasonic range finder, culture, interactive, multimedia, basic stamp, islam, audio-visual projection},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027766,
author = {Blue, Carroll Parrott},
title = {The Dawn at My Back},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027766},
doi = {10.1145/1027527.1027766},
abstract = {Interactive multimedia narrative in CD/DVD-ROMs and game design offers choice and non-linearity as communication signifiers. The viewer chooses where to go in an interactive design, viewing content in a non-traditional, non-linear fashion. However the content is totally controlled by the author, not the reader. The content is pre-determined while the viewer controls the viewing path in real time.<i>The Dawn At My Back: Memoir of a Black Texas Upbringing</i> outlines three parallel stories of a mother, a daughter, and a society by detailing racism's impact on each element. The concept is to design a combination Book/DVD-ROM/Website that allows the reader direct interaction with the narrative. This project expands on the idea that interactivity is a dialogue between viewer and story by encouraging the book's reader to become a DVD-ROM user and website co-author.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {993–994},
numpages = {2},
keywords = {interactive art, memoir, narrative, reader (user experience), storytelling, author, autobiography},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027767,
author = {Hohl, Michael},
title = {Radiomap: Experiential Interactive Environment},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027767},
doi = {10.1145/1027527.1027767},
abstract = {This paper describes the unencumbered interactive environment "radiomap". The first version of this interactive environment enables one or more individuals to walk about a projected photorealistic image of the Earth (Mercator projection[1], 8x4m) and listen to live internet radio broadcasts that are located at the corresponding locations. The interaction is simple and intuitive. This research project is exploring the experiential qualities of interactive environments, especially those that may be described as creating effects of presence, global awareness, holistic overview and feeling of interconnectedness.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {995–996},
numpages = {2},
keywords = {interaction principles, presence, immersive, unencumbered interaction, interactive installations, transformation of data into experience, psychological effects, natural interaction, insight, unencumbered, global awareness},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027768,
author = {Lawson, Shawn},
title = {Wu Wei},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027768},
doi = {10.1145/1027527.1027768},
abstract = {Interactive media is typically based on the idea of change. One creates a stimulus for the computer, which then gives a response. Changing the computer's response is determined by modifying its input.Wu Wei is the fundamental Taoist principle meaning "without action." When applied to an interactive artwork, this concept creates an oxymoron. Here, the intention is to act without acting. <i>Wu Wei</i> is both a non-interactive and interactive installation that uses computer vision as its control device. This piece is designed to question a participant's conceptions about interactive art, the pace of 21<sup>st</sup> century life, and digital media.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {997–998},
numpages = {2},
keywords = {interactive, invisible, chinese, action, meditation, non-action, scroll, taoism},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027769,
author = {Jaramillo, Cynthia Lawson},
title = {Vox Populi No. 2: A Bilingual Text and Sound Installation},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027769},
doi = {10.1145/1027527.1027769},
abstract = {This paper is a technical and conceptual description of the text and sound installation, Vox Populi No. 2 which integrates news feeds about Colombia, testimonies from Colombian citizens and user input.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {999–1000},
numpages = {2},
keywords = {installation, media and politics, interactivity, macromedia director, Colombia, new media, sound, arts, text},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027770,
author = {Yang, W.},
title = {Pictopia},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027770},
doi = {10.1145/1027527.1027770},
abstract = {The urban population in the developed world is living with unprecedented tolerance for diversity; material wealth has afforded us the time and space for our differences to co-exist. The ever proliferating cyberspace has added additional room to contain people, ideas and activities that are not necessarily compatible. Yet, is our city really multicultural? Cyberspace, instead of being on the fringe of physical reality, could become an infrastructure that enhances the intrinsic order in our city, resulting in a complex network of opportunities for our differences to interact and co-develop. Pictopia is a system in which our activities in the cyberspace can begin to overlap and intertwine with our everyday life in urban spaces. It prophesizes a new reality - a mixed reality that is rooted in the physical environment, harmoniously complimented and extended by virtual activities and resources. It uses the invisible geometrical orders beneath the city grids as a foundation and a conduit, to connect our memories and ideas to the physical world. Not only is it a functional file operating system, it also encourages its participants to question, learn, and visualize the relevance of their actions in cyberspace.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {1001–1002},
numpages = {2},
keywords = {urbanism, mediatecture, locatability, cybertecture, architecture},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027771,
author = {Senior, Andrew},
title = {Shibboleth: Exploring Cultural Boundaries in Speech},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027771},
doi = {10.1145/1027527.1027771},
abstract = {Shibboleth is a multimedia artwork that explores the cultural barriers created and enforced by accent and pronunciation differences. It is founded on the idea of biblical origin of a <i>shibboleth</i> --- a word or phrase that distinguishes one cultural group from another. The artwork consists of a computer interface through which users are able to to see and hear rhythmic audio-visual compositions of shibboleths created from previously recorded data and relevant sounds and imagery. Users can also use the interface to listen to examples of previously recorded shibboleths, as well as to add their own to a growing, geographically-indexed database.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {1003–1004},
numpages = {2},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027772,
author = {Wolanczyk, Roxanne},
title = {The Princess Series},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027772},
doi = {10.1145/1027527.1027772},
abstract = {The Princess Series is a narrative of a modern-day princess who found herself grown up without a fortune. Presented as a series of Flash animations, each story depicts her daily struggle to save her soul while trying to survive in the corporate world by making junk mail. She courageously faces the dilemmas, contradictions, and paradoxes of modern life. She questions her own emotions, ideals, psychology, gender, and identity, all in the hopes of a happy ending.The work can be presented on a variety of mediums such as computer screens, projectors, and plasma screens. Still images can also be scaled to any size for print.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {1005–1006},
numpages = {2},
keywords = {net art, interactive multimedia},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

@inproceedings{10.1145/1027527.1027773,
author = {Rubin, Cynthia Beth and Gluck, Robert J.},
title = {Layered Histories: The Wandering Bible of Marseilles},
year = {2004},
isbn = {1581138938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1027527.1027773},
doi = {10.1145/1027527.1027773},
abstract = {The artists developed an interactive work based on the imaginary story of an actual 13th century illuminated Bible, investigating the many levels of meaning of the Manuscript: as a beautiful artifact, as a work of art reflecting the convergence of cultures in medieval Spain, and as a text which tells stories which themselves are layered in meanings. Transforming their own photographs and sound samples with digital media, the creative process challenged the artists to incorporate traditional Jewish cultural motifs in a work intended to appeal to contemporary general audiences. Juxtaposition, reinterpretation, and hybrid formats as artistic approach parallel the essential nature of Jewish culture, as well that of other historically nomadic peoples.},
booktitle = {Proceedings of the 12th Annual ACM International Conference on Multimedia},
pages = {1007–1008},
numpages = {2},
keywords = {sound, Max/ MSP/Jitter, new media, morph, Columbia, text, installation, media, electroacoustic interactivity, arts},
location = {New York, NY, USA},
series = {MULTIMEDIA '04}
}

