@inproceedings{10.1145/641007.641009,
author = {Mayer-Patel, Ketan and Le, Long and Carle, Georg},
title = {An MPEG Performance Model and Its Application to Adaptive Forward Error Correction},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641009},
doi = {10.1145/641007.641009},
abstract = {We present a general analytical model for predicting the reconstructed frame rate of an MPEG stream. Our model captures the temporal relationships between I-, P, and B-frames but is independent of the channel and media characteristics. We derive an adaptive FEC scheme from the general model and verify it by comparing it to the results of a simulation. The prediction error of the model compared to the simulation for a wide array of parameter values is less than 5%. We then use the derived adaptive FEC scheme to study the optimal rate allocation (i.e., between generating a higher frame rate or increasing the protection for a lower frame rate) when equation-based TCP rate control is used to couple packet rates to channel characteristics such as round trip time and packet loss probabilities. Surprisingly, we find that optimal protection levels for I- and P-frames are relatively static as loss rates increase from 1% to 4% while changes in the frame type pattern are used to ameliorate the effects of the increased loss. The study demonstrates how our model can be used to reveal joint source/channel coding tradeoffs and how they relate to encoding and transmission parameters.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {1–10},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641010,
author = {Radenkovic, Milena and Greenhalgh, Chris},
title = {Multi-Party Distributed Audio Service with TCP Fairness},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641010},
doi = {10.1145/641007.641010},
abstract = {Distributed Partial Mixing is an approach to creating a distributed audio service that supports optimisation of bandwidth utilization across multiple related audio streams (e.g. from concurrently active audio sources) while maintaining fairness to TCP traffic in best effort networks. Rate adaptation of streamed audio is difficult because of its rate sensitivity, the relatively limited range of encoding bandwidths available and the potential impact on the end user of rate-adaptation artefacts (such as changes of encoding). This paper describes and demonstrates how our design combines TCP-fairness with the stability that is desirable for streaming audio and other rate sensitive media. In particular, our design combines: a distributed multi-stream management/mixing architecture, loss event and round-trip time monitoring, rate limiting based on a TCP rate equation, tuned increase and decrease strategies and a loss-driven network probing mode. Experimental validation is performed over a wide range of network conditions including against various congesting levels, TCP and independent DPM traffic.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {11–20},
numpages = {10},
keywords = {TCP-fairness, distributed partial mixing, mixing, multi-party audio, audio, congestion control, adaptation},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641012,
author = {Oshiba, Takashi and Koike, Yuichi and Tabuchi, Masahiro and Kamba, Tomonari},
title = {Personalized Advertisement-Duration Control for Streaming Delivery},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641012},
doi = {10.1145/641007.641012},
abstract = {This paper describes the development of a streaming advertisement delivery system that controls the insertion of streaming advertisements into streaming content.Conventional personalization techniques lack a time-control function for advertisement insertion, so the advertisement exposure for each user access can become excessive, much to the annoyance of viewers. This could devalue streaming content by making it less attractive.In our technique, advertisement insertion control is based on the history of each viewer. This personalization method makes it possible to maintain a balanced ratio of the advertisement length to the content length. As a result, our technique should encourage the growth of Internet streaming services and enable more effective and less intrusive advertising.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {21–28},
numpages = {8},
keywords = {internet streaming, advertisement delivery, personalization},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641013,
author = {Tantaoui, Mounir A. and Hua, Kien A. and Sheu, Simon},
title = {Interaction with Broadcast Video},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641013},
doi = {10.1145/641007.641013},
abstract = {In video-on-demand (VOD) applications, it is desirable to provide the user with the video-cassette-recorder-like (VCR) capabilities such as fast-forwarding a video or jumping to a specific frame. We address this issue in the broadcast framework, where each video is broadcast repeatedly on the network. Existing techniques rely on data prefetching as the mechanism to provide this functionality. This approach provides limited usability since the prefetching rate cannot keep up with typical fast-forward speeds. Fast-forwarding a video for several seconds would inevitably exhaust the prefetch buffer. We address this practical problem in this paper by repeatedly broadcasting the interactive versions of the videos. For instance, an interactive version might contain only every fifth frame in the original video. Our client software leverages these "interactive" broadcasts to provide better VCR service. We formally prove the correctness of this approach, and compare its performance to a prefetch method, called active buffer management. This scheme has been shown to offer, in the broadcast environment, the best performance to date. Our simulation results indicate that the new technique is superior in handling long-duration VCR actions.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {29–38},
numpages = {10},
keywords = {fast reverse, latency, fast forward, periodic broadcast, video on demand},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641014,
author = {Grigoras, Romulus and Charvillat, Vincent and Douze, Matthijs},
title = {Optimizing Hypervideo Navigation Using a Markov Decision Process Approach},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641014},
doi = {10.1145/641007.641014},
abstract = {Interaction with hypermedia documents is a required feature for new sophisticated yet flexible multimedia applications. This paper presents an innovative adaptive technique to stream hypervideo that takes into account user behaviour. The objective is to optimize hypervideo prefetching in order to reduce the latency caused by the network. This technique is based on a model provided by a Markov Decision Process approach. The problem is solved using two methods: classical stochastic dynamic programming algorithms and reinforcement learning. Experimental results under stochastic network conditions are very promising.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {39–48},
numpages = {10},
keywords = {reinforcement learning, prefetching, optimization, simulation, Markov Decision Process, navigation, streaming, hypermedia, uncertainty, interaction},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641016,
author = {Teixeira, Dario and Faihe, Yassine},
title = {In-Home Access to Multimedia Content},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641016},
doi = {10.1145/641007.641016},
abstract = {This paper discusses the problem of content overload in the home environment. We describe the various domains where the problem manifests itself, and we analyse which user activities could benefit from software assistance. In particular, we focus on the problem of searching for information, and we introduce the concept of Conversational Search as the means to tackle it. We also introduce a framework to test several heuristics related to Conversational Search, and show how using a model of the user can significantly improve the results of purely information-theoretical heuristics.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {49–56},
numpages = {8},
keywords = {multimedia, conversational search, browsing assistants, digital photography, content overload, user modelling, conversational interfaces, home environments},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641017,
author = {Chu, Wei-Ta and Chen, Herng-Yow},
title = {Cross-Media Correlation: A Case Study of Navigated Hypermedia Documents},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641017},
doi = {10.1145/641007.641017},
abstract = {The research issues on multiple media correlation have arisen with more and more integrated multimedia applications. The multimedia correlation is used to coordinate different media and facilitate cross-media access. This paper presents our work on two types of multimedia correlation: explicit and implicit relations. We develop a system to carefully capture explicit relations and devise some computed synchronization processes to discover implicit relations between media objects. The proposed computed synchronization techniques, including speech-text alignment process in temporal domain, automatic scrolling process in spatial domain, and content dependency check process in content domain, will be addressed. Experimental results show that in the speech-text alignment process 80% of forced alignment are in-sync even the speech recognition accuracy is as low as 25%. The automatic scrolling process effectively maintains a resynchronization mechanism in different displaying environments.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {57–66},
numpages = {10},
keywords = {computed synchronization process, cross-media correlation, explicit relation, implicit relation},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641018,
author = {Gotz, David and Mayer-Patel, Ketan and Manocha, Dinesh},
title = {IRW: An Incremental Representation for Image-Based Walkthroughs},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641018},
doi = {10.1145/641007.641018},
abstract = {We present a new representation for image-based interactive walk-throughs. The target applications reconstruct a scene from novel viewpoints using samples from a spatial image dataset collected from a plane at eye-level. These datasets consist of pose augmented 2D images and often have a very large number of samples. Our representation exploits spatial coherence and rearranges the input samples as epipolar images. The base unit corresponds to a column of the original image that can be individually addressed and accessed. The overall representation, IRW, supports incremental updates, efficient encoding, scalable performance, and selective inclusion used by different reconstruction algorithms. We demonstrate the performance of our representation on a synthetic as well as a real-world environment.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {67–76},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641020,
author = {Su\'{a}rez, F. J. and Garc\'{\i}a, X. X. and Garc\'{\i}a, V. G.},
title = {Lost Cost, Highly Available, High Performance Talks-on-Demand System},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641020},
doi = {10.1145/641007.641020},
abstract = {Real-time distribution of continuous media on demand is a natural step in the evoluation of internet services. Here, we briefly present an interactive talks-on-demand service currently integrated in a digital newspaper. Low cost, high availability and high performance are features of the system supporting the service.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {77–78},
numpages = {2},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641021,
author = {Zhu, Xingquan and Fan, Jianping and Hacid, Mohand-Said and Elmagarmid, Ahmed K.},
title = {ClassMiner: Mining Medical Video for Scalable Skimming and Summarization},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641021},
doi = {10.1145/641007.641021},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {79–80},
numpages = {2},
keywords = {video data mining, video summarization, event detection, scalable skimming, scene detection},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641022,
author = {Sun, Yanfeng and Zhang, Hongjiang and Zhang, Lei and Li, Mingjing},
title = {<i>MyPhotos</i>: A System for Home Photo Management and Processing},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641022},
doi = {10.1145/641007.641022},
abstract = {MyPhotos is a prototype system for home photo management and processing. Several home user orientated image processing and analysis tools are provided. And several auto grouping methods can help user to organize photos. The system also provides a natural user interface and a workflow for easy browsing and searching.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {81–82},
numpages = {2},
keywords = {image processing, home photo management, photo grouping},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641023,
author = {Mekenkamp, Gerhard and Huet, Benoit and Leonardi, Riccardo and Rose, Michael},
title = {Generating TV Summaries for CE-Devices},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641023},
doi = {10.1145/641007.641023},
abstract = {Automatically generated summaries of TV content are indispensable for content selection and navigation in CE-devices. We show two different types of summaries: Short video trailers and visual overviews consisting of representative frames. The demo does not only show the feasibility of the proposed algorithms, but also shows how different types of generated summaries can be used in future CE-devices.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {83–84},
numpages = {2},
keywords = {content analysis, video summaries},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641024,
author = {D\"{o}ller, Mario and Kosch, Harald and D\"{o}rflinger, Bernhard and Bachlechner, Alexander and Blaschke, Gisela},
title = {Demonstration of an MPEG-7 Multimedia Data Cartridge},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641024},
doi = {10.1145/641007.641024},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {85–86},
numpages = {2},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641025,
author = {Tan, Tele and Chen, Jiayi and Mulhem, Philippe and Kankanhalli, Mohan},
title = {SmartAlbum: A Multi-Modal Photo Annotation System},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641025},
doi = {10.1145/641007.641025},
abstract = {This demonstration presents a novel application (called SmartAlbum) for photo indexing and retrieval that unifies two different image indexing approaches. The system uses two modalities to extract information about a digital photograph; i.e. content-based and speech annotation for image description. The result is a powerful image retrieval tool that has capabilities beyond what current single-mode retrieval systems can offer. We show on a corpus of 1200 images the interest of our approach.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {87–88},
numpages = {2},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641026,
author = {Yann, Bodo and Nathalie, Laurent and Jean-Luc, Dugelay},
title = {A Scrambling Method Based on Disturbance of Motion Vector},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641026},
doi = {10.1145/641007.641026},
abstract = {Multimedia data security is very important for multimedia commerce on the Internet such as "pay-per-view" services. Thus, watermarking algorithms for data security appear. These algorithms describe methods and technologies that allow information to be hidden, for example a number or text, into a media, such as images, video, audio files... In this paper, we propose a new application of watermarking based on a scrambling process. In this application, we develop a waterscrambling technique in which video data are scrambled efficiently by disturbing a subset of motion vectors. The interest of this approach is its ability to scramble a video while maintaining a certain visibility. Effectively it permits the use of considerable levels of security in order to choose the level of perceptibility of the video. By using watermarking techniques we will be able to combine this approach with a classical copyright watermarking system.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {89–90},
numpages = {2},
keywords = {watermarking, waterscrambling, motion vector},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641027,
author = {Marpaung, Andreas H. and Brown, Sarah M. and Lisetti, Christine L.},
title = {A Technical Demonstration of Lola, the Robot Entertainer},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641027},
doi = {10.1145/641007.641027},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {91–93},
numpages = {3},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641028,
author = {Duan, Ling-Yu and Tian, Qi},
title = {Clear Face Analysis from MPEG Compressed Video},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641028},
doi = {10.1145/641007.641028},
abstract = {In this demonstration, we present a system to analyze the clear degree of faces present in MPEG compressed video of Head-and-Shoulders style. The proposed system consists of three hierarchical modules: low-level features extraction, robust face tracking, and clear faces selection. We have integrated the core algorithm into an Automated Transaction Service (ATS) surveillance system. The Incremental Focus of Attention (IFA) architecture is taken to combine pixel domain processing with compressed domain processing --- thus, implemented system exhibits computational efficiency and tolerance to very cluttered scenes. The proposed system has successively detected segments with clear frontal faces from more than 20 Automated Teller Machine (ATM) testing clips in MPEG format, each of which consists of 1~3 transactions. In addition, the proposed scheme implies some potential video mining applications, such as automatic checking to verify entry authorization, retrieval of suspicious activities in prerecorded video surveillance sequences.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {95–96},
numpages = {2},
keywords = {video analysis, clear face, compressed-domain processing},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641030,
author = {HASHIMOTO, Masayuki and MATSUO, Kenji and KOIKE, Atsushi and NAKAJIMA, Yasuyuki},
title = {Tile Boundary Artifact Reduction Algorithms for Tile Size Conversion of Wavelet Image},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641030},
doi = {10.1145/641007.641030},
abstract = {This paper proposes the tile size conversion method for the wavelet image transcoding gateway and a set of methods to reduce the tile boundary artifacts caused by the conversion.In the wavelet image coding system represented by JPEG2000, pictures are usually divided into one or more tiles and each tile then transformed separately. On low memory terminals such as mobile terminals, some decoders are likely to have limits on what tile sizes they can decode. Assuming a system using these limited decoders, methods were investigated for converting the tile size quickly and automatically at the gateway when image data with a non-decodable tile size is received at the gateway from another system. Furthermore, tile boundary artifacts reduction methods are investigated. This paper proposes a basic method, which creates a tiled wavelet coefficient sequence from a non-tiled wavelet coefficient sequence. This paper also verifies the validity of the proposed scheme by implementing it with a 5x3 reversible filter and a 9x7 irreversible filter.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {97–105},
numpages = {9},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641031,
author = {Yan, Wei-Qi and Kankanhalli, Mohan S},
title = {Detection and Removal of Lighting &amp; Shaking Artifacts in Home Videos},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641031},
doi = {10.1145/641007.641031},
abstract = {Many amateur videographers, like home video enthusiasts, may capture videos that are not of a professional quality. Many minor but visually annoying distortions like lighting imbalance and shaking artifacts could be introduced by the unskilled operations of the video camcorder. Since home videos constitute footage of great sentimental value, such videos cannot be summarily discarded. Unlike movies and sitcoms, shot re-takes of important events, such as wedding ceremonies are just not possible. Therefore, such distortions need to be corrected. In this paper, we present a novel method to detect segments of videos that have lighting and shaking artifacts. These segments can then be subjected to a restoration process that can remove these artifacts. We present techniques to correct lighting artifacts by appropriately adjusting the luminance. In order to remove the shaking artifact, image mosaicing is first employed to build a mosaic frame for the segment with the aid of edge blending techniques. Subsequently a Bezier-curve based blending of motion trajectory is employed to perform motion-compensated filtering of the shaking artifact. The restored video is then created by appropriately cropping the mosaic frame based on the compensated motion trajectory. We have implemented the developed techniques and the experimental results on home videos demonstrate the effectiveness of our approach. Detection and removal of artifacts are significant in other videos as well as those obtained from autonomous vehicles, robots and remote sensing.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {107–116},
numpages = {10},
keywords = {artifacts removal, lighting artifacts, video mosaic, video shaking},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641032,
author = {Mann, Steve and Manders, Corey and Fung, James},
title = {Painting with Looks: Photographic Images from Video Using Quantimetric Processing},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641032},
doi = {10.1145/641007.641032},
abstract = {When we ask the fundamental question "What does a camera measure?", we arrive at the concept of quantimetric imaging, which uses a new quantimetric unit, q, characteristic of a particular camera (e.g. each kind of camera defines its own quantimetric unit q based on its spectral response, etc.). Fluctuations in interframe exposures, along a sequence of images, give rise to a comparametric relationship between successive pairs of images. This allows us to estimate the response function of the camera (to derive the quantimetric unit q) as well as the relative differences in exposure. A new method of video image processing that exploits multiple differently exposed pictures (frames of the video sequence) of overlapping subject matter is thus possible. The method may be used whenever a video camera having automatic exposure captures multiple frames of video with the same subject matter appearing in regions of overlap between at least some of the successive video frames. Since almost all cameras have an automatic exposure feature, typically center weighted, when a light object falls in the center of the frame the exposure is automatically decreased, whereas the exposure is automatically increased when the camera swings around to point at a darker object. Such fluctuations in gain may be used to estimate the camera's response function, to estimate exposure differences, to do quantimetric processing, as well as to obtain images having both extended dynamic range and extended dynamic domain.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {117–126},
numpages = {10},
keywords = {comparametrics, image processing, comparametric equations, multiple exposures, video},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641033,
author = {Lei, Zhijun and Georganas, Nicolas D.},
title = {Rate Adaptation Transcoding for Precoded Video Streams},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641033},
doi = {10.1145/641007.641033},
abstract = {In order to transmit pre-encoded digital video over heterogeneous networks, it is necessary to employ transcoding techniques that convert pre-encoded video streams into streams having different bit rates and quality. The specified problem is referred to as rate shaping or rate adaptation. In this work, we propose a new rate control scheme for H.263+ based video transcoding. The proposed rate control scheme is comprised of Frame-Layer bit allocation and Macroblock-Layer rate control. At the frame layer, scene context statistics from the incoming video stream are utilized to detect scene changes and determine frame type. The bit budget is allocated to frames according to their energy and frame types. At the macroblock layer, a novel linear Rate-Quantization model is used for selecting quantization parameters for macroblocks. Implementation and experimental results show that the proposed algorithm can provide accurate bit allocation, and can effectively alleviate visual quality degradation after scene changes. This rate adaptation scheme can be used to provide flexible video bit rate adaptation for transmission of pre-encoded video over heterogeneous networks.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {127–136},
numpages = {10},
keywords = {rate quantization, video transcoding, rate adaptation, scene variations},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641035,
author = {Sagawa, Hirohiko and Takeuchi, Masaru},
title = {A Teaching System of Japanese Sign Language Using Sign Language Recognition and Generation},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641035},
doi = {10.1145/641007.641035},
abstract = {In recent years, the number of sign language learners is increasing in Japan. And there are many teaching materials of sign language such as textbooks, videotapes and software for PCs. However, these teaching materials have several problems that learners cannot study sign language sufficiently because the learners can mainly study manual gestures, cannot change the direction to see signed gestures, and cannot check their signed gestures by themselves. We developed a sign language teaching system applying sign language recognition and sign language generation technologies to solve these problems and realize effective sign language study. Further, we carried out an evaluation experiment by several users and confirmed that the developed system was effective.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {137–145},
numpages = {9},
keywords = {3DCG animation and teaching system, recognition, sign language},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641036,
author = {Roussel, Nicolas},
title = {Experiences in the Design of the <i>Well</i>, a Group Communication Device for <i>Teleconviviality</i>},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641036},
doi = {10.1145/641007.641036},
abstract = {Over the last forty years, a number of audiovisual systems have been proposed to allow people to communicate over distance. However, although these systems have greatly improved in their ability to support formal meetings, they are still hardly usable for the informal discussions that take place before and after the meeting or during breaks. This paper presents the well, a group communication device that combines audio and video links with an original design to support teleconviviality, the emergence of a relaxed atmosphere well adapted to distributed informal communication. The well is not intended to replace existing video-conferencing systems, but rather to supplement them as a solution to the informal communication problem. After introducing some related work, we provide an overview of the design concept of the well. We then present some details about its hardware configuration and the video compositing software it uses. Finally, we discuss some lessons learned from this work and conclude with directions for future research.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {146–152},
numpages = {7},
keywords = {iterative design, prototyping, informal communication, video-conferencing, teleconviviality},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641037,
author = {Mazalek, Ali and Davenport, Glorianna and Ishii, Hiroshi},
title = {Tangible Viewpoints: A Physical Approach to Multimedia Stories},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641037},
doi = {10.1145/641007.641037},
abstract = {We present a multimedia storytelling system that couples a tangible interface with a multiple viewpoint approach to interactive narratives. Over the centuries, stories have moved from the physical environment (around campfires and on the stage), to the printed page, then to movie, television and computer screens. Today, using wireless and tag sensing technologies, storytellers are able to bring digital stories back into our physical environment. The Tangible Viewpoints system explores how physical objects and augmented surfaces can be used as tangible embodiments of different character perspectives in an interactive tale. These graspable surrogates provide a direct mode of navigation to the story world, a means of bridging the gap between cyberspace and our physical environment as we engage with digital stories. The system supports stories told in a range of media, including audio, video, still image and text.In this paper, we first provide a context for Tangible Viewpoints based on research in the areas of tangible interfaces and interactive narratives. We then offer an overview of the Tangible Viewpoints functionality, and explain the design and implementation of the system. The current system has been used in two storytelling projects. We discuss each one, and look at how user feedback has affected or will affect further development. We conclude by suggesting several future applications for the Tangible Viewpoints interface.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {153–160},
numpages = {8},
keywords = {design, multimedia storytelling, interactive narrative, multiple point-of-view, physical interaction, tangible interface, character},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641038,
author = {Lisetti, Christine L. and Nasoz, Fatma},
title = {MAUI: A Multimodal Affective User Interface},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641038},
doi = {10.1145/641007.641038},
abstract = {Human intelligence is being increasingly redefined to include the all-encompassing effect of emotions upon what used to be considered 'pure reason'. With the recent progress of research in computer vision, speech/prosody recognition, and bio-feedback, real-time recognition of affect will enhance human-computer interaction considerably, as well as assist further progress in the development of new emotion theories.In this article, we describe how affect, moods and emotions closely interact with cognition and how affect and emotion are the quintessential multimodal processes in humans. We then propose an adaptive system architecture designed to sense the user's emotional and affective states via three multimodal subsystems (V, K, A): namely (1) the Visual (from facial images and videos), (2) Kinesthetic (from autonomic nervous system (ANS) signals), and (3) Auditory (from speech). The results of the system sensing are then integrated into the multimodal perceived multimodal anthropomorphic interface agent then adapts its interface by responding most appropriately to the current emotional states of its user, and provides intelligent multi-modal feedback to the user.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {161–170},
numpages = {10},
keywords = {affect recognition, interface agent, intelligent interfaces, emotions},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641040,
author = {Chen, Hong and Zheng, Nan-Ning and Liang, Lin and Li, Yan and Xu, Ying-Qing and Shum, Heung-Yeung},
title = {PicToon: A Personalized Image-Based Cartoon System},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641040},
doi = {10.1145/641007.641040},
abstract = {In this paper, we present PicToon, a cartoon system which can generate a personalized cartoon face from an input Picture. PicToon is easy to use and requires little user interaction. Our system consists of three major components: an image-based Cartoon Generator, an interactive Cartoon Editor for exaggeration, and a speech-driven Cartoon Animator. First, to capture an artistic style, the cartoon generation is decoupled into two processes: sketch generation and stroke rendering. An example-based approach is taken to automatically generate sketch lines which depict the facial structure. An inhomogeneous non-parametric sampling plus a flexible facial template is employed to extract the vector-based facial sketch. Various styles of strokes can then be applied. Second, with the pre-designed templates in Cartoon Editor, the user can easily make the cartoon exaggerated or more expressive. Third, a real-time lip-syncing algorithm is also developed that recovers a statistical audio-visual mapping between the character's voice and the corresponding lip configuration. Experimental results demonstrate the effectiveness of our system.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {171–178},
numpages = {8},
keywords = {example-based learning, user interfaces, lip-syncing, applications, non-parametric sampling, multi-modal interaction and integration},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641041,
author = {Rollins, Sami and Almeroth, Kevin C.},
title = {Pixie: A Jukebox Architecture to Support Efficient Peer Content Exchange},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641041},
doi = {10.1145/641007.641041},
abstract = {Peer-to-peer (P2P) content exchange has recently gained attention from both the research and industrial communities. The dynamic nature of peer networks and the resource constraints of peer hosts have introduced a number of unique technical challenges that must be addressed to make large-scale P2P content exchange applications viable. In this work, we present and evaluate Pixie, an architecture that integrates one-to-many distribution of content and peer networks. Pixie provides a valuable data location service as well as a number of scalability properties both in terms of data location and content distribution. Our results indicate that, using a one-to-many scheme, we can significantly reduce the resources consumed in searching for and distributing content across peer networks. These scalability properties will become increasingly important as peer content exchange is extended to support more advanced applications.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {179–188},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641042,
author = {Sundaram, Hari and Xie, Lexing and Chang, Shih-Fu},
title = {A Utility Framework for the Automatic Generation of Audio-Visual Skims},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641042},
doi = {10.1145/641007.641042},
abstract = {In this paper, we present a novel algorithm for generating audio-visual skims from computable scenes. Skims are useful for browsing digital libraries, and for on-demand summaries in set-top boxes. A computable scene is a chunk of data that exhibits consistencies with respect to chromaticity, lighting and sound. There are three key aspects to our approach: (a) visual complexity and grammar, (b) robust audio segmentation and (c) an utility model for skim generation. We define a measure of visual complexity of a shot, and map complexity to the minimum time for comprehending the shot. Then, we analyze the underlying visual grammar, since it makes the shot sequence meaningful. We segment the audio data into four classes, and then detect significant phrases in the speech segments. The utility functions are defined in terms of complexity and duration of the segment. The target skim is created using a general constrained utility maximization procedure that maximizes the information content and the coherence of the resulting skim. The objective function is constrained due to multimedia synchronization constraints, visual syntax and by penalty functions on audio and video segments. The user study results indicate that the optimal skims show statistically significant differences with other skims with compression rates up to 90%.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {189–198},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641044,
author = {Mart\'{\i}nez, Jos\'{e} M. and Gonz\'{a}lez, C\'{e}sar and Fern\'{a}ndez, Oscar and Garc\'{\i}a, Clara and de Ram\'{o}n, Jaime},
title = {Towards Universal Access to Content Using MPEG-7},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641044},
doi = {10.1145/641007.641044},
abstract = {This paper presents a system providing functionalities for cataloging multimedia content using MPEG-7 and accessing to content and descriptions. The cataloging application indexes content using MPEG-7 and creates annotated variations in order to have the capability of offering media content to a large amount of different terminals and through different access networks. The created multimedia database, both descriptions and content (original sources and variations), is used by, currently, two applications: a searching application, which allows a user selecting specific tags to find the desired media; and a filtering application for transparent access to the content database using profiles. These profiles can be selected from a profiles database or created by the user specifying content preferences, and network and terminal parameters.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {199–202},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641045,
author = {Mart\'{\i}nez, Jos\'{e} M. and Rubio, Luis F. and Mor\'{a}n, Francisco},
title = {Authoring 744: First Results},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641045},
doi = {10.1145/641007.641045},
abstract = {This paper presents the first results of the Authoring744 research initiative, which uses MPEG-7 to synthesize MPEG-4 content. The objective is to use MPEG-7 content descriptions to synthesize content, instead of creating descriptions by analyzing existing content. The output uses MPEG-4 XMT as the representation format, which is further used to create an MPEG-4 binary format, which can in turn be played.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {203–206},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641046,
author = {Arias, J. R. and Su\'{a}rez, F. J. and Garc\'{\i}a, D. F. and Garc\'{\i}a, X. X. and Garc\'{\i}a, V. G.},
title = {A Set of Metrics for Evaluation of Interactive News-on-Demand Systems},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641046},
doi = {10.1145/641007.641046},
abstract = {A key issue in any system for distribution of continuous media-on-demand is the capacity of the system with regard to quality of the service specifications, that is, the number of simultaneous streams the system can provide until degradation of quality of reproduction and interactivity perceived by the users. This work presents the evaluation of interactive video-on-demand systems, with special attention to limitations caused by the video server. The evaluation is based on a set of metrics designed to determine the number of streams a video server can support under specific requirements of quality of the service as perceived by the users. To validate the utility of these metrics, a prototype of a news-on-demand service has been built and the load for this kind of systems has been characterised. In addition, a load generator which emulates the concurrent access of several users to the system has been built. The evaluation establishes the relationship between the video server limitations and the quality of the service perceived by the users.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {207–210},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641047,
author = {Neumann, Christoph and Roca, Vincent},
title = {Multicast Streaming of Hierarchical MPEG-4 Presentations},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641047},
doi = {10.1145/641007.641047},
abstract = {This work introduces a novel approach for the streaming distribution of hierarchically encoded MPEG-4 presentations using IP-multicast. The main achievements of this approach are: (1) it is massively scalable in terms of number of users, (2) it ensures the reception of a minimum quality of the video to everybody, (3) bursts of packet losses do not automatically lead to a sudden change of quality unlike in most other video streaming solutions, (4) it is naturally TCP friendly, (5) it is immediately deployable and does not rely on any QoS mechanism in the network. This solution is well suited to a large scale television program distribution over the Internet. Yet it is not recommended for video-conferencing and applications with user interaction because it introduces a large playing delay.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {211–214},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641048,
author = {Vladimir, Dr. Portnykh and Deok-Ho, Dr. Kim},
title = {Task Oriented Non-Linear Method for Interactive Hypervideo Media Editing Systems},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641048},
doi = {10.1145/641007.641048},
abstract = {An apparatus and method for home and professional media editing aims is presented. The method uses task -oriented approach rather than well-known "timeline" or "storyboard" ways for dealing with media (video and audio) resources. The aim of this paper is to describe AVSEL, a language that can be used for formalization of user actions during editing video resources. In particular, logic aspects of editing process is underlined, namely, editing process is considered as process of making decisions and AVSEL is descriptor language to express editing logic in formal terms. Syntax and language semantics are given along with explaining samples. Some advantages of this approach, such as rendering optimization, flexible control of editing process are described.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {215–218},
numpages = {4},
keywords = {optimization, hypervideo editing systems, meta-language},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641049,
author = {Guerri, Juan C. and Palau, Carlos E. and Pajares, Ana and Esteve, Manuel},
title = {A Real-Time e-Learning System via Satellite Based on JMF and Windows Media},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641049},
doi = {10.1145/641007.641049},
abstract = {In this paper we present the design and development of a real-time e-learning system at the Polytechnic University of Valencia. The main novelty of this multimedia virtual classroom is the integration of Windows Media, Java Media Framework (JMF) and MPEG4 in a web-based environment. The communication network used in this real-time e-learning system is a satellite network for the multicasting of high-quality video from the teachers to the students using RTP, together with Internet/ISDN as return channel from the remote classrooms for low-quality video questions transmission. The system is fully operational and in the following year will be used as support for an e-learning co-operation project between Spain and South-America by a satellite communications operator.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {219–222},
numpages = {4},
keywords = {JMF, RTP/RTCP, Windows Media, e-learning, multimedia applications, satellite communications},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641050,
author = {Cucchiara, Rita and Grana, Costantino and Prati, Andrea},
title = {Semantic Transcoding for Live Video Server},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641050},
doi = {10.1145/641007.641050},
abstract = {In this paper we present transcoding techniques for a video server architecture that enables the user to access live video streams by using different devices with different capabilities. For live videos, annotation methods cannot be exploited. Instead we propose methods of on-the-fly transcoding that adapt the video content with respect to the user resources and the video semantic. Thus we propose an object-based transcoding with "classes of relevance" (for instance People, Face and Background). To compare the different strategies we propose a metric based on the Weighted Mean Square Error that allows the analysis of different application scenarios by means of a class-wise distortion measure. The obtained results show that the use of semantic can improve the bandwidth to distortion ratio significantly.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {223–226},
numpages = {4},
keywords = {PSNR, motion segmentation, performance evaluation metric, transcoding},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641051,
author = {Mulabegovic, Emir and Schonfeld, Dan and Ansari, Rashid},
title = {Lightweight Streaming Protocol (LSP)},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641051},
doi = {10.1145/641007.641051},
abstract = {A new streaming protocol is proposed for multimedia applications. The proposed protocol, referred to as Lightweight Streaming Protocol (LSP), is an application layer protocol that sits atop UDP. The protocol is intended to improve the quality and reliability of media stream by borrowing features from reliable protocols such as retransmission and flow control while not sacrificing performance. The protocol offers semi-reliable transport. Instead of trying to guarantee 100% data delivery the protocol simply recovers as many packets as possible within a specified deadline. In addition the protocol incorporates features such as probabilistic redundant NAK transmission and flow control through selective frame dropping. Preliminary simulations show that LSP performs extremely well in channels with random packet loss such as congested networks. The protocol also performs reasonably well in channels that have short bursts of lost packets such as wireless networks.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {227–230},
numpages = {4},
keywords = {video communications, real-time protocol, real-time streaming, streaming protocol, lightweight protocol, semi-reliable transport},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641052,
author = {Dimitrijevi\'{c}, Zoran and Rangaswami, Raju and Chang, Edward},
title = {Virtual IO: Preemptible Disk Access},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641052},
doi = {10.1145/641007.641052},
abstract = {Supporting preemptible disk access is essential for interactive multimedia applications that require short response time. In this study, we propose Virtual IO, an abstraction for disk IO, that transforms a non-preemptible IO request into a preemptible one. In order to achieve its objective efficiently, Virtual IO uses disk profiling to obtain accurate and detailed knowledge about the disk. Upon implementation of Virtual IO, we show that not only does Virtual IO enable highly preemptible disk access, but it does so with little or no loss in disk throughput.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {231–234},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641053,
author = {Gemmell, Jim and Bell, Gordon and Lueder, Roger and Drucker, Steven and Wong, Curtis},
title = {MyLifeBits: Fulfilling the Memex Vision},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641053},
doi = {10.1145/641007.641053},
abstract = {MyLifeBits is a project to fulfill the Memex vision first posited by Vannevar Bush in 1945. It is a system for storing all of one's digital media, including documents, images, sounds, and videos. It is built on four principles: (1) collections and search must replace hierarchy for organization (2) many visualizations should be supported (3) annotations are critical to non-text media and must be made easy, and (4) authoring should be via transclusion.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {235–238},
numpages = {4},
keywords = {Memex, multimedia, hypermedia, annotation, database},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641054,
author = {Hiraga, Rumi and Mizaki, Reiko and Fujishiro, Issei},
title = {Performance Visualization: A New Challenge to Music through Visualization},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641054},
doi = {10.1145/641007.641054},
abstract = {This paper describes performance visualization with its purposes, significance, and our prototype system. Performance visualization provides us with a new user interface for music systems, a non-subjective explanation and judgment for musical expression, and a visual aid to understand, analyze, and compare performances and their musical structures. It will also introduce a more challenging research on designing a musical data mining interface not by tags nor by contents but by the mood. Other challenges include finding qualitative characteristics of music with analysis methods for information visualization and synesthesia between visualized and sonified information. We will describe which information should be shown on the visualized figures for expressive performance. Then we will show our prototype system to visualize expressive performance consisting of several instruments.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {239–242},
numpages = {4},
keywords = {performance visualization},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641055,
author = {Wang, Jihua and Chua, Tat-Seng},
title = {A Framework for Video Scene Boundary Detection},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641055},
doi = {10.1145/641007.641055},
abstract = {Most current video retrieval systems use shot as the basis for information organization and access. In cinematography, scene is the basic story unit that the directors use to convey their ideas. This paper proposes a framework based on the concept of continuity to analyze video contents and extract scene boundaries. Starting from a set of shots, the framework successively applies the concept of visual, position, cameral focal distance, motion, audio and semantic continuity to group shots that exhibit some form of continuity into scenes. The idea is tested using the first three levels of continuity to extract the scenes defined using most common cinematic rules. The method has been found to be effective.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {243–246},
numpages = {4},
keywords = {scene detection, video retrieval, cinematic model},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641056,
author = {Tran, Duc A. and Hua, Kien A. and Do, Tai T.},
title = {Scalable Media Streaming in Large Peer-to-Peer Networks},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641056},
doi = {10.1145/641007.641056},
abstract = {We design a peer-to-peer technique for single-source media streaming. This technique allows the media server to distribute content to many clients by organizing them into an appropriate tree rooted at the server. This application-layer multicast tree has a height O(logN)where N is the number of clients, and a node degree bounded by a constant. This helps reduce the number of processing hops on the delivery path to a client while avoiding network bottleneck. Consequently, the end-to-end delay is kept small. Although one could build a tree satisfying such properties easily, an efficient control protocol between the nodes must be in place to maintain the tree under the effects of network dynamics and unpredictable client behaviors. Our technique handles such situations gracefully requiring a constant amortized control overhead. Especially, failure recovery can be done regionally with little impact on the existing clients.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {247–250},
numpages = {4},
keywords = {media streaming, application-layer multicast, peer to peer},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641057,
author = {Mostefaoui, Ahmed and Favory, Loic and Brunie, Lionel},
title = {SIRSALE: A Large Scale Video Indexing and Content-Based Retrieving System},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641057},
doi = {10.1145/641007.641057},
abstract = {This paper presents the SIRSALE system. SIRSALE is a video management system that allows users to deal with video streams stored in distributed repositories. SIRSALE is based on a modular model that allows adapting the system to deal with specific semantic contexts. Thus SIRSALE allows users to browse documents by structures (shots, scenes, sequences), to annotate the content of the video documents and to query the database by content, by using a graphical tool adapted to the user's specific topic of interest. The system has been demonstrated to professionals with a positive feedback.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {251–254},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641058,
author = {Matsuo, Yuya and Amano, Miki and Uehara, Kuniaki},
title = {Mining Video Editing Rules in Video Streams},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641058},
doi = {10.1145/641007.641058},
abstract = {Data mining is a technique to discover useful patterns or patterns of special interest as explicit knowledge from a vast quantity of data. In video editing, there are a lot of editing patterns. According to the editor's preferences, different editing patterns give the opportunity to achieve a variety of effects. Discovering the editing patterns is required, because it is useful to find each editor's skills and to use them for editing new video material. In this paper, we propose the methods of extracting editing rules from video stream by introducing data mining technique. We can edit a video material by applying the extracted rules. The edited video may produce the same quality as the video from which we extracted the patterns.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {255–258},
numpages = {4},
keywords = {shot size, video grammar, video editing, video material, data mining},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641059,
author = {Choi, Jeong-Dan and Byun, Ki-Jong and Jang, Byung-Tae and Hwang, Chi-Jeong},
title = {A Synchronization Method for Real Time Surround Display Using Clustered Systems},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641059},
doi = {10.1145/641007.641059},
abstract = {This note describes a synchronization method for use of the multichannel display and the associated clustered PC rendering systems, within multi user Virtual Reality online games with real time frame rates. It provides a real time surround game display to render the very complex 3D graphics objects. Our system is composed of Multi-channel Distributor, and Visualization Clients. Visual client system can be connected to multi monitors or projectors. With Multi-channel distributor, an application can be configured, at runtime, to span any number of visuals to makeup a complete surround and to manage the user game event. All visualization clients produced are frame synchronized to ensure visual uniformity. However, tightly synchronized PC cluster may cause a draw back in its rendering speed. So, we propose a dual scene graph management method to adaptively synchronize. One scene graph is conventionally organizes and control the rendering of its constituent objects. And the other is spatially grouping on the geometric objects found at the edge of two adjacent channels between of the clustered PCs and or not. In this paper describes the method of a construction dual-scene graph based clustered rendering system for scalable display in order to generate high-resolution images at real time frame rates. And also we are planning to develop a multi-projector display system which calibrates itself automatically regardless its shape of display surface and which provides a user with a seamless game display. Our results are well suited for surround 3D game displays such as multi-projector or multi-monitor running on a PC cluster.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {259–262},
numpages = {4},
keywords = {synchronization, multi-channel, clustered rendering system},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641060,
author = {Xie, Xing and Zeng, Hua-Jun and Ma, Wei-Ying},
title = {Enabling Personalization Services on the Edge},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641060},
doi = {10.1145/641007.641060},
abstract = {In this paper, we describe our work on enabling personalization services on the edge of the Internet. In contrast to traditional approaches, this method offers many advantages. First, content providers can make their content people-aware while the content is delivered to the user. Second, since the personalization work is distributed to an overlay network of edge servers, it greatly improves the scalability and availability of the services. Third, the sufficiency of user data collected in edge servers enables us to build more accurate user models which further enhance the performance of personalization services. We describe the implementation of a prototype system named Avatar and present some experimental result in this paper.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {263–266},
numpages = {4},
keywords = {adaptive content delivery, edge computing, user modeling, content delivery system, personalized Web},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641061,
author = {Ryu, Jeewoong and Sohn, Yumi and Kim, Munchuri},
title = {MPEG-7 Metadata Authoring Tool},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641061},
doi = {10.1145/641007.641061},
abstract = {Recently an international standard for Multimedia content description, MPEG-7, has been finalized in the 1st phase by reaching the FDIS level. MPEG-7 aims at providing structural and semantic description mechanism for multimedia contents so that content based searching/filtering and access to multimedia content can be possible in conjunction with multimedia description data, that is, MPEG-7 description data. However, the MPEG-7 specifications only specify the syntax and semantics of describing multimedia contents but not authoring content description data. In this paper, we introduce an MPEG-7 metadata authoring tool that can be used in generating MPEG-7 metadata data for multimedia contents. The MPEG-7 metadata authoring system has a generic architecture for MPEG-7 based metadata authoring but mainly relies on MPEG-7 Multimedia Description Schemes for multimedia description generation.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {267–270},
numpages = {4},
keywords = {descriptors, key frame, MPEG-7, metadata, authoring, multimedia description schemes},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641062,
author = {Lau, Rynson W. H. and Ng, Beatrice and Si, Antonio and Li, Frederick},
title = {Adaptive Partitioning for Multi-Server Distributed Virtual Environments},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641062},
doi = {10.1145/641007.641062},
abstract = {A distributed virtual environment (DVE) allows users at different geographical locations to share information and interact within a common virtual environment (VE) via a local network or through the Internet. However, when the number of users exploring the VE increases, the server will quickly become the bottleneck. To enable good performance, we are currently developing a multi-server DVE prototype. In this paper, we describe an adaptive data partitioning technique to dynamically partition the whole VE into regions. All objects within each region will be managed by a single server. As the loading of the servers changes, we show how it can be redistributed while minimizing the communication cost. Our initial results show that the proposed adaptive partitioning technique significantly improves the performance of the overall system.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {271–274},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641063,
author = {Kim, Kyuheon and Lee, Injae and Ki, Myungseok},
title = {Interactive Contents Authoring System Based on XMT and BIFS},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641063},
doi = {10.1145/641007.641063},
abstract = {As the Internet has been widely used for all the area of industries, the traditional characteristics of communication and broadcasting has been merged into a new service such as interactivity based broadcasting. Under an interactive environment, viewers not only watch broadcasting programs provided from a contents provider such as traditional broadcastings, but also pass their requirements to a service provider, obtain supplementary information and search broadcasting programs on the basis of their individual component objects. In order to access a program in terms of its component contents, thus, it is required to compose a scene and have reactions on the basis of its individual objects rather than a whole program itself. Therefore, this paper introduces a new authoring system, which can easily and conveniently produce an interactive contents-based broadcasting program by using MPEG-4 technologies. The authoring system presented in this paper describes a program in terms of two formats such as a textual format (XMT) for readability and a binary format (BiFS) for transmission. Since the XMT format is a XML-like one, it is easier for a user to understand and edit a scene composition. Alterantively, BiFS is suitable for transmission because of its binary property.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {275–278},
numpages = {4},
keywords = {MPEG-4, authoring system, interactive contents},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641064,
author = {Carlson, Darren and Schrader, Andreas},
title = {Seamless Media Adaptation with Simultaneous Processing Chains},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641064},
doi = {10.1145/641007.641064},
abstract = {In this paper we investigate a seamless method for the adaptation of streamed media by using simultaneous processing chains. The common approach for media adaptation is to deconstruct the current media processing chain and to construct a new media chain afterwards. As a consequence, media frames might be lost and the adaptation cycle needs significant time. In our approach, the new processing chain is built in parallel to the current one and the stream is switched to the new chain as soon as possible. With this mechanism, we can guarantee zero-loss behaviour in the sender, and at the same time, reduce the overall adaptation time significantly. The proposed method is independent of the actual codec and can be applied to both audio and video streams. We present a formal calculation of the possible improvements of our proposed mechanism with respect to information loss and adaptation speed and also report about results obtained in our implementation using the Java Media Framework.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {279–282},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641065,
author = {Costa, Miguel and Correia, Nuno and Guimar\~{a}es, Nuno},
title = {Annotations as Multiple Perspectives of Video Content},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641065},
doi = {10.1145/641007.641065},
abstract = {This paper describes a video annotation tool based on a new and flexible model, that gives several perspectives over the same video content. The model was designed in a way that allows having multiple views over the same video data, enabling users with different requirements to have the most appropriate interface. These views, video-lenses, highlight a specific aspect of the video content that is being annotated. Annotations are made using a timeline based interface with multiple tracks, where each track corresponds to a given video-lens. The format used to store and exchange the information is the MPEG-7 standard. The annotation tool (VAnnotator) is being developed in the scope of Vizard, an ambitious project that aims to define a new paradigm for video navigation, annotation, editing and retrieval. The Vizard project includes users, both from the production/archiving area and from the consumer electronics area, that help to define and validate the annotation requirements and functionality.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {283–286},
numpages = {4},
keywords = {MPEG-7, timeline model, authoring paradigms, video-lens, video annotation},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641066,
author = {Blechschmitt, Eric and Str\"{o}decke, Christoph},
title = {An Architecture to Provide Adaptive, Synchronized and Multimodal Human Computer Interaction},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641066},
doi = {10.1145/641007.641066},
abstract = {In this paper we present a solution to compose synchronized multimodal computer human interaction with a pattern-oriented approach. The focus of this paper is how to synchronize the different modalities of interaction.In our application scenario the system consists of mobile agents and the user interface is generated from a dialog description language, which is XML-encoded. The generated User Interface is executed by one or more UI-engines, which can use one or more modalities like a text chat system, a speech-based system or a graphical, window-oriented user interface. The user interface is separated and also structured by so-called dialog moves which are suitable to be adapted to different UI-engines. The system supports more than one UI-engine at the same time which results in a possibly multimodal interaction. The interaction is synchronized by observing the events produced by the dialog moves of each UI-engine.The system is evaluated in a project called MAP1 which deals with new human computer interaction methods in future mobile work environments.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {287–290},
numpages = {4},
keywords = {mobile agents, adaptive, dialog move, multimodal, synchronisation},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641067,
author = {Neven, Filip and Duval, Erik},
title = {Reusable Learning Objects: A Survey of LOM-Based Repositories},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641067},
doi = {10.1145/641007.641067},
abstract = {In this paper, we survey the field of learning object repositories. Learning objects are typically relatively small content components that are meant to be reusable in different contexts. Associated to these learning objects are metadata, so that they can be managed, searched, etc. As the international standardization in this area is making important progress, the number of these repositories is growing rapidly, and the whole field of learning objects is rapidly maturing as a research area in its own right.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {291–294},
numpages = {4},
keywords = {reusable learning objects, digital libraries, Learning Object Metadata (LOM), metadata, learning object repositories},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641068,
author = {Phung, Dinh Q. and Venkatesh, Svetha and Dorai, Chitra},
title = {High Level Segmentation of Instructional Videos Based on Content Density},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641068},
doi = {10.1145/641007.641068},
abstract = {Automatically partitioning instructional videos into topic sections is a challenging problem in e-learning environments for efficient content management and cataloging. This paper addresses this problem by proposing a novel density function to delineate sections underscored by changes in topics in instructional and training videos. The content density function draws guidance from the observation that topic boundaries coincide with the ebb and flow of the 'density' of content shown in these videos. Based on this function, we propose two methods for high-level segmentation by determining topic boundaries. We study the performance of the two methods on eight training videos, and our experimental results demonstrate the effectiveness and robustness of the two proposed high-level segmentation algorithms for learning media.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {295–298},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641069,
author = {Cherkasova, Ludmila and Staley, Loren},
title = {Measuring the Capacity of a Streaming Media Server in a Utility Data Center Environment},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641069},
doi = {10.1145/641007.641069},
abstract = {Abstract In order to design a "utility-aware" streaming media service which automatically requests the necessary resources from Utility Data Center infrastructure, several classic performance questions should be answered: how to measure the basic capacity of a streaming media server? what is the set of basic benchmarks exposing the performance limits and main bottlenecks of a media server? In this paper, we propose a set of benchmarks for measuring the basic capacities of streaming media systems for different expected workloads, and demonstrate the results using an experimental testbed.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {299–302},
numpages = {4},
keywords = {media system benchmarks, Utility Data Centers, media server capacity, measurements, enterprise media servers},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641070,
author = {Nock, H. J. and Iyengar, G. and Neti, C.},
title = {Assessing Face and Speech Consistency for Monologue Detection in Video},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641070},
doi = {10.1145/641007.641070},
abstract = {This paper considers schemes for determining which of a set of faces on screen, if any, is producing speech in a video soundtrack. Whilst motivated by the TREC 2002 (Video Retrieval Track) monologue detection task, the schemes are also applicable to voice and face-based biometrics systems, for assessing lip synchronization quality in movie editing and computer animation, and for speaker localization in video. Several approaches are discussed: two implementations of a generic mutual-information-based measure of the degree of synchrony between signals, which can be used with or without prior speech and face detection, and a stronger model-based scheme which follows speech and face detection with an assessment of face and lip movement plausibility. Schemes are compared on a corpus of 1016 test cases containing multiple faces and multiple speakers, a test set 200 times larger than the nearest comparable test set of which we are aware. The most successful and computationally cheapest scheme obtains an accuracy of 82% on the task of picking the "consistent" speaker from a set including three confusers. A final experiment demonstrates the potential utility of the scheme for speaker localization in video.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {303–306},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641071,
author = {Joung, YeSun and Kim, Kyuheon},
title = {An XMT API for Generation of the MPEG-4 Scene Description},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641071},
doi = {10.1145/641007.641071},
abstract = {Interactive broadcasting is now considered as a next generation broadcasting service, which covers territorial, mobile and wireless terminals. In interactive broadcasting, viewers not only watch the broadcasting programs but also pass their requirements to program providers. In order to represent this interactivity, it is considered that the MPEG-4 is a well-adopted standard because of its object-based scene description scheme, which is in the binary (BIFS) and textual (XMT) formats. This paper describes the XMT API that can generate, manipulate and translate an XML document for the interactive broadcasting content description, and also introduce an authoring system based on the provided the XMTAPI. Since the XMT is a textual format, content authors can easily exchange contents with other creators, applications and tools. This exchangeability of the XMT makes that authors can create interactive broadcasting contents more efficiently and rapidly. Therefore, our XMT API becomes core component module for developing interactive broadcasting contents.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {307–310},
numpages = {4},
keywords = {MPEG-4, XML, XMT, DOM},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641072,
author = {Kang, Hang-Bong},
title = {Analysis of Scene Context Related with Emotional Events},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641072},
doi = {10.1145/641007.641072},
abstract = {We propose a method for the detection of emotional events by analyzing scene context in video data. To analyze scene-level features, we compute the contextual information in video scenes. We divide the scene context into intra-scene context and interscene context. We define intra-scene context as the context within the scene such as the shots' coherences, shot's interactions and dominant features in color and motion information within the scene. We also define the inter-scene context as the given scene's relationship with other scenes. In detecting emotional events from video data, we first compute inter-scene context. Then, we select possible candidates which have large dissimilarities in comparison with previous scenes. Finally, we make a decision whether the candidate is emotional event or not. We experiment our proposed approach on test data and detect 70% of the occurrences of the emotional events such as fear and sadness.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {311–314},
numpages = {4},
keywords = {content analysis, emotional event, scene context},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641073,
author = {Zhang, Dongqing and Chang, Shih-Fu},
title = {Event Detection in Baseball Video Using Superimposed Caption Recognition},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641073},
doi = {10.1145/641007.641073},
abstract = {We have developed a novel system for baseball video event detection and summarization using superimposed caption text detection and recognition. The system detects different types of semantic level events in baseball video including scoring and last pitch of each batter. The system has two components: event detection and event boundary detection. Event detection is realized by change detection and recognition of game stat texts (such as text information showing in score box). Event boundary detection is achieved using our previously developed algorithm, which detects the pitch view as the event beginning and nonactive view as potential endings of the event. One unique contribution of the system is its capability to accurately detect the semantic level events by combining video text recognition with camera view recognition. Another unique feature is the real-time processing speed by taking advantage of compressed-domain approaches in part of the algorithms such as caption detection. To the best of our knowledge, this is the first system achieving accurate detection of multiple types of high-level semantic events in baseball videos.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {315–318},
numpages = {4},
keywords = {highlight extraction, sports video event detection, summarization, videotext detection, recognition, retrieval},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641074,
author = {Nasoz, Fatma and Ozyer, Onur and Lisetti, Christine L. and Finkelstein, Neal},
title = {Multimodal Affective Driver Interfaces for Future Cars},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641074},
doi = {10.1145/641007.641074},
abstract = {In this paper, we uncover a new potential application for multimedia technologies: car interfaces for enhanced driver's safety. We also describe the experiment we conducted in order to map certain physiological signals (galvanic skin response, heart beat, and temperature) to certain emotions (Neutral, Anger, Fear, Sadness, and Frustration). We demonstrate the results we gained and describe how we use these results to our Multimodal Affective Driver Interface for the drivers of the future cars.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {319–322},
numpages = {4},
keywords = {multi-modal affective intelligent interfaces, emotions, wearable computers, drivers' safety},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641075,
author = {Lin, Wei-Hao and Hauptmann, Alexander},
title = {News Video Classification Using SVM-Based Multimodal Classifiers and Combination Strategies},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641075},
doi = {10.1145/641007.641075},
abstract = {Video classification is the first step toward multimedia content understanding. When video is classified into conceptual categories, it is usually desirable to combine evidence from multiple modalities. However, combination strategies in previous studies were usually ad hoc. We investigate a meta-classification combination strategy using Support Vector Machine, and compare it with probability-based strategies. Text features from closed-captions and visual features from images are combined to classify broadcast news video. The experimental results show that combining multimodal classifiers can significantly improve recall and precision, and our meta-classification strategy gives better precision than the approach of taking the product of the posterior probabilities.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {323–326},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641076,
author = {Song, Seungho and Won, Youjip and Song, Injae},
title = {Empirical Study of User Perception Behavior for Mobile Streaming},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641076},
doi = {10.1145/641007.641076},
abstract = {The objective of this study is to examine the effect of individual factors over human perception behavior and to determine the right set of parameters which effectively exploit the underlying network and system capacity while maximizing the QoS perceived by the user. For the comprehensive test, we examine three different types of video clips: news, drama and sport game. From each of the original video clip, we vary the encoding factors as follows: playback rate(384Kbits/sec and 1.5 Mbits/sec), frame rate(5 frames/sec, 15 frames/sec, and 25 frames/sec) and spatial resolution(176x244 and 320x240). We performed extensive user experiment. We particularly focus on video streaming in mobile wireless environment where playback rate and screen size are relatively small. The analysis result reveals that out of three encoding factors, frame rate is the most influential factor. Spatial resolution does not make significant difference on QoS for three video categories. Playback rate results in noticeable difference in QoS. However, the analysis result suggests that the improvement on QoS obtained by quadrupling the playback rate (from 384Kbits/sec to 1.5 Mbits/sec) may not be justifiable particularly when the screen size is small.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {327–330},
numpages = {4},
keywords = {streaming, multimedia, empirical study, QoS, video},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641077,
author = {T, Ashwin and Gupta, Rahul and Ghosal, Sugata},
title = {Leveraging Non-Relevant Images to Enhance Image Retrieval Performance},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641077},
doi = {10.1145/641007.641077},
abstract = {Inherent subjectivity in user's perception of an image has motivated the use of relevance feedback (RF) in the image desigined output's retrieval process. RF techniques interactively determine the user's query concept, given the user's relevance judgments on a set of images. In this paper we propose a robust technique that utilizes non-relevant images to efficiently discover the relevant search region. A similarity metric, estimated using the relevant images is then used to rank and retrieve database images in the relevant region. The partitioning of the feature space is achieved by using a piecewise linear decision surface that separates the relevant and non-relevant images. Each of the hyperplanes constituting the decision surface is normal to the minimum distance vector from a non-relevant point to the convex hull of relevant points. Experimental results demonstrate significant improvement in retrieval performance for the small feedback size scenario over two well established RF algorithms.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {331–334},
numpages = {4},
keywords = {relevance feedback, ellipsoid query processing, similarity search, image retrieval, non-relevant judgment},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641078,
author = {Lienhard, Jochen and Lauer, Tobias},
title = {Multi-Layer Recording as a New Concept of Combining Lecture Recording and Students' Handwritten Notes},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641078},
doi = {10.1145/641007.641078},
abstract = {This paper describes a new way of creating multimedia documents combining recorded lectures and students' personal notes. Students use multimedia recordings of live presentations for revision and exam preparation. Based on the "Authoring on the Fly" concept we have developed a new system for multi-layer recording, where prepared materials, annotations made by the lecturer, and students' personal notes are captured during a live lecture. We describe the shift from the stand-alone lecture recording system to shared session recording and discuss the main issues which need to be tackled in the recording and the replay scenarios. We also point out the differences to other existing concepts. Finally we give a short vision of how the system could be used as a collaborative tele-recording tool in the future.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {335–338},
numpages = {4},
keywords = {collaborative workspace, annotation capturing, multi-layer recording, multimedia in education, authoring, lecture recording},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641079,
author = {Truong, Ba Tu and Venkatesh, Svetha and Dorai, Chitra},
title = {Application of Computational Media Aesthetics Methodology to Extracting Color Semantics in Film},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641079},
doi = {10.1145/641007.641079},
abstract = {Using film grammar as the underpinning, we study the extraction of structures in video based on color using a wide configuration of clustering methods combined with existing and new similarity measures. We study the visualisation of these structures, which we call Scene-Cluster Temporal Charts and show how it can bring out the interweaving of different themes and settings in a film. We also extract color events that filmmakers use to draw/force a viewer's attention to a shot/scene. This is done by first extracting a set of colors used rarely in film, and then building a probabilistic model for color event detection. We demonstrate with experimental results from ten movies that our algorithms are effective in the extraction of both scene-cluster temporal charts and color events.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {339–342},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641080,
author = {He, Xiaofei and Ma, Wei-Ying and King, Oliver and Li, Mingjing and Zhang, Hongjiang},
title = {Learning and Inferring a Semantic Space from User's Relevance Feedback for Image Retrieval},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641080},
doi = {10.1145/641007.641080},
abstract = {As current methods for content-based retrieval are incapable of capturing the semantics of images, we experiment with using spectral methods to infer a semantic space from user's relevance feedback, so the system will gradually improve its retrieval performance through accumulated user interactions. In addition to the long-term learning process, we also model the traditional approaches to query refinement using relevance feedback as a short-term learning process. The proposed short- and long-term learning frameworks have been integrated into an image retrieval system. Experimental results on a large collection of images have shown the effectiveness and robustness of our proposed algorithms.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {343–346},
numpages = {4},
keywords = {image retrieval, learning, user's relevance feedback},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641081,
author = {Han, Mei and Hua, Wei and Xu, Wei and Gong, Yihong},
title = {An Integrated Baseball Digest System Using Maximum Entropy Method},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641081},
doi = {10.1145/641007.641081},
abstract = {In this paper, we propose a novel system that is able to automatically detect and classify highlights from baseball game videos in TV broadcast. The digest system gives complete indexes of a baseball game which cover all of the status changes in a game. We achieve this by seamlessly integrating image, audio and speech clues using a maximum entropy based method. What distinguishes our system from previous ones is that we emphasize on the integration of multimedia features and the acquisition of domain knowledge through machine learning process. Integration of multimedia features is important because with the current state-of-the-art image and audio analysis techniques, most image and audio features we can extract from videos are very low level, and detecting/classifying sports game highlights based on features from single medium are doomed to yield poor performances. Acquiring domain knowledge through learning process is preferred over heuristic rules because machine learning process is more powerful for discovering and expressing domain knowledge. We perform extensive experiments on game videos including various stadiums, teams and broadcasted by different TV stations.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {347–350},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641082,
author = {Pan, Pengkai and Kastner, Carly and Crow, David and Davenport, Glorianna},
title = {M-Studio: An Authoring Application for Context-Aware Multimedia},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641082},
doi = {10.1145/641007.641082},
abstract = {Broadband wireless networks coupled with handheld computers and appropriate sensing technologies provide a channel for the delivery of mobile cinema. Mobile cinema changes the consumer experience of motion picture stories in that discrete cinematic sequences are delivered based on the consumer's location and the a story-real-time metric. The M-Studio authoring tool helps mobile story creators design, simulate and adjust mobile narratives. The tool provides the author with a graphical manipulation interface for linking content with a specific geographical space and a simulator allows the author to evaluate and iterate the content for continuity of story threads as they may be presented. The tool directly generates the code that is required for the server to deliver the cinematic sequences appropriately. This tool is discussed in the context of the two mobile narratives that have been created.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {351–354},
numpages = {4},
keywords = {authoring tool, mobile multimedia, story making/sharing, context-aware narrative},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641084,
author = {Bornard, Rapha\"{e}l and Lecan, Emmanuelle and Laborelli, Louis and Chenot, Jean-Hugues},
title = {Missing Data Correction in Still Images and Image Sequences},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641084},
doi = {10.1145/641007.641084},
abstract = {The ability to replace missing data in images and video is of key importance to many application fields. The general-purpose algorithm presented here is inspired by texture synthesis techniques but is suited to any complex natural scene and not restricted to stationary patterns. It has the property to be adapted to both still images and image sequences and to incorporate temporal information when available while preserving the simplicity of the algorithm. This method gives very good results in various situations without user intervention. The resulting computational cost is relatively low and corrections are usually produced within seconds.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {355–361},
numpages = {7},
keywords = {non-stationary and non-parametric Markovian models, restoration, constrained synthesis, image and video processing},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641085,
author = {Guo, Huiping and Georganas, Nicolas D.},
title = {Digital Image Watermarking for Joint Ownership},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641085},
doi = {10.1145/641007.641085},
abstract = {Though many image watermarking schemes have been proposed, none of them can resolve the problem of joint ownership. This paper proposes two novel algorithms that make use of a secret sharing scheme in cryptography to address this problem. The first one applies Shamir's (2, 2) threshold scheme to the watermarking algorithm. A watermark, which is a gaussian distributed random vector determined by two keys, is embedded to selected coefficients in all middle bands in the wavelet domain of an image, so that only when the two keys are put together can the ownership be verified. The second algorithm is a modification of the first one. Three random watermarks are embedded to middle bands in the wavelet domain of an image. For the watermark detection, two thresholds are set, so the watermark detector can verify partial ownership as well as full ownership. Experimental results show that both algorithms have the desired properties such as invisibility, reliable detection and robustness against a wide range of imaging processing operations.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {362–371},
numpages = {10},
keywords = {secret sharing scheme, cryptography, wavelet transform, digital watermarking},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641086,
author = {Kirovski, Darko and Malvar, Henrique and Yacobi, Yacov},
title = {Multimedia Content Screening Using a Dual Watermarking and Fingerprinting System},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641086},
doi = {10.1145/641007.641086},
abstract = {We present a new dual watermarking and fingerprinting system, where initially all copies of a protected object are identically watermarked using a secret key, but individual detection keys are distinct. By knowing a detection key, an adversary cannot recreate the original content from the watermarked content. However, knowledge of any one detection key is sufficient for modifying the object so that a detector using that key would fail to detect the marks. Detectors using other detection keys would not be fooled, and such a modified object necessarily contains enough information about the broken detector key - the fingerprint. Our dual system limits the scope of possible attacks, when compared to classic fingerprinting systems. Under optimal attacks, the size of the collusion necessary to remove the marks without leaving a detectable fingerprint is superlinear in object size, whereas classic fingerprinting has a lower bound on collusion resistance that is approximately fourth root in object size. By using our scheme one can achieve collusion resistance of up to 900,000 users for a two hour high-definition video.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {372–381},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641088,
author = {Moal, Damien Le and Takeuchi, Tadashi and Bandoh, Tadaaki},
title = {Cost-Effective Streaming Server Implementation Using Hi-Tactix},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641088},
doi = {10.1145/641007.641088},
abstract = {High performance and high quality for continuous media stream delivery needed by streaming server systems cannot be achieved efficiently using general-purpose operating systems, due to the overhead of the I/O mechanism implementation generally used. Special OS combined with powerful hardware can deliver better performance and quality but increases development complexity and deployment costs. The External I/O Engine Architecture adopts a hybrid approach, implementing streaming engines using the streaming-oriented Hi-Tactix operating system on inexpensive hardware, in combination with existing stream servers. The evaluation results of a QuickTime video server implemented with the existing Darwin Streaming Server using the External I/O Engine Architecture shows that Hi-Tactix can deliver 5 times the performance of a conventional OS and better stream quality, while keeping the amount of code necessary low.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {382–391},
numpages = {10},
keywords = {operating system, quicktime, audio/video streaming, real-time},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641089,
author = {Yeung, Siu F. and Lui, John C. S. and Yau, David K. Y.},
title = {A Case for a Multi-Key Secure Video Proxy: Theory, Design, and Implementation},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641089},
doi = {10.1145/641007.641089},
abstract = {Because of limited server and network capacities in multimedia streaming, proxies are commonly used to cache multimedia objects such that, by accessing nearby proxies, clients can enjoy smaller start-up latencies and reduced packet loss and delay jitters for their requests. However, the use of video proxies increases the risk that multimedia data are exposed to unauthorized access by intruders. In this paper, we present a framework for implementing a secure video proxy or, more generally, a secure proxy architecture. The framework employs a notion of asymmetric reversible parametric sequences to provide the following security properties: (1) data confidentiality during transmission, (2) end-to-end data confidentiality, (3) data confidentiality against proxy intruders, and (4) data confidentiality against member collusion. Our framework is grounded on a multi-key RSA technique such that system resilience against attacks is provably strong given standard computability assumptions. We also propose the use of a set of encryption configuration parameters to trade off proxy encryption throughput against the viewing quality of video by unauthorized parties. Implementation results on a Pentium III/800 MHz machine show that our techniques can simultaneously achieve high encryption throughput and extremely low video quality (in terms of both PSNR and the visual quality of decoded frames) during unauthorized viewing.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {392–401},
numpages = {10},
keywords = {multi-key RSA, video proxy, asymmetric parametric sequence functions, security},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641090,
author = {Poellabauer, Christian and Abbasi, Hasan and Schwan, Karsten},
title = {Cooperative Run-Time Management of Adaptive Applications and Distributed Resources},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641090},
doi = {10.1145/641007.641090},
abstract = {This paper presents Q-fabric, which is a set of lightweight, kernel-level abstractions for cooperative, distributed resource management and system/application adaptation. The basis of Q-fabric is its kernel-level, anonymous, asynchronous event service. With this mechanism, (1) applications can monitor and manage the local and remote resources they are using, (2) system-level resource managers can customize their actions to meet the needs of individual applications, and (3) policies can be developed that combine application adaptation with distributed resource management. Results presented in this paper demonstrate the Q-fabric's ability to effectively adapt and manage the resources of a distributed multimedia application. In this application, media streams are adapted at application-level via data down-sampling, and their resources are managed at system-level (e.g., task scheduling) to cope with run-time variations in resource availability. The Q-fabric is implemented as kernel modules on standard Linux platforms.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {402–411},
numpages = {10},
keywords = {event service, QoS management, adaptation, OS services},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641092,
author = {Wang, Yijin and Zhao, Peng and Zhang, Dong and Li, Mingjing and Zhang, Hongjiang},
title = {<i>MyVideos</i>: A System for Home Video Management},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641092},
doi = {10.1145/641007.641092},
abstract = {MyVideos is a prototype system for managing home digital videos. It provides the basic functionalities of video segmentation, summarization, grouping, and editing. It also supports the video playback by shot, group, or highlight.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {412–413},
numpages = {2},
keywords = {video grouping, video summary, home video management},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641093,
author = {Andr\'{e}s del Valle, Ana C. and Dugelay, Jean-Luc},
title = {Online Face Analysis: Coupling Head Pose-Tracking with Face Expression Analysis},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641093},
doi = {10.1145/641007.641093},
abstract = {Future human-machine interaction interfaces will need a perfect understanding of the person's behavior so that machines can learn from it, react accordingly, synthetically reproduce this behavior afterwards, etc. The study of user's head action and face expression is fundamental to achieve this comprehension. This technical demo shows the latest image processing techniques for face tracking and expression analysis developed at Eurecom. Our research on face analysis aims at synthetically reproducing head movements in telecom applications. Users will be able to test themselves on how our system can track and analyze their face expressions with just one webcamera only under any unconstrained environment.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {414–415},
numpages = {2},
keywords = {face analysis, face tracking, face animation, virtual reality, 3D-synthesis},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641094,
author = {Altman, Edward and Chen, Yu and Low, Wai Chong},
title = {Semantic Exploration of Lecture Videos},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641094},
doi = {10.1145/641007.641094},
abstract = {E-Learning is rapidly changing the way that universities and corporations offer education and training. In recent years, the acquisition and distribution of rich media content has been largely automated [1], However, existing applications are functionally and visually static and remain organized around the delivery media, rather than the knowledge representation and learning tasks of the student. The innovative approach of this system is the extraction of semantically meaningful structures in the lecture combined with text analysis to support task based queries. In this demonstration we will show this combination of pedagogical and content descriptions leads to novel forms of visualization and exploration of course lectures. System capabilities and semantic analysis technologies applied to lecture content obtained from a graduate level SMA (Singapore-MIT Alliance) distance education course will also be presented.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {416–417},
numpages = {2},
keywords = {MPEG-7, semantic analysis, lecture analysis, knowledge management, e-learning, visualization},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641095,
author = {Wolf, Patrick and Steinmetz, Arnd},
title = {LectureLounge: Experience Education beyond the Borders of the Classroom},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641095},
doi = {10.1145/641007.641095},
abstract = {LectureLounge is a research platform and a system to automatically and non-invasively capture, analyze, annotate, index, archive and publish live-presentations.On one hand LectureLounge covers the complete value chain from capturing to publication und the focus of automation and so is more than a media-on-demand system in operation. On the other hand LectureLounge is also a research platform designed and built to integrate modules of all kinds, for example, fully-automated capture systems, video/image feature extraction and analysis applications or MPEG-4/7 streaming modules.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {418},
numpages = {1},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641096,
author = {Duan, Ling-Yu and Xu, Min and Yu, Xiao-Dong and Tian, Qi},
title = {A Unified Framework for Semantic Shot Classification in Sports Videos},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641096},
doi = {10.1145/641007.641096},
abstract = {In this demonstration, we present a unified framework for semantic shot classification in sports videos. Unlike previous approaches, which focus on clustering by aggregating shots with similar low-level features, the proposed scheme makes use of domain knowledge of specific sport to perform a top-down video shot classification, including identification of video shots classes for each sport, and supervised learning and classification of given sports video with low-level and middle-level features extracted from the sports video. It's observed that for each sport we can predefine a small number of semantic shot classes, 5--10, which cover 90 to 95 % of sports broadcasting video. With supervised learning method, we can map the low-level features to middle-level semantic video shot attributes such as dominant object motion (a player), camera motion patterns, and court shape, etc. On the basis of the appropriate fusion of those middle-level shot attributes, we classify video shots into the predefined video shot classes, each of which has a clear semantic meaning. The proposed method has been tested over 3 types of sports videos: tennis, basketball, and soccer. Good classification results ranging from 80~95% have been achieved. The proposed framework provides a generic solution for sports video semantic shot classification, which can be adapted to a new sport type easily. With correctly classified sports video shots further structural and temporal analysis will be greatly facilitated.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {419–420},
numpages = {2},
keywords = {television, semantics, shot, sports, classification, video},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641097,
author = {Lai, Wei-Cheng and Chang, Chengwei and Chang, Edward and Cheng, Kwang-Ting and Crandell, Michael},
title = {PBIR-MM: Multimodal Image Retrieval and Annotation},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641097},
doi = {10.1145/641007.641097},
abstract = {We demonstrate PBIR-MM, an integrated system that we have built for conducting multimodal image retrieval. The system combines the strengths of content-based soft annotation (CBSA), multimodal relevance feedback through active learning, and perceptual distance formulation and indexing. PBIR-MM supports multimodal query and annotation in any combination of its three basic modes: seed-by-nothing, seed-by-keywords, and seed-by-content. We demonstrate PBIR-MM on a couple of very large image sets provided by image vendors and crawled from the Internet.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {421–422},
numpages = {2},
keywords = {query concept, active learning, image retrieval},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641098,
author = {Jaimes, Alejandro and Chang, Shih-Fu and Loui, Alexander C.},
title = {Duplicate Detection in Consumer Photography and News Video},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641098},
doi = {10.1145/641007.641098},
abstract = {Consumers often make more than one photograph of the same scene, creating non-identical duplicates and near duplicates. In Kodak's consumer photography database, on average, 19% of the images, per roll, fall into this category. Automatic detection of duplicates, therefore, is extremely useful in applications that help users organize their image collections. We introduce the challenging problem of non-identical duplicate image detection in consumer photography, describe STELLA (a novel interactive personal image collection organization system), and give an overview of our novel framework for detecting duplicate and near duplicate consumer photographs and news videos.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {423–424},
numpages = {2},
keywords = {copy detection, digital album, consumer photography},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641099,
author = {Chi, Chi-Hung and Cao, Yang},
title = {Progressive Proxy-Based Multimedia Transcoding System with Maximum Data Reuse},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641099},
doi = {10.1145/641007.641099},
abstract = {In this paper, we propose a new proxy-based transcoding system based on a novel, scalable, and progressive transfer model for multimedia data. This system features on-the-fly transcoding on streaming web data with negligible overhead, maximum data reuse among different transcoded versions of a web object, and the optimal bandwidth usage between the proxy and the server. The importance of the system reflects not only in its feasibility in implementation but also in its matching with the new HTTP protocol support for partial object retrieval and the emerging new multimedia data formats such as JPEG2000 and MPEG4.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {425–426},
numpages = {2},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641100,
author = {Yoshimi, Billibon H. and Pingali, Gopal S.},
title = {A Multimodal Speaker Detection and Tracking System for Teleconferencing},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641100},
doi = {10.1145/641007.641100},
abstract = {A serious problem in both audio and video conferencing facilities available today is the difficulty in determining who is speaking among a large number of participants. There is a strong need for developing meeting room infrastructure and teleconference facilities that improve the sense of presence and participation experienced in remote meetings. We present a distributed multimodal tracking system that uses multiple cameras and microphones to automatically select the current speaker among multiple meeting participants. The system actively obtains and transmits video showing a good view of the selected speaker. The tracking system is integrated into a web-based video conferencing application that connects seven meeting rooms around the globe. An important part of designing such a system is to determine sensor placement and configuration through systematic experiments in the actual rooms where the system is deployed.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {427–428},
numpages = {2},
keywords = {localization, video, IP, collaboration, telepresence, audio, face},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641101,
author = {B\"{o}sz\"{o}rm\'{e}nyi, L\'{a}szl\'{o} and D\"{o}ller, Mario and Hellwagner, Hermann and Kosch, Harald and Libsie, Mulugeta and Schojer, Peter},
title = {Comprehensive Treatment of Adaptation in Distributed Multimedia Systems in the ADMITS Project},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641101},
doi = {10.1145/641007.641101},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {429–430},
numpages = {2},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641102,
author = {L\"{o}ffler, Jobst and Biatov, Konstantin and Eckes, Christian and K\"{o}hler, Joachim},
title = {IFINDER: An MPEG-7-Based Retrieval System for Distributed Multimedia Content},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641102},
doi = {10.1145/641007.641102},
abstract = {This paper describes the MPEG-7 compliant indexing and retrieval system iFinder based on XML and open source database technology. The iFinder system automatically extracts metadata from A/V-content and allows access to the enriched content by means of a client/server-based retrieval engine. This multimedia retrieval system allows for search and retrieval of short video segments in huge multimedia archives. As a reference application, the iFinder system is used to index speeches from the German Parliament. The user can search for fragments of political speeches and receives matching video segments through a video streaming service.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {431–435},
numpages = {5},
keywords = {XML Databases, multi-modal content analysis, MPEG-7, speech and face recognition, distributed media archiving},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641104,
author = {Wang, James Z. and Li, Jia},
title = {Learning-Based Linguistic Indexing of Pictures with 2--d MHMMs},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641104},
doi = {10.1145/641007.641104},
abstract = {Automatic linguistic indexing of pictures is an important but highly challenging problem for researchers in computer vision and content-based image retrieval. In this paper, we introduce a statistical modeling approach to this problem. Categorized images are used to train a dictionary of hundreds of concepts automatically based on statistical modeling. Images of any given concept category are regarded as instances of a stochastic process that characterizes the category. To measure the extent of association between an image and the textual description of a category of images, the likelihood of the occurrence of the image based on the stochastic process derived from the category is computed. A high likelihood indicates a strong association. In our experimental implementation, the ALIP (Automatic Linguistic Indexing of Pictures) system, we focus on a particular group of stochastic processes for describing images, that is, the two-dimensional multiresolution hidden Markov models (2-D MHMMs). We implemented and tested the system on a photographic image database of 600 different semantic cat- egories, each with about 40 training images. Tested using 3,000 images outside the training database, the system has demonstrated good accuracy and high potential in linguistic indexing of these test images.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {436–445},
numpages = {10},
keywords = {image classification, wavelets, image segmentation, machine learning, computer vision, region matching, content-based image retrieval, hidden Markov model},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641105,
author = {Tarel, Jean-Philippe and Boughorbel, Sabri},
title = {On the Choice of Similarity Measures for Image Retrieval by Example},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641105},
doi = {10.1145/641007.641105},
abstract = {In image retrieval systems, a variety of simple similarity measures are used. The choice for one similarity measure or another is generally driven by an experimental comparison on a labeled database. The drawback of such an approach is that, while a large number of possible similarity measures can be tested, we do not know how to extend from the obtained results. However, the choice of a good similarity measure leads to noticeable better results. It is known that this choice is related to the variability of the images within the same class. Therefore, we propose a model of image retrieval systems and deduce a scheme for deriving the best similarity measure in a set of similarity measures, assuming a parametric model of the variability of feature vectors within the same class. An experimental validation of the model and the derived similarity measures is performed on synthetic ground-truth databases. Finally, from our experiments, we give several rules to follow for the design of ground-truth databases allowing reliable conclusions on the search of better similarity measures.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {446–455},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641106,
author = {Jing, Feng and Li, Mingjing and Zhang, Hong-Jiang and Zhang, Bo},
title = {An Effective Region-Based Image Retrieval Framework},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641106},
doi = {10.1145/641007.641106},
abstract = {We present a region-based image retrieval framework that integrates efficient region-based representation in terms of storage and retrieval and effective on-line learning capability. The framework consists of methods for image segmentation and grouping, indexing using modified inverted file, relevance feedback, and continuous learning. By exploiting a vector quantization method, a compact region-based image representation is achieved. Based on this representation, an indexing scheme similar to the inverted file technology is proposed. In addition, it supports relevance feedback based on the vector model with a weighting scheme. A continuous learning strategy is also proposed to enable the system to self improve. Experimental results on a database of 10,000 general-purposed images demonstrate the efficiency and effectiveness of the proposed framework.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {456–465},
numpages = {10},
keywords = {relevance feedback, inverted file, region-based image retrieval, continuous learning},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641107,
author = {Goh, King-Shy and Li, Beitao and Chang, Edward},
title = {DynDex: A Dynamic and Non-Metric Space Indexer},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641107},
doi = {10.1145/641007.641107},
abstract = {To date, almost all research work in the Content-Based Image Retrieval (CBIR) community has used Minkowski-like functions to measure similarity between images. In this paper, we first present a non-metric distance function, dynamic partial function (DPF), which works significantly better than Minkowski-like functions for measuring perceptual similarity; and we explain DPF's link to similarity theories in cognitive science. We then propose DynDex, an indexing method that deals with both the dynamic and non-metric aspects of the distance function. DynDex employs statistical methods including distance-based classification and bagging to enable efficient indexing with DPF. In addition to its efficiency for conducting similarity searches in very high-dimensional spaces, we show that DynDex remains effective when features are weighted dynamically for supporting personalized searches.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {466–475},
numpages = {10},
keywords = {high-dimensional index, similarity search, non-metric distance function},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641109,
author = {Chen, Milton},
title = {Achieving Effective Floor Control with a Low-Bandwidth Gesture-Sensitive Videoconferencing System},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641109},
doi = {10.1145/641007.641109},
abstract = {Multiparty videoconferencing with even a small number of people is often infeasible due to the high network bandwidth required. Bandwidth can be significantly reduced if most of the advantages of using full-motion video can be achieved with low-frame-rate video; unfortunately, the impact of low-frame-rate video on communication is relatively unexplored. We implemented a multiparty videoconferencing system that supports full-motion video, low-frame-rate video where the video is updated only once every few seconds, and a hybrid scheme where full-motion video is transmitted when the system detects that a user is making a gesture and low-frame-rate video is transmitted at all other times. We studied people using our system for small-group discussions and found that low-frame-rate video limited people's ability to request to speak or judge when to stop speaking. The hybrid scheme, conversely, was as effective as full-motion video for floor control, resulting in a similar number of speaker changes, while using only ten percent of the bandwidth.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {476–483},
numpages = {8},
keywords = {floor control, frame rate, multiparty videoconferencing},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641110,
author = {Liu, Qiong and Kimber, Don and Foote, Jonathan and Wilcox, Lynn and Boreczky, John},
title = {FlySPEC: A Multi-User Video Camera System with Hybrid Human and Automatic Control},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641110},
doi = {10.1145/641007.641110},
abstract = {FlySPEC is a video camera system designed for real-time remote operation. A hybrid design combines the high resolution of an optomechanical video camera with the wide field of view always available from a panoramic camera. The control system integrates requests from multiple users so that each controls a virtual camera. The control system seamlessly integrates manual and fully automatic control. It supports a range of options from untended automatic to full manual control. The system can also learn control strategies from user requests. Additionally, the panoramic view is always available for an intuitive interface, and objects are never out of view regardless of the zoom factor. We present the system architecture, an information-theoretic approach to combining panoramic and zoomed images to optimally satisfy user requests, and experimental results that show the FlySPEC system significantly assists users in a remote inspection tasks.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {484–492},
numpages = {9},
keywords = {collaborative and automatic camera control, distance learning, gesture based camera control, panoramic video, webcams, video communication, video conferencing, video production},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641111,
author = {Lee, Dar-Shyang and Erol, Berna and Graham, Jamey and Hull, Jonathan J. and Murata, Norihiko},
title = {Portable Meeting Recorder},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641111},
doi = {10.1145/641007.641111},
abstract = {The design and implementation of a portable meeting recorder is presented. Composed of an omni-directional video camera with four-channel audio capture, the system saves a view of all the activity in a meeting and the directions from which people spoke. Subsequent analysis computes metadata that includes video activity analysis of the compressed data stream and audio processing that helps locate events that occurred during the meeting. Automatic calculation of the room in which the meeting occurred allows for efficient navigation of a collection of recorded meetings. A user interface is populated from the metadata description to allow for simple browsing and location of significant events.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {493–502},
numpages = {10},
keywords = {appliance, audio processing, MPEG-2 compressed domain analysis, meeting recorder, omni-directional video},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641112,
author = {Cutler, Ross and Rui, Yong and Gupta, Anoop and Cadiz, JJ and Tashev, Ivan and He, Li-wei and Colburn, Alex and Zhang, Zhengyou and Liu, Zicheng and Silverberg, Steve},
title = {Distributed Meetings: A Meeting Capture and Broadcasting System},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641112},
doi = {10.1145/641007.641112},
abstract = {The common meeting is an integral part of everyday life for most workgroups. However, due to travel, time, or other constraints, people are often not able to attend all the meetings they need to. Teleconferencing and recording of meetings can address this problem. In this paper we describe a system that provides these features, as well as a user study evaluation of the system. The system uses a variety of capture devices (a novel 360° camera, a whiteboard camera, an overview camera, and a microphone array) to provide a rich experience for people who want to participate in a meeting from a distance. The system is also combined with speaker clustering, spatial indexing, and time compression to provide a rich experience for people who miss a meeting and want to watch it afterward.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {503–512},
numpages = {10},
keywords = {360 degree video, microphone array, meeting indexing, meeting capture, teleconferencing},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641114,
author = {Syeda-Mahmood, Tanveer},
title = {Retrieving Actions Embedded in Video},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641114},
doi = {10.1145/641007.641114},
abstract = {In a number of applications including surveillance, there is a need to reliably retrieve an action-depicting segment in a video. This is an enormously difficult problem due to the variability in an action's appearance when seen at different times. It requires reliable object and action segmentation, and robust methods for indexing the action content in a video. In this paper, we present a novel approach to action retrieval that extracts salient action events in query and database videos. These events serve as anchor points to initiate action recognition. Actions are recognized by forming a spatio-temporal shape for an action called the action cylinder. Robust recognition is achieved by recovering the viewpoint transformation and time correspondence between a query action and a given action segment in the video. We demonstrate the versatility of our method for the retrieving of complex actions within videos.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {513–522},
numpages = {10},
keywords = {recognition, actions, video understanding, segmentation},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641115,
author = {Cavallaro, Andrea and Steiger, Olivier and Ebrahimi, Touradj},
title = {Multiple Video Object Tracking in Complex Scenes},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641115},
doi = {10.1145/641007.641115},
abstract = {We present an automatic video object tracking algorithm capable of dealing with multiple simultaneous objects. The tracking is based on interactions between high-level and low-level image analysis results. The high-level result is a partition defining video objects, and the low-level result is a partition formed by homogeneous regions. For each region, a set of characteristic descriptors is produced. These region descriptors, and not regions themselves, are used to track the regions (and thus the objects) along time. Track management issues such as appearance and disappearance of objects, splitting and partial occlusions are resolved through interactions between regions and objects. Defining the tracking based on the parts of objects, identified by region segmentation, has led to a flexible technique that exploits the nature of the video object tracking problem. Experimental results show that the proposed method is able to track multiple rigid and deformable objects in indoor and outdoor scenes.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {523–532},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641116,
author = {Ma, Yu-Fei and Lu, Lie and Zhang, Hong-Jiang and Li, Mingjing},
title = {A User Attention Model for Video Summarization},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641116},
doi = {10.1145/641007.641116},
abstract = {Automatic generation of video summarization is one of the key techniques in video management and browsing. In this paper, we present a generic framework of video summarization based on the modeling of viewer's attention. Without fully semantic understanding of video content, this framework takes advantage of understanding of video content, this framework takes advantage of computational attention models and eliminates the needs of complex heuristic rules in video summarization. A set of methods of audio-visual attention model features are proposed and presented. The experimental evaluations indicate that the computational attention based approach is an effective alternative to video semantic analysis for video summarization.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {533–542},
numpages = {10},
keywords = {skimming, video summarization, attention model, video content analysis},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641117,
author = {Tuncel, Ertem and Ferhatosmanoglu, Hakan and Rose, Kenneth},
title = {VQ-Index: An Index Structure for Similarity Searching in Multimedia Databases},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641117},
doi = {10.1145/641007.641117},
abstract = {In this paper, we introduce a novel indexing technique based on efficient compression of the feature space for approximate similarity searching in large multimedia databases. Its main novelty is that state-of-the-art tools from the discipline of data compression are adopted to optimize the complexity-performance tradeoff in large data sets. The design procedure optimizes the query access time by jointly accounting for both database distribution and query statistics. We achieve efficient compression by using appropriate vector quantization (VQ) techniques, namely, multi-stage VQ and split-VQ, which are especially suited for limited memory applications. We partition the data set using the accumulated query history, and each partition of data points is separately compressed using a vector quantizer tailored to its distribution. The employed VQ techniques inherently provide a spectrum of points to choose from on the time/accuracy plane. This property is especially crucial for large multimedia databases where I/O time is a bottleneck, because it offers the flexibility to trade time for better accuracy. Our experiments demonstrate speedups of 20 to 35 over a VA-file technique that has been adapted for approximate nearest neighbor searching.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {543–552},
numpages = {10},
keywords = {retrieved information reduction, retrieved set reduction, vector quantization, approximate similarity searching, clustering, indexing},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641119,
author = {Foote, Jonathan and Cooper, Matthew and Girgensohn, Andreas},
title = {Creating Music Videos Using Automatic Media Analysis},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641119},
doi = {10.1145/641007.641119},
abstract = {We present methods for automatic and semi-automatic creation of music videos, given an arbitrary audio soundtrack and source video. Significant audio changes are automatically detected; similarly, the source video is automatically segmented and analyzed for suitability based on camera motion and exposure. Video with excessive camera motion or poor contrast is penalized with a high unsuitability score, and is more likely to be discarded in the final edit. High quality video clips are then automatically selected and aligned in time with significant audio changes. Video clips are adjusted to match the audio segments by selecting the most suitable region of the desired length. Besides a fully automated solution, our system can also start with clips manually selected and ordered using a graphical interface. The video is then created by truncating the selected clips (preserving the high quality portions) to produce a video digest that is synchronized with the soundtrack music, thus enhancing the impact of both.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {553–560},
numpages = {8},
keywords = {audio analysis, video analysis, music video, video editing},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641120,
author = {Christel, Michael G. and Hauptmann, Alexander G. and Wactlar, Howard D. and Ng, Tobun D.},
title = {Collages as Dynamic Summaries for News Video},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641120},
doi = {10.1145/641007.641120},
abstract = {This paper introduces the video collage, a novel effective interface for browsing and interpreting video collections. The paper discusses how collages are automatically produced, illustrates their use, and evaluates their effectiveness as summaries across news stories. Collages are presentations of text and images derived from multiple video sources, which provide an interactive visualization for a set of video documents, summarizing their contents and providing a navigation aid for further exploration. The dynamic creation of collages is based on user context, e.g., an originating query, coupled with automatic processing to refine the candidate imagery. Named entity identification and common phrase extraction provides descriptive text. The dynamic manipulation of collages allows user-directed browsing and reveals additional detail. The utility of collages as summaries is examined with respect to other published news summaries.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {561–569},
numpages = {9},
keywords = {video surrogate, video collage, information visualization},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641121,
author = {Pampalk, Elias and Rauber, Andreas and Merkl, Dieter},
title = {Content-Based Organization and Visualization of Music Archives},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641121},
doi = {10.1145/641007.641121},
abstract = {With Islands of Music we present a system which facilitates exploration of music libraries without requiring manual genre classification. Given pieces of music in raw audio format we estimate their perceived sound similarities based on psychoacoustic models. Subsequently, the pieces are organized on a 2-dimensional map so that similar pieces are located close to each other. A visualization using a metaphor of geographic maps provides an intuitive interface where islands resemble genres or styles of music. We demonstrate the approach using a collection of 359 pieces of music.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {570–579},
numpages = {10},
keywords = {clustering, content-based music retrieval, feature extraction, genre, rhythm, self-organizing map, user interface},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641123,
author = {Dorai, Chitra and Mauthe, Andreas and Nack, Frank and Rutledge, Lloyd and Sikora, Thomas and Zettl, Herbert},
title = {Media Semantics: Who Needs It and Why?},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641123},
doi = {10.1145/641007.641123},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {580–583},
numpages = {4},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641125,
author = {Yang, Cheng},
title = {Efficient Acoustic Index for Music Retrieval with Various Degrees of Similarity},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641125},
doi = {10.1145/641007.641125},
abstract = {Content-based music retrieval research has mostly focused on symbolic data rather than acoustical data. Given that there are no general-purpose transcription algorithms that can convert acoustical data into musical scores, new methods are needed to do music retrieval on acoustical data. In this paper, we review some existing methods on contentbased music retrieval, discuss different definitions of music similarity, and present a new framework to perform music indexing and retrieval. The framework is based on an earlier prototype we developed, with significant improvements.In our framework known as MACSIS, each audio file is broken down into small segments and converted into feature vectors. All vectors are stored in a high-dimensional indexing structure called LSH, a probabilistic indexing scheme that makes use of multiple hashing instances in parallel. At retrieval time, small segments of audio matches are retrieved from the index and pieced together using the Hough Transform technique, and results are used as the basis to rank candidate matches.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {584–591},
numpages = {8},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641126,
author = {Li, Jin},
title = {Embedded Audio Coding (EAC) with Implicit Auditory Masking},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641126},
doi = {10.1145/641007.641126},
abstract = {An embedded audio coder (EAC) is proposed with compression performance rivals the best available non-scalable audio coder. The key technology that empowers the EAC with high performance is the implicit auditory masking. Unlike the common practice, where an auditory masking threshold is derived from the input audio signal, transmitted to the decoder and used to quantize (modify) the transform coefficients; the EAC integrates the auditory masking process into the embedded entropy coding. The auditory masking threshold is derived from the encoded coefficients and used to change the order of coding. There is no need to store or send the auditory masking threshold in the EAC. By eliminating the overhead of the auditory mask, EAC greatly improves the compression efficiency, especially at low bitrate. Extensive experimental results demonstrate that the EAC coder substantially outperforms existing scalable audio coders and audio compression standards (MP3 and MPEG-4), and rivals the best available commercial audio coder. Yet the EAC compressed bitstream is fully scalable, in term of the coding bitrate, number of audio channels and audio sampling rate.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {592–601},
numpages = {10},
keywords = {sub-bitplane, JND threshold, implicit auditory masking, bitstream assembler, audio compression, scalable, entropy coding},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641127,
author = {Lu, Lie and Zhang, Hong-Jiang},
title = {Speaker Change Detection and Tracking in Real-Time News Broadcasting Analysis},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641127},
doi = {10.1145/641007.641127},
abstract = {This paper addresses the problem of real time speaker change detection and speaker tracking in broadcasted news video analysis. In such a case, both speaker identities and number of speakers are assumed unknown. A two-step speaker change detection algorithm, including potential change detection and refinement, is proposed. Speaker tracking is performed based on the results of speaker change detection. A Bayesian Fusion method is used to fuse multiple audio features to get a more reliable result. The algorithm has low complexity and runs in real-time with a very limited delay in analysis. Our experiments show that the algorithms produce very satisfactory results.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {602–610},
numpages = {9},
keywords = {speaker segmentation, speaker change detection, speaker tracking, audio content analysis},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641129,
author = {Nakajima, Tatsuo},
title = {Experiences with Building Middleware for Audio and Visual Networked Home Appliances on Commodity Software},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641129},
doi = {10.1145/641007.641129},
abstract = {In this paper, we describe our currently ongoing work to build distributed middleware for networked audio and visual home appliances, which is executed on commodity software. The current prototype has adopted HAVi(Home Audio/Video Interoperability) as distributed middleware for controlling home appliances, which makes it possible to integrate a variety of home appliances and services. In our system, we have implemented HAVi in Java. Programs processing continuous media that emulate digital consumer devices are directly implemented on the Linux operating systems. Since Java and Linux are running on a variety of embedded platforms, our software can be ported to a target embedded system without the modification. Therefore, new home applications can be developed on a standard PC platform, and this makes the development cost of future advanced home appliances dramatically cheap.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {611–620},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641130,
author = {Nakazawa, Jin and Tokuda, Hideyuki},
title = {A Pluggable Service-to-Service Communication Mechanism for Home Multimedia Networks},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641130},
doi = {10.1145/641007.641130},
abstract = {This paper proposes a pluggable service-to-service (S2S) communication mechanism in a middleware for home networks, called Virtual Networked Appliance (VNA) architecture. In the architecture, service description method and the plug-gable S2S communication mechanism are separated in an orthogonal way. Through the separation, VNA architecture solved problems of home networks on which users have to operate multiple heterogeneous middleware technologies simultaneously: middleware fragmentation problem, due to complexity of realizing heterogeneous services on one middle-ware technology: aspect realization violation problem. The pluggable S2S communication mechanism provides service programmers with a simple aspect representation method to define a service-specific protocol concern apart from the service's implementation. It also provides off-the-shelf protocol modules of such well-known communication protocols as RTP, RTSP, HTTP, and SMTP for an inter-service communication, and dynamically loads them based on the aspects defined by the programmer. This reduces the complexity of implementing heterogeneous services on the VNA architecture, thereby addressing the problems. In this paper, we first clarify the two problems. Then, we describe the proposed mechanism with an overview of the middleware architecture referring to a composite service: "Follow-You-and-Me Video."},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {621–630},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641131,
author = {Wichadakul, Duangdao and Gu, Xiaohui and Nahrstedt, Klara},
title = {A Programming Framework for Quality-Aware Ubiquitous Multimedia Applications},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641131},
doi = {10.1145/641007.641131},
abstract = {Ubiquitous computing promises a computing environment that seamlessly and pervasively delivers applications to the user, despite changes of resources, devices, and locations. However, few ubiquitous multimedia applications (UMAs) exist up-to-date. One of the main reasons lies in the fact that it is difficult and error-prone to build a UMA which is mobile and deployable in different ubiquitous environments, and still provides acceptable application-specific Quality-of-Service (QoS) guarantees. In this paper, we present the design and implementation of a novel programming framework, called 'QCompiler" to address the challenges. The framework includes (1) a high-level application specification for the application developer to easily write a UMA with specific quality, mobility, and ubiquity supports, (2) a meta-data compilation, which provides automated consistency checks, translations, and substitutions, to relieve the application developer from dealing with complex programming related to quality, mobility, and ubiquity, (3) a binding, which prepares a quality-aware specification to be executable, in a specific deployment environment, and (4)a run-time meta-data execution, utilizing the meta-data compilation's results, to manage and control a quality-aware multimedia application. As a case study, we apply the programming framework to build a mobile Video-on-Demand (VoD) application. The experimental results show tradeoffs between easiness and flexibility to develop and deploy UMA, and overheads during UMA instantiation and adaptation.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {631–640},
numpages = {10},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641133,
author = {Thakur, Aruna and Carr-Motycokva, Lenka},
title = {A Dynamic Controller for Optimal Layering of Video},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641133},
doi = {10.1145/641007.641133},
abstract = {Layering techniques for video transmission are being actively considered as a way of satisfying receivers in a heterogeneous environment. A layering scheme based on a combination of network constrains and the perceptual quality of video is an attractive proposition. In this paper a feed-forward post-codec controller has been described for sending a video sequence in an optimally layered way. For optimization the controller considers the perceptual quality of video, load on sender and load on network. The correlations used for the controller have been developed experimentally and deductively. The controller so developed has been shown to enhance the perceptual quality of video at the receiver end in a heterogeneous environment.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {641–643},
numpages = {3},
keywords = {perceptual quality, codec, layering, controller},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641134,
author = {Libsie, Mulugeta and Kosch, Harald},
title = {Content Adaptation of Multimedia Delivery and Indexing Using MPEG-7},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641134},
doi = {10.1145/641007.641134},
abstract = {This work introduces a framework for adapting MPEG-4 intra- and inter-Elementary Streams and for encoding the results in an MPEG-7 stream to be used for resource adaptation on the delivery path to the user.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {644–646},
numpages = {3},
keywords = {MPEG-7, MPEG4, resource adaptation, multimedia indexing},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641136,
author = {Zhao, Yafan and Richardson, Iain E. G.},
title = {Complexity Management for Video Encoders},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641136},
doi = {10.1145/641007.641136},
abstract = {Computational complexity is an important performance constraint for software-only video CODECs. The aim of this research is to develop a video coding system with variable, controllable computational complexity. Adaptive algorithms for DCT and motion estimation are proposed separately to reduce complexity of each function and maintain it at target level. An integrated approach to video CODEC complexity management is also addressed. This work will have potential benefit for a wide range of computation-constrained or power-constrained multimedia applications.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {647–649},
numpages = {3},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641137,
author = {Muir, Laura J. and Richardson, Iain E. G.},
title = {Video Telephony for the Deaf: Analysis and Development of an Optimised Video Compression Product},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641137},
doi = {10.1145/641007.641137},
abstract = {The multimedia capability of video telephony and video conferencing systems has many applications and benefits. This paper describes research and development that aims to optimise video compression systems for a specific application - personal communication at a distance for deaf people. Results of eye movement tracking experiments and proposals for image content prioritisation based on these results are presented. The requirement for an appropriate quality assessment methodology is also addressed.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {650–652},
numpages = {3},
keywords = {video conferencing, video telephony, eye movement tracking, sign language, image content prioritisation},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641138,
author = {Duflos, Sandrine and Kervella, Brigitte and Horlait, Eric},
title = {An Architecture for Policy-Based Security Management for Distributed Multimedia Services},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641138},
doi = {10.1145/641007.641138},
abstract = {In this paper, I will describe my Ph.D. research work on a multi level architecture to manage security for distributed multimedia services through the use of policies.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {653–655},
numpages = {3},
keywords = {security management, policy-driven management, security policies},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641140,
author = {Kaufmann, Hannes},
title = {Construct3D: An Augmented Reality Application for Mathematics and Geometry Education},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641140},
doi = {10.1145/641007.641140},
abstract = {Construct3D is a three dimensional geometry construction tool specifically designed for mathematics and geometry education. It is based on the mobile collaborative augmented reality system "Studierstube". We describe our efforts in developing a system for the improvement of spatial abilities and maximization of transfer of learning. Means of application and integration in mathematics and geometry education at high school as well as university level are being discussed. Anecdotal evidence supports our claim that Construct3D is easy to learn, encourages experimentation with geometric constructions and improves spatial skills.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {656–657},
numpages = {2},
keywords = {geometry education, spatial intelligence, mathematics education},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641141,
author = {Tang, Wai-Kwan and Wong, Tien-Tsin and Heng, Pheng-Ann},
title = {The Immersive Cockpit},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641141},
doi = {10.1145/641007.641141},
abstract = {Wide field-of-view (FOV) is necessary for many industrial applications, such as air traffic control, large vehicle driving and navigation. Unfortunately, the supporting structure/frame in most systems usually blocks part of the view, results in "blind spot" and raises the risk. In some cases, the working site is hazardous to the pilot. In this video demonstration, we introduce a video-based tele-immersive system, called the Immersive Cockpit. It captures live videos from the working site and recreates an immersive environment at the remote site where the pilot situates. It immerses the pilot at the remote site with a panoramic view of the environment, hence improves interactivity and safety. The design goals of our system are real-time, live, low-cost and scalable.We stitch multiple video streams captured from ordinary CCD cameras to generate a panoramic video. To avoid being blocked by the supporting frame, we allow a flexible placement of cameras. This approach trades the accuracy of the generated panorama image for a larger field-of-view. The panoramic video is presented on an immersive display which covers the field-of-view of the viewer.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {658–659},
numpages = {2},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641142,
author = {Doherty, John and Wilcox, Lynn and Girgensohn, Andreas},
title = {A Hitchcock Assisted Video Edited Night at the Opera},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641142},
doi = {10.1145/641007.641142},
abstract = {Hitchcock is a semi-automatic video editing system. This video shows users collaboratively authoring a home video.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {660–661},
numpages = {2},
keywords = {video keyframes, user interface, video editing},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641143,
author = {Liu, Kuo-Yu and Huang, Natalius and Wu, Bo-Hung and Chu, Wei-Ta and Chen, Herng-Yow},
title = {The WSML System: Web-Based Synchronization Multimedia Lecture System},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641143},
doi = {10.1145/641007.641143},
abstract = {This demonstration presents a web-based multimedia lecture system that perfectly integrates multimedia lecturing with static HTML pages and enables their presentation in synchronization. We develop key techniques to reproduce vivid web-teaching scenarios for on-demand access, including events capturing scheme and synchronized mechanism. To facilitate multimedia lectures creation, the easy-to-use authoring and managing tools specially designed for teachers have been also included in the development. In addition, integrated presentation and efficient access issues are also discussed for the student's aspect.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {662–663},
numpages = {2},
keywords = {synchronous presentation, synchronized mechanism, navigation events},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641144,
author = {Ip, Horace H. S. and Hay, Young and Tang, Alex C. C.},
title = {Body-Brush: A Body-Driven Interface for Visual Aesthetics},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641144},
doi = {10.1145/641007.641144},
abstract = {With the development of an innovative motion capture and analysis system using frontal infra-red illumination, and based on a systematic study of the relations between the human body movement and the visual art language, the Body-Brush turns the human body as a whole into a dynamic brush. The Body-Brush enables humans to interact intuitively with the machine to create a rich variety of visual forms and space within a virtual 3-D canvas.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {664–665},
numpages = {2},
keywords = {frontal infrared illumination, gesture analysis, human-computer interface, motion tracking},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641145,
author = {Gil, Jos\'{e} A. and Pont, Ana and Forc\'{e}n, Emilio},
title = {Interactive Guide to Valencia},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641145},
doi = {10.1145/641007.641145},
abstract = {This paper describes the features and development of the Interactive Guide to Valencia. This is a multimedia product based on a geographic information system database.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {666–667},
numpages = {2},
keywords = {GIS, 3D modeling, multimedia guide},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641146,
author = {Ghahremani, Kambiz and Shahabi, Cyrus and Yao, Shu-Yuen Didi and Zimmermann, Roger},
title = {Yima: Real-Time Multimedia Storage and Retrieval},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641146},
doi = {10.1145/641007.641146},
abstract = {Yima is a scalable, real-time streaming architecture that enables applications such as video-on-demand and distance learning on a large scale. While Yima incorporates lessons learned from first generation research prototypes, it also complies with industry standards in content format (MPEG-4) and communication protocols (RTP/RTSP). Yima improves upon both research and commercial approaches by using a bipartite design and alternative approaches to handling variable-bit-rate (VBR) video. We also integrated a selective retransmission protocol into Yima's RTP server to recover from packet loss. Lastly, we tweaked available hardware and software to achieve certain objectives (e.g., playback of HDTV streams on an HDTV monitor). Yima is operational and supports a variety of display bandwidths.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {668–669},
numpages = {2},
keywords = {continuous media, video server, MPEG-4, multimedia storage, scalable},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

@inproceedings{10.1145/641007.641147,
author = {Andersson, Ola and Cacciatore, Elenor and L\"{o}wgren, Jonas and Lundin, Thomas},
title = {Post-Hoc Worknotes: A Concept Demo of Video Content Management},
year = {2002},
isbn = {158113620X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/641007.641147},
doi = {10.1145/641007.641147},
abstract = {Post-hoc worknotes is a concept demonstration, an envisionment showing how workgroup communication could be supported using a combination of existing technologies in the field of nontextual information management. We have identified a number of use-driven requirements for video content management, including the tailoring of metadata structures to project and process models.},
booktitle = {Proceedings of the Tenth ACM International Conference on Multimedia},
pages = {670–671},
numpages = {2},
keywords = {content management, video processing, workgroup support},
location = {Juan-les-Pins, France},
series = {MULTIMEDIA '02}
}

