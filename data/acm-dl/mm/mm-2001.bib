@inproceedings{10.1145/500141.500143,
author = {Jain, Ramesh},
title = {TeleExperience: Communicating Compelling Experience},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500143},
doi = {10.1145/500141.500143},
abstract = {We experience our environment using our natural senses: sight, sound, touch, taste, and smell. These senses combined with the knowledge of the world allow us to experience and function in the world. Data are observed facts or measurements. Information is derived from data in a specific context. Experience is direct observation or participation in an event. The development of civilization is the story of the development of understanding of 'experience' and how to share it with fellow human beings of current and future generations. The desire to share experiences and desire to experience various events where one can not be present, will continue to be the motivating factor in the development of exciting technology in the future. A look at history shows how our society evolved to become an 'information society' and is on its way to becoming an 'experience society'.Compelling and engaging experiences require immersion in a rich set of multimedia data and information so that one can directly observe a subset of the data and information. TeleExperience is a natural major step in technology evolution. It will impact every aspect of our society including education, business, sexual behavior, and health care. TeleExperience will give rise to an experience society. In this presentation, we will examine the role of multimedia information systems, multimedia presentations, situated computing, perception systems, and personalization approaches to realize TeleExperience. Then we will discuss aspects of taking a promising and exciting technology from 'laboratory to popular practice' based on practical experience.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {1},
numpages = {1},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500145,
author = {Rui, Yong and He, Liwei and Gupta, Anoop and Liu, Qiong},
title = {Building an Intelligent Camera Management System},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500145},
doi = {10.1145/500141.500145},
abstract = {Given rapid improvements in storage devices, network infrastructure and streaming-media technologies, a large number of corporations and universities are recording lectures and making them available online for anytime, anywhere access. However, producing high-quality lecture videos is still labor intensive and expensive. Fortunately, recent technology advances are making it feasible to build automated camera management systems to capture lectures. In this paper we report our design of such a system, including system configuration, audio-visual tracking techniques, software architecture, and user study. Motivated by different roles in a professional video production team, we have developed a multi-cinematographer single-director camera management system. The system performs lecturer tracking, audience tracking, and video editing all fully automatically, and offers quality close to that of human-operated systems.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {2–11},
numpages = {10},
keywords = {sound source localization, automated camera management, virtual cinematographer, lecturer tracking, virtual director},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500146,
author = {Uchihashi, Shingo},
title = {Improvising Camera Control for Capturing Meeting Activities Using a Floor Plan},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500146},
doi = {10.1145/500141.500146},
abstract = {This paper describes camera control interfaces for capturing meetings and presentations into multimedia documents. While technologies are maturing to deliver multimedia documents over network, skilled human hands are still required to create the contents. We had dug into the problem and found that some portion of it derives from current camera control systems, which only provide interfaces for incremental navigations. Presets are provided for some systems to avoid cumbersome manipulations, but the difficulty to improvise controls remains untouched. We introduced an interface using floor plan for selecting an arbitrary area to be captured. We also conducted a study to compare our method with other two typical camera control interfaces. The results revealed that our method was significantly better than a typical joystick-metaphor interface. Although an interface with presets resulted superior for completing tasks in limited conditions, the participants judge the use of a floor plan to be equally good in respect to ease of camera navigation as they intended. They also indicated possible improvement for our interface to close in on the one with presets.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {12–18},
numpages = {7},
keywords = {camera control interface, camera control, contents creation, floor plan, meeting capture},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500147,
author = {Chen, Milton},
title = {Design of a Virtual Auditorium},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500147},
doi = {10.1145/500141.500147},
abstract = {We built a videoconference system called the Virtual Auditorium to support dialog-based distance learning. The instructor can see dozens of students on a tiled wall-sized display and establish eye contact with any student. Telephone-quality audio and television-quality video can be streamed using commodity codecs such as wavelet and MPEG-4. Support for stream migration allows a seamless user interface to span the multiple computers driving the display wall..We performed user studies on the auditorium parameters. We found that the optimal display wall size must balance two contradictory requirements: subjects prefer larger videos for seeing facial expressions and smaller videos for seeing everyone without head movement. Ideally, each video should have a field of view that spans 14 degrees, which corresponds to a slightly larger than life-size image. At the very least, each video should have a field of view of 6 degrees. We found that a video window should be less than 2.7 degrees horizontally and 9 degrees vertically from the camera in order to maintain the appearance of eye contact for the remote viewer. In addition, we describe a previously unreported gaze phenomenon: a person's expectation determines his perception of eye contact under ambiguous conditions.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {19–28},
numpages = {10},
keywords = {virtual auditorium, display wall, eye contact, distance learning},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500149,
author = {Slaney, Malcolm and Ponceleon, Dulce and Kaufman, James},
title = {Multimedia Edges: Finding Hierarchy in All Dimensions},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500149},
doi = {10.1145/500141.500149},
abstract = {This paper describes a new unified representation for the information in a video. We reduce the dimensionality of the signal with either a singular-value decomposition (on the semantic and image data) or mel-frequency cepstral coefficients (on the audio data) and then concatenate the vectors to form a multi-dimensional representation of the video. Using scale-space techniques we find large jumps in the video's path, which we call edges. We use these techniques to analyze the temporal properties of the audio and image data in a video. This analysis creates a hierarchical segmentation of the video, or a table-of-contents, from the audio, semantic and image data.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {29–40},
numpages = {12},
keywords = {color space, semantic space, latent semantic indexing, singular-value decomposition, hierarchy, temporal properties, multimedia, audio, images, automatic segmentation, video, scale space},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500150,
author = {K\"{u}hne, Gerald and Richter, Stephan and Beier, Markus},
title = {Motion-Based Segmentation and Contour-Based Classification of Video Objects},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500150},
doi = {10.1145/500141.500150},
abstract = {The segmentation of objects in video sequences constitutes a prerequisite for numerous applications ranging from computer vision tasks to second-generation video coding.We propose an approach for segmenting video objects based on motion cues. To estimate motion we employ the 3D structure tensor, an operator that provides reliable results by integrating information from a number of consecutive video frames. We present a new hierarchical algorithm, embedding the structure tensor into a multiresolution framework to allow the estimation of large velocities.The motion estimates are included as an external force into a geodesic active contour model, thus stopping the evolving curve at the moving object's boundary. A level set-based implementation allows the simultaneous segmentation of several objects.As an application based on our object segmentation approach we provide a video object classification system. Curvature features of the object contour are matched by means of a curvature scale space technique to a database containing preprocessed views of prototypical objects.We provide encouraging experimental results calculated on synthetic and real-world video sequences to demonstrate the performance of our algorithms.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {41–50},
numpages = {10},
keywords = {structure tensor, curvature scale, object classification, space, motion segmentation},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500151,
author = {Ngo, Chong-Wah and Pong, Ting-Chuen and Zhang, Hong-Jiang},
title = {On Clustering and Retrieval of Video Shots},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500151},
doi = {10.1145/500141.500151},
abstract = {Clustering of video data is an important issue in video abstraction, browsing and retrieval. In this paper, we propose a two-level hierarchical clustering approach by aggregating shots with similar motion and color features. Motion features are computed directly from 2D tensor histograms, while color features are represented by 3D color histograms. Cluster validity analysis is further applied to automatically determine the number of clusters at each level. Video retrieval can then be done directly based on the result of clustering. The proposed approach is found to be useful particularly for sports games, where motion and color are important visual cues when searching and browsing the desired video shots. Since most games involve two teams, clsssification and retrieval of teams becomes an interesting topic. To achieve these goals, nevertheless, an initial as well as critical step is to isolate team players from background regions. Thus, we also introduce approach to segment foreground objects (players) prior to classification and retrieval.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {51–60},
numpages = {10},
keywords = {team classification, hierarchical clustering, motion and color retrieval},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500153,
author = {Chambers, Desmond and Lyons, Gerard and Duggan, Jim},
title = {Stream Enhancements for the CORBA Event Service},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500153},
doi = {10.1145/500141.500153},
abstract = {This paper describes a number of enhancements for the standard CORBA Event Service. The basic service definition has been extended to support stream events, multimedia data flows, event fragmentation, quality of service definition, as well as multicast event delivery. The paper evaluates the service performance and describes experiences using the enhanced service in the development of a test application.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {61–69},
numpages = {9},
keywords = {objects, multimedia, events, groupware and multicast, CORBA, services, streams},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500154,
author = {Xu, Lihao},
title = {Efficient and Scalable On-Demand Data Streaming Using UEP Codes},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500154},
doi = {10.1145/500141.500154},
abstract = {In this paper, we propose and analyze a new multicast scheme for delivering on-demand streaming data using UEP UnEqual Protection codes. The scheme allows an end user to join the multicast channel for adata stream at ,any time to play out the requested data stream from its beginning after a fixed amount of initial delay time. Resource usage of the scheme, including server computing bandwidth,network bandwidth and client's buffer space, is only determined by the original data stream length and the initial playout delay, butindependent of either the number or the arrival pattern of individual end user requests. Thus the scheme is totally scalable with the number of end users, fully utilizing the data delivery efficiency of a multicast network.The scheme also use resources efficiently, e.g., with an initial delay of 30 and 60 seconds respectively, multicasting a 2-hour video using this scheme needs respectively about 5.5 and 4.8 times server computing bandwidth and network bandwidth of that for a single unicast delivery of the same original data stream.In addition, the scheme also tolerates packet loss transmission, thus significantly reduces the cost of implementing a reliable multicast network layer to ensure delivery of all packets.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {70–78},
numpages = {9},
keywords = {scalability, multicast, on-demand streaming data, UEP code, efficiency},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500155,
author = {Allen, Arthur},
title = {Optimal Delivery of Multi-Media Content over Networks},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500155},
doi = {10.1145/500141.500155},
abstract = {In this paper, we describe scalable optimal methods for delivering archived and live multi-media content from servers to multi-media client players endowed with substantial RAM or disk-based buffers. These methods result from the application of linearoptimization theory (linear programming) to the problem of how best to modulate the flow rate of constant-bit-rate (CBR) content for all sessions linking a server to its clients, in which session flow rates are subject to upper and lower bound constraints, and aggregate flow cannot exceed a specified maximum. An efficient O(n) algorithm to maximize aggregate flow is described. We propose a tunable minimum constraint on session flows that is shown to result in a rapid and sustained accumulation of reserve content within a player's buffer. An associated Call Admission Control (CAC) algorithm is also described. The benefits of the methods described include improved server efficiency, enhanced end-user experience (QOS), cost effective end to-end content delivery, directly from origin servers to clients without need of intervening edge-caching technology.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {79–88},
numpages = {10},
keywords = {video-on-Demand, VBR bandwidth smoothing, QOS, optimization, CBR, live events, CAC, linear programming, edge-caching, ad insertion},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500157,
author = {Wu, P. and Manjunath, B. S.},
title = {Adaptive Nearest Neighbor Search for Relevance Feedback in Large Image Databases},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500157},
doi = {10.1145/500141.500157},
abstract = {Relevance feedback is often used in refining similarity retrievals in image and video databases. Typically this involves modification to the similarity metrics based on the user feedback and recomputing a set of nearest neighbors using the modified similarity values. Such nearest neighbor computations are expensive given that typical image features, such as color and texture, are represented in high dimensional spaces. Search complexity is a ciritcal issue while dealing with large databases and this issue has not received much attention in relevance feedback research. Most of the current methods report results on very small data sets, of the order of few thousand items, where a sequential (and hence exhaustive search) is practical. The main contribution of this paper is a novel algorithm for adaptive nearest neigbor computations for high dimensional feature vectors and when the number of items in the databse is large. The proposed method exploits the correlations between two consecutive nearest neighbor searches when the underlying similarity metric is changing, and filters out a significant number of candidates ina two stage search and retrieval process, thus reducing the number of I/O accesses to the database. Detailed experimental results are provided using a set of about 700,000 images. Comparision to the existing method shows an order of magnitude overall imporovement.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {89–97},
numpages = {9},
keywords = {nearest neighbor search, relevance feedback, similarity retrieval},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500158,
author = {Su, Zhong and Li, Stan and Zhang, Hongjiang},
title = {Extraction of Feature Subspaces for Content-Based Retrieval Using Relevance Feedback},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500158},
doi = {10.1145/500141.500158},
abstract = {In the past few years, relevance feedback (RF) has been used as an effective solution for content-based image retrieval (CBIR). Although effective, the RF-CBIR framework does not address the issue of feature extraction for dimension reduction and noise reduction. In this paper, we propose a novel method for extracting features for the class of images represented by the positive images provided by subjective RF. Principal Component Analysis (PCA) is used to reduce both noise contained in the original image features and dimensionality of feature spaces. The method increases the retrieval speed and reduces the memory significantly without sacrificing the retrieval accuracy.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {98–106},
numpages = {9},
keywords = {relevance feedback, Bayesian estimation, content-based image retrieval (CBIR), principal component analysis (PCA)},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500159,
author = {Tong, Simon and Chang, Edward},
title = {Support Vector Machine Active Learning for Image Retrieval},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500159},
doi = {10.1145/500141.500159},
abstract = {Relevance feedback is often a critical component when designing image databases. With these databases it is difficult to specify queries directly and explicitly. Relevance feedback interactively determinines a user's desired output or query concept by asking the user whether certain proposed images are relevant or not. For a relevance feedback algorithm to be effective, it must grasp a user's query concept accurately and quickly, while also only asking the user to label a small number of images. We propose the use of a support vector machine active learning algorithm for conducting effective relevance feedback for image retrieval. The algorithm selects the most informative images to query a user and quickly learns a boundary that separates the images that satisfy the user's query concept from the rest of the dataset. Experimental results show that our algorithm achieves significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {107–118},
numpages = {12},
keywords = {support vector machines, relevance feedback, active learning, image retrieval, query concept},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500161,
author = {Syeda-Mahmood, Tanveer and Ponceleon, Dulce},
title = {Learning Video Browsing Behavior and Its Application in the Generation of Video Previews},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500161},
doi = {10.1145/500141.500161},
abstract = {With more and more streaming media servers becoming commonplace, streaming video has now become a popular medium of instruction, advertisement, and entertainment. With such prevalence comes a new challenge to the servers: Can they track browsing behavior of users to determine what interest users? Learning this information is potentially valuable not only for improved customer tracking and context-sensitive e-commerce, but also in the generation of fast previews of videos for easy pre-downloads. In this paper, we present a formal learning mechanism to track video browsing behavior of users. This information is then used to generate fast video previews. Specifically, we model the states a user transitions while browsing through videos to be the hidden states of a Hidden Markov Model. We estimate the parameters of the HMM using maximum likelihood estimation for each sample observation sequence of user interaction with videos. Video previews are then formed from interesting segments of the video automatically inferred from an analysis of the browsing states of viewers. Audio coherence in the previews is maintained by selecting clips spanning complete clauses containing topically significant spoken phrases. The utility of learning video browsing behavior is demonstrated through user studies and experiments.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {119–128},
numpages = {10},
keywords = {interesting content, video previews, topics, browsing behavior, learning, audio},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500162,
author = {Pingali, Gopal and Opalach, Agata and Carlbom, Ingrid},
title = {Multimedia Retrieval through Spatio-Temporal Activity Maps},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500162},
doi = {10.1145/500141.500162},
abstract = {As multiple video cameras and other sensors generate very large quantities of multimedia data in media productions and surveillance applications, a key challenge is to identify the relevant portions of the data and to rapidly retrieve the corresponding sensor data. Spatio-temporal activity maps serve as an efficient and intuitive graphical user interface for multimedia retrieval, particularly when the media streams are derived from multiple sensors observing a physical environment. We formulate the media retrieval problem in this context, and develop an architecture for interactive media retrieval by combining spatio-temporal "activity maps" with domain specific event information. Activity maps are computed from trajectories of motion of objects in the environment, which in turn are derived automatically by analysis of sensor data. We present an activity map based video retrieval system for the sport of tennis and demonstrate that the activity map based scheme significantly helps the user in a) discovering the relevant portions of the data, and b) non-linearly retrieving the corresponding media streams.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {129–136},
numpages = {8},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500163,
author = {Zhou, Xiang Sean and Huang, Thomas S.},
title = {Comparing Discriminating Transformations and SVM for Learning during Multimedia Retrieval},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500163},
doi = {10.1145/500141.500163},
abstract = {On-line learning or "relevance feedback" techniques for multimedia information retrieval have been explored from many different points of view: from early heuristic-based feature weighting schemes to recently proposed optimal learning algorithms, probabilistic/Bayesian learning algorithms, boosting techniques, discriminant-EM algorithm, support vector machine, and other kernel-based learning machines. Based on a careful examination of the problem and a detailed analysis of the existing solutions, we propose several discriminating transforms as the learning machine during the user interaction. We argue that relevance feedback problem is best represented as a biased classification problem, or a (1+x)-class classification problem. Biased Discriminant Transform (BDT) is shown to outperform all the others. A kernel form is proposed to capture non-linearity in the class distributions.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {137–146},
numpages = {10},
keywords = {support vector machine, relevance feedback, kernel method, multimedia retrieval, discriminating transform},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500165,
author = {Anastasiadis, Stergios V. and Sevcik, Kenneth C. and Stumm, Michael},
title = {Server-Based Smoothing of Variable Bit-Rate Streams},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500165},
doi = {10.1145/500141.500165},
abstract = {We introduce an algorithm that uses buffer space available at the server for smoothing disk transfers of variable bit-rate streams. Previous smoothing techniques prefetched stream data into the client buffer space, instead. However, emergence of personal computing devices with widely different hardware configurations means that we should not always assume abundance of resources at the client side. The new algorithm is shown to have optimal smoothing effect under the specified constraints. We incorporate it into a prototype server, and demonstrate significant increase in the number of streams concurrently supported at different system scales. We also extend our algorithm for striping variable bit-rate streams on heterogeneous disks. High bandwidth utilization is achieved across all the different disks, which leads to server throughput improved by several factors at high loads.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {147–158},
numpages = {12},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500166,
author = {Ooi, Wei Tsang and van Renesse, Robbert},
title = {Distributing Media Transformation over Multiple Media Gateways},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500166},
doi = {10.1145/500141.500166},
abstract = {Media gateways have been proposed as a solution to the network heterogeneity problem in media multicasting. Services on the gateways transform media streams as they flow through the gateways. In this paper, we present our work on composable services in media gateways. A user can request a computation to be performed on a set of media streams. The system then distributes the computation over multiple gateways for execution. We present an algorithm for decomposing the computation into sub-computations, and an application-level protocol that locates appropriate media gateways to run these sub-computations.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {159–168},
numpages = {10},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500167,
author = {Conrad, Phillip T. and Caro, Armando and Amer, Paul},
title = {ReMDoR: Remote Multimedia Document Retrieval over Partial Order Transport},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500167},
doi = {10.1145/500141.500167},
abstract = {This paper presents results from performance experiments that demonstrate and quantify performance improvements when a PO/R transpor5t service is used instead of an ordered/reliable service (O/R e.g., TCP) or an unordered/unreliable service (e.g. UDP). We first describe the Remote Multimedia Document Retrieval system (ReMDoR), an experimental application developed by the authors to evaluate the performance of remote document retrieval over a variety of transport protocols. We then provide a detailed analysis of experiments comparing O/R service to PO/R service for retrieval of a multimedia document. Our results show that between 5% and 10% loss, user-perceivable improvements in progressive display are obtained when PO/R service is used. These results suggest that when packet losses occur in an underlying packet-switched network, transport services providing reliable delivery over independent streams (such the emerging Internet protocol SCTP) are beneficial for retrieval of streaming multimedia.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {169–180},
numpages = {12},
keywords = {transport protocols, multimedia, partial order},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500169,
author = {Bulterman, Dick and Delp, Edward and Eleftheriadis, Alexandros and Fernicola, Pablo and Lanphier, Rob and Tan, See-Mong and Srinivasan, Savitha and Ponceleon, Dulce},
title = {Is Streaming Media Becoming Mainstream?},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500169},
doi = {10.1145/500141.500169},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {181–186},
numpages = {6},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500171,
author = {Pfeiffer, Silvia},
title = {Pause Concepts for Audio Segmentation at Different Semantic Levels},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500171},
doi = {10.1145/500141.500171},
abstract = {This paper presents work on the determination of temporal audio segmentations at different semantic levels. The segmentation algorithm draws upon the calculation of relative silences or pauses. A perceptual loudness measure is the only feature employed. An adaptive threshold is used for classification into pause and non-pause. The segmentation algorithm that determines perceptually relevant pause intervals for different semantic levels incorporates a minimum duration and a maximum interruption constraint. The influence of the different parameters on the segmentation is examined in experiments and presented in this paper. A new approach for evaluating segmentation accuracies is required. It is shown that the simple perceptual pause concept has a very high relevance when segmenting audio at different semantic levels.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {187–193},
numpages = {7},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500172,
author = {Wang, Ye and Vilermo, Miikka},
title = {A Compressed Domain Beat Detector Using MP3 Audio Bitstreams},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500172},
doi = {10.1145/500141.500172},
abstract = {This paper presents a novel beat detector that processes MPEG-1 Layer III (known as MP3) encoded audio bitstreams directly in the compressed domain. Most previous beat detection or tracking systems dealing with MIDI or PCM signals are not directly applicable to compressed audio bitstreams, such as MP3 bitstreams. We have developed the beat detector as a part of a beat-pattern based error concealment scheme for streaming music over error prone channels. Special effort was used to obtain a tailored trade-off between performance, complexity and memory consumption for this specific application. A comparison between the machine-detected results to the human annotation has shown that the proposed method correctly tracked beats in 4 out of 6 popular music test signals. The results were analyzed.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {194–202},
numpages = {9},
keywords = {beat detection, bitstream processing, error concealment, beat tracking, MP3, compressed domain processing, MPEG audio},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500173,
author = {Lu, Lie and Jiang, Hao and Zhang, HongJiang},
title = {A Robust Audio Classification and Segmentation Method},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500173},
doi = {10.1145/500141.500173},
abstract = {In this paper, we present a robust algorithm for audio classification that is capable of segmenting and classifying an audio stream into speech, music, environment sound and silence. Audio classification is processed in two steps, which makes it suitable for different applications. The first step of the classification is speech and non-speech discrimination. In this step, a novel algorithm based on KNN and LSP VQ is presented. The second step further divides non-speech class into music, environment sounds and silence with a rule based classification scheme. Some new features such as the noise frame ratio and band periodicity are introduced and discussed in detail. Our experiments in the context of video structure parsing have shown the algorithms produce very satisfactory results.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {203–211},
numpages = {9},
keywords = {audio classification and segmentation, audio content analysis},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@dataset{10.1145/review-500141.500173_R35246,
author = {Harb, Hadi},
title = {Review ID:R35246 for DOI: 10.1145/500141.500173},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-500141.500173_R35246}
}

@inproceedings{10.1145/500141.500175,
author = {Henderson, Tristan and Bhatti, Saleem},
title = {Modelling User Behaviour in Networked Games},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500175},
doi = {10.1145/500141.500175},
abstract = {In this paper we attempt to gain an understanding of the behaviour of users in a multipoint, interactive communication scenario. In particular, we wish to understand the dynamics of user participation at a session level. We present wide-area session level traces of the popular multiplayer networked games Quake and Half-Life. These traces were gathered by regularly polling 2256 game servers located all over the Internet, and querying the number of players present at each server and how long they had been playing. We analyse three specific features of the data: the number of players in a game, the interarrival times between players and the length of a player's session. We find significant time-of-day and network externality effects in the number of players. Player duration times fit an exponential distribution, while interarrival times fit a heavy-tailed distribution. The implications of our findings are discussed in the context of provisioning and charging for network quality of service for multipoint and multicast transmission. This work is ongoing.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {212–220},
numpages = {9},
keywords = {measurement, pricing, provisioning, games},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500176,
author = {Vogel, J\"{u}rgen and Mauve, Martin},
title = {Consistency Control for Distributed Interactive Media},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500176},
doi = {10.1145/500141.500176},
abstract = {In this paper we present a generic consistency control service for distributed interactive media, i.e. media which allow a distributed group of users to interact with the medium itself. Consistency control is vital to these media since they typically require that a local copy of the medium's state be maintained by each user's application. Our service helps the applications to keep the local state copies consistent. The main characteristics of this service are as follows: a significant number of inconsistencies are prevented by using a mechanism called local lag. Inconsistencies that cannot be prevented are repaired by an improved timewarp algorithm that can be executed locally without burdening the network or the applications of other users. Exceptional situations and consistency during late-join situations are supported by a consistent state request mechanism. Moreover, the service also supports the application in detecting intention conflicts between the actions of distinct users. The major part of this functionality is based on a media model and the application level protocol for distributed interactive media (RTP/I) and can thus be reused by arbitrary RTP/I-based applications. In order to demonstrate the feasibility of our approach and to evaluate its performance we have integrated the generic consistency service into a shared whiteboard system.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {221–230},
numpages = {10},
keywords = {distributed interactive media, local lag, consistency, late join, timewarp, RTP/I, intention conflict, mlb},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500177,
author = {Poellabauer, Christian and Schwan, Karsten and West, Richard},
title = {Coordinated CPU and Event Scheduling for Distributed Multimedia Applications},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500177},
doi = {10.1145/500141.500177},
abstract = {Distributed multimedia applications require support from the underlying operating system to achieve and maintain their desired Quality of Service (QoS). This has led to the creation of novel task and message schedulers and to the development of QoS mechanisms that allow applications to explicitly interact with relevant operating system services. However, the task scheduling techniques developed to date are not well equipped to take advantage of such interactions. As a result, important events such as position update messages in virtual environments may be ignored. If a CPU scheduler ignores these events, players will experience a lack of responsiveness or even inconsistencies in the virtual world. This paper argues that real-time and multimedia applications can benefit from coordinatedel event delivery mechanism, termed ECalls, that supports such coordination. We then show ECalls's ability to reduce variations in inter-frame times for media streams.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {231–240},
numpages = {10},
keywords = {scheduling, multimedia, quality of Service},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500179,
author = {Bailey, Brian P. and Konstan, Joseph A. and Carlis, John V.},
title = {DEMAIS: Designing Multimedia Applications with Interactive Storyboards},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500179},
doi = {10.1145/500141.500179},
abstract = {To create an innovative interactive multimedia application, a multimedia designer needs to rapidly explore numerous behavioral design ideas early in the design process, as creating innovative behavior is the cornerstone of creating innovative multimedia. Current tools and techniques do not support a designer's need for early behavior exploration, limiting her ability to rapidly explore and effectively communicate behavioral design ideas. To address this need, we have developed a sketch-based, interactive multimedia storyboard tool that uses a designer's ink strokes and textual annotations as an input design vocabulary. By operationalizing this vocabulary, the tool transforms an otherwise static sketch into a working example. The behavioral sketch can be quickly edited using gestures and an expressive visual language. By enabling a designer to explore and communicate behavioral design ideas using working examples early in the design process, our tool facilitates the creation of a more effective, compelling, and entertaining multimedia application.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {241–250},
numpages = {10},
keywords = {multimedia design, storyboards, gestures, authoring},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500180,
author = {Nack, Frank and Putz, Wolfgang},
title = {Designing Annotation before It's Needed},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500180},
doi = {10.1145/500141.500180},
abstract = {This paper considers the automated and semi-automated annotation of audiovisual media in a new type of production framework, A4SM (Authoring System for Syntactic, Semantic and Semiotic Modelling). We present the architecture of the framework and outline the underlying XML-Schema based content description structures of A4SM. We then describe tools for a news and demonstrate how video material can be annotated in real time and how this information can not only be used for retrieval but also can be used during the different phases of the production process itself. Finally, we discuss the pros and cons of our approach of evolving semantic networks as the basis for audio- visual content description.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {251–260},
numpages = {10},
keywords = {XML Schema, semantic networks, MPEG-7, news production, automated annotation},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500181,
author = {Nepal, Surya and Srinivasan, Uma and Reynolds, Graham},
title = {Automatic Detection of 'Goal' Segments in Basketball Videos},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500181},
doi = {10.1145/500141.500181},
abstract = {Advances in the media and entertainment industries, for example streaming audio and digital TV, present new challenges for managing large audio-visual collections. Efficient and effective retrieval from large content collections forms an important component of the business models for content holders and this is driving a need for research in audio-visual search and retrieval. Current content management systems support retrieval using low-level features, such as motion, colour, texture, beat and loudness. However, low-level features often have little meaning for the human users of these systems, who much prefer to identify content using high-level semantic descriptions or concepts. This creates a gap between the system and the user that must be bridged for these systems to be used effectively. The research presented in this paper describes our approach to bridging this gap in a specific content domain, sports video. Our approach is based on a number of automatic techniques for feature detection used in combination with heuristic rules determined through manual observations of sports footage. This has led to a set of models for interesting sporting events-goal segments-that have been implemented as part of an information retrieval system. The paper also presents results comparing output of the system against manually identified goals.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {261–269},
numpages = {9},
keywords = {temporal models, sports video analysis, content-based retrieval},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500183,
author = {Wijayaratne, Ravi and Reddy, A. L. Narasimha},
title = {System Support for Providing Integrated Services from Networked Multimedia Storage Servers},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500183},
doi = {10.1145/500141.500183},
abstract = {In this paper, we describe our experience in building an integrated multimedia storage system, Prism. Our current Linux-based implementation of Prism provides three levels of service: deadline guarantees for periodic applications, best-effort better response times for interactive applications and starvation-free throughput guarantees for aperiodic applications. Prism separates resource allocation from resource scheduling. Resource allocation is controlled across the service classes by a system-wide policy and service class specific admission controllers. Resource scheduling is done at the resources. This separation allows Prism to be deployed even when the storage system is separated on a network from the file system.We report on the important aspects of Prism architecture, innovations required to build Prism on top of Linux and lessons learned during the implementation and testing of Prism. We present experimental results to show that Prism achieves its goals in supporting multiple service classes within a single system. We compare Prism against standard Linux operating system to show the impact of our approach.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {270–279},
numpages = {10},
keywords = {file systems, disk, scheduling, multimedia, admission control},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500184,
author = {Bradshaw, Michael K. and Wang, Bing and Gao, Lixin and Kurose, Jim and Shenoy, Prashant and Towsley, Don and Sen, Subhabrata},
title = {Periodic Broadcast and Patching Services: Implementation, Measurement, and Analysis in an Internet Streaming Video Testbed},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500184},
doi = {10.1145/500141.500184},
abstract = {Multimedia streaming applications can consume a significant amount of server and network resources. Periodic broadcast and patching are two approaches that use multicast transmission and client buffering in innovative ways to reduce server and network load, while at the same time allowing asynchronous access to multimedia steams by a large number of clients. Current research in this area has focussed primarily on the algorithmic aspects of these approaches, with evaluation performed via analysis or simulation. In this paper, we describe the design and implementation of a flexible streaming video server and client testbed that implements both periodic broadcast and patching, and explore the issues that arise when implementing these algorithms. We present measurements detailing the overheads associated with the various server components (signaling, transmission schedule computation, data retrieval and transmission), the interactions between the various components of the architecture, and the overall end-to-end performance. We also discuss the importance of an appropriate server video segment caching policy. We conclude with a discussion of the insights gained from our implementation and experimental evaluation.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {280–290},
numpages = {11},
keywords = {server, periodic broadcast, patching},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500185,
author = {Sundaram, Vijay and Shenoy, Prashant},
title = {Bandwidth Allocation in a Self-Managing Multimedia File Server},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500185},
doi = {10.1145/500141.500185},
abstract = {In this paper, we argue that manageability of file servers is just as important, if not more, as performance. We focus on the design of a self-managing file server and address the specific problem of automating bandwidth allocation to application classes in single-disk and multi-disk servers. The bandwidth allocation techniques that we propose consists of two key components: a workload monitoring module that efficiently monitors the load in each application class and a bandwidth manager that uses these workload statistics to dynamically determine the allocation of each class. We evaluate the efficacy of our techniques via a simulation study and demonstrate that our techniques (i) exploit the semantics of each application class while determining their allocations, (ii) provide control over the time-scale of monitoring and allocation, and (iii) provide stable behavior even during transient overloads. Our comparison with a static allocation technique shows that dynamic bandwidth allocation can yield queue lengths that are 59% smaller during overloads and admit a larger number of soft real-time clients into the system.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {291–301},
numpages = {11},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500187,
author = {Tosun, Ali Saman Saman and Feng, Wu-chi},
title = {On Error Preserving Encryption Algorithms for Wireless Video Transmission},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500187},
doi = {10.1145/500141.500187},
abstract = {In this paper, we describe error preserving encryption mechanisms for transmission of vido over wireless networks. One of the main problems with the secure transmission of data over wireless networks is that the bit errors that occur need to typically be sesolved before decryption can begin. For vido straming applications, this is unacceptable due to the general requirement that video be presented to the user in a continuous manner with low latency. In this paper, we describe a systematic approach to understanding error preserving encryption algorithms. That is, encryption algorithms designed specifically for video to solve this problem. The main objective of this work is to ensure that the basic encryption of the stream can survive bit errors and that the errors are then passed to the application. We make use of the fact that video compression typically results in random byte distribution. Error preserving encryption algorithms are secure against ciphertext only attacks but vulnerable against known plaintext attacks. We limit this vulnerabillity by requiring a key exchange for each session.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {302–308},
numpages = {7},
keywords = {wireless video transmission, video encryption},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500188,
author = {Nguyen, Anthony G. and Hwang, Jenq-Neng},
title = {Scene Context Dependent Rate Control},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500188},
doi = {10.1145/500141.500188},
abstract = {To prevent the loss of the information embedded in the generated variable bit rate data that is transmitted over a constant bit rate channel, several methods were proposed in MPEG TMN5, H.263 TMN5, and TMN8. In these methods, the quantity of coded data is controlled by adjusting the coding parameters according to the amount of data remaining in the buffer. Because this control is based on the past coded information and does not reflect the nature of the image being coded, there is no assurance that sufficient image quality will be obtained. In this paper, we present a Scene Context Dependent coding scheme to control the generated variable bit rate data over a constant bit rate channel for non real-time video applications and show the improvements over the encoding using the TMN H263 codec. This can be considered as a method to control the bit rate in accordance with the characteristics of human visual perception using the combination of feedforward control, feed-backward control, and model-based approaches.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {309–318},
numpages = {10},
keywords = {rate control (RC), constant bit rate (CBR), variable bit rate (VBR), scene context dependent (SCD)},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500189,
author = {Cheng, Qiang and Huang, Thomas S.},
title = {An Image Watermarking Technique Using Pyramid Transform},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500189},
doi = {10.1145/500141.500189},
abstract = {An image watermarking technique based on pyramid transforms is proposed. An arbitrary binary pattern is formed into an effective hypothesized pattern and transmitted as a watermark. Multiresolution pyramid transforms are applied to host images, whose characteristics are exploited to embed the watermark. The detector is designed to be effective to a wide range of original signal sources and noise sources. The scheme is designed to achieve efficient trade-offs between perceptual invisibility, robustness and trustworthy detection. The experiments demonstrate that the proposed technique has high imperceptibility, good robustness, and accurate detection. It can be applied to copyright notification, enforcement, and fingerprinting.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {319–328},
numpages = {10},
keywords = {watermarking, verification coding, pyramid transfrom},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500191,
author = {Sun, Xinding and Foote, Jonathan and Kimber, Don and Manjunath, B. S.},
title = {Panoramic Video Capturing and Compressed Domain Virtual Camera Control},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500191},
doi = {10.1145/500141.500191},
abstract = {A system for capturing panoramic video and a novel method for corresponding compressed domain virtual camera control is presented. It targets applications such as classroom lectures and video conferencing. The proposed method is based on the FlyCam panoramic video system that is designed to produce high resolution and wide-angle video sequences by stitching the video pictures from multiple stationary cameras. The panoramic video sequence is compressed into an MPEG-2 stream for delivery. The proposed method integrates region of Interest (ROI) detection, tracking, and virtual camera control, and works on compressed domain information only. It first detects the ROI in the P (predictive coded) picture using only the macroblock type information, It then up-samples this detection result to obtain the ROI of the whole video stream. The ROI is tracked using a Kalman filter. The Kalman filter estimation results are used for virtual camera control that simulates human controlled video recording. The system has no physical camera motion and the virtual camera parameters are readily available for video indexing. The proposed system has been implemented for real time processing.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {329–347},
numpages = {19},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500192,
author = {Kimber, Don and Foote, Jonathan and Lertsithichai, Surapong},
title = {FlyAbout: Spatially Indexed Panoramic Video},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500192},
doi = {10.1145/500141.500192},
abstract = {We describe a system called FlyAbout which uses spatially indexed panoramic video for virtual reality applications. Panoramic video is captured by moving a 360@deg camera along continuous paths. Users can interactively replay the video with the ability to view any interesting object or choose a particular direction. Spatially indexed video gives the ability to travel along paths or roads with a map-like interface. At junctions, or intersection points, users can chose which path to follow as well as which direction to look, allowing interaction not available with conventional video. Combining the spatial index with a spatial databsdde of maps or objects allows users to navigate to specific locations or interactively inspect particular objects.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {339–347},
numpages = {9},
keywords = {virtual reality, video maps, spatial databases, interactive video, panoramic video},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500193,
author = {Wilson, Andrew and Mayer-Patel, Ketan and Manocha, Dinesh},
title = {Spatially-Encoded Far-Field Representations for Interactive Walkthroughs},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500193},
doi = {10.1145/500141.500193},
abstract = {We introduce the notion of spatially encoded video and use it for efficiently representing image-based impostors for interactive walkthroughs. As part of a pre-process, we automatically decompose the model and compute the far-fields. The resulting texture images are organized along multiple dimensions and can be accessed in a user-steered order at interactive rates. Our encoding algorithm can compress the impostors size by two orders of magnitude. Furthermore, the storage cost for additional impostors or samples grows sub-linearly. The resulting system has been applied to a complex CAD environment composed of 13 million triangles. We are able to render it at interactive rates on a PC with little loss in image quality.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {348–357},
numpages = {10},
keywords = {MPEG, spatial data structures, image databases, rendering systems, image-based rendering},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500195,
author = {Natatsu, Ryohei and Tadenuma, Makoto and Maekawa, Tadao},
title = {Computer Technologies That Support Kansei Expression Using the Body},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500195},
doi = {10.1145/500141.500195},
abstract = {Although the conventional concept of communication is the exchange of logical information, the exchange of Kansei has become very important recently, especially in the case of mobile telephone communications. In addition, it has been recognized that the use of the body, such as facial expressions and gestures, is essential in communications. These facts indicate that echnologies that can support Kansesi expression using the body will become key technologies for future communications. In the paper, this point is discussed first. Then, as examples of such technologies, research results obtained by the authors are described.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {358–364},
numpages = {7},
keywords = {interactive dance, communication, wearable computer, multimedia},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500196,
author = {Li, Yan and Yu, Feng and Xu, Ying-Qing and Chang, Eric and Shum, Heung-Yeung},
title = {Speech-Driven Cartoon Animation with Emotions},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500196},
doi = {10.1145/500141.500196},
abstract = {In this paper, we present a cartoon face animation system for multimedia HCI applications. We animate face cartoons not only from input speech, but also based on emotions derived from speech signal. Using a corpus of over 700 utterances from different speakers, we have trained SVMs (support vector machines) to recognize four categories of emotions: neutral, happiness, anger and sadness. Given each input speech phrase, we identify its emotion content as a mixture of all four emotions, rather than classifying it into a single emotion. Then, facial expressions are= generated from the recovered emotion for each phrase, by morphing different cartoon templates that correspond to various emotions. To ensure smooth transitions in the animation, we apply low-pass filtering to the recovered (and possibly jumpy) emotion sequence. Moreover, lip-syncing is applied to produce the lip movement from speech, by recovering a statistical audio-visual mapping. Experimental results demonstrate that cartoon animation sequences generated by our system are of good and convincing quality.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {365–371},
numpages = {7},
keywords = {speech emotion, multimedia HCI, cartoon animation, recognition, lip-syncing},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500197,
author = {Deshpande, Sachin and Zeng, Wenjun},
title = {Scalable Streaming of JPEG2000 Images Using Hypertext Transfer Protocol},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500197},
doi = {10.1145/500141.500197},
abstract = {This paper describes a scalable architecture for streaming of JPEG2000 images, using Hypertext Transfer Protocol (HTTP). JPEG2000 is a new image compression standard. One of the goals of JPEG2000 is to support large images. For a large image, even the compressed image file size can be very big. Thus downloading the entire image at its full resolution can take a long time depending upon the user's connection speed. Thus we propose to use streaming of JPEG2000 images. We use Hypertext transfer protocol (HTTP) for streaming. The use of HTTP to stream JPEG2000 images will ease its deployment, because of the widespread availability and accessibility of web servers. Thus JPEG2000 images can be hosted by web server and can be streamed to the client helper application. Our solution is scalable. The clients can view image at a variety of resolutions and quality levels. It is also possible to stream only selected region of the image at a particular resolution and decode this partial stream and display it at the client. Thus client devices with different capabilities, variety of screen resolutions, heterogeneous bandwidths can all achieve a scalable viewing of the same content stored in a single file.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {372–381},
numpages = {10},
keywords = {resolution scalability, JPEG2000, quality scalability, HTTP streaming, scalable streaming, image streaming, region-of-interest scalability},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500198,
author = {He, Liwei and Gupta, Anoop},
title = {Exploring Benefits of Non-Linear Time Compression},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500198},
doi = {10.1145/500141.500198},
abstract = {In comparison to text, audio-video content is much more challenging to browse. Time-compression has been suggested as a key technology that can support browsing-time compression speeds up the playback of audio-video content without causing the pitch to change. Simple forms of time-compression are starting to appear in commercial streaming-media products from Microsoft and Real Networks.In this paper we explore the potential benefits of more recent and advanced types of time compression, called non-linear time compression. The most advanced of these algorithms exploit fine-grain structure of human speech (e.g., phonemes) to differentially speedup segments of speech, so that the overall speedup can be higher. In this paper we explore what are the actual gains achieved by end-users from these advanced algorithms. Our results indicate that the gains are actually quite small in common cases and come with significant system complexity and some audio/video synchronization issues.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {382–391},
numpages = {10},
keywords = {time compression, digital library, user evaluation, multimedia browsing},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500200,
author = {Li, Jiang and Chen, Gang and Xu, Jizheng and Wang, Yong and Zhou, Hanning and Yu, Keman and Ng, King To and Shum, Heung-Yeung},
title = {Bi-Level Video: Video Communication at Very Low Bit Rates},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500200},
doi = {10.1145/500141.500200},
abstract = {The rapid development of wired and wireless networks tremendously
facilitates communications between people. However, most of the
current wireless networks still work in low bandwidths, and mobile
devices still suffer from weak computational power, short battery
lifetime and limited display capability. We developed a very low
bit-rate bi-level video coding technique, which can be used in
video communications almost anywhere, anytime on any device. The
spirit of this method is that rather than giving highest priority
to the basic colors of an image as in conventional DCT-based
compression methods, we give preference to the outline features of
scenes when we have limited bandwidths. These features can be
represented by bi-level image sequences that are converted from
gray-scale image sequences. By analyzing the temporal correlation
between successive frames and flexibilities in the scene
presentation using bi-level images, we achieve very high ratios
with our bi-level video compression scheme. Experiments show that
in low bandwidths, our method provides clearer shape, smoother
motion, shorter initial latency and much cheaper computational cost
than do DCT-based methods. Our method is especially suitable for
small mobile devices such as handheld PCs, palm-size PCs and mobile
phones that possess small display screens and light computational
power, and work in low bandwidth wireless networks. We have built
PC and Pocket PC versions of bi-level video phone systems, which
typically provide QCIF-size video with a frame rate of 5-15 fps for
a 9.6 Kbps bandwidth.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {392–400},
numpages = {9},
keywords = {MPEG, bi-level video, JBIG, video broadcast and communication, video coding, portrait video},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500201,
author = {Jang, Jyh-Shing Roger and Lee, Hong-Ru},
title = {Hierarchical Filtering Method for Content-Based Music Retrieval via Acoustic Input},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500201},
doi = {10.1145/500141.500201},
abstract = {This paper presents an implementation of a content-based music retrieval system that can take a user's acoustic input (8-second clip of singing or humming) via a microphone and then retrieve the intended song from a database containing over 3000 candidate songs. The system, known as Super MBox, demonstrates the feasibility of real-time music retrieval with a high success rate. Super MBox first takes the user's acoustic input from a microphone and converts it into a pitch vector. Then a hierarchical filtering method (HFM) is used to first filter out 80% unlikely candidates and then compare the query input with the remaining 20% candidates in a detailed manner. The output of Super MBox is a ranked song list according to the computed similarity scores. A brief mathematical analysis of the two-step HFM is given in the paper to explain how to derive the optimum parameters of the comparison engine. The proposed HFM and its analysis framework can be directly applied to other multimedia information retrieval systems. We have tested Super MBox extensively and found the top-20 success rate is over 85%, based on a dataset of about singing/humming 2000 clips from people with mediocre singing skills. Our studies demonstrate the feasibility of using Super MBox as a prototype for music search engines over the Internet and/or query engines in digital music libraries.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {401–410},
numpages = {10},
keywords = {pattern recognition, audio signal processing, audio indexing and retrieval, dynamic programming, content-based music retrieval, nearest neighbor search, dynamic time warping, query by singing},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500202,
author = {Naphade, Milind R. and Wang, Roy and Huang, Thomas S.},
title = {Supporting Audiovisual Query Using Dynamic Programming},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500202},
doi = {10.1145/500141.500202},
abstract = {A necessary capability for content-based retrieval is to support the paradigm of query by example. Most systems for video retrieval support queries using image sequences only. We present an algorithm for matching multimodal (audio-visual) patterns for the purpose of content-based video retrieval. The novel ability of our approach to use the information content in multiple media coupled with a strong emphasis on temporal similarity differentiates it from the state-of-the-art in content-based retrieval. At the core of the pattern matching scheme is a dynamic programming algorithm, which leads to a significant improvement in performance. Coupling the use of audio with video this algorithm can be applied to grouping of shots based on audio-visual similarity. We also support relevance feedback. The user can provide feedback to the system, by choosing clips, which are closer to the user's desired target. The system then automatically adjusts the relative weights or relevance of the media and fetches different sets of target clips accordingly. It is our observation that a few iterations of such feedback are generally sufficient, for retrieving the desired video clips.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {411–420},
numpages = {10},
keywords = {video retrieval, relevance feedback, dynamic programming, nonlinear warping},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500204,
author = {Ho, Jiann-Min and Hu, Jia-Cheng and Steenkiste, Peter},
title = {A Conference Gateway Supporting Interoperability between SIP and H.323},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500204},
doi = {10.1145/500141.500204},
abstract = {Increased network bandwidth is making desktop video conferencing an attractive application for an increasing number of computer users. Unfortunately, two competing standards for video conferencing signaling are in use, H.323 and SIP. In this paper we look at the interoperability between these two standards by developing a conferencing gateway that supports conferences involving both SIP and H.323 clients. By appropriately translating between H.323 and SIP operations, our prototype gateway supports basic multi-party video conferencing between NetMeeting (an H.323 client) and VIC (a SIP client) without modifications to the clients. However, our experiments also show that seamless interoperation would require changes to the client implementations and the standards.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {421–430},
numpages = {10},
keywords = {video conferencing signaling protocols, interoperability, H.323, video conferencing gateway, SIP},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500205,
author = {Liang, Yi J. and Steinbach, Eckehard G. and Girod, Bernd},
title = {Real-Time Voice Communication over the Internet Using Packet Path Diversity},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500205},
doi = {10.1145/500141.500205},
abstract = {The quality of real-time voice communication over best-effort networks is mainly determined by the delay and loss characteristics observed along the network path. Excessive playout buffering at the receiver is prohibitive and significantly delayed packets have to be discarded and considered as late loss. We propose to improve the tradeoff among delay, late loss rate, and speech quality using multi-stream transmission of real-time voice over the Internet, where multiple redundant descriptions of the voice stream are sent over independent network paths. Scheduling the playout of the received voice packets is based on a novel multi-stream adaptive playout scheduling technique that uses a Lagrangian cost function to trade delay versus loss. Experiments over the Internet suggest largely uncorrelated packet erasure and delay jitter characteristics for different network paths which leads to a noticeable path diversity gain. We observe significant reductions in mean end-to-end latency and loss rates as well as improved speech quality when compared to FEC protected single-path transmission at the same data rate. In addition to our Internet measurements, we analyze the performance of the proposed multi-path voice communication scheme using the ns network simulator for different network topologies, including shared network links.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {431–440},
numpages = {10},
keywords = {voice over IP, forward error correction, transmission, multi-stream transmission, packet path diversity, adaptive playout scheduling, multiple description coding, multi-path},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500206,
author = {Sanneck, Henning and Le, Nguyen Tuong Long and Wolisz, Adam and Carle, Georg},
title = {Intra-Flow Loss Recovery and Control for VoIP},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500206},
doi = {10.1145/500141.500206},
abstract = {"Best effort" packet-switched networks, like the Internet, do not offer a reliable transmission of packets to applications with real-time constraints such as voice. Thus, the loss of packets impairs the application-level utility. For voice this utility impairment is twofold: on one hand, even short bursts of lost packets may decrease significantly the ability of the receiver to conceal the packet loss and the speech signal playout is interrupted. On the other hand, some packets may be particular sensitive to loss as they carry more important information in terms of user perception than other packets.We first develop an end-to-end model based on loss run-lengths with which we can describe the loss distribution within a flow. These packet-level metrics are then linked to user-level objective speech quality metrics. Using this framework, we find that for low-compressing sample-based codecs (PCM) with loss concealment isolated packet losses can be concealed well, whereas burst losses have a higher perceptual impact. For high-compressing frame-based codecs (G.729) on one hand the impact of loss is amplified through error propagation caused by the decoder filter memories, though on the other hand such coding schemes help to perform loss concealment by extrapolation of decoder state. Contrary to sample-based codecs we show that the concealment performance may "break" at transitions within the speech signal however.We then propose mechanisms which differentiate between packets within a voice data flow to minimize the impact of packet loss. We designate these methods as "intra-flow" loss recovery and control. At the end-to-end level, identification of packets sensitive to loss (sender) as well as loss concealment (receiver) takes place. Hop-by-hop support schemes then allow to (statistically) trade the loss of one packet, which is considered more important, against another one of the same flow which is of lower importance. As both packets require the same cost in terms of network transmission, a gain in user perception is obtainable. We show that significant speech quality improvements can bem achieved and additional data and delay overhead can be avoided while still maintaining a network service which is virtually identical to best effort in the long term.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {441–454},
numpages = {14},
keywords = {differentiated services, loss sensitivity, voice over IP, loss metrics, loss concealment, queue management, objective speech quality measurement},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500208,
author = {Stienstra, Marcelle A.},
title = {Creating an Immersive Broadcast Experience},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500208},
doi = {10.1145/500141.500208},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {455–456},
numpages = {2},
keywords = {immersive broadcast experience, tangible interaction tools, interactive TV, interactive narratives, children, design for diversity},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500209,
author = {Ayg\"{u}, Ramazan Sava\c{s}},
title = {An Integrated Framework for Interactive Multimedia Presentations in Distributed Multimedia Systems},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500209},
doi = {10.1145/500141.500209},
abstract = {An interactive multimedia presentation in a distributed multimedia system requires synchronization of media streams, preprocessing media for content-based retrieval and low-bandwidth transmission over network, and user interface for interacting multimedia presentations. The power of synchronization models is limited to the synchronization specifications and user interactions. We propose an event-based synchronization model that can handle time-based actions while enabling user interactions like backward and skip. For effective transmission of multimedia data, the multimedia data needs to be preprocessed. The sprite generation and moving objects segmentation can reduce the required bandwidth significantly. We propose a method for multiresolution sprite which will allow reproduction of the video at different resolutions. The object segmentation will be extracted by generating a closed boundary for the object. Since the video data may also exist in a compressed format, we also propose to extract new features from the compressed video. We will consider compressed data that is generated by Discrete Cosine Transform (DCT) which has been used in MPEG-1, MPEG-2, MPEG-4 cite{MPEG-4} and H263.1. The user will be provided a high-level user interface to access the contents of the presentation. We will test this integrated framework on distance education project over the Internet.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {457–458},
numpages = {2},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500210,
author = {Lei, Zhijun},
title = {Media Transcoding for Pervasive Computing},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500210},
doi = {10.1145/500141.500210},
abstract = {The rapid development of wireless technologies and computer-embedded devices make it possible for people to use portable devices accessing multimedia information and service. In order to bring multimedia information and service to the various client devices while retaining the ability to go mobile, multimedia information must be adapted, which is referred to as media transcoding technology. In this paper, some related issues of media transcoding are discussed. Media transcoding techniques are classified from different perspectives. Then a general framework for media transcoding is proposed and explored. Video transcoding is discussed as the major research focus. Some methods in terms of video rate control, spatial resolution reduction, and heterogeneous video transcoding are explored.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {459–460},
numpages = {2},
keywords = {media transcoding, spatial resolution reduction, rate control, heterogeneous video transcoding, universal multimedia access},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500211,
author = {Cui, Yi and Nahrstedt, Klara},
title = {Supporting QoS for Ubiquitous Multimedia Service Delivery},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500211},
doi = {10.1145/500141.500211},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {461–462},
numpages = {2},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500212,
author = {Krasic, Charles and Walpole, Jonathan},
title = {Priority-Progress Streaming for Quality-Adaptive Multimedia},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500212},
doi = {10.1145/500141.500212},
abstract = {The Internet's ubiquity amply motivates us to harness it for video distribution, however, its best-effort service model is in direct conflict with video's inherent timeliness requirements. Today, the Internet is unrivaled in its rich composition, consisting of an unparalleled assortment of networks and hosts. This richness is the result of an architecture that emphasizes interoperability over predictable performance. From the lowest levels, the Internet architecture prefers the best effort service model. We feel current solutions for media-streaming have yet to adequately address this conflict between timeliness and best-effort service.We propose that streaming-media solutions targetted at the Internet must fully embrace the notion of graceful degradation, they must be architected with the expectation that they operate within a continuum of service levels, adjusting quality-resource trade-offs as necessary to achieve timeliness requirements. In the context of the Internet, the continuum of service levels spans across a number oftime scales, ranging from sub-second timescales to timescales as long as months and years. We say sub-second timescales in relation to short-term dynamics such as network traffic and host workloads, while timescales of months and years relate to the continuous deployment of improving network, compute and storage infrastructure.We support our thesis with a proposal for a streaming model which we claim is simple enough to use end-to-end, yet expressive enough to tame the conflict between real-time and best-effort personalities of Internet streaming. The model is called Priority-Progress streaming. In this proposal, we will describe the main features of Priority-Progress streaming, which we have been implemented in a software-based streaming video system, called the Quasar pipeline.Our work is primarily concerned with the class of streaming applications. To prevent confusion, we now clarify the important distinction between streaming and other forms of distribution, namely download. For a video, we assume download is defined so that the transfer of the video must complete before the video is viewed. Transfer and viewing are temporally sequential. With this definition, it is a simple matter to employ Quality-adaptive video. One algorithm would be to deliver the entire video in the order from low to high quality components. The user may terminate the download early, and the incomplete video will automatically have as high quality as was possible. Thus, Quality-adaptive download can be implemented in an entirely best-effort, time-insensitive, fashion. On the other hand, we assume streaming means that the user views the video at the same time that the transfer occurs. Transfer and viewing are concurrent. There are timeliness requirements inherent in this definition, which can only be reconciled with best-effort delivery through a time-sensitive adaptive approach.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {463–464},
numpages = {2},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500214,
author = {Arbeeny, Steele and Silver, Deborah},
title = {Spatial Navigation of Media Streams},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500214},
doi = {10.1145/500141.500214},
abstract = {Interactive multimedia walkthrough applications are useful tools for visualizing complex areas. These environments permit navigation through a virtual space based on intuitive actions like "go forward" or "go left". The space is generally constructed using computer graphics models and enhanced with video, still images, and sound. While video is usually incorporated into these models, it is played as taken, and generally as a dependent media, i.e. the navigation controls do not control the video even if the video is a "real" walkthrough of the virtual space. Integrating the real-world media and the computer graphics model by registering both within a common virtual reality framework would allow navigation in the computer graphics model to control video of the corresponding location in the real world and vice versa. This would cause the computer graphics model to be regenerated based on the camera position in the real world video. Additionally, by registering into the common framework, new media data of any type can be added into the presentation. This paper presents a multimedia data structure capable of supporting these operations. A prototypical mobile video capture device is discussed that can record the required video media and process it for inclusion in the framework described.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {467–470},
numpages = {4},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500215,
author = {Ayg\"{u}n, Ramazan Sava\c{s} and Zhang, Aidong},
title = {Middle-Tier for Multimedia Synchronization},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500215},
doi = {10.1145/500141.500215},
abstract = {The gap between the synchronization specification and the synchronization model limits user interactions for a multimedia presentation. The middle-tier for multimedia synchronization handles the synchronization rules that are directly extracted from the specification. In addition to these rules, the middle-tier also manages implicit synchronization rules which are not specified but can be extracted from other rules. The synchronization rules generated by the middle-tier assists the synchronization model to provide user interactions while keeping the synchronization specification minimal. We give examples of how these rules are generated from SMIL expressions.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {471–474},
numpages = {4},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500216,
author = {Oria, Vincent and \"{O}zsu, M. Tamer and Lin, Shu and Iglinski, Paul J.},
title = {Similarity Queries in the DISIMA Image DBMS},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500216},
doi = {10.1145/500141.500216},
abstract = {In the DISIMA system, an image is composed of salient objects that are regions of interest in the image. A salient object has some syntactic properties (shape, color, textures) on which some similarity searches are defined. In addition, a global multi-precision image similarity based on multi-scale color histograms allows similarity queries on images and sub-images.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {475–478},
numpages = {4},
keywords = {similarity searches, image database},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500217,
author = {Lu, Cheng and Drew, Mark S. and Au, James},
title = {Classification of Summarized Videos Using Hidden Markov Models on Compressed Chromaticity Signatures},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500217},
doi = {10.1145/500141.500217},
abstract = {Tools for efficiently summarizing and classifying video sequences are indispensable to assist in the synthesis and analysis of digital video. In this paper, we present a method for effective classification of different types of videos that uses the output of a concise video summarization technique that forms a list of keyframes. The summarization is produced by a method recently presented, in which we generate a universal basis on which to project a video frame feature that effectively reduces any video to the same lighting conditions. Each frame is represented by a compressed chromaticity signature. A multi-stage hierarchical clustering method efficiently summarizes any video. Here, we classify TV programs using a trained hidden Markov model, using the keyframe plus temporal features generated in the summaries.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {479–482},
numpages = {4},
keywords = {compressed chromaticity signature, video type classification, temporal feature, hidden Markov models},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500218,
author = {Christel, Michael G. and Huang, Chang},
title = {SVG for Navigating Digital News Video},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500218},
doi = {10.1145/500141.500218},
abstract = {Scalable Vector Graphics (SVG) is a language for describing two-dimensional graphics in XML, specifically vector graphic shapes, images, and text. SVG is a new World Wide Web Consortium (W3C) Candidate Recommendation as of November 2000, and this paper describes how SVG provides an ideal framework for presenting manipulable, interactive summarizations into a multimedia information repository. Specifically, we present VIBE and map SVG interfaces into a digital news video library for delivery through web browsers. Pan-and-zoom visualizations of video through SVG are discussed.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {483–485},
numpages = {3},
keywords = {digital video library, SVG, surrogate},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500219,
author = {Chun, Junchul and Stockman, George},
title = {Subband Image Segmentation Using VQ for Content-Based Image Retrieval},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500219},
doi = {10.1145/500141.500219},
abstract = {Retrieving images from a large image dataset using image content as a key is an important issue. In this paper, we present a new content-based image retrieval approach using a Wavelet transform and subband image segmentation. For the image retrieval, we first decompose the image using a Wavelet transform and adopt vector a quantization(VQ) algorithm to perform automatic segmentation based on image features such as color and texture. The wavelet transform decomposes the image into 4 subbands(LL,LH,HL,HH). Only the LL component is further decomposed until the desired depth is reached. The image segmentation is performed using the HIS color and texture features of the low pass sub-band component image. The VQ provides a transformation from the raw pixel data to a small group of homogeneous classes which are coherent in color and texture space. For managing a large image dataset, image compression is usually considered. In that sense, the segmentation of a compressed image or sub-band image is more efficient compared with using an uncompressed image since the compressed image preserves the information needed for the image segmentation task. An important aspect of the system is that using a sub-band image of the Wavelet transform can reduce the size and noise of the image. Thus, we can subsequently reduce the computational burden for the image segmentation. The experimental results of the proposed image retrieval system confirm the feasibility of our approach in retrieving accuracy and in lowering computational cost compared to using the original image.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {486–488},
numpages = {3},
keywords = {content-based retrieval, image segmentation, vector quantization, wavelet transform},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500220,
author = {Fullea, Eduardo and Mart"nez, Jos\'{e} M.},
title = {Robust Digital Image Watermarking Using DWT, DFT and Quality Based Average},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500220},
doi = {10.1145/500141.500220},
abstract = {This paper presents a digital image watermarking system that complements a wavelet based insertion module, with a resynchronization module, and a method for selecting the watermark using an estimated-quality-based average. The proposed system has been tested with attacks performed by Stirmark, obtaining results of robustness over 90%.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {489–491},
numpages = {3},
keywords = {stirmark, DWT, estimated quality based average, watermark, DFT},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500221,
author = {Shojania, Hassan and Li, Baochun},
title = {Experiences with MPEG-4 Multimedia Streaming},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500221},
doi = {10.1145/500141.500221},
abstract = {With the advent of next-generation multimedia technologies such as very-low bit rate MPEG-4 codec, multimedia streaming of high-quality video and audio has become a near-term reality. The high compression ratio and error resilience offered by the MPEG-4 standard promise near-term popularity for rich contents and exceptional quality to consumers over affordable Internet connections, such as xDSL, cable modem and 3G wireless networks. Audio and video streaming applications are at the center of such scenarios; and Quality-of-Service (QoS) support in such applications is critical to their widespread acceptance.To the best of our knowledge, there has been no existing open-source MPEG-4 multimedia streaming applications in the academic community, which leads to the lack of research results using MPEG-4 streaming, especially with respect to Quality-of-Service support. In this work, we have implemented an open-source MPEG-4 multimedia streaming testbed in IP-based networks. In this paper, we show our experiences and lessons learned with such a testbed. First, we describe the algorithms and solutions used in our implemention testbed, emphasizing several critical issues. Second, through extensive experiments, we demonstrate measurements of bandwidth requirements and data loss for streaming a set of multimedia samples with different bit rates over UDP, which is ubiquitously available in the TCP/IP protocol stack on all consumer operating systems. Finally, future work for further improvements is also discussed.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {492–494},
numpages = {3},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500222,
author = {Hong, Pengyu and Wen, Zhen and Huang, Thomas},
title = {An Integrated Framework for Face Modeling, Facial Motion Analysis and Synthesis},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500222},
doi = {10.1145/500141.500222},
abstract = {This paper presents an integrated framework for face modeling, facial motion analysis and synthesis. This framework systematically addresses three closely related research issues: (1) selecting a quantitative visual representation for face modeling and face animation; (2) automatic facial motion analysis based on the same visual representation; and (3) speech to facial coarticulation modeling. The framework provides a guideline for methodically building a face modeling and animation system. The systematicness of the framework is reflected by the links among its components, whose details are presented. Based on this framework, we improved a face modeling and animation system, called the iFACE system [4]. The final system provides functionalities for customizing a generic face model for an individual, text driven face animation, off-line speech driven face animation, and real-time speech driven face animation.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {495–498},
numpages = {4},
keywords = {facial motion analysis, speech to facial coarticulation modeling, face modeling, iFACE, face animation},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500223,
author = {Lin, Hsin-Chih and Chiu, Chih-Yi and Yang, Shi-Nine},
title = {LinStar Texture: A Fuzzy Logic CBIR System for Textures},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500223},
doi = {10.1145/500141.500223},
abstract = {In this study, we propose a fuzzy logic CBIR system for textures, named LinStar Texture (i.e., Linguistic Star for Textures). The proposed system consists of two major phases, including database creation and query comparison. In the database creation phase, six Tamura features are extracted to describe each texture image in the database. A term set on each Tamura feature is generated through a fuzzy clustering algorithm so that degrees of appearance for the feature can be interpreted as five linguistic terms. In the query comparison phase, a user can pose textual descriptions or visual examples to find the desired textures. Furthermore, the query can be expressed as a logic composition of linguistic terms or Tamura feature values. The final similarity is then computed by aggregating each individual similarity through min-max composition rules. Experimental results reveal the proposed system is indeed effective. The retrieved images are perceptually satisfactory. The retrieval time is very fast.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {499–501},
numpages = {3},
keywords = {content-based image retrieval (CBIR), semantic gap, term set, linguistic term, tamura feature, fuzzy clustering},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500224,
author = {Hu, Jianying and Zhong, Jialin and Bagga, Amit},
title = {Combined-Media Video Tracking for Summarization},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500224},
doi = {10.1145/500141.500224},
abstract = {Video summarization is receiving increasing attention due to the large amount of video content made available on the Internet. In this paper we present a novel idea to track video from multiple sources for video summarization. An algorithm that takes advantage of both video and close caption text information for video scene clustering is described. Experimental results are given followed by discussion on future directions.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {502–505},
numpages = {4},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500225,
author = {Dixon, John and Owen, Charles B.},
title = {Fast Client-Server Video Summarization for Continuous Capture},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500225},
doi = {10.1145/500141.500225},
abstract = {This paper describes a keyframe summarization method for client-server applications. This technique is designed for applications where a camera is collecting content on a continuous basis that must be transmitted in a summarized form to a remote database server over wireless network. The system combines three keyframe selection methods including a novel fast motion-based selection method, keyframe pooling and clustering for bandwidth control, and network bandwidth estimation.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {506–508},
numpages = {3},
keywords = {keyframe selection, video summarization},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500226,
author = {Vu, Khanh and Hua, Kien A. and Oh, JungHwan},
title = {Indexing for Efficient Processing of Noise-Free Queries},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500226},
doi = {10.1145/500141.500226},
abstract = {A typical query image contains not only relevant objects, but also irrelevant image areas. The latter, referred to as noise, has limited the effectiveness of existing image retrieval systems. In this paper, we propose a technique that allows users to define arbitrary-shaped queries out of example images. We present a new similarity model, and introduce an indexing technique for this new environment. Our query model is more expressive than the standard query-by-example. The user can draw a contour around a number of objects to specify spatial (relative distance) and scaling (relative size) constraints among them, or use separate contours to disassociate these objects. Our experimental results confirm that traditional approaches, such as Local Color Histogram and Correlogram, suffer from noisy queries. In contrast, our method can leverage arbitrary-shaped queries to offer significantly better performance. This is achieved using only a fraction of the storage overhead required by the other two techniques.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {509–511},
numpages = {3},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500227,
author = {Tan, Kun and Ribier, Richard and Liou, Shih-Ping},
title = {Content-Sensitive Video Streaming over Low Bitrate and Lossy Wireless Network},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500227},
doi = {10.1145/500141.500227},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {512–515},
numpages = {4},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500228,
author = {Na, Kwan-Sang and Baik, Doo-Kwon and Kim, Pan-Koo},
title = {A Practical Approach for Modeling the Quality of Multimedia Data},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500228},
doi = {10.1145/500141.500228},
abstract = {One of the most important objectives of data engineering is to deliver high quality data to users. In this paper, we (1) discuss the definition, problems and improvements methods of data qwuality, and (2) propose a modeling methodology for improving the multimedia data quality. And then, we introduce the method for improving the quality of semantic data using the proposed methodology. In this example, we propose to measure and remove the data ambiguities for improving the data quality.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {516–518},
numpages = {3},
keywords = {quality metric, semantic/syntactic quality modeling, data quality, conceptual modeling},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500229,
author = {Wenyin, Liu and Chen, Zheng and Lin, Fan and Yang, Rui and Li, Mingjing and Zhang, Hongjiang},
title = {Ubiquitous Media Agents for Managing Personal Multimedia Files},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500229},
doi = {10.1145/500141.500229},
abstract = {A novel idea of ubiquitous media agents is presented. Media agents are intelligent systems that are able to automatically collect and build personalized semantic indices of multimedia data on behalf of the user whenever and wherever he/she accesses/uses these multimedia data. The sources of these semantic descriptions are the textual context of the same documents that contain these multimedia data. The URLs of these multimedia data are indexed using these textual features. When the user wants to use these multimedia data once again, the media agents can also help the user find relevant multimedia data and provide proper suggestions based on the semantic indices. The media agents can also learn form the user's interaction records to refine the semantic indices and to model the user intentions and preferences. In our experiments, the media agents are effective in gathering relevant semantics for media objects and learning to provide precise suggestions when the user wants to re-use relevant media objects again.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {519–521},
numpages = {3},
keywords = {personalization, agent, multimedia information management, user adaptation, personal media management, learning},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500230,
author = {Malan, Katherine and Marsden, Gary and Blake, Edwin},
title = {Visual Query Tools for Uncertain Spatio-Temporal Data},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500230},
doi = {10.1145/500141.500230},
abstract = {Some multimedia archives contain data which have vague locations in time and space. By this we mean that, although there is some idea of when and where the entity is located, the precise information is unknown. In this paper, we present a novel approach to displaying and querying such uncertain data. We use the concepts of dynamic queries, add to this a 2D query tool for performing spatial queries and enable Boolean combinations of queries. We have implemented these ideas in a pilot system for querying African artwork. In this way, we show how it is possible for novice users to easily query large multimedia archives with complex uncertain attributes.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {522–524},
numpages = {3},
keywords = {cultural archive, uncertain data, graphical user interfaces, visual languages, query preview, dynamic queries},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500231,
author = {Moncrieff, Simon and Dorai, Chitra and Venkatesh, Svetha},
title = {Affect Computing in Film through Sound Energy Dynamics},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500231},
doi = {10.1145/500141.500231},
abstract = {We develop an algorithm for the detection and classification of affective sound events underscored by specific patterns of sound energy dynamics. We relate the portrayal of these events to proposed high level affect or emotional coloring of the events. In this paper, four possible characteristic sound energy events are identified that convey well established meanings through their dynamics to portray and deliver certain affect, sentiment related to the horror film genre. Our algorithm is developed with the ultimate aim of automatically structuring sections of films that contain distinct shades of emotion related to horror themes for nonlinear media access and navigation. An average of 82% of the energy events, obtained from the analysis of the audio tracks of sections of four sample films corresponded correctly to the proposed affect. While the discrimination between certain sound energy event types was low, the algotithm correctly detected 71% of the occurrences of the sound energy events within audio tracks of the films analyzed, and thus forms a useful basis for determining affective scenes characteristic of horror in movies.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {525–527},
numpages = {3},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500232,
author = {Chefa\"{\i}, Nawel and Georganas, Nicolas D. and Bochmann, Gregor V.},
title = {Preemptive Bandwidth Allocation Protocol for Multicast, Multi-Streams Environments},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500232},
doi = {10.1145/500141.500232},
abstract = {In this paper, we present a protocol that allocates resources in communication networks in order to assure specific QoS characteristics as requested by new connections. The design takes into consideration the possibility for the network allocation to adapt to application requirements.The proposed protocol uses a Bandwidth Preemptive Algorithm that permits adaptive bandwidth allocation in multicast, multi-stream environments. This design has been inspired by the one proposed by Sakate [1] where a centralized methodology is used. In our approach, we use a distributed methodology where we change the behavior of the communication service and allow the continuation of the service under more severe conditions. In other words, when there is a lack of bandwidth for a new connection, the communication service will try to find the missing bandwidth within the existent connections (or streams) when looking for a feasible path on a hop-by-hop basis, starting from the destination to an a on-tree node.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {528–530},
numpages = {3},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500233,
author = {Obeid, Mohamad and Jedynak, Bruno and Daoudi, Mohamed},
title = {Image Indexing &amp; Retrieval Using Intermediate Features},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500233},
doi = {10.1145/500141.500233},
abstract = {Visual information retrieval systems use low-level features such as color, texture and shape for image queries. Users usually have a more abstract notion of what will satisfy them. Using low-level features to correspond to high-level abstractions is one aspect of the semantic gap.In this paper, we introduce intermediate features. These are low-level "semantic features" and "high level image" features. That is, in one hand, they can be arranged to produce high level concept and in another hand, they can be learned from a small annotated database. These features can then be used in an image retrieval system.We report experiments where intermediate features are textures. These are learned from a small annotated database. The resulting indexing procedure is then demonstrated to be superior to a standard color histrogram indexing.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {531–533},
numpages = {3},
keywords = {intermediate feature, images retrieval, semantic},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500234,
author = {Olbrich, Stephan and Pralle, Helmut},
title = {A Tele-Immersive, Virtual Laboratory Approach Based on Real-Time Streaming of 3D Scene Sequences},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500234},
doi = {10.1145/500141.500234},
abstract = {In this paper we describe a distributed system approach for three-dimensional exploration in the context of high-performance computing, which supports postprocessing, online-visualization and interactive steering scenarios. Our processing chain consists of three instances (data source, streaming server, viewer), which can be distributed in high-performance networks and operated either in a full pipeline (on-the-fly 3D visualization, computational steering) or in asynchronously running pairs (visualization of prepared 3D scenes). It takes advantage of parallel data extraction, efficient 3D representation, and streaming protocols over TCP/IP.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {534–537},
numpages = {4},
keywords = {parallel visualization, gigabit networking, virtual re"ality, streaming},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500235,
author = {Zhu, Qiang and Chen, Jiashi},
title = {A New Approach for Rotated Face Detection},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500235},
doi = {10.1145/500141.500235},
abstract = {Human face detection has always been an important problem for face recognition and face tracking. Though considerable attempts have been made to detect and localize faces, these approaches have made assumptions that restrict their extension to more general cases. In this paper we design a novel method to detect a rotated face on the basis of image edge information. Considering the efficiency problem, we propose two key techniques in our approach: first, three points based RHT is applied to detect an ellipse; moreover, we speedup the template matching procedure through calculating the orientation histogram distribution and locating the symmetry axis of a rotated face. In the end, we will validate our idea by several experiment results.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {537–539},
numpages = {3},
keywords = {histogram, rotated face, face detection, hough transform, symmetry axis, edge detection},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500236,
author = {Sgouros, Nikitas M. and Kousidou, Sophia},
title = {Authoring and Execution Environments for Multimedia Applications Featuring Robotic Actors},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500236},
doi = {10.1145/500141.500236},
abstract = {Recent advances in multimedia systems and robotics encourage the development of novel types of applications that associate the use of various multimedia objects with the behavior of multiple robotic actors. Unfortunately, the development of such systems is hampered by the lack of appropriate authoring and execution environments. This paper seeks to fill this gap by describing CHOROS, a Java-based authoring environment for visually planning the behavior of multiple robotic actors and linking it with the rendering state of various multimedia objects. This is accomplished with an augmented reality interface in which the author draws the robot paths and associates them with timelines describing the use of various multimedia objects. During the actual execution of the application the environment automatically tracks and adjusts the behavior of the robotic actors in order to maintain its association with the rendering state of the multimedia objects.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {540–542},
numpages = {3},
keywords = {end-system and applications, authoring environments, multimedia tools, augmented reality and robotics},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500237,
author = {Chen, Yixin and Wang, James Z. and Li, Jia},
title = {FIRM: Fuzzily Integrated Region Matching for Content-Based Image Retrieval},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500237},
doi = {10.1145/500141.500237},
abstract = {We propose FIRM (Fuzzily Integrated Region Matching), an efficient and robust similarity measure for region-based image retrieval. Each image in our retrieval system is represented by a set of regions that are characterized by fuzzy sets. The FIRM measure, representing the overall similarity between two images, is defined as the similarity between two families of fuzzy sets. Compared with similarity measures based on individual regions and on all regions with crisp feature representations, our approach greatly reduces the influence of inaccurate segmentation. Experimental results based on a database of about 200,000 general-purpose images demonstrate improved accuracy, robustness, and high speed.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {543–545},
numpages = {3},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500238,
author = {Gonno, Yoshihisa and Nishio, Fumihiko and Tsunoda, Tomohiro and Yamagishi, Yasuaki},
title = {Integrated Broadband Environment for Personalized TV Experience (IBEX): Implementation Study and Practice},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500238},
doi = {10.1145/500141.500238},
abstract = {This is a continuing work on the IBEX, that is Integrated Broadband Environment for Personalized TV Experience. In this paper, we describe our implementation study of the IBEX as a TV-Anytime service platform. We also describe potential IBEX applications on the basis of TV-Anytime specifications. The Adaptive Content Guide (ACG) is expected to provide consumers with adaptive access to favorite contents and metadata customized not only for user preferences but also terminal capabilities. We also found current TV-Anytime specification lacks ability of describing terminal capabilities, which is required for universal access to the ACG.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {546–548},
numpages = {3},
keywords = {electronic program guide (EPG), MPEG-7, adaptive content guide (ACG), PDA, universal accessibility, metadata, mobile phone, TV-anytime},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500239,
author = {Won, Youjip and Cho, Kyeongsun and Park, Seung-Min},
title = {Mitigating Impact of Starting New Session in Zoned Disk},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500239},
doi = {10.1145/500141.500239},
abstract = {Cycle based disk scheduling approach is widely used to satisfy the timing constraints of the multimedia data retrieval. When new service request arrives at the server, the length of cycle needs to be extended to accommodate the new service session. Under legacy cycle based disk scheduling paradigm, the amount of blocks fetched for a session in each cycle becomes insufficient when the cycle is extended to accommodate a new stream and subsequently some of the ongoing sessions suffer from jitter. In this article, we present a technique called "prebuffering" which makes the streaming server resilient to the cycle extension. Our model is based upon the zone based disk.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {549–551},
numpages = {3},
keywords = {multimedia, streaming, jitter, zoned disk, disk scheduling},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500240,
author = {Wu, Zhengping and Chen, Chun},
title = {A New Foreground Extraction Scheme for Video Streams},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500240},
doi = {10.1145/500141.500240},
abstract = {The MPEG-4 video coding standard consists of object based coding schemes for multimedia and enables content based functionalities. Video objects in still pictures or video sequences should be first identified before the encoding process starts. An algorithm based on information fusion, which can be used for the extraction of foreground objects in video streams in real time is proposed in this paper. The method efficiently integrates image and motion information of video streams. The thresholding technique operated in the HSV space provides a better use of the color information than that in the traditional RGB space. Using enhanced boundary extracted from the motion region for contour adaptation offers an original method to refine the contour.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {552–554},
numpages = {3},
keywords = {color space, contour adaptation, information fusion, video segmentation},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500241,
author = {Zhou, Michelle X. and Pan, Shimei},
title = {Automated Authoring of Coherent Multimedia Discourse in Conversation Systems},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500241},
doi = {10.1145/500141.500241},
abstract = {We are building a full-fledged multimedia conversation framework called Responsive Information Architect (RIA), using a combination of AI and multimedia techniques. Here we describe RIA's capability of automated authoring of a coherent multimedia discourse, which is used by RIA to express itself when conversing with a user. Specifically, we focus on explaining three unique features of our automated authoring approach: automated authoring of multimedia interaction acts, dynamic insertion of multimedia punctuation acts, and systematic design of cross-media acts.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {555–558},
numpages = {4},
keywords = {automated generation of multimedia discourse, spoken language generation, multimedia authoring, multimedia conversation/dialogue, graphics generation},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500242,
author = {Bondy, Michel D. and Georganas, Nicolas D. and Petriu, Emil M. and Petriu, Dorina C. and Cordea, Marius D. and Whalen, Thomas E.},
title = {Model-Based Face and Lip Animation for Interactive Virtual Reality Applications},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500242},
doi = {10.1145/500141.500242},
abstract = {In this paper, we describe an experimental performance-driven animation system for an avatar face using model-based video coding and audio-track driven lip animation.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {559–563},
numpages = {5},
keywords = {and compression, multi-modal interaction and integration, voice-image synchronization, audio/image/video processing},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500243,
author = {Dimitrova, Nevenka and Jasinschi, Radu and Agnihotri, Lalitha and Zimmerman, John and McGee, Thomas and Li, Dongge},
title = {Personalizing Video Recorders Using Multimedia Processing and Integration},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500243},
doi = {10.1145/500141.500243},
abstract = {Current personal Vido recorders make it very easy for consumers to record whole TV programs. Our research however, focuses on personalizing TV at a sub-program level. We use a traditional Content-Based Information Retrieval system architecture consisting of archiving and retrieval modules. The archiving module employs a three-layered, multimodal integration framework to segment, analyze, characterize, and classify segments. The retrieval module relies on users personal preferences to deliver both full programs and video segments of interest. We tested retrieval concepts with real users and discovered that they see more value in segmenting non-narrative programs (e.g. news) than narrative programs (e.g. movies). We benchmarked individual algorithms and segment classification for celebrity and financial segments as instances of non-narrative content. For celebrity segments we obtained a total precision of 94.1% and recall of 85.7%, and for financial segments a total precision of 81.1% and a recall of 86.9%.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {564–567},
numpages = {4},
keywords = {content-based video retrieval, bayesian networks, multimodal integration},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500244,
author = {Xu, Changsheng and Zhu, Yongwei and Feng, David Dagan},
title = {Digital Audio Watermarking Based-on Multiple-Bit Hopping and Human Auditory System},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500244},
doi = {10.1145/500141.500244},
abstract = {A novel content-adaptive audio watermarking technique is proposed. To optimally balance in-audibility and robustness when embedding and extracting watermarks, the embedding scheme is high related to audio content by making use of the properties of human auditory system and multiple-bit hopping technique. The experimental results in robustness are provided to support all the novel features in our watermarking scheme.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {568–571},
numpages = {4},
keywords = {audio, human auditory system, digital watermarking},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500245,
author = {Khan, Javed I. and Guo, Zhong and Oh, Wansik},
title = {Motion Based Object Tracking in MPEG-2 Stream for Perceptual Region Discriminating Rate Transcoding},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500245},
doi = {10.1145/500141.500245},
abstract = {Object based bit allocation can result in significant improvement in the perceptual quality of relatively low bit-rate video. In this paper we describe a novel content aware video transcoding technique that can accept high-level description of video objects and extract them from incoming video stream and use it for perceptual encoding based extreme video downscaling.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {572–576},
numpages = {5},
keywords = {content aware streaming, video transcoding, perceptual encoding},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500246,
author = {Carpenter, Charles S. and Seales, W. Brent and Jaynes, Christopher and Stevens, Randall},
title = {Automated Basis-View and Match-Point Selection for the ArchVision RPC Image-Based Model},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500246},
doi = {10.1145/500141.500246},
abstract = {The Rich Photo-Realistic Content (RPC) image-based model defined and used by ArchVision represents a photo-realistic scene as an ordered set of images. A desired view from the represented viewing directions can quickly be extracted for rendering and display. The benefit of the RPC is its photo-realistic quality. One weakness, however, is that there is no support for view interpolation between closely related basis views. This paper presents results from a tool for creating a new RPC-like image-based model, which detects and discards captured views that are determined to be faithfully and automatically interpolated from the remaining images in the RPC. We exploit the geometric constraints of the acquisition system and provide an automated matching algorithm, and interpolation scheme, and an error metric displayed in a graphical tool for monitoring the quality impact of discarding particular frames.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {577–581},
numpages = {5},
keywords = {RPC image format, view morphing, image-based rendering, photo-realism, CAD},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500247,
author = {Park, Y. C. and Kim, P. K. and Golshani, F. and Panchanathan, S.},
title = {Technique for Eliminating Irrelevant Terms in Term Rewriting for Annotated Media Retrieval},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500247},
doi = {10.1145/500141.500247},
abstract = {In this paper, we present an efficient term rewriting technique that computes a degree of term to domain relevance. The proposed method resolves the problems in ontology integrated concept search. Those problems are (i) Pre-defined concept classes in ontology are not relevant to users (no proper concept class for a target annotation has not found). (ii) Too many similar concept classes are provided to a user therefore, a user may fail to choose a correct semantic class for a target annotation (ordinary users are not an expert in concept classification). The method uses sense disambiguation task for finding relevant terms for a given domain. Sense disambiguation requires term-to-term similarity measurement and term frequency measurement. For fair modeling of not observed term frequencies, discounting and redistribution model is applied. The proposed method is a compliment to our previous work presented in [13][14]. Robustness of our method is demonstrated through human judgment test that shows our method allows prediction of precise term list (overall 75% of correct prediction) that are relevant to a given domain.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {582–584},
numpages = {3},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500248,
author = {Manzolli, J\^{o}natas and Maia, Adolfo and Fornari, Jose and Damiani, Furio},
title = {The Evolutionary Sound Synthesis Method},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500248},
doi = {10.1145/500141.500248},
abstract = {A mathematical model for interactive sound synthesis based on the application of Genetic Algorithms (GA) is presented. The Evolutionary Sound Synthesis Method (ESSynth) generates sequences of waveform variants by the application of genetic operators on an initial population of waveforms. We describe how the waveforms can be treated as genetic code, the fitness evaluation methodology and how genetic operations such as crossover and mutation are used to produce generations of waveforms. Finally, we discuss the results evaluating the generated sounds.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {585–587},
numpages = {3},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500250,
author = {Shih, Timothy K.},
title = {Software Systems for Virtual University Operations},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500250},
doi = {10.1145/500141.500250},
abstract = {Distance Learning system is one of the most important applications of multimedia and communication technologies. In the past few years, Tamkang University has a special interesting group of research faculties from computer engineering, education, and literature departments. We follow the operation procedures of a virtual university, and developed Distance Learning system is one of the most important applications of multimedia and communication technologies. In a set of tools to be used by students, course designers, and instructors.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {591–592},
numpages = {2},
keywords = {assessment, distance education, web-based tutorial, distance Learning, virtual university},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500251,
author = {Hilt, Volker and Mauve, Martin and Vogel, J\"{u}rgen and Effelsberg, Wolfgang},
title = {Interactive Media on Demand: Generic Recording and Replay of Interactive Media Streams},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500251},
doi = {10.1145/500141.500251},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {593–594},
numpages = {2},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500252,
author = {van Setten, Mark and Oltmans, Erik},
title = {Demonstration of a Distributed MPEG-7 Video Search and Retrieval Application in the Educational Domain},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500252},
doi = {10.1145/500141.500252},
abstract = {This demonstration shows the end-user application of the Video-over-IP (VIP) system. This system encompasses a whole chain of processes for digital video databases, ranging from distributed content production to acquire MPEG-7 metadata (including speech-and video analysis) to the deployment and access to the video database by end users. This system has been developed as an application for the next generation Internet. The end-user application provides distributed search engines, tools to browse and analyze videos, and playlist functionalities. The tools have been developed using a user-centered design approach, to assure usability for the students and teachers in the pilot project.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {595–596},
numpages = {2},
keywords = {search and retrieval, MPEG-7, next generation internet application, video databases, distributed},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500253,
author = {Li, Jiang and Yu, Keman and Chen, Gang and Wang, Yong and Zhou, Hanning and Xu, Jizheng and Ng, King To and Wang, Kaibo and Wang, Lijie and Shum, Heung-Yeung},
title = {Portrait Video Phone},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500253},
doi = {10.1145/500141.500253},
abstract = {As the Internet and wirless networks are developed rapidly, the demand of communicating anywhere, anytime on any device emerges. However, most of the current wireless networks still work in low bandwidths, and mobile devices still suffer from weak computational power, short battery lifetime and limited display capability. We developed portrait video phone systems that can run on Pcs and Pocket Pcs at very low bit rates through the Internet. The core technology that portrait video phones employ is the so-called portrait video (or bi-level video) codec. Portrait video codec first converts a full-color video into a black/white image sequence and then compresses it into a black/white portrait-like video. Portrait video processes clearer shape, smoother motion, shorter initial latency, and cheaper computational cost than MPEG2, MPEG4 and H.263 for low bandwidths. Typically the portrait video phone provides QCIF-size video with a frame rate of 5-15 fps for a 9.6 Kbps video bandwidth. The portrait video is so small that it can even be transmitted through an HTTP proxy as text. Experiments show that the portrait video phones work well on ordinary GSM wireless telecommunication networks.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {597–598},
numpages = {2},
keywords = {video broadcast and communication, MPEG, bi-level video, video coding, portrait video, JBIG},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500254,
author = {Kosugi, Naoko and Nishimura, Go and Teramoto, Junji and Mii, Kazuyoshi and Onizuka, Makoto and Kon'ya, Seiichi and Kojima, Akira and Kataoka, Ryoji and Honishi, Takashi and Kushima, Kazuhiko},
title = {Content-Based Retrieval Applications on a Common Database Management System},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500254},
doi = {10.1145/500141.500254},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {599–600},
numpages = {2},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500255,
author = {Chen, Shu-Ching and Shyu, Mei-Ling and Jin, Xia and Chen, Qiong and Zhang, Chengcui and Strickrott, Jeff},
title = {A Flexible Image Retrieval and Multimedia Presentation Management System for Multimedia Databases},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500255},
doi = {10.1145/500141.500255},
abstract = {In today's fast-growing information age, multimedia data is becoming more and more common in daily applications, however this data is nearly useless if there is no computer-aided browsing, searching, and retrieving mechanism to obtain the desired contents. In this demonstration, we present a multimedia query and presentation management system for multimedia databases. It uses an unsupervised segmentation method for image and video feature extraction. A presentation design interface systems is provided that allows query results to be used to create multimedia presentations.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {601–602},
numpages = {2},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500256,
author = {Emond, Bruno and Brooks, Martin and Smith, Arnold},
title = {A Broadband Web-Based Application for Video Sharing and Annotation},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500256},
doi = {10.1145/500141.500256},
abstract = {This demonstration reports on the current stage of development of a web-based environment to support video sharing and annotation. The initial requirements and their implementation are briefly presented. The application is aimed at supporting the professional development of teachers with a multimedia application over a broadband network. However, work with teachers has pointed us to new requirements, differentiating VSA from prrevious work. Continued work with teachers will lead to further evolution of VSA.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {603–604},
numpages = {2},
keywords = {video annotation, broadband networks, video sharing},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500257,
author = {Shen, Xiaojun and Nourian, Saeid and Hertanto, Isabelle and Georganas, Nicolas},
title = {VCOM: Virtual Commerce in a Collaborative 3D World},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500257},
doi = {10.1145/500141.500257},
abstract = {Existing electronic commerce applications only provide the user with a relatively simple browser-based interface to access products. Buyers, however, are not provided with the same shopping experience, as they would have in an actual store or shopping mall. With the creation of a virtual shopping mall, simulations of most of the actual shopping environments and user interactions can be achieved. The virtual mall brings together the services and inventories of various vendors. Users can either navigate through the vendors, adding items into a virtual shopping cart, or perform intelligent searches through "user and vendor agents". The electronic mall prototype also allows the user to communicate with an "intelligent assistant" (IA) using simple voice commands. This assistant interacts with the shopper using voice synthesis and helps him or her use the interface to navigate efficiently in the mall. Real-time interactions among entities in the virtual environment are implemented over the Run Time Infrastructure of the High Level Architecture (RTI/HLA), an OMG and IEEE standard for distributed simulations and modeling developed by the US Department of Defense.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {605–606},
numpages = {2},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500258,
author = {de Oliveira, Jauvane C. and Malric, Fran\c{c}ois and Yang, Dongsheng and Nourian, Saeid and Georganas, Nicolas D.},
title = {Java Multimedia Telecollaboration},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500258},
doi = {10.1145/500141.500258},
abstract = {Many critics of the Java language have pointed performance deficiencies as a barrier to acceptable support of Collaborative Multimedia Systems. This paper presents four MCRLab products, fully written in Java that support collaboration amongst a group of users, and successfully demonstrate that Java collaboration frameworks are not only possible but also can perform at acceptable levels of quality, if designed correctly.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {607–608},
numpages = {2},
keywords = {jStreaming, JETS, java, collaboration, multimedia, CSCW, shared applets, H263, video streaming, JASBER, JASMINE},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500259,
author = {Tripathi, Avanish and Claypool, Mark},
title = {Demonstration of Improved Multimedia Streaming by Using Content-Aware Video Scaling},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500259},
doi = {10.1145/500141.500259},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {609–610},
numpages = {2},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500260,
author = {Chang, Edward and Cheng, Kwang-Ting and Lai, Wei-Cheng and Wu, Ching-Tung and Chang, Chengwei and Wu, Yi-Leh},
title = {PBIR: Perception-Based Image Retrieval-a System That Can Quickly Capture Subjective Image Query Concepts},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500260},
doi = {10.1145/500141.500260},
abstract = {We describe the Perception-Based Image Retrieval (PBIR) system that we have built on our recently developed query-concept learning algorithms, MEGA and SVMActive. We show that MEGA and SVMActive can learn a complex image-query concept in a small number of user iterations (usually three to four) on a large, multi-category, high-dimensional image database.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {611–614},
numpages = {4},
keywords = {query concept, image retrieval, support vector machines, active learning, relevance feedback},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500261,
author = {Zhang, Cha and Chen, Tsuhan},
title = {Indexing and Retrieval of 3D Models Aided by Active Learning},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500261},
doi = {10.1145/500141.500261},
abstract = {We demonstrate a system for indexing and retrieval of 3D models aided by active learning. We propose a new set of region-based features for 3D models. Each model is treated as a solid volume with a uniform density. Features such as the volume-surface ratio, the moment invariants and the Fourier transform coefficients are efficiently calculated from the mesh model directly. Comparable retrieval performance is achieved with other features such as the cord histogram, the 3D shape spectrum, etc. To further improve the performance, we incorporate hidden annotation into our system. We propose to use active learning to improve the annotation efficiency. We show that with active learning, the system can perform better than random annotation, and the retrieval result improves rapidly with the number of annotated samples. Moreover, relevance feedback is included in the system and combined with active learning, which provides better user-adoptive retrieval results.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {615–616},
numpages = {2},
keywords = {3D model retrieval, feature extraction, information retrieval, active learning, semantic distance},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500262,
author = {Khan, Javad I. and Yang, Seung Su and Gu, Qiong and Patel, Darsan and Mail, Patrick and Komogortsev, Oleg and Oh, Wansik and Guo, Zhong},
title = {Resource Adaptive Netcentric Systems: A Case Study with SONET - a Self-Organizing Network Embedded Transcoder},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500262},
doi = {10.1145/500141.500262},
abstract = {In this paper we discuss architecture for network aware adaptive systems for next generation networks. We present in the context of a novel cognizant video transcoding system, which is capable of negotiating local network state based rate and let the video propagate over extreme network with highly asymmetric link and node capacities utilizing knowlege about the network, content protocol and the content itself.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {617–620},
numpages = {4},
keywords = {active network, transcoding, adaptive video},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500263,
author = {Hosseini, Mojtaba and Georganas, Nicolas D.},
title = {Collaborative Virtual Environments for Training},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500263},
doi = {10.1145/500141.500263},
abstract = {As the cost of training individuals to learn how to use new technologies increases, the need for virtual environments that facilitate training becomes more noticeable. More specifically, the use of Collaborative Virtual Environments for training in industrial applications is of special interest. What follows is a discussion of two prototypes designed and implemented for the purpose of using Collaborative Virtual Environments in training scenarios.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {621–622},
numpages = {2},
keywords = {MPEG-4, COSMOS, CVE},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500264,
author = {Zhong, Di and Kumar, Raj and Chang, Shih-Fu},
title = {Real-Time Personalized Sports Video Filtering and Summarization},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500264},
doi = {10.1145/500141.500264},
abstract = {We demonstrate a real-time fully automated software system for filtering important events in sports video. Events represent occurrences of actions or state changes in video content. In the current prototype, we demonstrate detection of pitching in baseball and serving in tennis. For wireless video applications, we propose and apply a unique notion of content-based adaptive streaming,in which video encoding rate and media modality is dynamically varied according to the event filtering results. Our system includes an event detection module, an adaptive encoding module, and a buffer management module for adaptive streaming. We achieve the real-time performance by exploring compressed-domain techniques and multi-stage multi-resolution content-analysis processes.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {623–625},
numpages = {3},
keywords = {event detection, video filtering, MPEG-7, summarization, indexing},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500265,
author = {Boll, S. and Klas, W. and Menth, M. and Heinlein, C.},
title = {MPEG-L/MRP: Implementing Adaptive Streaming of MPEG Videos for Interactive Internet Applications},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500265},
doi = {10.1145/500141.500265},
abstract = {Existing multimedia streaming technologies offer no specific support for user interaction like jumping to bookmarks in a video, or switching to reverse play. When the users, e.g., jump to a bookmark, the player requests frames for the new presentation point from the server and resumes playing only when the data has arrived. Our solution for this problem is the client prefetching the buffering strategy, MPEG-L/MRP, that ensures that the frames which are needed for a response to a possible user interaction are already in the client's buffer, which leads to qucik and smooth reaction to user interactions. In case of variable bandwidth, our MPEG-1 streaming approach selects only a subset of all frames to be fetched from the server and supports a smooth presentation at a reduced frame rate with correct timelines.The technical demonstration shows the interactive streaming of MPEG-videos and illustrates our buffering and prefetching strategy.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {626–627},
numpages = {2},
keywords = {continuous media streaming, internet, MPEG-1 video},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500266,
author = {Lin, Ching-Yung and Chang, Shih-Fu},
title = {SARI: Self-Authentication-and-Recovery Image Watermarking System},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500266},
doi = {10.1145/500141.500266},
abstract = {In this project, we designed a novel image authentication system based on a our semi-fragile watermarking technique. The system, called SARI, can accept quantization-based lossy compression to a determined degree without any false alarm and can sensitively detect and locate malicious manipulations. It's the first system that has such capability in distinguishing malicious attacks from acceptable operations. Furthermore, the corrupted area can be approximately recovered by the information hidden in the other part of the contentimage. The amount of information embedded in our SARI system has nearly reached the theoretical maximum zero-error information hiding capacity of digital images. The software prototype includes two parts - the watermark embedder that's freely distributed and the authenticator that can be deployed online as a third-party service or used in the recipient side.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {628–629},
numpages = {2},
keywords = {authentication, multimedia security, recovery, watermarking, information hiding},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500267,
author = {Benitez, Ana B. and Change, Shih-Fu and Smith, John R.},
title = {IMKA: A Multimedia Organization System Combining Perceptual and Semantic Knowledge},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500267},
doi = {10.1145/500141.500267},
abstract = {In the demo, we present the IMKA system, which implements the innovative approach of integrating perceptual information such as low-level features and images, and symbolic information such as words to represent the knowlege associated with a large multimedia collection for multimedia organization and retrieval. The IMKA system utilizes the unique MediaNet framework, which greatly extends existing knowlege representation tools in the text domain (e.g., semantic networks and WordNet) and the multimedia domain (e.g. Multimedia Thesaurus) by combining perceptual and semantic concepts in the same network and by supporting perceptual and semantic relationships among concepts exemplified by different media. It also brings the level of multimedia retrieval closer to users' needs by translating low-level feature queries to high-level semantic queries and vice versa. We will demonstrate the process of constructing the MediaNet knowledge base and new ways of searching multimedia in the IMKA system by presenting the current implementation of the IMKA system that uses image collections from online sources.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {630–631},
numpages = {2},
keywords = {knowledge representation, MPEG-7, knowledge construction, multimedia organization and retrieval, MediaNet},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500268,
author = {Han, Richard and Lin, Ching-Yung and Smith, John R. and Tseng, Belle and Ha, Vida},
title = {CPU/Power-Constrained Mobile Devices},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500268},
doi = {10.1145/500141.500268},
abstract = {Due to the limited processing capability, memory constraints, and the power budget of mobile clients, multimedia coders and/or decoders are often difficult to implement on wireless handheld PDAs. In this Universal Tuner project, we designed and implemented a wireless video streaming system that transcodes MPEG-1/2 videos or live TV broadcasting videos to the BW or indexed color Palm OS devices. In our system, the complexity of multimedia compression and decompression algorithms is adaptively partitioned between the encoder and decoder. A mobile client would selectively disable or reenable stages of the algorithm to adapt to the device's effective processing capability. Our variable-complexity strategy of selective disabling of modules supports graceful degradation of the complexity of multimedia coding and decoding into a mobile client's low-power mode, i.e. the clock frequency of its next-generation low power CPU has been scaled down to conserve power. We modified the structure of the standard motion-compensated DCT video codecs to implement a simplified the encoder on a PC server and the decoder on a complexity-constrained PDA viewing client.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {632–633},
numpages = {2},
keywords = {PDA, video, audio, algorithms, cell phone, complexity, decompression, compression, graceful degradation, wireless, image, multimedia, mobile, partitioning, codec},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500269,
author = {Dorai, Chitra and Kermani, Parviz and Stewart, Avare},
title = {ELM-N: E-Learning Media Navigator},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500269},
doi = {10.1145/500141.500269},
abstract = {E-learning or learning via the Web is now changing the way universities and coprporations offer education and training. Rather than using conventional means for remotely distributing and delivering courses and classroom lectures, universities and enterprises are moving towards Web-based academic and training offerings. While content acquisition and distribution can be automated in a systematic fashion, research challenges remain in the area of personalized content delivery, access, and augmented interaction. Automated content indexing and annotation for easy and efficient access and navigation of various media elements associated with the course material become key takss in flexible content delivery and use. E-Learning Media Navigator (ELM-N) from IBM Research is a system with which a user can access and interact with online courses presented as audiovisual material, along with related slides and white broad contents in a time-synchronized fashion. In this demonstration, the system capabilities and research technologies behind them will be presented.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {634–635},
numpages = {2},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500270,
author = {Jang, Jyh-Shing Roger and Lee, Hong-Ru and Chen, Jiang-Chun},
title = {Super MBox: An Efficient/Effective Content-Based Music Retrieval System},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500270},
doi = {10.1145/500141.500270},
abstract = {This demo presents an implementation of a content-based music retrieval system that can take a user's acoustic input (8-second clip of singing or humming) via a microphone and then retrieve the intended song from a database containing 13,000 candidate songs. The system, known as Super MBox, demonstrates the feasibility of real-time music retrieval with a high recognition rate, which can be used for music search engines over the Internet and/or query engines in digital music libraries or karaoke machines.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {636–637},
numpages = {2},
keywords = {content-based music retrieval, audio signal processing, melody retrieval, query by tapping, query by humming, query by singing, dynamic time warping},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.1145/500141.500271,
author = {Bradshaw, Michael K. and Wang, Bing and Sen, Subhabrata and Gao, Lixin and Kurose, Jim and Shenoy, Prashant and Towsley, Don},
title = {Periodic Broadcast and Patching Services: Implementation, Measurement, and Analysis in an Internet Streaming Video Testbed},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500271},
doi = {10.1145/500141.500271},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {638–639},
numpages = {2},
keywords = {patching, periodic broadcast, server},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

