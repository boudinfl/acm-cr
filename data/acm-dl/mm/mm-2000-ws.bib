@inproceedings{10.1145/357744.357746,
author = {Akleman, Ergun and Chen, Jianer and Meric, Burak},
title = {Web-Based Intuitive and Effective Design of Symmetric Tiles},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357746},
doi = {10.1145/357744.357746},
abstract = {This paper presents a new approach for intuitive and effective design of periodic symmetric tiles. We observe that planar graphs can effectively represent symmetric tiles and graph drawing provides an intuitive paradigm for designing symmetric tiles. Moreover, based on our theoretical work to represent hexagonal symmetry by rectangular symmetry, we are able to present all symmetric tiles as graphs embedded on a torus and based on simple modulo operations. This approach enables us to develop a simple and efficient algorithm, which has been implemented in Java. By using this software, designers, architects and artists can create interesting symmetric tiles directly on the web. We also have designed a few examples of symmetric tiles to show the effectiveness of the approach.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {1–4},
numpages = {4},
keywords = {symmetric tiles},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357747,
author = {Barrientos, Francesca},
title = {Continuous Control of Avatar Gesture},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357747},
doi = {10.1145/357744.357747},
abstract = {We are developing an application to give humans the ability to transmit nonverbal communication behaviors through an avatar: specifically gesture, the movements of the arms and hands that accompany speech when people speak face-to-face. In this application the user will have continuous control over the avatar animation. The avatar will be like a virtual puppet and the user will manipulate the avatar using not strings or rods but the controlled and skilled motions of their hand. The system tracks hand motions and then maps that motion to the joint motions of a three-dimensional articulated avatar. As part of this research we will try out different ways of tracking the user's hand. Eventually we plan to test the efficacy of this system by incorporating it into a networked virtual environment in which two or more people can interact through the virtual medium. Working with artists will enable us to design a system that is expressive and to better understand the expressive power of this system.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {5–8},
numpages = {4},
keywords = {computer-mediated communications, virtual environments, avatars},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357748,
author = {Beaumont, Betty},
title = {Decompression: A Living Laboratory in Cyberspace},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357748},
doi = {10.1145/357744.357748},
abstract = {Decompression is a proposed cyberworld created by electronically collaging multiple stories and images of the contiguous worlds of technology, science and art. The developing Decompression centers around Ocean Landmark (1980), a collaborative art work that transformed 500 tons of an industrial coal waste product into a thriving underwater environment that is fished and feeds people. Decompression will image —for the first time— Ocean Landmark in its life-sustaining form. The technologically mediated images of this underwater oasis will be dynamic images visually related to sonograms, such as images of the fetus (a highly technologically mediated dynamic image) and side-scan sonar. As Ocean Landmark is a flourishing ecosystem, Decompression will develop into Living Laboratory, a thriving information-system in cyberspace. Modeled on virtual environments in which the user's perception and spatial position affects their experience of the space, Living Laboratory will be a dynamically changing art space with an architecture that combines technologically mediated images and virtual diverse perceptual displays. The realized Ocean Landmark, a model for ecological equilibrium in the invisible underwater world, is an interdisciplinary project that for two decades has resided in the domain of the imagination. By visualizing Ocean Landmark's invisible realm, Living Laboratory will elucidate and elaborate virtual perceptual models of different ways of experiencing information within a contemporaneous context. This Living Laboratory will grow, develop and evolve into a mature and provocative discursive community.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {9–12},
numpages = {4},
keywords = {ecological art, electronic media, invisibility, virtual reality, perceptual models},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357749,
author = {Fels, Sidney},
title = {Intimacy and Embodiment: Implications for Art and Technology},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357749},
doi = {10.1145/357744.357749},
abstract = {People have aesthetic experiences when they manipulate objects skillfully. Highly skilled performance with an object requires forming a highly intimate relationship with it. Aesthetics flow from this intimacy. This paper discusses three works which bring together technology and art to illustrate the issues of intimacy and embodiment. The three works are: Iamascope, video cubism and the forklift ballet.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {13–16},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357750,
author = {Gallagher, Jean},
title = {The Merging of the Arts with Technology},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357750},
doi = {10.1145/357744.357750},
abstract = {This paper supports the author's opinion that the merging of the arts with technology has been a natural process. She argues her point by citing a brief history of multi-media installations. Additionally, she discusses her recent work as an artist.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {17–20},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357751,
author = {Nack, Frank and Lindley, Craig},
title = {Production and Maintenance Environments for Interactive Audio-Visual Stories},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357751},
doi = {10.1145/357744.357751},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {21–24},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357752,
author = {Rueb, Teri},
title = {Gathering Crowds: Mapping the Post-Human Social Body},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357752},
doi = {10.1145/357744.357752},
abstract = {As a digital artist, I seek to create experiential works that engage participants in an infinite feedback loop of interaction and discovery. My goal is to create works that exist in a perpetual state of transformation and becoming. I am interested in the rhythm and music of everyday activities such as walking and driving—compositions that have no beginning, ending, inside or outside. Such movements, when captured and visualized, provide a portrait of the social body that reflects our understanding of Self and Other.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {25–26},
numpages = {2},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357753,
author = {Senior, Andrew},
title = {Virtual Garden: A Vision-Based Multimedia Installation},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357753},
doi = {10.1145/357744.357753},
abstract = {This paper describes a project proposal for a vision-based multimedia installation, bringing together computer vision, computer graphics and other modalities to generate a virtual Japanese garden. The installation provides a platform for exploring human-computer interaction through physical objects.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {27–30},
numpages = {4},
keywords = {multimedia installation, projection displays, Japanese garden, computer graphics, computer vision},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357754,
author = {Strohecker, Carol and Slaughter, A. H. and Horvath, M. A. and Appleton, N. J.},
title = {Zyklodeon: A Software Construction Kit Modeling Cyclic Timing Patterns},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357754},
doi = {10.1145/357744.357754},
abstract = {Zyklodeon is a software construction kit in which Players create colorful Dancers and set them into motion. Dancers' appearances are inspired by Picasso's post-Cubist works, and movements are inspired by Martha Graham's emphasis on the torso as life center. The figures breathe visibly and move gracefully as they encounter other Dancers. Zyklodeon Players construct the figures and set parameters for their movements, thus experimenting with time cycles and notions of emergence in dynamic systems. Our design challenge is to make such complex relationships accessible through coordination of image and sound. We illustrate Dancers' movements as well as measures for breathing and dancing cycles. Graphical communication of key moments in the cycles is augmented by triggering of sounds that combine to form lively music.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {31–34},
numpages = {4},
keywords = {conceptual development, dance, construction kits, learning environments},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357755,
author = {Tarabella, Leonello and Bertini, Graziano},
title = {Giving Expression to Multimedia Performance},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357755},
doi = {10.1145/357744.357755},
abstract = {In this paper we describe the experience of researchers and artists involved in the activities of the “computer ART lab” (cART lab) of the italian National Council of Research (C.N.R.) in Pisa, regarding the “wireless technology” developed for controlling in real-time and giving expression to interactive multimedia performances.Due to the daily increase in computers power and electronics systems able to sense the presence, the shape, the distance and the position of objects, a new field of investigation and implementation has been started in the last few years: computer recognition of human gesture [1][2]. As a result, the human body itself can now be considered as a natural and powerful expressive “interface” to give feeling to performances based on computer generated electro-acoustic music and computer generated visual-art. Modern human computer interfaces are extremely rich, incorporating traditional interface devices such as keyboard and mouse and a wealth of advanced media types: sound, video, animated graphics. The term multi-modal is often associated with such interfaces to emphasize that the combined use of multiple modes of perception is relevant to the user's interface [3][4].The most relevant devices and systems developed at cART lab for gesture recognition to be used in interactive multimedia performances are here reported.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {35–38},
numpages = {4},
keywords = {interaction, art, gesture, multimedia performance},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357756,
author = {Tzafestas, Elpida S.},
title = {Integrating Drawing Tools with Behavioral Modeling in Digital Painting},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357756},
doi = {10.1145/357744.357756},
abstract = {Our goal is to integrate traditional artistic media that demand hand dexterity (such as drawing) with intelligent systems techniques that may both constrain and nourish this dexterity. To this end we are experimenting with special brush tools that on top of traditional drawing provide possibilities that involve information processing and behavioral modeling. In this work, we are introducing a behavioral model as a color processing feature of our brush. More precisely, we use a regulation mechanism, that has been shown elsewhere to solve a typical problem in artificial ant societies, to distribute color on the drawing canvas. Our drawing tool, called “AntBrush”, manages to create controlled color variety during drawing by regulating its own quantity of color through picking and depositing color on the canvas. Different color effects are possible by controlling the brush's parameters on line.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {39–42},
numpages = {4},
keywords = {color cooking, ant algorithms, digital painting, behavioral modeling},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357757,
author = {Christopoulos, C. A. and Ebrahimi, T. and Skodras, A. N.},
title = {JPEG2000: The New Still Picture Compression Standard},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357757},
doi = {10.1145/357744.357757},
abstract = {This paper presents an overview of the upcoming JPEG2000 still picture compression standard. JPEG2000 is not only intended to provide rate-distortion and subjective image quality performance superior to existing JPEG standard, but to also provide functionality that the current JPEG standard can either not address efficiently nor address at all. Lossless and lossy compression, encoding of very large images, progressive transmission by pixel accuracy and by resolution, robustness to the presence of bit-errors and region-of-interest coding, are some representative examples of its features.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {45–49},
numpages = {5},
keywords = {subband coding, JPEG, wavelet transform, data compression, source coding, colour image coding},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357758,
author = {Park, Dong Kwon and Jeon, Yoon Seok and Won, Chee Sun},
title = {Efficient Use of Local Edge Histogram Descriptor},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357758},
doi = {10.1145/357744.357758},
abstract = {The purpose of this paper is to show how the edge histogram descriptor for MPEG-7 can be efficiently utilized for image matching. Since the edge histogram descriptor recommended for the MPEG-7 standard represents only local edge distribution in an image, the matching performance for image retrieval may not be satisfactory. In this paper, to increase the matching performance, we propose to use the global and semi-local edge histograms generated directly from the local histogram bins. Then, the global, semi-global, and local histograms of two images are compared to evaluate the similarity measure. Since we exploit the absolute locations of edge in the image as well as its global composition, the proposed matching method is considered to be a more image content-based retrieval. Experimental results support this claim. Experiments on test images for MPEG-7 core experiment show that the proposed method yields better retrieval performance especially for semantic similarity.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {51–54},
numpages = {4},
keywords = {histogram, image retrieval, MPEG-7, edge feature},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357759,
author = {Kauff, Peter and Sch\"{u}\"{u}r, Klaas},
title = {Fast Motion Estimation for Real-Time Shape-Adaptive MPEG-4 Encoding},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357759},
doi = {10.1145/357744.357759},
abstract = {This paper presents a fast motion estimator which can be used for real-time MPEG-4 encoding of arbitrarily shaped video objects. The approach is based on an existing algorithm which has already been applied successfully to format conversion. To exploit it for shape-adaptive coding, the algorithm has been adapted to the special properties of the MPEG-4 standard. With this new tool it becomes possible to encode arbitrarily shaped video objects (CIF, 25 Hz) in real-time with a MPEG-4 software encoder at a Pentium III 500 MHz. The real-time capability has to be paid by a slight loss of coding efficiency (about 0.2 dB in terms of rate-distortion measurements), compared to the MPEG-4 verification model.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {55–58},
numpages = {4},
keywords = {MPEG-4, recursive block matching, pixel-recursive matching, shape-adaptive coding, motion estimation},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357760,
author = {Crinon, Regis J. and Heredia, Edwin A.},
title = {The ATSC Data Broadcast Standard},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357760},
doi = {10.1145/357744.357760},
abstract = {The Advanced Television Systems Committee (ATSC) is about to complete its data broadcast standard. This specification will enable multimedia content providers to deliver applications using the broadband channels of digital television. This specification will also enable the integration of data based information technologies and television audio-visual services. The purpose of the paper is to provide a description of the most important principles making up the specification. More specifically, four components are presented: A collection of unidirectional delivery protocols, an application signaling framework for service discovery, an MPEG-2 Transport buffer model and finally, a Profile and Level-based classification of data services. The functionality provided by each of these components is reviewed.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {59–62},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357761,
author = {Gonno, Yoshihisa and Nishio, Fumihiko and Tsunoda, Tomohiro and Yamagishi, Yasuaki},
title = {White Paper on Integrated Broadband Environment Environment for Personalized TV Experience (IBEX)-Preliminary Edition},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357761},
doi = {10.1145/357744.357761},
abstract = {This document intends to describe a system overview of “Integrated Broadband Environment for Personalized TV Experience (IBEX)”. The IBEX features three major goals: to release audience from time constraint scheduled by broadcasters, to provide seamless and adaptive access between TV and the Web, and finally, to securely personalize TV experience for individual audience. In order to achieve open framework, these viewpoints must be properly developed in conjunction with well-organized data models and system architecture based on de-facto standard technology. The IBEX will provide a prototype system model built on upcoming integrated broadband digital TV infrastructure. The IBEX also intends to provide a service model for the TV-Anytime framework.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {63–66},
numpages = {4},
keywords = {structure, TV-anytime, metadata, schema, description, identification, contents, database},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357762,
author = {Dorai, Chitra and Bolle, Ruud and Dimitrova, Nevenka and Agnihotri, Lalitha and Wei, Gang},
title = {On the Evolution of Videotext Description Scheme and Its Validation Experiments for MPEG-7},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357762},
doi = {10.1145/357744.357762},
abstract = {Videotext refers to text superimposed on still images and video frames, and can be used in many MPEG-7 applications that deal with archival and delivery of images and video. It can be used to annotate and index large video and image collections, and enables text based search, automatic video logging, and video cataloging. This paper describes the joint work of IBM and Philips Research Laboratories on designing an MPEG-7 description scheme based on videotext. It describes the elements comprising the Videotext DS and discusses validation experiments performed to demonstrate the effectiveness of the DS in video browsing and classification tasks.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {67–70},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357763,
author = {Kim, Michelle and Wood, Steve and Cheok, Lai-Tee},
title = {Extensible MPEG-4 Textual Format (XMT)},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357763},
doi = {10.1145/357744.357763},
abstract = {This paper describes the Extensible MPEG-4 Textual format (XMT), a framework for representing MPEG-4 scene description using a textual syntax. The XMT allows the content authors to exchange their content with other authors, tools or service providers, and facilitates interoperability with both the X3D, developed by the Web3D consortium, and the Synchronized Multimedia Integration Language (SMIL) from the W3C consortium.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {71–74},
numpages = {4},
keywords = {X3D, authoring, scene description, textual format, MPEG-4, SMIL},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357764,
author = {Bj\"{o}rk, Niklas and Christopoulos, Charilaos},
title = {Video Transcoding for Universal Multimedia Access},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357764},
doi = {10.1145/357744.357764},
abstract = {This paper discusses the issue of adapting video streams to different type of terminals with different terminal capabilities such as screen size, amount of available memory, processing power and type of network access. This functionality will be very useful for the Universal Multimedia Access application related to MPEG-7 standardization activities. Two different models for transcoding are examined, rate reduction and resolution reduction. Results will show that the computational complexity of the basic transcoding model can be reduced for each model by, on average, 39% and 23% without significant loss in quality. Comparisons with the scaleable coding model are also shown.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {75–79},
numpages = {5},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357880,
author = {Charlesworth, J. P. A. and Garner, P. N.},
title = {Spoken Content Metadata and MPEG-7},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357880},
doi = {10.1145/357744.357880},
abstract = {The words spoken in an audio stream form an obvious descriptor essential to most audio-visual metadata standards. When derived using automatic speech recognition systems, the spoken content fits into neither low-level (representative) nor high-level (semantic) metadata categories. This results in difficulties in creating a representation that can support both interoperability between different extraction and application utilities while retaining robustness to the limitations of the extraction process. In this paper, we discuss the issues encountered in the design of the MPEG-7 spoken content descriptor and their applicability to other metadata standards.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {81–84},
numpages = {4},
keywords = {spoken content, robust retrieval, automatic speech recognition, interoperability, spoken document retrieval, MPEG-7},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357883,
author = {Ashour, Gal and Amir, Arnon and Ponceleon, Dulce and Srinivasan, Savitha},
title = {Architecture for Varying Multimedia Formats},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357883},
doi = {10.1145/357744.357883},
abstract = {In recent years, a few transitions in multimedia applications may be observed. We can identify at least two trends. Firstly, multimedia is being introduced in mainstream applications, leaving behind its traditional focus on highly professional markets, and on the gaming enhancement arena. Secondly, standardization bodies continue to work on media standards in order to provide a common approach to enable interoperability, better quality and efficiency under specified constraints. These new media standards are then added to existing archives of media, spanning a broad spectrum of legacy media standards. The result of these two trends is that a typical multimedia application, in order to be effective, needs to support many input types and provide the user with a seamless and transparent behavior. This paper discusses a pragmatic approach to this problem based on the object-oriented paradigm for real-world multimedia applications.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {85–88},
numpages = {4},
keywords = {multimedia standards, multimedia extension wrappers, object-oriented design, interoperability, multimedia abstraction layers},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357885,
author = {Pfeiffer, Silvia and Srinivasan, Uma},
title = {TV Anytime as an Application Scenario for MPEG-7},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357885},
doi = {10.1145/357744.357885},
abstract = {The ISO/MPEG group has identified a wide range of application scenarios [1] for their emerging MPEG-7 standard on audio-visual metadata. TV Anytime with their vision of future digital TV services [2] encompasses a large number of them. As TV Anytime has also identified metadata as one of the key requirements to realize their vision, MPEG-7 is the natural candidate to fill that role. Here, we describe technically how metadata for the TV Anytime scenario can be created using MPEG-7.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {89–92},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357887,
author = {Rehm, Eric},
title = {Representing Internet Streaming Media Metadata Using MPEG-7 Multimedia Description Schemes},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357887},
doi = {10.1145/357744.357887},
abstract = {Singingfish.com uses MPEG-7 description schemes to model the metadata characteristics of Internet streaming media. Further it has used MPEG-7 description schemes as the basis for a number of internal experiments, processes, as well as interchange with commercial content partners. This paper describes our selection of description schemes from the MPEG-7 Multimedia Description Schemes (MDS) Working Drafts, their ability (or lack thereof) to represent Internet streaming media metadata, and our experiences (successes and failures) in using MPEG-7 DS's in various applications critical to building an Internet streaming media search engine.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {93–98},
numpages = {6},
keywords = {multimedia, search engine, MPEG-7, streaming media},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357889,
author = {Benitez, Ana B. and Bulterman, Dick and Horowitz, Bradley and Eleftheriadis, Alexandros and Vaithilingam, Gandhi},
title = {Standards, Interoperability and Practice: Who Needs Standards Anyway? (Panel Session)},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357889},
doi = {10.1145/357744.357889},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {99–103},
numpages = {5},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357890,
author = {Dittmann, Jana and Steinebach, Martin and Kunkelmann, Thomas and Stoffels, Ludwig},
title = {H204M — Watermarking for Media: Classification, Quality Evaluation, Design Improvements},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357890},
doi = {10.1145/357744.357890},
abstract = {Security has become one of the most significant problems for spreading new information technology. Beside cryptographic solutions digital watermarking methods offer several protection possibilities. H204M — Watermarking for Media is a joined project at GMD-IPSI (German National Research Center for Information Technology) and the German broadcast archive DRA funded by the German government to classify, evaluate and improve digital watermarking techniques. Today a wide variety of techniques has been proposed but it is quite difficult to classify the approaches and measure their quality. Our intention in this project is to discuss the main watermarking parameter and to present a media independent classification scheme as a basis for quality evaluation. Furthermore one outstanding goal of the project is practical testing of existing techniques in a real scenario at the DRA with the content-management provider tecmath AG. Practical experiences are an essential basis for better design approaches. To date, such integration of watermarking algorithm into content management systems are not evaluated. In parallel a group was established initiated by Fabien Petitcolas to offer a public automated watermarking evaluation service: StirMark Benchmark. In our paper we present the H204M project scenario, first results of the media-independent classification scheme and the StirMark Benchmark evaluation service.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {107–110},
numpages = {4},
keywords = {evaluation service, digital watermarking, classification},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357892,
author = {Wohlmacher, Petra},
title = {Digital Certificates: A Survey of Revocation Methods},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357892},
doi = {10.1145/357744.357892},
abstract = {Digital certificates form a basis that allows entities to trust each other. Due to different constraints, a certificate is only valid within a specific period of time. Coming from several threats, there are important reasons why its validity must be terminated sooner than assigned and thus, the certificate needs to be revoked. This paper provides a classification of revocation methods and gives an overview of the main methods like CRL, CRS, CRT, and OCSP. If and in which way a revocation method is suited must be analyzed in accordance to their purpose.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {111–114},
numpages = {4},
keywords = {CRS, public-key certificate, OCSP, CRL, digital certificate, CRT, revocation, X.509, attribute certificate},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357893,
author = {Lu, Chun-Shien and Liao, Hong-Yuan Mark},
title = {Structural Digital Signature for Image Authentication: An Incidental Distortion Resistant Scheme},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357893},
doi = {10.1145/357744.357893},
abstract = {The existing digital data authentication methods are able to detect tampered regions, but are too fragile to resist incidental distortions. This paper will present a new digital signature scheme for image authentication by making use of image content (in the wavelet domain). Based on this concept, a structural digital signature (SDS) is constructed. SDS is a signature that can be used to judge whether an incoming modification is incidental or malicious. When the structure of an SDS is maintained near-complete, we classify the incoming modification as incidental; otherwise, it is malicious. Many incidental manipulations, which cannot be tolerated in previous digital signature or fragile watermarking methods, can now survive under the proposed scheme.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {115–118},
numpages = {4},
keywords = {wavelet transform, authentication, fragility, robustness, digital signature},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357895,
author = {Haitsma, Jaap and van der Veen, Michiel and Kalker, Ton and Bruekers, Fons},
title = {Audio Watermarking for Monitoring and Copy Protection},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357895},
doi = {10.1145/357744.357895},
abstract = {Based on existing technology used in image and video watermarking, we have developed a robust audio watermarking technique. The embedding algorithm operates in frequency domain, where the magnitudes of the Fourier coefficients are slightly modified. In the temporal domain, an additional scale parameter and gain function are necessary to refine the watermark and achieve perceptual transparency. Watermark detection relies on the Symmetrical Phase Only Matched Filtering (SPOMF) cross-correlation approach. Not only the presence of a watermark, but also its cyclic shift is detected. This shift supports a multi-bit payload for one particular watermark sequence. The watermarking technology proved to be very robust to a large number of signal processing “attacks” such as MP3 (64 kb/s), all-pass filtering, echo addition, time-scale modification, resampling, noise addition, etc. It is expected that this approach may contribute in a wide variety of existing (e.g. monitoring and copy protection) and future applications.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {119–122},
numpages = {4},
keywords = {watermark embedding, copy protection, watermark detection, broadcast monitoring, audio},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357898,
author = {Chandramouli, R. and Memon, Nasir D.},
title = {A Distributed Detection Framework for Steganalysis},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357898},
doi = {10.1145/357744.357898},
abstract = {Many watermarking algorithms have been proposed and studied for their robustness and other properties. But, there has been little effort is analyzing these algorithms for their vulnerability against detection by an adversary. As a general philosophy for robust watermarking the host signal and the watermarked signal are well separated in a statistical distance sense. This very nature can be exploited by an adversary to easily detect the watermark and perhaps remove it. We argue that the ability of a watermark to avoid detection by an adversary is a key factor that needs more attention. In this paper, we propose a framework, based on a distributed detection technique, that can be used by the adversary to study signals for the presence/absence of watermarks. We choose a particular spatial domain image watermarking algorithm and explain how the proposed framework can be applied to detect the watermark with very little knowledge about the watermark insertion procedure. The false alarm probability can be optimally traded-off with the probability of detection using the receiver operating characteristic function.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {123–126},
numpages = {4},
keywords = {covert channels, Steganography, distributed detection, fusion, watermarking, information hiding, Steganalysis},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357902,
author = {Ratha, Nalini K. and Connell, Jonathan H. and Bolle, Ruud M.},
title = {Secure Data Hiding in Wavelet Compressed Fingerprint Images},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357902},
doi = {10.1145/357744.357902},
abstract = {With the rapid growth of the Internet, electronic commerce revenue now amounts to several billion US dollars. To avoid fraud and misuse, buyers and sellers desire more secure methods of authentication than today's userid and password combinations. Automated biometrics technology in general, and fingerprints in particular, provide an accurate and reliable authentication method. However, fingerprint-based authentication requires accessing fingerprint images scanned remotely at the user's workstation, a potentially weak point in the security system. Stored or synthetic fingerprint images might be fraudulently transmitted, even if the communication channel itself is encrypted. In this paper we describe an algorithm for secure data hiding in wavelet compressed fingerprint images to alleviate this problem. Assuming the image capture device is secure, then only the decompressor on the server can locate the embedded message and thereby validate the submitted image.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {127–130},
numpages = {4},
keywords = {data hiding, watermarking, fingerprints, WSQ compression, authentication, biometrics},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357904,
author = {Alturki, Faisal and Mersereau, Russell},
title = {Secure High Data Embedding Rate for Steganographic Application},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357904},
doi = {10.1145/357744.357904},
abstract = {Data hiding is the process of secretly embedding information inside a data source without changing its perceptual quality or its statistical properties. In this paper we present a new data hiding technique for embedding a high data rate in the transform domain. This technique is suitable for applications such as covert communication and captioning. The technique is based on increasing the number of image transform coefficients used to carry the information by decorrelating the image samples in the spatial domain. The embedding technique does not introduce noticeable changes neither in the perceptual quality nor in the statistical properties of the cover image. Hence, it is considered to be secure.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {131–134},
numpages = {4},
keywords = {data embedding, steganography, watermarking, data security},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357907,
author = {Tirkel, Andrew Z. and Hall, Tom E.},
title = {Watermarking at Point of Origin},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357907},
doi = {10.1145/357744.357907},
abstract = {We describe a proposed scheme for watermarking images or video at the camera. This addresses the issue of image security between the point of origin and the point of distribution. The scheme is expected to find application in the security industry, where proof of tampering is important and in commercial photography, where breach of copyright is important.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {135–138},
numpages = {4},
keywords = {correlation, watermark, array, polynomial},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357909,
author = {Bao, Feng},
title = {Multimedia Content Protection by Cryptography and Watermarking in Tamper-Resistant Hardware},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357909},
doi = {10.1145/357744.357909},
abstract = {With the rapid growth of broadband network, distribution of multimedia via Internet is a must way to go. Content protection has become one of the most significant and challenging problems of this field. In this paper, we propose a general scheme that combines public key cryptography and watermarking technology together, to achieve wonderful content protection. The scheme is reliable, flexible and efficient.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {139–142},
numpages = {4},
keywords = {public key cryptography, watermarking technology, multimedia content protection, tamper-resistant hardware},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357912,
author = {Shaw, Graham},
title = {Digital Document Integrity},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357912},
doi = {10.1145/357744.357912},
abstract = {The revolution in digital data processing has brought many benefits to the way we create, organise and manage information, whether in the form of images, documents, audio or video files. The conversion of such information into digital form provides us with capabilities such as online storage and retrieval, efficient search processes and worldwide data transmission. But digital data also brings with it a major problem, namely the ease with which such information can be copied and tampered with, without the forensic trail of evidence that we have relied on for analogue and hard-copy files. The need has therefore arisen for technologies which are able to safeguard the integrity and authenticity of digital records, particularly if such records are subject to legal and/or ethical scrutiny. The preservation of integrity of digital records is particularly important where they are subject to concerted and possible criminal attack.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {143–144},
numpages = {2},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357913,
author = {Weippl, Edgar},
title = {Coimbra: Secure Web Access to Multimedia Content},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357913},
doi = {10.1145/357744.357913},
abstract = {In this paper, we describe various concepts how Web content can be published in a way so that copies cannot be illegally distributed. The required access control mechanisms are implemented using well-known cryptographic algorithms. A modified Web browser decrypts the content on-the-fly so that it is impossible for unauthorized users to copy and distribute the presented multimedia content.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {145–148},
numpages = {4},
keywords = {confidentiality, security model, discretionary access control, encryption},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357914,
author = {Ackermann, Ralf and Roedig, Utz and Zink, Michael and Griwodz, Carsten and Steinmetz, Ralf},
title = {Associating Network Flows with User and Application Information},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357914},
doi = {10.1145/357744.357914},
abstract = {The concept of authenticating users e.g. by means of a login process is very well established and there is no doubt that it is absolutely necessary and helpful in a multiuser environment. Unfortunately specific information about a user originating a data stream or receiving it, is often no longer available at the traversed network nodes. This applies to the even more specific question of what application is used as well. Routers, gateways or firewalls usually have to base their classification of data on IP header inspection or have to try to extract information from the packets payload.We present an approach that works transparently and allows to associate user and application specific information with IP data streams by only slightly modifying components of the operating system environment and infrastructure components. On top of this framework we show usage scenarios for dedicatedly placing copyright information in media content and for an enhancement of the interoperation with the security infrastructure.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {149–152},
numpages = {4},
keywords = {firewalls, network traffic marking, watermarking, security},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357916,
author = {Talwar, Vanish and Nahrstedt, Klara},
title = {Securing RSVP for Multimedia Applications},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357916},
doi = {10.1145/357744.357916},
abstract = {Distributed multimedia applications require end-to-end quality of service (QoS) in order to be accepted and used. One approach to achieve end-to-end QoS is to provide end-to-end resource reservations. Resource ReSerVation Protocol (RSVP) [5] [1] is a unicast and multicast signalling protocol for setting up network bandwidth reservation. In this paper, we propose a solution for securing RSVP messages in a flexible, efficient and scalable manner. Our solution extends the RSVP protocol with a scalable QoS protection, using a hybrid hierarchical security approach. The RSVP messages go through two different protocol treatments - one within subnetworks and the other across subnetworks. We use delayed integrity checking within the subnetwork by sending feedback messages from the egress node. A stronger integrity and encryption check is made on messages sent across subnetworks. Our solution is thus an intermediate approach between the extremes of hop by hop authentication [2] and the SDS/CD protocol [8] and overcomes the drawbacks of the two protocols.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {153–156},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357917,
author = {Grimm, R\"{u}diger and Rossnagel, Alexander},
title = {Can P3P Help to Protect Privacy Worldwide?},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357917},
doi = {10.1145/357744.357917},
abstract = {Privacy is a basic cultural requirement, often regulated by national law, but not everywhere in the same way. Privacy protection must be effective across national borders. Technical tools and procedures can help to enforce and propagate privacy protection for Internet communication worldwide. The “Platform for Privacy Preferences Project (P3P)” is a standardization approach of the World Wide Web Consortium for privacy protection of the Web. This article describes the history and current state of P3P and evaluates the effect of P3P against legal requirements, particularly against those strict laws in Germany and Europe. This article is an interdisciplinary cooperation with technical and legal background.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {157–160},
numpages = {4},
keywords = {law enforcement, self-regulation, privacy technology, PICS, privacy, P3P, regulation},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357919,
author = {Lepr\'{e}vost, Franck and Erard, Rapha\"{e}l and Ebrahimi, Touradj},
title = {How to Bypass the Wassenaar Arrangement: A New Application for Watermarking},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357919},
doi = {10.1145/357744.357919},
abstract = {The scope of this article is to clarify the current legal and political situation related to electronic surveillance on the one hand, and to export regulations for encryption software on the other hand. We will look at different international agreements, such as the UKUSA agreement and the Wassenaar arrangement, and elaborate on current encryption techniques falling under these regulations. This discussion is then followed by introducing the basic concepts of steganography and digital watermarking which could be used for secret communication. As a consequence, we propose an original way to legally bypass the international export regulations using these technologies. To this end a new watermarking technique is proposed, which is robust to JPEG2000 compression and provides a good channel capacity. The efficiency of the proposed technique is analyzed by means of simulations to allow for secure communications.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {161–164},
numpages = {4},
keywords = {Wassenaar arrangement, cryptography, watermarking, steganography},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357921,
author = {Song, Zhexuan and Roussopoulos, Nick},
title = {Using Hilbert Curve in Image Storing and Retrieving},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357921},
doi = {10.1145/357744.357921},
abstract = {In this paper, we present a method to accelerate the speed of retrieving subset of uncompressed images in a database without using extra disk space. First we change the storing method: pixels of an image are saved in Hilbert order instead of Row-wise order in traditional method. After studying the property of Hilbert curve, we give a new algorithm which greatly reduces the data segment numbers on the disk. Although we have to retrieve more data than necessary, because the speed of sequential readings is much faster than the speed of random readings, our method spends about 10% less elapsed time which is showed in our simulation experiments. In some systems, the saving can be as high as 90%.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {167–170},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.361911,
author = {Stehling, Renato O. and Nascimento, Mario A. and Falc\~{a}o, Alexandre X.},
title = {On “Shapes” of Colors for Content-Based Image Retrieval},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.361911},
doi = {10.1145/357744.361911},
abstract = {Color is a commonly used feature for realizing content-based image retrieval (CBIR). Towards this goal, this paper presents a new approach for CBIR which is based on well known and widely used color histograms. Contrasting to previous approaches, such as using a single color histogram for the whole image, or local color histograms for a fixed number of image cells, the one we propose (named Color Shape) uses a variable number of histograms, depending only on the actual number of colors present in the image. Our experiments using a large set of heterogeneous images and pre-defined query/answer sets show that the Color Shape approach offers good retrieval quality with relatively low space overhead, outperforming previous approaches.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {171–174},
numpages = {4},
keywords = {image metadata, image similarity retrieval, histograms, image databases},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357927,
author = {Yang, Zijun and Kuo, C. -C. Jay},
title = {Learning Image Similarities and Categories from Content Analysis and Relevance Feedback},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357927},
doi = {10.1145/357744.357927},
abstract = {In this work, a scheme that learns image similarities and categories from relevance feedback is presented. First, we choose the most suitable features to describe images by content analysis and categorize each image by predicting its semantic meanings. During the retrieval process, users are allowed to confirm semantic classification of the query example and evaluate retrieval results with relevance feedback. By analyzing the feedback information, the system learns both image similarities and semantic meanings. In similarity learning, the retrieving results are refined by modifying the similarity metric. Semantic learning is performed by using the decision tree training algorithm.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {175–178},
numpages = {4},
keywords = {image retrieval, interactive learning, relevance feedback},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357929,
author = {Zhu, Lei and Rao, Aibing and Zhang, Aidong},
title = {Advanced Feature Extraction for Keyblock-Based Image Retrieval},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357929},
doi = {10.1145/357744.357929},
abstract = {Keyblock, which is a new framework we proposed for content-based image retrieval, is a generalization of the text-based information retrieval technology in the image domain. In this framework, keyblocks, which are analogous to keywords in text document retrieval, can be constructed by exploiting the Vector Quantization (VQ) method which has been used for image compression. Then an image can be represented as a code matrix in which the elements are the indices of keyblocks in a codebook. Based on this image representation, information retrieval and database analysis techniques developed in the text domain can be generalized to image retrieval. In this paper, we propose new models named N-block models which are the generalization of the N-gram models in language modeling to extract comprehensive image features. The effort to capture context in a text document motivated the N-gram models. Similarly, the attempt to capture the content in an image motivates us to consider the correlations of keyblocks within an image. By comparing the performance of our approach with conventional techniques using color feature and wavelet texture feature, the experimental results demonstrate the effectiveness of these N-block models.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {179–183},
numpages = {5},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357930,
author = {Wei, Gang and Sethi, Ishwar K.},
title = {Omni-Face Detection for Video/Image Content Description},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357930},
doi = {10.1145/357744.357930},
abstract = {An omni-face detection scheme for image/video content description is proposed in this paper. It provides the ability to extract high-level features in terms of human activities rather than low-level features like color, texture and shape. The system relies on an omni-face detection system capable of locating human faces over a broad range of views in color images or videos with complex scenes. It uses the presence of skin-tone pixels coupled with shape, edge pattern and face-specific features to locate faces. The main distinguishing contribution of this work is being able to detect faces irrespective of their poses, including frontal-view and side-view, whereas contemporary systems deal with frontal-view faces only. The other novel aspects of the work lie in its iterative candidate filtering to segment objects from extraneous region, the use of Hausdorff distance-based normalized similarity measure to identify side-view facial profiles, and the exploration of hidden Markov model (HMM) to verify the presence of a side-view face. Image and video can be assigned with semantic descriptors based on human face information for later indexing and retrieval.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {185–189},
numpages = {5},
keywords = {content-based retrieval, image annotation, skin-tone filtering, face detection, side-view faces},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357931,
author = {Moriyama, Tsuyoshi and Sakauchi, Masao},
title = {Video Summarisation Based on the Psychological Content in the Track Structure},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357931},
doi = {10.1145/357744.357931},
abstract = {In this study, the method to summarise TV drama based on the psychological unfolding is proposed. In past researches, video summarisation has been achieved almost by way of choosing representative frames in visual track and never based on the mental side of video content. In this work, the video structure which consists of audio &amp; visual tracks (actor's utterances, BGM, background sound, effect sounds and shots) is modeled and the track-structure-based video summarization method is proposed. To extract the temporal feature patterns of the track structure correspondent with the specific psychological content, each tracks is first quantified by calculating existence ratio etc., and second the intra/inter track feature patterns are determined based on empirical knowledges. The proposed method is implemented and examined in the subjective experiment.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {191–194},
numpages = {4},
keywords = {human factors, multimedia, TV drama, theory, time series pattern, track structure, video summarisation},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357933,
author = {Ide, Ichiro and Hamada, Reiko and Sakai, Shuichi and Tanaka, Hidehiko},
title = {Scene Identification in News Video by Character Region Segmentation},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357933},
doi = {10.1145/357744.357933},
abstract = {Reflecting the demand for recycling and retrieval of video, we are proposing an automatic indexing system for news video that considers correspondences between textual indices and image contents. In this paper, we focus on the background image content (i.e. scene) identification portion of the system. The analysis is performed by segmenting (human) character region from background region, and was applied to actual news video for evaluation. The overall result showed the effectiveness of the proposed method by 7 to 8%, and indicated that character existence itself is an important feature. Individual observation among various scenes indicated that multiple features should be combinatorily used according to each scene, and that the data set should be exponentially extended for higher performance.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {195–200},
numpages = {6},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357934,
author = {Zhang, Yi and Chua, Tat-Seng},
title = {Detection of Text Captions in Compressed Domain Video},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357934},
doi = {10.1145/357744.357934},
abstract = {In this paper, we propose a new method for detecting text captions in MPEG video stream. It is based on the observation that text captions in video frames typically possess high contrast against the background for them to be visible. The method operates on DCT coefficients in MPEG domain. The main contribution of this work is in developing a binarzied contrast feature domain in which the presence of text in video frames can be highlighted. A weighting function is defined to deduce the probability of a text frame. From the set of representative text frames located, further techniques are developed to outline, segment, and recognise text captions. The techniques have been tested on commercial and news videos from the MPEG7 data set and local TCS news video. The results demonstrate that our approach is effective in detecting and locating text captions in general video.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {201–204},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357935,
author = {Babaguchi, Noboru and Kawai, Yoshihiko and Yasugi, Yukinobu and Kitahashi, Tadahiro},
title = {Linking Live and Replay Scenes in Broadcasted Sports Video},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357935},
doi = {10.1145/357744.357935},
abstract = {Content based video organization requires to understand semantical relationships such as identity and similarity between video segments. In particular, it is of great interest to identify scenes of the same event which may differ in their appearances. For broadcasted sports video, such scenes correspond to live and replay scenes that appear at different temporal positions. In this paper, we propose a method of linking up live and replay scenes by focusing on the domain knowledge about producing TV programs of sports: most of the replay scenes are sandwiched in between specific digital video effects. The replay scenes are linked with live scenes when the game is in play based on salient image features. We clarify the effectiveness of our method through fundamental experiments for American football games.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {205–208},
numpages = {4},
keywords = {video organization, live and replay scenes, broadcasted sports video},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357938,
author = {Shim, Choon-Bo and Chang, Jae-Woo},
title = {Spatio-Temporal Representation and Retrieval Using Moving Object's Trajectories},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357938},
doi = {10.1145/357744.357938},
abstract = {In this paper, we propose a new spatio-temporal representation scheme using moving objects' trajectories in video data. In order to support content-based retrieval on video data very well, our representation scheme considers the moving distance of an object during a given time interval as well as its temporal and spatial relations. Based on our representation scheme, we present a new similarity measure algorithms for the trajectory of moving objects, which provides ranking for the retrieved video results. Finally, we show from our experiment that our representation scheme achieves about 20% higher precision while holding about the same recall, compared with Li's and Shan's schemes.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {209–212},
numpages = {4},
keywords = {spatio-temporal representation, moving object's trajectory, video database},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357941,
author = {Zhou, Wensheng and Vellaikal, Asha and Kuo, C. C. Jay},
title = {Rule-Based Video Classification System for Basketball Video Indexing},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357941},
doi = {10.1145/357744.357941},
abstract = {Current information and communication technologies provide the infrastructure to send bits anywhere, but do not presume to handle information at the semantic level. This paper investigates the use of video content analysis and feature extraction and clustering techniques for further video semantic classifications and a supervised rule based video classification system is proposed. This system can be applied to the applications such as on-line video indexing, filtering and video summaries, etc. As an experiment, basketball video structure will be examined and categorized into different classes according to distinct visual and motional characteristics features by rule-based classifier. The semantics classes, the visual/motional feature descriptors and their statistical relationship are then studied in detail and experiment results based on basketball video will be provided and analyzed.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {213–216},
numpages = {4},
keywords = {knowledge-based systems, video indexing, rule-based reasoning, internet video access, video classification, decision tree, feature extraction},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357942,
author = {Zhao, Li and Qi, Wei and Li, Stan Z. and Yang, Shi-Qiang and Zhang, H. J.},
title = {Key-Frame Extraction and Shot Retrieval Using Nearest Feature Line (NFL)},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357942},
doi = {10.1145/357744.357942},
abstract = {Query by key frame or video example is a convenient and often effective way to search in video database. This paper proposes a new approach to support such searches. The main contribution of the proposed approach is the consideration of both feature extraction and distance computation as a whole process. With a video shot represented by key-frames corresponding to feature points in a feature space, a new metric is defined to measure the distance between a query image and a shot based on the concept of Nearest Feature Line (NFL). We propose to use the “breakpoints” of feature trajectory of a video shot as the key frames and use the lines passing through these points to represent the shot. When combined with the NFL method, it helps to achieve a better performance, as evidenced by experiments.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {217–220},
numpages = {4},
keywords = {color histogram, content-based retrieval, key-frame extraction, nearest feature line (NFL)},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357945,
author = {Ariki, Yasuo},
title = {Organization and Retrieval of Continuous Media},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357945},
doi = {10.1145/357744.357945},
abstract = {Because of the media digitization, a large amount of information such as speech, audio and video data is produced everyday. In order to retrieve data quickly and precisely from these databases, multimedia technologies for organizing and retrieving of speech, audio and video data are strongly required. In this paper, we overview the multimedia technologies such as organization and retrieval of speech, audio and video data, speaker indexing, audio summarization and cross media retrieval existing today. The main purpose of the organization is to produce tables of contents and indices from audio and video data automatically. In order to make these technologies feasible, first, processing units such as words on audio data and shots on video data are extracted. On a second step, they are meaningfully integrated into topics. Furthermore, the units extracted from different types of media are integrated for higher functions.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {221–226},
numpages = {6},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357948,
author = {Ioannou, S. and Moschovitis, G. and Ntalianis, K. and Karpouzis, K. and Kollias, S.},
title = {Effective Access to Large Audiovisual Assets Based on User Preferences},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357948},
doi = {10.1145/357744.357948},
abstract = {Current multimedia databases contain a wealth of information in the form of audiovisual, as well as text data. Even though efficient search algorithms have been developed for either media, there still exists the need for abstract presentation and summarization of the results of database users' queries. Moreover, multimedia retrieval systems should be capable of providing the user with additional information related to the specific subject of the query, as well as suggest other topics which users with a similar profile are interested in. In this paper, we present a number of solutions to these issues, giving as an example an integrated architecture we have developed, along with notions that support efficient and secure Internet access and easy addition of new material. Segmentation of the video in shots is followed by shot classification in a number of predetermined categories. Generation of users' profiles according to the same categories, enhanced by relevance feedback, permits an efficient presentation of the retrieved video shots or characteristic frames in terms of the user interest in them. Moreover, this clustering scheme assists the notion of “lateral” links that enable the user to continue retrieval with data of similar nature or content to those already returned. Furthermore, user groups are formed and modeled by registering actual preferences and practices; this enables the system to “predict” information that is possibly relevant to specific users and present it along with the returned results. The concepts utilized in this system can be smoothly integrated in MPEG-7 compatible multimedia database systems.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {227–232},
numpages = {6},
keywords = {web access, multimedia databases, query expansion, text-based search, user profiling},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357950,
author = {Kuruoglu, Ercan E. and Tan, Vern T.},
title = {Document Image Retrieval without OCRing Using a Video Scanning System},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357950},
doi = {10.1145/357744.357950},
abstract = {In this paper, we propose a technique for efficient document retrieval from digital libraries containing document images which are token based compressed. The query image is captured from a paper document by the video scanning tool of a multimedia system. The technique we propose uses the layout information supplied by the relative positions of the character tokens on the page of a “query” paper document to retrieve the original document in the image database. This technique avoids OCRing the query document and the documents in the database; moreover avoids decompressing the token based compressed documents in the database, therefore achieving important time and computational gains.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {233–236},
numpages = {4},
keywords = {video scanning, multimedia systems, image similarity retrieval, document image databases},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357953,
author = {Hamada, Reiko and Ide, Ichiro and Sakai, Shuichi},
title = {Associating Cooking Video with Related Textbook},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357953},
doi = {10.1145/357744.357953},
abstract = {We have been handling video with supplementary documents, such as cooking programs, and are working on integration of such media. Through the integration, many applications will become possible, for example, reconstruction of multimedia data that supplement the information of each medium, construction of interactive database, or kitchen automation. Until now, we have proposed an integration system that perform integrative analysis of image, audio and text and associate each other. In this paper, we will introduce the latest text analysis result and discuss about future image and audio analysis of the proposed system.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {237–241},
numpages = {5},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

@inproceedings{10.1145/357744.357955,
author = {Yamuna, Prakash and Candan, K. Sel\c{c}uk},
title = {Similarity-Based Retrieval of Temporal Documents},
year = {2000},
isbn = {1581133111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/357744.357955},
doi = {10.1145/357744.357955},
abstract = {In this paper, we describe a similarity-based retrieval framework that addresses the challenges associated with the temporal nature of multimedia documents. Multimedia documents consist of multiple media objects and a set of specifications (eg. temporal) that tie these objects together. Therefore, we describe similarity/dissimilarity measures that aim to capture document authors' intensions. We use a prioritized constraint-based framework to evaluate these measures. We also develop algorithms that efficiently compute these measures for special cases.},
booktitle = {Proceedings of the 2000 ACM Workshops on Multimedia},
pages = {243–246},
numpages = {4},
location = {Los Angeles, California, USA},
series = {MULTIMEDIA '00}
}

