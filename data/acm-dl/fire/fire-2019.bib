@inproceedings{10.1145/3368567.3368588,
author = {Sinha, Manjira and Radhakrishnan, Priya and Mannarswamy, Sandya and Parida, Monnie},
title = {CIQ@FIRE: Overview of the Shared Task on Fine-Grained Classification of Insincere Questions},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368588},
doi = {10.1145/3368567.3368588},
abstract = {Given the scale of CQA forums on the web, manual identification of Insincere Questions becomes challenging and costly. Hence automated approaches are needed, in addition to manual moderation to filter insincere questions in CQA sites. While this can be simplistically formulated as a binary classification task, insincere questions exhibit diverse characteristics such as Rhetorical, or Disparaging-Inflammatory, Hypothetical, or Objectionable. The proposed CIQ track aims to find a suitable model for Categorisation of Insincere Questions(CIQ) on CQA forums. We propose that segmenting insincere/non-information seeking questions will not only provide better identification, but also help to enable effective counter-measures based on the fine grained category it belongs to.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {1–3},
numpages = {3},
keywords = {Fine-grained Classification of Insincere Questions, information Retrieval from Community Question Answering Forums},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368587,
author = {Bhattacharya, Paheli and Ghosh, Kripabandhu and Ghosh, Saptarshi and Pal, Arindam and Mehta, Parth and Bhattacharya, Arnab and Majumder, Prasenjit},
title = {FIRE 2019 AILA Track: Artificial Intelligence for Legal Assistance},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368587},
doi = {10.1145/3368567.3368587},
abstract = {The FIRE 2019 AILA track focused on creating a framework for evaluating different methods of retrieving relevant prior/precedent cases and statutes given a factual scenario. There were two tasks for this track: (i) Identifying relevant prior cases for a given situation (Precedent Retrieval), and (ii) Identifying most relevant statutes for a given situation (Statute Retrieval). Given a situation that can lead to filing a case, the precedent retrieval task aims at finding case documents where similar legal situations were addressed. The statute retrieval task aims at finding relevant statutes that are applicable to the situation. The factual scenarios, statutes and prior case documents used in the tasks were from the Indian Supreme Court judiciary.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {4–6},
numpages = {3},
keywords = {Prior case retrieval, Legal data analytics, Statute retrieval, Legal facts},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368586,
author = {Rangel, Francisco and Rosso, Paolo and Charfi, Anis and Zaghouani, Wajdi and Ghanem, Bilal and S\'{a}nchez-Junquera, Javier},
title = {On the Author Profiling and Deception Detection in Arabic Shared Task at FIRE},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368586},
doi = {10.1145/3368567.3368586},
abstract = {This paper summarises the Author Profiling and Deception Detection in Arabic (APDA) shared task at PAN@FIRE 2019. Two have been the main aims of this year's task: i) to profile the age, gender and native language of a Twitter user; ii) to determine whether an Arabic text is deceptive or not in two different genres: Twitter and news headlines. For this purpose we have created three corpora in Arabic. Altogether, the approaches of 13 participants are evaluated.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {7–9},
numpages = {3},
keywords = {deception detection, Arabic, author profiling, Twitter, FIRE},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368585,
author = {Ghanem, Bilal and Karoui, Jihen and Benamara, Farah and Moriceau, V\'{e}ronique and Rosso, Paolo},
title = {IDAT at FIRE2019: Overview of the Track on Irony Detection in Arabic Tweets},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368585},
doi = {10.1145/3368567.3368585},
abstract = {This overview paper describes the first shared task on irony detection for the Arabic language. The task consists of a binary classification of tweets as ironic or not using a dataset composed of 5, 030 Arabic tweets about different political issues and events related to the Middle East and the Maghreb. Tweets in our dataset are written in Modern Standard Arabic but also in different Arabic language varieties including Egypt, Gulf, Levantine and Maghrebi dialects. Eighteen teams registered to the task among which ten submitted their runs. The methods of participants ranged from feature-based to neural networks using either classical machine learning techniques or ensemble methods. The best performing system achieved F-score value of 0.844, showing that classical feature-based models outperform the neural ones.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {10–13},
numpages = {4},
keywords = {Social media, Irony detection, Arabic language},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368584,
author = {Mandl, Thomas and Modha, Sandip and Majumder, Prasenjit and Patel, Daksh and Dave, Mohana and Mandlia, Chintak and Patel, Aditya},
title = {Overview of the HASOC Track at FIRE 2019: Hate Speech and Offensive Content Identification in Indo-European Languages},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368584},
doi = {10.1145/3368567.3368584},
abstract = {The identification of Hate Speech in Social Media is of great importance and receives much attention in the text classification community. There is a huge demand for research for languages other than English. The HASOC track intends to stimulate development in Hate Speech for Hindi, German and English. Three datasets were developed from Twitter and Facebook and made available. Binary classification and more fine-grained subclasses were offered in 3 subtasks. For all subtasks, 321 experiments were submitted. The approaches used most often were LSTM networks processing word embedding input. The performance of the best system for identification of Hate Speech for English, Hindi, and German was a Marco-F1 score of 0.78, 0.81 and 0.61, respectively.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {14–17},
numpages = {4},
keywords = {Evaluation, Deep Learning, Hate Speech, Text Classification},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368571,
author = {Choudhary, Chinmay and O'Riordan, Colm},
title = {A CNN Based Approach to Phrase-Labelling through Classification of N-Grams},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368571},
doi = {10.1145/3368567.3368571},
abstract = {Modern approaches address the task of Phrase-labelling within any input sentence (eg: NER, Chunking etc.) as a variant of word-tagging problem. These approaches extract the desired phrases as word-sequences which are mapped to specific tag-sequences (with Begin, Intermediate and End tag-types).However we argue that basic nature of Phrase-labelling is not temporal but spatial in nature. Thus we propose and test the hypothesis that a CNN based model that directly extracts labelled n-grams from the input sentence would outperform standard RNN based model.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {18–23},
numpages = {6},
keywords = {Phrase-labelling, Convolutional Neural Networks, Information Retrieval, NLP},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368572,
author = {Agarwal, Lucky and Thakral, Kartik and Bhatt, Gaurav and Mittal, Ankush},
title = {Authorship Clustering Using TF-IDF Weighted Word-Embeddings},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368572},
doi = {10.1145/3368567.3368572},
abstract = {In this paper, we propose a novel idea to solve the problem of Author Clustering which is introduced in PAN-2017 Author Identification task. First, we use word embeddings that brings semantic feature of the words along with the grammatical and syntactic information. Secondly, the documents are represented as the TF-IDF weighted sum of the embedding vectors corresponding to each word. A higher TF-IDF weight implies that the words have a stronger relationship in the documents in which they appear. Lastly, using hierarchical clustering all those documents written by each author are grouped together. Finally, we compare the proposed technique with the top submissions to PAN-2017 author clustering task. Through extensive experimentation, we show that the proposed technique outperforms various state-of-the-art models on the given task.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {24–29},
numpages = {6},
keywords = {Hierarchical clustering, Author Clustering, TF-IDF weighted word-embeddings, Author Identification, Word-Embeddings},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368579,
author = {Mahata, Sainik Kumar and Mandal, Soumil and Das, Dipankar and Bandyopadhyay, Sivaji},
title = {Code-Mixed to Monolingual Translation Framework},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368579},
doi = {10.1145/3368567.3368579},
abstract = {The use of multilingualism among the new generation is widespread in the form of code-mixed data on social media, and therefore a robust translation system is required for catering to the novice and monolingual users. In this work, we present a translation framework that uses a translation-transliteration strategy for translating code-mixed data into their equivalent monolingual instances. One of the goals of this work is to translate a code-mixed source (written in Roman script) to a Bengali target (written in Devanagari script), where the source may contain English, along with transliterated Bengali. Finally, to convert the output to a more readable form, it is reordered using a target language model. The decisive advantage of the proposed framework is that it does not require a code-mixed to monolingual parallel corpus for training and decoding. On testing the framework, it achieved BLEU and TER scores of 16.47 and 55.45, respectively. Since the proposed framework deals with various sub-modules, we dive deeper into the importance of each of them, analyze the errors and finally, discuss some improvement strategies.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {30–35},
numpages = {6},
keywords = {Neural Network, Transliteration, Code-Mixing, Machine Translation},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368582,
author = {Sinha, Aman and Patekar, Parth and Mamidi, Radhika},
title = {Unsupervised Approach for Monitoring Satire on Social Media},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368582},
doi = {10.1145/3368567.3368582},
abstract = {The content on social media now-a-days includes a huge number of messages both in textual and visual forms that are satirical in nature. Satire in the form of irony, sarcasm, and ridicule to a person, is depicted by memes on social media. Satire detection in text is an active area of research, but in the visual domain it is relatively less explored. The objective of our work is detection of satire in images taken from the popular photo-sharing platform - Flickr. Traditional methods for visual satire detection are based on supervised learning which has a necessary requirement of annotating the data which is a tedious task. In our work, to address this issue, we propose a novel, unsupervised approach which leverages the visual semantics of the images. We provide a study of clustering methods, where the difference between visual semantics of the two classes - satirical and non-satirical - becomes the basis for classification of visual content. Here, we suggest an autoencoder based clustering framework to effectively combine embedded feature learning and clustering assignments for detection of satire.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {36–41},
numpages = {6},
keywords = {satire detection, auto encoders, unsupervised learning, social media},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368581,
author = {Priyadarshi, Ankur and Saha, Sujan Kumar},
title = {A Hybrid Approach to Develop the First Stemmer in Maithili},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368581},
doi = {10.1145/3368567.3368581},
abstract = {This paper presents a hybrid approach to extract the stems from the Maithili words. Development of stemmer for various languages has gained adequate attention of the researchers for decades. Stemmers have also been developed for most of the major Indian languages. However, no work is found on the development of Maithili stemmer. In this first attempt, we use a hybrid model where rule-base acts as the core module. We study the inflections of the major parts-of-speech categories and define rules accordingly. The rule-based module is supported by neural word-embedding and suffix stripping. Suffix stripping is used to increase the coverage and word embedding is used to restrict erroneous stem generation. The system is evaluated using a test data collected from Maithili literature and news text. The final system achieves an accuracy of 84.6%.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {42–46},
numpages = {5},
keywords = {Maithili Language, Suffix Stripper, Stemmer, Rule-based Stemmer},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368577,
author = {Mahato, Devasish and Dudhal, Disha and Revagade, Dhanashree and Bhargava, Yesoda},
title = {A Method to Detect Inconsistent Annotations in a Medical Document Using UMLS},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368577},
doi = {10.1145/3368567.3368577},
abstract = {Information retrieval from clinical documents relies heavily on annotated corpus. Any inconsistency in annotations, in form of heterogeneous annotations for similar concepts, could be detrimental to the quality of information retrieved. In extreme cases, this may lead to incorrect deductions about patient's medical history and result in erroneous decisions. In the present work, a complete end-to-end system that identifies inconsistencies in a clinically annotated document is presented and analysed. Unified Medical Language System(UMLS) is used to identify medical concepts in the clinical document. The output is presented in a clustered format wherein, each cluster identifies a unique medical concept and contains its semantic synonyms. For each semantic synonym, inconsistent annotations and the sentences in which they occur in the document are listed. The work could be useful for annotation experts who need automated tools to verify their work.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {47–51},
numpages = {5},
keywords = {Inconsistency Detection, Information Retrieval, UMLS, Natural Language Processing},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368568,
author = {Ghosh, Souvick and Ghosh, Satanu},
title = {Exploring the Ideal Depth of Neural Network When Predicting Question Deletion on Community Question Answering},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368568},
doi = {10.1145/3368567.3368568},
abstract = {In recent years, Community Question Answering (CQA) has emerged as a popular platform for knowledge curation and archival. An interesting aspect of question answering is that it combines aspects from natural language processing, information retrieval, and machine learning. In this paper, we have explored how the depth of the neural network influences the accuracy of prediction of deleted questions in question-answering forums. We have used different shallow and deep models for prediction and analyzed the relationships between number of hidden layers, accuracy, and computational time. The results suggest that while deep networks perform better than shallow networks in modeling complex non-linear functions, increasing the depth may not always produce desired results. We observe that the performance of the deep neural network suffers significantly due to vanishing gradients when large number of hidden layers are present. Constantly increasing the depth of the model increases accuracy initially, after which the accuracy plateaus, and finally drops. Adding each layer is also expensive in terms of the time required to train the model. This research is situated in the domain of neural information retrieval and contributes towards building a theory on how deep neural networks can be efficiently and accurately used for predicting question deletion. We predict deleted questions with more than 90% accuracy using two to ten hidden layers, with less accurate results for shallower and deeper architectures.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {52–55},
numpages = {4},
keywords = {Prediction, Community Question Answering, Deep Learning, Question Deletion, Analysis, Machine Learning, Artificial Intelligence},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368576,
author = {Shukla, Vaibhav and Sinha, Manjira and Dasgupta, Tirthankar},
title = {Automatic Humor Detection from Code-Mixed Tweets},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368576},
doi = {10.1145/3368567.3368576},
abstract = {In this paper, we have studied a series of deep convolution recurrent neural network models for automatic recognition of humor from Hindi-English code mixed text. The proposed model takes into consideration both word level and sentence level embeddings. We have observed that neural network architectures that make use of the bidirectional LSTM and CNN models along with the combined word and sentence embeddings perform better than the other baseline models.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {56–59},
numpages = {4},
keywords = {Code-mixing, Humor Detection, Convolution recurrent neural network},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368578,
author = {Das, Sourya Dipta and Mandal, Soumil and Das, Dipankar},
title = {Language Identification of Bengali-English Code-Mixed Data Using Character &amp; Phonetic Based LSTM Models},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368578},
doi = {10.1145/3368567.3368578},
abstract = {Language identification of social media text still remains a challenging task due to properties like code-mixing and inconsistent phonetic transliterations. In this paper, we present a supervised learning approach for language identification at the word level of low resource Bengali-English code-mixed data taken from social media. We employ two methods of word encoding, namely character based and root phone based to train our deep LSTM models. Utilizing these two models we created two ensemble models using stacking and threshold technique which gave 91.78% and 92.35% accuracies respectively on our testing data.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {60–64},
numpages = {5},
keywords = {code-mixing, phonetic encoding, code-switching, language identification, character encoding},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3368567.3368583,
author = {Jaiswal, Amit Kumar and Liu, Haiming and Frommholz, Ingo},
title = {Information Foraging for Enhancing Implicit Feedback in Content-Based Image Recommendation},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368567.3368583},
doi = {10.1145/3368567.3368583},
abstract = {User implicit feedback plays an important role in recommender systems. However, finding implicit features is a tedious task. This paper aims to identify users' preferences through implicit behavioural signals for image recommendation based on the Information Scent Model of Information Foraging Theory. In the first part, we hypothesise that the users' perception is improved with visual cues in the images as behavioural signals that provide users' information scent during information seeking. We designed a content-based image recommendation system to explore which image attributes (i.e., visual cues or bookmarks) help users find their desired image. We found that users prefer recommendations predicated by visual cues and therefore consider the visual cues as good information scent for their information seeking. In the second part, we investigated if visual cues in the images together with the images itself can be better perceived by the users than each of them on its own. We evaluated the information scent artifacts in image recommendation on the Pinterest image collection and the WikiArt dataset. We find our proposed image recommendation system supports the implicit signals through Information Foraging explanation of the information scent model.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {65–69},
numpages = {5},
keywords = {Information Foraging Theory, Recommendation System, Image Search},
location = {Kolkata, India},
series = {FIRE '19}
}

