@inproceedings{10.1145/3293339.3293340,
author = {Basu, Moumita and Ghosh, Saptarshi and Ghosh, Kripabandhu},
title = {Overview of the FIRE 2018 Track: Information Retrieval from Microblogs during Disasters (IRMiDis)},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293340},
doi = {10.1145/3293339.3293340},
abstract = {In countries like the US, European countries, Australia and Japan, user-generated content from microblogging sites is extensively used for crowdsourcing actionable information during disasters. However, there has been limited work in this direction in India. Moreover, there has been a limited attempt to verify the credibility of the information extracted from microblogs from other reliable sources. To this end, the FIRE 2018 Information Retrieval from Microblogs during Disasters (IRMiDis) track focused on the identification of factual or fact-checkable tweets and supporting news article for each fact-checkable tweets. The data consists of around 50, 000 microblogs (tweets) from Twitter and 6, 000 news articles, that were posted during the Nepal earthquake in April 2015. There were two tasks. The first task (Task 1) was to identify factual or fact-checkable tweets and the second task (Task 2) was to identify supporting news articles for fact-checkable tweets.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {1–5},
numpages = {5},
keywords = {Disaster, Microblogs, Multi-source data, FIRE, Fact-checkable},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293341,
author = {Ram R, Vijay Sundar and Devi, Sobha Lalitha},
title = {Overview of Verb Phrase Translation in Machine Translation: English to Tamil and Hindi to Tamil},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293341},
doi = {10.1145/3293339.3293341},
abstract = {We present an overview of verb phrase translation in machine translation from English to Tamil and Hindi to Tamil track, where English, Hindi and Tamil belong to three different language families, namely, Indo-European, Indo-Aryan and Dravidian family respectively. Verb phrases carry syntactic information such as tense, aspect, modal, and PNG (person, number and gender) other than the main verb. The characteristics of verb phrase vary between languages, which make the task challenging. We have five registrations and three out of the five registered teams submitted their runs. The runs are evaluated based on the correctness of tense, aspect, modal (TAM) and PNG of the verb phrase. The performance scores of the participants show the complexity of the task.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {6–10},
numpages = {5},
keywords = {Verb phrase translation, English-Tamil, Hindi-Tamil},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293342,
author = {M, Anand Kumar and HB, Barathi Ganesh and KP, Soman and SG, Ajay},
title = {Indian Native Language Identification - INLI 2018},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293342},
doi = {10.1145/3293339.3293342},
abstract = {The growth of digital platforms enables the industries to serve user specific services. Most of the time, the information of the internet users are not explicitly available and it acts as a constrain in developing the personalized applications. There comes the need for author profiling tasks, which intends to predict the internet users characteristics from their texts. Native language Identification is one among the author profiling task, that predicts the authors native language from their texts available in other language. We have proposed Indian Native Language Identification task, where the internet users texts are written in English and participants needs to find, whether the user's native language is from Tamil, Malayalam, Kannada, Telugu, Bengali and Hindi. The corpus is collected from texts from regional news paper pages available in Facebook by considering the hypothesis that the user belongs to a particular region will read the news from respective regional news paper.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {11–15},
numpages = {5},
keywords = {Indian Languages, FIRE 2018, Native Language Identification, Author Profiling},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293343,
author = {Sharjeel, Muhammad and Fatima, Mehwish and Anwar, Saba and Nawab, Rao Muhammad Adeel},
title = {Multilingual Author Profiling on SMS Track at FIRE'18},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293343},
doi = {10.1145/3293339.3293343},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {16–17},
numpages = {2},
keywords = {Author profiling, Natural Language Processing, Multilingual text processing, SMS corpus},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293344,
author = {HB, Barathi Ganesh and KP, Soman and U, Reshma and Kale, Mandar and Mankame, Prachi and Kulkarni, Gouri and Kale, Anitha and M, Anand Kumar},
title = {Information Extraction for Conversational Systems in Indian Languages - Arnekt IECSIL},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293344},
doi = {10.1145/3293339.3293344},
abstract = {Data being the new source of wealth, mining intelligence from every possible units of it, has become today's salient feature in many fields. Text data is not limited to one language and this has showcased its usability in creating multiple applications from various languages. Development of Indian languages is just getting better both in terms of resource and application specific. Information Extraction for Conversational Systems in Indian Languages - Arnekt IECSIL has taken its step in creating its own resource in Indian languages (Hindi, Kannada, Malayalam, Tamil and Telugu) for Named Entity Recognition (NER) and Information Extraction (IE) tasks. This overview paper will be detailing more on the existing Indian language corpora development and the steps taken for building our own corpus along with its statistics.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {18–20},
numpages = {3},
keywords = {Information Extraction, Named Entity Recognition, Corpus creation for Indian Languages, Indian Languages, Relation Extraction, FIRE 2018},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293345,
author = {Chali, Yllias and Islam, Rafat},
title = {Question-Question Similarity in Online Forums},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293345},
doi = {10.1145/3293339.3293345},
abstract = {In this paper, we applied deep learning framework to tackle the tasks of finding duplicate questions. We implemented some models following the siamese architecture using the popular recurrent network such as Long-Short term memory (LSTM), Bi-direction Long-Short term memory (biLSTM) to find the semantic similarity between questions. We started with a basic model and further extended the basic model into three different models. Our models provide a refined, composite representation of the questions. The addition of Convolutional Neural Network (CNN) with the recurrent networks is a new approach for the sentence representation. We also applied attention mechanism for getting better contextual meaning of the questions. We generated a representation of a question according to the context of another question for solving the task. As neural models are data driven, we trained our models extensively by making pairs, such as question-question over a large-scale real-life dataset. We used a datset consisting of 400K labeled question pairs which are published by a well known question-answer forum Quora. We evaluate our models based on metrics like accuracy, precision, recall, F1 scores. Our methods and experiments demonstrate some significant improvements over the baseline systems and the state-of-the-art systems.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {21–28},
numpages = {8},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293346,
author = {Ganguly, Debasis and Afli, Haithem and Roy, Dwaipayan},
title = {Word Embedding Based Semantic Cross-Lingual Document Alignment in Comparable Corpora},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293346},
doi = {10.1145/3293339.3293346},
abstract = {Crosslingual information retrieval (CLIR) finds its application in aligning documents across comparable corpora. However, traditional CLIR, due to the term independence assumption, cannot consider the semantic similarity between the constituent words of the candidate pairs of documents in two different languages. Moreover, traditional CLIR models score a document by aggregating only the weights of the constituent terms that match with those of the query, while the other non-matching terms of the document do not significantly contribute to the similarity function. Word vector embedding allows the provision to model the semantic distances between terms by the application of standard distance metrics between their corresponding real valued vectors. This paper develops a word vector embedding based CLIR model that uses the average distances between the embedded word vectors of the source and target language documents to rank candidate document pairs. Our experiments with the WMT bilingual document alignment dataset reveal that the word vector based similarity significantly improves the recall of crosslingual document alignment in comparison to the classical language modeling based CLIR.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {28–34},
numpages = {7},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293347,
author = {Yang, Hua and Gon\c{c}alves, Teresa},
title = {How Does Word Embeddings-Based Query Expansion Perform in Consumer Health Information Search? A Novel Solution for CHIS FIRE'2016 Track},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293347},
doi = {10.1145/3293339.3293347},
abstract = {General search engines have been widely used by non-expert consumers when searching for health information on the web. In a health information search scenario, although being able to answer a factual query where the answers are direct and definite, general search engines are still far from effective to answer a query where the answers contain multiple perspectives. CHIS FIRE'2016 track aims to investigate complex health information search in such a scenarios. Different from other teams work, this paper put forward a novel solution to this task. An information retrieval model with improved query expansion techniques were employed. The evaluation results outperform the best team score with a large margin and show the effectiveness of the approach.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {35–40},
numpages = {6},
keywords = {consumer health information search, query expansion, word embeddings},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293348,
author = {Reddy, Vamshi K. G. and Rani, Pratibha and Pudi, Vikram and Sharma, Dipti M.},
title = {Decision Tree Ensemble for Parts-of-Speech Tagging of Resource-Poor Languages},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293348},
doi = {10.1145/3293339.3293348},
abstract = {Ensemble POS taggers are a good choice to integrate and leverage benefits of various types of POS taggers. This can help the large number (6500+) of resource-poor languages which do not have much annotated training data by providing ways to integrate semi-supervised/unsupervised taggers with supervised taggers. In this paper we present our experiments of developing ensemble POS taggers using a decision tree. We integrate a semi-supervised data mining approach that uses context based lists (CBLs) for POS tagging with supervised (1) Support Vector Machine based POS tagger, called SVMTool and (2) Conditional Random Field based POS tagger. The results are enhanced semi-supervised ensemble POS taggers which outperform the base methods. In these POS taggers, we use a decision tree to decide when to rely on the output of supervised tagger, and when to rely on the semi-supervised CBL method. The CBL based tagger uses rich contextual information which helps in tagging both existing and unseen words and uses no domain knowledge while supervised taggers give good performance for words present in the training model and can include domain based features. Hence, these algorithms have complementary strengths and in our ensemble we are able to combine these strengths. Enhanced performance of our new POS taggers over the base methods suggests that integrating these methods combines the qualities of these in the new tagger which enhances the performance. Therefore, these new semi-supervised ensemble taggers are more suitable for resource-poor languages.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {41–47},
numpages = {7},
keywords = {Natural Language Processing, Resource Poor Language, Ensemble Classifier, POS Tagging, CRF, SVM, CBL},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293349,
author = {Rimjhim and Chakraborty, Roshni},
title = {Characterizing User Reactions Towards Twitter's 280 Character Limit},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293349},
doi = {10.1145/3293339.3293349},
abstract = {Twitter is one of the most popular forums for information sharing and interactions among individuals. The continuous rise in the demand and usage of Twitter in various applications have led to the increase in the character limit recently. However, this decision to increase the character limit evokes a variety of research questions, regarding the actual necessity of this decision for users, utilization of the increased characters by the users, reactions of the users and whether the users across the world reacts to this change. In this paper, we intend to answer the queries and characterize the initial reactions, measure the actual usage of new character limit. The initial user reactions depict emotion diversity as well as dependence on geography. Additionally, the usage of character count post this change is highly skewed with newer character count usage present in tail of the distribution which highlights that a very small number of subsequent tweets are of high character count(ranging from 150--240 characters).},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {48–51},
numpages = {4},
keywords = {Tweet Character Count, Emotion Diversity, text mining, Readability},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293351,
author = {Roy, Pronoy and Gupta, Yayati and Ramawat, Prashant and K, Rajeshwari and Iyengar, S. R.S.},
title = {A Longitudinal Study of Public Emotions during Demonetization in India},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293351},
doi = {10.1145/3293339.3293351},
abstract = {Demonetization of currency notes of ₹500 and ₹1000 in India resulted in keen observations, analysis and evaluations of the government by economists across the globe. A huge amount of user-generated content was generated as online users of social media exchanged their views about the various events occurring around them on a daily basis. This study presents a temporal sentiment analysis of tweets related to demonetization.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {52–55},
numpages = {4},
keywords = {Twitter, Sentiment Analysis, NRC, R},
location = {Gandhinagar, India},
series = {FIRE'18}
}

@inproceedings{10.1145/3293339.3293352,
author = {B, Premjith and K.P, Soman and Poornachandran, Prabaharan},
title = {A Deep Learning Based Part-of-Speech (POS) Tagger for Sanskrit Language by Embedding Character Level Features},
year = {2018},
isbn = {9781450362085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293339.3293352},
doi = {10.1145/3293339.3293352},
abstract = {Part-of-Speech (POS) tagging is an important task in Natural Language Processing and numerous taggers have been developed for POS tagging in several languages. In Sanskrit also, one of the oldest languages in the world, many POS taggers were developed. However, less attention was given to the machine learning based POS tagging. In this paper, various deep learning algorithms are used for implementing a POS tagger for Sanskrit. This problem is framed as a sequence labeling problem at the character level. Therefore, a word to be POS tagged is considered as a sequence of characters and the sequential relationship among the characters in a word is captured with the deep learning algorithms such as Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM) networks, Gate Recurrent Unit (GRU) and their bidirectional versions. The character level formulation of the problem reduces the memory requirement compared to the word level implementations and also increases the accuracy of labeling. The performance of the labeling task was analyzed with the different combinations of hyper-parameters. We obtained the accuracy score of 97.86% with Bidirectional GRU. The character level implementations of both uni and bidirectional forms of RNN, LSTM and GRU outperformed all world level implementations in terms of accuracy, number of trainable parameters and the storage requirement.},
booktitle = {Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {56–60},
numpages = {5},
keywords = {Sanskrit POS tagging, Character embedding, Deep learning, Gated Recurrent Unit, Long Short-Term Memory Networks, Recurrent Neural Network},
location = {Gandhinagar, India},
series = {FIRE'18}
}

