@inproceedings{10.1145/2701336.2701638,
author = {Oard, Douglas W. and White, Jerome and Paik, Jiaul and Sankepally, Rashmi and Jansen, Aren},
title = {The FIRE 2013 Question Answering for the Spoken Web Task},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701638},
doi = {10.1145/2701336.2701638},
abstract = {The FIRE 2013 Question Answering for the Spoken Web (QASW) task was an information retrieval evaluation in which the goal was to match spoken Gujarati questions to spoken Gujarati answers. This paper describes the design of the task, the development of the test collection, the runs that were submitted, and the corresponding results.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {1},
numpages = {3},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701635,
author = {Moens, Marie-Francine},
title = {Argumentation Mining: Where Are We Now, Where Do We Want to Be and How Do We Get There?},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701635},
doi = {10.1145/2701336.2701635},
abstract = {This paper gives a short overview of the state-of-the-art and goals of argumentation mining and it provides ideas for further research. Its content is based on two invited lectures on argumentation mining respectively at the FIRE 2013 conference at the India International Center in New Delhi, India and a lecture given as SICSA distinguished visitor at the University of Dundee, UK in the summer of 2014.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {2},
numpages = {6},
keywords = {Structured Learning, State-of-the-Art Survey, Text Entailment},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701634,
author = {Leveling, Johannes},
title = {Monolingual and Crosslingual SMS-Based FAQ Retrieval},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701634},
doi = {10.1145/2701336.2701634},
abstract = {This paper presents results for DCU's second participation in the SMS-based FAQ Retrieval task at FIRE. For FIRE 2012, we submitted runs for the monolingual English and Hindi and the crosslingual English to Hindi subtasks. Compared to our experiments for FIRE 2011, our system was simplified by using a single retrieval engine (instead of three) and using a single approach for detection of out of domain queries (instead of three). In our approach, the SMS queries are transformed into a normalized, corrected form and submitted to a retrieval engine to obtain a ranked list of FAQ results. A classifier trained on features extracted from the training data then determines which queries are out of domain and which are not. For our crosslingual English to Hindi experiments, we trained a statistical machine translation system for Hindi to English translation to translate the full Hindi FAQ documents into English. The retrieval then operates on the corrected English input and retrieves results from the translated Hindi FAQ documents.Our best experiments achieved an MRR of 0.949 for the monolingual English subtask, 0.880 for the monolingual Hindi subtask, and 0.450 for the crosslingual subtask.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {3},
numpages = {6},
keywords = {SMS normalization, CLIR, FAQ retrieval},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701636,
author = {Roy, Rishiraj Saha and Choudhury, Monojit and Majumder, Prasenjit and Agarwal, Komal},
title = {Overview of the FIRE 2013 Track on Transliterated Search},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701636},
doi = {10.1145/2701336.2701636},
abstract = {In this paper, we provide an overview of the FIRE 2013 track on transliterated search and describe the datasets released as part of the track. This was the first year that the track was organized. We had proposed two subtasks as part of the challenge. In the first subtask, which we had proposed for Hindi, Bangla, and Gujarati, participants had to devise an algorithm to label the true languages of words in a sentence. Additionally, if a non-English word was identified, the algorithm was also supposed to provide the transliteration of the word in the native script. The second subtask was retrieval-based, where mixed-script documents had to be retrieved and ranked by relevance in response to ad hoc queries. The queries in our dataset were Bollywood Hindi song lyrics, in Roman script. We received a total of 25 run submissions from five different teams across the world (three from India and two from abroad). Conducting this track helped us generate awareness about the importance of transliteration in the context of Indian languages. Results show that there is considerable scope for improvement of transliteration accuracies for the studied languages.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {4},
numpages = {7},
keywords = {Shared task, Cross-script IR, Transliterated search},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701637,
author = {Sankepally, Rashmi and Kokel, Harsha and Agarwal, Komal and Majumder, Prasenjit},
title = {Morpheme Extraction Task at FIRE 2012--2013},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701637},
doi = {10.1145/2701336.2701637},
abstract = {The Morpheme Extraction task (MET) was organized for the first time in FIRE 2012 and subsequently in FIRE 2013. Participating systems were required to provide morphemes of given term lists. The track was offered in five languages viz. Bengali, Gujarati, Hindi, Odia, Marathi in 2012 and a sixth language: Tamil was added in 2013. Evaluation was done in two different ways viz., IR evaluation and Linguistic evaluation. The IR evaluation exercise comprised of retrieval experiments on given corpora with a standard set of queries with fixed relevant judgements and culminated by finding the Mean Average Precision for the runs. For Linguistic evaluation, system generated morphemes were compared against gold standard morpheme analyses. This overview paper describes the goals, data, tasks, participants, evaluation and results obtained.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {5},
numpages = {4},
keywords = {Morphological analysis, Stemming},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701639,
author = {Gupta, Parth and Clough, Paul and Rosso, Paolo and Stevenson, Mark and Banchs, Rafael E.},
title = {PAN@FIRE: Overview of the Cross-Language !Ndian News Story Search (CL!NSS) Track},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701639},
doi = {10.1145/2701336.2701639},
abstract = {The automatic alignment of documents in a quasi-comparable corpus is an important research problem for a resource poor cross-language technologies. News stories form one of the most prolific and abundant language resource. The PAN@FIRE task, cross-language !ndia news story search (CL!NSS), aimed to address the news story linking task across languages English and Hindi. We present the overview of the track with results and analysis.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {6},
numpages = {7},
keywords = {Text reuse, cross-language information retrieval, news search},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701648,
author = {Ghosh, Kripabandhu and Chakraborty, Anirban and Parui, Swapan Kumar},
title = {Improving IR Performance from OCRed Text Using Cooccurrence},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701648},
doi = {10.1145/2701336.2701648},
abstract = {Information Retrieval performance is hurt to a great extent by OCR errors. Much research has been reported on modelling and correction of OCR errors. However, all the existing systems make use of language dependent resources or training texts to study the nature of errors. No research has been reported on improving retrieval performance from erroneous text when no training data is available. We propose a novel algorithm for automatic detection of OCR errors and improvement of retrieval performance from the erroneous corpus. Our algorithm does not use any training data or any language specific resources like thesaurus. It also does not use any knowledge about the language except that the word delimiter is blank space. We have tested our algorithm on erroneous OCRed Bangla FIRE collection offered in the RISOT 2012 track and obtained about 9% improvement over the OCRed baseline. However, the improvement is not statistically significant.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {7},
numpages = {7},
keywords = {Cooccurrence, Query Expansion},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701644,
author = {Mhaisale, Shahbaaz and Patil, Sangameshwar and Mahamuni, Kiran},
title = {Weighted Edit Distance Based FAQ Retrieval Using Noisy Queries},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701644},
doi = {10.1145/2701336.2701644},
abstract = {In this paper, we describe our contribution to the FIRE 2013 shared task on "FAQ Retrieval using Noisy Queries". Short messaging service (SMS) and voice-based interfaces such as Siri have become quite popular for quick information retrieval these days. The problem posed in this FIRE 2013 shared task is that given an SMS query or speech-to-text transcript of a voice based query, find the best matching frequently asked question (FAQ) from a database or return NULL if there is no relevant FAQ. In our solution, we first normalize the query and then compute the similarity between the query and each question using weighted edit distance. We observe that instead of using the standard edit distance which gives equal weight for all the string edit operations (such as insertion, deletion, transposition, substitution), weighted edit distance works significantly better for checking similarity of SMS queries with FAQ database questions. We determine whether a query is out of domain (i.e. cannot be answered using current set of questions in the FAQ database) using a simple classifier using FAQ database itself. Our method identified 105 out of 148 out-of-domain queries correctly and 188 out of 392 in-domain queries correctly with mean reciprocal rank (MRR) of 0.8836. Since we observed very little correlation in the transcript of speech queries with best matching question in the training data, we also report the results for SMS only queries. On the SMS queries, our method identified 188 of 200 queries correctly, resulting in an MRR of 0.968.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {8},
numpages = {4},
keywords = {noisy text processing, SMS based retrieval, SMS interface, FAQ Retrieval, natural language processing, text cleansing},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701642,
author = {Shaikh, Anwar Dilawar and Shah, Rajiv Ratn and Shaikh, Rahis},
title = {SMS Based FAQ Retrieval for Hindi, English and Malayalam},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701642},
doi = {10.1145/2701336.2701642},
abstract = {This paper presents our approach for the SMS-based FAQ Retrieval monolingual task in FIRE 2012 and FIRE 2013. Current approach predicts the matching of an SMS and FAQs more accurately as compared to our previous solution for this task which was submitted in FIRE 2011. We provide solution for SMS and FAQs matching in Malayalam language (an Indian language) in addition to Hindi and English this time. In order to perform a matching between SMS queries and FAQ database, we introduce enhanced similarity score, proximity score, enhanced length score and an answer matching system. We introduce the stemming of terms and consider the effects of joining adjacent terms in SMS query and FAQ to improve the similarity score. We propose a novel method to normalize FAQ and SMS tokens to improve the accuracy for Hindi language. Moreover, we suggest a few character substitutions to handle error in the SMS query. We demonstrate the effectiveness of our approach by considering many real-life FAQ-datasets provided by FIRE from a number of different domains such as Health, Telecom, Insurance and Railway booking. Experimental results confirm that our solution for the SMS-based FAQ Retrieval monolingual task is very encouraging and among the top submissions which performed very well for English, Hindi and Malayalam. The Mean Reciprocal Rank (MRR) scores for our approach are 0.971, 0.973 and 0.761 respectively for English, Hindi and Malayalam SMS-based FAQ Retrieval monolingual task in FIRE 2012. Furthermore, our solution topped the task for Hindi language with MRR score equal to 0.971 in FIRE 2013. Our approach performs very well for English language as well in FIRE 2013 despite transcripts of the speech queries are included in test dataset along with the normal SMS queries.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {9},
numpages = {8},
keywords = {TF-IDF, length score, SMS query, similarity score, SMS processing, proximity score, FAQ retrieval},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701650,
author = {Arora, Piyush and Foster, Jennifer and Jones, Gareth J. F.},
title = {Applying Query Formulation and Fusion Techniques For Cross Language News Story Search},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701650},
doi = {10.1145/2701336.2701650},
abstract = {Cross Language News story search (CLNSS) is concerned with finding documents describing the same events in documents in different languages. As well as supporting information retrieval (IR), CLNSS has other applications in mining parallel and comparable data across different languages. In this paper, we present an overview of the work carried out for our participation in the Cross Language !ndian News Story Search (CL!NSS) task at FIRE 2013. In the CL!NSS task we explored the problem of cross language news search for the English-Hindi language pair. English news stories are used as queries to seek similar news documents from Hindi news articles. Hindi being a resource-scarce language offers many challenges towards retrieving relevant news articles. We investigate and contrast translation of input queries from English to Hindi using the Google and Bing translation services. To support translation of out-of-vocabulary words we use the Google transliteration service. A key challenge of the CL!NSS task is formation of search queries from the English news articles, since they are much longer than the much shorter queries typically used in IR applications. To address this problem, we explore the use of summarization to extract a query from the input news documents, and use these summarized queries as the input to the cross language IR system. We explore the use of query expansion using pseudo relevance feedback (PRF) in the IR process, since this has been shown to be effective for cross language IR in many previous investigations. We also explore in detail the use of data fusion techniques over different sets of retrieved results obtained using diverse query formulation techniques. For the CL!NSS task our team submitted 3 main runs. The results of our best run was ranked first among official submissions based on NDCG@5 and NDCG@10 values and second for NDCG@1 values. For the 25 test queries the results of our best main run were NDCG@1 0.7400, NDCG@5 0.6809 and NDCG@10 0.7268. We present our methodology, official results and results of a number of post-task experiments that were conducted to further examine the cross language search problem. Our experiments reveal that query formulation plays a vital role in improving search results for news documents across different languages. Instead of using the complete news documents the summarized queries show better performance. Data fusion techniques also help to improve the performance of the system by boosting the rank of documents, thus improving the NDCG scores.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {10},
numpages = {9},
keywords = {Query Summarization, Cross Language News Search, Query Translation, Data Fusion, Hindi Information Retrieval, Pseudo Relevance Feedback},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701640,
author = {Kumar, Aarti and Das, Sujoy},
title = {Pre-Retrieval Based Strategies for Cross Language News Story Search},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701640},
doi = {10.1145/2701336.2701640},
abstract = {The task of measuring text reuse and linking target and source documents becomes challenging if reused text has been translated in other language and even more challenging if translation language uses a different script and syntactical structure. This year, in CLINSS, focus was on journalistic text reuse between texts written in two different languages. This paper focuses on identifying text reuse between texts written in two different languages-English and Hindi and aims at evaluating the CLINSS dataset by linking 25 target English news stories with top 100 Hindi news stories out of corpora of 50691 stories. This is our first participation at CLINSS task and we have submitted two sets of runs as MANIT-1 and MANIT-2. In MANIT-1 two pre-retrieval strategies 1) Query formed using Proper Noun and 2) Query formed using words whose frequency is equal to or higher than average frequency are used to formulate the query. Query is translated using either dictionary based or machine translation CLIR based approach before retrieving the documents. In Run 1 and 2 pre-retrieval strategies clubbed up with CLIR's dictionary based approach is used to link English news stories with Hindi news stories. In Run-3 instead of using dictionary based approach, freely available online Google translate [18] and online Changathi Hindi transliterater [6] is used as Hindi resources for translating/transliterating the query. Through MANIT-1 runs the attempt is to evaluate the performance of two pre-retrieval strategies and to compare the existing dictionary based and machine translation based approaches of CLIR. It is observed that dictionary based approach clubbed up with proper noun based pre-retrieval strategy performed better.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {11},
numpages = {10},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701646,
author = {Ganguly, Debasis and Leveling, Johannes and Jones, Gareth J. F.},
title = {DCU@Morpheme Extraction Task of FIRE-2012: Rule-Based Stemmers for Bengali and Hindi},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701646},
doi = {10.1145/2701336.2701646},
abstract = {For the participation of Dublin City University (DCU) in the FIRE-2012 Morpheme Extraction Task (MET), we investigated rule based stemming approaches for Bengali and Hindi IR. The MET task itself is an attempt to obtain a fair and direct comparison between various stemming algorithms by measuring the relative gains in retrieval effectiveness as obtained with each stemming algorithm on the same dataset. In our stemming approach, linguistic knowledge was used to manually craft the rules for removing the commonly occurring plural suffixes for Hindi and Bengali. Additionally, rules for removing classifiers and case markers in Bengali were also formulated. Our rule-based stemming algorithms produced the best and the second-best retrieval effectiveness for Hindi and Bengali datasets respectively.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {12},
numpages = {5},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701641,
author = {Jain, Anubha and Das, Sujoy},
title = {Hindi Stemmer @ FIRE-2013},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701641},
doi = {10.1145/2701336.2701641},
abstract = {This paper describes a language independent approach for extracting Hindi morpheme from a given list of Hindi words of Morpheme Extraction Task (MET) at FIRE 2013. In this approach list of Hindi word is submitted to the system and it generates stemmed Hindi root word from it. The proposed approach has shown an improvement of 3.40% over base-line result. The approach is applied on Hindi language but it may also be used for any other language due to its language independent nature.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {13},
numpages = {3},
keywords = {Morpheme, Prefixes, Stemmer, Suffixes},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701647,
author = {Senapati, Apurbalal and Das, Arjun and Garain, Utpal},
title = {Named-Entity Recognition in Bengali},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701647},
doi = {10.1145/2701336.2701647},
abstract = {This paper describes two systems for Named Entity Recognition (NER) and performance of two systems has been compared. The first system is a rule-based one whereas the second one is statistical (based on CRF) in nature. The systems vary in some other aspects too, for example, the first system works on untagged data (not even POS tag is done) to identify NER whereas the second system makes use of a POS tagger and a chunker. The rules used by the first system are mined from the training data. The CRF-based classification does not require any explicit linguistic rules but it uses a gazetteer built from Wiki and other sources.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {14},
numpages = {5},
keywords = {POS-Tagger, Chunker, Named Entity Recognition, Natural Language Processing},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701643,
author = {Ramrakhiyani, Nitin and Pawar, Sachin and Palshikar, Girish Keshav},
title = {A System for Classification of Propositions of the Indian Supreme Court Judgements},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701643},
doi = {10.1145/2701336.2701643},
abstract = {In this work, we describe a system for classification of propositions from legal judgements of the Supreme Court of India. The system was submitted for participation to the Information Access in the Legal Domain track at the Forum for Information Retrieval Evaluation (FIRE) 2013. The system uses a multi-class Maximum Entropy classifier and various specially designed features to capture the underlying characteristics of the legal propositions. The best performing feature set was chosen by 10-fold cross-validation over the training set. The system achieved an accuracy of 65.03% on the training set and an accuracy of 51.02% on the test set.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {15},
numpages = {4},
keywords = {legal proposition classification, legal text classification, text classification},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701645,
author = {Kanapala, Ambedkar and Pal, Sukomal},
title = {ISM@FIRE-2013 Information Access in The Legal Domain},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701645},
doi = {10.1145/2701336.2701645},
abstract = {This paper describes the work that we did as a participant in the task of Adhoc retrieval from legal documents (Consumer Law and Hindu Marriage &amp; Divorce Law) at FIRE 2013. We managed two runs using the Indri search retrieval system as official submission. However, post-submission, we experimented with ten different models using the TERRIER system. With the available qrels, we could evaluate only the runs pertaining to Consumer Law. Initial results have shown substantial improvement in retrieval performance. Our experimentation has also resulted in preparing a cookbook for optimal parameter-setting for a number of Terrier models. In Identification and Classification of Propositions in Court Judgment (parse each judgment into individual propositions), we have written a program which takes a single file as an input from the corpus and breaks the data of the given file into individual sentences. In summary, ours was a rich learning experience which needs to be continued to gain further insights. Also, we believe as pilot track, information access from legal domain is promising enough to be continued further as it has potential of being a fertile research area, specifically in Indian context.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {16},
numpages = {5},
keywords = {Information Retrieval, Adhoc retrieval, legal domain, evaluation},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

@inproceedings{10.1145/2701336.2701649,
author = {Prabhakar, Dinesh Kumar and Pal, Sukomal},
title = {ISM@FIRE-2013 Shared Task on Transliterated Search},
year = {2013},
isbn = {9781450328302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701336.2701649},
doi = {10.1145/2701336.2701649},
abstract = {This paper describes the approach we adopted during official submission of FIRE-2013 Shared Task on Transliterated Search along with few other approaches that we experimented post-submission. The techniques solve the problem of language labeling, by identifying query word as English or Hindi (E or H) term in mixed language sentence queries. Manual and machine learning algorithms are used. For the transliteration of H labeled word we use manual (dictionary based), generative (grapheme based) and combination of both in different algorithms. We observe that learning based classification improves labeling accuracy. Extraction based transliteration gives better result than Generation based when the terms are available in bilingual dictionary. But it may lead to incorrect transliteration if terms are wrongly aligned and the approach fails for out-of-dictionary words. In this case transliteration by generation is the only alternative. But generation alone does not perform well because of spelling variation in transliterated terms. During evaluation we also observe that transliteration systems are generally corpus-biased. Although our performance in the official submission was moderate, we obtain better results during our post-submission experiments.},
booktitle = {Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation},
articleno = {17},
numpages = {6},
keywords = {Word labeling, Text classification, Transliteration},
location = {New Delhi, India},
series = {FIRE '12 &amp; '13}
}

