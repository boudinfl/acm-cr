@inproceedings{10.5555/1885110.1885112,
author = {Peters, Carol},
title = {What Happened in CLEF 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The organization of the CLEF 2009 evaluation campaign is described and details are provided concerning the tracks, test collections, evaluation infrastructure, and participation. The aim is to provide the reader of these proceedings with a complete picture of the entire campaign, covering both text and multimedia retrieval experiments. In the final section, the main results achieved by CLEF in the first ten years of activity are discussed and plans for the future of CLEF are presented.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {1–12},
numpages = {12},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885114,
author = {Gonzalo, Julio and Peinado, V\'{\i}ctor and Clough, Paul and Karlgren, Jussi},
title = {Overview of ICLEF 2009: Exploring Search Behaviour in a Multilingual Folksonomy Environment},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper summarises activities from the iCLEF 2009 task. As in 2008, the task was organised based on users participating in an interactive cross-language image search experiment. Organizers provided a default multilingual search system (Flickling) which accessed images from Flickr, with the whole iCLEF experiment run as an online game. Interaction by users with the system was recorded in log files which were shared with participants for further analyses, and provide a future resource for studying various effects on user-orientated cross-language search. In total six groups participated in iCLEF with different approaches, ranging from pure log analysis to specific experiment designs using the Flickling interface.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {13–20},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885115,
author = {Peinado, V\'{\i}ctor and L\'{o}pez-Ostenero, Fernando and Gonzalo, Julio},
title = {Analysis of Multilingual Image Search Logs: Users' Behavior and Search Strategies},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we summarize the analysis performed on the logs of multilingual image search provided by iCLEF09 and its comparison with the logs released in the iCLEF08 campaign. We have processed more than one million log lines in order to identify and characterize 5, 243 individual search sessions. We focus on the analysis of users' behavior and their performance trying to find possible correlations between: a) the language skills of the users and the annotation language of the target images; and b) the final outcome of the search session. We have observed that the proposed task can be considered as easy, even though users with no competence in the annotation language of the images tend to perform more interactions and to use cross-language facilities more frequently. Usage of relevance feedback is remarkably low, but successful users use it more often.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {21–28},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885116,
author = {Navarro-Colorado, Borja and Puchol-Blasco, Marcel and Terol, Rafael M. and V\'{a}zquez, Sonia and Lloret, Elena},
title = {User Behaviour and Lexical Ambiguity in Cross-Language Image Retrieval},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Our objective in this paper is to determine the necessity of Word Sense Disambiguation in Information Retrieval tasks, according to user behaviour. We estimate and analyse the lexical ambiguity of queries in Cross-Language Image Retrieval (using search logs from a multilingual search interface for Flickr) and measure its correlation with search effectiveness. We show to what extent the lexical ambiguity of a query can influence the successful retrieval of an image in a multilingual framework.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {29–36},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885117,
author = {Ruiz, Miguel E. and Chin, Pok},
title = {Users' Image Seeking Behavior in a Multilingual Tag Environment},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper presents the results of a user study conducted in the framework of the Interactive Image Retrieval task at CLEF 2009. The main goal of our research is to understand the way in which users search for images that have been annotated with multilingual tags. The study is based on the application of grounded theory to try to understand the challenges that users face when searching for images that have multilingual annotations, and how they cope with these challenges to find the information they need. The study includes two methods of data collection: an online survey and a face to face interview that included a search task using Flickling. Because this was our first year participating in the interactive image CLEF, we found that the most challenging aspect of conducting a user centered evaluation in the context of CLEF is the short amount of time that is available from the time the task is defined and the deadline for submitting results. We were able to conduct face to face interviews for approximately three weeks (from 6/29/2009 to 7/17/2009) before the Flickling system was shut down. Our online survey was also made available at the end of June and we report here the results that we have collected until the end of November 2009. During this time we collected 27 responses to the online questionnaire and 6 face to face interviews. Our results indicate that 67% of the users search for images at least once a week and that the most common purposes for finding images are entertainment and professional. Our results from the user interviews indicate that the users find the known-item retrieval task hard to do due to the difficulty in expressing the contents of the target image using tags that could have also been assigned by the creator of the image. The face to face interviews also give some feedback for improving the current Flickling interface, particularly the addition of a spell checking mechanism and the improvement of the multilingual translation of terms selected by users.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {37–44},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885119,
author = {Paramita, Monica Lestari and Sanderson, Mark and Clough, Paul},
title = {Diversity in Photo Retrieval: Overview of the ImageCLEFPhoto Task 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The ImageCLEF Photo Retrieval Task 2009 focused on image retrieval and diversity. A new collection was utilised in this task consisting of approximately half a million images with English annotations. Queries were based on analysing search query logs and two different types were released: one containing information about image clusters; the other without. A total of 19 participants submitted 84 runs. Evaluation, based on Precision at rank 10 and Cluster Recall at rank 10, showed that participants were able to generate runs of high diversity and relevance. Findings show that submissions based on using mixed modalities performed best compared to those using only concept-based or content-based retrieval methods. The selection of query fields was also shown to affect retrieval performance. Submissions not using the cluster information performed worse with respect to diversity than those using this information. This paper summarises the ImageCLEFPhoto task for 2009.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {45–59},
numpages = {15},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885120,
author = {Tsikrika, Theodora and Kludas, Jana},
title = {Overview of the WikipediaMM Task at ImageCLEF 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {ImageCLEF's wikipediaMM task provides a testbed for the system-oriented evaluation of multimedia information retrieval from a collection of Wikipedia images. The aim is to investigate retrieval approaches in the context of a large and heterogeneous collection of images (similar to those encountered on the Web) that are searched for by users with diverse information needs. This paper presents an overview of the resources, topics, and assessments of the wikipediaMM task at ImageCLEF 2009, summarises the retrieval approaches employed by the participating groups, and provides an analysis of the main evaluation results.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {60–71},
numpages = {12},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885121,
author = {M\"{u}ller, Henning and Kalpathy-Cramer, Jayashree and Eggel, Ivan and Bedrick, Steven and Radhouani, Sa\"{\i}d and Bakke, Brian and Kahn, Charles E. and Hersh, William},
title = {Overview of the CLEF 2009 Medical Image Retrieval Track},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {2009 was the sixth year for the ImageCLEF medical retrieval task. Participation was strong again with 38 registered research groups. 17 groups submitted runs and thus participated actively in the tasks. The database in 2009 was similar to the one used in 2008, containing scientific articles from two radiology journals, Radiology and Radiographics. The size of the database was increased to a total of 74,902 images. For the first time, 5 case-based topics were provided as an exploratory task. These topics' unit of retrieval was intended to be the source article and not the image itself. Case-based topics are designed to be closer to the clinical workflow, as clinicians often seek information about patient cases using incomplete information consisting of symptoms, findings, and a set of images. Supplying cases to a clinician from the scientific literature that are similar to the case (s)he is treating models what may become an important application of image retrieval in the future.We also introduced a lung nodule detection task in 2009. This task used the CT slices from the Lung Imaging Data Consortium (LIDC) includeding ground truth in the from of manual annotations. The goal of this task was to create algorithms to automatically detect lung nodules. Although there seemed to be significant interest in the task only two groups submitted results with a proprietary software from an industry participant achieving very good results.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {72–84},
numpages = {13},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885122,
author = {Tommasi, Tatiana and Caputo, Barbara and Welter, Petra and G\"{u}ld, Mark Oliver and Deserno, Thomas M.},
title = {Overview of the CLEF 2009 Medical Image Annotation Track},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper describes the last round of the medical image annotation task in ImageCLEF 2009. After four years, we defined the task as a survey of all the past experience. Seven groups participated to the challenge submitting nineteen runs. They were asked to train their algorithms on 12677 images, labelled according to four different settings, and to classify 1733 images in the four annotation frameworks. The aim is to understand how each strategy answers to the increasing number of classes and to the unbalancing. A plain classification scheme using support vector machines and local descriptors outperformed the other methods.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {85–93},
numpages = {9},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885123,
author = {Nowak, Stefanie and Dunker, Peter},
title = {Overview of the CLEF 2009 Large-Scale Visual Concept Detection and Annotation Task},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The Large-Scale Visual Concept Detection and Annotation Task (LS-VCDT) in ImageCLEF 2009 aims at the detection of 53 concepts in consumer photos. These concepts are structured in an ontology which can be utilized during training and classification of the photos. The dataset consists of 18,000 Flickr photos which were manually annotated with 53 concepts. 5,000 photos were used for training and 13,000 for testing. Two evaluation paradigms have been applied, the evaluation per concept and the evaluation per photo. The evaluation per concept was performed by calculating the Equal Error Rate (EER) and the Area Under Curve (AUC). For the evaluation per photo a recently proposed ontology-based measure was utilized that takes the hierarchy and the relations of the ontology into account and calculates a score per photo. Altogether 19 research groups participated and submitted 73 runs. For the concepts, an average AUC of 84% could be achieved, including concepts with an AUC of 95%. The classification performance for each photo ranged between 68.7% and 100% with an average score of 89.6%.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {94–109},
numpages = {16},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885124,
author = {Pronobis, Andrzej and Xing, Li and Caputo, Barbara},
title = {Overview of the CLEF 2009 Robot Vision Track},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The robot vision track has been proposed to the ImageCLEF participants for the first time in 2009 and attracted considerable attention. The track addressed the problem of visual place recognition applied to robot topological localization. Participants were asked to classify rooms of an office environment on the basis of image sequences captured by a perspective camera mounted on a mobile robot. The algorithms proposed by the participants had to answer the question "where are you?" (I am in the kitchen, in the corridor, etc) when presented with a test sequence imaging rooms seen during training, or additional rooms that were not imaged in the training sequence. The participants were asked to solve the problem separately for each test image (obligatory task). Additionally, results could also be reported for algorithms exploiting the temporal continuity of the image sequences (optional task). Robustness of the algorithms was evaluated in presence of variations introduced by changing illumination conditions and dynamic variations observed across a time span of almost two years. The participants submitted 18 runs to the obligatory task, and 9 to the optional task. The best results were obtained by the Idiap Research Institute, Martigny, Switzerland for the obligatory task and the University of Castilla-La Mancha, Albacete, Spain for the optional task.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {110–119},
numpages = {10},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885126,
author = {Navarro, Sergio and Mu\~{n}oz, Rafael and Llopis, Fernando},
title = {Diversity Promotion: Is Reordering Top-Ranked Documents Sufficient?},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In our participation in the ImageCLEF 2009 Photo Retrieval task we pursued two objectives: Firstly, to re-evaluate MultiModal Local Context Analysis (MMLCA), our multimodal fusion technique. Secondly, to evaluate a new subquery generation technique based on clustering. From the experiments conducted: Firstly, we confirmed MMLCA performs better for generic domain collections than the other local expansion techniques evaluated. Secondly, our proposal of subquery generation based on clustering, obtained good results (5th best textual run of the Photo Retrieval task). Besides these results in this paper we try to reflect on the extent to which reordering techniques are appropriate to promote diversity. Results suggest that while reordering strategies limit the margin of improvement due to their use of a limited number of documents, the use of approaches based on subqueries generation can overcome this limitation.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {120–123},
numpages = {4},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885127,
author = {Ah-Pine, Julien and Clinchant, Stephane and Csurka, Gabriela},
title = {Comparison of Several Combinations of Multimodal and Diversity Seeking Methods for Multimedia Retrieval},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The aim of this paper is to analyze the technologies designed and used in the context of XRCE's participation in the Photo Retrieval Task of ImageCLEF 2009 [1]. We evaluate and compare different mono and multimedia retrieval methods and two distinct diversity-seeking strategies as well. Our analysis allows us to better understand which combinations of basic approaches are the best ones. It appears that taking advantage of the multimodal nature of the data by means of our cross-modal similarities technique and leveraging different text representations of the topics in the goal of covering distinct related subtopics, allow us to tackle the Photo Retrieval Task effectively.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {124–132},
numpages = {9},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885128,
author = {Leelanupab, Teerapong and Zuccon, Guido and Goyal, Anuj and Halvey, Martin and Punitha, P. and Jose, Joemon M.},
title = {University of Glasgow at ImageCLEFPhoto 2009: Optimising Similarity and Diversity in Image Retrieval},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we describe the approaches adopted to generate the runs submitted to ImageCLEFPhoto 2009 with an aim to promote document diversity in the rankings. Four of our runs are text based approaches that employ textual statistics extracted from the captions of images, i.e. MMR [1] as a state of the art method for result diversification, two approaches that combine relevance information and clustering techniques, and an instantiation of Quantum Probability Ranking Principle. The fifth run exploits visual features of the provided images to rerank the initial results by means of Factor Analysis. The results reveal that our methods based on only text captions consistently improve the performance of the respective baselines, while the approach that combines visual features with textual statistics shows lower levels of improvements.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {133–141},
numpages = {9},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885129,
author = {Garc\'{\i}a-Serrano, Ana and Benavent, Xaro and Granados, Ruben and De Ves, Esther and Go\~{n}i, Jos\'{e} Miguel},
title = {Multimedia Retrieval by Means of Merge of Results from Textual and Content Based Retrieval Subsystems},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The main goal of this paper it is to present our experiments in ImageCLEF 2009 Campaign (photo retrieval task). In 2008 we proved empirically that the Text-based Image Retrieval (TBIR) methods defeats the Content-based Image Retrieval CBIR "quality" of results, so this time we developed several experiments in which the CBIR helps the TBIR. The TBIR System [6] main improvement is the named-entity sub-module. In case of the CBIR system [3] the number of low-level features has been increased from the 68 component used at ImageCLEF 2008 up to 114 components, and only the Mahalanobis distance has been used. We propose an ad-hoc management of the topics delivered, and the generation of XML structures for 0.5 million captions of the photographs (corpus) delivered. Two different merging algorithms were developed and the third one tries to improve our previous cluster level results promoting the diversity. Our best run for precision metrics appeared in position 16th, in the 19th for MAP score, and for diversity value in position 11th, for a total of 84 submitted experiments. Our best and "only textual" experiment was the 6th one over 41.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {142–149},
numpages = {8},
keywords = {indexing, information retrieval, fusion, content-based image retrieval, textual-based retrieval, merge results lists},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885130,
author = {El Demerdash, Osama and Bergler, Sabine and Kosseim, Leila},
title = {Image Query Expansion Using Semantic Selectional Restriction},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper describes our participation at ImageCLEF 2009. We participated in the photographic retrieval task (ImageCLEFPhoto). Our method is based on cross-media pseudo-relevance feedback. We have enhanced the pseudo-relevance feedback mechanism by using semantic selectional restrictions. We use Terrier for text retrieval and our own simple block-based visual retrieval engine. The results obtained at ImageCLEF 2009 show that our method is robust and promising. However, there is room for improvement on the visual retrieval.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {150–156},
numpages = {7},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885131,
author = {Zhu, Qian and Inkpen, Diana},
title = {Clustering for Text and Image-Based Photo Retrieval at CLEF 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {For this year's Image CLEF Photo Retrieval task, we investigated the effectiveness of 1) image content-based retrieval, 2) text-based retrieval, and 3) integrated text and image retrieval. We investigated whether the clustering of results can increase diversity by returning as many different clusters of images in the results as possible. Our image system used the FIRE engine to extract image features such as color, texture, and shape from a data collection consisting of about half a million images. The text-retrieval backend used Lucene to extract texts from image annotations, title, and cluster tags. Our results revealed that among the three image features, color yields the highest retrieval precision, followed by shape, then texture. A combination of color extraction with text retrieval increased precision, but only to a certain extent. Clustering also improved diversity, only in our text-based clustering runs.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {157–163},
numpages = {7},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885133,
author = {Moulin, Christophe and Barat, C\'{e}cile and Lema\^{\i}tre, C\'{e}dric and G\'{e}ry, Mathias and Ducottet, Christophe and Largeron, Christine},
title = {Combining Text/Image in WikipediaMM Task 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper reports our multimedia information retrieval experiments carried out for the ImageCLEF Wikipedia task 2009. We extend our previous multimedia model defined as a vector of textual and visual information based on a bag of words approach [6]. We extract additional textual information from the original Wikipedia articles and we compute several image descriptors (local colour and texture features). We show that combining linearly textual and visual information significantly improves the results.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {164–171},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885134,
author = {Min, Jinming and Wilkins, Peter and Leveling, Johannes and Jones, Gareth J. F.},
title = {Document Expansion for Text-Based Image Retrieval at CLEF 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we describe and analyze our participation in the WikipediaMM task at CLEF 2009. Our main efforts concern the expansion of the image metadata from the Wikipedia abstracts collection - DBpedia. In our experiments, we use the Okapi feedback algorithm for document expansion. Compared with our text retrieval baseline, our best document expansion RUN improves MAP by 17.89%. As one of our conclusions, document expansion from external resource can play an effective factor in the image metadata retrieval task.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {172–176},
numpages = {5},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885135,
author = {Myoupo, D\'{e}bora and Popescu, Adrian and Le Borgne, Herv\'{e} and Mo\"{e}llic, Pierre-Alain},
title = {Multimodal Image Retrieval over a Large Database},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We introduce a new multimodal retrieval technique which combines query reformulation and visual image reranking in order to deal with results sparsity and imprecision, respectively. Textual queries are reformulated using Wikipedia knowledge and results are then reordered using a k-NN based reranking method. We compare textual and multimodal retrieval and show that introducing visual reranking results in a significant improvement of performance.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {177–184},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885136,
author = {D\'{\i}az-Galiano, Manuel Carlos and Mart\'{\i}n-Valdivia, Mar\'{\i}a Teresa and Ure\~{n}a-L\'{o}pez, L. Alfonso and Perea-Ortega, Jos\'{e} Manuel},
title = {Using WordNet in Multimedia Information Retrieval},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This work investigates the use of external knowledge in a corpus with minimal textual information. We have expanded the original collection with WordNet terms in order to enrich the information included in this corpus. In addition, we have have carried out experiments with original and expanded topics. However, the obtained results show that it is necessary to continue investigating the expansion methodology. The query expansion does not improve the results, although using only the expansion for the corpus slightly achieves better MAP.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {185–188},
numpages = {4},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885138,
author = {Arafa, Waleed and Ibrahim, Ragia},
title = {Medical Image Retrieval: ISSR at CLEF 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper represents the first participation of the Institute of Statistical Studies and Research (ISSR) at Cairo University group in CLEF 2009-Medical image retrieval track. The main objective is to improve retrieving medical image depending on associated image text. The other purpose of our participation is to experiment different text features such as article title, image caption and article paragraphs denoting to the image. We propose a simple and effective extraction method to find relevant paragraphs based on the structure of HTML files. Automatic translation of queries in different languages other than collection language is also experimented. For indexing and retrieval, we used the LEMUR toolkit. In this paper the results of 9 runs are submitted in order to compare retrieval based on different text features, as well as the effect of stop word lists and the use of relevance feedback.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {189–194},
numpages = {6},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885139,
author = {Ye, Zheng and Huang, Xiangji and Hu, Qinmin and Lin, Hongfei},
title = {An Integrated Approach for Medical Image Retrieval through Combining Textual and Visual Features},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we present an empirical study for monolingual medical image retrieval. In particular, we present a series of experiments in ImageCLEFmed 2009 task. There are three main goals. First, we evaluate traditional well-known weighting models in the text retrieval domain, such as BM25, TFIDF and Language Model (LM), for context-based image retrieval. Second, we evaluate statistical-based feedback models and ontology-based feedback models. Third, we investigate how content-based image retrieval can be integrated with these two basic technologies in traditional text retrieval domain. The experimental results have shown that: 1) traditional weighting models work well in context-based medical image retrieval task especially when the parameters are tuned properly; 2) statistical-based feedback models can further improve the retrieval performance when a small number of documents are used for feedback; however, the medical image retrieval can not benefit from ontology-based query expansion method used in this paper; 3) the retrieval performance can be slightly boosted via an integrated retrieval approach.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {195–202},
numpages = {8},
keywords = {ontologies, CBIR, MeSH, weighting model, visual and textual retrieval, pseudo relevance feedback},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885140,
author = {Maisonnasse, Lo\"{\i}c and Harrathi, Farah and Roussey, Catherine and Calabretto, Sylvie},
title = {Analysis Combination and Pseudo Relevance Feedback in Conceptual Language Model: LIRIS Participation at ImageCLEFmed},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper presents the LIRIS contribution to the CLEF 2009 medical retrieval task (i.e. ImageCLEFmed). Our model makes use of the textual part of the corpus and of the medical knowledge found in the Unified Medical Language System (UMLS) knowledge sources. As proposed in [6] last year, we used a conceptual representation for each sentence and we proposed a language modeling approach. We test two versions of conceptual unigram language model; one that use the log-probability of the query and a second one that compute the Kullback-Leibler divergence. We used different concept detection methods and we combine these detection methods on queries and documents. This year we mainly test the impact of the use of additional analysis on queries. We also test combinations on French queries where we combine translation and analysis, in order to solve the lack of French terms in UMLS, this provide good results close from the English ones. To complete these combinations we proposed a pseudo relevance method. This approach use the n first retrieve documents to form one pseudo query that is used in the Kullback-Leibler model to complete the original query. The results of this approach show that extending the queries with such an approach improves the results.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {203–210},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885141,
author = {Zhou, Xin and Eggel, Ivan and M\"{u}ller, Henning},
title = {The MedGIFT Group at ImageCLEF 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {MedGIFT is a medical imaging group of the Geneva University Hospitals and the University of Geneva, Switzerland. Since 2004, the group has participated ImageCLEF each year, focusing on the medical imaging tasks. For the medical image retrieval task, two existing retrieval engines were used: the GNU Image Finding Tool (GIFT) for visual retrieval and Apache Lucene for text. Various strategies were applied to improve the retrieval performance. In total, 16 runs were submitted, 10 for the image-based topics and 6 for the case-based topics. The base-line GIFT setup used for the past three years obtained the best results among all our submissions.For medical image annotation two approaches were tested. One approach is using GIFT for retrieval and kNN (k-Nearest Neighbors) for classification. The second approach used the Scale-Invariant Feature Transform (SIFT) with a Support VectorMachine (SVM) classifier. Three runs were submitted, two with the GIFT-kNN approach and one using the common results of the two approaches. The GIFT-kNN approach gave stable results. The SIFT-SVM approach did not achieve the expected performance, most likely due to the SVM Kernel used that was not optimized.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {211–218},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885142,
author = {Berber, Tolga and Alpkocak, Adil},
title = {An Extended Vector Space Model for Content-Based Image Retrieval},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper describes participation of Dokuz Eylul University to the ImageCLEF2009Med task. This year, we proposed a new model for content-based image retrieval combining both textual and visual information in the same space. It simply extends traditional vector space model of text retrieval with visual terms. The proposed model also supports to close the semantic gap problem of content-based image retrieval. Experiments showed that our proposed system improves the performance of textual retrieval methods by adding visual terms. The proposed method was evaluated on the ImageCLEFmed 2009 dataset and it was ranked the best performance among the participants in automatic mixed retrieval including both text and visual features.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {219–222},
numpages = {4},
keywords = {visual terms, vector space model, content-based image retrieval, semantic gap},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885143,
author = {Radhouani, Sa\"{\i}d and Kalpathy-Cramer, Jayashree and Bedrick, Steven and Bakke, Brian and Hersh, William},
title = {Using Media Fusion and Domain Dimensions to Improve Precision in Medical Image Retrieval},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we focus on improving retrieval performance, especially early precision, in the task of solving medical multimodal queries. The queries we deal with consist of a visual component, given as a set of image-examples, and textual annotation, provided as a set of words. The queries' semantic content can be classified along three domain dimensions: anatomy, pathology, and modality. To solve these queries, we interpret their semantic content using both textual and visual data. Medical images often are accompanied by textual annotations, which in turn typically include explicit mention of their image's anatomy or pathology. Annotations rarely include explicit mention of image modality, however. To address this, we use an image's visual features to identify its modality. Our system thereby performs image retrieval by combining purely visual information about an image with information derived from its textual annotations. In order to experimentally evaluate our approach, we performed a set of experiments using the 2009 ImageCLEFmed collection using our integrated system as well as a purely textual retrieval system. Our integrated approach consistently outperformed our text-only system by 43% in MAP and by 71% in precision within the top 5 retrieved documents. We conclude that this improved performance is due to our method of combining visual and textual features.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {223–230},
numpages = {8},
keywords = {performance evaluation, medical image retrieval, media fusion, image classification, image modality extraction, domain dimensions},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885145,
author = {Dimitrovski, Ivica and Kocev, Dragi and Loskovska, Suzana and D\v{z}eroski, Sa\v{s}o},
title = {ImageCLEF 2009 Medical Image Annotation Task: PCTs for Hierarchical Multi-Label Classification},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we describe an approach to the automatic medical image annotation task of the 2009 CLEF cross-language image retrieval campaign (ImageCLEF). This work focuses on the process of feature extraction from radiological images and their hierarchical multi-label classification. To extract features from the images we use two different techniques: edge histogram descriptor (EHD) and Scale Invariant Feature Transform (SIFT) histogram. To annotate the images, we use predictive clustering trees (PCTs) which are able to handle target concepts that are organized in a hierarchy, i.e., perform hierarchical multi-label classification. Furthermore, we construct ensembles (Bagging and Random Forests) that use PCTs as base classifiers: this improves the predictive/ classification performance.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {231–238},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885146,
author = {Avni, Uri and Greenspan, Hayit and Goldberger, Jacob},
title = {Dense Simple Features for Fast and Accurate Medical X-Ray Annotation},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We present a simple, fast and accurate image categorization system, applied to medical image databases within the ImageCLEF 2009 medical annotation task. The methodology presented is based on local representation of the image content, using a bag of visual words approach in multiple scales, with a kernel based SVM classifier. The system was ranked first in this challenge, with total error score of 852.8.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {239–246},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885147,
author = {Unay, Devrim and Soldea, Octavian and Ozogur-Akyuz, Sureyya and Cetin, Mujdat and Ercil, Aytul},
title = {Automated X-Ray Image Annotation: Single versus Ensemble of Support Vector Machines},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Advances in the medical imaging technology has lead to an exponential growth in the number of digital images that needs to be acquired, analyzed, classified, stored and retrieved in medical centers. As a result, medical image classification and retrieval has recently gained high interest in the scientific community. Despite several attempts, such as the yearly-held ImageCLEF Medical Image Annotation Challenge, the proposed solutions are still far from being sufficiently accurate for real-life implementations.In this paper we summarize the technical details of our experiments for the ImageCLEF 2009 medical image annotation challenge. We use a direct and two ensemble classification schemes that employ local binary patterns as image descriptors. The direct scheme employs a single SVM to automatically annotate X-ray images. The two proposed ensemble schemes divide the classification task into sub-problems. The first ensemble scheme exploits ensemble SVMs trained on IRMA sub-codes. The second learns from subgroups of data defined by frequency of classes. Our experiments show that ensemble annotation by training individual SVMs over each IRMA sub-code dominates its rivals in annotation accuracy with increased process time relative to the direct scheme.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {247–254},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885149,
author = {Gao, Yan and Li, Yiqun},
title = {Topological Localization of Mobile Robots Using Probabilistic Support Vector Classification},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Topologically localizing a mobile robot using visual information alone is a difficult problem. We propose a localization system that comprises Gaussian derivatives as raw local descriptors, a three-tier spatial pyramid of histograms as the image descriptor, and probabilistic multi-class support vector machines for classification. Based on the probability estimate, the proposed system is able to predict the unknown class which corresponds to locations that are not imaged in the training sequence. To exploit the continuity of the sequence, a smoothing procedure can be applied, which is shown to be simple yet effective.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {255–260},
numpages = {6},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885150,
author = {Van De Sande, Koen E. A. and Gevers, Theo and Smeulders, Arnold W. M.},
title = {The University of Aamsterdam's Concept Detection System at ImageCLEF 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Our group within the University of Amsterdam participated in the large-scale visual concept detection task of ImageCLEF 2009. Our experiments focus on increasing the robustness of the individual concept detectors based on the bag-of-words approach, and less on the hierarchical nature of the concept set used. To increase the robustness of individual concept detectors, our experiments emphasize in particular the role of visual sampling, the value of color invariant features, the influence of codebook construction, and the effectiveness of kernel-based learning parameters. The participation in ImageCLEF 2009 has been successful, resulting in the top ranking for the large-scale visual concept detection task in terms of both EER and AUC. For 40 out of 53 individual concepts, we obtain the best performance of all submissions to this task. For the hierarchical evaluation, which considers the whole hierarchy of concepts instead of single detectors, using the concept likelihoods estimated by our detectors directly works better than scaling these likelihoods based on the class priors.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {261–268},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885151,
author = {Binder, Alexander and Kawanabe, Motoaki},
title = {Enhancing Recognition of Visual Concepts with Primitive Color Histograms via Non-Sparse Multiple Kernel Learning},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In order to achieve good performance in image annotation tasks, it is necessary to combine information from various image features. In recent competitions on photo annotation, many groups employed the bag-of-words (BoW) representations based on the SIFT descriptors over various color channels. In fact, it has been observed that adding other less informative features to the standard BoW degrades recognition performances. In this contribution, we will show that even primitive color histograms can enhance the standard classifiers in the ImageCLEF 2009 photo annotation task, if the feature weights are tuned optimally by non-sparse multiple kernel learning (MKL) proposed by Kloft et al.. Additionally, we will propose a sorting scheme of image subregions to deal with spatial variability within each visual concept.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {269–276},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885152,
author = {Boro&amp;scedil, Emanuela and Ro\c{s}ca, George and Iftene, Adrian},
title = {Using SIFT Method for Global Topological Localization for Indoor Environments},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The paper represents a brief description of our system as one of the solutions to the problem of global topological localization for indoor environments. The experiment involves analyzing images acquired with a perspective camera mounted on a robot platform and applying a feature-based method (SIFT) and two main systems in order to search and classify the given images. To obtain acceptable results and improved performance improvement, the algorithm acquires two main maturity levels: one capable of running in real-time and taking care of the computers' resources and the other one capable of classifying correctly the input images. One of the principal benefits of the developed system is a server-client architecture that brings efficiency to the table along with statistical methods that improve the quality of data with their design.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {277–282},
numpages = {6},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885153,
author = {Iftene, Adrian and Vamanu, Loredana and Croitoru, Cosmina},
title = {UAIC at ImageCLEF 2009 Photo Annotation Task},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, UAIC system participating in the ImageCLEF 2009 Photo Annotation task is described. The UAIC team's debut in the ImageCLEF competition has enriched us with the experience of developing the first system for the Photo Annotation task, paving the way for subsequent ImageCLEF participations. Evaluation of the used modules shown that there is more work to capture as many possible situations.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {283–286},
numpages = {4},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885154,
author = {Ngiam, Jiquan and Goh, Hanlin},
title = {Learning Global and Regional Features for Photo Annotation},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper describes a method that learns a variety of features to perform photo annotation. We introduce concept-specific regional features and combine them with global features. The regional features were extracted through a novel region selection algorithm based on Multiple Instance Learning. Supervised classification for photo annotation was learned using Support Vector Machines with extended Gaussian Kernels over the χ2 distance, together with a simple greedy feature selection. The method was evaluated using the ImageCLEF 2009 Photo Annotation task and competitive benchmarking results were achieved.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {287–290},
numpages = {4},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885155,
author = {Fakeri-Tabrizi, Ali and Tollari, Sabrina and Usunier, Nicolas and Gallinari, Patrick},
title = {Improving Image Annotation in Imbalanced Classification Problems with Ranking SVM},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We try to overcome the imbalanced data set problem in image annotation by choosing a convenient loss function for learning the classifier. Instead of training a standard SVM, we use a Ranking SVM in which the chosen loss function is helpful in the case of imbalanced data. We compare the Ranking SVM to a classical SVM with different visual features. We observe that Ranking SVM always improves the prediction quality, and can perform up to 23% better than the classical SVM.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {291–294},
numpages = {4},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885156,
author = {Feng, Yue and Halvey, Martin and Jose, Joemon M.},
title = {University of Glasgow at ImageCLEF 2009 Robot Vision Task: A Rule Based Approach},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {For the submission from the University of Glasgow for the Image-CLEF 2009 Robot Vision Task a large set of interesting points were extracted using an edge corner detector, these points were used to represent each image. The RANSAC method [1] was then applied to estimate the similarity between test and training images based on the number of matched pairs of points. The location of robot was then annotated based on the training image which contains the highest number of matched point pairs with the test image. A set of decision rules with the respect to the trajectory behaviour of robot's motion were defined to refine the final results. An illumination filter was also applied for two of the runs in order to reduce the illumination effect.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {295–298},
numpages = {4},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885157,
author = {Dumont, Emilie and Glotin, Herv\'{e} and Paris, S\'{e}bastien and Zhao, Zhong-Qiu},
title = {A Fast Visual Word Frequency - Inverse Image Frequency for Detector of Rare Concepts},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we propose an original image retrieval model inspired from the vector space information retrieval model. We build for different features and different scales a visual concept dictionary composed by visual words intended to represent a semantic concept, and then we represent an image by the frequency of the visual words within the image. Then the image similarity is computed as in the textual domain where a textual document is represented by a vector in which each component is the frequency of occurrence of a specific textual word in that document. We then adapt the common text-based paradigm by using the TF-IDF weighting scheme to construct a WF-IIF weighting scheme in our Multi-Scale Visual Dictionary (MSVD) vector space model.The experiments are conducted on the 2009 Visual Concept Detection ImageCLEF Campaign. We compare WF-IIF to usual direct Support-Vector Machine (SVM) algorithm. We demonstrate that SVM and WFIIF are in average over all the concept giving the same Area Under the Curve (AUC). We then discuss the fusion process that should enhance the whole system, and of some particular properties of MSVD, that shall be less dependant of the training set size of each concept than the SVM.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {299–306},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885158,
author = {Llorente, Ainhoa and Motta, Enrico and R\"{u}ger, Stefan},
title = {Exploring the Semantics behind a Collection to Improve Automated Image Annotation},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The goal of this research is to explore several semantic relatedness measures that help to refine annotations generated by a base-line non-parametric density estimation algorithm. Thus, we analyse the benefits of performing a statistical correlation using the training set or using the World Wide Web versus approaches based on a thesaurus like WordNet or Wikipedia (considered as a hyperlink structure). Experiments are carried out using the dataset provided by the 2009 edition of the ImageCLEF competition, a subset of the MIR-Flickr 25k collection. Best results correspond to approaches based on statistical correlation as they do not depend on a prior disambiguation phase like WordNet and Wikipedia. Further work needs to be done to assess whether proper disambiguation schemas might improve their performance.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {307–314},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885159,
author = {Xing, Li and Pronobis, Andrzej},
title = {Multi-Cue Discriminative Place Recognition},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we report on our successful participation in the RobotVision challenge in the ImageCLEF 2009 campaign. We present a place recognition system that employs four different discriminative models trained on different global and local visual cues. In order to provide robust recognition, the outputs generated by the models are combined using a discriminative accumulation method. Moreover, the system is able to provide an indication of the confidence of its decision. We analyse the properties and performance of the system on the training and validation data and report the final score obtained on the test run which ranked first in the obligatory track of the RobotVision task.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {315–323},
numpages = {9},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885160,
author = {Pham, Trong-Ton and Maisonnasse, Lo\"{\i}c and Mulhem, Philippe and Chevallet, Jean-Pierre and Qu\'{e}not, Georges and Al Batal, Rami},
title = {MRIM-LIG at ImageCLEF 2009: Robotvision, Image Annotation and Retrieval Tasks},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper describes mainly the experiments that have been conducted by the MRIM group at the LIG in Grenoble for the the ImageCLEF 2009 campaign, focusing on the work done for the Robotvision task. The proposal for this task is to study the behaviour of a generative approach inspired by the language model of information retrieval. To fit with the specificity of the Robotvision task, we added post-processing in a way to tackle with the fact that images do belong only to several classes (rooms) and that image are not independent from each others (i.e., the robot cannot in one second be in three different rooms). The results obtained still need improvement, but the use of such language model in the case of Robotvision is showed. Some results related to the Image Retrieval task and the Image annotation task are also presented.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {324–331},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885162,
author = {Eggel, Ivan and M\"{u}ller, Henning},
title = {The ImageCLEF Management System},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The ImageCLEF image retrieval track has been part of CLEF (Cross Language Evaluation Forum) since 2003. Organizing ImageCLEF and its large participation of research groups involves a considerable amount of work and data to manage. Goal of the management system described in this paper was to create a system for the organization of ImageCLEF to reduce manual work and professionalize the structures. All ImageCLEF sub tracks having a page in a single run submission system reduces work of organizers and makes submissions easier for participants. The system was developed as a web application using Java and JavaServer Faces (JSF) on Glassfish with a Postgres 8.3 database. The main functionality consists of user, collection and subtrack management as well as run submissions. The system has two main user groups, participants and administrators. The main task for participants is to register for subtasks and then submit runs. Administrators create collections for the sub tasks and can define the data and constraints for submissions. The described system was used for ImageCLEF 2009 with 86 subscribed users and more than 300 submitted runs in 7 subtracks. The system has proved to significantly reduce manual work and will be used for upcoming ImageCLEF events and other evaluation campaigns.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {332–339},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885163,
author = {Dar\'{o}czy, B\'{a}lint and Petr\'{a}s, Istv\'{a}n and Bencz\'{u}r, Andr\'{a}s A. and Fekete, Zsolt and Nemeskey, D\'{a}vid and Sikl\'{o}si, D\'{a}vid and Weiner, Zsuzsa},
title = {Interest Point and Segmentation-Based Photo Annotation},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Our approach to the ImageCLEF 2009 tasks is based on image segmentation, SIFT keypoints and Okapi BM25-based text retrieval. We use feature vectors to describe the visual content of an image segment, a keypoint or the entire image. The features include color histograms, a shape descriptor as well as a 2D Fourier transform of a segment and an orientation histogram of detected keypoints. We trained a Gaussian Mixture Model (GMM) to cluster the feature vectors extracted from the image segments and keypoints independently. The normalized Fisher gradient vector computed from GMM of SIFT descriptors is a well known technique to represent an image with only one vector. Novel to our method is the combination of Fisher vectors for keypoints with those of the image segments to improve classification accuracy. We introduced correlation-based combining methods to further improve classification quality.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {340–347},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885164,
author = {Garc\'{\i}a-Cumbreras, Miguel A. and D\'{\i}az-Galiano, Manuel Carlos and Mart\'{\i}n-Valdivia, Mar\'{\i}a Teresa and Montejo-Raez, Arturo and Ure\~{n}a-L\'{o}pez, L. Alfonso},
title = {University of Ja\'{e}n at ImageCLEF 2009: Medical and Photo Tasks},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This papers describes the participation of the SINAI research group in the medical and photo retrieval ImageCLEF tasks. The approach for medical retrieval continues our usage of the MeSH ontology for query expansion, but comparing it to term expansion within the documents in the collection. Regarding the photo retrieval task, diversity of top results has been pursued by applying a clustering algorithm. For both tasks, results and dicussion are included. In general, no relevant findings were obtained with the novel approaches applied.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {348–353},
numpages = {6},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885166,
author = {Larson, Martha and Newman, Eamonn and Jones, Gareth J. F.},
title = {Overview of VideoCLEF 2009: New Perspectives on Speech-Based Multimedia Content Enrichment},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {VideoCLEF 2009 offered three tasks related to enriching video content for improved multimedia access in a multilingual environment. For each task, video data (Dutch-language television, predominantly documentaries) accompanied by speech recognition transcripts were provided. The Subject Classification Task involved automatic tagging of videos with subject theme labels. The best performance was achieved by approaching subject tagging as an information retrieval task and using both speech recognition transcripts and archival metadata. Alternatively, classifiers were trained using either the training data provided or data collected from Wikipedia or via general Web search. The Affect Task involved detecting narrative peaks, defined as points where viewers perceive heightened dramatic tension. The task was carried out on the "Beeldenstorm" collection containing 45 short-form documentaries on the visual arts. The best runs exploited affective vocabulary and audience directed speech. Other approaches included using topic changes, elevated speaking pitch, increased speaking intensity and radical visual changes. The Linking Task, also called "Finding Related Resources Across Languages," involved linking video to material on the same subject in a different language. Participants were provided with a list of multimedia anchors (short video segments) in the Dutch-language "Beeldenstorm" collection and were expected to return target pages drawn from English-language Wikipedia. The best performing methods used the transcript of the speech spoken during the multimedia anchor to build a query to search an index of the Dutch-language Wikipedia. The Dutch Wikipedia pages returned were used to identify related English pages. Participants also experimented with pseudo-relevance feedback, query translation and methods that targeted proper names.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {354–368},
numpages = {15},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885167,
author = {Dobril\u{a}, Tudor-Alexandru and Diacona\c{s}u, Mihail-Ciprian and Lungu, Irina-Diana and Iftene, Adrian},
title = {Methods for Classifying Videos by Subject and Detecting Narrative Peak Points},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {2009 marked UAIC's first participation at the VideoCLEF evaluation campaign. Our group built two separate systems for the "Subject Classification" and "Affect Detection" tasks. For the first task we created two resources starting from Wikipedia pages and pages identified with Google and used two tools for classification: Lucene and Weka. For the second task we extracted the audio component from a given video file, using FFmpeg. After that, we computed the average amplitude for each word from the transcript, by applying the Fast Fourier Transform algorithm in order to analyze the sound. A brief description of our systems' components is given in this paper.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {369–372},
numpages = {4},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885168,
author = {Perea-Ortega, Jos\'{e} Manuel and Montejo-R\'{a}ez, Arturo and Mart\'{\i}n-Valdivia, Mar\'{\i}a Teresa and Ure\~{n}a-L\'{o}pez, L. Alfonso},
title = {Using Support Vector Machines as Learning Algorithm for Video Categorization},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper describes a supervised learning approach to classify Automatic Speech Recognition (ASR) transcripts from videos. A training collection was generated using the data provided by the Video-CLEF 2009 framework. These data contained metadata files about videos. The Support Vector Machines (SVM) learning algorithm was used in order to evaluate two main experiments: using the metadata files for generating the training corpus and without using them. The obtained results show the expected increase in precision due to the use of metadata in the classification of the test videos.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {373–376},
numpages = {4},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885169,
author = {K\"{u}rsten, Jens and Eibl, Maximilian},
title = {Video Classification as IR Task: Experiments and Observations},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper describes experiments we conducted in conjunction with the VideoCLEF 2009 classification task. In our second participation in the task we experimented with treating classification as an IR problem and used the Xtrieval framework [1] to run our experiments. We confirmed that the IR approach achieves strong results although the data set was changed. We proposed an automatic threshold to limit the number of labels per document. Query expansion performed better than the corresponding baseline experiments in terms of mean average precision. We also found that combining the ASR transcriptions and the archival metadata improved the classification performance unless query expansion was used.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {377–384},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885170,
author = {Larson, Martha and Jochems, Bart and Smits, Ewine and Ordelman, Roeland},
title = {Exploiting Speech Recognition Transcripts for Narrative Peak Detection in Short-Form Documentaries},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Narrative peaks are points at which the viewer perceives a spike in the level of dramatic tension within the narrative flow of a video. This paper reports on four approaches to narrative peak detection in television documentaries that were developed by a joint team consisting of members from Delft University of Technology and the University of Twente within the framework of the VideoCLEF 2009 Affect Detection task. The approaches make use of speech recognition transcripts and seek to exploit various sources of evidence in order to automatically identify narrative peaks. These sources include speaker style (word choice), stylistic devices (use of repetitions), strategies strengthening viewers' feelings of involvement (direct audience address) and emotional speech. These approaches are compared to a challenging baseline that predicts the presence of narrative peaks at fixed points in the video, presumed to be dictated by natural narrative rhythm or production convention. Two approaches deliver top narrative peak detection results. One uses counts of personal pronouns to identify points in the video where viewers feel most directly involved. The other uses affective word ratings to calculate scores reflecting emotional language.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {385–392},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885171,
author = {Kierkels, Joep J. M. and Soleymani, Mohammad and Pun, Thierry},
title = {Identification of Narrative Peaks in Video Clips: Text Features Perform Best},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A methodology is proposed to identify narrative peaks in video clips. Three basic clip properties are evaluated which reflect on video, audio and text related features in the clip. Furthermore, the expected distribution of narrative peaks throughout the clip is determined and exploited for future predictions. Results show that only the text related feature, related to the usage of distinct words throughout the clip, and the expected peak-distribution are of use when finding the peaks. On the training set, our best detector had an accuracy of 47% in finding narrative peaks. On the test set, this accuracy dropped to 24%.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {393–400},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885172,
author = {Raaijmakers, Stephan and Versloot, Corn\'{e} and De Wit, Joost},
title = {A Cocktail Approach to the VideoCLEF'09 Linking Task},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper, we describe the TNO approach to the Finding Related Resources or linking task of VideoCLEF09. Our system consists of a weighted combination of off-the-shelf and proprietary modules, including the Wikipedia Miner toolkit of the University of Waikato. Using this cocktail of largely off-the-shelf technology allows for setting a baseline for future approaches to this task.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {401–408},
numpages = {8},
location = {Corfu, Greece},
series = {CLEF'09}
}

@inproceedings{10.5555/1885110.1885173,
author = {Gyarmati, \'{A}gnes and Jones, Gareth J. F.},
title = {When to Cross over? Cross-Language Linking Using Wikipedia for VideoCLEF 2009},
year = {2009},
isbn = {3642157505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We describe Dublin City University (DCU)'s participation in the VideoCLEF 2009 Linking Task. Two approaches were implemented using the Lemur information retrieval toolkit. Both approaches first extracted a search query from the transcriptions of the Dutch TV broadcasts. One method first performed search on a Dutch Wikipedia archive, then followed links to corresponding pages in the English Wikipedia. The other method first translated the extracted query using machine translation and then searched the English Wikipedia collection directly. We found that using the original Dutch transcription query for searching the Dutch Wikipedia yielded better results.},
booktitle = {Proceedings of the 10th International Conference on Cross-Language Evaluation Forum: Multimedia Experiments},
pages = {409–412},
numpages = {4},
location = {Corfu, Greece},
series = {CLEF'09}
}

