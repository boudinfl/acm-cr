@inproceedings{10.1007/11519645_2,
author = {Braschler, Martin and Di Nunzio, Giorgio M. and Ferro, Nicola and Peters, Carol},
title = {CLEF 2004: Ad Hoc Track Overview and Results Analysis},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_2},
doi = {10.1007/11519645_2},
abstract = {We describe the objectives and organization of the CLEF 2004 ad hoc track and discuss the main characteristics of the experiments. The results are analyzed and commented and their statistical significance is investigated. The paper concludes with some observations on the impact of the CLEF campaign on the state-of-the-art in cross-language information retrieval.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {10–26},
numpages = {17},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_3,
author = {Savoy, Jacques and Berger, Pierre-Yves},
title = {Selection and Merging Strategies for Multilingual Information Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_3},
doi = {10.1007/11519645_3},
abstract = {In our fourth participation in the CLEF evaluation campaigns, our objective was to verify whether our combined query translation approach would work well with new requests and new languages (Russian and Portuguese in this case). As a second objective, we were to suggest a selection procedure able to extract a smaller number of documents from collections that seemed to contain no or only a few relevant items for the current request. We also applied different merging strategies in order to obtain more evidence about their respective relative merits.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {27–37},
numpages = {11},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_4,
author = {Chevallet, Jean-Pierre and S\'{e}rasset, Gilles},
title = {Using Surface-Syntactic Parser and Deviation from Randomness},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_4},
doi = {10.1007/11519645_4},
abstract = {This document presents the experiments we performed for our CLEF 2004 participation. We have tested the use of surface-syntactic parsing to extract indexing terms. We have also studied the Deviation From Randomness weighting. For the bilingual part, we have experimented reinforcement query weighting using an association thesaurus.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {38–49},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_5,
author = {McNamee, Paul and Mayfield, James},
title = {Cross-Language Retrieval Using HAIRCUT at CLEF 2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_5},
doi = {10.1007/11519645_5},
abstract = {JHU/APL continued to explore the use of knowledge-light methods for multilingual retrieval during the CLEF 2004 evaluation. We relied on the language-neutral techniques of character n-gram tokenization, pre-translation query expansion, statistical translation using aligned parallel corpora, fusion from disparate retrievals, and reliance on language similarity when resources are scarce. We participated in the monolingual and bilingual evaluations. Our results support the claims that n-gram based retrieval is highly effective; that fusion of multiple retrievals is helpful in bilingual retrieval; and, that reliance on language similarity in lieu of translation can outperform a high performing system using abundant translation resources and a less similar query language.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {50–59},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_6,
author = {Di Nunzio, G. M. and Ferro, N. and Orio, N.},
title = {Experiments on Statistical Approaches to Compensate for Limited Linguistic Resources},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_6},
doi = {10.1007/11519645_6},
abstract = {Information Retrieval systems can benefit from advanced linguistic resources when carrying out tasks such as word-stemming or query translation. The main goal of our experiments has been the development of methodologies that minimize the human labor needed for creating linguistic resources for new languages. For this purpose, we have applied statistical techniques to extract information directly from the collections.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {60–72},
numpages = {13},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_7,
author = {Gayo-Avello, Daniel and \'{A}lvarez-Guti\'{e}rrez, Dar\'{\i}o and Gayo-Avello, Jos\'{e}},
title = {Application of Variable Length <i>N</i>-Gram Vectors to Monolingual and Bilingual Information Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_7},
doi = {10.1007/11519645_7},
abstract = {Our group in the Department of Informatics at the University of Oviedo has participated, for the first time, in two tasks at CLEF: monolingual (Russian) and bilingual (Spanish-to-English) information retrieval. Our main goal was to test the application to IR of a modified version of the n-gram vector space model (codenamed blindLight). This new approach has been successfully applied to other NLP tasks such as language identification or text summarization and the results achieved at CLEF 2004, although not exceptional, are encouraging. There are two major differences between the blindLight approach and classical techniques: (1) relative frequencies are no longer used as vector weights but are replaced by n-gram significances, and (2) cosine distance is abandoned in favor of a new metric inspired by sequence alignment techniques, not so computationally expensive. In order to perform cross-language IR we have developed a naive n-gram pseudo-translator similar to those described by McNamee and Mayfield or Pirkola et al.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {73–82},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_8,
author = {Besan\c{c}on, Romaric and Ferret, Olivier and Fluhr, Christian},
title = {Integrating New Languages in a Multilingual Search System Based on a Deep Linguistic Analysis},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_8},
doi = {10.1007/11519645_8},
abstract = {The LIC2M has designed a cross-lingual search engine based on a deep linguistic analysis of documents and queries that works on French, English, Spanish, German, Arabic and Chinese. For our participation in the CLEF 2004 campaign, we tested the integration in our system of Russian and Finnish, based on a simplified processing. The results we obtained are not good on the new languages introduced, which shows that our system strongly depends on a correct linguistic analysis of the documents. However, integrating more processing steps in the simplified analysis of new languages so that the results of this analysis are more comparable with the results of the complete linguistic analysis seems to be a good direction for improvements.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {83–89},
numpages = {7},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_9,
author = {Llopis, Fernando and Mu\~{n}oz, Rafael and Terol, Rafael M. and Noguera, Elisa},
title = {IR-n R2: Using Normalized Passages},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_9},
doi = {10.1007/11519645_9},
abstract = {This paper describes the fourth participation of the IR-n system (Alicante University) at the CLEF evaluation campaigns. For CLEF 2004, we modified our similarity measure and query expansion model. For the similarity measure, we now use normalization based on the number of words for each of the passages. We tested two different approaches for query expansion: the first one is based on documents and the second on passages.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {90–99},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_10,
author = {Nadeau, David and Jarmasz, Mario and Barri\`{e}re, Caroline and Foster, George and St-Jacques, Claude},
title = {Using COTS Search Engines and Custom Query Strategies at CLEF},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_10},
doi = {10.1007/11519645_10},
abstract = {This paper presents a system for bilingual information retrieval using commercial off-the-shelf search engines (COTS). Several custom query construction, expansion and translation strategies are compared. We present the experiments and the corresponding results for the CLEF 2004 event.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {100–109},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_11,
author = {Moulinier, Isabelle and Williams, Ken},
title = {Report on Thomson Legal and Regulatory Experiments at CLEF-2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_11},
doi = {10.1007/11519645_11},
abstract = {Thomson Legal and Regulatory participated in the CLEF-2004 monolingual and bilingual tracks. Monolingual experiments included Portuguese, Russian and Finnish. We investigated a new query structure to handle Finnish compounds. Our main focus was bilingual search from German to French. Our approach used query translation and post-translation pseudo-relevance feedback. We compared two translation models for query translation, and captured compound translations through fertility probabilities. While the fertility-based approach picks good terms, it does not help improve bilingual retrieval. Pseudo-relevance feedback, on the other hand, resulted in improved average precision.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {110–122},
numpages = {13},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_12,
author = {Kamps, Jaap and Adafre, Sisay Fissaha and de Rijke, Maarten},
title = {Effective Translation, Tokenization and Combination for Cross-Lingual Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_12},
doi = {10.1007/11519645_12},
abstract = {Our approach to cross-lingual document retrieval starts from the assumption that effective monolingual retrieval is at the core of any cross-language retrieval system. We devote particular attention to three crucial ingredients of our approach to cross-lingual retrieval. First, effective tokenization techniques are essential to cope with morphological variations common in many European languages. Second, effective combination methods allow us to combine the best of different strategies. Finally, effective translation methods for translating queries or documents turn a monolingual retrieval system into a cross-lingual retrieval system proper. The viability of our approach is shown by a series of experiments in monolingual, bilingual, and multilingual retrieval.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {123–134},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_13,
author = {Kishida, Kazuaki and Kando, Noriko and Chen, Kuang-Hua},
title = {Two-Stage Refinement of Transitive Query Translation with English Disambiguation for Cross-Language Information Retrieval: An Experiment at CLEF 2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_13},
doi = {10.1007/11519645_13},
abstract = {This paper reports experimental results of cross-language information retrieval (CLIR) from German to French. The authors focus on CLIR in cases where available language resources are very limited. Thus transitive translation of queries using English as a pivot language was used to search French document collections for German queries without any direct bilingual dictionary or MT system for these two languages. The two-stage refinement of query translations that we proposed at the previous CLEF 2003 campaign is again used for enhancing performance of the pivot language approach. In particular, disambiguation of English terms in the middle stage of transitive translation was attempted as a new experiment. Our results show that the two-stage refinement method is able to significantly improve search performance of bilingual IR using a pivot language, but unfortunately, the English disambiguation has almost no effect.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {135–142},
numpages = {8},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_14,
author = {Argaw, Atelach Alemu and Asker, Lars and C\"{o}ster, Rickard and Karlgren, Jussi},
title = {Dictionary-Based Amharic: English Information Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_14},
doi = {10.1007/11519645_14},
abstract = {We present two approaches to the Amharic – English bilingual track in CLEF 2004. Both experiments use a dictionary based approach to translate the Amharic queries into English Bags-of-words, but while one approach removes non-content bearing words from the Amharic queries based on their IDF value, the other uses a list of English stop words to perform the same task. The resulting translated (English) terms are then submitted to a retrieval engine that supports the Boolean and vector-space models. In our experiments, the second approach (based on a list of English stop words) performs slightly better than the one based on IDF values for the Amharic terms.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {143–149},
numpages = {7},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_15,
author = {Karlgren, Jussi and Sahlgren, Magnus and J\"{a}rvinen, Timo and C\"{o}ster, Rickard},
title = {Dynamic Lexica for Query Translation},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_15},
doi = {10.1007/11519645_15},
abstract = {This experiment tests a simple, scalable, and effective approach to building a domain-specific translation lexicon using distributional statistics over parallellized bilingual corpora. A bilingual lexicon is extracted from aligned Swedish-French data, used to translate CLEF topics from Swedish to French, which resulting French queries are then in turn used to retrieve documents from the French language CLEF collection. The results give 34 of fifty queries on or above median for the “precision at 1000 documents” recall oriented score; with many of the errors possible to handle by the use of string-matching and cognate search. We conclude that the approach presented here is a simple and efficient component in an automatic query translation system.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {150–155},
numpages = {6},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_16,
author = {Mart\'{\i}nez-Santiago, Fernando and Garc\'{\i}a-Cumbreras, Miguel A. and D\'{\i}az-Galiano, Manuel C. and Ure\~{n}a, L. Alfonso},
title = {SINAI at CLEF 2004: Using Machine Translation Resources with a Mixed 2-Step RSV Merging Algorithm},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_16},
doi = {10.1007/11519645_16},
abstract = {In CLEF 2004, the SINAI group participated in the multilingual task. Our main interest was to test Machine Translation (MT) with a mixed 2-step RSV merging algorithm. Since 2-step RSV requires grouping the document frequency for each term with the translations for that term, and MT translates whole phrases better than working word for word, it is not directly feasible to use MT with a 2-step RSV merging algorithm. To solve this problem, we have tested an algorithm which aligns the original query and its translation(s) at term level.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {156–164},
numpages = {9},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_17,
author = {Hackl, Ren\'{e} and Mandl, Thomas and Womser-Hacker, Christa},
title = {Mono- and Crosslingual Retrieval Experiments at the University of Hildesheim},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_17},
doi = {10.1007/11519645_17},
abstract = {In this year's participation we continued to evaluate open source information retrieval software. We used mainly the Lucene system and experimented with some of the most effective optimization strategies applied in the past CLEF campaigns. The effectiveness of open source and other free tools can be greatly enhanced by employing these optimization strategies. For most languages, blind relevance feedback led to considerable improvement. On the other hand, indexing strategies with n-grams did not lead to any improvements in our experiments.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {165–169},
numpages = {5},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_18,
author = {Levow, Gina-Anne and Matveeva, Irina},
title = {University of Chicago at CLEF2004: Cross-Language Text and Spoken Document Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_18},
doi = {10.1007/11519645_18},
abstract = {The University of Chicago participated in the Cross-Language Evaluation Forum 2004 (CLEF2004) cross-language multilingual, bilingual, and spoken language tracks. Cross-language experiments focused on meeting the challenges of new languages with freely available resources. We found that modest effectiveness could be achieved with the additional application of pseudo-relevance feedback to overcome some gaps in impoverished lexical resources. Experiments with a new dimensionality reduction approach for re-ranking of retrieved results yielded no improvement, however. Finally, spoken document retrieval experiments aimed to meet the challenges of unknown story boundary conditions and noisy retrieval through query-based merger of fine-grained overlapping windows and pseudo-feedback query expansion to enhance retrieval.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {170–179},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_19,
author = {Ruiz, Miguel E. and Srikanth, Munirathnam},
title = {UB at CLEF2004: Cross Language Information Retrieval Using Statistical Language Models},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_19},
doi = {10.1007/11519645_19},
abstract = {This paper presents the results of the State University of New York at Buffalo (UB) in the Mono-lingual and Multi-lingual tasks at CLEF 2004. For these tasks we used an approach based on statistical language modeling. Our Adhoc retrieval work used the TAPIR toolkit developed in house by M Srikanth. Our approach focused on the validation and adaptation of the language model system to work in a multilingual environment and in exploring ways to merge results from multiple collections into a single list of results. We explored the use of a measure of query ambiguity, also known as clarity score, for merging results of the individual collections into a single list of retrieved documents. Our results indicate that the use of clarity scores normalized across queries gives statistically significant improvements over using a fixed merging order.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {180–187},
numpages = {8},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_20,
author = {Go\~{n}i-Menoyo, Jos\'{e} M. and Gonz\'{a}lez, Jos\'{e} C. and Mart\'{\i}nez-Fern\'{a}ndez, J. L. and Villena, J.},
title = {MIRACLE's Hybrid Approach to Bilingual and Monolingual Information Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_20},
doi = {10.1007/11519645_20},
abstract = {The main goal of the bilingual and monolingual participation of the MIRACLE team in CLEF 2004 was to test the effect of combination approaches on information retrieval. The starting point was a set of basic components: stemming, transformation, filtering, generation of n-grams, weighting and relevance feedback. Some of these basic components were used in different combinations and order of application for document indexing and for query processing. A second order combination was also tested, mainly by averaging or selective combination of the documents retrieved by different approaches for a particular query.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {188–199},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_21,
author = {Gey, Fredric C.},
title = {Searching a Russian Document Collection Using English, Chinese and Japanese Queries},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_21},
doi = {10.1007/11519645_21},
abstract = {This UC Berkeley project experimented with English and German topics for bilingual retrieval from the CLEF Russian news collection with comparison to Russian → Russian monolingual retrieval. In CLEF 2004 we also experimented with Chinese and Japanese as topic languages, using English as the ‘pivot' language. For bilingual retrieval our approaches were query translation (for English as a topic language) and ‘fast' document translation from Russian to English (for Chinese and Japanese translated to English as the topic language). Chinese and Japanese topic retrieval significantly underperformed English → Russian retrieval because of the ‘double translation' loss of effectiveness.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {200–206},
numpages = {7},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_22,
author = {Jones, Gareth J. F. and Burke, Michael and Judge, John and Khasin, Anna and Lam-Adesina, Adenike and Wagner, Joachim},
title = {Dublin City University at CLEF 2004: Experiments in Monolingual, Bilingual and Multilingual Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_22},
doi = {10.1007/11519645_22},
abstract = {The Dublin City University group participated in the monolingual, bilingual and multilingual retrieval tasks. The main focus of our investigation for CLEF 2004 was extending our information retrieval system to document languages other than English, and completing the multilingual task comprising four languages: English, French, Russian and Finnish. Our retrieval system is based on the City University Okapi BM25 system with document preprocessing using the Snowball stemming software and stopword lists. Our French monolingual experiments compare retrieval using French documents and topics, and documents and topics translated into English. Our results indicate that working directly in French is more effective for retrieval than adopting document and topic translation. A breakdown of our multilingual retrieval results by the individual languages shows that similar overall average precision can be achieved when there is significant underlying variation in performance for individual languages.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {207–220},
numpages = {14},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_23,
author = {Tomlinson, Stephen},
title = {Finnish, Portuguese and Russian Retrieval with Hummingbird SearchServer<superscript>TM</superscript> at CLEF 2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_23},
doi = {10.1007/11519645_23},
abstract = {Hummingbird participated in the Finnish, Portuguese, Russian and French monolingual information retrieval tasks of the Cross-Language Evaluation Forum (CLEF) 2004. SearchServer's experimental lexical stemmers significantly increased mean average precision for each of the 4 languages. For Finnish, mean average precision was significantly higher with SearchServer's experimental decompounding option enabled. Using the stemming interpretations which led to the highest score in each document instead of using the same interpretations for all documents was of significant benefit for Russian.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {221–232},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_24,
author = {Savoy, Jacques},
title = {Data Fusion for Effective European Monolingual Information Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_24},
doi = {10.1007/11519645_24},
abstract = {For our fourth participation in the CLEF evaluation campaigns, our first objective was to propose an effective and general stopword list and a light stemming procedure for the Portuguese language. Our second objective was to obtain a better picture of the relative merit of various search engines when processing documents in the Finnish and Russian languages. Finally, based on the Z-score method we suggested a data fusion strategy intended to improve monolingual searches in various European languages.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {233–244},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_25,
author = {Cardoso, Nuno and Silva, M\'{a}rio J. and Costa, Miguel},
title = {The XLDB Group at CLEF 2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_25},
doi = {10.1007/11519645_25},
abstract = {This paper describes the participation of the XLDB Group in the CLEF monolingual ad hoc task for Portuguese. We present tumba!, a Portuguese search engine and describe its architecture and the underlying assumptions. We discuss the way we used tumba! in CLEF, providing details on our runs and our experiments with ranking algorithms.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {245–252},
numpages = {8},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_26,
author = {Lioma, Christina and He, Ben and Plachouras, Vassilis and Ounis, Iadh},
title = {The University of Glasgow at CLEF 2004: French Monolingual Information Retrieval with Terrier},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_26},
doi = {10.1007/11519645_26},
abstract = {This paper describes our participation in the CLEF 2004 French monolingual task. We used our Information Retrieval platform, Terrier, and experimented with query expansion and query length normalisation.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {253–259},
numpages = {7},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_27,
author = {Kluck, Michael},
title = {The Domain-Specific Track in CLEF 2004: Overview of the Results and Remarks on the Assessment Process},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_27},
doi = {10.1007/11519645_27},
abstract = {An overview of the research teams participating in the domain-specific track in CLEF 2004 and their runs is given together with a summary of approaches and results. The assessment procedure is also described and the problem of diverging judgments between the assessors is discussed. Some considerations for future research are made.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {260–270},
numpages = {11},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_28,
author = {Leveling, Johannes and Hartrumpf, Sven},
title = {University of Hagen at CLEF 2004: Indexing and Translating Concepts for the GIRT Task},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_28},
doi = {10.1007/11519645_28},
abstract = {This paper describes the second participation of the University of Hagen in the German Indexing and Retrieval Test (GIRT) task of the CLEF 2004 evaluation campaign with both monolingual and bilingual information retrieval experiments. For monolingual experiments with the German document collection, the focus is on applying and comparing three indexing methods targeting word forms, disambiguated concepts, and extended semantic networks. The bilingual experiments for retrieving English documents for German topics rely on translating and expanding query terms based on ranking semantically related English terms for a German concept. English translations are compiled from heterogeneous resources, including multilingual lexicons such as EuroWordNet and dictionaries available online.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {271–282},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_29,
author = {Baziz, Mustapha and Boughanem, Mohand and Aussenac-Gilles, Nathalie},
title = {IRIT at CLEF 2004: The English GIRT Task},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_29},
doi = {10.1007/11519645_29},
abstract = {This paper describes our participation to the monolingual English GIRT task. The main objectives of our experiments were to evaluate the use of Mercure IRS (designed at IRIT/SIG) on domain specific corpus. Two other techniques of automatic query reformulation using WordNet are evaluated.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {283–291},
numpages = {9},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_30,
author = {Kojima, Yuichi},
title = {Ricoh at CLEF 2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_30},
doi = {10.1007/11519645_30},
abstract = {This paper describes Ricoh's participation is monolingual and bi-lingual information retrieval tasks done on the German Indexing and Retrieval Testdatabase (GIRT) at the Cross-Language Evaluation Forum (CLEF) 2004. We used a commercial morphological analyzer to decompound words and parallel corpora to retrieve bi-lingual information. While monolingual information retrieval was improved by using the analyzer, bi-lingual information retrieval still has room for improvement.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {292–297},
numpages = {6},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_31,
author = {Petras, Vivien},
title = {GIRT and the Use of Subject Metadata for Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_31},
doi = {10.1007/11519645_31},
abstract = {The use of domain-specific metadata (subject keywords) is tested for monolingual and bilingual retrieval on the GIRT social science collection. A new technique, Entry Vocabulary Modules, which adds subject keywords selected from the controlled vocabulary to the query, has been tested. As in previous years, we compare our techniques of thesaurus matching and Entry Vocabulary Modules to simple machine translation techniques in bilingual retrieval. A combination of machine translation and thesaurus matching achieves better results, whereas the introduction of Entry Vocabulary Modules has negligent impact on the retrieval results. Retrieval results for the German and English GIRT collection for monolingual as well as bilingual retrieval (with English and German as query languages) will be represented.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {298–309},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_32,
author = {Gonzalo, Julio and Oard, Douglas W.},
title = {ICLEF 2004 Track Overview: Pilot Experiments in Interactive Cross-Language Question Answering},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_32},
doi = {10.1007/11519645_32},
abstract = {For the 2004 Cross-Language Evaluation Forum (CLEF) interactive track (iCLEF), five participating teams used a common evaluation design to assess the ability of interactive systems of their own design to support the task of finding specific answers to narrowly focused questions in a collection of documents written in a language different from the language in which the questions were expressed. This task is an interactive counterpart to the fully automatic cross-language question answering task at CLEF 2003 and 2004. This paper describes the iCLEF 2004 evaluation design, outlines the experiments conducted by the participating teams, and presents some initial results from analyses of official evaluation measures that were reported to each participating team.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {310–322},
numpages = {13},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_33,
author = {L\'{o}pez-Ostenero, Fernando and Gonzalo, Julio and Peinado, V\'{\i}ctor and Verdejo, Felisa},
title = {Interactive Cross-Language Question Answering: Searching Passages versus Searching Documents},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_33},
doi = {10.1007/11519645_33},
abstract = {iCLEF 2004 is the first comparative evaluation of interactive Cross-Language Question Answering systems. The UNED group has participated in this task comparing two strategies to help users in the answer finding task: the baseline system is just a standard document retrieval engine searching machine-translated versions of the documents; the contrastive system is identical, but searches passages which contain expressions of the appropriate answer type. Although the users prefer the passage system because searching is faster and simpler, it leads to slightly worse results, because the document context (which is not available in the passage retrieval system) turns out to be useful to verify the correctness of candidate answers; this makes an interesting difference with automatic Q&amp;A systems. In addition, our experiment sets a strong baseline of 69% strict accuracy, showing that Cross-Language Question Answering can be efficiently accomplished by users without using dedicated Q&amp;A technology.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {323–333},
numpages = {11},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_34,
author = {Navarro, Borja and Moreno, Lorenza and V\'{a}zquez, Sonia and Llopis, Fernando and Montoyo, Andr\'{e}s and Var\'{o}, Miguel \'{A}ngel},
title = {Improving Interaction with the User in Cross-Language Question Answering through Relevant Domains and Syntactic Semantic Patterns},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_34},
doi = {10.1007/11519645_34},
abstract = {The iCLEF 2004 experiment at the University of Alicante has focused on how to assist users when searching the correct answer in passages written in a language different from the one of the query. The language of the users is Spanish and the language of the documents/passages English. In order to help users, a first system shows, together with the passage in English, the relevant domains of the passage and the relevant domains of the query. These relevant domains were extracted automatically from WordNet Domains. A second system shows, together with the passage in English, the syntactic-semantic patterns (SSP) of each passage and the SSP of the query. The SSP are formed by the verb and the main nouns of a sentence (that is, the head nouns of the main complements). For users with low English skills, our hypothesis is that knowing the relevant domain and/or the SSP will be useful to find the correct answer in the passage. The results show that the SSP are a little bit better in the interaction with the users. However, some users say that it is easier to find the answer knowing the relevant domains than through the SSP.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {334–342},
numpages = {9},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_35,
author = {Hansen, Preben and Karlgren, Jussi and Sahlgren, Magnus},
title = {Cooperation, Bookmarking, and Thesaurus in Interactive Bilingual Question Answering},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_35},
doi = {10.1007/11519645_35},
abstract = {The study presented involves several different contextual aspects and is the latest in a continuing series of exploratory experiments on information access behaviour in a multi-lingual context [1, 2]. This year's interactive cross-lingual information access experiment was designed to measure three parameters we expected would affect the performance of users in cross-lingual tasks in languages in which the users are less than fluent. Firstly, introducing new technology, we measure the effect of topic-tailored term expansion on query formulation. Secondly, introducing a new component in the interactive interface, we investigate – without measuring by using a control group – the effect of a bookmark panel on user confidence in the reported result. Thirdly, we ran subjects pair-wise and allowed them to communicate verbally, to investigate how people may cooperate and collaborate with a partner during a search session performing a similar but non-identical search task.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {343–347},
numpages = {5},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_36,
author = {He, Daqing and Wang, Jianqiang and Luo, Jun and Oard, Douglas W.},
title = {Summarization Design for Interactive Cross-Language Question Answering},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_36},
doi = {10.1007/11519645_36},
abstract = {This paper describes an experimental investigation of interactive techniques for cross-language information access. The task was to answer factual questions from a large collection of documents written in a language in which the user has little proficiency. An interactive cross-language retrieval system that included optional user-assisted query translation, display of translated summaries for individual document ranked in order of decreasing degree of match to the user's query, and optional full-text examination of individual documents was provided. Two alternative types of extractive summaries were tried using a systematically varied presentation order, one drawn from a single segment of the translated document and the other drawn from three (usually) shorter segments of the translated document. On average, users were able to correctly answer just 62% of the sixteen assigned questions in an average of 176 seconds per question. Little difference was found between the two summary types for this task in an experiment using eight human subjects. Time on task and the number of query iterations were found to exhibit a positive correlation with question difficulty.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {348–362},
numpages = {15},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_37,
author = {Figuerola, Carlos G. and Zazo, Angel F. and Alonso Berrocal, Jos\'{e} L. and de Aldana, Emilio Rodr\'{\i}guez V\'{a}zquez},
title = {Interactive and Bilingual Question Answering Using Term Suggestion and Passage Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_37},
doi = {10.1007/11519645_37},
abstract = {The Question Answering Task requires user interaction. Users can help the system by reformulating the questions, adding information to them or selecting the documents on which the system should work to obtain the answers. Our group has researched the effects on user interaction of suggesting terms to be added to the question, and the differences between using fragments or complete documents. This article describes the experiments we carried out and discusses the results we obtained.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {363–370},
numpages = {8},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_38,
author = {Magnini, Bernardo and Vallin, Alessandro and Ayache, Christelle and Erbach, Gregor and Pe\~{n}as, Anselmo and de Rijke, Maarten and Rocha, Paulo and Simov, Kiril and Sutcliffe, Richard},
title = {Overview of the CLEF 2004 Multilingual Question Answering Track},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_38},
doi = {10.1007/11519645_38},
abstract = {Following the pilot Question Answering Track at CLEF 2003, a new evaluation exercise for multilingual QA systems took place in 2004. This paper reports on the novelties introduced in the new campaign and on participants' results. Almost all the cross-language combinations between nine source languages and seven target languages were exploited to set up more than fifty different tasks, both monolingual and bilingual. New types of questions (How- questions and definition questions) were given as input to the participating systems, while just one exact answer per question was allowed as output. The evaluation exercise has highlighted some difficulties in assessing definition questions and can be improved in the future, but the overall analysis of submissions shows encouraging results.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {371–391},
numpages = {21},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_39,
author = {Perret, Laura},
title = {A Question Answering System for French},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_39},
doi = {10.1007/11519645_39},
abstract = {This paper describes our first participation in the QA@CLEF monolingual and bilingual task, where our objective was to propose a question answering system designed to respond to French queries searching French documents. We wanted to combine a classic information retrieval model (based on the Okapi probabilistic model) with a linguistic approach based mainly on syntactic analysis. In order to utilize our monolingual system in the bilingual task, we automatically translated into French queries written in seven other source languages, namely Dutch, German, Italian, Portuguese, Spanish, English and Bulgarian.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {392–403},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_40,
author = {Sutcliffe, Richard F. E. and Gabbay, Igal and Mulcahy, Michael and O'Gorman, Aoife},
title = {Cross-Language French-English Question Answering Using the DLT System at CLEF 2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_40},
doi = {10.1007/11519645_40},
abstract = {We describe the system built by the Documents and Linguistic Technology (DLT) Group at University of Limerick for participation in the French-English Question Answering Task of the Cross Language Evaluation Forum (CLEF). The starting point was the system we used for the same task last year. Besides incremental improvements to the query type identification and named entity recognition components, the query analysis and translation stage was much more sophisticated than last year. This resulted in improved performance.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {404–410},
numpages = {7},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_41,
author = {Neumann, G\"{u}nter and Sacaleanu, Bogdan},
title = {Experiments on Robust NL Question Interpretation and Multi-Layered Document Annotation for a Cross–Language Question/Answering System},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_41},
doi = {10.1007/11519645_41},
abstract = {This report describes the work done by the QA group of the Language Technology Lab at DFKI, for the 2004 edition of the Cross-Language Evaluation Forum (CLEF). Based on the experience we obtained through our participation at QA@Clef-2003 with our initial cross-lingual QA prototype system BiQue (cf. [1]), the focus of the system extension for this year's task was a) on robust NL question interpretation using advanced linguistic-based components, b) flexible interface strategies to IR-search engines, and c) on strategies for off-line annotation of the data collection, which support query-specific indexing and answer selection.The overall architecture of the extended system, as well as the results obtained in the CLEF–2004 Monolingual German and Bilingual German/English QA tracks will be presented and discussed throughout the paper.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {411–422},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_42,
author = {Ahn, David and Jijkoun, Valentin and M\"{u}ller, Karin and de Rijke, Maarten and Schlobach, Stefan and Mishne, Gilad},
title = {Making Stone Soup: Evaluating a Recall-Oriented Multi-Stream Question Answering System for Dutch},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_42},
doi = {10.1007/11519645_42},
abstract = {We describe the participation of the University of Amsterdam in the Question Answering track at CLEF 2004. We took part in the monolingual Dutch task and, for the first time, also in the bilingual English to Dutch task. This year's system is a further elaboration and refinement of the multi-stream architecture we introduced last year, extended with improved candidate answer re-ranking and filtering, and with additional answer finding strategies. We report the evaluation results for the whole system and its various components. The results indicate the recall-oriented approach to QA is an effective one.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {423–434},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_43,
author = {Tanev, Hristo and Negri, Matteo and Magnini, Bernardo and Kouylekov, Milen},
title = {The DIOGENE Question Answering System at CLEF-2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_43},
doi = {10.1007/11519645_43},
abstract = {This paper presents the ITC-irst Multilingual Question Answering system Diogene. The system was used successfully on the CLEF-2003, TREC-2003, TREC-2002 and TREC-2001 QA tracks. Diogene relies on a classical three-layer architecture: question processing, document retrieval, answer extraction and validation. Diogene uses MultiWordNet [8] (http:// multiwordnet.itc.it) which facilitates the transfer of knowledge between languages. For answer validation we used the Web. This year we also used a set of linguistic templates for answering specific questions like definition questions, location questions, and a subset of who-is and what-is questions. Diogene participated in both the monolingual Italian-Italian task and in the cross-language Italian-English task. We also collaborated with the Bulgarian Academy of Sciences in the cross-language Bulgarian-English QA task.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {435–445},
numpages = {11},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_44,
author = {Ahn, Kisuh and Alex, Beatrice and Bos, Johan and Dalmas, Tiphaine and Leidner, Jochen L. and Smillie, Matthew B.},
title = {Cross-Lingual Question Answering Using off-the-Shelf Machine Translation},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_44},
doi = {10.1007/11519645_44},
abstract = {We show how to adapt an existing monolingual open-domain QA system to perform in a cross-lingual environment, using off-the-shelf machine translation software. In our experiments we use French and German as source language, and English as target language. For answering factoid questions, our system performs with an accuracy of 16% (German to English) and 20% (French to English), respectively. The loss of correctly answered questions caused by the MT component is estimated at 10% for French, and 15% for German. The accuracy of our system on correctly translated questions is 28% for German and 29% for French.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {446–457},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_45,
author = {Osenova, Petya and Simov, Alexander and Simov, Kiril and Tanev, Hristo and Kouylekov, Milen},
title = {Bulgarian-English Question Answering: Adaptation of Language Resources},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_45},
doi = {10.1007/11519645_45},
abstract = {This paper describes the Bulgarian part of a Bulgarian–English question answering system. The Bulgarian modules are implemented as a question analysis procedure within a Bulgarian question answering system — BulQA. The paper presents the available language resources and corresponding technology which is used for the analysis of the questions in Bulgarian and their translation into English format, which is necessary for answer extraction. CLaRK System is used as an implementation platform.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {458–469},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_46,
author = {Grau, Brigitte and Illouz, Gabriel and Monceaux, Laura and Robba, Isabelle and Vilnat, Anne and Bourdil, Guillaume and Elkateb-Gara, Fa\"{\i}za and Ferret, Olivier and Mathieu, Beno\^{\i}t},
title = {Answering French Questions in English by Exploiting Results from Several Sources of Information},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_46},
doi = {10.1007/11519645_46},
abstract = {Our bilingual QA system MUSCLEF, is based on QALC, the monolingual system with which we have participated in the previous TREC, where our best results were obtained when we combined the results of several searches. First, QALC searched a reliable document collection for answers, and second the WEB. We kept this strategy for CLEF, returning two runs. In the first one, we modified QALC so as to handle multilinguality by translating the terms identified in the question. In the second run, we combined the results of the first run with those obtained by first translating the question, then applying the full QALC strategy i.e. searching both the collection and the WEB. The final evaluation confirms the fact that the best results are obtained by combining different sources of information.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {470–481},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_47,
author = {Aunimo, Lili and Kuuskoski, Reeta and Makkonen, Juha},
title = {Finnish as Source Language in Bilingual Question Answering},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_47},
doi = {10.1007/11519645_47},
abstract = {This paper presents a bilingual question answering system that has Finnish as its source language and English as its target language. The system was evaluated in the QA@CLEF 2004 evaluation campaign. It is the only officially evaluated QA system that takes Finnish as input. The system is based on question classification and analysis, translation of important query terms, document retrieval, answer pattern instantiation and answer selection. The system achieves an accuracy of 10,88%.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {482–493},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_48,
author = {de Pablo-S\'{a}nchez, C\'{e}sar and Mart\'{\i}nez-Fern\'{a}ndez, Jos\'{e} Luis and Mart\'{\i}nez, Paloma and Villena, Julio},
title = {MiraQA: Experiments with Learning Answer Context Patterns from the Web},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_48},
doi = {10.1007/11519645_48},
abstract = {We present the miraQA system which is MIRACLE's first experience in Question Answering for monolingual Spanish. The general architecture of the system developed for QA@CLEF 2004 is presented as well as evaluation results. miraQA characterizes by learning the rules for answer extraction from the Web using a Hidden Markov Model of the context in which answers appear. We used a supervised approach that uses questions and answers from last years evaluation set for training.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {494–501},
numpages = {8},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_49,
author = {P\'{e}rez-Couti\~{n}o, M. and Solorio, T. and Montes-y-G\'{o}mez, M. and L\'{o}pez-L\'{o}pez, A. and Villase\~{n}or-Pineda, L.},
title = {Question Answering for Spanish Supported by Lexical Context Annotation},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_49},
doi = {10.1007/11519645_49},
abstract = {This paper describes the prototype developed by the Language Technologies Laboratory at INAOE for Spanish monolingual QA evaluation task at CLEF 2004. Our approach is centered on the use of context at a lexical level in order to identify possible answers to factoid questions. This method is supported by an alternative one based on pattern recognition in order to identify candidate answers to definition questions. We describe the methods applied at different stages of the system and our prototype architecture for question answering. The paper shows and discusses the results we achieved with this approach.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {502–511},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_50,
author = {Hartrumpf, Sven},
title = {Question Answering Using Sentence Parsing and Semantic Network Matching},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_50},
doi = {10.1007/11519645_50},
abstract = {The paper describes a question answering system for German called InSicht. All documents in the system are analyzed by a syntactico-semantic parser in order to represent each document sentence by a semantic network. A question sent to InSicht is parsed yielding its semantic network representation and its sentence type. The semantic network is expanded by applying equivalence rules, implicational rules, and concept variations based on semantic relations in computer lexicons and other knowledge sources. During the search stage, every semantic network generated for the question is matched with semantic networks for document sentences. If a match succeeds, an answer is generated from the matching semantic network for the supporting document. InSicht is evaluated on the QA@CLEF 2004 test set. A hierarchy of problem classes is proposed and a sample of suboptimally answered questions is annotated with these problem classes. Finally, some conclusions are drawn, main problems are identified, and directions for future work as suggested by these problems are indicated.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {512–521},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_51,
author = {Costa, Lu\'{\i}s},
title = {First Evaluation of Esfinge: A Question Answering System for Portuguese},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_51},
doi = {10.1007/11519645_51},
abstract = {This paper starts by describing Esfinge, a general domain Portuguese question answering system that uses the redundancy available in the Web as an important resource to find its answers. The paper also presents the strategies employed to participate in CLEF-2004 and discusses the results obtained. Three different strategies were tested: searching the answers only in the CLEF document collection, searching the answers in the Web and using the CLEF document collection to confirm these answers and finally searching the answers only in the Web. The intriguing question of why the system performed better when joining the two information sources, even though it was designed for the Web is discussed; in this connection, different language varieties and some problems of Google are mentioned. The paper concludes describing some of the work planned for the near future.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {522–533},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_52,
author = {Quaresma, Paulo and Quintano, Lu\'{\i}s and Rodrigues, Irene and Saias, Jos\'{e} and Salgueiro, Pedro},
title = {University of \'{E}Vora in QA@CLEF-2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_52},
doi = {10.1007/11519645_52},
abstract = {The approach followed by the University of \'{E}vora team when building a system for participation in the CLEF 2004 question answering task for Portuguese is described. The system is based on two steps: for each question, a first search selects a set of potentially relevant documents; each of these documents is then analysed to obtain a semantic representation and the answer to the initial query. This approach was applied to the QA@CLEF test set for Portuguese with interesting results that have allowed us to identify the strong and weak features of our system.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {534–543},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_53,
author = {D\'{\i}az, Enrique M\'{e}ndez and Ferro, Jes\'{u}s Vilares and Souto, David Cabrero},
title = {COLE Experiments at QA@CLEF 2004 Spanish Monolingual Track},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_53},
doi = {10.1007/11519645_53},
abstract = {This paper is a report on our third participation in CLEF. More precisely, this year we have participated in the Spanish Monolingual Question Answering Track for the first time. As a result we have developed a prototype of a QA system. Our prototype continues to apply the Natural Language Processing techniques we had already developed for single word conflation. In addition, the question analysis is based on complex pattern matching either over forms, part-of-speech tags or lemmas of the words involved. Regarding the search for relevant parts of documents containing the required answer, we use conventional IR techniques, whilst the extraction of the answer from the relevant parts of documents is again based on pattern matching.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {544–551},
numpages = {8},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_54,
author = {Vicedo, Jos\'{e} L. and Saiz, Maximiliano and Izquierdo, Rub\'{e}n and Llopis, Fernando},
title = {Does English Help Question Answering in Spanish?},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_54},
doi = {10.1007/11519645_54},
abstract = {This paper describes the architecture, operation and results obtained with the Question Answering prototype for Spanish developed in the Department of Language Processing and Information Systems at the University of Alicante for the CLEF-2004 Spanish monolingual QA evaluation task. Our system is based on the prototype developed for the CLEF-2003 Spanish monolingual task [3]. This system has been enhanced with capabilities regarding the use of documents in different languages to obtain evidence for supporting and complementing the CLEF Spanish corpora. In particular, the experiments described are intended to study how to use English Web documents to support monolingual Spanish QA.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {552–556},
numpages = {5},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_55,
author = {Ferr\'{e}s, Daniel and Kanaan, Samir and Ageno, Alicia and Gonz\'{a}lez, Edgar and Rodr\'{\i}guez, Horacio and Surdeanu, Mihai and Turmo, Jordi},
title = {The TALP-QA System for Spanish at CLEF 2004: Structural and Hierarchical Relaxing of Semantic Constraints},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_55},
doi = {10.1007/11519645_55},
abstract = {This paper describes TALP-QA, a multilingual open-domain Question Answering (QA) system that processes both factoid and definition questions. The system is described and evaluated in the context of our participation in the CLEF 2004 Spanish Monolingual QA task.Our approach to factoid questions is to build a semantic representation of the questions and the sentences in the passages retrieved for each question. A set of Semantic Constraints (SC) are extracted for each question. An answer extraction algorithm extracts and ranks sentences that satisfy the SCs of the question. If matches are not possible the algorithm relaxes the SCs structurally (removing constraints) and/or hierarchically (abstracting the constraints using a taxonomy).Answers to definition questions are generated by selecting the text fragment with more density of those terms more frequently related to the question's target (the Named Entity (NE) that appears in the question) throughout the corpus.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {557–568},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_56,
author = {Bertagna, Francesca and Chiran, Luminita and Simi, Maria},
title = {ILC-UniPI Italian QA},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_56},
doi = {10.1007/11519645_56},
abstract = {This paper introduces the general architecture of a prototype for monolingual Italian QA. The adopted strategies, the tools and resources for the linguistic processing are presented, together with the system results.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {569–580},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_57,
author = {Herrera, Jes\'{u}s and Pe\~{n}as, Anselmo and Verdejo, Felisa},
title = {Question Answering Pilot Task at CLEF 2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_57},
doi = {10.1007/11519645_57},
abstract = {A Pilot Question Answering Task has been activated in the Cross-Language Evaluation Forum 2004 with a twofold objective. In the first place, the evaluation of Question Answering systems when they have to answer conjunctive lists, disjunctive lists and questions with temporal restrictions. In the second place, the evaluation of systems' capability to give an accurate self-scoring about the confidence on their answers. In this way, two measures have been designed to be applied on all these different types of questions and to reward systems that give a confidence score with a high correlation with the human assessments. The forty eight runs submitted to the Question Answering Main Track have been taken as a case of study, confirming that some systems are able to give a very accurate score and showing how the measures proposed reward this fact.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {581–590},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_58,
author = {Saquete, E. and Vicedo, J. L. and Mart\'{\i}nez-Barco, P. and Mu\~{n}oz, R. and Llopis, F.},
title = {Evaluation of Complex Temporal Questions in CLEF-QA},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_58},
doi = {10.1007/11519645_58},
abstract = {This paper presents the evaluation of a QA system for the treatment of complex temporal questions. The system was implemented in a multilayered architecture where complex temporal questions are first decomposed into simple questions, according to the temporal relations expressed in the original question. These simple questions are then processed independently by our standard Question Answering engine and their respective answers are filtered to satisfy the temporal restrictions of each simple question. The answers to the simple decomposed questions are then combined, according to the temporal relations extracted from the original complex question, to give the final answer. This evaluation was performed as a pilot task in the Spanish QA Track of the Cross Language Evaluation Forum 2004.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {591–596},
numpages = {6},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_59,
author = {Clough, Paul and M\"{u}ller, Henning and Sanderson, Mark},
title = {The CLEF 2004 Cross-Language Image Retrieval Track},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_59},
doi = {10.1007/11519645_59},
abstract = {The purpose of this paper is to outline efforts from the 2004 CLEF cross–language image retrieval campaign (ImageCLEF). The aim of this CLEF track is to explore the use of both text and content–based retrieval methods for cross–language image retrieval. Three tasks were offered in the ImageCLEF track: a TREC–style ad-hoc retrieval task, retrieval from a medical collection, and a user–centered (interactive) evaluation task. Eighteen research groups from a variety of backgrounds and nationalities participated in ImageCLEF. In this paper we describe the ImageCLEF tasks, submissions from participating groups and summarise the main findings.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {597–613},
numpages = {17},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_60,
author = {Clough, Paul},
title = {Caption and Query Translation for Cross-Language Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_60},
doi = {10.1007/11519645_60},
abstract = {For many cross-language retrieval tasks, the predominant approach is to translate the query into the language of the document collection (target language). This often gives results as good as, if not better, than translating the document collection into the query language (source language). In this paper, we evaluate query versus document translation for the ImageCLEF 2004 bilingual ad hoc retrieval task. Image retrieval is achieved through matching textual queries to associated image captions for the following languages: French, German, Spanish and Italian using commercially and publicly available resources. On average, we find query translation to outperform document translation (77% of English MAP compared to 65% respectively) but this varies widely across language and query. Combining document and query translation we achieve an average MAP of 85% of English.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {614–625},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_61,
author = {Saiz-Noeda, Maximiliano and Vicedo, Jos\'{e} Luis and Izquierdo, Rub\'{e}n},
title = {Pattern-Based Image Retrieval with Constraints and Preferences on ImageCLEF 2004},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_61},
doi = {10.1007/11519645_61},
abstract = {This paper presents the approach used by the University of Alicante in the ImageCLEF 2004 adhoc retrieval task. This task is performed through multilingual search requests (topics) against an historic photographic collection in which images are accompanied with English captions. This approach uses these captions to perform retrieval and is based on a set of constraints and preferences that allow the rejection or scoring of images for the retrieval task. The constraints are implemented through a set of co-occurrence patterns based on regular expressions and the approach is extended in one of the experiments with the use of WordNet synonyms.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {626–632},
numpages = {7},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_62,
author = {M\"{u}ller, Henning and Geissb\"{u}hler, Antoine},
title = {How to Visually Retrieve Images from the St. Andrews Collection Using GIFT},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_62},
doi = {10.1007/11519645_62},
abstract = {The ImageCLEF task of CLEF has a main goal in the retrieval of images from multi–lingual collections. The 2003 imageCLEF saw no group using the visual information of images, which is inherently language independent. The query topics of the St. Andrews collection are defined in a way that makes visual retrieval hard as visual similarity plays a marginal role whereas semantics and background knowledge are extremely important, which can only be obtained from text. This article describes the submission of an entirely visual result. It also proposes improvements for visual retrieval systems with the current data. Section explains possible ways to make this query task more appealing to visual retrieval research groups, explaining problems of visual retrieval and what The task can do to overcome present problems. A benchmarking event is needed for visual information retrieval to remove barriers in performance. ImageCLEF can be this event and identify areas where visual retrieval might be better than textual and vice–versa. The combination of visual and textual features is an important field where research is needed.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {633–642},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_63,
author = {Peinado, V\'{\i}ctor and Artiles, Javier and L\'{o}pez-Ostenero, Fernando and Gonzalo, Julio and Verdejo, Felisa},
title = {UNED at ImageCLEF 2004: Detecting Named Entities and Noun Phrases for Automatic Query Expansion and Structuring},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_63},
doi = {10.1007/11519645_63},
abstract = {This paper describes UNED experiments at the Image CLEF bilingual ad hoc task. Two different strategies are attempted: i) automatic expansion and translation using noun phrases; ii) automatic detection of named entities in the query for structured search on image caption fields.All our experiments obtain results above the average MAP for the bilingual task. Structured searches using named entities improve performance over a strong baseline (Pirkola's structured query approach), achieving one of the best results for the whole bilingual track. Expansion with noun phrases, however, degrades results, possibly due to the mismatch between train and test collections.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {643–652},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_64,
author = {Jones, Gareth J. F. and Groves, Declan and Khasin, Anna and Lam-Adesina, Adenike and Mellebeek, Bart and Way, Andy},
title = {Dublin City University at CLEF 2004: Experiments with the ImageCLEF St. Andrew's Collection},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_64},
doi = {10.1007/11519645_64},
abstract = {For the CLEF 2004 ImageCLEF St Andrew's Collection task the Dublin City University group carried out three sets of experiments: standard cross-language information retrieval (CLIR) runs using topic translation via machine translation (MT), combination of this run with image matching results from the GIFT/Viper system, and a novel document rescoring approach based on automatic MT evaluation metrics. Our standard MT-based CLIR works well on this task. Encouragingly combination with image matching lists is also observed to produce small positive changes in the retrieval output. However, rescoring using the MT evaluation metrics in their current form significantly reduced retrieval effectiveness.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {653–663},
numpages = {11},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_65,
author = {Lin, Wen-Cheng and Chang, Yih-Chen and Chen, Hsin-Hsi},
title = {From Text to Image: Generating Visual Query for Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_65},
doi = {10.1007/11519645_65},
abstract = {This paper explores the uses of visual features for cross-language access to an image collection. An approach which transforms textual queries into visual representations is proposed. The relationships between text and images are mined. We employ the mined relationships to construct visual queries from textual ones. The retrieval results using textual and visual queries are combined to generate the final ranked list. We conducted English monolingual and Chinese-English cross-language retrieval experiments. The performances are quite good. The average precision of English monolingual textual run is 0.6304. The performance of cross-lingual retrieval is about 70% of monolingual retrieval. Comparatively, the gain of the generated visual query is not significant. If only appropriate query terms are selected to generate visual query, retrieval performance could be increased.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {664–675},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_66,
author = {Alvarez, Carmen and Oumohmed, Ahmed Id and Mignotte, Max and Nie, Jian-Yun},
title = {Toward Cross-Language and Cross-Media Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_66},
doi = {10.1007/11519645_66},
abstract = {This paper describes our approach used in ImageCLEF 2004. Our focus is on image retrieval using text, i.e. Cross-Media IR. To do this, we first determine the strong relationships between keywords and types of visual features such as texture or shape. Then, the subset of images retrieved by text retrieval are used as examples to match other images according to the most important types of features of the query words.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {676–687},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_67,
author = {Deselaers, Thomas and Keysers, Daniel and Ney, Hermann},
title = {FIRE – Flexible Image Retrieval Engine: ImageCLEF 2004 Evaluation},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_67},
doi = {10.1007/11519645_67},
abstract = {We describe FIRE, a content-based image retrieval system, and the methods we used within this system in the ImageCLEF 2004 evaluation. In FIRE, various features are available to represent images. The diversity of available features allows the user to adapt the system to the task at hand. A weighted combination of features admits flexible query formulations and helps with processing specific queries. For the ImageCLEF 2004 evaluation, we used the image content alone and obtained the best result in the category “only visual features, fully automatic retrieval” in the medical retrieval task. Additionally, the results compare favorably to other systems, even if they make use of the textual information in addition to the images.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {688–698},
numpages = {11},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_68,
author = {Mart\'{\i}nez-Fern\'{a}ndez, J. L. and Garc\'{\i}a-Serrano, A. and Villena, J. and M\'{e}ndez-S\'{a}enz, V.},
title = {MIRACLE Approach to ImageCLEF 2004: Merging Textual and Content-Based Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_68},
doi = {10.1007/11519645_68},
abstract = {This paper presents the image retrieval techniques tested by the MIRACLE (Multilingual Information RetrievAl for the CLEf campaign) research group as part of the ImageCLEF 2004 initiative. Two main lines of research continuing the past year's experiments were considered: the application of linguistic techniques to improve retrieval performance and the combination of textual and content-based image retrieval.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {699–708},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_69,
author = {Besan\c{c}on, Romaric and H\`{e}de, Patrick and Moellic, Pierre-Alain and Fluhr, Christian},
title = {Cross-Media Feedback Strategies: Merging Text and Image Information to Improve Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_69},
doi = {10.1007/11519645_69},
abstract = {The CEA-LIST/LIC2M develops both cross-language information retrieval systems and content-based image retrieval systems. The ad hoc and medical tasks of the ImageCLEF campaign offered us the opportunity to perform some experiments on merging the results of the two systems. The results obtained show that the performance of each system highly depends on the corpus and the task: feedback strategies can improve the results, but the parameters used are to be tuned according to the confidence of each system on the task and corpus: for the ad hoc task, text retrieval performs good whereas results of image retrieval are poor. On the other hand, for the medical task, the image retrieval performs better, and text retrieval can improve overall results only with reinforcement strategies.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {709–717},
numpages = {9},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_70,
author = {M\"{u}ller, Henning and Geissb\"{u}hler, Antoine and Ruch, Patrick},
title = {ImageCLEF 2004: Combining Image and Multi-Lingual Search for Medical Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_70},
doi = {10.1007/11519645_70},
abstract = {This article describes the technologies used for the various runs submitted by the University of Geneva in the context of the 2004 ImageCLEF competition. As our expertise is mainly in the field of medical image retrieval, most of our effort was concentrated on the medical image retrieval task. Described are the runs that were submitted including technical details for each of the single runs and a short explication of the obtained results compared with the results of submissions from other groups. We describe the problems encountered with respect to optimising the system and with respect to finding a balance between weighting textual and visual features for retrieval. A better balance seems possible when using training data for optimisation and with relevance judgements being available for a control of the retrieval quality.The results show that relevance feedback is extremely important for optimal results. Query expansion with visual features only gives minimal changes in result quality. If textual features are added in the automatic query expansion, the results improve significantly. Visual and textual results combined deliver the best performance.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {718–727},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_71,
author = {van Zaanen, Menno and de Croon, Guido},
title = {Multi-Modal Information Retrieval Using FINT},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_71},
doi = {10.1007/11519645_71},
abstract = {In this article, we describe the FINT system, which stands for Find Images aNd Text. This system is built in the context of the VindIT project, which focuses on handling large amounts of multi-media data. The system described here iteratively searches through a multi-media database by computing distances between the data entries (images and text). From each entry, a feature vector is computed. Distances between database entries are computed using a weighted version of their corresponding feature vector and entries similar to the initial search query are selected based on these distances. Here, we will describe the system and settings that were used in the medical retrieval task of the ImageCLEF 2004 competition.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {728–739},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_72,
author = {Howarth, Peter and Yavlinsky, Alexei and Heesch, Daniel and R\"{u}ger, Stefan},
title = {Medical Image Retrieval Using Texture, Locality and Colour},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_72},
doi = {10.1007/11519645_72},
abstract = {We describe our experiments for the Image CLEF medical retrieval task. Our efforts were focused on the initial visual search. A content-based approach was followed. We used texture, localisation and colour features that have been proven by previous experiments. The images in the collection had specific characteristics. Medical images have a formulaic composition for each modality and anatomic region. We were able to choose features that would perform well in this domain. Tiling a Gabor texture feature to add localisation information proved to be particularly effective. The distances from each feature were combined with equal weighting. This smoothed the performance across the queries. The retrieval results showed that this simple approach was successful, with our system coming third in the automatic retrieval task.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {740–749},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_73,
author = {Cheng, Pei-Cheng and Chien, Been-Chian and Ke, Hao-Ren and Yang, Wei-Pang},
title = {SMIRE: Similar Medical Image Retrieval Engine},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_73},
doi = {10.1007/11519645_73},
abstract = {This paper aims at finding images that are similar to a medical image example query. We propose several image features based on wavelet coefficients, including color histogram, gray-spatial histogram, coherence moment, and gray correlogram, to facilitate the retrieval of similar medical images. The initial retrieval results are obtained via visual feature analysis. An automatic feedback mechanism that clusters visually and textually similar images among these initial results was also proposed to help refine the query. In the ImageCLEF 2004 evaluation, the experimental results show that our system is excellence in mean average precision.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {750–760},
numpages = {11},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_74,
author = {Lubbers, Koen and de Vries, Arjen P. and Huibers, Theo and van der Vet, Paul},
title = {A Probabilistic Approach to Medical Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_74},
doi = {10.1007/11519645_74},
abstract = {We present a probabilistic approach to the medical retrieval task. We experimented with the Westerveld method [1] to obtain our results for ImageCLEF. In addition to these results we describe our findings of involving a medical expert in our research. The expert helped us identifying useful image retrieval applications and reflected upon the setup of ImageCLEF's medical task. Finally we describe the evaluation of an interactive implementation of the probabilistic approach.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {761–772},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_75,
author = {Ruiz, Miguel E. and Srikanth, Munirathnam},
title = {UB at CLEF2004 Cross Language Medical Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_75},
doi = {10.1007/11519645_75},
abstract = {This paper presents the results of the State University of New York at Buffalo in the cross-language medical image retrieval task at CLEF 2004. Our work in image retrieval explores the combination of image and text retrieval using automatic query expansion. The system uses pseudo relevance feedback on the case descriptions associated with the top 10 images to improve ranking of images retrieved by a CBIR system. The results show significant improvements with respect to a base line that uses only image retrieval.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {773–780},
numpages = {8},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_76,
author = {Thies, Christian and G\"{u}ld, Mark Oliver and Fischer, Benedikt and Lehmann, Thomas M.},
title = {Content-Based Queries on the Casimage Database within the IRMA Framework},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_76},
doi = {10.1007/11519645_76},
abstract = {Recent research has suggested that there is no general similarity measure, which can be applied on arbitrary databases without any parameterization. Hence, the optimal combination of similarity measures and parameters must be identified for each new image repository. This optimization loop is time consuming and depends on the experience of the designer as well as the knowledge of the medical expert. It would be useful if results that have been obtained for one data set can be transferred to another without extensive re-design. This transfer is vital if content-based image retrieval is integrated into complex environments such as picture archiving and communication systems. The image retrieval in medical applications (IRMA) project defines a framework that strictly separates data administration and application logic. This permits an efficient transfer of the data abstraction of one database on another without re-designing the software. In the ImageCLEF competition, the query performance was evaluated on the CasImage data set without optimization of the feature combination successfully applied to the IRMA corpus. IRMA only makes use of basic features obtained from grey-value representations of the images without additional textual annotations. The results indicate that transfer of parameterization is possible without time consuming parameter adaption and significant loss of retrieval quality.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {781–792},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_77,
author = {Cheng, Pei-Cheng and Yeh, Jen-Yuan and Ke, Hao-Ren and Chien, Been-Chian and Yang, Wei-Pang},
title = {Comparison and Combination of Textual and Visual Features for Interactive Cross-Language Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_77},
doi = {10.1007/11519645_77},
abstract = {This paper concentrates on the user-centered search task at ImageCLEF 2004. In this work, we combine both textual and visual features for cross-language image retrieval, and propose two interactive retrieval systems – T_ICLEF and VCT_ICLEF. The first one incorporates a relevance feedback mechanism based on textual information while the second one combines textual and image information to help users find a target image. The experimental results show that VCT_ICLEF had a better performance in almost all cases. Overall, it helped users find the topic image within a fewer iterations with a maximum of 2 iterations saved. Our user survey also reported that a combination of textual and visual information is helpful to indicate to the system what a user really wanted in mind.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {793–804},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_78,
author = {Bansal, Vineet and Zhang, Chen and Chai, Joyce Y. and Jin, Rong},
title = {MSU at ImageCLEF: Cross Language and Interactive Image Retrieval},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_78},
doi = {10.1007/11519645_78},
abstract = {In this report, we describe our studies with cross language and interactive image retrieval in ImageCLEF 2004. Typical cross language retrieval requires special linguistic resources, such as bilingual dictionaries. In this study, we focus on the issue of how to achieve good retrieval performance given only an online translation system. We compare two approaches, i.e., a translation-based approach and a model-based approach, and find that the later one performs substantially better than the former one. For interactive image retrieval, we investigated the potential use of user relevance feedback (URF), which was designed to address the mismatch problem between user queries and system descriptions. Our strategy is to let the system select important terms for user feedback before expanding queries. However, our preliminary results appear to indicate that the URF approach developed at the current stage is not working. We report our current investigation and discuss lessons learned from this experience.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {805–815},
numpages = {11},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_79,
author = {Federico, Marcello and Bertoldi, Nicola and Levow, Gina-Anne and Jones, Gareth J. F.},
title = {CLEF 2004 Cross-Language Spoken Document Retrieval Track},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_79},
doi = {10.1007/11519645_79},
abstract = {This paper summarizes the Cross-Language Spoken Document Retrieval (CL-SDR) track held at CLEF 2004. The CL-SDR task at CLEF 2004 was again based on the TREC-8 and TREC-9 SDR tasks. This year the CL-SDR task was extended to explore the unknown story boundaries condition introduced at TREC. The paper reports results from the participants showing that as expected cross-language results are reduced relative to a monolingual baseline, although the amount to which they are degraded varies for different topic languages.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {816–820},
numpages = {5},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_80,
author = {Santos, Diana and Rocha, Paulo},
title = {The Key to the First CLEF with Portuguese: Topics, Questions and Answers in CHAVE},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_80},
doi = {10.1007/11519645_80},
abstract = {In this paper we report the work done by Linguateca in order to add Portuguese to two tracks of CLEF, namely the ad hoc IR and the QA tracks. We start with a brief description of Linguateca's aims and the way we see CLEF from the standpoint of Portuguese language processing. We then comment on several interesting problems that emerged during our work and offer some suggestions for improvement, and finally raise some possibly controversial points for discussion.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {821–832},
numpages = {12},
location = {Bath, UK},
series = {CLEF'04}
}

@inproceedings{10.1007/11519645_81,
author = {Mandl, Thomas and Womser-Hacker, Christa},
title = {How Do Named Entities Contribute to Retrieval Effectiveness?},
year = {2004},
isbn = {3540274200},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11519645_81},
doi = {10.1007/11519645_81},
abstract = {The search for features in topics and queries relevant for the performance in information retrieval is an important strategy for system optimization. Named entities in topics are a significant feature contributing to the quality of the retrieval results. In this contribution, we present an analysis on the correlation between the number of named entities present in a topic formulation and the final retrieval quality for these topics by retrieval systems within CLEF. The analysis includes the results of CLEF 2004. We found that a medium positive correlation exists for German, English and Spanish topics. Furthermore, the effect of the document or target language on the retrieval quality is also investigated.},
booktitle = {Proceedings of the 5th Conference on Cross-Language Evaluation Forum: Multilingual Information Access for Text, Speech and Images},
pages = {833–842},
numpages = {10},
location = {Bath, UK},
series = {CLEF'04}
}

