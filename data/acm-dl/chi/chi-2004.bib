@inproceedings{10.1145/985692.985693,
author = {Intille, Stephen S. and Bao, Ling and Tapia, Emmanuel Munguia and Rondoni, John},
title = {Acquiring in Situ Training Data for Context-Aware Ubiquitous Computing Applications},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985693},
doi = {10.1145/985692.985693},
abstract = {Ubiquitous, context-aware computer systems may ultimately enable computer applications that naturally and usefully respond to a user's everyday activity. Although new algorithms that can automatically detect context from wearable and environmental sensor systems show promise, many of the most flexible and robust systems use probabilistic detection algorithms that require extensive libraries of training data with labeled examples. In this paper, we describe the need for such training data and some challenges we have identified when trying to collect it while testing three context-detection systems for ubiquitous computing and mobile applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {experience sampling, user interface design, context-aware, ubiquitous, supervised learning, computing},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985694,
author = {Law, Effie Lai-Chong and Hvannberg, Ebba Thora},
title = {Analysis of Combinatorial User Effect in International Usability Tests},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985694},
doi = {10.1145/985692.985694},
abstract = {User effect in terms of influencing the validity and reliability of results derived from standard usability tests has been studied with different approaches during the last decade, but inconsistent findings were obtained. User effect is further complicated by other confounding variables. With the use of various computational models, we analyze the extent of user effect in a relatively complex arrangement of international usability tests in which four different European countries were involved. We explore five aspects of user effect, including optimality of sample size, evaluator effect, effect of heterogeneous subgroups, performance of task variants, and efficiency of problem discovery. Some implications for future research are drawn.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {9–16},
numpages = {8},
keywords = {Monte Carlo simulation, user effect, international usability test, binomial model, evaluator effect},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985695,
author = {H\"{a}m\"{a}l\"{a}inen, Perttu and Lindholm, Mikko and Nyk\"{a}nen, Ari and H\"{o}ysniemi, Johanna},
title = {Animaatiokone: An Installation for Creating Clay Animation},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985695},
doi = {10.1145/985692.985695},
abstract = {This paper describes Animaatiokone, an installation for experimenting and learning about stop-motion animation. Located in a movie theater, it allows people to create clay animation while waiting for a movie. Collaboration between users is supported, for example, by sharing of clay actors. The installation's user interface allows even beginners to create and edit animation with help of automatic onion-skinning and simple controls developed through iterative testing and prototyping. In test use, the installation has been popular and hundreds of animations have been created and made available via the installation's homepage http://www.animaatiokone.net},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {17–24},
numpages = {8},
keywords = {collaborative storytelling, clay animation},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985696,
author = {schraefel, m. c. and Hughes, Gareth V. and Mills, Hugo R. and Smith, Graham and Payne, Terry R. and Frey, Jeremy},
title = {Breaking the Book: Translating the Chemistry Lab Book into a Pervasive Computing Lab Environment},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985696},
doi = {10.1145/985692.985696},
abstract = {The UK e-Science programme is relying on the evolution of the paper lab book into a pervasive data gathering lab system. To date take up of existing commercial or research lab book replacement systems has not been great. In this paper, we reconsider both the role of the lab book in the experimental cycle, as well as its affective and experiential properties as an artefact, in order to design an e-Science lab book that will be acceptable to the scientists who will use it. To this end we combined and extended existing design analysis models in order to assess the artefact functionally and experientially. We present the approach we developed, the prototype we designed based on our analysis, and the results of the formative study we performed of the artefact in real use. We show that our design elicitation method strongly contributed to the success of our prototype's take up.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {25–32},
numpages = {8},
keywords = {design methods, pervasive computing, e-science},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985697,
author = {Dey, Anind K. and Hamid, Raffay and Beckmann, Chris and Li, Ian and Hsu, Daniel},
title = {A CAPpella: Programming by Demonstration of Context-Aware Applications},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985697},
doi = {10.1145/985692.985697},
abstract = {Context-aware applications are applications that implicitly take their context of use into account by adapting to changes in a user's activities and environments. No one has more intimate knowledge about these activities and environments than end-users themselves. Currently there is no support for end-users to build context-aware applications for these dynamic settings. To address this issue, we present a CAPpella, a programming by demonstration Context-Aware Prototyping environment intended for end-users. Users "program" their desired context-aware behavior (situation and associated action) in situ, without writing any code, by demonstrating it to a CAPpella and by annotating the relevant portions of the demonstration. Using a meeting and medicine-taking scenario, we illustrate how a user can demonstrate different behaviors to a CAPpella. We describe a CAPpella's underlying system to explain how it supports users in building behaviors and present a study of 14 end-users to illustrate its feasibility and usability.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {33–40},
numpages = {8},
keywords = {context-aware computing, end-user programming, programming-by-demonstration, statistical machine learning},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985698,
author = {Sugimoto, Masanori and Hosoi, Kazuhiro and Hashizume, Hiromichi},
title = {<i>Caretta</i>: A System for Supporting Face-to-Face Collaboration by Integrating Personal and Shared Spaces},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985698},
doi = {10.1145/985692.985698},
abstract = {In this paper, a system called Caretta that integrates personal and shared spaces to support face-to-face collaboration is described. We use PDAs and a multiple-input sensing board for personal and shared spaces, respectively. Users of Caretta can discuss and negotiate with each other in the shared space by manipulating physical objects, while they individually examine their ideas in their own personal spaces. Caretta allows users to participate in group activities interchangeably and seamlessly using both these spaces. Caretta is applicable to various collaborative tasks. In this paper, it supports users in urban planning tasks. User studies of Caretta demonstrated that it allowed users to collaborate in a flexible fashion: users could work individually in their personal spaces at their own pace, cooperatively work together in the shared space, and smoothly transition between both of the spaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {41–48},
numpages = {8},
keywords = {personal and shared spaces, PDA, face-to-face collaboration, sensing board},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985699,
author = {Schiano, Diane J. and Ehrlich, Sheryl M. and Sheridan, Kyle},
title = {Categorical Imperative <i>NOT</i>: Facial Affect is Perceived <i>Continuously</i>},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985699},
doi = {10.1145/985692.985699},
abstract = {Facial affect (or emotion) recognition is a central issue for many VMC and naturalistic computing applications. Most computational models assume "categorical perception" of facial affect, in which a benign illusion promotes robust recognition of emotional expressions even under severe degradation conditions, including temporal compression. However, this applied interest in human facial affect perception is coming at a time when the evidence for categorical perception is being challenged in the basic research literature, largely on methodological grounds. The research presented here systematically addresses the classic evidence for categorical perception of facial affect, using high-quality digital imaging and display technologies and improved research methods. In doing so, it illustrates a fruitful convergence of basic and applied research. The evidence does NOT support categorical perception of facial affect, which in turn underlines the importance of preserving high-fidelity motion information in portraying emotion. This research provides new human behavioral data on facial affect perception, and underscores the importance of careful consideration of facial affect compression methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {49–56},
numpages = {8},
keywords = {affect, emotion, face, naturalistic computing, affective computing, facial affect, nonverbal communication, VMC, avatars, facial expression of emotion, video compression},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985700,
author = {Miller, Robert C. and Marshall, Alisa M.},
title = {Cluster-Based Find and Replace},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985700},
doi = {10.1145/985692.985700},
abstract = {In current text editors, the find &amp; replace command offers only two options: replace one match at a time prompting for confirmation, or replace all matches at once without any confirmation. Both approaches are prone to errors. This paper explores a third way: cluster-based find &amp; replace, in which the matches are clustered by similarity and whole clusters can be replaced at once. We hypothesized that cluster-based find &amp; replace would make find &amp; replace tasks both faster and more accurate, but initial user studies suggest that clustering may improve speed on some tasks but not accuracy. Users also prefer using a perfect-selection strategy for find &amp; replace, rather than an interleaved decision-action strategy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {57–64},
numpages = {8},
keywords = {clustering, error prevention, find &amp; replace, text editing},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985701,
author = {Lee, John D. and Hoffman, Joshua D. and Hayes, Elizabeth},
title = {Collision Warning Design to Mitigate Driver Distraction},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985701},
doi = {10.1145/985692.985701},
abstract = {As computers and other information technology move into cars and trucks, distraction-related crashes are likely to become an important problem. This paper begins to address this problem by examining how alert strategy (graded and single-stage) and alert modality (haptic and auditory) affect how well collision warning systems mitigate distraction and direct drivers attention to the car ahead when it unexpectedly brakes. We conducted two experiments in which drivers interacted with an in-vehicle email system and a collision warning system signaled a braking lead vehicle. The first experiment showed that graded alerts led to a greater safety margin and a lower rate of inappropriate responses to nuisance warnings. A second experiment focused on attitudes toward the collision warning system and found that graded alerts were more trusted than single stage alerts and that haptic alerts, a vibrating seat in these experiments, were perceived as less annoying and more appropriate. Graded haptic alerts offer a promising approach to developing context aware computing in a safety-critical application.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {65–72},
numpages = {8},
keywords = {trust, user acceptance, collision warning systems, smart cars, distraction, notification systems},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985702,
author = {Tory, Melanie and Moller, Torsten and Atkins, M. Stella and Kirkpatrick, Arthur E.},
title = {Combining 2D and 3D Views for Orientation and Relative Position Tasks},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985702},
doi = {10.1145/985692.985702},
abstract = {We compare 2D/3D combination displays to displays with 2D and 3D views alone. Combination displays we consider are: orientation icon (i.e., side-by-side), in-place methods (e.g., clip planes), and a new method called ExoVis. We specifically analyze performance differences (i.e., time and accuracy) for 3D orientation and relative position tasks. Empirical results show that 3D displays are effective for approximate navigation and relative positioning whereas 2D/3D combination displays (orientation icon and ExoVis) are useful for precise orientation and position tasks. Combination 2D/3D displays had as good or better performance as 2D displays. Clip planes were not effective for a 3D orientation task, but may be useful when only one slice is needed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {73–80},
numpages = {8},
keywords = {empirical study, experiment, 2D and 3D visualization, display design, orientation and relative position tasks},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985703,
author = {Wigdor, Daniel and Balakrishnan, Ravin},
title = {A Comparison of Consecutive and Concurrent Input Text Entry Techniques for Mobile Phones},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985703},
doi = {10.1145/985692.985703},
abstract = {The numeric keypads on mobile phones generally consist of 12 keys (0-9, *, #). Ambiguity arises when the 36-character alpha-numeric English alphabet is mapped onto this smaller number of keys. In this paper, we first present a taxonomy of the various techniques for resolving this ambiguity, dividing them into techniques that use consecutive actions to first select a character grouping and then a character from within that grouping, and those that use concurrent actions to achieve the same end. We then present the design and implementation of a chording approach to text entry that uses concurrent key presses. We conducted a controlled experiment that compared this chording technique to one-handed and two-handed versions of the commonly used MultiTap technique. The results show that the concurrent chording technique significantly outperforms both versions of the consecutive action MultiTap technique.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {81–88},
numpages = {8},
keywords = {text input, mobile phones, chording},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985704,
author = {Findlater, Leah and McGrenere, Joanna},
title = {A Comparison of Static, Adaptive, and Adaptable Menus},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985704},
doi = {10.1145/985692.985704},
abstract = {Software applications continue to grow in terms of the number of features they offer, making personalization increasingly important. Research has shown that most users prefer the control afforded by an adaptable approach to personalization rather than a system-controlled adaptive approach. No study, however, has compared the efficiency of the two approaches. In a controlled lab study with 27 subjects we compared the measured and perceived efficiency of three menu conditions: static, adaptable and adaptive. Each was implemented as a split menu, in which the top four items remained static, were adaptable by the subject, or adapted according to the subject's frequently and recently used items. The static menu was found to be significantly faster than the adaptive menu, and the adaptable menu was found to be significantly faster than the adaptive menu under certain conditions. The majority of users preferred the adaptable menu overall. Implications for interface design are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {89–96},
numpages = {8},
keywords = {interaction techniques, adaptive interfaces, customization, user study, adaptable interfaces, menu design},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985705,
author = {Kieras, David E. and Santoro, Thomas P.},
title = {Computational GOMS Modeling of a Complex Team Task: Lessons Learned},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985705},
doi = {10.1145/985692.985705},
abstract = {This paper presents the lessons learned when a computational GOMS modeling tool was used to evaluate user interface concepts and team structure designs for a new class of military shipboard workstations. The lessons are both encouraging and cautionary: For example, computational GOMS models scaled well to a large and complex task involving teams of users. Interruptability and working memory constructs had to be added to conventional GOMS model concepts. However, two surprises emerged: First, the non-psychological aspects of the model construction were the practical bottleneck. Second, user testing data in this domain were difficult to collect and lacked definition, meaning that the model provided a better characterization of the design details than the user testing data. Included in these lessons are recommendations for future model applications and modeling methodology development.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {97–104},
numpages = {8},
keywords = {human performance modeling},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985706,
author = {Bade, Ragnar and Schlechtweg, Stefan and Miksch, Silvia},
title = {Connecting Time-Oriented Data and Information to a Coherent Interactive Visualization},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985706},
doi = {10.1145/985692.985706},
abstract = {In modern intensive care units (ICUs), the medical staff has to monitor a huge amount of high-dimensional and time-oriented data, which needs to be visualized user- and task-specifically to ease diagnosis and treatment planning. Available visual representations, like diagrams or charts neglect the implicit information as well as a-priory or associated knowledge about the data and its meaning (for example, 38.5°C (101.3°F) is moderate fever and 41°C (105.8°F) is critical fever). Another challenge is to provide appropriate interaction techniques to explore and navigate the data and its temporal dimensions. In this context one major challenge is to connect time-oriented data and information to a coherent interactive visualization. In this paper we present different interactive visualization techniques which enable the users to reveal the data at several levels of detail and abstraction, ranging from a broad overview to the fine structure. We will also introduce a time visualization and navigation technique that connects overview+detail, pan+zoom, and focus+context features to one powerful time-browser.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {105–112},
numpages = {8},
keywords = {health care, visualization, user interface design, temporal data modeling and abstraction, medical application: intensive care units, information visualization},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985707,
author = {Gonz\'{a}lez, Victor M. and Mark, Gloria},
title = {"Constant, Constant, Multi-Tasking Craziness": Managing Multiple Working Spheres},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985707},
doi = {10.1145/985692.985707},
abstract = {Most current designs of information technology are based on the notion of supporting distinct tasks such as document production, email usage, and voice communication. In this paper we present empirical results that suggest that people organize their work in terms of much larger and thematically connected units of work. We present results of fieldwork observation of information workers in three different roles: analysts, software developers, and managers. We discovered that all of these types of workers experience a high level of discontinuity in the execution of their activities. People average about three minutes on a task and somewhat more than two minutes using any electronic tool or paper document before switching tasks. We introduce the concept of working spheres to explain the inherent way in which individuals conceptualize and organize their basic units of work. People worked in an average of ten different working spheres. Working spheres are also fragmented; people spend about 12 minutes in a working sphere before they switch to another. We argue that design of information technology needs to support people's continual switching between working spheres.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {113–120},
numpages = {8},
keywords = {attention management, empirical study, information overload, interruptions, personal information management},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985708,
author = {Vera, Alonso and Howes, Andrew and McCurdy, Michael and Lewis, Richard L.},
title = {A Constraint Satisfaction Approach to Predicting Skilled Interactive Cognition},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985708},
doi = {10.1145/985692.985708},
abstract = {In this paper we report a new approach to generating predictions about skilled interactive cognition. The approach, which we call Cognitive Constraint Modeling, takes as input a description of the constraints on a task environment, on user strategies, and on the human cognitive architecture and generates as output a prediction of the time course of interaction. In the Cognitive Constraint Models that we have built this is achieved by encoding the assumptions inherent in CPM-GOMS as a set of constraints and reasoning about them using finite domain constraint satisfaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {121–128},
numpages = {8},
keywords = {tools for usability evaluation, user modeling},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985709,
author = {Hancock, Jeffrey T. and Thom-Santelli, Jennifer and Ritchie, Thompson},
title = {Deception and Design: The Impact of Communication Technology on Lying Behavior},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985709},
doi = {10.1145/985692.985709},
abstract = {Social psychology has demonstrated that lying is an important, and frequent, part of everyday social interactions. As communication technologies become more ubiquitous in our daily interactions, an important question for developers is to determine how the design of these technologies affects lying behavior. The present research reports the results of a diary study, in which participants recorded all of their social interactions and lies for seven days. The data reveal that participants lied most on the telephone and least in email, and that lying rates in face-to-face and instant messaging interactions were approximately equal. This pattern of results suggests that the design features of communication technologies (e.g., synchronicity, recordability, and copresence) affect lying behavior in important ways, and that these features must be considered by both designers and users when issues of deception and trust arise. The implications for designing applications that increase, decrease or detect deception are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {129–134},
numpages = {6},
keywords = {deception, trust, CMC, media, communication, lying},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985710,
author = {Luchini, Kathleen and Quintana, Chris and Soloway, Elliot},
title = {Design Guidelines for Learner-Centered Handheld Tools},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985710},
doi = {10.1145/985692.985710},
abstract = {Handheld computers are mobile, flexible devices that can provide real-time, one-to-one support for students from within the context of their learning activities. This paper describes the design of three learner-centered handheld tools used as part of a nine-month classroom study involving thirty-three eighth grade students. A review of related work identifies some of the challenges of building educational software within the constraints of handheld screens, and two broad design guidelines are synthesized to help address these challenges. The first design guideline focuses on decomposing the learning activity to identify salient tasks and the type of supports (or scaffolds) students need to engage in these tasks, then building separate handheld workspaces to support each task. The second guideline focuses on methods for implementing scaffolds within these task-based workspaces while preserving the usability of the overall handheld software.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {135–142},
numpages = {8},
keywords = {handhelds, learner-centered design},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985711,
author = {Vronay, David and Wang, Shuo},
title = {Designing a Compelling User Interface for Morphing},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985711},
doi = {10.1145/985692.985711},
abstract = {We present a new user interface for the common morphing tool found in animation packages. Previously this interface has been based on the features of the underlying algorithm, with little regard to how artists actually use this feature. By careful design and analysis of a user study, we were able to design a novel user interface that greatly enhances the usability of the morphing tool for animation. Our improvements come in three areas: First, we replicate the artists' own ad-hoc annotation language and interaction techniques in the user interface. Second, we make the user experience more fluid and editable, to support exploration and iteration. Finally, we use the artists' morph expectations to redesign the morph algorithm itself to be more predictable. We conclude by discussing how our user study technique could help other interface design tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {143–149},
numpages = {7},
keywords = {interaction design, user interface design, prototyping animation, user-centered design / human-centered design, user studies},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985712,
author = {Ko, Andrew J. and Myers, Brad A.},
title = {Designing the Whyline: A Debugging Interface for Asking Questions about Program Behavior},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985712},
doi = {10.1145/985692.985712},
abstract = {Debugging is still among the most common and costly of programming activities. One reason is that current debugging tools do not directly support the inquisitive nature of the activity. Interrogative Debugging is a new debugging paradigm in which programmers can ask why did and even why didn't questions directly about their program's runtime failures. The Whyline is a prototype Interrogative Debugging interface for the Alice programming environment that visualizes answers in terms of runtime events directly relevant to a programmer's question. Comparisons of identical debugging scenarios from user tests with and without the Whyline showed that the Whyline reduced debugging time by nearly a factor of 8, and helped programmers complete 40% more tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {151–158},
numpages = {8},
keywords = {program slicing, debugging, Alice},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985713,
author = {Hourizi, Rachid and Johnson, Peter},
title = {Designing to Support Awareness: A Predictive, Composite Model},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985713},
doi = {10.1145/985692.985713},
abstract = {In this paper we propose an account of human/computer awareness for use in the (re)design of complex human/computer interaction, before empirically testing its utility. Specifically, having situated our work in the wider field of human/computer awareness research, we address the well-reported phenomenon of "situation awareness" breakdowns in the aviation domain. We assert the need for an explanatory and predictive model of the phenomenon if the frequency of such breakdowns is to be reduced and propose such a model. We then go on to investigate the utility of our model as a guide for design through the discussion of a recent experiment involving manipulations of an animated warning signal on a simulated cockpit control panel. Our results show initial support both for the model and for our assertion of its utility. We conclude that our composite view of awareness yields practical benefit in the design of human computer awareness support.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {159–166},
numpages = {8},
keywords = {predictive model, interaction design, awareness},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985714,
author = {Shen, Chia and Vernier, Fr\'{e}d\'{e}ric D. and Forlines, Clifton and Ringel, Meredith},
title = {DiamondSpin: An Extensible Toolkit for around-the-Table Interaction},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985714},
doi = {10.1145/985692.985714},
abstract = {DiamondSpin is a toolkit for the efficient prototyping of and experimentation with multi-person, concurrent interfaces for interactive shared displays. In this paper, we identify the fundamental functionality that tabletop user interfaces should embody, then present the toolkit's architecture and API. DiamondSpin provides a novel real-time polar to Cartesian transformation engine that has enabled new, around-the-table interaction metaphors to be implemented. DiamondSpin allows arbitrary document positioning and orientation on a tabletop surface. Polygonal tabletop layouts such as rectangular, octagonal, and circular tabletops can easily be constructed. DiamondSpin also supports multiple work areas within the same digital tabletop. Multi-user operations are offered through multi-threaded input event streams, multiple active objects, and multiple concurrent menus. We also discuss insights on tabletop interaction issues we have observed from a set of applications built with DiamondSpin.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {167–174},
numpages = {8},
keywords = {tabletop toolkit},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985715,
author = {Czerwinski, Mary and Horvitz, Eric and Wilhite, Susan},
title = {A Diary Study of Task Switching and Interruptions},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985715},
doi = {10.1145/985692.985715},
abstract = {We report on a diary study of the activities of information workers aimed at characterizing how people interleave multiple tasks amidst interruptions. The week-long study revealed the type and complexity of activities performed, the nature of the interruptions experienced, and the difficulty of shifting among numerous tasks. We present key findings from the diary study and discuss implications of the findings. Finally, we describe promising directions in the design of software tools for task management, motivated by the findings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {175–182},
numpages = {8},
keywords = {office and workplace, multitasking, information worker, interruptions, task switching, diary study},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985716,
author = {Kuzuoka, Hideaki and Yamazaki, Keiichi and Yamazaki, Akiko and Kosaka, Jun'ichi and Suga, Yasuko and Heath, Christian},
title = {Dual Ecologies of Robot as Communication Media: Thoughts on Coordinating Orientations and Projectability},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985716},
doi = {10.1145/985692.985716},
abstract = {The aim of our study is to investigate systems for supporting remote instruction via a mobile robot. In the real world, instructions are typically given through words and body orientations such as head movements, which make it possible to project others' actions. Projectability is an important resource in organizing multiple actions among multiple participants in co-ordination with one another. It can likewise be said that in the case of robot-human collaboration, it is necessary to design a robot's head so that a local participant can project the robot's (and remote person's) actions. GestureMan is a robot that is designed to support such projectability properties. It is argued that a remote controlled mobile robot, designed as a communication medium, makes relevant dual ecologies: ecology at a remote (robot operator's) site and at a local participant's (robot's) site. In order to design a robot as a viable communication medium, it is essential to consider how these ecologies can be mediated and supported.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {183–190},
numpages = {8},
keywords = {robot-mediated communication, human-robot interaction},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985717,
author = {Fussell, Susan R. and Kiesler, Sara and Setlock, Leslie D. and Scupelli, Peter and Weisband, Suzanne},
title = {Effects of Instant Messaging on the Management of Multiple Project Trajectories},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985717},
doi = {10.1145/985692.985717},
abstract = {We present a study of the effects of instant messaging (IM) on individuals' management of work across multiple collaborative projects. Groups of four participants completed four web design tasks. Each participant worked on two tasks, each task with a different partner who was either co-located or remote, connected via IM. In one condition, each participant had one co-located and one remote partner. In a second condition, both partners were remote. We examined communication, division of labor, and task performance as a function of condition. The results indicated that nearly all participants divided their time unequally between projects, but less unequally in the remote/remote condition. In the co-located/remote condition, participants favored the task with the co-located partner. The results show that the effects of IM differ depending on people's multiple tasks are distributed across space. We propose a new IM interface that promotes awareness of multiple collaborators on multiple tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {191–198},
numpages = {8},
keywords = {coordination mechanisms, CSCW, empirical studies, intellectual teamwork, collaborative writing, distributed work},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985718,
author = {Harter, Tim and Vroegindeweij, Sander and Geelhoed, Erik and Manahan, Meera and Ranganathan, Parthasarathy},
title = {Energy-Aware User Interfaces: An Evaluation of User Acceptance},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985718},
doi = {10.1145/985692.985718},
abstract = {The utility of a handheld device is often constrained by the battery life, particularly with recent usage patterns where the device is likely to be powered on at all times. The display component in these devices is a major consumer of battery energy and reducing its energy consumption can significantly enhance its utility. This primary research explores the impact of emerging technologies that provide energy-saving display modifications on perceived ease of use, quality, and overall user acceptance, and seeks to understand the tradeoffs between energy reduction and user acceptance for future interfaces. For our study, twelve handheld users reviewed energy-adaptive and standard display interfaces during five scenarios representing frequently performed tasks. The results show good acceptance of energy-aware user interfaces. While displays for tasks involving notifications and menus were deemed acceptable, primarily due to enhanced contrast levels, displays for longer tasks involving greater informational context need additional work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {199–206},
numpages = {8},
keywords = {energy-aware user interfaces, OLED, power consumption and battery life, energy saving displays},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985719,
author = {Fogarty, James and Hudson, Scott E. and Lai, Jennifer},
title = {Examining the Robustness of Sensor-Based Statistical Models of Human Interruptibility},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985719},
doi = {10.1145/985692.985719},
abstract = {Current systems often create socially awkward interruptions or unduly demand attention because they have no way of knowing if a person is busy and should not be interrupted. Previous work has examined the feasibility of using sensors and statistical models to estimate human interruptibility in an office environment, but left open some questions about the robustness of such an approach. This paper examines several dimensions of robustness in sensor-based statistical models of human interruptibility. We show that real sensors can be constructed with sufficient accuracy to drive the predictive models. We also create statistical models for a much broader group of people than was studied in prior work. Finally, we examine the effects of training data quantity on the accuracy of these models and consider tradeoffs associated with different combinations of sensors. As a whole, our analyses demonstrate that sensor-based statistical models of human interruptibility can provide robust estimates for a variety of office workers in a range of circumstances, and can do so with accuracy as good as or better than people. Integrating these models into systems could support a variety of advances in human computer interaction and computer-mediated communication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {207–214},
numpages = {8},
keywords = {sensor-based interfaces, managing human attention, context-aware computing, machine learning, situationally appropriate interaction},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985720,
author = {Cadiz, JJ and Narin, Attila and Jancke, Gavin and Gupta, Anoop and Boyle, Michael},
title = {Exploring PC-Telephone Convergence with the Enhanced Telephony Prototype},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985720},
doi = {10.1145/985692.985720},
abstract = {Industry trends suggest that the PC and telephone user experiences will converge over the next several years. This convergence raises important questions for the HCI community: how should the PC-phone user experience be designed, and how does PC-phone technology affect work practices? This paper focuses on the first question and provides some initial data on the second question. We describe a PC-phone prototype we built called Enhanced Telephony, and we report data from an eight month field deployment of Enhanced Telephony within our company where over 7,000 people installed the prototype. Results indicate that PC-phone software is a promising technology for the workplace and that the most valuable features may be those that help people manage their incoming calls.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {215–222},
numpages = {8},
keywords = {computer telephony integration (CTI), computer mediated communication, telephones},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985721,
author = {Paulos, Eric and Goodman, Elizabeth},
title = {The Familiar Stranger: Anxiety, Comfort, and Play in Public Places},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985721},
doi = {10.1145/985692.985721},
abstract = {As humans we live and interact across a wildly diverse set of physical spaces. We each formulate our own personal meaning of place using a myriad of observable cues such as public-private, large-small, daytime-nighttime, loud-quiet, and crowded-empty. Not surprisingly, it is the people with which we share such spaces that dominate our perception of place. Sometimes these people are friends, family and colleagues. More often, and particularly in public urban spaces we inhabit, the individuals who affect us are ones that we repeatedly observe and yet do not directly interact with - our Familiar Strangers. This paper explores our often ignored yet real relationships with Familiar Strangers. We describe several experiments and studies that led to designs for both a personal, body-worn, wireless device and a mobile phone based application that extend the Familiar Stranger relationship while respecting the delicate, yet important, constraints of our feelings and affinities with strangers in pubic places.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {223–230},
numpages = {8},
keywords = {wearable, wireless, urban computing, digital scent, community, d\'{e}tournement, strangers, d\'{e}rive, public place},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985722,
author = {Olsen, Dan R. and Wood, Stephen Bart},
title = {Fan-out: Measuring Human Control of Multiple Robots},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985722},
doi = {10.1145/985692.985722},
abstract = {A goal of human-robot interaction is to allow one user to operate multiple robots simultaneously. In such a scenario the robots provide leverage to the user's attention. The number of such robots that can be operated is called the fan-out of a human-robot team. Robots that have high neglect tolerance and lower interaction time will achieve higher fan-out. We define an equation that relates fan-out to a robot's activity time and its interaction time. We describe how to measure activity time and fan-out. We then use the fan-out equation to compute interaction effort. We can use this interaction effort as a measure of the effectiveness of a human-robot interaction design. We describe experiments that validate the fan-out equation and its use as a metric for improving human-robot interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {231–238},
numpages = {8},
keywords = {fan-out, human-robot interaction, multiple robots},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985723,
author = {L\'{e}cuyer, Anatole and Burkhardt, Jean-Marie and Etienne, Laurent},
title = {Feeling Bumps and Holes without a Haptic Interface: The Perception of Pseudo-Haptic Textures},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985723},
doi = {10.1145/985692.985723},
abstract = {We present a new interaction technique to simulate textures in desktop applications without a haptic interface. The proposed technique consists in modifying the motion of the cursor on the computer screen - i.e. the Control/Display ratio. Assuming that the image displayed on the screen corresponds to a top view of the texture, an acceleration (or deceleration) of the cursor indicates a negative (or positive) slope of the texture. Experimental evaluations showed that participants could successfully identify macroscopic textures such as bumps and holes, by simply using the variations of the motion of the cursor. Furthermore, the participants were able to draw the different profiles of bumps and holes which were simulated, correctly. These results suggest that our technique enabled the participants to successfully conjure a mental image of the topography of the macroscopic textures. Applications for this technique are: the feeling of images (pictures, drawings) or GUI components (windows' edges, buttons), the improvement of navigation, or the visualization of scientific data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {239–246},
numpages = {8},
keywords = {control/display ratio, bump and hole, texture, pseudo-haptic},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985724,
author = {Oulasvirta, Antti},
title = {Finding Meaningful Uses for Context-Aware Technologies: The Humanistic Research Strategy},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985724},
doi = {10.1145/985692.985724},
abstract = {Human-computer interaction (HCI) is undergoing a paradigm change towards interaction that is contextually adapted to rich use situations taking place "beyond the desktop". Currently, however, there are only few successful applications of context-adapted HCI, arguably because use scenarios have not been based on holistic understanding of the society, users, and use situations. A humanistic research strategy, utilized at the Helsinki Institute for Information Technology, aims to structure the innovation and evaluation of scenarios for future technologies. Population trends and motivational needs are analyzed to recognize psycho-socially relevant design opportunities. Ethnography, ethnomethodology, bodystorming, and computer simulations of use situations are conducted to understand use situations. The goal of design is to empower users by supporting their autonomy and control. Three design cases illustrate the approach. The paper showcases an emerging framework for informed innovation of use potentials.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {247–254},
numpages = {8},
keywords = {research strategy, humanism, user-centered design, use scenarios, empowerment, context-awareness},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985725,
author = {Baudisch, Patrick and Pruitt, John and Ball, Steve},
title = {Flat Volume Control: Improving Usability by Hiding the Volume Control Hierarchy in the User Interface},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985725},
doi = {10.1145/985692.985725},
abstract = {The hardware-inspired volume user interface model that is in use across all of today's operating systems is the source of several usability issues. One of them is that restoring the volume of a muted application can require an inappropriately long troubleshooting process: in addition to manipulating the application's volume and mute controls, users may also have to visit the system's volume control panel to find and adjust additional controls there. The "flat" volume control model presented in this paper eliminates this and other problems by hiding the hardware-oriented volume model from the user. Using the flat model, users use one slider per application to indicate how loud they want the respective applications to play; the slider then internally adjusts all hardware volume variables necessary to obtain the requested output. By offering a single point of control for each application, the flat model simplifies controlling application volume and restoring muted applications. In our studies, participants completed all four volume control and mixing tasks faster and with less error when using the flat model than when using the existing hardware-oriented volume control model. Participants also indicated a subjective preference for the flat model over the existing model.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {255–262},
numpages = {8},
keywords = {audio, volume control, user interface, sound},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985726,
author = {Schwesig, Carsten and Poupyrev, Ivan and Mori, Eijiro},
title = {Gummi: A Bendable Computer},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985726},
doi = {10.1145/985692.985726},
abstract = {Gummi is an interaction technique and device concept based on physical deformation of a handheld device. The device consists of several layers of flexible electronic components, including sensors measuring deformation of the device. Users interact with this device by a combination of bending and 2D position control. Gummi explores physical interaction techniques and screen interfaces for such a device. Its graphical user interface facilitates a wide range of interaction tasks, focused on browsing of visual information. We implemented both hardware and software prototypes to explore and evaluate the proposed interaction techniques.Our evaluations have shown that users can grasp Gummi's key interaction principles within minutes. Gummi demonstrates promising possibilities for new interaction techniques and devices based on flexible electronic components.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {263–270},
numpages = {8},
keywords = {GUI, interaction design, smartcards, flexible electronics, mobile computing, embodied interaction, handheld devices},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985727,
author = {Adamczyk, Piotr D. and Bailey, Brian P.},
title = {If Not Now, When? The Effects of Interruption at Different Moments within Task Execution},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985727},
doi = {10.1145/985692.985727},
abstract = {User attention is a scarce resource, and users are susceptible to interruption overload. Systems do not reason about the effects of interrupting a user during a task sequence. In this study, we measure effects of interrupting a user at different moments within task execution in terms of task performance, emotional state, and social attribution. Task models were developed using event perception techniques, and the resulting models were used to identify interruption timings based on a user's predicted cognitive load. Our results show that different interruption moments have different impacts on user emotional state and positive social attribution, and suggest that a system could enable a user to maintain a high level of awareness while mitigating the disruptive effects of interruption. We discuss implications of these results for the design of an attention manager.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {271–278},
numpages = {8},
keywords = {task models, affective state, attention, interruption},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985728,
author = {Huang, Elaine M. and Russell, Daniel M. and Sue, Alison E.},
title = {IM Here: Public Instant Messaging on Large, Shared Displays for Workgroup Interactions},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985728},
doi = {10.1145/985692.985728},
abstract = {Instant messaging (IM) in the workplace has proven to be a valuable tool for facilitating informal communication. Its benefits, however, are generally limited to times when users are in front of their computers. Because so much work takes place while people are mobile within their workplace, we sought to extend the benefits of IM beyond people's personal machines and into publicly accessible groupware. We first conducted a study of large display groupware applications (LDGAs) to understand the affordances that large displays offer for groupware, and the factors surrounding their adoption. We developed the IM Here system for shared IM on large displays using the lessons learned from the study. In this paper, we present the findings of our LDGA study, the design of IM Here and the preliminary results of our evaluation of IM as a public resource for workgroups.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {279–286},
numpages = {8},
keywords = {computer mediated communication, instant messaging, groupware, large displays, public displays},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985729,
author = {Robertson, T. J. and Prabhakararao, Shrinu and Burnett, Margaret and Cook, Curtis and Ruthruff, Joseph R. and Beckwith, Laura and Phalgune, Amit},
title = {Impact of Interruption Style on End-User Debugging},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985729},
doi = {10.1145/985692.985729},
abstract = {Although researchers have begun to explicitly support end-user programmers' debugging by providing information to help them find bugs, there is little research addressing the proper mechanism to alert the user to this information. The choice of alerting mechanism can be important, because as previous research has shown, different interruption styles have different potential advantages and disadvantages. To explore impacts of interruptions in the end-user debugging domain, this paper describes an empirical comparison of two interruption styles that have been used to alert end-user programmers to debugging information. Our results show that negotiated-style interruptions were superior to immediate-style interruptions in several issues of importance to end-user debugging, and further suggest that a reason for this superiority may be that immediate-style interruptions encourage different debugging strategies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {287–294},
numpages = {8},
keywords = {end-user programming, debugging, interruptions, surprise-explain-reward, end-user software engineering},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985730,
author = {Vemuri, Sunil and DeCamp, Philip and Bender, Walter and Schmandt, Chris},
title = {Improving Speech Playback Using Time-Compression and Speech Recognition},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985730},
doi = {10.1145/985692.985730},
abstract = {Despite the ready availability of digital recording technology and the continually decreasing cost of digital storage, browsing audio recordings remains a tedious task. This paper presents evidence in support of a system designed to assist with information comprehension and retrieval tasks from a large collection of recorded speech. Two techniques are employed to assist users with these tasks. First, a speech recognizer creates necessarily error-laden transcripts of the recorded speech. Second, audio playback is time-compressed using the SOLAFS technique. When used together, subjects are able to perform comprehension tasks with more speed and accuracy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {295–302},
numpages = {8},
keywords = {speech recognition, information retrieval, time-compressed audio},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985731,
author = {Ryokai, Kimiko and Marti, Stefan and Ishii, Hiroshi},
title = {I/O Brush: Drawing with Everyday Objects as Ink},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985731},
doi = {10.1145/985692.985731},
abstract = {We introduce I/O Brush, a new drawing tool aimed at young children, ages four and up, to explore colors, textures, and movements found in everyday materials by "picking up" and drawing with them. I/O Brush looks like a regular physical paintbrush but has a small video camera with lights and touch sensors embedded inside. Outside of the drawing canvas, the brush can pick up color, texture, and movement of a brushed surface. On the canvas, children can draw with the special "ink" they just picked up from their immediate environment. In our preliminary study with kindergarteners, we found that children not only produced complex works of art using I/O Brush, but they also engaged in explicit talk about patterns and features available in their environment. I/O Brush invites children to explore the transformation from concrete and familiar raw material into abstract concepts about patterns of colors, textures and movements.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {303–310},
numpages = {8},
keywords = {tangible user interface, children, explaining, building blocks, storytelling, drawing, input device},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985732,
author = {Jacko, Julie A. and Barnard, Leon and Kongnakorn, Thitima and Moloney, Kevin P. and Edwards, Paula J. and Emery, V. Kathlene and Sainfort, Francois},
title = {Isolating the Effects of Visual Impairment: Exploring the Effect of AMD on the Utility of Multimodal Feedback},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985732},
doi = {10.1145/985692.985732},
abstract = {This study examines the effects of multimodal feedback on the performance of older adults with an ocular disease, Age-Related Macular Degeneration (AMD), when completing a simple computer-based task. Visually healthy older users (n = 6) and older users with AMD (n = 6) performed a series of drag-and-drop tasks that incorporated a variety of different feedback modalities. The user groups were equivalent with respect to traditional visual function metrics and measured subject cofactors, aside from the presence or absence of AMD. Results indicate that users with AMD exhibited decreased performance, with respect to required feedback exposure time. Some non-visual and multimodal feedback forms show potential as solutions to enhance performance, for those with AMD as well as for visually healthy older adults.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {311–318},
numpages = {8},
keywords = {multimodal feedback, universal access, visual impairment, multimodality, visual feedback, age-related macular degeneration (AMD), visually impaired users},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985733,
author = {von Ahn, Luis and Dabbish, Laura},
title = {Labeling Images with a Computer Game},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985733},
doi = {10.1145/985692.985733},
abstract = {We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {319–326},
numpages = {8},
keywords = {image labeling, online games, World Wide Web, distributed knowledge acquisition},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985734,
author = {Beamish, Timothy and Maclean, Karon and Fels, Sidney},
title = {Manipulating Music: Multimodal Interaction for DJs},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985734},
doi = {10.1145/985692.985734},
abstract = {In this paper we consider the general goal of supporting physical manipulation of digital audio in a specific context: the performance disk jockey (DJ) seeking to migrate from vinyl to digital media. We classify both the DJ's traditional processes and tools and the field's newest technology.D'Groove, our own technological contribution, is a force feedback turntable used to manipulate digital audio in novel ways. We present an observational study of professional DJ's using D'Groove, and discuss this approach's attributes and directions for future augmentation. Finally, we extend our conclusions about the DJ's emerging needs to the broader domain of digital audio manipulation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {327–334},
numpages = {8},
keywords = {turntable, haptic, digital audio, audio control, DJ, tangible &amp; physical interfaces, force feedback, manual media manipulation, music, disk jockey},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985735,
author = {McGee, Mick},
title = {Master Usability Scaling: Magnitude Estimation and Master Scaling Applied to Usability Measurement},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985735},
doi = {10.1145/985692.985735},
abstract = {Master Usability Scaling (MUS) is a measurement method for developing a universal usability continuum based on magnitude estimation and master scaling. The universal usability continuum allows true ratio comparisons, potentially between all items measurable by the construct of usability (attributes, tasks, or products -- software or hardware) that have contributed to the meta-set by following the procedures prescribed. This paper describes the background for MUS, data reduction, and cases studies in software usability assessment.MUS is based on a new measurement method of usability, Usability Magnitude Estimation (UME) [9], where users estimate usability magnitude according to an objective definition of usability. UME allows all items measured within a single usability activity to be compared across one continuum. MUS utilizes UME to assess standard reference tasks across different usability activities to construct one meta-set of data. This meta-set of data can be represented as a universal usability continuum. MUS is simple to administer, easy to comprehend, and with advanced underlying calculations, powerful to use. The MUS continuum has the potential to be a widespread, robust, universal measurement scale of usability.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {335–342},
numpages = {8},
keywords = {universal, usability, scale, definition, master},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985736,
author = {St. Amant, Robert and Horton, Thomas E. and Ritter, Frank E.},
title = {Model-Based Evaluation of Cell Phone Menu Interaction},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985736},
doi = {10.1145/985692.985736},
abstract = {Cell phone interfaces are now ubiquitous. In this paper, we describe concepts to support the analysis of cell phone menu hierarchies. We present an empirical study of user performance on five simple tasks of menu traversal on a cell phone. Two models we tested, based on GOMS and ACT-R, give very good predictions of behavior. We use the study results to motivate an effective evaluation process for menu hierarchies. Our work makes several contributions: a novel and timely study of a new, very common HCI task; new models for accurately predicting performance; novel development tools to support such modeling; and a search procedure to generate menu hierarchies that reduce traversal time, in simulation studies, by about a third.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {343–350},
numpages = {8},
keywords = {mobile telephones, menu traversal, evaluation, cognitive modeling},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985737,
author = {Pavlovych, Andriy and Stuerzlinger, Wolfgang},
title = {Model for Non-Expert Text Entry Speed on 12-Button Phone Keypads},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985737},
doi = {10.1145/985692.985737},
abstract = {In this paper we present a new model for predicting text entry speed on a 12-button mobile phone keypad. The proposed model can predict the performance of novice users. Like other models for text entry, the proposed model includes a movement component based on Fitts' law and a linguistic component based on letter digraph probabilities. It also adds cognitive delay times before key presses and takes into account the fact that Fitts' law cannot model multiple presses of the same key accurately. Finally, we compare the prediction of our model to previously published experimental results, demonstrate that it fits observed results for novices very well, and list some observations about learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {351–358},
numpages = {8},
keywords = {model, mobile phones, text entry},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985738,
author = {Po, Barry A. and Fisher, Brian D. and Booth, Kellogg S.},
title = {Mouse and Touchscreen Selection in the Upper and Lower Visual Fields},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985738},
doi = {10.1145/985692.985738},
abstract = {Neuroanatomical evidence indicates the human eye's visual field can be functionally divided into two vertical hemifields, each specialized for specific functions. The upper visual field (UVF) is specialized to support perceptual tasks in the distance, while the lower visual field (LVF) is specialized to support visually-guided motor tasks, such as pointing. We present a user study comparing mouse- and touchscreen-based pointing for items presented in the UVF and LVF on an interactive display. Consistent with the neuroscience literature, we found that mouse and touchscreen pointing were faster and more accurate for items presented in the LVF when compared to pointing at identical targets presented in the UVF. Further analysis found previously unreported performance differences between the visual fields for touchscreen pointing that were not observed for mouse pointing. This indicates that a placement of interactive items favorable to the LVF yields superior user performance, especially for systems dependent on direct touch interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {359–366},
numpages = {8},
keywords = {touchscreens, interactive displays, Fitts Law, visual fields, pointing, mice},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985739,
author = {Baudisch, Patrick and Gutwin, Carl},
title = {Multiblending: Displaying Overlapping Windows Simultaneously without the Drawbacks of Alpha Blending},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985739},
doi = {10.1145/985692.985739},
abstract = {Alpha blending allows the simultaneous display of overlapping windows-such as palette windows in visual workspaces. Although alpha blending has been used in some applications, such as games, it has not been widely adopted. One reason for the limited acceptance is that in many scenarios, alpha blending compromises the readability of content. We introduce a new blending mechanism called multiblending that uses a vector of blending weights, one for each class of features, rather than a single transparency value. Multiblending can in most cases be automatically optimized to preserve the most relevant features of both the palette and the background window. We present the results of a user study in which multiblended palettes provided higher recognizability of both the background and the palette than the best participating version of alpha blending.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {367–374},
numpages = {8},
keywords = {windows, semitransparency, alpha blending},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985740,
author = {Muller, Michael J. and Geyer, Werner and Brownholtz, Beth and Wilcox, Eric and Millen, David R.},
title = {One-Hundred Days in an Activity-Centric Collaboration Environment Based on Shared Objects},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985740},
doi = {10.1145/985692.985740},
abstract = {This paper describes a new collaboration technology that is carefully poised between informal, ad hoc, easy-to-initiate collaborative tools, vs. more formal, structured, and high-overhead collaborative applications. Our approach focuses on the support of lightweight, informally structured, opportunistic activities featuring heterogeneous threads of shared objects with dynamic membership. We introduce our design concepts, and we provide a detailed first look at data from the first 100 days of usage by 20 researchers and 13 interns, who both confirmed our hypotheses and surprised us by reinventing the technology in several ways.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {375–382},
numpages = {8},
keywords = {activity-centric collaboration, computer-mediated communication, CSCW, synchronous/asynchronous collaboration, user study},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985741,
author = {Baker, Ryan Shaun and Corbett, Albert T. and Koedinger, Kenneth R. and Wagner, Angela Z.},
title = {Off-Task Behavior in the Cognitive Tutor Classroom: When Students "Game the System"},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985741},
doi = {10.1145/985692.985741},
abstract = {We investigate the prevalence and learning impact of different types of off-task behavior in classrooms where students are using intelligent tutoring software. We find that within the classrooms studied, no other type of off-task behavior is associated nearly so strongly with reduced learning as "gaming the system": behavior aimed at obtaining correct answers and advancing within the tutoring curriculum by systematically taking advantage of regularities in the software's feedback and help. A student's frequency of gaming the system correlates as strongly to post-test score as the student's prior domain knowledge and general academic achievement. Controlling for prior domain knowledge, students who frequently game the system score substantially lower on a post-test than students who never game the system. Analysis of students who choose to game the system suggests that learned helplessness or performance orientation might be better accounts for why students choose this behavior than lack of interest in the material. This analysis will inform the future re-design of tutors to respond appropriately when students game the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {383–390},
numpages = {8},
keywords = {off-task behavior, user modeling, field research methods, intelligent tutoring systems},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985742,
author = {Crabtree, Andy and Benford, Steve and Rodden, Tom and Greenhalgh, Chris and Flintham, Martin and Anastasi, Rob and Drozd, Adam and Adams, Matt and Row-Farr, Ju and Tandavanitj, Nick and Steed, Anthony},
title = {Orchestrating a Mixed Reality Game 'on the Ground'},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985742},
doi = {10.1145/985692.985742},
abstract = {Successfully staging a mixed reality game in which online players are chased through a virtual city by runners located in the real world requires extensive orchestration work. An ethnographic study shows how this concerted achievement extends beyond the control room to the runners on the street. This, in turn, suggests the need to 'decentralize' orchestration and develop support for collaboration 'on the ground'. The study leads to design proposals for orchestration interfaces for mobile experiences that augment situational awareness and surreptitious monitoring among mobile participants and support troubleshooting in situations where participants are disconnected or are unable to access positioning systems such as GPS.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {391–398},
numpages = {8},
keywords = {orchestration, GPS, mobile &amp; wireless games, ethnography},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985743,
author = {Klemmer, Scott R. and Li, Jack and Lin, James and Landay, James A.},
title = {Papier-Mache: Toolkit Support for Tangible Input},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985743},
doi = {10.1145/985692.985743},
abstract = {Tangible user interfaces (TUIs) augment the physical world by integrating digital information with everyday physical objects. Currently, building these UIs requires "getting down and dirty" with input technologies such as computer vision. Consequently, only a small cadre of technology experts can currently build these UIs. Based on a literature review and structured interviews with nine TUI researchers, we created Papier-M\^{a}ch\'{e}, a toolkit for building tangible interfaces using computer vision, electronic tags, and barcodes. Papier-Mache introduces a high-level event model for working with these technologies that facilitates technology portability. For example, an application can be prototyped with computer vision and deployed with RFID. We present an evaluation of our toolkit with six class projects and a user study with seven programmers, finding the input abstractions, technology portability, and monitoring window to be highly effective.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {399–406},
numpages = {8},
keywords = {API design, barcode, toolkits, tangible interfaces, augmented reality, computer vision, RFID},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985744,
author = {Moffatt, Karyn and McGrenere, Joanna and Purves, Barbara and Klawe, Maria},
title = {The Participatory Design of a Sound and Image Enhanced Daily Planner for People with Aphasia},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985744},
doi = {10.1145/985692.985744},
abstract = {Aphasia is a cognitive disorder that impairs speech and language. From interviews with aphasic individuals, their caregivers, and speech-language pathologists, the need was identified for a daily planner that allows aphasic users to independently manage their appointments. We used a participatory design approach to develop ESI Planner (the Enhanced with Sound and Images Planner) for use on a PDA and subsequently evaluated it in a lab study. This methodology was used in order to achieve both usable and adoptable technology. In addition to describing our experience in designing ESI Planner, two main contributions are provided: general guidelines for working with special populations in the development of technology, and design guidelines for accessible handheld technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {407–414},
numpages = {8},
keywords = {universal usability, handheld devices, assistive technology, multi-modal interaction, cognitive disabilities, participatory design},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985745,
author = {Teevan, Jaime and Alvarado, Christine and Ackerman, Mark S. and Karger, David R.},
title = {The Perfect Search Engine is Not Enough: A Study of Orienteering Behavior in Directed Search},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985745},
doi = {10.1145/985692.985745},
abstract = {This paper presents a modified diary study that investigated how people performed personally motivated searches in their email, in their files, and on the Web. Although earlier studies of directed search focused on keyword search, most of the search behavior we observed did not involve keyword search. Instead of jumping directly to their information target using keywords, our participants navigated to their target with small, local steps using their contextual knowledge as a guide, even when they knew exactly what they were looking for in advance. This stepping behavior was especially common for participants with unstructured information organization. The observed advantages of searching by taking small steps include that it allowed users to specify less of their information need and provided a context in which to understand their results. We discuss the implications of such advantages for the design of personal information management tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {415–422},
numpages = {8},
keywords = {search, orienteering, information seeking, observational study, teleporting, context},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985746,
author = {Isokoski, Poika},
title = {Performance of Menu-Augmented Soft Keyboards},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985746},
doi = {10.1145/985692.985746},
abstract = {We report results on the performance of the combination of soft keyboards and marking menus. A model of expert user performance indicated an 11 - 37% (depending on the keyboard layout) improvement in text entry rate over the same keyboard without the menu. To verify the advantage in real usage, we conducted two experiments using the QWERTY keyboard layout with and without the menu. The first experiment imitated nearly perfect cognitive performance and measured motor performance. Using the menu saved time. The second experiment measured performance in a realistic text entry task. Initially using the menu slows down text entry. By the end of the 20-session experiment both conditions were equally fast. With continued practice text entry is likely to be faster with the menu.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {423–430},
numpages = {8},
keywords = {Fitts' law, text entry, soft keyboard, marking menu},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985747,
author = {Gergle, Darren and Millen, David R. and Kraut, Robert E. and Fussell, Susan R.},
title = {Persistence Matters: Making the Most of Chat in Tightly-Coupled Work},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985747},
doi = {10.1145/985692.985747},
abstract = {How much history of the dialogue should a chat client include? Some chat clients have minimized the dialogue history to deploy the space for other purposes. A theory of conversational coordination suggests that stripping away history raises the cost of conversational grounding, creating problems for both writers and readers. To test this proposition and inform design, we conducted an experiment in which one person instructed another on how to solve a simple puzzle. Participants had chat clients that showed either a single conversational turn or six of them. Having the dialogue history helped collaborators communicate efficiently and led to faster and better task performance. The dialogue history was most useful when the puzzles were more linguistically complex and when instructors could not see the work area. We present evidence of participants adapting their discourse to partially compensate for deficits in the communication media.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {431–438},
numpages = {8},
keywords = {shared visual space, persistence, language, empirical studies, computer-mediated communication, communication, text chat},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985748,
author = {Tan, Desney S. and Gergle, Darren and Scupelli, Peter G. and Pausch, Randy},
title = {Physically Large Displays Improve Path Integration in 3D Virtual Navigation Tasks},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985748},
doi = {10.1145/985692.985748},
abstract = {Previous results have shown that users perform better on spatial orientation tasks involving static 2D scenes when working on physically large displays as compared to small ones. This was found to be true even when the displays presented the same images at equivalent visual angles. Further investigation has suggested that large displays may provide a greater sense of presence, which biases users into adopting more efficient strategies to perform tasks. In this work, we extend those findings, demonstrating that users are more effective at performing 3D virtual navigation tasks on large displays. We also show that even though interacting with the environment affects performance, effects induced by interactivity are independent of those induced by physical display size. Together, these findings allow us to derive guidelines for the design and presentation of interactive 3D environments on physically large displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {439–446},
numpages = {8},
keywords = {path integration, physically large display, visual angle, presence, 3D virtual navigation, field of view, immersion},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985749,
author = {Grossman, Tovi and Balakrishnan, Ravin},
title = {Pointing at Trivariate Targets in 3D Environments},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985749},
doi = {10.1145/985692.985749},
abstract = {We investigate pointing in true 3D environments where the target size varies in three spatial dimensions. We also study the effect of the user's physical movement angle on pointing performance. Results show that target size dimension along the primary axis of movement has a greater impact on performance than the other two dimensions. Movement angle also significantly affects performance, and changes the relative impact of the three target dimensions. Building upon recent results in the modeling of bivariate pointing, we propose and validate a new model that describes pointing at trivariate targets. This model also accounts for movement angle, and outperforms previously published models.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {447–454},
numpages = {8},
keywords = {3D Fitts' Law, pointing, volumetric displays},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985750,
author = {John, Bonnie E. and Prevas, Konstantine and Salvucci, Dario D. and Koedinger, Ken},
title = {Predictive Human Performance Modeling Made Easy},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985750},
doi = {10.1145/985692.985750},
abstract = {Although engineering models of user behavior have enjoyed a rich history in HCI, they have yet to have a widespread impact due to the complexities of the modeling process. In this paper we describe a development system in which designers generate predictive cognitive models of user behavior simply by demonstrating tasks on HTML mock-ups of new interfaces. Keystroke-Level Models are produced automatically using new rules for placing mental operators, then implemented in the ACT-R cognitive architecture. They interact with the mock-up through integrated perceptual and motor modules, generating behavior that is automatically quantified and easily examined. Using a query-entry user interface as an example [19], we demonstrate that this new system enables more rapid development of predictive models, with more accurate results, than previously published models of these tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {455–462},
numpages = {8},
keywords = {KLM, cognitive modeling, GOMS},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985751,
author = {Heer, Jeffrey and Good, Nathaniel S. and Ramirez, Ana and Davis, Marc and Mankoff, Jennifer},
title = {Presiding over Accidents: System Direction of Human Action},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985751},
doi = {10.1145/985692.985751},
abstract = {As human-computer interaction becomes more closely modeled on human-human interaction, new techniques and strategies for human-computer interaction are required. In response to the inevitable shortcomings of recognition technologies, researchers have studied mediation: interaction techniques by which users can resolve system ambiguity and error. In this paper we approach the human-computer dialogue from the other side, examining system-initiated direction and mediation of human action. We conducted contextual interviews with a variety of experts in fields involving human-human direction, including a film director, photographer, golf instructor, and 911 operator. Informed by these interviews and a review of prior work, we present strategies for directing physical human action and an associated design space for systems that perform such direction. We illustrate these concepts with excerpts from our interviews and with our implemented system for automated media capture or "Active Capture," in which an unaided computer system uses techniques identified in our design space to act as a photographer, film director, and cinematographer.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {463–470},
numpages = {8},
keywords = {active capture, mediation, multimedia systems design, error-prone systems, error, direction, recognition},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985752,
author = {Jensen, Carlos and Potts, Colin},
title = {Privacy Policies as Decision-Making Tools: An Evaluation of Online Privacy Notices},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985752},
doi = {10.1145/985692.985752},
abstract = {Studies have repeatedly shown that users are increasingly concerned about their privacy when they go online. In response to both public interest and regulatory pressures, privacy policies have become almost ubiquitous. An estimated 77% of websites now post a privacy policy. These policies differ greatly from site to site, and often address issues that are different from those that users care about. They are in most cases the users' only source of information.This paper evaluates the usability of online privacy policies, as well as the practice of posting them. We analyze 64 current privacy policies, their accessibility, writing, content and evolution over time. We examine how well these policies meet user needs and how they can be improved. We determine that significant changes need to be made to current practice to meet regulatory and usability requirements.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {471–478},
numpages = {8},
keywords = {privacy, WWW, consent, readability, e-commerce, usability},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985753,
author = {Svanaes, Dag and Seland, Gry},
title = {Putting the Users Center Stage: Role Playing and Low-Fi Prototyping Enable End Users to Design Mobile Systems},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985753},
doi = {10.1145/985692.985753},
abstract = {This paper sums up lessons learned from a sequence of cooperative design workshops where end users were enabled to design mobile systems through scenario building, role playing, and low-fidelity prototyping. We present a resulting fixed workshop structure with well-chosen constraints that allows for end users to explore and design new technology and work practices. In these workshops, the systems developers get input to design from observing how users stage and act out current and future use scenarios and improvise new technology to fit their needs. A theoretical framework is presented to explain the creative processes involved and the workshop as a user-centered design method. Our findings encourage us to recommend the presented workshop structure for design projects involving mobility and computer-mediated communication, in particular project where the future use of the resulting products and services also needs to be designed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {479–486},
numpages = {8},
keywords = {role playing, participatory design, mobile computing},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985754,
author = {Ramos, Gonzalo and Boulos, Matthew and Balakrishnan, Ravin},
title = {Pressure Widgets},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985754},
doi = {10.1145/985692.985754},
abstract = {Current user interface widgets typically assume that the input device can only provide x-y position and binary button press information. Other inputs such as the continuous pressure data provided by styluses on tablets are rarely used. We explore the design space of using the continuous pressure sensing capabilities of styluses to operate multi-state widgets. We present the results of a controlled experiment that investigates human ability to perform discrete target selection tasks by varying a stylus' pressure, with full or partial visual feedback. The experiment also considers different techniques for confirming selection once the target is acquired. Based on the experimental results, we discuss implications for the design of pressure sensitive widgets. A taxonomy of pressure widgets is presented, along with a set of initial concept sketches of various pressure widget designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {487–494},
numpages = {8},
keywords = {pressure input, isometric input, pressure widgets, pen-based interfaces},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985755,
author = {Bitton, Jo\"{e}lle and Agamanolis, Stefan and Karau, Matthew},
title = {RAW: Conveying Minimally-Mediated Impressions of Everyday Life with an Audio-Photographic Tool},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985755},
doi = {10.1145/985692.985755},
abstract = {This paper traces the development of RAW, a system combining a tool and a process for capturing and conveying audiovisual impressions of everyday life. The project aims to enable a relationship between the user of the tool and an audience in a different place or time with an absolute minimum of editorial mediation by a third party. The tool itself incorporates a digital camera and a binaural audio recording device that captures the minute of sound before and after a picture is taken. To inform the design process, we tested prototypes in a progression of three studies within different cultural contexts in Ireland, France, and Mali. We present the results of these experiences, in which we observed among our participants an emerging set of ways of exploiting the tool for different purposes: social glances, depictions of activities, active documentation, and intentional discourses. We also discuss more generally the advantages and pitfalls of multicultural analyses of prototype technologies like the one we undertook.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {495–502},
numpages = {8},
keywords = {unedited media, binaural sound recording, everyday life, cultural exchange, photography, Africa, memory, storytelling, multicultural studies, Mali, audiophotography, contextual audio},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985756,
author = {Gutwin, Carl and Benford, Steve and Dyck, Jeff and Fraser, Mike and Vaghi, Ivan and Greenhalgh, Chris},
title = {Revealing Delay in Collaborative Environments},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985756},
doi = {10.1145/985692.985756},
abstract = {Delay is an unavoidable reality in collaborative environments. We propose an approach to dealing with delay in which 'decorators' are introduced into the interface. Decorators show the presence, magnitude and effects of delay so that participants can better understand its consequences and adopt their own natural coping strategies. Two experiments with different decorators show that this approach can significantly reduce errors in specific collaborative activities. We conclude that revealing delays is one way in which groupware can benefit from accepting and working with the reality of distributed systems, rather than trying to maintain the illusion of copresent interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {503–510},
numpages = {8},
keywords = {jitter, latency, groupware, collaborative environments, shared workspaces, network delay},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985757,
author = {Hughes, Stephen and Lewis, Michael},
title = {Robotic Camera Control for Remote Exploration},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985757},
doi = {10.1145/985692.985757},
abstract = {A video stream from a single camera is often the foundation for situational awareness in teleoperation activities. Poor camera placement, narrow field-of-view and other camera properties can significantly impair the operator's perceptual link to the environment, inviting cognitive mistakes and general disorientation. This paper provides a brief overview of viewpoint control research for 3D virtual environments (VE) to motivate a user study that evaluates the effectiveness of viewpoint controls on a simulated robotic vehicle. Findings suggest that providing a camera that is controlled independently from the orientation of the vehicle may facilitate wayfinding tasks. Moreover, there is evidence to support the use of separate cameras and interfaces for different navigational subtasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {511–517},
numpages = {7},
keywords = {robotics aided search-and-rescue, human-robot interaction, robotics, remote exploration, viewpoint control},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985758,
author = {Blanch, Renaud and Guiard, Yves and Beaudouin-Lafon, Michel},
title = {Semantic Pointing: Improving Target Acquisition with Control-Display Ratio Adaptation},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985758},
doi = {10.1145/985692.985758},
abstract = {We introduce semantic pointing, a novel interaction technique that improves target acquisition in graphical user interfaces (GUIs). Semantic pointing uses two independent sizes for each potential target presented to the user: one size in motor space adapted to its importance for the manipulation, and one size in visual space adapted to the amount of information it conveys. This decoupling between visual and motor size is achieved by changing the control-to-display ratio according to cursor distance to nearby targets. We present a controlled experiment supporting our hypothesis that the performance of semantic pointing is given by Fitts' index of difficulty in motor rather than visual space. We apply semantic pointing to the redesign of traditional GUI widgets by taking advantage of the independent manipulation of motor and visual widget sizes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {519–526},
numpages = {8},
keywords = {pointing, Fitts' law, graphical user interface, semantic pointing, control-display ratio},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985759,
author = {Whittaker, Steve and Amento, Brian},
title = {Semantic Speech Editing},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985759},
doi = {10.1145/985692.985759},
abstract = {Editing speech data is currently time-consuming and error-prone. Speech editors rely on acoustic waveform representations, which force users to repeatedly sample the underlying speech to identify words and phrases to edit. Instead we developed a semantic editor that reduces the need for extensive sampling by providing access to meaning. The editor shows a time-aligned errorful transcript produced by applying automatic speech recognition (ASR) to the original speech. Users visually scan the words in the transcript to identify important phrases. They then edit the transcript directly using standard word processing 'cut and paste' operations, which extract the corresponding time-aligned speech. ASR errors mean that users must supplement what they read in the transcript by accessing the original speech. Even when there are transcript errors, however, the semantic representation still provides users with enough information to target what they edit and play, reducing the need for extensive sampling. A laboratory evaluation showed that semantic editing is more efficient than acoustic editing even when ASR is highly inaccurate.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {527–534},
numpages = {8},
keywords = {speech browsing, speech retrieval, acoustic representations, speech recognition, speech editing, transcripts},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985760,
author = {McCarthy, John D. and Sasse, M. Angela and Miras, Dimitrios},
title = {Sharp or Smooth? Comparing the Effects of Quantization vs. Frame Rate for Streamed Video},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985760},
doi = {10.1145/985692.985760},
abstract = {We introduce a new methodology to evaluate the perceived quality of video with variable physical quality. The methodology is used to evaluate existing guidelines - that high frame rate is more important than quantization when watching high motion video, such as sports coverage. We test this claim in two studies that examine the relationship between these physical quality metrics and perceived quality. In Study 1, 41 soccer fans viewed CIF-sized images on a desktop computer. Study 2 repeated the experiment with 37 soccer fans, viewing the same content, in QCIF size, on a palmtop device. Contrary to existing guidelines, we found that users prefer high-resolution images to high frame rate. We conclude that the rule "high motion = high frame rate" does not apply to small screens. With small screen devices, reducing quantization removes important information about the players and the ball. These findings have important implications for service providers and designers of streamed video applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {535–542},
numpages = {8},
keywords = {eye tracking, video frame rate, Quality of Service, quantization factors, video streaming},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985761,
author = {Lampe, Cliff and Resnick, Paul},
title = {Slash(Dot) and Burn: Distributed Moderation in a Large Online Conversation Space},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985761},
doi = {10.1145/985692.985761},
abstract = {Can a system of distributed moderation quickly and consistently separate high and low quality comments in an online conversation? Analysis of the site Slashdot.org suggests that the answer is a qualified yes, but that important challenges remain for designers of such systems. Thousands of users act as moderators. Final scores for comments are reasonably dispersed and the community generally agrees that moderations are fair. On the other hand, much of a conversation can pass before the best and worst comments are identified. Of those moderations that were judged unfair, only about half were subsequently counterbalanced by a moderation in the other direction. And comments with low scores, not at top-level, or posted late in a conversation were more likely to be overlooked by moderators.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {543–550},
numpages = {8},
keywords = {computer-mediated communication, recommender systems, collaborative filtering},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985762,
author = {Fisher, Danyel and Dourish, Paul},
title = {Social and Temporal Structures in Everyday Collaboration},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985762},
doi = {10.1145/985692.985762},
abstract = {Everyday work frequently involves coordinating and collaborating with others, but the structure of collaboration is largely invisible to conventional desktop applications. We are exploring ways to support everyday collaboration by allowing applications access to the social, organizational, and temporal settings within which work is conducted. In this paper, we present two generations of systems supporting everyday collaboration, focusing on ways to recover and represent the temporal and social structures of online activity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {551–558},
numpages = {8},
keywords = {social networks, collaboration patterns, awareness},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985763,
author = {Erickson, Thomas and Huang, Wei and Danis, Catalina and Kellogg, Wendy A.},
title = {A Social Proxy for Distributed Tasks: Design and Evaluation of a Working Prototype},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985763},
doi = {10.1145/985692.985763},
abstract = {This paper describes an approach to managing tasks and processes that are distributed across a large number of people. The basic idea is to use a social visualization called a task proxy to create a shared awareness amongst the participants in a task or process. The process awareness provided by the task proxy enables its users to monitor the task state, the states of participants, and to communicate with those in particular states. We describe the concept, a first prototype, its evaluation, and discuss future directions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {559–566},
numpages = {8},
keywords = {design, awareness, workflow, visualization, social proxy, CSCW, task support, social computing, process awareness},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985764,
author = {Anderson, Richard J. and Hoyer, Crystal and Wolfman, Steven A. and Anderson, Ruth},
title = {A Study of Digital Ink in Lecture Presentation},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985764},
doi = {10.1145/985692.985764},
abstract = {Digital inking systems are becoming increasingly popular across a variety of domains. In particular, many systems now allow instructors to write on digital surfaces in the classroom. Yet, our understanding of how people actually use writing in these systems is limited. In this paper, we report on classroom use of writing in one such system, in which the instructor annotates projected slides using a Tablet PC. Through a detailed analysis of lecture archives, we identify key use patterns. In particular, we categorize a major use of ink as analogous to physical gestures and present a framework for analyzing this ink; we explore the relationship between the ephemeral meaning of many annotations and their persistent representation; and we observe that instructors make conservative use of the system's features. Finally, we discuss implications of our study to the design of future digital inking systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {567–574},
numpages = {8},
keywords = {educational technology, classroom presentation, distance learning, digital ink, penbased user interface},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985765,
author = {Vi\'{e}gas, Fernanda B. and Wattenberg, Martin and Dave, Kushal},
title = {Studying Cooperation and Conflict between Authors with <i>History Flow</i> Visualizations},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985765},
doi = {10.1145/985692.985765},
abstract = {The Internet has fostered an unconventional and powerful style of collaboration: "wiki" web sites, where every visitor has the power to become an editor. In this paper we investigate the dynamics of Wikipedia, a prominent, thriving wiki. We make three contributions. First, we introduce a new exploratory data analysis tool, the history flow visualization, which is effective in revealing patterns within the wiki context and which we believe will be useful in other collaborative situations as well. Second, we discuss several collaboration patterns highlighted by this visualization tool and corroborate them with statistical analysis. Third, we discuss the implications of these patterns for the design and governance of online collaborative social spaces. We focus on the relevance of authorship, the value of community surveillance in ameliorating antisocial behavior, and how authors with competing perspectives negotiate their differences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {575–582},
numpages = {8},
keywords = {collaboration, wiki, revision history, document, visualization},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985766,
author = {Boardman, Richard and Sasse, M. Angela},
title = {"Stuff Goes into the Computer and Doesn't Come out": A Cross-Tool Study of Personal Information Management},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985766},
doi = {10.1145/985692.985766},
abstract = {This paper reports a study of Personal Information Management (PIM), which advances research in two ways: (1) rather than focusing on one tool, we collected cross-tool data relating to file, email and web bookmark usage for each participant, and (2) we collected longitudinal data for a subset of the participants. We found that individuals employ a rich variety of strategies both within and across PIM tools, and we present new strategy classifications that reflect this behaviour. We discuss synergies and differences between tools that may be useful in guiding the design of tool integration. Our longitudinal data provides insight into how PIM behaviour evolves over time, and suggests how the supporting nature of PIM discourages reflection by users on their strategies. We discuss how the promotion of some reflection by tools and organizations may benefit users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {583–590},
numpages = {8},
keywords = {user study, tool integration, web bookmarks, email, personal information management, files},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985767,
author = {Tsang, Steve and Balakrishnan, Ravin and Singh, Karan and Ranjan, Abhishek},
title = {A Suggestive Interface for Image Guided 3D Sketching},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985767},
doi = {10.1145/985692.985767},
abstract = {We present an image guided pen-based suggestive interface for sketching 3D wireframe models. Rather than starting from a blank canvas, existing 2D images of similar objects serve as a guide to the user. Image based filters enable attraction, smoothing, and resampling of input curves, and allows for their selective application using pinning and gluing techniques. New input strokes also invoke suggestions of relevant geometry that can be used, reducing the need to explicitly draw all parts of the new model. All suggestions appear in-place with the model being built, in the user's focal attention space. A curve matching algorithm seamlessly augments basic suggestions with more complex ones from a database populated with previously used geometry. The interface also incorporates gestural command input, and interaction techniques for camera controls that enable smooth transitions between orthographic and perspective views.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {591–598},
numpages = {8},
keywords = {sketching interfaces, image based interaction},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985768,
author = {Counts, Scott and Fellheimer, Eric},
title = {Supporting Social Presence through Lightweight Photo Sharing on and off the Desktop},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985768},
doi = {10.1145/985692.985768},
abstract = {Lightweight photo sharing, particularly via mobile devices, is fast becoming a common communication medium used for maintaining a presence in the lives of friends and family. How should such systems be designed to maximize this social presence while maintaining simplicity? An experimental photo sharing system was developed and tested that, compared to current systems, offers highly simplified, group-centric sharing, automatic and persistent people-centric organization, and tightly integrated desktop and mobile sharing and viewing. In an experimental field study, the photo sharing behaviors of groups of family or friends were studied using their normal photo sharing methods and with the prototype sharing system. Results showed that users found photo sharing easier and more fun, shared more photos, and had an enhanced sense of social presence when sharing with the experimental system. Results are discussed in the context of design principles for the rapidly increasing number of lightweight photo sharing systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {599–606},
numpages = {8},
keywords = {photo sharing, mobile devices, social computing, digital photographs, social presence},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985769,
author = {Mizobuchi, Sachi and Yasumura, Michiaki},
title = {Tapping vs. Circling Selections on Pen-Based Devices: Evidence for Different Performance-Shaping Factors},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985769},
doi = {10.1145/985692.985769},
abstract = {Tapping-based selection methods for handheld devices may need to be supplemented with other approaches as increasingly complex tasks are carried out using those devices. Circling selection methods (such as the Lasso) allow users to select objects on a touch screen by circling with a pen. An experimental comparison of the selection time and accuracy between a circling method and a traditional tapping style of selection was carried out. The experiment used a two dimensional grid (varying in terms of the sizes and the distances of the targets). Analysis of variance showed that tapping selection time differed significantly depending on the size and spacing of the targets. In contrast, circling selection times differed significantly for different levels of target cohesiveness and shape complexity. The results are discussed in terms of implications for design of new pen-based selection methods for handheld devices, and also in terms of evaluation methodology for input selection methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {607–614},
numpages = {8},
keywords = {gesture input, handheld devices, input and interaction technologies, pen user interface, target selection},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985770,
author = {Karahalios, Karrie and Donath, Judith},
title = {Telemurals: Linking Remote Spaces with Social Catalysts},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985770},
doi = {10.1145/985692.985770},
abstract = {Telemurals is an abstract audio-video installation that seeks to initiate and sustain interaction between and within two remote spaces. Our goal is to improve the social aspects of casual mediated communications by incorporating events into the design of the communication medium that encourage people to engage in interaction when they otherwise would not. We call these events social catalysts, for they encourage people to initiate and sustain interaction. In this paper we discuss the design process and goals of our first Telemurals link between two public spaces, the building of Telemurals, and an ethnographic study describing how the system affected interaction between and within these two spaces based on the theories discussed in this paper.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {615–622},
numpages = {8},
keywords = {telepresence, ethnography, social catalyst, remote connections, video, mediated communication, mediated spaces, social interaction},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985771,
author = {Goza, S. M. and Ambrose, R. O. and Diftler, M. A. and Spain, I. M.},
title = {Telepresence Control of the NASA/DARPA Robonaut on a Mobility Platform},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985771},
doi = {10.1145/985692.985771},
abstract = {Engineers at the Johnson Space Center recently combined the upper body of the National Aeronautics and Space Administration (NASA) / Defense Advanced Research Projects Agency (DARPA) Robonaut system with a Robotic Mobility Platform (RMP) to make an extremely mobile humanoid robot designed to interact with human teammates. Virtual Reality gear that immerses a human operator into Robonaut's working environment provides the primary control pathway for remote operations. Human/robot interface challenges are addressed in the control system for teleoperators, console operators and humans working directly with the Robonaut. Multiple control modes are available for controlling the five fingered dexterous robot hands and operator selectable depending on the type of grasp required. A relative positioning system is used to maximize operator comfort during arm and head motions. Foot pedals control the mobility base. Initial tasks that include working with human rated tools, navigating hallways and cutting wires are presented and show the effectiveness of telepresence control for this class of robot.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {623–629},
numpages = {7},
keywords = {telepresence, humanoid robot, teleoperation},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985772,
author = {Ludford, Pamela J. and Cosley, Dan and Frankowski, Dan and Terveen, Loren},
title = {Think Different: Increasing Online Community Participation Using Uniqueness and Group Dissimilarity},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985772},
doi = {10.1145/985692.985772},
abstract = {Online communities can help people form productive relationships. Unfortunately, this potential is not always fulfilled: many communities fail, and designers don't have a solid understanding of why. We know community activity begets activity. The trick, however, is to inspire participation in the first place. Social theories suggest methods to spark positive community participation. We carried out a field experiment that tested two such theories. We formed discussion communities around an existing movie recommendation web site, manipulating two factors: (1) similarity-we controlled how similar group members' movie ratings were; and (2) uniqueness-we told members how their movie ratings (with respect to a discussion topic) were unique within the group. Both factors positively influenced participation. The results offer a practical success story in applying social science theory to the design of online communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {631–638},
numpages = {8},
keywords = {online communities, social psychology, recommender systems, uniqueness, similarity},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985773,
author = {Ingmarsson, Magnus and Dinka, David and Zhai, Shumin},
title = {TNT: A Numeric Keypad Based Text Input Method},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985773},
doi = {10.1145/985692.985773},
abstract = {With the evolving functionality in television-based (TV-based) information and entertainment appliances, there is an increased need to enable users input text through remote control devices. We present a novel text input method, The Numpad Typer (TNT), for interactive TV, multimedia home terminals or other similar applications. Embodied in a TV remote control and guided by a visual map on the TV screen, TNT was designed for consistent spatial Stimuli-Response (S-R) compatibility and consistency of use. Five users tested TNT in ten sessions of 45-minutes. This initial investigation showed that users on average could type 9.3 and 17.7 correct words per minute with TNT doing the slowest and the fastest session respectively. The study also showed that the users found the TNT method easy to grasp and fun to use. Subjectively the participants felt they mastered the method rather quickly in comparison to their actual speed improvement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {639–646},
numpages = {8},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985774,
author = {Raffle, Hayes Solos and Parkes, Amanda J. and Ishii, Hiroshi},
title = {Topobo: A Constructive Assembly System with Kinetic Memory},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985774},
doi = {10.1145/985692.985774},
abstract = {We introduce Topobo, a 3D constructive assembly system embedded with kinetic memory, the ability to record and playback physical motion. Unique among modeling systems is Topobo's coincident physical input and output behaviors. By snapping together a combination of Passive (static) and Active (motorized) components, people can quickly assemble dynamic biomorphic forms like animals and skeletons with Topobo,animate those forms by pushing, pulling, and twisting them, and observe the system repeatedly play back those motions. For example, a dog can be constructed and then taught to gesture and walk by twisting its body and legs. The dog will then repeat those movements and walk repeatedly.Our evaluation of Topobo in classrooms with children ages 5-13 suggests that children develop affective relationships with Topobo creations and that their experimentation with Topobo allows them to learn about movement and animal locomotion through comparisons of their creations to their own bodies. Eighth grade science students' abilities to quickly develop various types of walking robots suggests that a tangible interface can support understanding how balance, leverage and gravity affect moving structures because the interface itself responds to the forces of nature that constrain such systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {647–654},
numpages = {8},
keywords = {digital manipulative, toy, modular robotics, children, learning, tangible interface, education, programming by demonstration},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985775,
author = {Nakanishi, Hideyuki and Koizumi, Satoshi and Ishida, Toru and Ito, Hideaki},
title = {Transcendent Communication: Location-Based Guidance for Large-Scale Public Spaces},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985775},
doi = {10.1145/985692.985775},
abstract = {Many studies have been conducted on supporting communication in home and office spaces, but relatively few studies have explored supporting communication in large-scale public spaces, despite the importance of such environments in our daily lives. We propose a transcendent means of communication as an emerging style in this pervasive computing era: a system that allows administrative staff to effectively help visitors in large-scale public spaces. The visitors' context is used to provide a bird's-eye view of a simulated public space for the staff to grasp the situation and point at a particular location within the view to indicate the visitors they intend to address. The results of an experiment showed synergic effects between the bird's-eye view and the first-person one in determining the spatial movements of people. In indoor and outdoor large-scale public spaces, a central railway station and a park, we installed our prototypes and learned the implications of its use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {655–662},
numpages = {8},
keywords = {bird's-eye view, transcendent communication, public space, station, visual communication, park, simulated space},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985776,
author = {Sillence, Elizabeth and Briggs, Pam and Fishwick, Lesley and Harris, Peter},
title = {Trust and Mistrust of Online Health Sites},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985776},
doi = {10.1145/985692.985776},
abstract = {Do different design and information content factors influence trust and mistrust of online health sites? Fifteen women faced with a risky health decision were observed while searching the Internet for information and advice over four consecutive weeks. In some sessions their searches were unstructured, whilst in other sessions they were directed to review specific sites, chosen for their trust design elements. Content analysis of concurrent verbalisations and group discussion protocols provided support for a staged model wherein design appeal predicted rejection (mistrust) and credibility of information and personalisation of content predicted selection (trust) of advice sites.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {663–670},
numpages = {8},
keywords = {credibility, social identity, Internet, computer-mediated communication, trust, health},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985777,
author = {Lyons, Kent and Starner, Thad and Plaisted, Daniel and Fusia, James and Lyons, Amanda and Drew, Aaron and Looney, E. W.},
title = {Twiddler Typing: One-Handed Chording Text Entry for Mobile Phones},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985777},
doi = {10.1145/985692.985777},
abstract = {An experienced user of the Twiddler, a one--handed chording keyboard, averages speeds of 60 words per minute with letter--by--letter typing of standard test phrases. This fast typing rate coupled with the Twiddler's 3x4 button design, similar to that of a standard mobile telephone, makes it a potential alternative to multi--tap for text entry on mobile phones. Despite this similarity, there is very little data on the Twiddler's performance and learnability. We present a longitudinal study of novice users' learning rates on the Twiddler. Ten participants typed for 20 sessions using two different methods. Each session is composed of 20 minutes of typing with multi--tap and 20 minutes of one--handed chording on the Twiddler. We found that users initially have a faster average typing rate with multi--tap; however, after four sessions the difference becomes negligible, and by the eighth session participants type faster with chording on the Twiddler. Furthermore, after 20 sessions typing rates for the Twiddler are still increasing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {671–678},
numpages = {8},
keywords = {chording, mobile phones, keypad input, text entry, multi--tap},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985778,
author = {Jiang, Xiaodong and Hong, Jason I. and Takayama, Leila A. and Landay, James A.},
title = {Ubiquitous Computing for Firefighters: Field Studies and Prototypes of Large Displays for Incident Command},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985778},
doi = {10.1145/985692.985778},
abstract = {In this paper, we demonstrate how field studies, interviews, and low-fidelity prototypes can be used to inform the design of ubiquitous computing systems for firefighters. We describe the artifacts and processes used by firefighters to assess, plan, and communicate during emergency situations, showing how accountability affects these decisions, how their current Incident Command System supports these tasks, and some drawbacks of existing solutions. These factors informed the design of a large electronic display for supporting the incident commander, the person who coordinates the overall response strategy in an emergency. Although our focus was on firefighters, our results are applicable for other aspects of emergency response as well, due to common procedures and training.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {679–686},
numpages = {8},
keywords = {firefighter, field study, ubiquitous computing, low-fidelity prototypes, emergency response},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985779,
author = {Lin, Min and Lutters, Wayne G. and Kim, Tina S.},
title = {Understanding the Micronote Lifecycle: Improving Mobile Support for Informal Note Taking},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985779},
doi = {10.1145/985692.985779},
abstract = {People frequently write messages to themselves. These informal, hurried personal jottings serve as temporary storage for notable information as well as reminders for future action. Many mobile technologies have been designed specifically to support this ubiquitous behavior; however, adoption has been universally problematic. Despite its clear utility, the process of taking micronotes stubbornly resists computing support. This field study examines the lifecycles of the canonical micronote forms (immediate use, temporary storage, and prospective memory aid), pinpointing the behaviors that are mismatched with current mobile support. Implications for improving the design of these systems are presented, culminating in a vision for integrated paper-digital micronote systems. This shifts the development focus away from trying to support the entire micronote lifecycle, emphasizing instead the different behaviors best supported by the different technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {687–694},
numpages = {8},
keywords = {mobile computing, field study, user study, note taking},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985780,
author = {Everett, Sarah P. and Byrne, Michael D.},
title = {Unintended Effects: Varying Icon Spacing Changes Users' Visual Search Strategy},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985780},
doi = {10.1145/985692.985780},
abstract = {Users of modern GUIs routinely engage in visual searches for various control items, such as buttons and icons. Because this is so ubiquitous, it is important that the visual properties of user interfaces support such searches. The current research is aimed at deepening our understanding of how the visual spacing between icons affects visual search times. We constructed an experiment based on previous icon sets [8] where spacing between icons was systematically manipulated, and for which we had a computational cognitive model that predicted performance. In particular, the model predicted that larger spacing would lead to slower search times. While this prediction was borne out, there was an unanticipated finding: users in this new experiment were substantially slower than in previous similar experiments with smaller spacing. In fact, results from this new experiment were better fit with a model that employed a fundamentally different, and less efficient, search strategy. A second experiment was conducted to explicitly test the surprising result that this varied and larger icon spacing would lead to increased search times. Results were consistent with this hypothesis. These results imply that while small differences in visual layout may not intrinsically produce large differences in user performance, they may cause users to adopt suboptimal strategies that do produce such differences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {695–702},
numpages = {8},
keywords = {user and cognitive models, iconic displays, visual search},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985781,
author = {Cornett, Steve},
title = {The Usability of Massively Multiplayer Online Roleplaying Games: Designing for New Users},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985781},
doi = {10.1145/985692.985781},
abstract = {This study examines the usability challenges faced by new players of massively multiplayer online role-playing games (MMORPGs), one of the fastest-growing segments of the video game industry. Played in completely online worlds, these games allow players to communicate with one another, form groups and communities, and compete in a variety of fantasy environments.Nineteen subjects participated in an exploratory usability study of four games, three MMORPGs and a similar single-player game used for comparison. Results reveal that many people not usually considered as potential players of these games may be interested in them, but a wide variety of usability issues present serious problems for players inexperienced with the genre. Based on an analysis of the usability data and player feedback, specific recommendations are made to improve the experience of these games for new players. These results further demonstrate the applicability and importance of usability testing to video games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {703–710},
numpages = {8},
keywords = {MMORPG, roleplaying game, online game, massively-multiplayer, game usability, RPG},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985782,
author = {Terry, Michael and Mynatt, Elizabeth D. and Nakakoji, Kumiyo and Yamamoto, Yasuhiro},
title = {Variation in Element and Action: Supporting Simultaneous Development of Alternative Solutions},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985782},
doi = {10.1145/985692.985782},
abstract = {The complexity of many problems necessitates creating and exploring multiple, alternative solutions. However, current user interfaces do not cleanly support creating alternatives at a time when they are likely to be discovered: as users interactively modify data. This paper presents Parallel Paths, a novel model of interaction that facilitates generating, manipulating, and comparing alternative solutions. In contrast to existing approaches such as automated history capture tools, Parallel Paths emphasizes the active, simultaneous development of multiple, alternative solutions. We demonstrate this model of interaction in Parallel Pies, a user interface mechanism developed for image manipulation tasks that allows users to: easily create solution alternatives as they interact with a command; embed the alternatives in the same workspace; manipulate the alternatives independently or simultaneously as if they were the same object; and perform side-by-side comparisons of each. Results from an initial evaluation are presented, along with implications for future designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {711–718},
numpages = {8},
keywords = {interaction models, experimentation, parallel exploration, exploration, what-if tools},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985783,
author = {Lin, James J. W. and Abi-Rached, Habib and Lahav, Michal},
title = {Virtual Guiding Avatar: An Effective Procedure to Reduce Simulator Sickness in Virtual Environments},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985783},
doi = {10.1145/985692.985783},
abstract = {This study developed a new procedure, a Virtual Guiding Avatar (VGA), which combined self-motion prediction cues and an independent visual background (IVB) to alleviate simulator sickness (SS). The VGA, which was embodied as an abstract airplane, was designed to lead the participant along a horizontal motion trajectory through a virtual environment. Both motion prediction cues and IVBs, which provide an earth-fixed reference frame, reduced SS in separate previous studies. Participants were exposed to complex visual motion through a cartoon-like simulated environment in a very wide field of view driving simulator. Participants' responses to avatars with varying motion properties - fixed, rotation only or rotation plus translation - were assessed using a within-subjects experimental design. Results indicated that SS was reduced by a VGA that presented rotational cues alone or rotation plus translation. The VGA also increased participants' sense of presence and enjoyment relative to conditions lacking a VGA. The VGA procedure can be used to enhance user experiences in immersive virtual environments as well as to improve motion simulator design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {719–726},
numpages = {8},
keywords = {motion prediction, virtual environment, avatar, simulator sickness, prediction},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985784,
author = {Paek, Tim and Dumais, Susan and Logan, Ron},
title = {WaveLens: A New View onto Internet Search Results},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985784},
doi = {10.1145/985692.985784},
abstract = {Internet search results are typically displayed as a list conforming to a static style sheet. The difficulty of perusing this list can be exacerbated when screen real estate is limited. When space is limited, either, few results are seen, or result descriptions are abbreviated, making it difficult to know whether to follow a particular web link. In this paper, we describe "WaveLens," a dynamic layout technique for displaying search results, which addresses these issues by combining a fisheye lens with progressive exposure of page content. Results from a usability study showed that participants performed faster and more accurately on a search task with one of two distinct parameter settings of WaveLens as compared to the typical static list. In a post-hoc questionnaire, participants favored that setting over both the static list and another setting which involved animated zoom. We discuss design implications for the retrieval and display of search results.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {727–734},
numpages = {8},
keywords = {information visualization, information retrieval, user interface},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985692.985785,
author = {Bellotti, Victoria and Dalal, Brinda and Good, Nathaniel and Flynn, Peter and Bobrow, Daniel G. and Ducheneaut, Nicolas},
title = {What a To-Do: Studies of Task Management towards the Design of a Personal Task List Manager},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985785},
doi = {10.1145/985692.985785},
abstract = {This paper reports on the results of studies of task management to support the design of a task list manager. We examined the media used to record and organize to-dos and tracked how tasks are completed over time. Our work shows that, contrary to popular wisdom, people are not poor at prioritizing. Rather, they have well-honed strategies for tackling particular task management challenges. By illustrating what factors influence task completion and how representations function to support task management, we hope to provide a strong foundation for the design of a personal to-do list manager. We also present some preliminary efforts in this direction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {735–742},
numpages = {8},
keywords = {to-dos, task management, ethnography},
location = {Vienna, Austria},
series = {CHI '04}
}

