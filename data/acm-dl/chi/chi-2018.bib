@inproceedings{10.1145/3173574.3173575,
author = {Das, Sauvik and Lo, Joanne and Dabbish, Laura and Hong, Jason I.},
title = {Breaking! A Typology of Security and Privacy News and How It's Shared},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173575},
doi = {10.1145/3173574.3173575},
abstract = {News coverage of security and privacy (S&amp;P) events is pervasive and may affect the salience of S&amp;P threats to the public. To better understand this coverage and its effects, we asked: What types of S&amp;P news come into people's awareness? How do people hear about and share this news? Over two years, we recruited 1999 participants to fill out a survey on emergent S&amp;P news events. We identified four types of S&amp;P news: financial data breaches, corporate personal data breaches, high sensitivity systems breaches, and politicized / activist cybersecurity. These event types strongly correlated with how people shared S&amp;P news-e.g., financial data breaches were shared most (42%), while politicized / activist cybersecurity events were shared least (21%). Furthermore, participants' age, gender and security behavioral intention strongly correlated with how they heard about and shared S&amp;P news-e.g., males more often felt a personal responsibility to share, and older people were less likely to hear about S&amp;P news through conversation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {usable privacy and security, privacy, social cybersecurity, quantitative methods, news media, cybersecurity},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173576,
author = {Cho, Youngjun and Bianchi-Berthouze, Nadia and Marquardt, Nicolai and Julier, Simon J.},
title = {Deep Thermal Imaging: Proximate Material Type Recognition in the Wild through Deep Learning of Spatial Surface Temperature Patterns},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173576},
doi = {10.1145/3173574.3173576},
abstract = {We introduce Deep Thermal Imaging, a new approach for close-range automatic recognition of materials to enhance the understanding of people and ubiquitous technologies of their proximal environment. Our approach uses a low-cost mobile thermal camera integrated into a smartphone to capture thermal textures. A deep neural network classifies these textures into material types. This approach works effectively without the need for ambient light sources or direct contact with materials. Furthermore, the use of a deep learning network removes the need to handcraft the set of features for different materials. We evaluated the performance of the system by training it to recognize 32 material types in both indoor and outdoor environments. Our approach produced recognition accuracies above 98% in 14,860 images of 15 indoor materials and above 89% in 26,584 images of 17 outdoor materials. We conclude by discussing its potentials for real-time use in HCI applications and future directions.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {thermal imaging, sensing, context-aware mobile computing, in the wild, material recognition, deep learning},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173577,
author = {Liao, Q. Vera and Mas-ud Hussain, Muhammed and Chandar, Praveen and Davis, Matthew and Khazaeni, Yasaman and Crasso, Marco Patricio and Wang, Dakuo and Muller, Michael and Shami, N. Sadat and Geyer, Werner},
title = {All Work and No Play?},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173577},
abstract = {Many conversational agents (CAs) are developed to answer users' questions in a specialized domain. In everyday use of CAs, user experience may extend beyond satisfying information needs to the enjoyment of conversations with CAs, some of which represent playful interactions. By studying a field deployment of a Human Resource chatbot, we report on users' interest areas in conversational interactions to inform the development of CAs. Through the lens of statistical modeling, we also highlight rich signals in conversational interactions for inferring user satisfaction with the instrumental usage and playful interactions with the agent. These signals can be utilized to develop agents that adapt functionality and interaction styles. By contrasting these signals, we shed light on the varying functions of conversational interactions. We discuss design implications for CAs, and directions for developing adaptive agents based on users' conversational behaviors.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173578,
author = {Jensen, Rikke Hagensby and Strengers, Yolande and Kjeldskov, Jesper and Nicholls, Larissa and Skov, Mikael B.},
title = {Designing the Desirable Smart Home: A Study of Household&nbsp;Experiences and Energy Consumption Impacts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173578},
doi = {10.1145/3173574.3173578},
abstract = {Research has shown that desirable designs shape the use and experiences people have when interacting with technology. Nevertheless, how desirability influences energy consumption is often overlooked, particularly in HCI studies evaluating the sustainability benefits of smart home technology. In this paper, we present a qualitative study with 23 Australian households who reflect on their experiences of living with smart home devices. Drawing on Nelson and Stolterman's concept of desiderata we develop a typology of householders' desires for the smart home and their energy implications. We structure these desires as three smart home personas: the helper, optimiser and hedonist, which align with desiderata's three approaches to desire (reason, ethics and aesthetics). We use these insights to discuss how desirability can be used within HCI for steering design of the smart home towards sustainability.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {desirability, domestic, smart homes, sustainability, energy consumption, desiderata},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173579,
author = {Barati, Bahareh and Giaccardi, Elisa and Karana, Elvin},
title = {The Making of Performativity in Designing [with] Smart Material Composites},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173579},
abstract = {As the material becomes active in disclosing the fullness of its capabilities, the boundaries between human and nonhuman performances are destabilized in productive practices that take their departure from materials. This paper illuminates the embodied crafting of action possibilities in material-driven design (MDD) practices with electroluminescent materials. The paper describes and discusses aspects of the making process of electroluminescent materials in which matter, structure, form, and computation are manipulated to deliberately disrupt the affordance of the material, with the goal to explore unanticipated action possibilities and materialize the performative qualities of the sample. In light of this account, the paper concludes by urging the HCI community to performatively rupture the material, so to be able to act upon it as if it was always unfinished or underdeveloped. This, it is shown, can help open up the design space of smart material composites and reveal their latent affordances.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inproceedings{10.1145/3173574.3173580,
author = {Myers, Chelsea and Furqan, Anushay and Nebolsky, Jessica and Caro, Karina and Zhu, Jichen},
title = {Patterns for How Users Overcome Obstacles in Voice User Interfaces},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173580},
doi = {10.1145/3173574.3173580},
abstract = {Voice User Interfaces (VUIs) are growing in popularity. However, even the most current VUIs regularly cause frustration for their users. Very few studies exist on what people do to overcome VUI problems they encounter, or how VUIs can be designed to aid people when these problems occur. In this paper, we analyze empirical data on how users (n=12) interact with our VUI calendar system, DiscoverCal, over three sessions. In particular, we identify the main obstacle categories and types of tactics our participants employ to overcome them. We analyzed the patterns of how different tactics are used in each obstacle category. We found that while NLP Error obstacles occurred the most, other obstacles are more likely to frustrate or confuse the user. We also found patterns that suggest participants were more likely to employ a "guessing" approach rather than rely on visual aids or knowledge recall.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {voice user interfaces, user experience, voice control},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173581,
author = {Garbett, Andrew and Chatting, David and Wilkinson, Gerard and Lee, Clement and Kharrufa, Ahmed},
title = {ThinkActive: Designing for Pseudonymous Activity Tracking in the Classroom},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173581},
doi = {10.1145/3173574.3173581},
abstract = {We report on the design of ThinkActive - a system to encourage primary aged school children to reflect on their own personal activity data in the classroom. We deployed the system with a cohort of 30 school children, over a six-week period, in partnership with an English Premier League Football club's health and nutrition programme. The system utilizes inexpensive activity trackers and pseudonymous avatars to promote reflection with personal data using an in-situ display within the classroom. Our design explores pseudonymity as an approach to managing privacy and personal data within a public setting. We report on the motivations, challenges, and opportunities for students, teachers, and third-party providers to engage in the collection and sharing of activity data with primary school children.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {education, classroom, pseudonymous, personal informatics},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173582,
author = {Hamidi, Foad and Scheuerman, Morgan Klaus and Branham, Stacy M.},
title = {Gender Recognition or Gender Reductionism? The Social Implications of Embedded Gender Recognition Systems},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173582},
doi = {10.1145/3173574.3173582},
abstract = {Automatic Gender Recognition (AGR) refers to various computational methods that aim to identify an individual's gender by extracting and analyzing features from images, video, and/or audio. Applications of AGR are increasingly being explored in domains such as security, marketing, and social robotics. However, little is known about stakeholders' perceptions and attitudes towards AGR and how this technology might disproportionately affect vulnerable communities. To begin to address these gaps, we interviewed 13 transgender individuals, including three transgender technology designers, about their perceptions and attitudes towards AGR. We found that transgender individuals have overwhelmingly negative attitudes towards AGR and fundamentally question whether it can accurately recognize such a subjective aspect of their identity. They raised concerns about privacy and potential harms that can result from being incorrectly gendered, or misgendered, by technology. We present a series of recommendations on how to accommodate gender diversity when designing new digital systems.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gender identity, transgender, autonomy, user-centered design, automatic gender recognition},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173583,
author = {Matias, J. Nathan and Mou, Merry},
title = {CivilServant: Community-Led Experiments in Platform Governance},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173583},
doi = {10.1145/3173574.3173583},
abstract = {As online platforms monitor and intervene in the daily lives of billions of people, platforms are being used to govern enduring social problems. Field experiments could inform wise uses of this power if tensions between democratic values and experimentation could be resolved. In this paper, we introduce CivilServant, a novel experimentation infrastructure that online communities and their moderators use to evaluate policies and replicate each others' findings. We situate CivilServant in the political history of policy experiments and present design considerations for community participation, ethics, and replication. Based on two case studies of community-led experiments and public debriefings on the reddit platform, we share findings on community deliberation about experiment results. We also report on uses of evidence, finding that experiments informed moderator practices, community policies, and replications by communities and platforms. We discuss the implications of these findings for evaluating platform governance in an open, democratic, experimenting society.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ethics, platforms, field experiments, policy evaluation, governance, action research, randomized trials, moderation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173584,
author = {Chidziwisano, George Hope and Wyche, Susan},
title = {M-Kulinda: Using a Sensor-Based Technology Probe to Explore Domestic Security in Rural Kenya},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173584},
doi = {10.1145/3173574.3173584},
abstract = {In rural Kenyan households, property theft is a persistent problem. To explore how Information and Communication Technologies (ICTs) may be used to address this problem we designed and deployed "M-Kulinda"-a sensor-based technology probe. We used interview, observation, diary, and data logging methods to understand 20 households' experiences using the system. Our findings suggest that a probe's approach is useful in this context, more specifically we found that participants used our system in different ways to address their specific needs (e.g., monitoring poultry, electronics, and their family members). We also observed changes in our participants' understanding of sensors; M-Kulinda prompted them to reflect on other areas where sensors could be used in their households. We present design implications based on these findings, and offer new perspectives on the role of technology in deterring crime.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hci4d, technology probes, home protection, rural, ictd, kenya},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173585,
author = {Khurana, Rushil and McIsaac, Duncan and Lockerman, Elliot and Mankoff, Jennifer},
title = {Nonvisual Interaction Techniques at the Keyboard Surface},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173585},
doi = {10.1145/3173574.3173585},
abstract = {Web user interfaces today leverage many common GUI design patterns, including navigation bars and menus (hierarchical structure), tabular content presentation, and scrolling. These visual-spatial cues enhance the interaction experience of sighted users. However, the linear nature of screen translation tools currently available to blind users make it difficult to understand or navigate these structures. We introduce Spatial Region Interaction Techniques (SPRITEs) for nonvisual access: a novel method for navigating two-dimensional structures using the keyboard surface. SPRITEs 1) preserve spatial layout, 2) enable bimanual interaction, and 3) improve the end user experience. We used a series of design probes to explore different methods for keyboard surface interaction. Our evaluation of SPRITEs shows that three times as many participants were able to complete spatial tasks with SPRITEs than with their preferred current technology.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {keyboard, accessibility, interaction techniques},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173586,
author = {Durrant, Abigail C. and Kirk, David S. and Trujillo-Pisanty, Diego and Martindale, Sarah},
title = {Admixed Portrait: Design to Understand Facebook Portrayals in New Parenthood},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173586},
abstract = {We report on a design-led study of the photographic representation of self and family on Facebook during and after becoming parents for the first time. Our experience-centered, research-through-design study engaged eight participants across five UK homes, in a month-long deployment of a prototype technology -- a design research artifact, Admixed Portrait, that served to prompt participant reflection on first-time parenthood. In addition to pre- and post-deployment interviews, participants kept diaries capturing personal reflections during the deployment, on daily social media use and interactions with Admixed. Our qualitative insights on social media representations of transitional experience and identity for new parents, reveal how their online 'photowork' related to self-expression and social functioning. We contribute design considerations for developing tools to support photographic expression in social media use, and methodological insights about design-led inquiry for understanding transitional experiences.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3173574.3173587,
author = {Gweon, Gahgene and Kim, Bugeun and Kim, Jinyoung and Lee, Kung Jin and Rhim, Jungwook and Choi, Jueun},
title = {MABLE: Mediating Young Children's Smart Media Usage with Augmented Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173587},
abstract = {There has been a growing concern over the huge increase in use of smart media by young children. This study explores the possibility of using augmented-reality(AR) for regulat-ing preschoolers' media usage behavior. With MABLE (mobile application for behavioral learning and education), parents can provide AR-assisted feedback by changing facial expressions and sound effects. When overlaying a smart media, which has MABLE running, in front of a QR marker on a puppet, a facial expression is displayed on top of the puppet's face. A two-week long experiment with 36 parent-child pairs showed that compared to using just the puppet, using MABLE showed higher amount of engage-ment among preschoolers. For the effectiveness of parental mediation in terms of self-control, our data showed mixed results. MABLE had positive effects in that the amount of rule-compliance increased and problematic behaviors de-creased, whereas the level of behavioral dependency on smart media was not influenced.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inproceedings{10.1145/3173574.3173588,
author = {Jansen, Yvonne and Hornb\ae{}k, Kasper},
title = {How Relevant Are Incidental Power Poses for HCI?},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173588},
doi = {10.1145/3173574.3173588},
abstract = {The concept of power pose originates from a Psychology study from 2010 which suggested that holding an expansive pose can change hormone levels and increase risk-taking behavior. Follow-up experiments suggested that expansive poses incidentally imposed by the design of an environment lead to more dishonest behaviors. While multiple replication attempts of the 2010 study failed, the follow-up experiments on incidental postures have so far not been replicated. As UI design in HCI can incidentally lead to expansive body postures, we attempted two conceptual replications: we first asked 44 participants to tap areas on a wall-sized display and measured their self-reported sense of power; we then asked 80 participants to play a game on a large touch-screen and measured risk-taking. Based on Bayesian analyses we find that incidental power poses had little to no effect on our measures but could cause physical discomfort. We conclude by discussing our findings in the context of theory-driven research in HCI.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {bayesian analysis, power pose, incidental postures},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173589,
author = {Stowell, Elizabeth and Lyson, Mercedes C. and Saksono, Herman and Wurth, Rene\'{e} C. and Jimison, Holly and Pavel, Misha and Parker, Andrea G.},
title = {Designing and Evaluating MHealth Interventions for Vulnerable Populations: A Systematic Review},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173589},
doi = {10.1145/3173574.3173589},
abstract = {Diverse disciplines, including Human-Computer Interaction have explored how mobile health (mHealth) applications can transform healthcare and health promotion. Increasingly, research has explored how mHealth tools can promote healthy behaviors within vulnerable populations-groups that disproportionately experience barriers to wellness. We conducted a systematic review of 83 papers from diverse disciplines to characterize the design and impact of mHealth tools in low-socioeconomic (low-SES) and racial/ethnic minority individuals. Our findings highlight that the diversity within low-SES and racial/ethnic minority groups was not reflected in the populations studied. Most studies focused on improving the health of individuals, often neglecting factors at the community and society levels that influence health disparities. Moreover, few improvements in health outcomes were demonstrated. We further discuss factors that acted as barriers and facilitators of mHealth intervention adoption. Our findings highlight trends that can drive critically needed digital health innovations for vulnerable populations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {socioeconomic status, minority, systematic review, ethnicity, race, mhealth, vulnerable populations},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173590,
author = {Vaccaro, Kristen and Huang, Dylan and Eslami, Motahhare and Sandvig, Christian and Hamilton, Kevin and Karahalios, Karrie},
title = {The Illusion of Control: Placebo Effects of Control Settings},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173590},
doi = {10.1145/3173574.3173590},
abstract = {Algorithmic prioritization is a growing focus for social media users. Control settings are one way for users to adjust the prioritization of their news feeds, but they prioritize feed content in a way that can be difficult to judge objectively. In this work, we study how users engage with difficult-to-validate controls. Via two paired studies using an experimental system -- one interview and one online study -- we found that control settings functioned as placebos. Viewers felt more satisfied with their feed when controls were present, whether they worked or not. We also examine how people engage in sensemaking around control settings, finding that users often take responsibility for violated expectations -- for both real and randomly functioning controls. Finally, we studied how users controlled their social media feeds in the wild. The use of existing social media controls had little impact on user's satisfaction with the feed; instead, users often turned to improvised solutions, like scrolling quickly, to see what they want.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {placebo effect, social media, control settings, sensemaking},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173591,
author = {Flores, German and Manduchi, Roberto},
title = {Easy Return: An App for Indoor Backtracking Assistance},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173591},
doi = {10.1145/3173574.3173591},
abstract = {We present a system that, implemented as an iPhone app controllable from an Apple Watch, can help a blind person backtrack a route taken in a building. This system requires no maps of the building or environment modifications. While traversing a path from a starting location to a destination, the system builds and records a path representation in terms of a sequence of turns and of step counts between turns. If the user wants to backtrack the same path, the system can provide assistance by tracking the user's location in the recorded path, and producing directional information in speech form about the next turns and step counts to follow. The system was tested with six blind participants in a controlled indoor experiment.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {wayfinding, spatial accessibility, inertial sensing, step counting},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173592,
author = {Freeman, Euan and Williamson, Julie and Subramanian, Sriram and Brewster, Stephen},
title = {Point-and-Shake: Selecting from Levitating Object Displays},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173592},
doi = {10.1145/3173574.3173592},
abstract = {Acoustic levitation enables a radical new type of human-computer interface composed of small levitating objects. For the first time, we investigate the selection of such objects, an important part of interaction with a levitating object display. We present Point-and-Shake, a mid-air pointing interaction for selecting levitating objects, with feedback given through object movement. We describe the implementation of this technique and present two user studies that evaluate it. The first study found that users could accurately (96%) and quickly (4.1s) select objects by pointing at them. The second study found that users were able to accurately (95%) and quickly (3s) select occluded objects. These results show that Point-and-Shake is an effective way of initiating interaction with levitating object displays.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {ray-cast pointing, acoustic levitation, pointing, selection},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173593,
author = {Horak, Tom and Badam, Sriram Karthik and Elmqvist, Niklas and Dachselt, Raimund},
title = {When David Meets Goliath: Combining Smartwatches with a Large Vertical Display for Visual Data Exploration},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173593},
doi = {10.1145/3173574.3173593},
abstract = {We explore the combination of smartwatches and a large interactive display to support visual data analysis. These two extremes of interactive surfaces are increasingly popular, but feature different characteristics-display and input modalities, personal/public use, performance, and portability. In this paper, we first identify possible roles for both devices and the interplay between them through an example scenario. We then propose a conceptual framework to enable analysts to explore data items, track interaction histories, and alter visualization configurations through mechanisms using both devices in combination. We validate an implementation of our framework through a formative evaluation and a user study. The results show that this device combination, compared to just a large display, allows users to develop complex insights more fluidly by leveraging the roles of the two devices. Finally, we report on the interaction patterns and interplay between the devices for visual exploration as observed during our study.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multi-display environment, data exploration, visual analysis, large display, smartwatch, cross-device interaction},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173594,
author = {Billah, Syed Masum and Ashok, Vikas and Porter, Donald E. and Ramakrishnan, I.V.},
title = {SteeringWheel: A Locality-Preserving Magnification Interface for Low Vision Web Browsing},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173594},
doi = {10.1145/3173574.3173594},
abstract = {Low-vision users struggle to browse the web with screen magnifiers. Firstly, magnifiers occlude significant portions of the webpage, thereby making it cumbersome to get the webpage overview and quickly locate the desired content. Further, magnification causes loss of spatial locality and visual cues that commonly define semantic relationships in the page; reconstructing semantic relationships exclusively from narrow views dramatically increases the cognitive burden on the users. Secondly, low-vision users have widely varying needs requiring a range of interface customizations for different page sections; dynamic customization in extant magnifiers is disruptive to users' browsing. We present SteeringWheel, a magnification interface that leverages content semantics to preserve local context. In combination with a physical dial, supporting simple rotate and press gestures, users can quickly navigate different webpage sections, easily locate desired content, get a quick overview, and seamlessly customize the interface. A user study with 15 low-vision participants showed that their web-browsing efficiency improved by at least 20 percent with SteeringWheel compared to extant screen magnifiers.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {web-browsing, low-vision, visual impairments, accessibility, user-interface, locality, magnifier},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173595,
author = {Buschek, Daniel and Roppelt, Bianka and Alt, Florian},
title = {Extending Keyboard Shortcuts with Arm and Wrist Rotation Gestures},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173595},
doi = {10.1145/3173574.3173595},
abstract = {We propose and evaluate a novel interaction technique to enhance physical keyboard shortcuts with arm and wrist rotation gestures, performed during keypresses: rolling the wrist, rotating the arm/wrist, and lifting it. This extends the set of shortcuts from key combinations (e.g. ctrl + v) to combinations of key(s) and gesture (e.g. v + roll left) and enables continuous control. We implement this approach for isolated single keypresses, using inertial sensors of a smartwatch. We investigate key aspects in three studies: 1) rotation flexibility per keystroke finger, 2) rotation control, and 3) user-defined gesture shortcuts. As a use case, we employ our technique in a painting application and assess user experience. Overall, results show that arm and wrist rotations during keystrokes can be used for interaction, yet challenges remain for integration into practical applications. We discuss recommendations for applications and ideas for future research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {wrist rotation, keyboard, smartwatch, elicitation study},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173596,
author = {Hui, Julie S. and Gergle, Darren and Gerber, Elizabeth M.},
title = {IntroAssist: A Tool to Support Writing Introductory Help Requests},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173596},
doi = {10.1145/3173574.3173596},
abstract = {Writing introductory help requests is a key part of develop-ing new professional connections, such as through email and other online messaging systems. This paper presents the design and an experimental evaluation of IntroAssist-a web-based tool that leverages cognitive apprenticeship in-structional methods to support writing introductory help requests through an expert-informed checklist, tagged peer examples, self-tagging, and suggested word limit. In a study of IntroAssist with novice entrepreneurs, we find that 1) expert raters consider help requests written with the tool as more effective, 2) participants are able to perform introduc-tory help seeking skills after the tool is removed, and 3) participants report being more likely to send help requests written with the tool. We present implications for the de-velopment of systems that support the initiation of profes-sional relationships.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {professional connec-tions, entrepreneurship, social capital, help seeking, skills},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173597,
author = {Niu, Xi and Abbas, Fakhri and Maher, Mary Lou and Grace, Kazjon},
title = {Surprise Me If You Can: Serendipity in Health Information},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173597},
doi = {10.1145/3173574.3173597},
abstract = {Our natural tendency to be curious is increasingly important now that we are exposed to vast amounts of information. We often cope with this overload by focusing on the familiar: information that matches our expectations. In this paper we present a framework for interactive serendipitous information discovery based on a computational model of surprise. This framework delivers information that users were not actively looking for, but which will be valuable to their unexpressed needs. We hypothesize that users will be surprised when presented with information that violates the expectations predicted by our model of them. This surprise model is balanced by a value component which ensures that the information is relevant to the user. Within this framework we have implemented two surprise models, one based on association mining and the other on topic modeling approaches. We evaluate these two models with thirty users in the context of online health news recommendation. Positive user feedback was obtained for both of the computational models of surprise compared to a baseline random method. This research contributes to the understanding of serendipity and how to "engineer" serendipity that is favored by users.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {surprise, computational models, value, health news, serendipity, information retrieval systems},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173598,
author = {Tanveer, M. Iftekhar and Samrose, Samiha and Baten, Raiyan Abdul and Hoque, M. Ehsan},
title = {Awe the Audience: How the Narrative Trajectories Affect Audience Perception in Public Speaking},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173598},
doi = {10.1145/3173574.3173598},
abstract = {Telling a great story often involves a deliberate alteration of emotions. In this paper, we objectively measure and analyze the narrative trajectories of stories in public speaking and their impact on subjective ratings. We conduct the analysis using the transcripts of over 2000 TED talks and estimate potential audience response using over 5 million spontaneous annotations from the viewers. We use IBM Watson Tone Analyzer to extract sentence-wise emotion, language, and social scores. Our study indicates that it is possible to predict (with AUC as high as 0.88) the subjective ratings of the audience by analyzing the narrative trajectories. Additionally, we find that some trajectories (for example, a flat trajectory of joy) correlate well with some specific ratings (e.g. "Longwinded') assigned by the viewers. Such an association could be useful in forecasting audience responses using objective analysis.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ted talks, narrative trajectories, styles of storytelling, pattern recognition, affective computing, clustering},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173599,
author = {Avery, Jeff and Malacria, Sylvain and Nancel, Mathieu and Casiez, G\'{e}ry and Lank, Edward},
title = {Introducing Transient Gestures to Improve Pan and Zoom on Touch Surfaces},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173599},
doi = {10.1145/3173574.3173599},
abstract = {Despite the ubiquity of touch-based input and the availability of increasingly computationally powerful touchscreen devices, there has been comparatively little work on enhancing basic canonical gestures such as swipe-to-pan and pinch-to-zoom. In this paper, we introduce transient pan and zoom, i.e. pan and zoom manipulation gestures that temporarily alter the view and can be rapidly undone. Leveraging typical touchscreen support for additional contact points, we design our transient gestures such that they co-exist with traditional pan and zoom interaction. We show that our transient pan-and-zoom reduces repetition in multi-level navigation and facilitates rapid movement between document states. We conclude with a discussion of user feedback, and directions for future research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {tablet, multi-touch, bimanual input},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173600,
author = {Gorman, Benjamin M. and Flatla, David R.},
title = {MirrorMirror: A Mobile Application to Improve Speechreading Acquisition},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173600},
doi = {10.1145/3173574.3173600},
abstract = {Many people around the world have difficulties in day-to-day conversation due to hearing loss. Hearing aids often fail to offer enough benefits and have low adoption rates. However, people with hearing loss find that speechreading can improve their understanding during conversation, but speechreading is a challenging skill to learn. Speechreading classes can improve acquisition, however there are a limited number of classes available and students can only practice effectively when attending class. To address this, we conducted a postal survey with 59 speechreading students to understand students' perspectives on practicing. Using our findings, we developed an Android application called MirrorMirror - a new Speechreading Acquisition Tool (SAT) that allows students to practice their speechreading by recording and watching videos of people they frequently speak with. We evaluated MirrorMirror through three case studies with speechreading students and found that they could effectively target their speechreading practice on people, words and situations they encounter during daily conversations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {lipreading, accessibility, speechreading, hearing loss},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173601,
author = {Trindade, Daniel and Rodrigues, Andr\'{e} and Guerreiro, Tiago and Nicolau, Hugo},
title = {Hybrid-Brailler: Combining Physical and Gestural Interaction for Mobile Braille Input and Editing},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173601},
doi = {10.1145/3173574.3173601},
abstract = {Braille input enables fast nonvisual entry speeds on mobile touchscreen devices. Yet, the lack of tactile cues commonly results in typing errors, which are hard to correct. We propose Hybrid-Brailler, an input solution that combines physical and gestural interaction to provide fast and accurate Braille input. We use the back of the device for physical chorded input while freeing the touchscreen for gestural interaction. Gestures are used in editing operations, such as caret movement, text selection, and clipboard control, enhancing the overall text entry experience. We conducted two user studies to assess both input and editing performance. Results show that Hybrid-Brailler supports fast entry rates as its virtual counterpart, while significantly increasing input accuracy. Regarding editing performance, when compared with the mainstream technique, Hybrid-Brailler shows performance benefits of 21% in speed and increased editing accuracy. We finish with lessons learned for designing future nonvisual input and editing techniques.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {braille, text entry, mobile, blind, touchscreen, editing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173602,
author = {Ayobi, Amid and Sonne, Tobias and Marshall, Paul and Cox, Anna L.},
title = {Flexible and Mindful Self-Tracking: Design Implications from Paper Bullet Journals},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173602},
abstract = {Digital self-tracking technologies offer many potential benefits over self-tracking with paper notebooks. However, they are often too rigid to support people's practical and emotional needs in everyday settings. To inform the design of more flexible self-tracking tools, we examine bullet journaling: an analogue and customisable approach for logging and reflecting on everyday life. Analysing a corpus of paper bullet journal photos and related conversations on Instagram, we found that individuals extended and adapted bullet journaling systems to their changing practical and emotional needs through: (1) creating and combining personally meaningful visualisations of different types of trackers, such as habit, mood, and symptom trackers; (2) engaging in mindful reflective thinking through design practices and self-reflective strategies; and (3) posting photos of paper journals online to become part of a self-tracking culture of sharing and learning. We outline two interrelated design directions for flexible and mindful self-tracking: digitally extending analogue self-tracking and supporting digital self-tracking as a mindful design practice.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.1145/3173574.3173603,
author = {Li, Yang and Bengio, Samy and Bailly, Gilles},
title = {Predicting Human Performance in Vertical Menu Selection Using Deep Learning},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173603},
doi = {10.1145/3173574.3173603},
abstract = {Predicting human performance in interaction tasks allows designers or developers to understand the expected performance of a target interface without actually testing it with real users. In this work, we present a deep neural net to model and predict human performance in performing a sequence of UI tasks. In particular, we focus on a dominant class of tasks, i.e., target selection from a vertical list or menu. We experimented with our deep neural net using a public dataset collected from a desktop laboratory environment and a dataset collected from hundreds of touchscreen smartphone users via crowdsourcing. Our model significantly outperformed previous methods on these datasets. Importantly, our method, as a deep model, can easily incorporate additional UI attributes such as visual appearance and content semantics without changing model architectures. By understanding about how a deep learning model learns from human behaviors, our approach can be seen as a vehicle to discover new patterns about human behaviors to advance analytical modeling.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {recurrent neural networks, lists, deep learning, lstm, touchscreen, performance modeling, menus, tensorflow},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173604,
author = {Benford, Steve and Koleva, Boriana and Preston, William Westwood and Angus, Alice and Thorn, Emily-Clare and Glover, Kevin},
title = {Customizing Hybrid Products},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173604},
abstract = {We explore how the convergence of the digital and physical into hybrid products leads to new possibilities for customization. We report on a technology probe, a hybrid advent calendar with both paper form and digital layers of content, both of which were designed to be customizable. We reveal how over two hundred active users adapted its physical and digital aspects in various ways, some anticipated and familiar, but others surprising. This leads us to contribute concepts to help understand and design for hybrid customization -- the idea of broad customization spanning physical and digital; end-to-end customization by different stakeholders along the value chain for a product; and the combination of these into customization maps.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3173605,
author = {Le, Huy Viet and Mayer, Sven and Bader, Patrick and Henze, Niels},
title = {Fingers' Range and Comfortable Area for One-Handed Smartphone Interaction Beyond the Touchscreen},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173605},
abstract = {Previous research and recent smartphone development presented a wide range of input controls beyond the touchscreen. Fingerprint scanners, silent switches, and Back-of-Device (BoD) touch panels offer additional ways to perform input. However, with the increasing amount of input controls on the device, unintentional input or limited reachability can hinder interaction. In a one-handed scenario, we conducted a study to investigate the areas that can be reached without losing grip stability (comfortable area), and with stretched fingers (maximum range) using four different phone sizes. We describe the characteristics of the comfortable area and maximum range for different phone sizes and derive four design implications for the placement of input controls to support one-handed BoD and edge interaction. Amongst others, we show that the index and middle finger are the most suited fingers for BoD interaction and that the grip shifts towards the top edge with increasing phone sizes.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173606,
author = {Rule, Adam and Tabard, Aur\'{e}lien and Hollan, James D.},
title = {Exploration and Explanation in Computational Notebooks},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173606},
doi = {10.1145/3173574.3173606},
abstract = {Computational notebooks combine code, visualizations, and text in a single document. Researchers, data analysts, and even journalists are rapidly adopting this new medium. We present three studies of how they are using notebooks to document and share exploratory data analyses. In the first, we analyzed over 1 million computational notebooks on GitHub, finding that one in four had no explanatory text but consisted entirely of visualizations or code. In a second study, we examined over 200 academic computational notebooks, finding that although the vast majority described methods, only a minority discussed reasoning or results. In a third study, we interviewed 15 academic data analysts, finding that most considered computational notebooks personal, exploratory, and messy. Importantly, they typically used other media to share analyses. These studies demonstrate a tension between exploration and explanation in constructing and sharing computational notebooks. We conclude with opportunities to encourage explanation in computational media without hindering exploration.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {jupyter notebook, data science, computational notebook, narrative, data analysis},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173607,
author = {Nittala, Aditya Shekhar and Withana, Anusha and Pourjafarian, Narjes and Steimle, J\"{u}rgen},
title = {Multi-Touch Skin: A Thin and Flexible Multi-Touch Sensor for On-Skin Input},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173607},
doi = {10.1145/3173574.3173607},
abstract = {Skin-based touch input opens up new opportunities for direct, subtle, and expressive interaction. However, existing skin-worn sensors are restricted to single-touch input and limited by a low resolution. We present the first skin overlay that can capture high-resolution multi-touch input. Our main contributions are: 1) Based on an exploration of functional materials, we present a fabrication approach for printing thin and flexible multi-touch sensors for on-skin interactions. 2) We present the first non-rectangular multi-touch sensor overlay for use on skin and introduce a design tool that generates such sensors in custom shapes and sizes. 3) To validate the feasibility and versatility of our approach, we present four application examples and empirical results from two technical evaluations. They confirm that the sensor achieves a high signal-to-noise ratio on the body under various grounding conditions and has a high spatial accuracy even when subjected to strong deformations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {multi-touch input, fabrication, electronic skin, flexible sensor, wearable computing, on-body input},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173608,
author = {Hullman, Jessica and Kim, Yea-Seul and Nguyen, Francis and Speers, Lauren and Agrawala, Maneesh},
title = {Improving Comprehension of Measurements Using Concrete Re-Expression Strategies},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173608},
doi = {10.1145/3173574.3173608},
abstract = {It can be difficult to understand physical measurements (e.g., 28 lb, 600 gallons) that appear in news stories, data reports, and other documents. We develop tools that automatically re-express unfamiliar measurements using the measurements of familiar objects. Our work makes three contributions: (1) we identify effectiveness criteria for objects used in concrete measurement re-expressions; (2) we operationalize these criteria in a scalable method for mining a large dataset of concrete familiar objects with their physical dimensions from Amazon and Wikipedia; and (3) we develop automated concrete re-expression tools that implement three common re-expression strategies (adding familiar context, reunitization and proportional analogy) as energy minimization algorithms. Crowdsourced evaluations of our tools indicate that people find news articles with re-expressions more helpful and re- expressions help them to better estimate new measurements.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {reunitization, proportional analogy, measurement re-expression, analogy},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173609,
author = {Morris, Meredith Ringel and Fourney, Adam and Ali, Abdullah and Vonessen, Laura},
title = {Understanding the Needs of Searchers with Dyslexia},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173609},
doi = {10.1145/3173574.3173609},
abstract = {As many as 20% of English speakers have dyslexia, a language disability that impacts reading and spelling. Web search is an important modern literacy skill, yet the accessibility of this language-centric endeavor to people with dyslexia is largely unexplored. We interviewed ten adults with dyslexia and conducted an online survey with 81 dyslexic and 80 non-dyslexic adults, in which participants described challenges they face in various stages of web search (query formulation, search result triage, and information extraction). We also report the findings of an online study in which 174 adults with dyslexia and 172 without dyslexia rated the readability and relevance of sets of search query results. Our findings demonstrate differences in behaviors and preferences between dyslexic and non-dyslexic searchers, and indicate that factoring readability into search engine rankings and/or interfaces may benefit both dyslexic and non-dyslexic users.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {reading disabilities, dyslexia, search engine, learning disabilities, web search},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173610,
author = {Ledo, David and Houben, Steven and Vermeulen, Jo and Marquardt, Nicolai and Oehlberg, Lora and Greenberg, Saul},
title = {Evaluation Strategies for HCI Toolkit Research},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173610},
doi = {10.1145/3173574.3173610},
abstract = {Toolkit research plays an important role in the field of HCI, as it can heavily influence both the design and implementation of interactive systems. For publication, the HCI community typically expects toolkit research to include an evaluation component. The problem is that toolkit evaluation is challenging, as it is often unclear what 'evaluating' a toolkit means and what methods are appropriate. To address this problem, we analyzed 68 published toolkit papers. From our analysis, we provide an overview of, reflection on, and discussion of evaluation methods for toolkit contributions. We identify and discuss the value of four toolkit evaluation strategies, including the associated techniques that each employs. We offer a categorization of evaluation strategies for toolkit researchers, along with a discussion of the value, potential limitations, and trade-offs associated with each strategy.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {prototyping, user interfaces, toolkits, design, evaluation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173611,
author = {Zhang, Jiawei and Surakitbanharn, Chittayong and Elmqvist, Niklas and Maciejewski, Ross and Qian, Zhenyu and Ebert, David S.},
title = {TopoText: Context-Preserving Text Data Exploration Across Multiple Spatial Scales},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173611},
doi = {10.1145/3173574.3173611},
abstract = {TopoText is a context-preserving technique for visualizing text data for multi-scale spatial aggregates to gain insight into spatial phenomena. Conventional exploration requires users to navigate across multiple scales but only presents the information related to the current scale. This limitation potentially adds more steps of interaction and cognitive overload to the users. TopoText renders multi-scale aggregates into a single visual display combining novel text-based encoding and layout methods that draw labels along the boundary or filled within the aggregates. The text itself not only summarizes the semantics at each individual scale, but also indicates the spatial coverage of the aggregates and their underlying hierarchical relationships. We validate TopoText with both a user study as well as several application examples.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {text visualization, context preservation, geospatial visualization, typographic map, multi-scale analysis},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173612,
author = {Bach, Benjamin and Wang, Zezhong and Farinella, Matteo and Murray-Rust, Dave and Henry Riche, Nathalie},
title = {Design Patterns for Data Comics},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173612},
abstract = {Data comics for data-driven storytelling are inspired by the visual language of comics and aim to communicate insights in data through visualizations. While comics are widely known, few examples of data comics exist and there has not been any structured analysis nor guidance for their creation. We introduce data-comic design-patterns, each describing a set of panels with a specific narrative purpose, that allow for rapid storyboarding of data comics while showcasing their expressive potential. Our patterns are derived from i) analyzing common patterns in infographics, datavideos, and existing data comics, ii) our experiences creating data comics for different scenarios. Our patterns demonstrate how data comics allow an author to combine the best of both worlds: spatial layout and overview from infographics as well as linearity and narration from videos and presentations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173613,
author = {Oduor, Erick and Waweru, Peninah and Lenchner, Jonathan and Neustaedter, Carman},
title = {Practices and Technology Needs of a Network of Farmers in Tharaka Nithi, Kenya},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173613},
doi = {10.1145/3173574.3173613},
abstract = {Farmers in rural areas of Kenya generally rely on traditional agricultural practices inherited from past generations. However, population increases and climate changes have put pressure on resources such as land and water. These resource pressures have created a need to broaden and expand farming practices. We conducted an exploratory study with farmers in Tharaka Nithi, Kenya to explore their practices, if and how they used ICT, and how the technologies used might be designed to aid their practices, if at all. Overall, our results show that farmers desired more knowledge to enable them apply ICT interventions in ways that improved yields. Farmers were also interested in accessing information on soil fertility, water predictability and market opportunities. These findings suggest opportunities for technology design to support farming practices among rural communities in rural settings. We also articulate social challenges that designers will face when thinking about coming up with such solutions.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {mobile phones, farming technologies, rural farming, farmers},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173614,
author = {Liu, Jen and Byrne, Daragh and Devendorf, Laura},
title = {Design for Collaborative Survival: An Inquiry into Human-Fungi Relationships},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173614},
doi = {10.1145/3173574.3173614},
abstract = {In response to recent calls for HCI to address ongoing environmental crises and existential threats, this paper introduces the concept of collaborative survival and examines how it shapes the design of interactive artifacts. Collaborative survival describes how our (human) ability to persist as a species is deeply entangled with and dependent upon the health of a multitude of other species. We explore collaborative survival within the context of designing tools for mushroom foraging and reflect on how interactive products can open new pathways for noticing and joining-with these entanglements towards preferable futures. In addition to highlighting three tactics-engagement, attunement and expansion-that can guide designs towards multispecies flourishing, our prototypes illustrate the potential for wearable technology to extend the body into the environment.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {fungi, wearable technology, sensing, post-anthropocentric design, collaborative survival},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173615,
author = {Bopp, Julia Ayumi and Opwis, Klaus and Mekler, Elisa D.},
title = {“An Odd Kind of Pleasure”: Differentiating Emotional Challenge in Digital Games},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173615},
doi = {10.1145/3173574.3173615},
abstract = {Recent work introduced the notion of emotional challenge as a means to afford more unique and diverse gaming experiences. However, players' experience of emotional challenge has received little empirical attention. It remains unclear whether players enjoy it and what exactly constitutes the challenge thereof. We surveyed 171 players about a challenging or an emotionally challenging experience, and analyzed their responses with regards to what made the experience challenging, their emotional response, and the relation to core player experience constructs. We found that emotional challenge manifested itself in different ways, by confronting players with difficult themes or decisions, as well as having them deal with intense emotions. In contrast to more'conventional' challenge, emotional challenge evoked a wider range of negative emotions and was appreciated significantly more by players. Our findings showcase the appeal of uncomfortable gaming experiences, and extend current conceptualizations of challenge in games.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {emotion, emotional challenge, challenge, player experience},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173616,
author = {Yan, Yukang and Yu, Chun and Ma, Xiaojuan and Huang, Shuai and Iqbal, Hasan and Shi, Yuanchun},
title = {Eyes-Free Target Acquisition in Interaction Space around the Body for Virtual Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173616},
doi = {10.1145/3173574.3173616},
abstract = {Eyes-free target acquisition is a basic and important human ability to interact with the surrounding physical world, relying on the sense of space and proprioception. In this research, we leverage this ability to improve interaction in virtual reality (VR), by allowing users to acquire a virtual object without looking at it. We expect this eyes-free approach can effectively reduce head movements and focus changes, so as to speed up the interaction and alleviate fatigue and VR sickness. We conduct three lab studies to progressively investigate the feasibility and usability of eyes-free target acquisition in VR. Results show that, compared with the eyes-engaged manner, the eyes-free approach is significantly faster, provides satisfying accuracy, and introduces less fatigue and sickness; Most participants (13/16) prefer this approach. We also measure the accuracy of motion control and evaluate subjective experience of users when acquiring targets at different locations around the body. Based on the results, we make suggestions on designing appropriate target layout and discuss several design issues for eyes-free target acquisition in VR.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {proprioception, eyes-free, target acquisition, virtual reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173617,
author = {Brock, Michael and Quigley, Aaron and Kristensson, Per Ola},
title = {Change Blindness in Proximity-Aware Mobile Interfaces},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173617},
doi = {10.1145/3173574.3173617},
abstract = {Interface designs on both small and large displays can encourage people to alter their physical distance to the display. Mobile devices support this form of interaction naturally, as the user can move the device closer or further away as needed. The current generation of mobile devices can employ computer vision, depth sensing and other inference methods to determine the distance between the user and the display. Once this distance is known, a system can adapt the rendering of display content accordingly and enable proximity-aware mobile interfaces. The dominant method of exploiting proximity-aware interfaces is to remove or superimpose visual information. In this paper, we investigate change blindness in such interfaces. We present the results of two experiments. In our first experiment we show that a proximity-aware mobile interface results in significantly more change blindness errors than a non-moving interface. The absolute difference in error rates was 13.7%. In our second experiment we show that within a proximity-aware mobile interface, gradual changes induce significantly more change blindness errors than instant changes---confirming expected change blindness behavior. Based on our results we discuss the implications of either exploiting change blindness effects or mitigating them when designing mobile proximity-aware interfaces.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {interface design, proxemics, change blindness, proximity aware interfaces, proximity interaction},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173618,
author = {Alhadreti, Obead and Mayhew, Pam},
title = {Rethinking Thinking Aloud: A Comparison of Three Think-Aloud Protocols},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173618},
abstract = {This paper presents the results of a study that compared three think-aloud methods: concurrent think-aloud, retrospective think-aloud, and a hybrid method. The three methods were compared through an evaluation of a library website, which involved four points of comparison: task performance, participants' experiences, usability problems discovered, and the cost of employing the methods. The results revealed that the concurrent method outperformed both the retrospective and the hybrid methods in facilitating successful usability testing. It detected higher numbers of usability problems than the retrospective method, and produced output comparable to that of the hybrid method. The method received average to positive ratings from its users, and no reactivity was observed. Lastly, this method required much less time on the evaluator's part than did the other two methods, which involved double the testing and analysis time.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173619,
author = {Rzayev, Rufat and Woundefinedniak, Pawe\l{} W. and Dingler, Tilman and Henze, Niels},
title = {Reading on Smart Glasses: The Effect of Text Position, Presentation Type and Walking},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173619},
doi = {10.1145/3173574.3173619},
abstract = {Smart glasses are increasingly being used in professional contexts. Having key applications such as short messaging and newsreader, they enable continuous access to textual information. In particular, smart glasses allow reading while performing other activities as they do not occlude the user's world view. For efficient reading, it is necessary to understand how a text should be presented on them. We, therefore, conducted a study with 24 participants using a Microsoft HoloLens to investigate how to display text on smart glasses while walking and sitting. We compared text presentation in the top-right, center, and bottom-center positions with Rapid Serial Visual Presentation (RSVP) and line-by-line scrolling. We found that text displayed in the top-right of smart glasses increases subjective workload and reduces comprehension. RSVP yields higher comprehension while sitting. Conversely, reading with scrolling yields higher comprehension while walking. Insights from our study inform the design of reading interfaces for smart glasses.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {hololens, smart glasses, rsvp, reading on the go, reading},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173620,
author = {Piumsomboon, Thammathip and Lee, Gun A. and Hart, Jonathon D. and Ens, Barrett and Lindeman, Robert W. and Thomas, Bruce H. and Billinghurst, Mark},
title = {Mini-Me: An Adaptive Avatar for Mixed Reality Remote Collaboration},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173620},
doi = {10.1145/3173574.3173620},
abstract = {We present Mini-Me, an adaptive avatar for enhancing Mixed Reality (MR) remote collaboration between a local Augmented Reality (AR) user and a remote Virtual Reality (VR) user. The Mini-Me avatar represents the VR user's gaze direction and body gestures while it transforms in size and orientation to stay within the AR user's field of view. A user study was conducted to evaluate Mini-Me in two collaborative scenarios: an asymmetric remote expert in VR assisting a local worker in AR, and a symmetric collaboration in urban planning. We found that the presence of the Mini-Me significantly improved Social Presence and the overall experience of MR collaboration.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {awareness, mixed reality, gesture, remote collaboration, avatar, virtual reality, augmented reality, gaze, redirected, remote embodiment},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173621,
author = {Hasan, Rakibul and Hassan, Eman and Li, Yifang and Caine, Kelly and Crandall, David J. and Hoyle, Roberto and Kapadia, Apu},
title = {Viewer Experience of Obscuring Scene Elements in Photos to Enhance Privacy},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173621},
doi = {10.1145/3173574.3173621},
abstract = {With the rise of digital photography and social networking, people are sharing personal photos online at an unprecedented rate. In addition to their main subject matter, photographs often capture various incidental information that could harm people's privacy. While blurring and other image filters may help obscure private content, they also often affect the utility and aesthetics of the photos, which is important since images shared in social media are mainly for human consumption. Existing studies of privacy-enhancing image filters either primarily focus on obscuring faces, or do not systematically study how filters affect image utility. To understand the trade-offs when obscuring various sensitive aspects of images, we study eleven filters applied to obfuscate twenty different objects and attributes, and evaluate how effectively they protect privacy and preserve image quality for human viewers.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {image filtering, image obfuscation, privacy},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173622,
author = {Wheeler, Earnest and Dillahunt, Tawanna R.},
title = {Navigating the Job Search as a Low-Resourced Job Seeker},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173622},
doi = {10.1145/3173574.3173622},
abstract = {The Internet is providing increasing access to information about employment opportunities, but not everyone can leverage it effectively. Research suggests that job seekers with limited access to Internet technologies are being left behind, while those with limited social resources are expected to rely on the Internet even more. In this work, we conducted in-depth semi-structured interviews with 11 low-resourced job seekers in a metropolitan area in the Midwestern USA to understand how social and digital resources support their efforts to find work. We find that online resources support job seekers in finding relevant jobs via search, but do not help them identify opportunities to improve their job search process or increase their chances of securing employment. We recommend that systems aiming to support low-resourced job seekers design for deeper engagement with their users across the job search process, to help users recognize ways to improve on their existing practices.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {digital divide, underserved job seekers, employment, design, information seeking},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173623,
author = {Cheon, EunJeong and Su, Norman Makoto},
title = {The Value of Empty Space for Design},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173623},
doi = {10.1145/3173574.3173623},
abstract = {We present a study on a group of people who, upon adopting a new lifestyle movement, have discovered and constructed alternative aspects of space. Drawing on 23 interviews with minimalists and participant observations of their Meetup meetings, we highlight the central role of empty space in their lives at home. Our findings show how empty space for minimalists emerge as a new, hitherto unknown space in the home and the ways minimalists seek to create, maintain, and stay sensitive to these empty spaces. Empty spaces for minimalists signify their achievements, exudes aesthetic appeal, and provide a sanctuary away from city life. We propose new opportunities for design based on our findings of empty space. We suggest that design should consider supporting the practices and values that revolve around the absence of artifacts.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {space, empty space, value-sensitive design, alternative lifestyle, place, sub.c.ulture, minimalists},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173624,
author = {Wang, Guan and Suh, Ayoung},
title = {Disorder or Driver? The Effects of Nomophobia on Work-Related Outcomes in Organizations},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173624},
doi = {10.1145/3173574.3173624},
abstract = {Nomophobia, which refers to discomfort or anxiety caused by being unable to use one's smartphone, has become prevalent among smartphone users. However, the influence of nomophobia on employees' work-related outcomes remains unclear. Drawing on the job demands-resources theory, this study develops a model that explores the interplay between employees' nomophobia, work engagement, emotional exhaustion, work interruption, and job productivity. The proposed model was tested using data collected from 187 employees in one organization. The results demonstrate that some employees with high levels of nomophobia feel more engaged with their work and more productive, yet others tend to be emotionally exhausted and feel they are less productive. By illuminating the dual effects of nomophobia on employees' work-related outcomes, this study extends our understanding of how smartphone use positively and negatively affects employees in the workplace. The notion of nomophobia in the workplace is discussed, along with new directions for research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {job productivity, nomophobia, jd-r model, smartphone use, work interruption},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173625,
author = {Shen, Solace and Tennent, Hamish and Claure, Houston and Jung, Malte},
title = {My Telepresence, My Culture? An Intercultural Investigation of Telepresence Robot Operators' Interpersonal Distance Behaviors},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173625},
doi = {10.1145/3173574.3173625},
abstract = {Interpersonal distance behaviors can vary significantly across countries and impact human social interaction. Do these cross-cultural differences play out when one of the interaction partners participates through a teleoperated robot? Emerging research shows that when being approached by a robot, people tend to hold similar cultural preferences as they would for an approaching human. However, no work yet has investigated this question from a robot teleoperator's perspective. Toward answering this, we conducted an online study (N = 774) using a novel simulation paradigm across two countries (U.S. and India). Results show that in the role of a telepresence robot operator, participants exhibited cross-cultural differences in interpersonal distance behavior in line with human-human proxemic research, indicating that culture-specific distance behavior can manifest in the way a robot operator controls a robot. We discuss implications for designers who seek to automate path planning and navigation for teleoperated robots.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {telepresence robots, proxemics, robotic telepresence systems, interpersonal distance, robot-mediated communication, human-robot interaction, cross-cultural},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173626,
author = {Sannon, Shruti and Bazarova, Natalya N. and Cosley, Dan},
title = {Privacy Lies: Understanding How, When, and Why People Lie to Protect Their Privacy in Multiple Online Contexts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173626},
doi = {10.1145/3173574.3173626},
abstract = {In this paper, we study online privacy lies: lies primarily aimed at protecting privacy. Going beyond privacy lenses that focus on privacy concerns or cost/benefit analyses, we explore how contextual factors, motivations, and individual-level characteristics affect lying behavior through a 356-person survey. We find that statistical models to predict privacy lies that include attitudes about lying, use of other privacy-protective behaviors (PPBs), and perceived control over information improve on models based solely on self-expressed privacy concerns. Based on a thematic analysis of open-ended responses, we find that the decision to tell privacy lies stems from a range of concerns, serves multiple privacy goals, and is influenced by the context of the interaction and attitudes about the morality and necessity of lying. Together, our results point to the need for conceptualizations of privacy lies-and PPBs more broadly-that account for multiple goals, perceived control over data, contextual factors, and attitudes about PPBs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {computer-mediated communication, privacy, privacy-protective behaviors, deception},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173627,
author = {Fiesler, Casey and Hallinan, Blake},
title = {"We Are the Product": Public Reactions to Online Data Sharing and Privacy Controversies in the Media},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173627},
doi = {10.1145/3173574.3173627},
abstract = {As online platforms increasingly collect large amounts of data about their users, there has been growing public concern about privacy around issues such as data sharing. Controversies around practices perceived as surprising or even unethical often highlight patterns of privacy attitudes when they spark conversation in the media. This paper examines public reaction "in the wild" to two data sharing controversies that were the focus of media attention-regarding the social media and communication services Facebook and WhatsApp, as well as the email service unroll.me. These controversies instigated discussion of data privacy and ethics, accessibility of website policies, notions of responsibility for privacy, cost-benefit analyses, and strategies for privacy management such as non-use. An analysis of reactions and interactions captured by comments on news articles not only reveals information about pervasive privacy attitudes, but also suggests communication and design strategies that could benefit both platforms and users.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {policy, terms of service, data, online comments, journalism, privacy, online platforms, data sharing, non-use, ethics, social media},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173628,
author = {Gugenheimer, Jan and Stemasov, Evgeny and Sareen, Harpreet and Rukzio, Enrico},
title = {FaceDisplay: Towards Asymmetric Multi-User Interaction for Nomadic Virtual Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173628},
doi = {10.1145/3173574.3173628},
abstract = {Mobile VR HMDs enable scenarios where they are being used in public, excluding all the people in the surrounding (Non-HMD Users) and reducing them to be sole bystanders. We present FaceDisplay, a modified VR HMD consisting of three touch sensitive displays and a depth camera attached to its back. People in the surrounding can perceive the virtual world through the displays and interact with the HMD user via touch or gestures. To further explore the design space of FaceDisplay, we implemented three applications (FruitSlicer, SpaceFace and Conductor) each presenting different sets of aspects of the asymmetric co-located interaction (e.g. gestures vs touch). We conducted an exploratory user study (n=16), observing pairs of people experiencing two of the applications and showing a high level of enjoyment and social interaction with and without an HMD. Based on the findings we derive design considerations for asymmetric co-located VR applications and argue that VR HMDs are currently designed having only the HMD user in mind but should also include Non-HMD Users.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multi-user virtual reality, co-located multiplayer, nomadic virtual reality, asymmetric virtual reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173629,
author = {Ngoon, Tricia J. and Fraser, C. Ailie and Weingarten, Ariel S. and Dontcheva, Mira and Klemmer, Scott},
title = {Interactive Guidance Techniques for Improving Creative Feedback},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173629},
abstract = {Good feedback is critical to creativity and learning, yet rare. Many people do not know how to actually provide effective feedback. There is increasing demand for quality feedback -- and thus feedback givers -- in learning and professional settings. This paper contributes empirical evidence that two interactive techniques -- reusable suggestions and adaptive guidance -- can improve feedback on creative work. We present these techniques embodied in the CritiqueKit system to help reviewers give specific, actionable, and justified feedback. Two real-world deployment studies and two controlled experiments with CritiqueKit found that adaptively-presented suggestions improve the quality of feedback from novice reviewers. Reviewers also reported that suggestions and guidance helped them describe their thoughts and reminded them to provide effective feedback.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3173574.3173630,
author = {Kacorri, Hernisa and Ohn-Bar, Eshed and Kitani, Kris M. and Asakawa, Chieko},
title = {Environmental Factors in Indoor Navigation Based on Real-World Trajectories of Blind Users},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173630},
abstract = {Indoor localization technologies can enhance quality of life for blind people by enabling them to independently explore and navigate indoor environments. Researchers typically evaluate their systems in terms of localization accuracy and user behavior along planned routes. We propose two measures of path-following behavior: deviation from optimal route and trajectory variability. Through regression analysis of real-world trajectories from blind users, we identify relationships between a) these measures and b) elements of the environment, route characteristics, localization error, and instructional cues that users receive. Our results provide insights into path-following behavior for turn-by-turn indoor navigation and have implications for the design of future interactions. Moreover, our findings highlight the importance of reporting these environmental factors and route properties in similar studies. We present automated and scalable methods for their calculation and to encourage their reporting for better interpretation and comparison of results across future studies.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173631,
author = {Vashistha, Aditya and Sethi, Pooja and Anderson, Richard},
title = {BSpeak: An Accessible Voice-Based Crowdsourcing Marketplace for Low-Income Blind People},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173631},
doi = {10.1145/3173574.3173631},
abstract = {BSpeak is an accessible crowdsourcing marketplace that enables blind people in developing regions to earn money by transcribing audio files through speech. We examine accessibility and usability barriers that 15 first-time users, who are low-income and blind, experienced while completing transcription tasks on BSpeak and Mechanical Turk (MTurk). Our mixed-methods analysis revealed severe accessibility barriers in MTurk due to the absence of landmarks, unlabeled UI elements, and improper use of HTML headings. Compared to MTurk, participants found BSpeak significantly more accessible and usable, and completed tasks with higher accuracy in lesser time due to its voice-based implementation. In a two-week field deployment of BSpeak in India, 24 low-income blind users earned rupee 7,310 by completing over 16,000 transcription tasks to yield transcriptions with 87% accuracy. Through our analysis of BSpeak's strengths and weaknesses, we provide recommendations for designing crowdsourcing marketplaces for low-income blind people in resource-constrained settings.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {india, crowdsourcing, voice, accessibility, hci4d},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173632,
author = {Toxtli, Carlos and Monroy-Hern\'{a}ndez, Andr\'{e}s and Cranshaw, Justin},
title = {Understanding Chatbot-Mediated Task Management},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173632},
doi = {10.1145/3173574.3173632},
abstract = {Effective task management is essential to successful team collaboration. While the past decade has seen considerable innovation in systems that track and manage group tasks, these innovations have typically been outside of the principal communication channels: email, instant messenger, and group chat. Teams formulate, discuss, refine, assign, and track the progress of their collaborative tasks over electronic communication channels, yet they must leave these channels to update their task-tracking tools, creating a source of friction and inefficiency. To address this problem, we explore how bots might be used to mediate task management for individuals and teams. We deploy a prototype bot to eight different teams of information workers to help them create, assign, and keep track of tasks, all within their main communication channel. We derived seven insights for the design of future bots for coordinating work.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {mediated communication, bot, chatbot, task management},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173633,
author = {Morris, Meredith Ringel and Johnson, Jazette and Bennett, Cynthia L. and Cutrell, Edward},
title = {Rich Representations of Visual Content for Screen Reader Users},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173633},
doi = {10.1145/3173574.3173633},
abstract = {Alt text (short for "alternative text") is descriptive text associated with an image in HTML and other document formats. Screen reader technologies speak the alt text aloud to people who are visually impaired. Introduced with HTML 2.0 in 1995, the alt attribute has not evolved despite significant changes in technology over the past two decades. In light of the expanding volume, purpose, and importance of digital imagery, we reflect on how alt text could be supplemented to offer a richer experience of visual content to screen reader users. Our contributions include articulating the design space of representations of visual content for screen reader users, prototypes illustrating several points within this design space, and evaluations of several of these new image representations with people who are blind. We close by discussing the implications of our taxonomy, prototypes, and user study findings.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {screen readers, accessibility, blindness, captions, visual impairment, alternative text, alt text},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173634,
author = {Lottridge, Danielle and Bentley, Frank R.},
title = {Let's Hate Together: How People Share News in Messaging, Social, and Public Networks},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173634},
abstract = {There are currently a wide variety of ways to share news with others: from sharing in a personal message, to sharing on a social network, to publicly posting. Through a survey with over one thousand people and an artifact analysis of 262 shared articles, we examine differences in motivations and frequency of sharing news on public, social and private platforms. We find that public sharing is more focused on spreading an ideology, while private sharing in messaging is dominated by stories inspired by the recipient's interests or context. The survey revealed three main groups of news sharing practices: those who shared to all channels (public, social, private), those who didn't share at all, and those who shared to private and social. The groups differed in their attitudes toward online discussion; those that shared the most were neutral and those that didn't share had negative attitudes about discussion online. We discuss sharing practices and implications for social systems that support sharing news.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173635,
author = {Karpashevich, Pavel and Hornecker, Eva and Honauer, Michaela and Sanches, Pedro},
title = {Reinterpreting Schlemmer's Triadic Ballet: Interactive Costume for Unthinkable Movements},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173635},
doi = {10.1145/3173574.3173635},
abstract = {In the 1920s, Oskar Schlemmer, artist in the Bauhaus movement, created the Triadic Ballet costumes. These re-strict movement of dancers, creating new expressions. In-spired by this, we designed an interactive wire costume. It restricts lower body movements, and emphasizes arm movements spurring LED-light 'sparks' and 'waves' wired in a tutu-like costume. The Wire Costume was introduced to a dancer who found that an unusual bond emerged be-tween her and the costume. We discuss how sensory altera-tion (sight, kinesthetic awareness and proprioception) and bodily training to adjust to the new soma, can result in nov-el, evocative forms of expression. The interactive costume can foster a certain mood, introduce feelings, and even embody a whole character -- only revealed once worn and danced. We describe a design exploration combining cul-tural and historical research, interviews with experts and material explorations that culminated in a novel prototype.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interdisciplinary collaboration, theatrical performance, costume design, wearables, design research, crafts},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173636,
author = {Unbehaun, David and Vaziri, Daryoush Daniel and Aal, Konstantin and Wieching, Rainer and Tolmie, Peter and Wulf, Volker},
title = {Exploring the Potential of Exergames to Affect the Social and Daily Life of People with Dementia and Their Caregivers},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173636},
abstract = {This paper presents the outcomes of an exploratory field study that examined the social impact of an ICT-based suite of exergames for people with dementia and their caregivers. Qualitative data was collected over a period of 8 months, during which time we studied the daily life of 14 people with dementia and their informal and professional caregivers. We focus on the experiential aspects of the system and examine its social impact when integrated into the daily routines of both people with dementia themselves and their professional and family caregivers. Our findings indicate that relatives were able to regain leisure time, whilst people with dementia were able to recapture certain aspects of their social and daily activities that might otherwise have been lost to them. Results suggest that the system enhanced social-interaction, invigorated relationships, and improved the empowerment of people with dementia and their caregivers to face daily challenges.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inproceedings{10.1145/3173574.3173637,
author = {Roumen, Thijs Jan and M\"{u}ller, Willi and Baudisch, Patrick},
title = {Grafter: Remixing 3D-Printed Machines},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173637},
doi = {10.1145/3173574.3173637},
abstract = {Creating new 3D printed objects by recombining models found in hobbyist repositories has been referred to as "re-mixing". In this paper, we explore how to best support users in remixing a specific class of 3D printed objects, namely those that perform mechanical functions. In our survey, we found that makers remix such machines by manually extracting parts from one parent model and combine it with parts from a different parent model. This approach often puts axles made by one maker into bearings made by another maker or combines a gear by one maker with a gear by a different maker. This approach is problem-atic, however, as parts from different makers tend to fit poorly, which results in long series of tweaks and test-prints until all parts finally work together. We address this with our interactive system grafter. Grafter does two things. First, grafter largely automates the process of extracting and recombining mechanical elements from 3D printed machines. Second, it enforces a more efficient approach to reuse: it prevents users from extracting indi-vidual parts, but instead affords extracting groups of me-chanical elements that already work together, such as axles and their bearings or pairs of gears. We call this mecha-nism-based remixing. In a final user study, all models that participants had remixed using grafter could be 3D printed without further tweaking and worked immediately.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {remixing, fabrication, 3d printing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173638,
author = {Nguyen, Cuong and DiVerdi, Stephen and Hertzmann, Aaron and Liu, Feng},
title = {Depth Conflict Reduction for Stereo VR Video Interfaces},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173638},
doi = {10.1145/3173574.3173638},
abstract = {Applications for viewing and editing 360° video often render user interface (UI) elements on top of the video. For stereoscopic video, in which the perceived depth varies over the image, the perceived depth of the video can conflict with that of the UI elements, creating discomfort and making it hard to shift focus. To address this problem, we explore two new techniques that adjust the UI rendering based on the video content. The first technique dynamically adjusts the perceived depth of the UI to avoid depth conflict, and the second blurs the video in a halo around the UI. We conduct a user study to assess the effectiveness of these techniques in two stereoscopic VR video tasks: video watching with subtitles, and video search.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {360, virtual reality, video interface, subtitles, stereoscopic},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173639,
author = {Strohmeier, Paul and Boring, Sebastian and Hornb\ae{}k, Kasper},
title = {From Pulse Trains to "Coloring with Vibrations": Motion Mappings for Mid-Air Haptic Textures},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173639},
abstract = {Can we experience haptic textures in mid-air? Typically, the experience of texture is caused by vibration of the fingertip as it moves over the surface of an object. This object's surface also guides the finger's movement, creating an implicit motion-to-vibration mapping. If we wish to simulate a texture in mid-air, such guidance does not exist, making the choice of motion-to-vibration mapping non-obvious. We evaluate the experience of moving a pointer with four different motion-to vibration mappings in an interview study. We found that some mappings lead to a perception shift, transforming the experience. When this occurs, the pointer is no longer perceived as vibrating, interactions become more pleasurable, and users have an increased experience of agency and control. We discuss how to leverage this in the design of haptic interfaces.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173640,
author = {Hong, Sungsoo (Ray) and Suh, Minhyang (Mia) and Henry Riche, Nathalie and Lee, Jooyoung and Kim, Juho and Zachry, Mark},
title = {Collaborative Dynamic Queries: Supporting Distributed Small Group Decision-Making},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173640},
doi = {10.1145/3173574.3173640},
abstract = {Communication is critical in small group decision-making processes during which each member must be able to express preferences to reach consensus. Finding consensus can be difficult when each member in a group has a perspective that potentially conflicts with those of others. To support groups attempting to harmonize diverse preferences, we propose Collaborative Dynamic Queries (C-DQ), a UI component that enables a group to filter queries over decision criteria while being aware of others' preferences. To understand how C-DQ affects a group's behavior and perception in the decision-making process, we conducted 2 studies with groups who were prompted to make decisions together on mobile devices in a dispersed and synchronous situation. In Study 1, we found showing group preferences with C-DQ helped groups to communicate more efficiently and effectively. In Study 2, we found filtering candidates based on each member's own filter range further improved a groups' communication efficiency and effectiveness.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {group decision-making, group awareness, consensus, collaborative dynamic queries, group filtering, visualization},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173641,
author = {Jang, Esther and Barela, Mary Claire and Johnson, Matt and Martinez, Philip and Festin, Cedric and Lynn, Margaret and Dionisio, Josephine and Heimerl, Kurtis},
title = {Crowdsourcing Rural Network Maintenance and Repair via Network Messaging},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173641},
doi = {10.1145/3173574.3173641},
abstract = {Repair and maintenance requirements limit the successful operation of rural infrastructure. Current best practices are centralized management, which requires travel from urban areas and is prohibitively expensive, or intensively training community members, which limits scaling. We explore an alternative model: crowdsourcing repair from the community. Leveraging a Community Cellular Network in the remote Philippines, we sent SMS to all active network subscribers (n = 63) requesting technical support. From the pool of physical respondents, we explored their ability to repair through mock failures and conducted semi-structured interviews about their experiences with repair. We learned that community members would be eager to practice repair if allowed, would network to recruit more expertise, and seemingly have the collective capacity to resolve some common failures. They are most successful when repairs map directly to their lived experiences. We suggest infrastructure design considerations that could make repairs more tractable and argue for an inclusive approach.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {technology for development, ictd, crowdsourcing, internet access, rural development},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173642,
author = {Thomsen, Josephine Raun and Krogh, Peter Gall and Schnedler, Jacob Alb\ae{}k and Linnet, Hanne},
title = {Interactive Interior and Proxemics Thresholds: Empowering Participants in Sensitive Conversations},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173642},
doi = {10.1145/3173574.3173642},
abstract = {The position and workings of interactive interior elements matter greatly on the relations people may enact. This paper reports on the conception and evaluation of an interactive table and its interior effects designed to support sensitive consultations between healthcare personnel, patients and relatives as they happen during treatment of cancer diseases in a hospital department of oncology. The interior design includes the physical shape of artefact, its digital functionality and how the seating around it is to take place. The design of the table is substantiated through observations of current practice, framing of the design challenge, conceptualization, and exploring form giving alternatives. Through a set of evaluations in actual use settings it is argued how the design concept of the table as interactive interior points to how notions in interaction proxemics should be rearticulated. In particular, this paper argues how proxemics thresholds should be regarded as dynamic and relational.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {design in the wild, interactive interior, sensitive contexts, interaction proxemics, healthcare},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173643,
author = {Milne, Lauren R. and Ladner, Richard E.},
title = {Blocks4All: Overcoming Accessibility Barriers to Blocks Programming for Children with Visual Impairments},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173643},
doi = {10.1145/3173574.3173643},
abstract = {Blocks-based programming environments are a popular tool to teach children to program, but they rely heavily on visual metaphors and are therefore not fully accessible for children with visual impairments. We evaluated existing blocks-based environments and identified five major accessibility barriers for visually impaired users. We explored techniques to overcome these barriers in an interview with a teacher of the visually impaired and formative studies on a touchscreen blocks-based environment with five children with visual impairments. We distill our findings on usable touchscreen interactions into guidelines for designers of blocks-based environments.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {visual impairments, accessibility, computer science education, blocks-based programming environments},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173644,
author = {Skirpan, Michael Warren and Yeh, Tom and Fiesler, Casey},
title = {What's at Stake: Characterizing Risk Perceptions of Emerging Technologies},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173644},
doi = {10.1145/3173574.3173644},
abstract = {One contributing factor to how people choose to use technology is their perceptions of associated risk. In order to explore this influence, we adapted a survey instrument from risk perception literature to assess mental models of users and technologists around risks of emerging, data-driven technologies (e.g., identity theft, personalized filter bubbles). We surveyed 175 individuals for comparative and individual assessments of risk, including characterizations using psychological factors. We report our observations around group differences (e.g., expert versus non-expert) in how people assess risk, and what factors may structure their conceptions of technological harm. Our findings suggest that technologists see these risks as posing a bigger threat to society than do non-experts. Moreover, across groups, participants did not see technological risks as voluntarily assumed. Differences in how people characterize risk have implications for the future of design, decision-making, and public communications, which we discuss through a lens we call risk-sensitive design.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {risk, design, ethics},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173645,
author = {Boucher, Andy and Brown, Dean and Ovalle, Liliana and Sheen, Andy and Vanis, Mike and Odom, William and Oogjes, Doenja and Gaver, William},
title = {TaskCam: Designing and Testing an Open Tool for Cultural Probes Studies},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173645},
doi = {10.1145/3173574.3173645},
abstract = {TaskCams are simple digital cameras intended to serve as a tool for Cultural Probe studies and made available by the Interaction Research Studio via open-source distribution. In conjunction with an associated website, instructions and videos, they represent a novel strategy for disseminating and facilitating a research methodology. At the same time, they provide a myriad of options for customisation and modification, allowing researchers to adopt and adapt them to their needs. In the first part of this paper, the design team describes the rationale and design of the TaskCams and the tactics developed to make them publicly available. In the second part, the story is taken up by designers from the Everyday Design Studio, who assembled their own TaskCams and customised them extensively for a Cultural Probe study they ran for an ongoing project. Rather than discussing the results of their study, we focus on how their experiences reveal some of the issues both in producing and using open-source products such as these. These suggest the potential of TaskCams to support design-led user studies more generally.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {context studies, cultural probes, user studies, open source, design research, making},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173646,
author = {Encinas, Enrique and Blythe, Mark and Lawson, Shaun and Vines, John and Wallace, Jayne and Briggs, Pam},
title = {Making Problems in Design Research: The Case of Teen Shoplifters on Tumblr},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173646},
doi = {10.1145/3173574.3173646},
abstract = {HCI draws on a variety of traditions but recently there have been calls to consolidate contributions around the problems researchers set out to solve. However, with this comes the assumption that problems are tractable and certain, rather than constructed and framed by researchers. We take as a case study a Tumblr community of teen shoplifters who post on how to steal from stores, discuss shoplifting as political resistance, and share jokes and stories about the practice. We construct three different "problems" and imagine studies that might result from applying different design approaches: Design Against Crime; Critical Design and Value Sensitive Design. Through these studies we highlight how interpretations of the same data can lead to radically different design responses. We conclude by discussing problem making as a historically and politically contingent process that allow researchers to connect data and design according to certain moral and ethical principles.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {tumblr, problem solving, social media, design fiction, teens, shoplifting, research through design},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173647,
author = {Homaeian, Leila and Goyal, Nippun and Wallace, James R. and Scott, Stacey D.},
title = {Group vs Individual: Impact of TOUCH and TILT Cross-Device Interactions on Mixed-Focus Collaboration},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173647},
doi = {10.1145/3173574.3173647},
abstract = {Cross-device environments (XDEs) have been developed to support a multitude of collaborative activities. Yet, little is known about how different cross-device interaction techniques impact group collaboration, including how their impact on independent and joint work that often occurs during group work. In this work, we explore the impact of two XDE data browsing techniques: TOUCH and TILT. Through a mixed-methods study of a collaborative sensemaking task, we show that TOUCH and TILT have distinct impacts on how groups accomplish, and shift between, independent and joint work. Finally, we reflect on these findings and how they can more generally inform the design of XDEs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {touch, tilt, mixed-focus collaboration, cross-device},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173648,
author = {Vega, Julio and Couth, Samuel and Poliakoff, Ellen and Kotz, Sonja and Sullivan, Matthew and Jay, Caroline and Vigo, Markel and Harper, Simon},
title = {Back to Analogue: Self-Reporting for Parkinson's Disease},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173648},
doi = {10.1145/3173574.3173648},
abstract = {We report the process used to create artefacts for self-reporting Parkinson's Disease symptoms. Our premise was that a technology-based approach would provide participants with an effective, flexible, and resilient technique. After testing four prototypes using Bluetooth, NFC, and a microcontroller we accomplished almost full compliance and high acceptance using a paper diary to track day-to-day fluctuations over 49 days. This diary is tailored to each patient's condition, does not require any handwriting, allows for implicit reminders, provides recording flexibility, and its answers can be encoded automatically. We share five design implications for future Parkinson's self-reporting artefacts: reduce participant completion demand, design to offset the effect of tremor on input, enable implicit reminders, design for positive and negative consequences of increased awareness of symptoms, and consider the effects of handwritten notes in compliance, encoding burden, and data quality.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {parkinson's disease, paper diary, ema, self-report},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173649,
author = {Alavi, Hamed S. and Verma, Himanshu and Mlynar, Jakub and Lalanne, Denis},
title = {The Hide and Seek of Workspace: Towards Human-Centric Sustainable Architecture},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173649},
doi = {10.1145/3173574.3173649},
abstract = {This contribution exemplifies how the study of space perception and its impact on space-use behavior can inform sustainable architecture. We describe our attempt to integrate the methods of user research in an architectural project that was focused on optimization of space usage. In an office building, two large office rooms were refurbished to provide desk-sharing opportunities through hot-desking. We studied the space-use behavior of 33 office workers over eight weeks in those two rooms as well as their occasional presence in ten other areas (cafeteria, atrium, meeting rooms, etc.). Quantitative and qualitative analyses were performed to understand the nature and nuances of space occupancy at the scope of the building and within the refurbished offices. While at the scope of building the patterns of movements between rooms were found to be related to the professional profile of the users, at the scope of office the occupancy patterns were influenced by the spatial design of workspaces. More precisely, certain visual attributes of a workspace, namely Visual Exposure and Visual Openness, could determine whether or not it was regularly used. In this paper, we describe our findings in detail and discuss their implications for sustainable building design.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {sustainable architecture, visual attributes of space, human-building interaction, shared offices, sustainability},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173650,
author = {Bennett, Cynthia L. and E, Jane and Mott, Martez E. and Cutrell, Edward and Morris, Meredith Ringel},
title = {How Teens with Visual Impairments Take, Edit, and Share Photos on Social Media},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173650},
doi = {10.1145/3173574.3173650},
abstract = {We contribute a qualitative investigation of how teens with visual impairments (VIP) access smartphone photography, from the time they take photos through editing and sharing them on social media. We observed that they largely want to engage with photos visually, similarly to their sighted peers, and have developed strategies around photo capture, editing, sharing, and consumption that attempt to mitigate usability limitations of current photography and social media apps. We demonstrate the need for more work examining how young people with low vision engage with smartphone photography and social media, as they are heavy users of such technologies and have challenges distinct from their totally blind counterparts. We conclude with design considerations to alleviate the usability barriers we uncovered and for making smartphone photography and social media more accessible and relevant for VIPs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {accessibility, visual impairment, snapchat, instagram, social media, blindness, photography},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173651,
author = {Odom, William and Wakkary, Ron and Bertran, Ishac and Harkness, Matthew and Hertz, Garnet and Hol, Jeroen and Lin, Henry and Naus, Bram and Tan, Perry and Verburg, Pepijn},
title = {Attending to Slowness and Temporality with Olly and Slow Game: A Design Inquiry Into Supporting Longer-Term Relations with Everyday Computational Objects},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173651},
doi = {10.1145/3173574.3173651},
abstract = {Slowness has emerged as a rich lens to frame HCI investigations into supporting longer-term human-technology relations. Yet, there is a need to further address how we design for slowness on conceptual and practical levels. Drawing on the concepts of unawareness, intersections, and ensembles, we contribute an investigation into designing for slowness and temporality grounded in design practice through two cases: Olly and Slow Game. We designed these artifacts over two and a half years with careful attention to how the set of concepts influenced key design decisions in terms of their form, materials, and computational qualities. Our designer-researcher approach revealed that, when put into practice, the concepts helped generatively grapple with slowness and temporality, but are in need of further development to be mobilized for design. We critically reflect on insights emerging across our practice-based research to reflexively refine the concepts and better support future HCI research and practice.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {temporality, research through design, slow technology},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173652,
author = {Yan, Yukang and Yu, Chun and Ma, Xiaojuan and Yi, Xin and Sun, Ke and Shi, Yuanchun},
title = {VirtualGrasp: Leveraging Experience of Interacting with Physical Objects to Facilitate Digital Object Retrieval},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173652},
doi = {10.1145/3173574.3173652},
abstract = {We propose VirtualGrasp, a novel gestural approach to retrieve virtual objects in virtual reality. Using VirtualGrasp, a user retrieves an object by performing a barehanded gesture as if grasping its physical counterpart. The object-gesture mapping under this metaphor is of high intuitiveness, which enables users to easily discover, remember the gestures to retrieve the objects. We conducted three user studies to demonstrate the feasibility and effectiveness of the approach. Progressively, we investigated the consensus of the object-gesture mapping across users, the expressivity of grasping gestures, and the learnability and performance of the approach. Results showed that users achieved high agreement on the mapping, with an average agreement score [35] of 0.68 (SD=0.27). Without exposure to the gestures, users successfully retrieved 76% objects with VirtualGrasp. A week after learning the mapping, they could recall the gestures for 93% objects.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gesture, object selection, mapping},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173653,
author = {Foong, Pin Sym and Zhao, Shengdong and Tan, Felicia and Williams, Joseph Jay},
title = {Harvesting Caregiving Knowledge: Design Considerations for Integrating Volunteer Input in Dementia Care},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173653},
doi = {10.1145/3173574.3173653},
abstract = {Improving volunteer performance leads to better caregiving in dementia care settings. However, caregiving knowledge systems have been focused on eliciting and sharing expert, primary caregiver knowledge, rather than volunteer-provided knowledge. Through the use of an experience prototype, we explored the content of volunteer caregiver knowledge and identified ways in which such non-expert knowledge can be useful to dementia care. By using lay language, sharing information specific to the client and collaboratively finding strategies for interaction, volunteers were able to boost the effectiveness of future volunteers. Therapists who reviewed the content affirmed the reliability of volunteer caregiver knowledge and placed value on its recency, variety and its ability to help bridge language and professional barriers. We discuss how future systems designed for eliciting and sharing volunteer caregiver knowledge can be used to promote better dementia care.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {volunteers, health, dementia care, caregiving},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173654,
author = {Rapp, Amon},
title = {Gamification for Self-Tracking: From World of Warcraft to the Design of Personal Informatics Systems},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173654},
doi = {10.1145/3173574.3173654},
abstract = {World of Warcraft (WoW) may be a source of inspiration to enrich the Personal Informatics systems user's experience and, at the same time, improve gamification design. Through the findings of a four-year reflexive ethnography in WoW, I outline how its game design elements support players in making sense of their own data, emphasizing how "game numbers" are turned into meanings. On the basis of the study results, I propose a series of design considerations to be used in the design of self-tracking systems, which recommend to embody data into digital entities, provide different analytical tools depending on the users' expertise through a flexible model, and foster the formation of "communities of practice" in order to support learning processes.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {quantified self, gamification, personal informatics, world of warcraft, self-tracking},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173655,
author = {Kyt\"{o}, Mikko and Ens, Barrett and Piumsomboon, Thammathip and Lee, Gun A. and Billinghurst, Mark},
title = {Pinpointing: Precise Head- and Eye-Based Target Selection for Augmented Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173655},
abstract = {Head and eye movement can be leveraged to improve the user's interaction repertoire for wearable displays. Head movements are deliberate and accurate, and provide the current state-of-the-art pointing technique. Eye gaze can potentially be faster and more ergonomic, but suffers from low accuracy due to calibration errors and drift of wearable eye-tracking sensors. This work investigates precise, multimodal selection techniques using head motion and eye gaze. A comparison of speed and pointing accuracy reveals the relative merits of each method, including the achievable target size for robust selection. We demonstrate and discuss example applications for augmented reality, including compact menus with deep structure, and a proof-of-concept method for on-line correction of calibration drift.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3173574.3173656,
author = {Hamdan, Nur Al-huda and Voelker, Simon and Borchers, Jan},
title = {Sketch&amp;Stitch: Interactive Embroidery for E-Textiles},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173656},
abstract = {E-Textiles are fabrics that integrate electronic circuits and components. Makers use them to create interactive clothing, furniture, and toys. However, this requires significant manual labor and skills, and using technology-centric design tools. We introduce Sketch&amp;Stitch, an interactive embroidery system to create e-textiles using a traditional crafting approach: Users draw their art and circuit directly on fabric using colored pens. The system takes a picture of the sketch, converts it to embroidery patterns, and sends them to an embroidery machine. Alternating between sketching and stitching, users build and test their design incrementally. Sketch&amp;Stitch features Circuitry Stickers representing circuit boards, components, and custom stitch patterns for wire crossings to insulate, and various textile touch sensors such as pushbuttons, sliders, and 2D touchpads. Circuitry Stickers serve as placeholders during design. Using computer vision, they are recognized and replaced later in the appropriate embroidery phases. We close with technical considerations and application examples.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3173574.3173657,
author = {Ma, Ning F. and Yuan, Chien Wen and Ghafurian, Moojan and Hanrahan, Benjamin V.},
title = {Using Stakeholder Theory to Examine Drivers' Stake in Uber},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173657},
abstract = {Uber is a ride-sharing platform that is part of the 'gig-economy,' where the platform supports and coordinates a labor market in which there are a large number of ephemeral, piecemeal jobs. Despite numerous efforts to understand the impacts of these platforms and their algorithms on Uber drivers, how to better serve and support drivers with these platforms remains an open challenge. In this paper, we frame Uber through the lens of Stakeholder Theory to highlight drivers' position in the workplace, which helps inform the design of a more ethical and effective platform. To this end, we analyzed Uber drivers' forum discussions about their lived experiences of working with the Uber platform. We identify and discuss the impact of the stakes that drivers have in relation to both the Uber corporation and their passengers, and look at how these stakes impact both the platform and drivers' practices.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173658,
author = {Kogan, Marina and Palen, Leysia},
title = {Conversations in the Eye of the Storm: At-Scale Features of Conversational Structure in a High-Tempo, High-Stakes Microblogging Environment},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173658},
doi = {10.1145/3173574.3173658},
abstract = {This work propels social media research beyond the single post as the unit of analysis toward fuller treatment of interaction by making the construct of the conversation analytically available. We offer a method for constructing @reply conversations in Twitter to apprehend social media conversational features at scale. We apply this method to the high-tempo, high-stakes environment of 2012's Hurricane Sandy, with its high volume of online talk by affected locals and distinct disaster-stage phasing by which to consider interactional difference. We investigate the temporality of conversations; the relationality of who speaks to whom; the number and kind of conversationalists; and how content affects temporal features. The analysis reveals that, during the height of the emergency, people expand conversations both in number and kind of conversational partners-just as their information search intensifies. This expansion contributes to longer, slower-paced conversations in the high-emergency period, suggesting reliance on online relationships during times of greatest uncertainty.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social media, social computing, crisis informatics, computer supported cooperative work},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173659,
author = {Head, Andrew and Glassman, Elena L. and Hartmann, Bj\"{o}rn and Hearst, Marti A.},
title = {Interactive Extraction of Examples from Existing Code},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173659},
doi = {10.1145/3173574.3173659},
abstract = {Programmers frequently learn from examples produced and shared by other programmers. However, it can be challenging and time-consuming to produce concise, working code examples. We conducted a formative study where 12 participants made examples based on their own code. This revealed a key hurdle: making meaningful simplifications without introducing errors. Based on this insight, we designed a mixed-initiative tool, CodeScoop, to help programmers extract executable, simplified code from existing code. CodeScoop enables programmers to "scoop" out a relevant subset of code. Techniques include selectively including control structures and recording an execution trace that allows authors to substitute literal values for code and variables. In a controlled study with 19 participants, CodeScoop helped programmers extract executable code examples with the intended behavior more easily than with a standard code editor.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {example sharing, programming support},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173660,
author = {Whitmire, Eric and Benko, Hrvoje and Holz, Christian and Ofek, Eyal and Sinclair, Mike},
title = {Haptic Revolver: Touch, Shear, Texture, and Shape Rendering on a Reconfigurable Virtual Reality Controller},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173660},
doi = {10.1145/3173574.3173660},
abstract = {We present Haptic Revolver, a handheld virtual reality controller that renders fingertip haptics when interacting with virtual surfaces. Haptic Revolver's core haptic element is an actuated wheel that raises and lowers underneath the finger to render contact with a virtual surface. As the user's finger moves along the surface of an object, the controller spins the wheel to render shear forces and motion under the fingertip. The wheel is interchangeable and can contain physical textures, shapes, edges, or active elements to provide different sensations to the user. Because the controller is spatially tracked, these physical features can be spatially registered with the geometry of the virtual environment and rendered on-demand. We evaluated Haptic Revolver in two studies to understand how wheel speed and direction impact perceived realism. We also report qualitative feedback from users who explored three application scenarios with our controller.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, haptics},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173661,
author = {Katsini, Christina and Fidas, Christos and Raptis, George E. and Belk, Marios and Samaras, George and Avouris, Nikolaos},
title = {Influences of Human Cognition and Visual Behavior on Password Strength during Picture Password Composition},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173661},
doi = {10.1145/3173574.3173661},
abstract = {Visual attention, search, processing and comprehension are important cognitive tasks during a graphical password composition activity. Aiming to shed light on whether individual differences on visual behavior affect the strength of the created passwords, we conducted an eye-tracking study (N=36), and adopted an accredited cognitive style theory to interpret the results. The analysis revealed that users with different cognitive styles followed different patterns of visual behavior which affected the strength of the created passwords. Motivated, by the results of the first study, we introduced adaptive characteristics to the user authentication mechanism, aiming to assist specific cognitive style user groups to create more secure passwords, and conducted a second study with a new sample (N=40) to test the adaptive characteristics. Results strengthen our assumptions that adaptive mechanisms based on users' differences in cognitive and visual behavior uncover a new perspective for improving the password's strength within graphical user authentication realms.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {graphical user authentication, cognitive styles, field dependence-independence, visual behavior, usable security, eye-tracking, cued-recall authentication, picture passwords},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173662,
author = {Williams, Alex C. and Kaur, Harmanpreet and Mark, Gloria and Thompson, Anne Loomis and Iqbal, Shamsi T. and Teevan, Jaime},
title = {Supporting Workplace Detachment and Reattachment with Conversational Intelligence},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173662},
doi = {10.1145/3173574.3173662},
abstract = {Research has shown that productivity is mediated by an individual's ability to detach from their work at the end of the day and reattach with it when they return the next day. In this paper we explore the extent to which structured dialogues, focused on individuals' work-related tasks or emotions, can help them with the detachment and reattachment processes. Our inquiry is driven with SwitchBot, a conversational bot which engages with workers at the start and end of their work day. After preliminarily validating the design of a detachment and reattachment dialogue frame-work with 108 crowdworkers, we study SwitchBot's use in-situ for 14 days with 34 information workers. We find that workers send fewer e-mails after work hours and spend a larger percentage of their first hour at work using productivity applications than they normally would when using SwitchBot. Further, we find that productivity gains were better sustained when conversations focused on work-related emotions. Our results suggest that conversational bots can be effective tools for aiding workplace detachment and reattachment and help people make successful use of their time on and off the job.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {reattachment, bot, resumption, detachment, productivity},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173663,
author = {Cheng, Lung-Pan and Chang, Li and Marwecki, Sebastian and Baudisch, Patrick},
title = {ITurk: Turning Passive Haptics into Active Haptics by Making Users Reconfigure Props in Virtual Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173663},
doi = {10.1145/3173574.3173663},
abstract = {We present a system that complements virtual reality experiences with passive props, yet still allows modifying the virtual world at runtime. The main contribution of our system is that it does not require any actuators; instead, our system employs the user to reconfigure and actuate otherwise passive props. We demonstrate a foldable prop that users reconfigure to represent a suitcase, fuse cabinet, railing, and a seat. A second prop, suspended from a long pendulum, not only stands in for inanimate objects, but also for objects that move and demonstrate proactive behavior, such as a group of flying droids that physically attack the user. Our approach conveys a sense of a living, animate world, when in reality the user is the only animate entity present in the system, complemented with only one or two physical props. In our study, participants rated their experience as more enjoyable and realistic than a corresponding no-haptics condition.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {immersion, human actuation, haptics, virtual reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173664,
author = {Butscher, Simon and Hubenschmid, Sebastian and M\"{u}ller, Jens and Fuchs, Johannes and Reiterer, Harald},
title = {Clusters, Trends, and Outliers: How Immersive Technologies Can Facilitate the Collaborative Analysis of Multidimensional Data},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173664},
doi = {10.1145/3173574.3173664},
abstract = {Immersive technologies such as augmented reality devices are opening up a new design space for the visual analysis of data. This paper studies the potential of an augmented reality environment for the purpose of collaborative analysis of multidimensional, abstract data. We present ART, a collaborative analysis tool to visualize multidimensional data in augmented reality using an interactive, 3D parallel coordinates visualization. The visualization is anchored to a touch-sensitive tabletop, benefiting from well-established interaction techniques. The results of group-based, expert walkthroughs show that ART can facilitate immersion in the data, a fluid analysis process, and collaboration. Based on the results, we provide a set of guidelines and discuss future research areas to foster the development of immersive technologies as tools for the collaborative analysis of multidimensional data.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3d parallel coordinates, augmented reality, collaboration, immersive analytics, multi-touch table},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173665,
author = {Berke, Larwan and Kafle, Sushant and Huenerfauth, Matt},
title = {Methods for Evaluation of Imperfect Captioning Tools by Deaf or Hard-of-Hearing Users at Different Reading Literacy Levels},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173665},
abstract = {As Automatic Speech Recognition (ASR) improves in accuracy, it may become useful for transcribing spoken text in real-time for Deaf and Hard-of-Hearing (DHH) individuals. To quantify users' comprehension and opinion of automatic captions, which inevitably contain some errors, we must identify appropriate methodologies for evaluation studies with DHH users, including quantitative measurement instruments suitable to the various literacy levels among the DHH population. A literature review guided our selection of several probes (e.g. multiple-choice comprehension-question accuracy or response time, scalar-questions about user estimation of ASR errors or their impact, users' numerical estimation of accuracy), which we evaluated in a lab study with DHH users, wherein their literacy levels and the actual accuracy of each caption stimulus were factors. For some probes, participants with lower literacy had more positive subjective responses overall, and, for participants with particular literacy score ranges, some probes were insufficiently sensitive to distinguish between caption accuracy levels.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173666,
author = {Mark, Gloria and Czerwinski, Mary and Iqbal, Shamsi T.},
title = {Effects of Individual Differences in Blocking Workplace Distractions},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173666},
doi = {10.1145/3173574.3173666},
abstract = {Information workers are experiencing ever-increasing online distractions in the workplace, and software to block distractions is becoming more popular. We conducted an exploratory field study with 32 information workers in their workplace using software to block online distractions for one week. We discovered that with online distractions blocked, participants assessed their focus and productivity to be significantly higher. Those who benefited most were those who reported being less in control of their work, associated with personality traits of lower Conscientiousness and Lack of Perseverence. Unexpectedly, those reporting higher control of work experienced a cost of higher workload with online distractions blocked. Those who reported the greatest increase in focus with distractions blocked were those who were more susceptible to social media distractions. Without distractions, people with higher control of work worked longer stretches without physical breaks, with consequently higher stress. We present design recommendations to promote focus for our observed coping behaviors.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {focus, distractions, productivity, field study, multitasking, interruptions, workplace, social media},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173667,
author = {Gardner, Daniel L. and Tanenbaum, Joshua G.},
title = {Dynamic Demographics: Lessons from a Large-Scale Census of Performative Possibilities in Games},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173667},
doi = {10.1145/3173574.3173667},
abstract = {While much popular discussion of representation in games exists, there is very little rigorously collected data available from which to draw direct conclusions. In this study, we set out to address this gap by performing a census of playable characters across a large sample of contemporary games. We gathered data from 200 games including independently published ("indie") games and so-called "AAA" titles from large publishers. While our initial analysis yielded some insight into the landscape of playable characters, it also highlighted the contingent, negotiated, and interpretive nature of representation in games. This led to additional analysis that emphasized the ways in which this negotiation manifests in research in the methods and metrics used to quantify representation. We argue that researchers studying representation in games need to treat it as a possibility space for a multitude of potential interpretations rather than a singular, measurable, phenomenon.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {media census, representation in games},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173668,
author = {Wakkary, Ron and Oogjes, Doenja and Lin, Henry W. J. and Hauser, Sabrina},
title = {Philosophers Living with the Tilting Bowl},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173668},
abstract = {This paper reports on a postphenomenological inquiry of six trained philosophers, who as study participants lived with and reflected on a research product we designed known as the Tilting Bowl: a ceramic bowl that unpredictably but gently tilts multiple times daily. The Tilting Bowl is a counterfactual artifact that is designed specifically for this study as part of a material speculation approach to design research. A postphenomenological inquiry looks to describe and analyze accounts of relationships between humans and technological artifacts, and how each mutually shapes the other through mediations that form the human subjectivity and objectivity of any given situation. This paper contributes an empirical account and analysis of the relations that emerged (background and alterity) and the relativistic views that co-constitute the philosophers, Tilting Bowl, and their specific worlds. The findings demonstrate the relevance of this philosophical framing to fundamentally and broadly understand how people engage digital artifacts.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173669,
author = {Xiao, Robert and Cao, Teng and Guo, Ning and Zhuo, Jun and Zhang, Yang and Harrison, Chris},
title = {LumiWatch: On-Arm Projected Graphics and Touch Input},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173669},
doi = {10.1145/3173574.3173669},
abstract = {Compact, worn computers with projected, on-skin touch interfaces have been a long-standing yet elusive goal, largely written off as science fiction. Such devices offer the potential to mitigate the significant human input/output bottleneck inherent in worn devices with small screens. In this work, we present the first fully functional and self-contained projection smartwatch implementation, containing the requisite compute, power, projection and touch-sensing capabilities. Our watch offers roughly 40&nbsp;sq. cm of interactive surface area -- more than five times that of a typical smartwatch display. We demonstrate continuous 2D finger tracking with interactive, rectified graphics, transforming the arm into a touchscreen. We discuss our hardware and software implementation, as well as evaluation results regarding touch accuracy and projection visibility.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {depth sensing, smartwatch, time-of-flight, touch interaction, on-body interaction, projection},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173670,
author = {Kim, Yongsung and Gergle, Darren and Zhang, Haoqi},
title = {Hit-or-Wait: Coordinating Opportunistic Low-Effort Contributions to Achieve Global Outcomes in On-the-Go Crowdsourcing},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173670},
doi = {10.1145/3173574.3173670},
abstract = {We consider the challenge of motivating and coordinating large numbers of people to contribute to solving local, communal problems through their existing routines. In order to design such "on-the-go crowdsourcing" systems, there is a need for mechanisms that can effectively coordinate contributions to address problem solving needs in the physical world while leveraging people's existing mobility with minimal disruption. We thus introduce Hit-or-Wait, a general decision-theoretic mechanism that intelligently controls decisions over when to notify a person of a task, in ways that reason both about system needs across tasks and about a helper's changing patterns of mobility. Through simulations and a field study in the context of community-based lost-and-found, we demonstrate that using Hit-or-Wait enables a system to make efficient use of people's contributions with minimal disruptions to their routines without the need for explicit coordination. Interviews with field study participants further suggest that highlighting an individual's contribution to the global goal may help people value their contributions more.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {physical crowdsourcing, decision theory, mobile crowdsourcing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173671,
author = {Chen, Runyuan (Jason) and Orand, Mania and Choi, Shin Young (Lucia) and Choi, Leena},
title = {An Empirical Exploration of Mindfulness Design Using Solo Travel Domain},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173671},
doi = {10.1145/3173574.3173671},
abstract = {Despite recent popularity of mindfulness smartphone applications and an interest in incorporating mindfulness into new technologies, existing applications tend to focus mainly on its meditation dimension. In this paper, we review existing literature on digital and traditional mindfulness to map its design space and synthesize the findings with our prior research on designing for aesthetic needs. We identify "recollection" and "evaluation" as two important dimensions of mindfulness that have not yet been incorporated into popular digital tools. Through a two-phase design activity over 16 months, we developed ColorAway, an innovative tool that promotes mindfulness through interaction with modified travel photos. Recruited participants evaluated ColorAway and offered unique insights into how mindfulness can be better designed. We also discuss how the process of designing for mindfulness can possibly inform the design of personal technology. This research is part of a larger study that builds on scholarly research and theories with the goal of designing interactive technologies for solo travelers.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {hcd, design, solo travel, reflection, mindfulness, hci},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173672,
author = {Leong, Zeina Atrash and Horn, Michael S. and Thaniel, Lisa and Meier, Emily},
title = {Inspiring AWE: Transforming Clinic Waiting Rooms into Informal Learning Environments with Active Waiting Education},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173672},
doi = {10.1145/3173574.3173672},
abstract = {This research explores patient education in pediatric hematology and oncology clinics. Based on interviews, observations, and a review of existing patient materials, we argue that education in clinic waiting rooms is in need of reform. We applied design principles from research in science museums along with tangible interaction techniques to create the Sickle Cell Station, an interactive learning experience about sickle cell disease. To evaluate the effectiveness of this design we observed approximately 580 participants in a pediatric hematology clinic waiting area in four different design conditions. These observations included detailed video analysis of 81 patients and their parents to understand their interaction and learning with the Sickle Cell Station. Our results show an engaging learning experience with relevant conversation, inquiry, and collaboration. We describe how patient engagement varied in the four design conditions and conclude with implications for new designs in the area of Active Waiting Education (AWE).},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {education, children, health, interactive media, design},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173673,
author = {Wilson, Graham and McGill, Mark and Jamieson, Matthew and Williamson, Julie R. and Brewster, Stephen A.},
title = {Object Manipulation in Virtual Reality Under Increasing Levels of Translational Gain},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173673},
doi = {10.1145/3173574.3173673},
abstract = {Room-scale Virtual Reality (VR) has become an affordable consumer reality, with applications ranging from entertainment to productivity. However, the limited physical space available for room-scale VR in the typical home or office environment poses a significant problem. To solve this, physical spaces can be extended by amplifying the mapping of physical to virtual movement (translational gain). Although amplified movement has been used since the earliest days of VR, little is known about how it influences reach-based interactions with virtual objects, now a standard feature of consumer VR. Consequently, this paper explores the picking and placing of virtual objects in VR for the first time, with translational gains of between 1x (a one-to-one mapping of a 3.5m*3.5m virtual space to the same sized physical space) and 3x (10.5m*10.5m virtual mapped to 3.5m*3.5m physical). Results show that reaching accuracy is maintained for up to 2x gain, however going beyond this diminishes accuracy and increases simulator sickness and perceived workload. We suggest gain levels of 1.5x to 1.75x can be utilized without compromising the usability of a VR task, significantly expanding the bounds of interactive room-scale VR.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {amplified movement, redirected walking, virtual reality, translational gain, object manipulation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173674,
author = {Emmerich, Katharina and Masuch, Maic},
title = {Watch Me Play: Does Social Facilitation Apply to Digital Games?},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173674},
doi = {10.1145/3173574.3173674},
abstract = {The presence of observers and virtual characters can significantly shape our gaming experience. Researchers suppose that most of the basic socio-psychological phenomena are also applicable for digital games. However, the social processes in gaming setups can differ from our experience in other social situations. Our work emphasizes that awareness. Insights are needed for the purposeful design of a game's social setting, specifically in applied contexts of learning and training. Here, we focus on the social facilitation effect, which describes an unconscious change in performance due to the presence of others, by investigating the impact of real observers and virtual agents on player experience and performance in four different games. The results of our four studies show that, in contrast to previous assumptions, in-game success was not significantly influenced by the presence of any social entity, indicating that social facilitation does not generally apply to the context of playing digital games.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual agent, social presence, player experience, digital games, performance, observer, social facilitation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173675,
author = {Tu, Pei-Yun and Yuan, Chien Wen (Tina) and Wang, Hao-Chuan},
title = {Do You Think What I Think: Perceptions of Delayed Instant Messages in Computer-Mediated Communication of Romantic Relations},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173675},
doi = {10.1145/3173574.3173675},
abstract = {In romantic relationships, Instant Messaging (IM) can serve as a communication channel to maintain a sense of mutual presence and relational closeness when being physically separated. However, IM is asynchronous by design. There can exist time delay for people to receive and reply to incoming messages, which may violate romantic partner's mutual expectation. Limited understanding is available around how unintended and intended delays affect the relationship of romantic partners. This work examines how romantic partners grow, perceive, and use mutual knowledge about each other in delayed IM to resolve the expectancy violation. We conducted a 7-day diary study on 16 pairs of romantic couples and used the diary entries as probes for post-study one-on-one interviews. Our findings show that couples employ different strategies of information grounding to parse and resolve delayed IM. Based on these findings, we propose several theoretical and practical implications.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {instant messaging, common ground, relational communication, delayed communication, romantic relationship, expectancy violations theory, computer-mediated communication, grounding},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173676,
author = {Sharmin, Moushumi and Hossain, Md Monsur and Saha, Abir and Das, Maitraye and Maxwell, Margot and Ahmed, Shameem},
title = {From Research to Practice: Informing the Design of Autism Support Smart Technology},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173676},
abstract = {Smart technologies (wearable and mobile devices) show tremendous potential in the detection, diagnosis, and management of Autism Spectrum Disorder (ASD) by enabling continuous real-time data collection, identifying effective treatment strategies, and supporting intervention design and delivery. Though promising, effective utilization of smart technology in aiding ASD is still limited. We propose a set of implications to guide the design of ASD-support technology by analyzing 149 peer-reviewed articles focused on children with autism from ACM Digital Library, IEEE Xplore, and PubMed. Our analysis reveals that technology should facilitate real-time detection and identification of points-of-interest, adapt its behavior driven by the real-time affective state of the user, utilize familiar and unfamiliar features depending on user-context, and aid in revealing even minuscule progress made by children with autism. Our findings indicate that such technology should strive to blend-in with everyday objects. Moreover, gradual exposure and desensitization may facilitate successful adaptation of novel technology.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3173574.3173677,
author = {Rader, Emilee and Cotter, Kelley and Cho, Janghee},
title = {Explanations as Mechanisms for Supporting Algorithmic Transparency},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173677},
abstract = {Transparency can empower users to make informed choices about how they use an algorithmic decision-making system and judge its potential consequences. However, transparency is often conceptualized by the outcomes it is intended to bring about, not the specifics of mechanisms to achieve those outcomes. We conducted an online experiment focusing on how different ways of explaining Facebook's News Feed algorithm might affect participants' beliefs and judgments about the News Feed. We found that all explanations caused participants to become more aware of how the system works, and helped them to determine whether the system is biased and if they can control what they see. The explanations were less effective for helping participants evaluate the correctness of the system's output, and form opinions about how sensible and consistent its behavior is. We present implications for the design of transparency mechanisms in algorithmic decision-making systems based on these results.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173678,
author = {Odom, William and Duel, Tijs},
title = {On the Design of OLO Radio: Investigating Metadata as a Design Material},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173678},
doi = {10.1145/3173574.3173678},
abstract = {With the massive adoption of music streaming services globally, metadata is being generated that captures people's music listening histories in more precise detail than ever before. These metadata archives offer a valuable and overlooked resource for designing new ways of supporting people in experiencing the music they have listened to over the course of their lives. Yet, little research has demonstrated how metadata can be applied as a material in design practice. We describe the design of OLO Radio, a device that leverages music listening history metadata to support experiences of exploring and living with music from one's past. We unpack and reflect on design choices that made use of the exacting precision captured in listening history metadata archives to support relatively imprecise qualities of feedback and interaction to encourage rich, open-ended experiences of contemplation, curiosity, and enjoyment over time. We conclude with implications for HCI research and practice in this space.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {temporality, research through design, metadata, interaction design, digital music},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173679,
author = {Starbird, Kate and Dailey, Dharma and Mohamed, Owla and Lee, Gina and Spiro, Emma S.},
title = {Engage Early, Correct More: How Journalists Participate in False Rumors Online during Crisis Events},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173679},
doi = {10.1145/3173574.3173679},
abstract = {Journalists are struggling to adapt to new conditions of news production and simultaneously encountering criticism for their role in spreading misinformation. Against the backdrop of this "crisis in journalism", this research seeks to understand how journalists are actually participating in the spread and correction of online rumors. We compare the engagement behaviors of journalists to non-journalists- and specifically other high visibility users-within five false rumors that spread on Twitter during three crisis events. Our findings show journalists engaging earlier than non-journalists in the spread and the correction of false rumors. However, compared to other users, journalists are (proportionally) more likely to deny false rumors. Journalists are also more likely to author original tweets and to be retweeted-underscoring their continued role in shaping the news. Interestingly, journalists scored high on "power user" measures, but were distinct from other power users in significant ways-e.g. by being more likely to deny rumors.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {news production, rumoring, journalism, twitter, rumor, social media},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173680,
author = {Br\"{u}hlmann, Florian and Vollenwyder, Beat and Opwis, Klaus and Mekler, Elisa D.},
title = {Measuring the “Why” of Interaction: Development and Validation of the User Motivation Inventory (UMI)},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173680},
doi = {10.1145/3173574.3173680},
abstract = {Motivation is a fundamental concept in understanding people's experiences and behavior. Yet, motivation to engage with an interactive system has received only limited attention in HCI. We report the development and validation of the User Motivation Inventory (UMI). The UMI is an 18-item multidimensional measure of motivation, rooted in self-determination theory (SDT). It is designed to measure intrinsic motivation, integrated, identified, introjected, and external regulation, as well as amotivation. Results of two studies (total N = 941) confirm the six-factor structure of the UMI with high reliability, as well as convergent and discriminant validity of each subscale. Relationships with core concepts such as need satisfaction, vitality, and usability were studied. Additionally, the UMI was found to detect differences in motivation for people who consider abandoning a technology compared to those who do not question their use. The central role of motivation in users' behavior and experience is discussed.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {scale development, technology use, user experience, motivation, usability, self-determination theory},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173681,
author = {Speicher, Maximilian and Nebeling, Michael},
title = {GestureWiz: A Human-Powered Gesture Design Environment for User Interface Prototypes},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173681},
doi = {10.1145/3173574.3173681},
abstract = {Designers and researchers often rely on simple gesture recognizers like Wobbrock et al.'s $1 for rapid user interface prototypes. However, most existing recognizers are limited to a particular input modality and/or pre-trained set of gestures, and cannot be easily combined with other recognizers. In particular, creating prototypes that employ advanced touch and mid-air gestures still requires significant technical experience and programming skill. Inspired by $1's easy, cheap, and flexible design, we present the GestureWiz prototyping environment that provides designers with an integrated solution for gesture definition, conflict checking, and real-time recognition by employing human recognizers in a Wizard of Oz manner. We present a series of experiments with designers and crowds to show that GestureWiz can perform with reasonable accuracy and latency. We demonstrate advantages of GestureWiz when recreating gesture-based interfaces from the literature and conducting a study with 12 interaction designers that prototyped a multimodal interface with support for a wide range of novel gestures in about 45 minutes.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {wizard of oz, gesture-based interfaces, rapid prototyping, crowdsourcing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173682,
author = {Zhou, Sharon and Valentine, Melissa and Bernstein, Michael S.},
title = {In Search of the Dream Team: Temporally Constrained Multi-Armed Bandits for Identifying Effective Team Structures},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173682},
doi = {10.1145/3173574.3173682},
abstract = {Team structures---roles, norms, and interaction patterns---define how teams work. HCI researchers have theorized ideal team structures and built systems nudging teams towards them, such as those increasing turn-taking, deliberation, and knowledge distribution. However, organizational behavior research argues against the existence of universally ideal structures. Teams are diverse and excel under different structures: while one team might flourish under hierarchical leadership and a critical culture, another will flounder. In this paper, we present DreamTeam: a system that explores a large space of possible team structures to identify effective structures for each team based on observable feedback. To avoid overwhelming teams with too many changes, DreamTeam introduces multi-armed bandits with temporal constraints: an algorithm that manages the timing of exploration--exploitation trade-offs across multiple bandits simultaneously. A field experiment demonstrated that DreamTeam teams outperformed self-managing teams by 38%, manager-led teams by 46%, and teams with unconstrained bandits by 41%. This research advances computation as a powerful partner in establishing effective teamwork.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {teams, multi-armed bandits., technical social computing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173683,
author = {Gatehouse, Cally and Wood, Matthew and Briggs, Jo and Pickles, James and Lawson, Shaun},
title = {Troubling Vulnerability: Designing with LGBT Young People's Ambivalence Towards Hate Crime Reporting},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173683},
doi = {10.1145/3173574.3173683},
abstract = {HCI is increasingly working with 'vulnerable' people, yet there is a danger that the label of vulnerability can alienate and stigmatize the people such work aims to support. We report our study investigating the application of interaction design to increase rates of hate crime reporting amongst Lesbian, Gay, Bisexual and Transgender young people. During design-led workshops, participants expressed ambivalence towards reporting. While recognizing their exposure to hate crime, they simultaneously rejected being identified as victim as implied in the act of reporting. We used visual communication design to depict the young people's ambivalent identities and contribute insights into how these fail and succeed to account for the intersectional, fluid and emergent nature of LGBT identities through the design research process. We argue that by producing ambiguously designed texts alongside conventional outcomes, we 'trouble' our design research narratives as a tactic to disrupt static and reductive understandings of vulnerability within HCI.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design workshops, lgbt young people, ambiguity in design, hate crime reporting},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173684,
author = {Jones, Michael D. and Anderson, Zann and Walker, Casey and Seppi, Kevin},
title = {PHUI-Kit: Interface Layout and Fabrication on Curved 3D Printed Objects},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173684},
doi = {10.1145/3173574.3173684},
abstract = {We seek to make physical user interface (PHUI) design more like graphical user interface (GUI) design by using a drag-and drop interface to place widgets, allowing widgets to be repositioned and by hiding implementation details. PHUIs are interfaces built from tangible widgets arranged on the surfaces of physical objects. PHUI layout will become more important as we move from rectangular screens to purpose-built interactive devices. Approaches to PHUI layout based on sculpture make it difficult to reposition widgets, and software approaches do not involve placing widgets on the device exterior. We created PHUI-kit, a software approach to PHUI layout on 3D printed enclosures, which has a drag-and-drop interface, supports repositioning of widgets, and hides implementation details. We describe algorithms for placing widgets on curved surfaces, modifying the enclosure geometry, and routing wiring inside the enclosure. The tool is easy to use and supports a wide range of design possibilities.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {fabrication, internet of things, maker culture, user interface layout},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173685,
author = {Kaspar, Alexandre and Patterson, Genevieve and Kim, Changil and Aksoy, Yagiz and Matusik, Wojciech and Elgharib, Mohamed},
title = {Crowd-Guided Ensembles: How Can We Choreograph Crowd Workers for Video Segmentation?},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173685},
doi = {10.1145/3173574.3173685},
abstract = {In this work, we propose two ensemble methods leveraging a crowd workforce to improve video annotation, with a focus on video object segmentation. Their shared principle is that while individual candidate results may likely be insufficient, they often complement each other so that they can be combined into something better than any of the individual results---the very spirit of collaborative working. For one, we extend a standard polygon-drawing interface to allow workers to annotate negative space, and combine the work of multiple workers instead of relying on a single best one as commonly done in crowdsourced image segmentation. For the other, we present a method to combine multiple automatic propagation algorithms with the help of the crowd. Such combination requires an understanding of where the algorithms fail, which we gather using a novel coarse scribble video annotation task. We evaluate our ensemble methods, discuss our design choices for them, and make our web-based crowdsourcing tools and results publicly available.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {keyframe segmentation, segmentation propagation, crowdsourcing, video object segmentation, ensemble methods},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173686,
author = {Petrelli, Daniela and O'Brien, Sinead},
title = {Phone vs. Tangible in Museums: A Comparative Study},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173686},
doi = {10.1145/3173574.3173686},
abstract = {Despite years of HCI research on digital technology in museums, it is still unclear how different interactions impact on visitors'. A comparative evaluation of smart replicas, phone app and smart cards looked at the personal preferences, behavioural change, and the appeal of mobiles in museums. 76 participants used all three interaction modes and gave their opinions in a questionnaire; participants interaction was also observed. The results show the phone is the most disliked interaction mode while tangible interaction (smart card and replica combined) is the most liked. Preference for the phone favour mobility to the detriment of engagement with the exhibition. Different behaviours when interacting with the phone or the tangibles where observed. The personal visiting style appeared to be only marginally affected by the device. Visitors also expect museums to provide the phones against the current trend of developing apps in a "bring your own device" approach.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {comparison, mobile phone, museum, tangible interaction},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173687,
author = {Wang, Junxiang and Yin, Jianwei and Deng, Shuiguang and Li, Ying and Pu, Calton and Tang, Yan and Luo, Zhiling},
title = {Evaluating User Satisfaction with Typography Designs via Mining Touch Interaction Data in Mobile Reading},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173687},
doi = {10.1145/3173574.3173687},
abstract = {Previous work has demonstrated that typography design has a great influence on users' reading experience. However, current typography design guidelines are mainly for general purpose, while the individual needs are nearly ignored. To achieve personalized typography designs, an important and necessary step is accurately evaluating user satisfaction with the typography designs. Current evaluation approaches, e.g., asking for users' opinions directly, however, interrupt the reading and affect users' judgments. In this paper, we propose a novel method to address this challenge by mining users' implicit feedbacks, e.g., touch interaction data. We conduct two mobile reading studies in Chinese to collect the touch interaction data from 91 participants. We propose various features based on our three hypotheses to capture meaningful patterns in the touch behaviors. The experiment results show the effectiveness of our evaluation models with higher accuracy on comparing with the baseline under three text difficulty levels, respectively.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {implicit feedback, mobile reading, user satisfaction, typography design, text difficulty, touch interaction data},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173688,
author = {Guberek, Tamy and McDonald, Allison and Simioni, Sylvia and Mhaidli, Abraham H. and Toyama, Kentaro and Schaub, Florian},
title = {Keeping a Low Profile? Technology, Risk and Privacy among Undocumented Immigrants},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173688},
abstract = {Undocumented immigrants in the United States face risks of discrimination, surveillance, and deportation. We investigate their technology use, risk perceptions, and protective strategies relating to their vulnerability. Through semi-structured interviews with Latinx undocumented immigrants, we find that while participants act to address offline threats, this vigilance does not translate to their online activities. Their technology use is shaped by needs and benefits rather than risk perceptions. While our participants are concerned about identity theft and privacy generally, and some raise concerns about online harassment, their understanding of government surveillance risks is vague and met with resignation. We identify tensions among self-expression, group privacy, and self-censorship related to their immigration status, as well as strong trust in service providers. Our findings have implications for digital literacy education, privacy and security interfaces, and technology design in general. Even minor design decisions can substantially affect exposure risks and well-being for such vulnerable communities.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inproceedings{10.1145/3173574.3173689,
author = {Bornschein, Jens and Bornschein, Denise and Weber, Gerhard},
title = {Comparing Computer-Based Drawing Methods for Blind People with Real-Time Tactile Feedback},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173689},
doi = {10.1145/3173574.3173689},
abstract = {In this paper, we present a drawing workstation for blind people using a two-dimensional tactile pin-matrix display for in- and output. Four different input modalities, namely menu-based, gesture-based, freehand-stylus and a Time-of-Flight (ToF) depth segmentation of real-world object silhouettes, are utilized to create graphical shapes. Users can freely manipulate shapes after creation. Twelve blind users evaluated and compared the four image creation modalities. During evaluation, participants had to copy four different images. The results show that all modalities are highly appropriate for non-visual drawing tasks. There is no generally preferred drawing modality, but most participants rated the robust and well-known menu-based interaction as very good. Furthermore, menu was second in performance and the most accurate drawing modality. Our evaluation demonstrated direct manipulation works well for blind users at the position of the reading hand. In general, our drawing tool allows blind users to create appealing images.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tactile drawing, drawing by blind people, two-dimensional pin-matrix device, tactile graphics, evaluation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173690,
author = {Zhao, Yuhang and Bennett, Cynthia L. and Benko, Hrvoje and Cutrell, Edward and Holz, Christian and Morris, Meredith Ringel and Sinclair, Mike},
title = {Enabling People with Visual Impairments to Navigate Virtual Reality with a Haptic and Auditory Cane Simulation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173690},
doi = {10.1145/3173574.3173690},
abstract = {Traditional virtual reality (VR) mainly focuses on visual feedback, which is not accessible for people with visual impairments. We created Canetroller, a haptic cane controller that simulates white cane interactions, enabling people with visual impairments to navigate a virtual environment by transferring their cane skills into the virtual world. Canetroller provides three types of feedback: (1) physical resistance generated by a wearable programmable brake mechanism that physically impedes the controller when the virtual cane comes in contact with a virtual object; (2) vibrotactile feedback that simulates the vibrations when a cane hits an object or touches and drags across various surfaces; and (3) spatial 3D auditory feedback simulating the sound of real-world cane interactions. We designed indoor and outdoor VR scenes to evaluate the effectiveness of our controller. Our study showed that Canetroller was a promising tool that enabled visually impaired participants to navigate different virtual spaces. We discuss potential applications supported by Canetroller ranging from entertainment to mobility training.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {white cane, auditory feedback, blindness, haptic feedback, virtual reality, mobility, visual impairments},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173691,
author = {Zhang, Yang and Harrison, Chris},
title = {Pulp Nonfiction: Low-Cost Touch Tracking for Paper},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173691},
doi = {10.1145/3173574.3173691},
abstract = {Paper continues to be a versatile and indispensable material in the 21st century. Of course, paper is a passive medium with no inherent interactivity, precluding us from computationally-enhancing a wide variety of paper-based activities. In this work, we present a new technical approach for bringing the digital and paper worlds closer together, by enabling paper to track finger input and also drawn input with writing implements. Importantly, for paper to still be considered paper, our method had to be very low cost. This necessitated research into materials, fabrication methods and sensing techniques. We describe the outcome of our investigations and show that our method can be sufficiently low-cost and accurate to enable new interactive opportunities with this pervasive and venerable material.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {input, touch tracking, paper, interaction techniques, pen tracking, multi-touch, electric field tomography},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173692,
author = {Lindley, Si\^{a}n E. and Smyth, Gavin and Corish, Robert and Loukianov, Anastasia and Golembewski, Michael and Luger, Ewa A. and Sellen, Abigail},
title = {Exploring New Metaphors for a Networked World through the File Biography},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173692},
doi = {10.1145/3173574.3173692},
abstract = {We present a body of work undertaken in response to the challenge outlined by Harper et al. in their paper, ?'What is a File?' [9]. Through a conceptual and design-led exploration of new file metaphors, we developed the 'file biography', a digital entity that encompasses the provenance of a file and allows the user to keep track of how it propagates. We explored this through prototyping and utilised it in two user studies. In the studies, we (i) asked people to sketch out file biographies for their own content, and (ii) deployed a tool enabling users to build their own simple file biographies across multiple versions of Word documents. We conclude that new file metaphors may need to play different roles for different types of digital content, with a distinction being drawn between content that is 'in production' and virtual possessions that are, in a sense, a 'finished' artefact.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {patina, propagation, control, provenance, fork, version control, grammar of action, virtual possession, ownership},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173693,
author = {Wu, Alan Yusheng and Munteanu, Cosmin},
title = {Understanding Older Users' Acceptance of Wearable Interfaces for Sensor-Based Fall Risk Assessment},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173693},
abstract = {Algorithms processing data from wearable sensors promise to more accurately predict risks of falling -- a significant concern for older adults. Substantial engineering work is dedicated to increasing the prediction accuracy of these algorithms; yet fewer efforts are dedicated to better engaging users through interactive visualizations in decision-making using these data. We present an investigation of the acceptance of a sensor-based fall risk assessment wearable device. A participatory design was employed to develop a mobile interface providing visualizations of sensor data and algorithmic assessments of fall risks. We then investigated the acceptance of this interface and its potential to motivate behavioural changes through a field deployment, which suggested that the interface and its belt-mounted wearable sensors are perceived as usable. We also found that providing contextual information for fall risk estimation combined with relevant practical fall prevention instructions may facilitate the acceptance of such technologies, potentially leading to behaviour change.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173694,
author = {DeVito, Michael A. and Birnholtz, Jeremy and Hancock, Jeffery T. and French, Megan and Liu, Sunny},
title = {How People Form Folk Theories of Social Media Feeds and What It Means for How We Study Self-Presentation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173694},
doi = {10.1145/3173574.3173694},
abstract = {Self-presentation is a process that is significantly complicated by the rise of algorithmic social media feeds, which obscure information about one's audience and environment. User understandings of these systems, and therefore user ability to adapt to them, are limited, and have recently been explored through the lens of folk theories. To date, little is understood of how these theories are formed, and how they tie to the self-presentation process in social media. This paper presents an exploratory look at the folk theory formation process and the interplay between folk theories and self-presentation via a 28-participant interview study. Results suggest that people draw from diverse sources of information when forming folk theories, and that folk theories are more complex, multifaceted and malleable than previously assumed. This highlights the need to integrate folk theories into both social media systems and theories of self-presentation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user understandings, algorithm awareness, folk theories, theory formation, algorithms, social media, algorithmic curation, social feeds, grounded theory},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173695,
author = {Gilon, Karni and Chan, Joel and Ng, Felicia Y. and Liifshitz-Assaf, Hila and Kittur, Aniket and Shahaf, Dafna},
title = {Analogy Mining for Specific Design Needs},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173695},
doi = {10.1145/3173574.3173695},
abstract = {Finding analogical inspirations in distant domains is a powerful way of solving problems. However, as the number of inspirations that could be matched and the dimensions on which that matching could occur grow, it becomes challenging for designers to find inspirations relevant to their needs. Furthermore, designers are often interested in exploring specific aspects of a product-- for example, one designer might be interested in improving the brewing capability of an outdoor coffee maker, while another might wish to optimize for portability. In this paper we introduce a novel system for targeting analogical search for specific needs. Specifically, we contribute an analogical search engine for expressing and abstracting specific design needs that returns more distant yet relevant inspirations than alternate approaches.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {focus, inspiration, text embedding, creativity, innovation, product dimensions, computational analogy, abstraction},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173696,
author = {Chancellor, Stevie and Counts, Scott},
title = {Measuring Employment Demand Using Internet Search Data},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173696},
doi = {10.1145/3173574.3173696},
abstract = {We are in a transitional economic period emphasizing automation of physical jobs and the shift towards intellectual labor. How can we measure and understand human behaviors of job search, and how communities are adapting to these changes? We use internet search data to estimate employment demand in the United States. Starting with 225 million raw job search queries in 2015 and 2016 from a popular search engine, we classify queries into one of 15 fields of employment with accuracy and F-1 of 97%, and use the resulting query volumes to estimate per-sector employment demand in U.S. counties. We validate against Bureau of Labor Statistics measures, and then demonstrate benefits for communities, showing significant differences in the types of jobs searched for across socio-economic dimensions like poverty and education level. We discuss implications for macroeconomic measurement, as well as how community leaders, policy makers, and the field of HCI can benefit.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {employment, internet search, big data, job search},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173697,
author = {Liu, Zhicheng and Thompson, John and Wilson, Alan and Dontcheva, Mira and Delorey, James and Grigg, Sam and Kerr, Bernard and Stasko, John},
title = {Data Illustrator: Augmenting Vector Design Tools with Lazy Data Binding for Expressive Visualization Authoring},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173697},
doi = {10.1145/3173574.3173697},
abstract = {Building graphical user interfaces for visualization authoring is challenging as one must reconcile the tension between flexible graphics manipulation and procedural visualization generation based on a graphical grammar or declarative languages. To better support designers' workflows and practices, we propose Data Illustrator, a novel visualization framework. In our approach, all visualizations are initially vector graphics; data binding is applied when necessary and only constrains interactive manipulation to that data bound property. The framework augments graphic design tools with new concepts and operators, and describes the structure and generation of a variety of visualizations. Based on the framework, we design and implement a visualization authoring system. The system extends interaction techniques in modern vector design tools for direct manipulation of visualization configurations and parameters. We demonstrate the expressive power of our approach through a variety of examples. A qualitative study shows that designers can use our framework to compose visualizations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {systems, graphic design, interaction techniques, data visualization, framework, authoring},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173698,
author = {Ghosh, Arup Kumar and Badillo-Urquiola, Karla and Guha, Shion and LaViola Jr, Joseph J. and Wisniewski, Pamela J.},
title = {Safety vs. Surveillance: What Children Have to Say about Mobile Apps for Parental Control},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173698},
doi = {10.1145/3173574.3173698},
abstract = {Mobile applications ("apps") developed to promote online safety for children are underutilized and rely heavily on parental control features that monitor and restrict their child's mobile activities. This asymmetry in parental surveillance initiates an interesting research question -- how do children themselves feel about such parental control apps? We conducted a qualitative analysis of 736 reviews of 37 mobile online safety apps from Google Play that were publicly posted and written by children (ages 8-19). Our results indicate that child ratings were significantly lower than that of parents with 76% of the child reviews giving apps a single star. Children felt that the apps were overly restrictive and invasive of their personal privacy, negatively impacting their relationships with their parents. We relate these findings with HCI literature on mobile online safety, including broader literature around privacy and surveillance, and outline design opportunities for online safety apps.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {adolescents, parental control apps, mobile online safety},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173699,
author = {Kuijer, Lenneke and Giaccardi, Elisa},
title = {Co-Performance: Conceptualizing the Role of Artificial Agency in the Design of Everyday Life},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173699},
doi = {10.1145/3173574.3173699},
abstract = {This paper introduces the notion of co-performance, with the aim to offer Human-Computer Interaction (HCI) researchers and practitioners a new perspective on the role of artificial agency in everyday life, from automated systems to autonomous devices. In contrast to 'smartness,' which focuses on a supposed autonomy of artifacts, co-performance considers artifacts as capable of learning and performing next to people. This shifts the locus of design from matters of distributions of agency at design time, to matters of embodied learning in everyday practice for both human and artificial performers. From this perspective, co-performance acknowledges the dynamic differences in capabilities between humans and artifacts, and highlights the fundamentally recursive relation between professional design and use. Implications for HCI design practice are unpacked through reflections on smart thermostat design in light of historic changes in roles between humans and heating systems, and changing ideas of appropriateness in everyday practices of domestic heating.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {autonomous devices, artificial agency, theories of practice, co-performance, smart thermostats, theoretic foundations},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173700,
author = {Kizilcec, Ren\'{e} F. and Bakshy, Eytan and Eckles, Dean and Burke, Moira},
title = {Social Influence and Reciprocity in Online Gift Giving},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173700},
doi = {10.1145/3173574.3173700},
abstract = {Giving gifts is a fundamental part of human relationships that is being affected by technology. The Internet enables people to give at the last minute and over long distances, and to observe friends giving and receiving gifts. How online gift giving spreads in social networks is therefore important to understand. We examine 1.5 million gift exchanges on Facebook and show that receiving a gift causes individuals to be 56% more likely to give a gift in the future. Additional surveys show that online gift giving was more socially acceptable to those who learned about it by observing friends' participation instead of a non-social encouragement. Most receivers pay the gift forward instead of reciprocating directly online, although surveys revealed additional instances of direct reciprocity, where the initial gifting occurred offline. Thus, social influence promotes the spread of online gifting, which both complements and substitutes for offline gifting.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {quasi-experiment, reciprocity, cooperation, peer effects, online gifts, facebook, social networks, social learning},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173701,
author = {Luo, Yuhan and Lee, Bongshin and Wohn, Donghee Yvette and Rebar, Amanda L. and Conroy, David E. and Choe, Eun Kyoung},
title = {Time for Break: Understanding Information Workers' Sedentary Behavior Through a Break Prompting System},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173701},
abstract = {Extended periods of uninterrupted sedentary behavior are detrimental to long-term health. While prolonged sitting is prevalent among information workers, it is difficult for them to break prolonged sedentary behavior due to the nature of their work. This work aims to understand information workers' intentions &amp; practices around standing or moving breaks. We developed Time for Break, a break prompting system that enables people to set their desired work duration and prompts them to stand up or move. We conducted an exploratory field study (N = 25) with Time for Break to collect participants' work &amp; break intentions and behaviors for three weeks, followed by semi-structured interviews. We examined rich contexts affecting participants' receptiveness to standing or moving breaks, and identified how their habit strength and self-regulation are related to their break-taking intentions &amp; practices. We discuss design implications for interventions to break up periods of prolonged sedentary behavior in workplaces.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.1145/3173574.3173702,
author = {Rietzler, Michael and Geiselhart, Florian and Gugenheimer, Jan and Rukzio, Enrico},
title = {Breaking the Tracking: Enabling Weight Perception Using Perceivable Tracking Offsets},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173702},
doi = {10.1145/3173574.3173702},
abstract = {Virtual reality (VR) technology strives to enable a highly immersive experience for the user by including a wide variety of modalities (e.g. visuals, haptics). Current VR hardware however lacks a sufficient way of communicating the perception of weight of an object, resulting in scenarios where users can not distinguish between lifting a bowling ball or a feather. We propose a solely software based approach of simulating weight in VR by deliberately using perceivable tracking offsets. These tracking offsets nudge users to lift their arm higher and result in a visual and haptic perception of weight. We conducted two user studies showing that participants intuitively associated them with the sensation of weight and accept them as part of the virtual world. We further show that compared to no weight simulation, our approach led to significantly higher levels of presence, immersion and enjoyment. Finally, we report perceptional thresholds and offset boundaries as design guidelines for practitioners.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pseudo haptics, virtual reality, weight perception},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173703,
author = {Lindlbauer, David and Wilson, Andy D.},
title = {Remixed Reality: Manipulating Space and Time in Augmented Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173703},
doi = {10.1145/3173574.3173703},
abstract = {We present Remixed Reality, a novel form of mixed reality. In contrast to classical mixed reality approaches where users see a direct view or video feed of their environment, with Remixed Reality they see a live 3D reconstruction, gathered from multiple external depth cameras. This approach enables changing the environment as easily as geometry can be changed in virtual reality, while allowing users to view and interact with the actual physical world as they would in augmented reality. We characterize a taxonomy of manipulations that are possible with Remixed Reality: spatial changes such as erasing objects; appearance changes such as changing textures; temporal changes such as pausing time; and viewpoint changes that allow users to see the world from different points without changing their physical location. We contribute a method that uses an underlying voxel grid holding information like visibility and transformations, which is applied to live geometry in real time.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, remixed reality, augmented reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173704,
author = {Yang, Qian and Banovic, Nikola and Zimmerman, John},
title = {Mapping Machine Learning Advances from HCI Research to Reveal Starting Places for Design Innovation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173704},
abstract = {HCI has become particularly interested in using machine learning (ML) to improve user experience (UX). However, some design researchers claim that there is a lack of design innovation in envisioning how ML might improve UX. We investigate this claim by analyzing 2,494 related HCI research publications. Our review confirmed a lack of research integrating UX and ML. To help span this gap, we mined our corpus to generate a topic landscape, mapping out 7 clusters of ML technical capabilities within HCI. Among them, we identified 3 under-explored clusters that design researchers can dig in and create sensitizing concepts for. To help operationalize these technical design materials, our analysis then identified value channels through which the technical capabilities can provide value for users: self, context, optimal, and utility-capability. The clusters and the value channels collectively mark starting places for envisioning new ways for ML technology to improve people's lives.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inproceedings{10.1145/3173574.3173705,
author = {Schrapel, Maximilian and Stadler, Max-Ludwig and Rohs, Michael},
title = {Pentelligence: Combining Pen Tip Motion and Writing Sounds for Handwritten Digit Recognition},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173705},
doi = {10.1145/3173574.3173705},
abstract = {Digital pens emit ink on paper and digitize handwriting. The range of the pen is typically limited to a special writing surface on which the pen's tip is tracked. We present Pentelligence, a pen for handwritten digit recognition that operates on regular paper and does not require a separate tracking device. It senses the pen tip's motions and sound emissions when stroking. Pen motions and writing sounds exhibit complementary properties. Combining both types of sensor data substantially improves the recognition rate. Hilbert envelopes of the writing sounds and mean-filtered motion data are fed to neural networks for majority voting. The results on a dataset of 9408 handwritten digits taken from 26 individuals show that motion+sound outperforms single-sensor approaches at an accuracy of 78.4% for 10 test users. Retraining the networks for a single writer on a dataset of 2120 samples increased the precision to 100% for single handwritten digits at an overall accuracy of 98.3%.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {digit recognition, neural networks, writing motion, sound emissions, digital pens, writing sound, handwriting recognition},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173706,
author = {Shim, Youngbo Aram and Lee, Jaeyeon and Lee, Geehyuk},
title = {Exploring Multimodal Watch-Back Tactile Display Using Wind and Vibration},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173706},
doi = {10.1145/3173574.3173706},
abstract = {A tactile display on the back of a smartwatch is an attractive output option; however, its channel capacity is limited owing to the small contact area. In order to expand the channel capacity, we considered using two perceptually distinct types of stimuli, wind and vibration, together on the same skin area. The result is a multimodal tactile display that combines wind and vibration to create "colored" tactile sensations on the wrist. As a first step toward this goal, we conducted in this study four user experiments with a wind-vibration tactile display to examine different ways of combining wind and vibration: Individual, Sequential, and Simultaneous. The results revealed the sequential combination of wind and vibration to exhibit the highest potential, with an information transfer capacity of 3.29 bits. In particular, the transition of tactile modality was perceived at an accuracy of 98.52%. The current results confirm the feasibility and potential of a multimodal tactile display combining wind and vibration.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {vibrotactile display, watch-back tactile display, multimodal tactile display, airflow display, wearable tactile display},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173707,
author = {Weld, Galen and Perrier, Trevor and Aker, Jenny and Blumenstock, Joshua E. and Dillon, Brian and Kamanzi, Adalbertus and Kokushubira, Editha and Webster, Jennifer and Anderson, Richard J.},
title = {EKichabi: Information Access through Basic Mobile Phones in Rural Tanzania},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173707},
abstract = {This paper presents eKichabi, a tool for retrieving contact information for agriculture-related enterprises in Tanzania. eKichabi is an Unstructured Supplementary Service Data (USSD) application which users can access through basic mobile phones. We describe our focus groups, a design iteration, deployment in four villages, and follow up interviews by phone. This work demonstrates the feasibility of USSD for information access applications that have the potential for deployment on a large scale in the developing world. From user interviews, we identified strong evidence of eKichabi fulfilling an unmet need for business related information, both in identifying business contacts in other villages, as well locating specific service providers. One of our key findings demonstrates that users access information through multiple modes, including text search, in addition to menu navigation organized by both business sector category and geographic area.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3173708,
author = {Kim, Jennifer G. and Hong, Hwajung and Karahalios, Karrie},
title = {Understanding Identity Presentation in Medical Crowdfunding},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173708},
abstract = {People desire to present themselves favorably to others. However, medical crowdfunding beneficiaries are often expected to present their dire medical conditions and financial straits to solicit financial support. To investigate how beneficiaries convey their situation on medical crowdfunding pages and how contributors perceive the presented information, we interviewed both medical crowdfunding beneficiaries and contributors. While beneficiaries emphasized the serious of their medical situations to signal their deservedness of support, contributor participants gave less attention to that content. Rather, they focused on their impression of the beneficiary's character formed by various features of contributions such as the contributor's names, messages, and shared pictures. These contribution features further signaled common connections between the beneficiary and contributors and each contributor's unique involvement in the beneficiary's medical journey. However, the contribution amount resulted in judgement about other contributors. We suggest design opportunities and challenges that apply these results to the design of medical crowdfunding interfaces.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3173709,
author = {M\"{a}kel\"{a}, Ville and Khamis, Mohamed and Mecke, Lukas and James, Jobin and Turunen, Markku and Alt, Florian},
title = {Pocket Transfers: Interaction Techniques for Transferring Content from Situated Displays to Mobile Devices},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173709},
abstract = {We present Pocket Transfers: interaction techniques that allow users to transfer content from situated displays to a personal mobile device while keeping the device in a pocket or bag. Existing content transfer solutions require direct manipulation of the mobile device, making inter-action slower and less flexible. Our introduced tech-niques employ touch, mid-air gestures, gaze, and a mul-timodal combination of gaze and mid-air gestures. We evaluated the techniques in a novel user study (N=20), where we considered dynamic scenarios where the user approaches the display, completes the task, and leaves. We show that all pocket transfer techniques are fast and seen as highly convenient. Mid-air gestures are the most efficient touchless method for transferring a single item, while the multimodal method is the fastest touchless method when multiple items are transferred. We provide guidelines to help researchers and practitioners choose the most suitable content transfer techniques for their systems.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173710,
author = {Bowyer, Alex and Montague, Kyle and Wheater, Stuart and McGovern, Ruth and Lingam, Raghu and Balaam, Madeline},
title = {Understanding the Family Perspective on the Storage, Sharing and Handling of Family Civic Data},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173710},
doi = {10.1145/3173574.3173710},
abstract = {Across social care, healthcare and public policy, enabled by the "big data" revolution (which has normalized large-scale data-based decision-making), there are moves to "join up" citizen databases to provide care workers with holistic views of families they support. In this context, questions of personal data privacy, security, access, control and (dis-)empowerment are critical considerations for system designers and policy makers alike. To explore the family perspective on this landscape of what we call Family Civic Data, we carried out ethnographic interviews with four North-East families. Our design-game-based interviews were effective for engaging both adults and children to talk about the impact of this dry, technical topic on their lives. Our findings, delivered in the form of design guidelines, show support for dynamic consent: families would feel most empowered if involved in an ongoing co-operative relationship with state welfare and civic authorities through shared interaction with their data.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design games, ethnographic interviews, ubicomp, boundary objects, big data, dynamic consent, family design games, data privacy, data sharing, healthcare, social care, civic data, data security, user-centered design, family, personal data, family research},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173711,
author = {Feng, Mi and Deng, Cheng and Peck, Evan M. and Harrison, Lane},
title = {The Effects of Adding Search Functionality to Interactive Visualizations on the Web},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173711},
doi = {10.1145/3173574.3173711},
abstract = {The widespread use of text-based search in user interfaces has led designers in visualization to occasionally add search functionality to their creations. Yet it remains unclear how search may impact a person's behavior. Given the unstructured context of the web, users may not have explicit information-seeking goals and designers cannot make assumptions about user attention. To bridge this gap, we observed the impact of integrating search with five visualizations across 830 online participants. In an unguided task, we find that (1) the presence of text-based search influences people's information-seeking goals, (2) search can alter the data that people explore and how they engage with it, and (3) the effects of search are amplified in visualizations where people are familiar with the underlying dataset. These results suggest that text-search in web visualizations drives users towards more diverse information seeking goals, and may be valuable in a range of existing visualization designs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visualization, evaluation, interaction, search},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173712,
author = {Conlen, Matthew and Stalla, Sara and Jin, Chelly and Hendrie, Maggie and Mushkin, Hillary and Lombeyda, Santiago and Davidoff, Scott},
title = {Towards Design Principles for Visual Analytics in Operations Contexts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173712},
doi = {10.1145/3173574.3173712},
abstract = {Operations engineering teams interact with complex data systems to make technical decisions that ensure the operational efficacy of their missions. To support these decision-making tasks, which may require elastic prioritization of goals dependent on changing conditions, custom analytics tools are often developed. We were asked to develop such a tool by a team at the NASA Jet Propulsion Laboratory, where rover telecom operators make decisions based on models predicting how much data rovers can transfer from the surface of Mars. Through research, design, implementation, and informal evaluation of our new tool, we developed principles to inform the design of visual analytics systems in operations contexts. We offer these principles as a step towards understanding the complex task of designing these systems. The principles we present are applicable to designers and developers tasked with building analytics systems in domains that face complex operations challenges such as scheduling, routing, and logistics.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {theory, visual design, visualization, design principles, design research methods, contextual inquiry, information seeking &amp; search, operations, qualitative methods},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173713,
author = {Gruning, Jane},
title = {Displaying Invisible Objects: Why People Rarely Re-Read E-Books},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173713},
doi = {10.1145/3173574.3173713},
abstract = {This study of paper and e-books investigates how specific affordances of physical and digital objects relate to people's valuations and uses of those objects over time. We found that while the visibility of paper books amplified the meaningfulness of organizational and display actions taken with regards to those objects, the systems that supported interactions with e-books instead tended to make such actions less meaningful. We argue that these systems also discouraged re-uses of e-books for most participants -- the important exceptions being several participants who used the book-focused social networking site Goodreads. This paper details how the affordances and limitations that resulted from the material constructions of paper and e-books impacted participants' uses of and feelings towards those objects, and examines the implications of using a supplementary online system for displaying digital objects.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {digital objects, display, e-books, e-readers, goodreads, kindle, ownership, books, virtual possessions},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173714,
author = {Dillman, Kody R. and Mok, Terrance Tin Hoi and Tang, Anthony and Oehlberg, Lora and Mitchell, Alex},
title = {A Visual Interaction Cue Framework from Video Game Environments for Augmented Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173714},
doi = {10.1145/3173574.3173714},
abstract = {Based on an analysis of 49 popular contemporary video games, we develop a descriptive framework of visual interaction cues in video games. These cues are used to inform players what can be interacted with, where to look, and where to go within the game world. These cues vary along three dimensions: the purpose of the cue, the visual design of the cue, and the circumstances under which the cue is shown. We demonstrate that this framework can also be used to describe interaction cues for augmented reality applications. Beyond this, we show how the framework can be used to generatively derive new design ideas for visual interaction cues in augmented reality experiences.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {game design, interaction cues, augmented reality, guidance},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173715,
author = {Cockburn, Andy and Gutwin, Carl and Dix, Alan},
title = {HARK No More: On the Preregistration of CHI Experiments},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173715},
doi = {10.1145/3173574.3173715},
abstract = {Experimental preregistration is required for publication in many scientific disciplines and venues. When experimental intentions are preregistered, reviewers and readers can be confident that experimental evidence in support of reported hypotheses is not the result of HARKing, which stands for Hypothesising After the Results are Known. We review the motivation and outcomes of experimental preregistration across a variety of disciplines, as well as previous work commenting on the role of evaluation in HCI research. We then discuss how experimental preregistration could be adapted to the distinctive characteristics of Human-Computer Interaction empirical research, to the betterment of the discipline.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {p-fishing, file drawer effect, experimental preregistration, replication, nhst controversy, harking},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173716,
author = {Rusn\'{a}k, V\'{\i}t and Appert, Caroline and Chapuis, Olivier and Pietriga, Emmanuel},
title = {Designing Coherent Gesture Sets for Multi-Scale Navigation on Tabletops},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173716},
abstract = {Multi-scale navigation interfaces were originally designed to enable single users to explore large visual information spaces on desktop workstations. These interfaces can also be quite useful on tabletops. However, their adaptation to co-located multi-user contexts is not straightforward. The literature describes different interfaces, that only offer a limited subset of navigation actions. In this paper, we first identify a comprehensive set of actions to effectively support multi-scale navigation. We report on a guessability study in which we elicited user-defined gestures for triggering these actions, showing that there is no natural design solution, but that users heavily rely on the now-ubiquitous slide, pinch and turn gestures. We then propose two interface designs based on this set of three basic gestures: one involves two-hand variations on these gestures, the other combines them with widgets. A comparative study suggests that users can easily learn both, and that the gesture-based, visually-minimalist design is a viable option, that saves display space for other controls.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173717,
author = {Schoop, Eldon and Smith, James and Hartmann, Bjoern},
title = {HindSight: Enhancing Spatial Awareness by Sonifying Detected Objects in Real-Time 360-Degree Video},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173717},
doi = {10.1145/3173574.3173717},
abstract = {Our perception of our surrounding environment is limited by the constraints of human biology. The field of augmented perception asks how our sensory capabilities can be usefully extended through computational means. We argue that spatial awareness can be enhanced by exploiting recent advances in computer vision which make high-accuracy, real-time object detection feasible in everyday settings. We introduce HindSight, a wearable system that increases spatial awareness by detecting relevant objects in live 360-degree video and sonifying their position and class through bone conduction headphones. HindSight uses a deep neural network to locate and attribute semantic information to objects surrounding a user through a head-worn panoramic camera. It then uses bone conduction headphones, which preserve natural auditory acuity, to transmit audio notifications for detected objects of interest. We develop an application using HindSight to warn cyclists of approaching vehicles outside their field of view and evaluate it in an exploratory study with 15 users. Participants reported increases in perceived safety and awareness of approaching vehicles when using HindSight.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {augmented perception, sonification, computer vision, 360-degree video},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173718,
author = {Fernandes, Michael and Walls, Logan and Munson, Sean and Hullman, Jessica and Kay, Matthew},
title = {Uncertainty Displays Using Quantile Dotplots or CDFs Improve Transit Decision-Making},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173718},
abstract = {Everyday predictive systems typically present point predictions, making it hard for people to account for uncertainty when making decisions. Evaluations of uncertainty displays for transit prediction have assessed people's ability to extract probabilities, but not the quality of their decisions. In a controlled, incentivized experiment, we had subjects decide when to catch a bus using displays with textual uncertainty, uncertainty visualizations, or no-uncertainty (control). Frequency-based visualizations previously shown to allow people to better extract probabilities (quantile dotplots) yielded better decisions. Decisions with quantile dotplots with 50 outcomes were(1) better on average, having expected payoffs 97% of optimal(95% CI: [95%,98%]), 5 percentage points more than control (95% CI: [2,8]); and (2) more consistent, having within-subject standard deviation of 3 percentage points (95% CI:[2,4]), 4 percentage points less than control (95% CI: [2,6]).Cumulative distribution function plots performed nearly as well, and both outperformed textual uncertainty, which was sensitive to the probability interval communicated. We discuss implications for real time transit predictions and possible generalization to other domains.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173719,
author = {H\"{a}nsel, Katrin and Poguntke, Romina and Haddadi, Hamed and Alomainy, Akram and Schmidt, Albrecht},
title = {What to Put on the User: Sensing Technologies for Studies and Physiology Aware Systems},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173719},
doi = {10.1145/3173574.3173719},
abstract = {Fitness trackers not just provide easy means to acquire physiological data in real-world environments due to affordable sensing technologies, they further offer opportunities for physiology-aware applications and studies in HCI; however, their performance is not well understood. In this paper, we report findings on the quality of 3 sensing technologies: PPG-based wrist trackers (Apple Watch, Microsoft Band 2), an ECG-belt (Polar H7) and reference device with stick-on ECG electrodes (Nexus 10). We collected physiological (heart rate, electrodermal activity, skin temperature) and subjective data from 21 participants performing combinations of physical activity and stressful tasks. Our empirical research indicates that wrist devices provide a good sensing performance in stationary settings. However, they lack accuracy when participants are mobile or if tasks require physical activity. Based on our findings, we suggest a textitDesign Space for Wearables in Research Settings and reflected on the appropriateness of the investigated technologies in research contexts.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {wearable technology, validation, stress, affective computing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173720,
author = {Nakikj, Drashko and Mamykina, Lena},
title = {Lost in Migration: Information Management and Community Building in an Online Health Community},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173720},
doi = {10.1145/3173574.3173720},
abstract = {The ever-growing volume of information within online health communities (OHCs) presents an urgent need for new solutions that improve the efficiency of information organization and retrieval for their members. To meet this need, OHCs may choose to adopt off-the-shelf platforms that provide novel features for information management, but were not specifically designed to meet these communities' needs. The questions remain, however, as to the impact of these new platforms on social dynamics within OHCs and their well-being. To examine these questions, we qualitatively studied a migration of a popular OHC, focusing on diabetes self-management, between two off-the-shelf social computing platforms. Despite improving information management, the migration served as a catalyst to reveal the importance of features for identity management and closed circle communication that were not apparent to either the management or the membership of the community. We describe the study and draw implications for research and design for OHCs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {community building, socio-emotional support, balanced design, social computing platform, informational support, information management, platform migration, online health community},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173721,
author = {Illi, Mikko and Karyda, Maria and Lucero, Andr\'{e}s},
title = {On Visual Granularity: Collocated Sales Meeting Interactions in the Machine Industry},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173721},
doi = {10.1145/3173574.3173721},
abstract = {Visual representations are being used in typical sales meetings of the machine industry to exchange information and support social interactions. In these meetings, sales representatives design for granularity by taking into account verbal and visual details of communication. Our article builds on increasingly occurring collocated interactions in sales meetings investigating the social relevance of mobile devices in face-to-face settings. The article aims to understand the supporting and disturbing role of visual granularity in sales meetings and develops design implications for interaction designers. We conducted an ethnographic study of sales meetings in material handling and paper machine industries, including Conversation Analysis (CA) of video recordings, and involving groups of professional analysts that are seldom used in HCI. Our findings draw evidence from sales meetings and design processes on successful and unsuccessful use of granularity in visual representations. Finally, we propose seven design guidelines for visual granularity striving to understand buyers' perceptions and visual qualities.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visual representations, collocated interaction, conversation analysis, ethnomethodology, granularity},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173722,
author = {Thebault-Spieker, Jacob and Halfaker, Aaron and Terveen, Loren G. and Hecht, Brent},
title = {Distance and Attraction: Gravity Models for Geographic Content Production},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173722},
doi = {10.1145/3173574.3173722},
abstract = {Volunteered Geographic Information (VGI), such as contributions to OpenStreetMap and geotagged Wikipedia articles, is often assumed to be produced locally. However, recent work has found that peer-produced VGI is frequently contributed by non-locals. We evaluate this approach across hundreds of content types from Wikipedia, OpenStreetMap, and eBird, and show that these models can describe more than 90% of "VGI flows" for some content types. Our findings advance geographic HCI theory, suggesting some spatial mechanisms underpinning VGI production. We also discuss design implications that can help (a) human and algorithmic consumers of VGI evaluate the perspectives it contains and (b) address geographic coverage variations in these platforms (e.g. via more effective volunteer recruitment strategies).},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {geographic hci, wikipedia, gravity models, spatial interaction models, volunteered geographic information (vgi), openstreetmap, ebird},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173723,
author = {Tian, Rundong and Sterman, Sarah and Chiou, Ethan and Warner, Jeremy and Paulos, Eric},
title = {MatchSticks: Woodworking through Improvisational Digital Fabrication},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173723},
abstract = {Digital fabrication tools have broadened participation in making and enabled new methods of rapid physical prototyping across diverse materials. We present a novel smart tool designed to complement one of the first materials employed by humans - wood - and celebrate the fabrication practice of joinery. Our tool, MatchSticks, is a digital fabrication system tailored for joinery. Combining a portable CNC machine, touchscreen user interface, and parametric joint library, MatchSticks enables makers of varying skill to rapidly explore and create artifacts from wood. Our system embodies tacit woodworking knowledge and distills the distributed workflow of CNC tools into a hand tool; it operates on materials existing machines find difficult, produces assemblies much larger than its workspace, and supports the parallel creation of geometries. We describe the workflow and technical details of our system, present example artifacts produced by our tool, and report results from our user study.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173724,
author = {Abtahi, Parastoo and Follmer, Sean},
title = {Visuo-Haptic Illusions for Improving the Perceived Performance of Shape Displays},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173724},
doi = {10.1145/3173574.3173724},
abstract = {In this work, we utilize visuo-haptic illusions to improve the perceived performance of encountered-type haptic devices, specifically shape displays, in virtual reality. Shape displays are matrices of actuated pins that travel vertically to render physical shapes; however, they have limitations such as low resolution, small display size, and low pin speed. To address these limitations, we employ illusions such as redirection, scaling, and retargeting that take advantage of the visual dominance effect, the idea that vision often dominates when senses conflict. Our evaluation of these techniques suggests that redirecting sloped lines with angles less than 40 degrees onto a horizontal line is an effective technique for increasing the perceived resolution of the display. Scaling up the virtual object onto the shape display by a factor less than 1.8x can also increase the perceived resolution. Finally, using vertical redirection a perceived 3x speed increase can be achieved.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {perception, haptics, illusion, virtual reality, shape displays},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173725,
author = {Meissner, Janis Lena and Strohmayer, Angelika and Wright, Peter and Fitzpatrick, Geraldine},
title = {A Schnittmuster for Crafting Context-Sensitive Toolkits},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173725},
doi = {10.1145/3173574.3173725},
abstract = {DIY-making can be an expensive pastime if makers are relying on ready-made toolkits, specialised materials and off-shelf components. Many prefabricated commercial kits seek to lower the learning barrier of making and to help beginners to successfully take their first steps in engineering. However, as soon as the novices become a little more advanced, these toolkits often do not fit the specific requirements of personal maker projects anymore. We introduce the idea of a Schnittmuster (or a meta-toolkit) as a novel approach to toolkit design that seeks to address these creativity-limiting factors as well as practical entrance hurdles. To demonstrate the adaptive power of the Schnittmuster concept, we discuss an exemplar in the context of capacitive touch sensing (FlexE-Touch). Implemented under the constraints of materials, user skill sets and making environments, we illustrate how the Schnittmuster facilitated four cheap and flexible toolkit instantiations for crafting custom touch sensor electrodes.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {empowerment, toolkits, diy, social justice, making},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173726,
author = {Wiseman, Sarah and Gould, Sandy J. J.},
title = {Repurposing Emoji for Personalised Communication: Why 🍕 Means “I Love You”},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173726},
abstract = {The use of emoji in digital communication can convey a wealth of emotions and concepts that otherwise would take many words to express. Emoji have become a popular form of communication, with researchers claiming emoji represent a type of "ubiquitous language" that can span different languages. In this paper however, we explore how emoji are also used in highly personalised and purposefully secretive ways. We show that emoji are repurposed for something other than their "intended" use between close partners, family members and friends. We present the range of reasons why certain emoji get chosen, including the concept of "emoji affordance" and explore why repurposing occurs. Normally used for speed, some emoji are instead used to convey intimate and personal sentiments that, for many reasons, their users cannot express in words. We discuss how this form of repurposing must be considered in tasks such as emoji-based sentiment analysis.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inproceedings{10.1145/3173574.3173727,
author = {Qiu, Will and Parigi, Palo and Abrahao, Bruno},
title = {More Stars or More Reviews?},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173727},
doi = {10.1145/3173574.3173727},
abstract = {The large majority of reputation systems use features such as star ratings and reviews to give users a reputation in online peer-to-peer markets. Both have been shown to be effective for signaling trustworthiness. However, the exact extent to which these features can change perceptions of users' trustworthiness remains an open question. Using data from an online experiment conducted on Airbnb users, we investigate which of the two types of reputation information --average star rating or the number of reviews --is more important for signaling a user's trustworthiness. We find that the relative effectiveness of ratings and reviews differ depending on whether reputation has a strong or a weak differentiation power. Our findings show that reputation effects are contingent on and susceptible to the context created by the alternative choices presented to users, highlighting how reputation information is displayed can drastically alter their efficacy for engendering trust.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {sharing economy, reputation and rating systems, trust, airbnb},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173728,
author = {Thudt, Alice and Hinrichs, Uta and Huron, Samuel and Carpendale, Sheelagh},
title = {Self-Reflection and Personal Physicalization Construction},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173728},
doi = {10.1145/3173574.3173728},
abstract = {Self-reflection is a central goal of personal informatics systems, and constructing visualizations from physical tokens has been found to help people reflect on data. However, so far, constructive physicalization has only been studied in lab environments with provided datasets. Our qualitative study investigates the construction of personal physicalizations in people's domestic environments over 2-4 weeks. It contributes an understanding of (1) the process of creating personal physicalizations, (2) the types of personal insights facilitated, (3) the integration of self-reflection in the physicalization process, and (4) its benefits and challenges for self-reflection. We found that in constructive personal physicalization, data collection, construction and self-reflections are deeply intertwined. This extends previous models of visualization creation and data-driven self-reflection. We outline how benefits such as reflection through manual construction, personalization, and presence in everyday life can be transferred to a wider set of digital and physical systems.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {self-reflection, constructive visualization, personal data},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173729,
author = {Forghani, Azadeh and Neustaedter, Carman and Vu, Manh C. and Judge, Tejinder K. and Antle, Alissa N.},
title = {G2G: The Design and Evaluation of a Shared Calendar and Messaging System for Grandparents and Grandchildren},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173729},
doi = {10.1145/3173574.3173729},
abstract = {Distance separated grandparents and grandchildren often face challenges in staying connected. To explore this topic, we designed G2G, a shared calendar and video messaging system to connect young children (ages 5-10) with their grandparents over distance. Our design focused on providing grandparents and grandchildren with an awareness of each other's lives to support conversations and design elements to help reduce the need for parent scaffolding. A field study with two grandparent-grandchild pairs over two months showed that systems designed around structured communication can help young children develop a routine around staying in touch with their remote grandparents. Autonomy in maintaining awareness can help children to be engaged more easily. This suggests that designs focusing on connecting young children to their grandparents over distance should be flexible yet structured and designing to reduce parental scaffolding can lead to positive effects and strengthened relationships.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {family communication, grandchildren, grandparents, asynchronous communication, video, calendaring},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173730,
author = {Back, Jon and Turmo Vidal, Laia and Waern, Annika and Paget, Susan and Salln\"{a}s Pysander, Eva-Lotta},
title = {Playing Close to Home: Interaction and Emerging Play in Outdoor Play Installations},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173730},
doi = {10.1145/3173574.3173730},
abstract = {Outdoor play is becoming an increasingly marginalised activity in the urban landscape. Even in HCI, research on interactive solutions for outdoor play has largely been limited to special areas and in particular playgrounds. But children play everywhere, and especially play close to home is central in children's play activities. In this article we draw upon knowledge about designing for children's play in interaction design as well as in landscape architecture, to study how interactive play installations can be integrated in outdoor environments of a residential area. We present a field study in which digitally enhanced play installations were installed, in dialogue with the landscape, in between the buildings of a residential area. We focus on how emerging play activities made use of the installations as well as of the surrounding landscape in expected as well as unexpected ways. Based on the observations, we discuss how residential play is special, and how this affects how to design for it.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {playgrounds, play, landscape architecture, landscape, digitally enhanced playground, playing close to home},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173731,
author = {Henley, Austin Z. and Mu\c{c}lu, KΙvan\c{c} and Christakis, Maria and Fleming, Scott D. and Bird, Christian},
title = {CFar: A Tool to Increase Communication, Productivity, and Review Quality in Collaborative Code Reviews},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173731},
doi = {10.1145/3173574.3173731},
abstract = {Collaborative code review has become an integral part of the collaborative design process in the domain of software development. However, there are well-documented challenges and limitations to collaborative code review---for instance, high-quality code reviews may require significant time and effort for the programmers, whereas faster, lower-quality reviews may miss code defects. To address these challenges, we introduce CFar, a novel tool design for extending collaborative code review systems with an automated code reviewer whose feedback is based on program-analysis technologies. To validate this design, we implemented CFar as a production-quality tool and conducted a mixed-method empirical evaluation of the tool usage at Microsoft. Through the field deployment of our tool and a laboratory study of professional programmers using the tool, we produced several key findings showing that CFar enhances communication, productivity, and review quality in human--human collaborative code review.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {code review, collaborative design, programming environments},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173732,
author = {Andalibi, Nazanin and Forte, Andrea},
title = {Announcing Pregnancy Loss on Facebook: A Decision-Making Framework for Stigmatized Disclosures on Identified Social Network Sites},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173732},
doi = {10.1145/3173574.3173732},
abstract = {Pregnancy loss is a common experience that is often not disclosed in spite of potential disclosure benefits such as social support. To understand how and why people disclose pregnancy loss online, we interviewed 27 women in the U.S. who are social media users and had recently experienced pregnancy loss. We developed a decision-making framework explaining pregnancy loss disclosures on identified social network sites (SNS) such as Facebook. We introduce network-level reciprocal disclosure, a theory of how disclosure reciprocity, usually applied to understand dyadic exchanges, can operate at the level of a social network to inform decision-making about stigmatized disclosures in identified SNSs. We find that 1) anonymous disclosures on other sites help facilitate disclosure on identified sites (e.g., Facebook), and 2) awareness campaigns enable sharing about pregnancy loss for many who would not disclose otherwise. Finally, we discuss conceptual and design implications. CAUTION: This paper includes quotes about pregnancy loss.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {preventive disclosure, social support, reproductive health, grief, prenatal, social media, facebook, pregnancy loss, pregnancy and i, awareness campaign, stillbirth, stigma, miscarriage, self-disclosure, women's health, network-level reciprocal disclosure},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173733,
author = {Zade, Himanshu and Drouhard, Margaret and Chinh, Bonnie and Gan, Lu and Aragon, Cecilia},
title = {Conceptualizing Disagreement in Qualitative Coding},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173733},
doi = {10.1145/3173574.3173733},
abstract = {Collaborative qualitative coding often involves coders assign- ing different labels to the same instance, leading to ambiguity. We refer to such an instance of ambiguity as disagreement in coding. Analyzing reasons for such a disagreement is essential-- both for purposes of bolstering user understanding gained from coding and reinterpreting the data collaboratively, and for negotiating user-assigned labels for building effective machine learning models. We propose a conceptual definition of collective disagreement using diversity and divergence within the coding distributions. This perspective of disagreement translates to diverse coding contexts and groups of coders irrespective of discipline. We introduce two tree-based ranking metrics as standardized ways of comparing disagreements in how data instances have been coded. We empirically validate that, of the two tree-based metrics, coders' perceptions of dis- agreement match more closely with the n-ary tree metric than with the post-traversal tree metric.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {ambiguity, qualitative coding, disagreement, theory},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173734,
author = {Kang, Laewoo (Leo) and Jackson, Steven J. and Sengers, Phoebe},
title = {Intermodulation: Improvisation and Collaborative Art Practice for HCI},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173734},
doi = {10.1145/3173574.3173734},
abstract = {This paper integrates theory, ethnography, and collaborative artwork to explore improvisational activity as both topic and tool of multidisciplinary HCI inquiry. Building on theories of improvisation drawn from art, music, HCI and social science, and two ethnographic studies based on interviews, participant observation and collaborative art practice, we seek to elucidate the improvisational nature of practice in both art and ordinary action, including human-computer interaction. We identify five key features of improvisational action -- reflexivity, transgression, tension, listening, and interdependence -- and show how these can deepen and extend both linear and open-ended methodologies in HCI and design. We conclude by highlighting collaborative engagement based on 'intermodulation' as a tool of multidisciplinary inquiry for HCI research and design.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {art practice, creativity, collaboration, improvisation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173735,
author = {Koyama, Yuki and Goto, Masataka},
title = {OptiMo: Optimization-Guided Motion Editing for Keyframe Character Animation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173735},
abstract = {The mission of animators is to create nuanced, high-quality character motions. To achieve this, the careful editing of animation curves---curves that determine how a series of keyframed poses are interpolated over time---is an important task. Manual editing affords full and precise control, but requires tedious and nonintuitive trials and errors. Numerical optimization can automate such exploration; however, automatic solutions cannot always be perfect, and it is difficult for animators to control optimization owing to its black-box behavior. In this paper, we present a new framework called optimization-guided motion editing, which is aimed at maintaining a sense of full control while utilizing the power of optimization. We have designed interactions and developed a set of mathematical formulations to enable them. We discuss the framework's potential by demonstrating several usage scenarios with our proof-of-concept system, named OptiMo.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173736,
author = {Chen, Xiang 'Anthony' and Coros, Stelian and Hudson, Scott E.},
title = {Medley: A Library of Embeddables to Explore Rich Material Properties for 3D Printed Objects},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173736},
doi = {10.1145/3173574.3173736},
abstract = {In our everyday life, we interact with and benefit from objects with a wide range of material properties. In contrast, personal fabrication machines (e.g., desktop 3D printers) currently only support a much smaller set of materials. Our goal is to close the gap between current limitations and the future of multi-material printing by enabling people to explore the reuse of material from everyday objects into their custom designs. To achieve this, we develop a library of embeddables--everyday objects that can be cut, worked and embedded into 3D printable designs. We describe a design space that characterizes the geometric and material properties of embeddables. We then develop Medley---a design tool whereby users can import a 3D model, search for embeddables with desired material properties, and interactively edit and integrate their geometry to fit into the original design. Medley also supports the final fabrication and embedding process, including instructions for carving or cutting the objects, and generating optimal paths for inserting embeddables. To validate the expressiveness of our library, we showcase numerous examples augmented by embeddables that go beyond the objects' original printed materials.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {fabrication, embeddables, multi-material printing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173737,
author = {Nissen, Bettina and Pschetz, Larissa and Murray-Rust, Dave and Mehrpouya, Hadi and Oosthuizen, Shaune and Speed, Chris},
title = {GeoCoin: Supporting Ideation and Collaborative Design with Smart Contracts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173737},
doi = {10.1145/3173574.3173737},
abstract = {Design and HCI researchers are increasingly working with complex digital infrastructures, such as cryptocurrencies, distributed ledgers and smart contracts. These technologies will have a profound impact on digital systems and their audiences. However, given their emergent nature and technical complexity, involving non-specialists in the design of applications that employ these technologies is challenging. In this paper, we discuss these challenges and present GeoCoin, a location-based platform for embodied learning and speculative ideating with smart contracts. In collaborative workshops with GeoCoin, participants engaged with location-based smart contracts, using the platform to explore digital 'debit' and 'credit' zones in the city. These exercises led to the design of diverse distributed-ledger applications, for time-limited financial unions, participatory budgeting, and humanitarian aid. These results contribute to the HCI community by demonstrating how an experiential prototype can support understanding of the complexities behind new digital infrastructures and facilitate participant engagement in ideation and design processes.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {design and ideation, distributed ledgers, geofencing, smart city, smart contracts},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173738,
author = {Khan, Hassan and Hengartner, Urs and Vogel, Daniel},
title = {Evaluating Attack and Defense Strategies for Smartphone PIN Shoulder Surfing},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173738},
doi = {10.1145/3173574.3173738},
abstract = {We evaluate the efficacy of shoulder surfing defenses for PIN-based authentication systems. We find tilting the device away from the observer, a widely adopted defense strategy, provides limited protection. We also evaluate a recently proposed defense incorporating an "invisible pressure component" into PIN entry. Contrary to earlier claims, our results show this provides little defense against malicious insider attacks. Observations during the study uncover successful attacker strategies for reconstructing a victim's PIN when faced with a tilt defense. Our evaluations identify common misconceptions regarding shoulder surfing defenses, and highlight the need to educate users on how to safeguard their credentials from these attacks.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {mobile devices, authentication, shoulder surfing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173739,
author = {Goedicke, David and Li, Jamy and Evers, Vanessa and Ju, Wendy},
title = {VR-OOM: Virtual Reality On-ROad Driving SiMulation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173739},
abstract = {Researchers and designers of in-vehicle interactions and interfaces currently have to choose between performing evaluation and human factors experiments in laboratory driving simulators or on-road experiments. To enjoy the benefit of customizable course design in controlled experiments with the immediacy and rich sensations of on-road driving, we have developed a new method and tools to enable VR driving simulation in a vehicle as it travels on a road. In this paper, we describe how the cost-effective and flexible implementation of this platform allows for rapid prototyping. A preliminary pilot test (N = 6), centered on an autonomous driving scenario, yields promising results, illustrating proof of concept and indicating that a basic implementation of the system can invoke genuine responses from test participants.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inproceedings{10.1145/3173574.3173740,
author = {Rogers, Katja and Colley, Mark and Lehr, David and Frommel, Julian and Walch, Marcel and Nacke, Lennart E. and Weber, Michael},
title = {KickAR: Exploring Game Balancing Through Boosts and Handicaps in Augmented Reality Table Football},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173740},
doi = {10.1145/3173574.3173740},
abstract = {When player skill levels are not matched, games provide an unsatisfying player experience. Player balancing is used across many digital game genres to address this, but has not been studied for co-located augmented reality (AR) tabletop games, where using boosts and handicaps can adjust for different player skill levels. In the setting of an AR table football game, we studied the importance of game balancing being triggered by the game system or the players, and whether player skill should be required to trigger game balancing. We implemented projected icons to prominently display game balancing mechanics in the AR table football game. In a within-subjects study (N=24), we found players prefer skill-based control over game balancing and that different triggers are perceived as having different fairness. Further, the study showed that even game balancing that is perceived as unfair can provide enjoyable game experiences. Based on our findings, we provide suggestions for player balancing in AR tabletop games.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {player experience, game balancing, foosball, mario kart effect, augmented reality, handicap},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173741,
author = {Magrisso, Shiran and Mizrahi, Moran and Zoran, Amit},
title = {Digital Joinery For Hybrid Carpentry},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173741},
doi = {10.1145/3173574.3173741},
abstract = {The craft of carpentry relies on joinery: the connections between pieces of wood to create multipart structures. In traditional woodworking, joints are limited to the manual chisel skills of the craftsperson, or to capabilities of the machines, which favorite 90° or 180° angle joints with no more than two elements. We contribute an interactive design process in which joints are generated digitally to allow for unrestricted beam connectors, then produced from Nylon-12 using selective laser sintering (SLS) 3D printing. We present our Generative Joinery Design Tool and demonstrate our system on a selection of stools. The paper exemplifies the potential of Digital Joinery to enhance carpentry by incorporating a hybrid and interactive level of design sophistication and affordances that are very hard to achieve with traditional skills and tools.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {computer-aided design, design, digital fabrication, hybrid, joinery, woodwork, 3d printing, carpentry},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173742,
author = {Kauffmann, Nina and Winkler, Franz and Vollrath, Mark},
title = {What Makes an Automated Vehicle a Good Driver?},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173742},
doi = {10.1145/3173574.3173742},
abstract = {An automated vehicle needs to learn how human road users experience the intentions of other drivers and understand how they communicate with each other in order to avoid misunderstandings and prevent giving a negative external image during interactions. The aim of the present study is to identify a cooperative lane change indication which other drivers understand unambiguously and prefer when it comes to lane change announcements in a dense traffic situation on the highway. A fixed-base driving simulator study is conducted with N = 66 participants in Germany in a car-following scenario. Participants rated, from the lag driver's perspective, different lane change announcements of another driver which varied in lateral movements (i.e., duration, lateral offset). Main findings indicate that a medium offset and moderate duration of lateral movement is experienced as most cooperative. The results are crucial for the development of lane change strategies for automated vehicles.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {dense traffic, external image, gap acceptance, lane change, communication between human drivers},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173743,
author = {Price, Blaine A. and Kelly, Ryan and Mehta, Vikram and McCormick, Ciaran and Ahmed, Hanad and Pearce, Oliver},
title = {Feel My Pain: Design and Evaluation of Painpad, a Tangible Device for Supporting Inpatient Self-Logging of Pain},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173743},
doi = {10.1145/3173574.3173743},
abstract = {Monitoring patients' pain is a critical issue for clinical caregivers, particularly among staff responsible for providing analgesic relief. However, collecting regularly scheduled pain readings from patients can be difficult and time-consuming for clinicians. In this paper we present Painpad, a tangible device that was developed to allow patients to engage in self-logging of their pain. We report findings from two hospital-based field studies in which Painpad was deployed to a total of 78 inpatients recovering from ambulatory surgery. We find that Painpad results in improved frequency and compliance with pain logging, and that self-logged scores may be more faithful to patients' experienced pain than corresponding scores reported to nurses. We also show that older adults may prefer tangible interfaces over tablet-based alternatives for reporting their pain, and we contribute design lessons for pain logging devices intended for use in hospital settings.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {pain diaries, health, mobile devices, pain logging},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173744,
author = {Lu, Di and Marlow, Jennifer and Kocielnik, Rafal and Avrahami, Daniel},
title = {Challenges and Opportunities for Technology-Supported Activity Reporting in the Workplace},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173744},
doi = {10.1145/3173574.3173744},
abstract = {Effective communication of activities and progress in the workplace is crucial for the success of many modern organizations. In this paper, we extend current research on workplace communication and uncover opportunities for technology to support effective work activity reporting. We report on three studies: With a survey of 68 knowledge workers followed by 14 in-depth interviews, we investigated the perceived benefits of different types of progress reports and an array of challenges at three stages: Collection, Composition, and Delivery. We show an important interplay between written and face-to-face reporting, and highlight the importance of tailoring a report to its audience. We then present results from an analysis of 722 reports composed by 361 U.S.-based knowledge workers, looking at the influence of the audience on a report's language. We conclude by discussing opportunities for future technologies to assist both employees and managers in collecting, interpreting, and reporting progress in the workplace.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {awareness, activity reporting, workplace, collaboration},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173745,
author = {Niess, Jasmin and Woundefinedniak, Pawe\l{} W.},
title = {Supporting Meaningful Personal Fitness: The Tracker Goal Evolution Model},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173745},
abstract = {While the number of users sporting fitness trackers is constantly increasing, little is understood about how tracking goals can evolve over time. As recent studies have shown that the long-term health effects of trackers are limited, we need to readdress how trackers engage users. We conducted semi-structured interviews and an online survey to explore how users change their tracking goals. Based on our results, we created the Tracker Goal Evolution Model. The model describes how tracker goals can evolve from internal user needs through qualitative goals to quantitative goals that can be used with trackers. It also includes trust and reflection as key contextual factors contributing to meaningful transitions between goals. We postulate showing how tracker goals relate to other personal fitness goals as key for long-term engagement with trackers. Our model is useful for designers of future trackers as a tool to create evolving and meaningful tracking goals.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173746,
author = {Taylor, Nick and Clarke, Loraine},
title = {Everybody's Hacking: Participation and the Mainstreaming of Hackathons},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173746},
doi = {10.1145/3173574.3173746},
abstract = {Hackathons have become a popular tool for bringing people together to imagine new possibilities for technology. Despite originating in technology communities, hackathons have now been widely adopted by a broad range of organisations. This mainstreaming of hackathons means they encompass a very different range of attendees and activities than they once did, to the extent that some events billed as hackathons may involve no coding at all. Given this shift away from production of code, they might instead be seen as an increasingly popular participatory design activity, from which designers and researchers in HCI can learn. Through fieldwork at six hackathons that targeted non-technical communities, we identify the types of activities and contributions that emerge through these events and the barriers and tensions that might exist. In doing so, we contribute a greater understanding of hackathons as a growing phenomenon and as a potential tool for participatory research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {hackathons, jams, participatory design, co-design, innovation, making},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173747,
author = {Siddhpuria, Shaishav and Malacria, Sylvain and Nancel, Mathieu and Lank, Edward},
title = {Pointing at a Distance with Everyday Smart Devices},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173747},
abstract = {Large displays are becoming commonplace at work, at home, or in public areas. However, interaction at a distance -- anything greater than arms-length -- remains cumbersome, restricts simultaneous use, and requires specific hardware augmentations of the display: touch layers, cameras, or dedicated input devices. Yet a rapidly increasing number of people carry smartphones and smartwatches, devices with rich input capabilities that can easily be used as input devices to control interactive systems. We contribute (1) the results of a survey on possession and use of smart devices, and (2) the results of a controlled experiment comparing seven distal pointing techniques on phone or watch, one- and two-handed, and using different input channels and mappings. Our results favor using a smartphone as a trackpad, but also explore performance tradeoffs that can inform the choice and design of distal pointing techniques for different contexts of use.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inproceedings{10.1145/3173574.3173748,
author = {Kery, Mary Beth and Radensky, Marissa and Arya, Mahima and John, Bonnie E. and Myers, Brad A.},
title = {The Story in the Notebook: Exploratory Data Science Using a Literate Programming Tool},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173748},
doi = {10.1145/3173574.3173748},
abstract = {Literate programming tools are used by millions of programmers today, and are intended to facilitate presenting data analyses in the form of a narrative. We interviewed 21 data scientists to study coding behaviors in a literate programming environment and how data scientists kept track of variants they explored. For participants who tried to keep a detailed history of their experimentation, both informal and formal versioning attempts led to problems, such as reduced notebook readability. During iteration, participants actively curated their notebooks into narratives, although primarily through cell structure rather than markdown explanations. Next, we surveyed 45 data scientists and asked them to envision how they might use their past history in an future version control system. Based on these results, we give design guidance for future literate programming tools, such as providing history search based on how programmers recall their explorations, through contextual details including images and parameters.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {end-user programmers (eup), exploratory programming, literate programming, data science, end-user software engineering (euse)},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173750,
author = {Marky, Karola and Kulyk, Oksana and Renaud, Karen and Volkamer, Melanie},
title = {What Did I Really Vote For?  On the Usability of Verifiable E-Voting Schemes},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173750},
doi = {10.1145/3173574.3173750},
abstract = {E-voting has been embraced by a number of countries, delivering benefits in terms of efficiency and accessibility. End-to-end verifiable e-voting schemes facilitate verification of the integrity of individual votes during the election process. In particular, methods for cast-as-intended verification enable voters to confirm that their cast votes have not been manipulated by the voting client. A well-known technique for effecting cast-as-intended verification is the Benaloh Challenge. The usability of this challenge is crucial because voters have to be actively engaged in the verification process. In this paper, we report on a usability evaluation of three different approaches of the Benaloh Challenge in the remote e-voting context. We performed a comparative user study with 95 participants. We conclude with a recommendation for which approaches should be provided to afford verification in real-world elections and suggest usability improvements.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cast-as-intended verifiability, usability evaluation, e-voting, benaloh challenge, end-to-end verifiability},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173751,
author = {Sahoo, Deepak Ranjan and Neate, Timothy and Tokuda, Yutaka and Pearson, Jennifer and Robinson, Simon and Subramanian, Sriram and Jones, Matt},
title = {Tangible Drops: A Visio-Tactile Display Using Actuated Liquid-Metal Droplets},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173751},
abstract = {We present Tangible Drops, a visio-tactile display that for the first time provides physical visualization and tactile feedback using a planar liquid interface. It presents digital information interactively by tracing dynamic patterns on horizontal flat surfaces using liquid metal drops on a programmable electrode array. It provides tactile feedback with directional information in the 2D vector plane using linear locomotion and/or vibration of the liquid metal drops. We demonstrate move, oscillate, merge, split and dispense-from-reservoir functions of the liquid metal drops by consuming low power (450 mW per electrode) and low voltage (8--15 V). We report on results of our empirical study with 12 participants on tactile feedback using 8 mm diameter drops, which indicate that Tangible Drops can convey tactile sensations such as changing speed, varying direction and controlled oscillation with no visual feedback. We present the design space and demonstrate the applications of Tangible Drops, and conclude by suggesting potential future applications for the technique.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3173574.3173752,
author = {Wong, Pui Chung and Zhu, Kening and Fu, Hongbo},
title = {FingerT9: Leveraging Thumb-to-Finger Interaction for Same-Side-Hand Text Entry on Smartwatches},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173752},
abstract = {We introduce FingerT9, leveraging the action of thumb-to-finger touching on the finger segments, to support same-side-hand (SSH) text entry on smartwatches. This is achieved by mapping a T9 keyboard layout to the finger segments. Our solution avoids the problems of fat finger and screen occlusion, and enables text entry using the same-side hand which wears the watch. In the pilot study, we determined the layout mapping preferred by the users. We conducted an experiment to compare the text-entry performances of FingerT9, the tilt-based SSH input, and the direct-touch non-SSH input. The results showed that the participants performed significantly faster and more accurately with FingerT9 than the tilt-based method. There was no significant difference between FingerT9 and direct-touch methods in terms of efficiency and error rate. We then conducted the second experiment to study the learning curve on SSH text entry methods: FingerT9 and the tilt-based input. FingerT9 gave significantly better long-term improvement. In addition, eyes-free text entry (i.e., looking at the screen output but not the keyboard layout mapped on the finger segments) was made possible once the participants were familiar with the keyboard layout.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10}
}

@inproceedings{10.1145/3173574.3173753,
author = {Singhal, Samarth and Neustaedter, Carman and Odom, William and Bartram, Lyn and Heshmat, Yasamin},
title = {Time-Turner: Designing for Reflection and Remembrance of Moments in the Home},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173753},
doi = {10.1145/3173574.3173753},
abstract = {Families preserve memories of their special and everyday experiences, though it can be hard to capture all these moments in everyday life. We explore the concept of automated forms of capturing family life and presenting them through situated, tangible everyday artifacts in the home. We designed Time-Turner, an always-on video recording system along with a set of three drink coasters that allow family members to easily search, filter and replay videos to connect to their past. We engaged households in speculative enactments and interviews to explore the design space. Our findings point to the value of witnessing real rather than staged moments and the ways in which the affordances of everyday artifacts can allow media to be 'lived with' as a part of everyday life. Yet our design also revealed tensions around sharing and changing perceptions across time and generations. This points to design challenges around safeguarding this media and capturing 'reality' as opposed to curated content.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {always-on video, remembering, memories, domestic computing, home, co-speculation., families},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173754,
author = {Machuletz, Dominique and Laube, Stefan and B\"{o}hme, Rainer},
title = {Webcam Covering as Planned Behavior},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173754},
doi = {10.1145/3173574.3173754},
abstract = {Most of today's laptops come with an integrated webcam placed above the screen to enable video conferencing. Due to the risk of webcam spying attacks, some laptop users seem to be concerned about their privacy and seek protection by covering the webcam. This paper is the first to investigate personal characteristics and beliefs of users with and without webcam covers by applying the Theory of Planned Behavior. We record the privacy behavior of 180 users, develop a path model, and analyze it by applying Partial Least Squares. The analysis indicates that privacy concerns do not significantly influence users' decision to use a webcam cover. Rather, this behavior is influenced by users' attitudes, social environment, and perceived control over protecting privacy. Developers should take this as a lesson to design privacy enhancing technologies which are convenient, verifiably effective and endorsed by peers.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {usability, privacy, theory of planned behavior (tpb), webcam cover, field study, partial least squares (pls)},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173755,
author = {Gong, Jun and Xu, Zheer and Guo, Qifan and Seyed, Teddy and Chen, Xiang 'Anthony' and Bi, Xiaojun and Yang, Xing-Dong},
title = {WrisText: One-Handed Text Entry on Smartwatch Using Wrist Gestures},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173755},
doi = {10.1145/3173574.3173755},
abstract = {We present WrisText - a one-handed text entry technique for smartwatches using the joystick-like motion of the wrist. A user enters text by whirling the wrist of the watch hand, towards six directions which each represent a key in a circular keyboard, and where the letters are distributed in an alphabetical order. The design of WrisText was an iterative process, where we first conducted a study to investigate optimal key size, and found that keys needed to be 55º or wider to achieve over 90% striking accuracy. We then computed an optimal keyboard layout, considering a joint optimization problem of striking accuracy, striking comfort, word disambiguation. We evaluated the performance of WrisText through a five-day study with 10 participants in two text entry scenarios: hand-up and hand-down. On average, participants achieved a text entry speed of 9.9 WPM across all sessions, and were able to type as fast as 15.2 WPM by the end of the last day.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {one-handed input, smartwatch, text entry},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173756,
author = {Schmitz, Martin and Herbers, Martin and Dezfuli, Niloofar and G\"{u}nther, Sebastian and M\"{u}hlh\"{a}user, Max},
title = {Off-Line Sensing: Memorizing Interactions in Passive 3D-Printed Objects},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173756},
doi = {10.1145/3173574.3173756},
abstract = {Embedding sensors into objects allow them to recognize various interactions. However, sensing usually requires active electronics that are often costly, need time to be assembled, and constantly draw power. Thus, we propose off-line sensing: passive 3D-printed sensors that detect one-time interactions, such as accelerating or flipping, but neither require active electronics nor power at the time of the interaction. They memorize a pre-defined interaction via an embedded structure filled with a conductive medium (e.g., a liquid). Whether a sensor was exposed to the interaction can be read-out via a capacitive touchscreen. Sensors are printed in a single pass on a consumer-level 3D printer. Through a series of experiments, we show the feasibility of off-line sensing.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {digital fabrication, capacitive sensing, mechanism, input, 3d printing, sensors, metamaterial},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173757,
author = {Irannejad Bisafar, Farnaz and Martinez, Lina Itzel and Parker, Andrea G.},
title = {Social Computing-Driven Activism in Youth Empowerment Organizations: Challenges and Opportunities},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173757},
abstract = {Throughout the world, organizations empower youth to participate in civic engagement to impact social change, and adult-youth collaborations are instrumental to the success of such initiatives. However, little is known about how technology supports this activism work, despite the fact that tools such as Social Networking Applications (SNAs) are increasingly being leveraged in such contexts. We report results from a qualitative study of SNA use within a youth empowerment organization. Using the analytical lens of object-oriented publics, our findings reveal opportunities and challenges that youth and staff face when they use SNAs. We describe the illegibility of youth outreach efforts on SNAs, and how this illegibility complicated staff attempts to hold youth accountable. We also characterize how youth and staff differed in what they felt were socially appropriate uses of SNA features, and tensions that arose in the co-use of these tools. We conclude with implications for the design of collaborative technologies that support youth-led activism in organizational contexts.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173758,
author = {Park, Seonwook and Gebhardt, Christoph and R\"{a}dle, Roman and Feit, Anna Maria and Vrzakova, Hana and Dayama, Niraj Ramesh and Yeo, Hui-Shyong and Klokmose, Clemens N. and Quigley, Aaron and Oulasvirta, Antti and Hilliges, Otmar},
title = {AdaM: Adapting Multi-User Interfaces for Collaborative Environments in Real-Time},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173758},
doi = {10.1145/3173574.3173758},
abstract = {Developing cross-device multi-user interfaces (UIs) is a challenging problem. There are numerous ways in which content and interactivity can be distributed. However, good solutions must consider multiple users, their roles, their preferences and access rights, as well as device capabilities. Manual and rule-based solutions are tedious to create and do not scale to larger problems nor do they adapt to dynamic changes, such as users leaving or joining an activity. In this paper, we cast the problem of UI distribution as an assignment problem and propose to solve it using combinatorial optimization. We present a mixed integer programming formulation which allows real-time applications in dynamically changing collaborative settings. It optimizes the allocation of UI elements based on device capabilities, user roles, preferences, and access rights. We present a proof-of-concept designer-in-the-loop tool, allowing for quick solution exploration. Finally, we compare our approach to traditional paper prototyping in a lab study.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {distributed user interface, ui adaptation, cross-device interaction, optimization},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173759,
author = {Arora, Rahul and Habib Kazi, Rubaiat and Grossman, Tovi and Fitzmaurice, George and Singh, Karan},
title = {SymbiosisSketch: Combining 2D &amp; 3D Sketching for Designing Detailed 3D Objects in Situ},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173759},
abstract = {We present SymbiosisSketch, a hybrid sketching system that combines drawing in air (3D) and on a drawing surface (2D) to create detailed 3D designs of arbitrary scale in an augmented reality (AR) setting. SymbiosisSketch leverages the complementary affordances of 3D (immersive, unconstrained, life-sized) and 2D (precise, constrained, ergonomic) interactions for in situ 3D conceptual design. A defining aspect of our system is the ongoing creation of surfaces from unorganized collections of 3D curves. These surfaces serve a dual purpose: as 3D canvases to map strokes drawn on a 2D tablet, and as shape proxies to occlude the physical environment and hidden curves in a 3D sketch. SymbiosisSketch users draw interchangeably on a 2D tablet or in 3D within an ergonomically comfortable canonical volume, mapped to arbitrary scale in AR. Our evaluation study shows this hybrid technique to be easy to use in situ and effective in transcending the creative potential of either traditional sketching or drawing in air.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inproceedings{10.1145/3173574.3173760,
author = {Tyack, April and Wyeth, Peta and Klarkowski, Madison},
title = {Video Game Selection Procedures For Experimental Research},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173760},
doi = {10.1145/3173574.3173760},
abstract = {Videogames are complex stimuli, and selecting games that consistently induce a desired player experience (PX) in an experimental setting can be challenging. The number of relatively high-quality games being released each year continues to increase, which makes deriving a shortlist of plausible candidate games from this pool increasingly problematic. Despite this, guidance for structuring and reporting on the game selection process remains limited. This paper therefore proposes two approaches to game selection: the first leverages online videogame databases and existing PX research, and is structured with respect to widely-applicable videogame metadata. The second process applies established game design theory to serve researchers when insufficient connections between desired PX outcomes and recognisable game elements exist. Both methods are accompanied by example reports of their application. The present work aims to assist experimental researchers in selecting videogames likely to meet their needs, while encouraging more rigorous standards of reporting in the field.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {video games, experiments, game selection, player experience},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173761,
author = {Romat, Hugo and Appert, Caroline and Bach, Benjamin and Henry-Riche, Nathalie and Pietriga, Emmanuel},
title = {Animated Edge Textures in Node-Link Diagrams: A Design Space and Initial Evaluation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173761},
doi = {10.1145/3173574.3173761},
abstract = {Network edge data attributes are usually encoded using color, opacity, stroke thickness and stroke pattern, or some combination thereof. In addition to these static variables, it is also possible to animate dynamic particles flowing along the edges. This opens a larger design space of animated edge textures, featuring additional visual encodings that have potential not only in terms of visual mapping capacity but also playfulness and aesthetics. Such animated edge textures have been used in several commercial and design-oriented visualizations, but to our knowledge almost always in a relatively ad hoc manner. We introduce a design space and Web-based framework for generating animated edge textures, and report on an initial evaluation of particle properties - particle speed, pattern and frequency - in terms of visual perception.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {animation, particles, trees, node-link diagrams, networks},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173762,
author = {Nagels, Steven and Ramakers, Raf and Luyten, Kris and Deferme, Wim},
title = {Silicone Devices: A Scalable DIY Approach for Fabricating Self-Contained Multi-Layered Soft Circuits Using Microfluidics},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173762},
doi = {10.1145/3173574.3173762},
abstract = {We present a scalable Do-It-Yourself (DIY) fabrication workflow for prototyping highly stretchable yet robust devices using a CO2 laser cutter, which we call Silicone Devices. Silicone Devices are self-contained and thus embed components for input, output, processing, and power. Our approach scales to arbitrary complex devices as it supports techniques to make multi-layered stretchable circuits and buried VIAs. Additionally, high-frequency signals are supported as our circuits consist of liquid metal and are therefore highly conductive and durable. To enable makers and interaction designers to prototype a wide variety of Silicone Devices, we also contribute a stretchable sensor toolkit, consisting of touch, proximity, sliding, pressure, and strain sensors. We demonstrate the versatility and novel opportunities of our technique by prototyping various samples and exploring their use cases. Strain tests report on the reliability of our circuits and preliminary user feedback reports on the user-experience of our workflow by non-engineers.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ubiquitous computing, wearable computing, flexible circuits, diy, fabrication, stretchable circuits},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173763,
author = {Hsieh, Meng-Ju and Liang, Rong-Hao and Huang, Da-Yuan and Ke, Jheng-You and Chen, Bing-Yu},
title = {RFIBricks: Interactive Building Blocks Based on RFID},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173763},
doi = {10.1145/3173574.3173763},
abstract = {We present RFIBricks, an interactive building block system based on ultrahigh frequency radio-frequency identification (RFID) sensing. The system enables geometry resolution based on a simple yet highly generalizable mechanism: an RFID contact switch, which is made by cutting each RFID tag into two parts, namely antenna and chip. A magnetic connector is then coupled with each part. When the antenna and chip connect, an interaction event with an ID is transmitted to the reader. On the basis of our design of RFID contact switch patterns, we present a system of interactive physical building blocks that resolves the stacking order and orientation when one block is stacked upon another, determines a three-dimensional (3D) geometry built on a two-dimensional base plate, and detects user inputs by incorporating electromechanical sensors. Because it is calibration-free and does not require batteries in each block, it facilitates straightforward maintenance when deployed at scale. Compared with other approaches, this RFID-based system resolves several critical challenges in human-computer interaction, such as 1) determining the identity and the built 3D geometry of passive building blocks, 2) enabling stackable token+constraint interaction on a tabletop, and 3) tracking in-hand assembly.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {constructive assembly, building blocks, rfid, tangible user interface},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173764,
author = {Poeller, Susanne and Birk, Max V. and Baumann, Nicola and Mandryk, Regan L.},
title = {Let Me Be Implicit: Using Motive Disposition Theory to Predict and Explain Behaviour in Digital Games},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173764},
doi = {10.1145/3173574.3173764},
abstract = {We introduce explicit and implicit motives (i.e., achievement, affiliation, power, autonomy) into player experience research and situate them in existing theories of player motivation, personality, playstyle, and experience. Additionally, we conducted an experiment with 109 players in a social play situation and show that: 1. As expected, there are several correlations of playstyle, personality, and motivation with explicit motives, but few with implicit motives; 2. The implicit affiliation motive predicts in-game social behaviour; and 3. The implicit affiliation motive adds significant variance to explain regression models of in-game social behaviours even when we control for social aspects of personality, the explicit affiliation motive, self-esteem, and social player traits. Our results support that implicit motives explain additional variance because they access needs that are experienced affectively and pre-consciously, and not through cognitive interpretation necessary for explicit expression and communication, as is the case in any approaches that use self-report.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {implicit motives, motive disposition theory, explicit motives, digital games, player types},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173765,
author = {Chaves, Ana Paula and Gerosa, Marco Aurelio},
title = {Single or Multiple Conversational Agents? An Interactional Coherence Comparison},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173765},
abstract = {Chatbots focusing on a narrow domain of expertise are in great rise. As several tasks require multiple expertise, a designer may integrate multiple chatbots in the background or include them as interlocutors in a conversation. We investigated both scenarios by means of a Wizard of Oz experiment, in which participants talked to chatbots about visiting a destination. We analyzed the conversation content, users' speech, and reported impressions. We found no significant difference between single- and multi-chatbots scenarios. However, even with equivalent conversation structures, users reported more confusion in multi-chatbots interactions and adopted strategies to organize turn-taking. Our findings indicate that implementing a meta-chatbot may not be necessary, since similar conversation structures occur when interacting to multiple chatbots, but different interactional aspects must be considered for each scenario.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173766,
author = {Romanosky, Julianne and Chetty, Marshini},
title = {Understanding the Use and Impact of the Zero-Rated Free Basics Platform in South Africa},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173766},
doi = {10.1145/3173574.3173766},
abstract = {Companies are offering zero-rated, or data-charge free Internet services to help bring unconnected users online where Internet access is less affordable. However, it is unclear whether these services achieve this goal or how they shape Internet use. To inform evidence-based policy around and the design of zero-rated services, we show in this paper how mobile users are making use of Facebook's controversial Free Basics platform. We present findings from interviews of 35 Free Basics users in South Africa: current low-income users and non-regular student users. Our findings suggest that Free Basics does shape Internet usage, for instance, users spend more time online because of 'free' apps. Second, Free Basics saves users money but adoption of the platform depends on access to other 'free' Internet options. Finally, most users are confused about how zero-rated services work and what 'free' means. Based on our findings, we make recommendations for future work.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {zero-rating, free basics, south africa, zero-rated, internet},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173767,
author = {Rogerson, Melissa J. and Gibbs, Martin R. and Smith, Wally},
title = {Cooperating to Compete: The Mutuality of Cooperation and Competition in Boardgame Play},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173767},
abstract = {This paper examines the complex relationship between competition and cooperation in boardgame play. We understand boardgaming as distributed cognition, where people work together in a shared activity to accomplish the game. Although players typically compete against each other, this competition is only possible through ongoing cooperation to negotiate, enact and maintain the rules of play. In this paper, we report on a study of people playing modern boardgames. We analyse how knowledge of the game's state is distributed amongst the players and the game components, and examine the different forms of cooperation and collaboration that occur during play. Further, we show how players use the material elements of the game to support articulation work and to improve their awareness and understanding of the game's state. Our goal is to examine the coordinative practices that the players use during play and explicate the ways in which these enable competition.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173768,
author = {Ghosh, Arup Kumar and Badillo-Urquiola, Karla and Rosson, Mary Beth and Xu, Heng and Carroll, John M. and Wisniewski, Pamela J.},
title = {A Matter of Control or Safety? Examining Parental Use of Technical Monitoring Apps on Teens' Mobile Devices},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173768},
doi = {10.1145/3173574.3173768},
abstract = {Adoption rates of parental control applications ("apps") for teens' mobile devices are low, but little is known about the characteristics of parents (or teens) who use these apps. We conducted a web-based survey of 215 parents and their teens (ages 13-17) using two separate logistic regression models (parent and teen) to examine the factors that predicted parental use of technical monitoring apps on their teens' mobile devices. Both parent and teen models confirmed that low autonomy granting (e.g., authoritarian) parents were the most likely to use parental control apps. The teen model revealed additional nuance, indicating that teens who were victimized online and had peer problems were more likely to be monitored by their parents. Overall, increased parental control was associated with more (not fewer) online risks. We discuss the implications of these findings and provide design recommendations for mobile apps that promote online safety through engaged, instead of restrictive, parenting.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mobile smart phones, adolescent online safety, technical monitoring, parental mediation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173769,
author = {Mahyar, Narges and James, Michael R. and Ng, Michelle M. and Wu, Reginald A. and Dow, Steven P.},
title = {CommunityCrit: Inviting the Public to Improve and Evaluate Urban Design Ideas through Micro-Activities},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173769},
doi = {10.1145/3173574.3173769},
abstract = {While urban design affects the public, most people do not have the time or expertise to participate in the process. Many online tools solicit public input, yet typically limit interaction to collecting complaints or early-stage ideas. This paper explores how to engage the public in more complex stages of urban design without requiring a significant time commitment. After observing workshops, we designed a system called CommunityCrit that offers micro-activities to engage communities in elaborating and evaluating urban design ideas. Through a four-week deployment, in partnership with a local planning group seeking to redesign a street intersection, CommunityCrit yielded 352 contributions (around 10 minutes per participant). The planning group reported that CommunityCrit provided insights on public perspectives and raised awareness for their project, but noted the importance of setting expectations for the process. People appreciated that the system provided a window into the planning process, empowered them to contribute, and supported diverse levels of skills and availability.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {crowdsourcing, civic technology, urban design, publics},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173770,
author = {Gori, Julien and Rioul, Olivier and Guiard, Yves and Beaudouin-Lafon, Michel},
title = {The Perils of Confounding Factors: How Fitts' Law Experiments Can Lead to False Conclusions},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173770},
doi = {10.1145/3173574.3173770},
abstract = {The design of Fitts' historical reciprocal tapping experiment gravely confounds index of difficulty ID with target distance D: Summary statistics for the candidate Fitts model and a competing model may appear identical, and the validity of Fitts' model for some tasks can be legitimately questioned. We show that the contamination of ID by either target distance D or width W is due to the common practices of pooling and averaging data belonging to different distance-width (D,W) pairs for the same ID, and taking a geometric progression for values of D and W. We analyze a case study of the validation of Fitts' law in eye-gaze movements, where an unfortunate experimental design has misled researchers into believing that eye-gaze movements are not ballistic. We then provide simple guidelines to prevent confounds: Practitioners should carefully design the experimental conditions of (D,W), fully distinguish data acquired for different conditions, and put less emphasis on r² scores. We also recommend investigating the use of stochastic sampling for D and W.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {models, factor confounds, fitts' law},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173771,
author = {Zhang, Eda and Culbertson, Gabriel and Shen, Solace and Jung, Malte},
title = {Utilizing Narrative Grounding to Design Storytelling Gamesfor Creative Foreign Language Production},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173771},
doi = {10.1145/3173574.3173771},
abstract = {Foreign language students must learn to use language creatively to overcome knowledge gaps and keep readers or listeners interested. However, few tools exist to support practicing this skill. Therefore, we set out to explore design of storytelling games for practicing creative language use. Through an iterative design process, we identified narrative grounding (establishing common ground for collaborative narrative) as key to student engagement and learning. However, designing games for narrative grounding while keeping the game flexible enough to easily accommodate teacher goals is challenging. Considering this challenge, we designed a collaborative storytelling game where students help scaffold the narrative and teachers can easily integrate language goals with "language cards". In an in-classroom evaluation with 36 students, we show the importance of narrative grounding for learning. Qualitative evidence also suggests narrative grounding makes the game more engaging for players. We conclude with discussion of design implications for digital language learning tools.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {schools/educational setting, storytelling games, collaboration, language learning},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173772,
author = {Holloway, Leona and Marriott, Kim and Butler, Matthew},
title = {Accessible Maps for the Blind: Comparing 3D Printed Models with Tactile Graphics},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173772},
abstract = {Tactile maps are widely used in Orientation and Mobility (O&amp;M) training for people with blindness and severe vision impairment. Commodity 3D printers now offer an alternative way to present accessible graphics, however it is unclear if 3D models offer advantages over tactile equivalents for 2D graphics such as maps. In a controlled study with 16 touch readers, we found that 3D models were preferred, enabled the use of more easily understood icons, facilitated better short term recall and allowed relative height of map elements to be more easily understood. Analysis of hand movements revealed the use of novel strategies for systematic scanning of the 3D model and gaining an overview of the map. Finally, we explored how 3D printed maps can be augmented with interactive audio labels, replacing less practical braille labels. Our findings suggest that 3D printed maps do indeed offer advantages for O&amp;M training.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173773,
author = {Suzuki, Ryo and Kato, Jun and Gross, Mark D. and Yeh, Tom},
title = {Reactile: Programming Swarm User Interfaces through Direct Physical Manipulation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173773},
doi = {10.1145/3173574.3173773},
abstract = {We explore a new approach to programming swarm user interfaces (Swarm UI) by leveraging direct physical manipulation. Existing Swarm UI applications are written using a robot programming framework: users work on a computer screen and think in terms of low-level controls. In contrast, our approach allows programmers to work in physical space by directly manipulating objects and think in terms of high-level interface design. Inspired by current UI programming practices, we introduce a four-step workflow-create elements, abstract attributes, specify behaviors, and propagate changes-for Swarm UI programming. We propose a set of direct physical manipulation techniques to support each step in this workflow. To demonstrate these concepts, we developed Reactile, a Swarm UI programming environment that actuates a swarm of small magnets and displays spatial information of program states using a DLP projector. Two user studies-an in-class survey with 148 students and a lab interview with eight participants-confirm that our approach is intuitive and understandable for programming Swarm UIs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {swarm user interfaces, tangible programming, programming by demonstration, direct manipulation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173774,
author = {Tabassum, Madiha and Alqhatani, Abdulmajeed and Aldossari, Marran and Richter Lipford, Heather},
title = {Increasing User Attention with a Comic-Based Policy},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173774},
doi = {10.1145/3173574.3173774},
abstract = {End user license agreements, terms of service agreements and privacy policies all suffer from many of the same problems: people rarely read them and yet still agree to whatever is contained within them. There are many usability challenges with these policies: they are often lengthy, with jargon filled language that is difficult to quickly comprehend. However, these notices are the primary tool for users to understand the privacy implications of their digital activities and make informed decisions on which websites and software they use. Prior research has explored alternative designs for such notices, using more visual and structured interfaces for conveying information. We expand upon these results by exploring a comic-based interface, examining whether it can engage users to pay more attention to a terms of service agreement. Our results indicate that the comic version did hold user attention for longer than text-based alternatives, encouraging deeper investigation into comic-based interfaces.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {end user license agreement, privacy, privacy policy, comic, terms of service},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173775,
author = {Hauser, Sabrina and Wakkary, Ron and Odom, William and Verbeek, Peter-Paul and Desjardins, Audrey and Lin, Henry and Dalton, Matthew and Schilling, Markus and de Boer, Gijs},
title = {Deployments of the Table-Non-Table: A Reflection on the Relation Between Theory and Things in the Practice of Design Research},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173775},
doi = {10.1145/3173574.3173775},
abstract = {Design-oriented research in HCI has increasingly migrated towards theoretical perspectives to understand the implications of newly crafted technology in everyday life. However, in this context, the relations between theory and understanding the things we make are not always clear, especially the degree to which the nature of research artifacts is revealed through or determined by theory. We examine a series of field deployment studies we conducted with our research artifact table-non-table over the course of four and a half years that we came to see as a postphenomenological inquiry. Importantly, our interpretations of this artifact, methodological concerns, and theoretical groundings evolved over time. We account for and critically reflect on these shifts in the relationship between theory and our design artifact. We detail how theory was enacted and embodied in our design research practice and offer insights into the complex relations between theory and things in design-oriented HCI research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {postphenomenology, design theory, field studies, research through design},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173776,
author = {Eardley, Rachel and Roudaut, Anne and Gill, Steve and Thompson, Stephen J.},
title = {Investigating How Smartphone Movement is Affected by Body Posture},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173776},
doi = {10.1145/3173574.3173776},
abstract = {We present an investigation into how hand usage is affected by different body postures (Sitting at a table, Lying down and Standing) when interacting with smartphones. We theorize a list of factors (smartphone support, body support and muscle usage) and explore their influence the tilt and rotation of the smartphone. From this we draw a list of hypotheses that we investigate in a quantitative study. We varied the body postures and grips (Symmetric bimanual, Asymmetric bimanual finger, Asymmetric bimanual thumb and Single-handed) studying the effects through a dual pointing task. Our results showed that the body posture Lying down had the most movement, followed by Sitting at a table and finally Standing. We additionally generate reports of motions performed using different grips. Our work extends previous research conducted with multiple grips in a sitting position by including other body postures, it is anticipated that UI designers will use our results to inform the development of mobile user interfaces.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {interaction, lying down, standing, grasp, handgrip, body posture, design, mobile device, smartphone},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173777,
author = {Thieme, Anja and Bennett, Cynthia L. and Morrison, Cecily and Cutrell, Edward and Taylor, Alex S.},
title = {<i>"I Can Do Everything but See!" </i> -- How People with Vision Impairments Negotiate Their Abilities in Social Contexts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173777},
doi = {10.1145/3173574.3173777},
abstract = {This research takes an orientation to visual impairment (VI) that does not regard it as fixed or determined alone in or through the body. Instead, we consider (dis)ability as produced through interactions with the environment and configured by the people and technology within it. Specifically, we explore how abilities become negotiated through video ethnography with six VI athletes and spectators during the Rio 2016 Paralympics. We use generated in-depth examples to identify how technology can be a meaningful part of ability negotiations, emphasizing how these embed into the social interactions and lives of people with VI. In contrast to treating technology as a solution to a 'sensory deficit', we understand it to support the triangulation process of sense-making through provision of appropriate additional information. Further, we suggest that technology should not try and replace human assistance, but instead enable people with VI to better identify and interact with other people in-situ.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {vision impairment, collaboration, assistive technology, accessibility, ability, social technology, blindness, ethnography},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173778,
author = {Boyd, LouAnne E. and Gupta, Saumya and Vikmani, Sagar B. and Gutierrez, Carlos M. and Yang, Junxiang and Linstead, Erik and Hayes, Gillian R.},
title = {VrSocial: Toward Immersive Therapeutic VR Systems for Children with Autism},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173778},
doi = {10.1145/3173574.3173778},
abstract = {Social communication frequently includes nuanced nonverbal communication cues, including eye contact, gestures, facial expressions, body language, and tone of voice. This type of communication is central to face-to-face interaction, but can be challenging for children and adults with autism. Innovative technologies can provide support by augmenting human-delivered cuing and automated prompting. Specifically, immersive virtual reality (VR) offers an option to generalize social skill interventions by concretizing nonverbal information in real-time social interactions. In this work, we explore the design and evaluation of three nonverbal communication applications in immersive VR. The results of this work indicate that delivering real-time visualizations of proximity, speaker volume, and duration of one's speech is feasible in immersive VR and effective for real-time support for proximity regulation for children with autism. We conclude with design considerations for therapeutic VR systems.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visualization, accessibility, prosody, immersive vr, assistive technology, proximity, nonverbal communication, autism},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173779,
author = {Aksan, Emre and Pece, Fabrizio and Hilliges, Otmar},
title = {DeepWriting: Making Digital Ink Editable via Deep Generative Modeling},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173779},
doi = {10.1145/3173574.3173779},
abstract = {Digital ink promises to combine the flexibility and aesthetics of handwriting and the ability to process, search and edit digital text. Character recognition converts handwritten text into a digital representation, albeit at the cost of losing personalized appearance due to the technical difficulties of separating the interwoven components of content and style. In this paper, we propose a novel generative neural network architecture that is capable of disentangling style from content and thus making digital ink editable. Our model can synthesize arbitrary text, while giving users control over the visual appearance (style). For example, allowing for style transfer without changing the content, editing of digital ink at the word level and other application scenarios such as spell-checking and correction of handwritten text. We furthermore contribute a new dataset of handwritten text with fine-grained annotations at the character level and report results from an initial user evaluation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {handwriting, digital ink, stylus-based interfaces, deep learning, recurrent neural networks},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173780,
author = {Wilkinson, Gerard and Bartindale, Tom and Nappey, Tom and Evans, Michael and Wright, Peter and Olivier, Patrick},
title = {Media of Things: Supporting the Production of Metadata Rich Media Through IoT Sensing},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173780},
abstract = {Rich metadata is becoming a key part of the broadcast production pipeline. This information can be used to deliver compelling new consumption experiences which are personalized, location-aware, interactive and multi-screen. However, media producers are struggling to generate the metadata required for such experiences, using inefficient post-production solutions which are limited in how much of the original context they can capture. In response, we present Media of Things (MoT), a tool for on-location media productions. MoT enables practical and flexible generation of sensor based point-of-capture metadata. We demonstrate how embedded ubiquitous sensing technologies such as the Internet of Things can be leveraged to produce context rich, time sequenced metadata in a production studio. We reflect on how this workflow can be integrated within the constraints of broadcast production and the possibilities that emerge from access to rich data at the beginning of the production lifecycle to produce well described media for reconfigurable consumption.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173781,
author = {Williams, Joseph Jay and Rafferty, Anna N. and Tingley, Dustin and Ang, Andrew and Lasecki, Walter S. and Kim, Juho},
title = {Enhancing Online Problems Through Instructor-Centered Tools for Randomized Experiments},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173781},
doi = {10.1145/3173574.3173781},
abstract = {Digital educational resources could enable the use of randomized experiments to answer pedagogical questions that instructors care about, taking academic research out of the laboratory and into the classroom. We take an instructor-centered approach to designing tools for experimentation that lower the barriers for instructors to conduct experiments. We explore this approach through DynamicProblem, a proof-of-concept system for experimentation on components of digital problems, which provides interfaces for authoring of experiments on explanations, hints, feedback messages, and learning tips. To rapidly turn data from experiments into practical improvements, the system uses an interpretable machine learning algorithm to analyze students' ratings of which conditions are helpful, and present conditions to future students in proportion to the evidence they are higher rated. We evaluated the system by collaboratively deploying experiments in the courses of three mathematics instructors. They reported benefits in reflecting on their pedagogy, and having a new method for improving online problems for future students.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {randomized experiments, instructional design, online education, dynamic experimentation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173782,
author = {Vtyurina, Alexandra and Fourney, Adam},
title = {Exploring the Role of Conversational Cues in Guided Task Support with Virtual Assistants},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173782},
doi = {10.1145/3173574.3173782},
abstract = {Voice-based conversational assistants are growing in popularity on ubiquitous mobile and stationary devices. Cortana, as well as Google Home, Amazon Echo, and others, can provide support for various tasks from managing reminders to booking a hotel. However, with few exceptions, user input is limited to explicit queries or commands. In this work, we explore the role of implicit conversational cues in guided task completion scenarios. In a Wizard of Oz study, we found that, for the task of cooking a recipe, nearly one-quarter of all user-assistant exchanges were initiated from implicit conversational cues rather than from plain questions. Given that these implicit cues occur in such high frequency, we conclude by presenting a set of design implications for the design of guided task experiences in contemporary conversational assistants.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {conversational systems, conversational cues, task support},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173783,
author = {Vovk, Alla and Wild, Fridolin and Guest, Will and Kuula, Timo},
title = {Simulator Sickness in Augmented Reality Training Using the Microsoft HoloLens},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173783},
doi = {10.1145/3173574.3173783},
abstract = {Augmented Reality is on the rise with consumer-grade smart glasses becoming available in recent years. Those interested in deploying these head-mounted displays need to understand better the effect technology has on the end user. One key aspect potentially hindering the use is motion sickness, a known problem inherited from virtual reality, which so far remains under-explored. In this paper we address this problem by conducting an experiment with 142 subjects in three different industries: aviation, medical, and space. We evaluate whether the Microsoft HoloLens, an augmented reality head-mounted display, causes simulator sickness and how different symptom groups contribute to it (nausea, oculomotor and disorientation). Our findings suggest that the Microsoft HoloLens causes across all participants only negligible symptoms of simulator sickness. Most consumers who use it will face no symptoms while only few experience minimal discomfort in the training environments we tested it in.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {simulator sickness, microsoft hololens, motion sickness, augmented reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173784,
author = {Mueller, Florian 'Floyd' and Byrne, Richard and Andres, Josh and Patibanda, Rakesh},
title = {Experiencing the Body as Play},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173784},
abstract = {Games research in HCI is continually interested in the human body. However, recent work suggests that the field has only begun to understand how to design bodily games. We propose that the games research field is advancing from playing with digital content using a keyboard, to using bodies to play with digital content, towards a future where we experience our bodies as digital play. To guide designers interested in supporting players to experience their bodies as play, we present two phenomenological perspectives on the human body (K\"{o}rper and Leib) and articulate a suite of design tactics using our own and other people's work. We hope with this paper, we are able to help designers embrace the point that we both "have" a body and "are" a body, thereby aiding the facilitation of the many benefits of engaging the human body through games and play, and ultimately contributing to a more humanized technological future.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173785,
author = {DiFranzo, Dominic and Taylor, Samuel Hardman and Kazerooni, Franccesca and Wherry, Olivia D. and Bazarova, Natalya N.},
title = {Upstanding by Design: Bystander Intervention in Cyberbullying},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173785},
doi = {10.1145/3173574.3173785},
abstract = {Although bystander intervention can mitigate the negative effects of cyberbullying, few bystanders ever attempt to intervene. In this study, we explored the effects of interface design on bystander intervention using a simulated custom-made social media platform. Participants took part in a three-day, in-situ experiment, in which they were exposed to several cyberbullying incidents. Depending on the experimental condition, they received different information about the audience size and viewing notifications intended to increase a sense of personal responsibility in bystanders. Results indicated that bystanders were more likely to intervene indirectly than directly, and information about the audience size and viewership increased the likelihood of flagging cyberbullying posts through serial mediation of public surveillance, accountability, and personal responsibility. The study has implications for understanding bystander effect in cyberbullying, and how to develop design solutions to encourage bystander intervention in social media.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {cyberbullying, social networking sites, bystander intervention},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173786,
author = {Redmiles, Elissa M. and Chachra, Neha and Waismeyer, Brian},
title = {Examining the Demand for Spam: Who Clicks?},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173786},
doi = {10.1145/3173574.3173786},
abstract = {Despite significant advances in automated spam detection, some spam content manages to evade detection and engage users. While the spam supply chain is well understood through previous research, there is little understanding of spam consumers. We focus on the demand side of the spam equation examining what drives users to click on spam via a large-scale analysis of de-identified, aggregated Facebook log data (n=600,000). We find (1) that the volume of spam and clicking norms in a users' network are significantly related to individual consumption behavior; (2) that more active users are less likely to click, suggesting that experience and internet skill (weakly correlated with activity level) may create more savvy consumers; and (3) we confirm previous findings about the gender effect in spam consumption, but find this effect largely corresponds to spam topics. Our findings provide practical insights to reduce demand for spam content, thereby affecting spam profitability.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {social media, facebook, security behavior, spam},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173787,
author = {Punpongsanon, Parinya and Wen, Xin and Kim, David S. and Mueller, Stefanie},
title = {ColorMod: Recoloring 3D Printed Objects Using Photochromic Inks},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173787},
doi = {10.1145/3173574.3173787},
abstract = {Recent research has shown how to change the color of existing objects using photochromic materials. These materials can switch their appearance from transparent to colored when exposed to light of a certain wavelength. The color remains even when the object is removed from the light source. The process is fully reversible allowing users to recolor the object as many times as they want. So far, these systems have been limited to single color changes, i.e. changes from transparent to colored. In this paper, we present ColorMod, a method to extend this approach to multi-color changes (e.g., red-to-yellow). We accomplish this using a multi-color pattern with one color per voxel across the surface of the object. When recoloring the object, our system locally activates only those voxels that have the desired color and turns all other voxels off. We describe ColorMod's hardware/software system and its user interface that comes with a conversion tool for 3D&nbsp;printing as well as a painting tool that matches physical voxels with the desired appearance. We also contribute our own material formula for a 3D-printable photochromic ink.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {projector-camera system, 3d printing, personal fabrication},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173788,
author = {Gui, Xinning and Kou, Yubo and Pine, Kathleen and Ladaw, Elisa and Kim, Harold and Suzuki-Gill, Eli and Chen, Yunan},
title = {Multidimensional Risk Communication: Public Discourse on Risks during an Emerging Epidemic},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173788},
doi = {10.1145/3173574.3173788},
abstract = {Crisis informatics has examined how institutions and individuals seek, communicate, and curate information in response to crises. The public's communication and perception of risks on social media remain understudied. In this study, we report a qualitative analysis of public perceptions of risks and risk management measures on Reddit during the Zika crisis, an emerging epidemic associated with high uncertainty regarding pathology, epidemiology, and broad consequences. We found two types of perceived risks: ones directly caused by the Zika virus, and ones potentially introduced by authorities' risk management measures. Risk perceptions unfolded along multiple dimensions beyond the imminent and personal level. Reddit users discussed in a speculative way to foresee various risks in the long run or at larger geographical scales. We discuss the multidimensionality and speculative nature of risk perception on social media, and derive implications for crisis informatics research and public health research and practice.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {public participation, risk perception, public health crisis, zika virus, crisis informatics, biological crisis, emerging epidemic, risk communication, social media},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173789,
author = {Zhao, Yuhang and Wu, Shaomei and Reynolds, Lindsay and Azenkot, Shiri},
title = {A Face Recognition Application for People with Visual Impairments: Understanding Use Beyond the Lab},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173789},
doi = {10.1145/3173574.3173789},
abstract = {Recognizing others is a major challenge for people with visual impairments (VIPs) and can hinder engagement in social activities. We present Accessibility Bot, a research prototype bot on Facebook Messenger, that leverages state-of-the-art computer vision and a user's friends' tagged photos on Facebook to help people with visual impairments recognize their friends. Accessibility Bot provides users information about identity and facial expressions and attributes of friends captured by their phone's camera. To guide our design, we interviewed eight VIPs to understand their challenges and needs in social activities. After designing and implementing the bot, we conducted a diary study with six VIPs to study its use in everyday life. While most participants found the Bot helpful, their experience was undermined by perceived low recognition accuracy, difficulty aiming a camera, and lack of knowledge about the phone's status. We discuss these real-world challenges, identify suitable use cases for Accessibility Bot, and distill design implications for future face recognition applications.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visual impairment, social activity, face recognition},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173790,
author = {Remy, Christian and Bates, Oliver and Dix, Alan and Thomas, Vanessa and Hazas, Mike and Friday, Adrian and Huang, Elaine M.},
title = {Evaluation Beyond Usability: Validating Sustainable HCI Research},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173790},
doi = {10.1145/3173574.3173790},
abstract = {The evaluation of research artefacts is an important step to validate research contributions. Sub-disciplines of HCI often pursue primary goals other than usability, such as Sustainable HCI (SHCI), HCI for development, or health and wellbeing. For such disciplines, established evaluation methods are not always appropriate or sufficient, and new conventions for identifying, discussing, and justifying suitable evaluation methods need to be established. In this paper, we revisit the purpose and goals of evaluation in HCI and SHCI, and elicit five key elements that can provide guidance to identifying evaluation methods for SHCI research. Our essay is meant as a starting point for discussing current and improving future evaluation practice in SHCI; we also believe it holds value for other subdisciplines in HCI that encounter similar challenges while evaluating their research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sustainable hci, validation, evaluation, sustainability},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173791,
author = {Lim, Hajin and Cosley, Dan and Fussell, Susan R.},
title = {Beyond Translation: Design and Evaluation of an Emotional and Contextual Knowledge Interface for Foreign Language Social Media Posts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173791},
abstract = {Although many social media sites now provide machine translation (MT) for foreign language posts, translation of a post may not suffice to support understanding of, and engagement with, that post. We present SenseTrans, a tool that provides emotional and contextual annotations generated by natural language analysis in addition to machine translation. We evaluated SenseTrans in a laboratory experiment in which native English speakers browsed five Facebook profiles in foreign languages. One group used the SenseTrans interface while the other group used MT alone. Participants using SenseTrans reported significantly greater understanding of the posts, and greater willingness to engage with the posts. However, no additional cognitive load was associated with using an interface that provided more information. These results provide promising support for the idea of using computational tools to annotate communication to support multilingual sense making and interaction on social media.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173792,
author = {Lee, Joon Hyub and An, Sang-Gyun and Kim, Yongkwan and Bae, Seok-Hyung},
title = {Projective Windows: Bringing Windows in Space to the Fingertip},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173792},
doi = {10.1145/3173574.3173792},
abstract = {In augmented and virtual reality (AR and VR), there may be many 3D planar windows with 2D texts, images, and videos on them. However, managing the position, orientation, and scale of such a window in an immersive 3D workspace can be difficult. Projective Windows strategically uses the absolute and apparent sizes of the window at various stages of the interaction to enable the grabbing, moving, scaling, and releasing of the window in one continuous hand gesture. With it, the user can quickly and intuitively manage and interact with windows in space without any controller hardware or dedicated widget. Through an evaluation, we demonstrate that our technique is performant and preferable, and that projective geometry plays an important role in the design of spatial user interfaces.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {3d window management, virtual reality, augmented reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173793,
author = {Huo, Ke and Cao, Yuanzhi and Yoon, Sang Ho and Xu, Zhuangying and Chen, Guiming and Ramani, Karthik},
title = {Scenariot: Spatially Mapping Smart Things Within Augmented Reality Scenes},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173793},
doi = {10.1145/3173574.3173793},
abstract = {The emerging simultaneous localizing and mapping (SLAM) based tracking technique allows the mobile AR device spatial awareness of the physical world. Still, smart things are not fully supported with the spatial awareness in AR. Therefore, we present Scenariot, a method that enables instant discovery and localization of the surrounding smart things while also spatially registering them with a SLAM based mobile AR system. By exploiting the spatial relationships between mobile AR systems and smart things, Scenariot fosters in-situ interactions with connected devices. We embed Ultra-Wide Band (UWB) RF units into the AR device and the controllers of the smart things, which allows for measuring the distances between them. With a one-time initial calibration, users localize multiple IoT devices and map them within the AR scenes. Through a series of experiments and evaluations, we validate the localization accuracy as well as the performance of the enabled spatial aware interactions. Further, we demonstrate various use cases through Scenariot.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {localization, spatial interactions, iot, smart environment, context awareness, slam, uwb, augmented reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173794,
author = {Dierk, Christine and Nicholas, Molly Jane Pearce and Paulos, Eric},
title = {AlterWear: Battery-Free Wearable Displays for Opportunistic Interactions},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173794},
doi = {10.1145/3173574.3173794},
abstract = {As the landscape of wearable devices continues to expand, power remains a major issue for adoption, usability, and miniaturization. Users are faced with an increasing number of personal devices to manage, charge, and care for. In this work, we argue that power constraints limit the design space of wearable devices. We present AlterWear: an architecture for new wearable devices that implement a batteryless design using electromagnetic induction via NFC and bistable e-ink displays. Although these displays are active only when in proximity to an NFC-enabled device, this unique combination of hardware enables both quick, dynamic and long-term interactions with persistent visual displays. We demonstrate new wearables enabled through AlterWear with dynamic, fashion-forward, and expressive displays across several form factors, and evaluate them in a user study. By forgoing the need for onboard power, AlterWear expands the ecosystem of functional and fashionable wearable technologies.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {e-ink displays, wearables, ambient displays, cosmetic computing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173795,
author = {Palacin-Silva, Maria V. and Knutas, Antti and Ferrario, Maria Angela and Porras, Jari and Ikonen, Jouni and Chea, Chandara},
title = {The Role of Gamification in Participatory Environmental Sensing: A Study In the Wild},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173795},
doi = {10.1145/3173574.3173795},
abstract = {Participatory sensing (PS) and citizen science hold promises for a genuinely interactive and inclusive citizen engagement in meaningful and sustained collection of data about social and environmental phenomena. Yet the underlying motivations for public engagement in PS remain still unclear particularly regarding the role of gamification, for which HCI research findings are often inconclusive. This paper reports the findings of an experimental study specifically designed to further understand the effects of gamification on citizen engagement. Our study involved the development and implementation of two versions (gamified and non-gamified) of a mobile application designed to capture lake ice coverage data in the sub-arctic region. Emerging findings indicate a statistically significant effect of gamification on participants' engagement levels in PS. The motivation, approach and results of our study are outlined and implications of the findings for future PS design are reflected.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {citizen science, participatory sensing, civic technology, gamification, human behavior, engagement, environmental sensing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173796,
author = {Yamashita, Naomi and Kuzuoka, Hideaki and Kudo, Takashi and Hirata, Keiji and Aramaki, Eiji and Hattori, Kazuki},
title = {How Information Sharing about Care Recipients by Family Caregivers Impacts Family Communication},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173796},
doi = {10.1145/3173574.3173796},
abstract = {Previous research has shown that tracking technologies have the potential to help family caregivers optimize their coping strategies and improve their relationships with care recipients. In this paper, we explore how sharing the tracked data (i.e., caregiving journals and patient's conditions) with other family caregivers affects home care and family communication. Although previous works suggested that family caregivers may benefit from reading the records of others, sharing patients' private information might fuel negative feelings of surveillance and violation of trust for care recipients. To address this research question, we added a sharing feature to the previously developed tracking tool and deployed it for six weeks in the homes of 15 family caregivers who were caring for a depressed family member. Our findings show how the sharing feature attracted the attention of care recipients and helped the family caregivers discuss sensitive issues with care recipients.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {family communication, caregiving, depression, informal caregiver, healthcare technology, tracking technology},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173797,
author = {Xia, Haijun and Henry Riche, Nathalie and Chevalier, Fanny and De Araujo, Bruno and Wigdor, Daniel},
title = {DataInk: Direct and Creative Data-Oriented Drawing},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173797},
abstract = {Creating whimsical, personal data visualizations remains a challenge due to a lack of tools that enable for creative visual expression while providing support to bind graphical content to data. Many data analysis and visualization creation tools target the quick generation of visual representations, but lack the functionality necessary for graphics design. Toolkits and charting libraries offer more expressive power, but require expert programming skills to achieve custom designs. In contrast, sketching affords fluid experimentation with visual shapes and layouts in a free-form manner, but requires one to manually draw every single data point. We aim to bridge the gap between these extremes. We propose DataInk, a system supports the creation of expressive data visualizations with rigorous direct manipulation via direct pen and touch input. Leveraging our commonly held skills, coupled with a novel graphical user interface, DataInk enables direct, fluid, and flexible authoring of creative data visualizations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173798,
author = {Jensen, Mads M\o{}ller and R\"{a}dle, Roman and Klokmose, Clemens N. and Bodker, Susanne},
title = {Remediating a Design Tool: Implications of Digitizing Sticky Notes},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173798},
doi = {10.1145/3173574.3173798},
abstract = {Sticky notes are ubiquitous in design processes because of their tangibility and ease of use. Yet, they have well-known limitations in professional design processes, as documentation and distribution are cumbersome at best. This paper compares the use of sticky notes in ideation with a remediated digital sticky notes setup. The paper contributes with a nuanced understanding of what happens when remediating a physical design tool into digital space, by emphasizing focus shifts and breakdowns caused by the technology, but also benefits and promises inherent in the digital media. Despite users' preference for creating physical notes, handling digital notes on boards was easier and the potential of proper documentation make the digital setup a possible alternative. While the analogy in our remediation supported a transfer of learned handling, the users' experiences across technological setups impact their use and understanding, yielding new concerns regarding cross-device transfer and collaboration.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {comparative analysis, design tools, sticky notes, cross-device interaction, remediation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173799,
author = {Li, Hanlin and Bora, Disha and Salvi, Sagar and Brady, Erin},
title = {Slacktivists or Activists? Identity Work in the Virtual Disability March},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173799},
doi = {10.1145/3173574.3173799},
abstract = {Protests are important social forms of activism, but can be inaccessible to people with disabilities. Online activism, like the 2017 Disability March, has provided alternative venues for involvement in accessible protesting and social movements. In this study, we use identity theory as a lens to understand why and how disabled activists engaged in an online movement, and its impact on their self-concepts. We interviewed 18 disabled activists about their experiences with online protesting during the Disability March. Respondents' identities (as both disabled individuals and as activists) led them to organize or join the March, evolved alongside the group's actions, and were reprioritized or strained as a result of their involvement. Our findings describe the values and limitations of this activism to our respondents, highlight the tensions they perceived about their activist identities, and present opportunities to support further accessibility and identity changes by integrating technology into their activist experiences.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {activism, accessibility, identity theory, social media},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173800,
author = {Concannon, Shauna Julia and Balaam, Madeline and Simpson, Emma and Comber, Rob},
title = {Applying Computational Analysis to Textual Data from the Wild: A Feminist Perspective},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173800},
doi = {10.1145/3173574.3173800},
abstract = {With technologies that afford much larger-scale data collection than previously imagined, new ways of processing and interpreting qualitative textual data are required. HCI researchers use a range of methods for interpreting the 'full range of human experience' from qualitative data, however, such approaches are not always scalable. Feminist geography seeks to explore how diverse and varied accounts of place can be understood and represented, whilst avoiding reductive classification systems. In this paper, we assess the extent to which unsupervised topic models can support such a research agenda. Drawing on literature from Feminist and Critical GIS, we present a case study analysis of a Volunteered Geographic Information dataset of reviews about breastfeeding in public spaces. We demonstrate that topic modelling can offer novel insights and nuanced interpretations of complex concepts such as privacy and be integrated into a critically reflexive feminist data analysis approach that captures and represents diverse experiences of place.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {critical gis, text analysis, feminist gis, gis, human-data-interaction, geodata, data analysis, topic modelling, feminism},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173801,
author = {Ibrahim, Seray B. and Vasalou, Asimina and Clarke, Michael},
title = {Design Opportunities for AAC and Children with Severe Speech and Physical Impairments},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173801},
abstract = {Augmentative and alternative communication (AAC) technologies can support children with severe speech and physical impairments (SSPI) to express themselves. Yet, these seemingly 'enabling' technologies are often abandoned by this target group, suggesting a need to understand how they are used in communication. Little research has considered the interaction between people, interaction design and the material dimension of AAC. To address this, we report on a qualitative video study that examines the situated communication of five children using AAC in a special school. Our findings offer a new perspective on reconceptualising AAC design and use revealing four areas for future design: (1) incorporating an embodied view of communication, (2) designing to emphasise children's competence and agency, (3) regulating the presence, prominence and value of AAC, and (4) supporting a wider range of communicative functions that help address children's needs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3173574.3173802,
author = {Evans, Hayley I. and Wong-Villacres, Marisol and Castro, Daniel and Gilbert, Eric and Arriaga, Rosa I. and Dye, Michaelanne and Bruckman, Amy},
title = {Facebook in Venezuela: Understanding Solidarity Economies in Low-Trust Environments},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173802},
abstract = {Since 2014, Venezuela has experienced severe economic crisis, including scarcity of basic necessities such as food and medicine. This has resulted in over-priced goods, scams, and other forms of economic abuse. We present an investigation of Venezuelans' efforts to form an alternative, Solidarity Economy (SE) through Facebook Groups. In these groups, individuals can barter for items at fair prices. We highlight group practices and design features of Facebook Groups which support solidarity or anti-solidarity behaviors. We conclude by leveraging design principles for online communities presented by Kollock to present strategies to design more effective SEs in environments of low trust.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3173803,
author = {Pal, Joyojeet and Chandra, Priyank and Kameswaran, Vaishnav and Parameshwar, Aakanksha and Joshi, Sneha and Johri, Aditya},
title = {Digital Payment and Its Discontents: Street Shops and the Indian Government's Push for Cashless Transactions},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173803},
abstract = {In November 2016, the Government of India banned the vast majority of the nation's banknotes in a move referred to as 'demonetization', with the stated goals of fighting corruption, terrorism, and eventually expanding digital transactions. In this study of 200 shop-keepers in Mumbai and Bengaluru, we found that cash shortage increased digital payment adoption but that digital payments fell after new banknotes became available. Digital payment adoption depended on the nature and scope of transactions, type of product sold, as well as personal factors specific to business owners such as comfort and familiarity with other digital technologies and online transactions. Using theoretical work on market and information behavior, we examined environmental pushes for technology adoption against prevalent transactional practices, trust, and control. We propose that the move toward digital payments must be framed within a larger undertaking of technology-driven modernity that drives these initiatives, rather than just the efficiency or productivity gains digital payments present.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173804,
author = {Lee, Byungjoo and Kim, Sunjun and Oulasvirta, Antti and Lee, Jong-In and Park, Eunji},
title = {Moving Target Selection: A Cue Integration Model},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173804},
doi = {10.1145/3173574.3173804},
abstract = {This paper investigates a common task requiring temporal precision: the selection of a rapidly moving target on display by invoking an input event when it is within some selection window. Previous work has explored the relationship between accuracy and precision in this task, but the role of visual cues available to users has remained unexplained. To expand modeling of timing performance to multimodal settings, common in gaming and music, our model builds on the principle of probabilistic cue integration. Maximum likelihood estimation (MLE) is used to model how different types of cues are integrated into a reliable estimate of the temporal task. The model deals with temporal structure (repetition, rhythm) and the perceivable movement of the target on display. It accurately predicts error rate in a range of realistic tasks. Applications include the optimization of difficulty in game-level design.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {player modeling, moving target selection, game balancing, temporal pointing, level of difficulty, cue integration},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173805,
author = {Bounov, Dimitar and DeRossi, Anthony and Menarini, Massimiliano and Griswold, William G. and Lerner, Sorin},
title = {Inferring Loop Invariants through Gamification},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173805},
doi = {10.1145/3173574.3173805},
abstract = {In today's modern world, bugs in software systems incur significant costs. One promising approach to improve software quality is automated software verification. In this approach, an automated tool tries to prove the software correct once and for all. Although significant progress has been made in this direction, there are still many cases where automated tools fail. We focus specifically on one aspect of software verification that has been notoriously hard to automate: inferring loop invariants that are strong enough to enable verification. In this paper, we propose a solution to this problem through gamification and crowdsourcing. In particular, we present a puzzle game where players find loop invariants without being aware of it, and without requiring any expertise on software verification. We show through an experiment with Mechanical Turk users that players enjoy the game, and are able to solve verification tasks that automated state-of-the-art tools cannot.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {program verification, loop invariants, games},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173806,
author = {Singh, Divit P. and Lisle, Lee and Murali, T. M. and Luther, Kurt},
title = {CrowdLayout: Crowdsourced Design and Evaluation of Biological Network Visualizations},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173806},
doi = {10.1145/3173574.3173806},
abstract = {Biologists often perform experiments whose results generate large quantities of data, such as interactions between molecules in a cell, that are best represented as networks (graphs). To visualize these networks and communicate them in publications, biologists must manually position the nodes and edges of each network to reflect their real-world physical structure. This process does not scale well, and graph layout algorithms lack the biological underpinnings to offer a viable alternative. In this paper, we present CrowdLayout, a crowdsourcing system that leverages human intelligence and creativity to design layouts of biological network visualizations. CrowdLayout provides design guidelines, abstractions, and editing tools to help novice workers perform like experts. We evaluated CrowdLayout in two experiments with paid crowd workers and real biological network data, finding that crowds could both create and evaluate meaningful, high-quality layouts. We also discuss implications for crowdsourced design and network visualizations in other domains.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {computational biology, crowdsourcing, graphs, networks, design, graph drawing, visualization, citizen science},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173807,
author = {Blythe, Mark and Encinas, Enrique and Kaye, Jofish and Avery, Miriam Lueck and McCabe, Rob and Andersen, Kristina},
title = {Imaginary Design Workbooks: Constructive Criticism and Practical Provocation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173807},
doi = {10.1145/3173574.3173807},
abstract = {his paper reports on design strategies for critical and experimental work that remains constructive. We report findings from a design workshop that explored the "home hub" space through "imaginary design workbooks". These feature ambiguous images and annotations written in an invented language to suggest a design space without specifying any particular idea. Many of the concepts and narratives which emerged from the workshop focused on extreme situations: some thoughtful, some dystopian, some even mythic. One of the workshop ideas was then developed with a senior social worker who works with young offenders. A "digital social worker" concept was developed and critiqued simultaneously. We draw on Foucault's history of surveillance to "defamiliarise" both the home hub technology and the current youth justice system. We argue that the dichotomy between "constructive" and "critical" design is false because design is never neutral.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {research through design, design fiction, well being},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173808,
author = {Mariakakis, Alex and Parsi, Sayna and Patel, Shwetak N. and Wobbrock, Jacob O.},
title = {Drunk User Interfaces: Determining Blood Alcohol Level through Everyday Smartphone Tasks},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173808},
doi = {10.1145/3173574.3173808},
abstract = {Breathalyzers, the standard quantitative method for assessing inebriation, are primarily owned by law enforcement and used only after a potentially inebriated individual is caught driving. However, not everyone has access to such specialized hardware. We present drunk user interfaces: smartphone user interfaces that measure how alcohol affects a person's motor coordination and cognition using performance metrics and sensor data. We examine five drunk user interfaces and combine them to form the "DUI app". DUI uses machine learning models trained on human performance metrics and sensor data to estimate a person's blood alcohol level (BAL). We evaluated DUI on 14 individuals in a week-long longitudinal study wherein each participant used DUI at various BALs. We found that with a global model that accounts for user-specific learning, DUI can estimate a person's BAL with an absolute mean error of 0.005% ± 0.007% and a Pearson's correlation coefficient of 0.96 with breathalyzer measurements.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {safety, inebriation, situational impairments, drunkenness, mobile, smartphones, alcohol, health, driving},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173809,
author = {Bellini, Rosanna and Olivier, Patrick and Comber, Rob},
title = {“That Really Pushes My Buttons”: Designing Bullying and Harassment Training for the Workplace},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173809},
abstract = {Workplace bullying and harassment have been identified as two of the most concerning silent and unseen occupational hazards of the 21st century. The design of bespoke training addressing domain-specific job roles and relations presents a particular challenge. Using the concept of data-in-place where data is understood as being bound and produced by a particular place, this paper describes how locally-situated accounts can be used to engage employees in workplace-specific training seminars. Using higher education as a case study, we describe a four-stage design process for future training efforts: (1) in-depth interviews for further understanding of bullying and harassment; (2) design of digital probes for capturing contextual data; (3) probe deployment and subsequent data analysis; (4) data-driven discussion-based seminars. We outline the potential for digital probes in promoting the denormalization of toxic workplace cultures, considerations for novel sensitive data governance models, and the discussion of data-in-place's temporal dimension.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.1145/3173574.3173810,
author = {Brul\'{e}, Emeline and Bailly, Gilles},
title = {Taking into Account Sensory Knowledge: The Case of Geo-Techologies for Children with Visual Impairments},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173810},
doi = {10.1145/3173574.3173810},
abstract = {This paper argues for designing geo-technologies supporting non-visual sensory knowledge. Sensory knowledge refers to the implicit and explicit knowledge guiding our uses of our senses to understand the world. To support our argument, we build on an 18 months field-study on geography classes for primary school children with visual impairments. Our findings show (1) a paradox in the use of non-visual sensory knowledge: described as fundamental to the geography curriculum, it is mostly kept out of school; (2) that accessible geo-technologies in the literature mainly focus on substituting vision with another modality, rather than enabling teachers to build on children's experiences; (3) the importance of the hearing sense in learning about space. We then introduce a probe, a wrist-worn device enabling children to record audio cues during field-trips. By giving importance to children's hearing skills, it modified existing practices and actors' opinions on non-visual sensory knowledge. We conclude by reflecting on design implications, and the role of technologies in valuing diverse ways of understanding the world.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {wearable, sensory knowledge, design, probe, geography, visual impairments, maps, education},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173811,
author = {Huang, Jin and Tian, Feng and Fan, Xiangmin and Zhang, Xiaolong (Luke) and Zhai, Shumin},
title = {Understanding the Uncertainty in 1D Unidirectional Moving Target Selection},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173811},
doi = {10.1145/3173574.3173811},
abstract = {In contrast to the extensive studies on static target pointing, much less formal understanding of moving target acquisition can be found in the HCI literature. We designed a set of experiments to identify regularities in 1D unidirectional moving target selection, and found a Ternary-Gaussian model to be descriptive of the endpoint distribution in such tasks. The shape of the distribution as characterized by μ and σ in the Gaussian model were primarily determined by the speed and size of the moving target. The model fits the empirical data well with 0.95 and 0.94 R2 values for μ and σ , respectively. We also demonstrated two extensions of the model, including 1) predicting error rates in moving target selection; and 2) a novel interaction technique to implicitly aid moving target selection. By applying them in a game interface design, we observed good performances in both predicting error rates (e.g., 2.7% mean absolute error) and assisting moving target selection (e.g., 33% or a greater increase in pointing accuracy).},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {error rate prediction, endpoint distribution, moving target selection, pointing accuracy},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173812,
author = {Kim, Yongkwan and An, Sang-Gyun and Lee, Joon Hyub and Bae, Seok-Hyung},
title = {Agile 3D Sketching with Air Scaffolding},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173812},
doi = {10.1145/3173574.3173812},
abstract = {Hand motion and pen drawing can be intuitive and expressive inputs for professional digital 3D authoring. However, their inherent limitations have hampered wider adoption. 3D sketching using hand motion is rapid but rough, and 3D sketching using pen drawing is delicate but tedious. Our new 3D sketching workflow combines these two in a complementary manner. The user makes quick hand motions in the air to generate approximate 3D shapes, and uses them as scaffolds on which to add details via pen-based 3D sketching on a tablet device. Our air scaffolding technique and corresponding algorithm extract only the intended shapes from unconstrained hand motions. Then, the user sketches 3D ideas by defining sketching planes on these scaffolds while appending new scaffolds, as needed. A user study shows that our progressive and iterative workflow enables more agile 3D sketching compared to ones using either hand motion or pen drawing alone.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3d sketching, hand motion, scaffolding, product design},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173813,
author = {Leiva, Luis A. and Mart\'{\i}n-Albo, Daniel and Plamondon, R\'{e}jean and Vatavu, Radu-Daniel},
title = {KeyTime: Super-Accurate Prediction of Stroke Gesture Production Times},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173813},
abstract = {We introduce KeyTime, a new technique and accompanying software for predicting the production times of users' stroke gestures articulated on touchscreens. KeyTime employs the principles and concepts of the Kinematic Theory, such as lognormal modeling of stroke gestures' velocity profiles, to estimate gesture production times significantly more accurately than existing approaches. Our experimental results obtained on several public datasets show that KeyTime predicts user-independent production times that correlate r=.99 with groundtruth from just one example of a gesture articulation, while delivering an average error in the predicted time magnitude that is 3 to 6 times smaller than that delivered by CLC, the best prediction technique up to date. Moreover, KeyTime reports a wide range of useful statistics, such as the trimmed mean, median, standard deviation, and confidence intervals, providing practitioners with unprecedented levels of accuracy and sophistication to characterize their users' a priori time performance with stroke gesture input.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173814,
author = {Dillahunt, Tawanna R. and Kameswaran, Vaishnav and McLain, Desiree and Lester, Minnie and Orr, Delores and Toyama, Kentaro},
title = {Entrepreneurship and the Socio-Technical Chasm in a Lean Economy},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173814},
doi = {10.1145/3173574.3173814},
abstract = {Online technologies are increasingly hailed as enablers of entrepreneurship and income generation. Recent evidence suggests, however, that even the best such tools disproportionately favor those with pre-existing entrepreneurial advantages. Despite intentions, the technology on its own seems far from addressing socio-economic inequalities. Using participatory action research, we investigated why this might be, in an intimate, close-up context. Over a 1-year period, we--a collaborative team of university researchers and residents of Detroit's East Side--worked to establish a neighborhood tour whose initial goal was to raise supplementary income and fundraise for community block clubs. We found that in addition to technical requirements, such as communication tools, a range of non-technological efforts is needed to manage projects, build self-efficacy, and otherwise support community participants. Our findings widen Ackerman's "socio-technical gap" for some contexts and offer a counterpoint to overgeneralized claims about well-designed technologies being able to address certain classes of social challenges.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {lean economies, social-technical gap, entrepreneurship},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173815,
author = {Marwecki, Sebastian and Brehm, Maximilian and Wagner, Lukas and Cheng, Lung-Pan and Mueller, Florian 'Floyd' and Baudisch, Patrick},
title = {VirtualSpace - Overloading Physical Space with Multiple Virtual Reality Users},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173815},
doi = {10.1145/3173574.3173815},
abstract = {Although virtual reality hardware is now widely available, the uptake of real walking is hindered by the fact that it requires often impractically large amounts of physical space. To address this, we present VirtualSpace, a novel system that allows overloading multiple users immersed in different VR experiences into the same physical space. VirtualSpace accomplishes this by containing each user in a subset of the physical space at all times, which we call tiles; app-invoked maneuvers then shuffle tiles and users across the entire physical space. This allows apps to move their users to where their narrative requires them to be while hiding from users that they are confined to a tile. We show how this enables VirtualSpace to pack four users into 16m2. In our study we found that VirtualSpace allowed participants to use more space and to feel less confined than in a control condition with static, pre-allocated space.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {locomotion, virtual reality, real walking},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173816,
author = {Dey, Sanorita and Karahalios, Karrie and Fu, Wai-Tat},
title = {Effects of Socially Stigmatized Crowdfunding Campaigns in Shaping Opinions},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173816},
doi = {10.1145/3173574.3173816},
abstract = {Donation-based crowdfunding platforms have an increasing number of campaigns on socially stigmatized topics. These platforms' widespread online reachability and the large flow of monetary donations have the potential to shape individuals' opinions by influencing their perceptions. However, little research has been done to investigate whether these campaigns impact individuals' opinions and how. We conducted an experiment to explore how an attitude-inconsistent campaign on fairness and equality for LGBTIQ people influenced participants' opinion on this topic. Although all the participants changed their perceived opinions after reading the support for the campaigns, participants opposing equality were less inclined to change their attitude than participants supporting equality. To examine this difference further, we conducted another experiment where participants were exposed to both attitude-consistent and attitude-inconsistent campaigns with varying levels of social support. Participants opposing equality showed less sensitivity to the level of social support, and wanted to donate significantly more money to anti-equality campaigns compared to those who supported equality. Results demonstrate the complex role of crowdfunding campaigns in shaping individuals' opinions on stigmatized topics.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {shaping opinions, stigmatized crowdfunding campaigns, social support, biased assimilation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173817,
author = {Wuertz, Jason and Alharthi, Sultan A. and Hamilton, William A. and Bateman, Scott and Gutwin, Carl and Tang, Anthony and Toups, Zachary and Hammer, Jessica},
title = {A Design Framework for Awareness Cues in Distributed Multiplayer Games},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173817},
doi = {10.1145/3173574.3173817},
abstract = {In the physical world, teammates develop situation awareness about each other's location, status, and actions through cues such as gaze direction and ambient noise. To support situation awareness, distributed multiplayer games provide awareness cues - information that games automatically make available to players to support cooperative gameplay. The design of awareness cues can be extremely complex, impacting how players experience games and work with teammates. Despite the importance of awareness cues, designers have little beyond experiential knowledge to guide their design. In this work, we describe a design framework for awareness cues, providing insight into what information they provide, how they communicate this information, and how design choices can impact play experience. Our research, based on a grounded theory analysis of current games, is the first to provide a characterization of awareness cues, providing a palette for game designers to improve design practice and a starting point for deeper research into collaborative play.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {workspace awareness, distributed multiplayer games, awareness cues, situation awareness, game design},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173818,
author = {Schneider, Hanna and Eiband, Malin and Ullrich, Daniel and Butz, Andreas},
title = {Empowerment in HCI - A Survey and Framework},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173818},
doi = {10.1145/3173574.3173818},
abstract = {Empowering people through technology is of increasing concern in the HCI community. However, there are different interpretations of empowerment, which diverge substantially. The same term thus describes an entire spectrum of research endeavours and goals. This conceptual unclarity hinders the development of a meaningful discourse and exchange. To better understand what empowerment means in our community, we reviewed 54 CHI full papers using the terms empower and empowerment. Based on our analysis and informed by prior writings on power and empowerment, we construct a framework that serves as a lens to analyze notions of empowerment in current HCI research. Finally, we discuss the implications of these notions of empowerment on approaches to technology design and offer recommendations for future work. With this analysis, we hope to add structure and terminological clarity to this growing and important facet of HCI research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {literature survey, empowerment, power, framework},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173819,
author = {Matulic, Fabrice and Vogel, Daniel},
title = {Multiray: Multi-Finger Raycasting for Large Displays},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173819},
doi = {10.1145/3173574.3173819},
abstract = {We explore and evaluate a multi-finger raycasting design space that we call "multiray". Each finger projects a ray on to the display, so the user is interacting from a distance using a form of direct input. Specifically, we propose techniques, where patterns of ray intersections created by hand postures form 2D geometric shapes to trigger actions and perform direct manipulations that go beyond single-point selections. Two formative studies examine characteristics of multi-finger raycasting for different projection methods, shapes, and tasks. Based on the results of those investigations, we demonstrate a number of dynamic UI controls and operations that utilise multiray points and shapes.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mid-air gestures, large displays, pointing, freehand gestures},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173820,
author = {Sadeghian Borojeni, Shadan and Boll, Susanne C.J. and Heuten, Wilko and B\"{u}lthoff, Heinrich H. and Chuang, Lewis},
title = {Feel the Movement: Real Motion Influences Responses to Take-over Requests in Highly Automated Vehicles},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173820},
doi = {10.1145/3173574.3173820},
abstract = {Take-over requests (TORs) in highly automated vehicles are cues that prompt users to resume control. TORs however, are often evaluated in non-moving driving simulators. This ignores the role of motion, an important source of information for users who have their eyes off the road while engaged in non-driving related tasks. We ran a user study in a moving-base driving simulator to investigate the effect of motion on TOR responses. We found that with motion, user responses to TORs vary depending on the road context where TORs are issued. While previous work showed that participants are fast to respond to urgent cues, we show that this is true only when TORs are presented on straight roads. Urgent cues issued on curved roads elicit slower responses than non-urgent cues on curved roads. Our findings indicate that TORs should be designed to be aware of road context to accommodate natural user responses.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {motion simulator, automated driving, take-over requests, motion cueing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173821,
author = {Weng, Di and Zhu, Heming and Bao, Jie and Zheng, Yu and Wu, Yingcai},
title = {HomeFinder Revisited: Finding Ideal Homes with Reachability-Centric Multi-Criteria Decision Making},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173821},
doi = {10.1145/3173574.3173821},
abstract = {Finding an ideal home is a difficult and laborious process. One of the most crucial factors in this process is the reachability between the home location and the concerned points of interest, such as places of work and recreational facilities. However, such importance is unrecognized in the extant real estate systems. By characterizing user requirements and analytical tasks in the context of finding ideal homes, we designed ReACH, a novel visual analytics system that assists people in finding, evaluating, and choosing a home based on multiple criteria, including reachability. In addition, we developed an improved data-driven model for approximating reachability with massive taxi trajectories. This model enables users to interactively integrate their knowledge and preferences to make judicious and informed decisions. We show the improvements in our model by comparing the theoretical complexities with the prior study and demonstrate the usability and effectiveness of the proposed system with task-based evaluation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {reachability, location selection, urban visual analytics},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173822,
author = {Miau, Daniel and Feiner, Steven},
title = {SpaceTokens: Interactive Map Widgets for Location-Centric Interactions},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173822},
doi = {10.1145/3173574.3173822},
abstract = {Map users often need to interact repetitively with multiple important locations. For example, a traveler may frequently check her hotel or a train station on a map, use them to localize an unknown location, or investigate routes involving them. Ironically, these location-centric tasks cannot be performed using locations directly; users must instead pan and zoom the map or use a menu to access locations. We propose SpaceTokens, interactive widgets that act as clones of locations, and which users can create and place on map edges like virtual whiteboard magnets. SpaceTokens make location a first-class citizen of map interaction. They empower users to rapidly perform location-centric tasks directly using locations: users can select combinations of on-screen locations and SpaceTokens to control the map window, or connect them to create routes. Participants in a study overwhelmingly preferred a SpaceTokens prototype over Google Maps on identical smartphones for the majority of tasks.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {maps, revisitation, location-centric interaction, navigation, bookmarks},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173823,
author = {Zheng, Jingjie and Bi, Xiaojun and Li, Kun and Li, Yang and Zhai, Shumin},
title = {M3 Gesture Menu: Design and Experimental Analyses of Marking Menus for Touchscreen Mobile Interaction},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173823},
doi = {10.1145/3173574.3173823},
abstract = {Despite their learning advantages in theory, marking menus have faced adoption challenges in practice, even on today's touchscreen-based mobile devices. We address these challenges by designing, implementing, and evaluating multiple versions of M3 Gesture Menu (M3), a reimagination of marking menus targeted at mobile interfaces. M3 is defined on a grid rather than in a radial space, relies on gestural shapes rather than directional marks, and has constant and stationary space use. Our first controlled experiment on expert performance showed M3 was faster and less error-prone by a factor of two than traditional marking menus. A second experiment on learning demonstrated for the first time that users could successfully transition to recall-based execution of a dozen commands after three ten-minute practice sessions with both M3 and Multi-Stroke Marking Menu. Together, M3, with its demonstrated resolution, learning, and space use benefits, contributes to the design and understanding of menu selection in the mobile-first era of end-user computing.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {novice to expert behavior transition, marking menu, gesture interface, smartphone},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173824,
author = {Carrasco, Matthew and Kerne, Andruid},
title = {Queer Visibility: Supporting LGBT+ Selective Visibility on Social Media},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173824},
doi = {10.1145/3173574.3173824},
abstract = {LGBT+ people adjust the presentation of their gender and sexual identities in response to social pressures, but their level of visibility differs between social media. We interviewed seventeen LGBT+ students at a socially-conservative university to investigate: (1) how do social media affect LGBT+ user experience of managing self presentation; and (2) how do social media affect participation in LGBT+ communities? We develop implications for design to support queering social media. (1) Give people abilities to present themselves with selective visibility, enabling choices about privacy and sharing, in contrast with the HCI design principle of indiscriminate 'making visible'. That is, enable participants to define their social media identities in their own ways. (2) Conduct studies, with a methodology likewise ensures that participants can define their gender and sexual identities in their own ways, rather than according to a predetermined vocabulary.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {networked public, privacy, queer, social media, impression management, lgbt},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173825,
author = {Hahn, Nathan and Chang, Joseph Chee and Kittur, Aniket},
title = {Bento Browser: Complex Mobile Search Without Tabs},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173825},
doi = {10.1145/3173574.3173825},
abstract = {People engaged in complex searches such as planning a vacation or understanding their medical symptoms are often overwhelmed by opening and managing many tabs. These challenges are exacerbated as search moves to smartphones and mobile devices where screen real-estate is limited and tasks are frequently suspended, resumed, and interleaved. Rather than continue to utilize tab-based browsing for complex search, we introduce a new way of browsing through a scaffolded interface. The list of search results serves as a mutable workspace, where a user can track progress on a specific information query. The search query serves as a gateway into this workspace, accessed through a task-subtask hierarchy. We instantiate this in the Bento mobile search system and investigate its effectiveness in three studies. We find converging evidence that users were able to make progress on their complex searching tasks with this structure, and find it more organized and easier to revisit.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {exploratory search, mobile, sensemaking},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173826,
author = {Qi, Jie and Buechley, Leah and Huang, Andrew "bunnie" and Ng, Patricia and Cross, Sean and Paradiso, Joseph A.},
title = {Chibitronics in the Wild: Engaging New Communities in Creating Technology with Paper Electronics},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173826},
doi = {10.1145/3173574.3173826},
abstract = {We share a study on the public adoption the Chibitronics circuit sticker toolkit, an open source, commercially available hardware toolkit for learning and creating electronics on paper. We examine sales data over a two-and-a-half-year period from November 2013, when the kit was launched commercially, to June 2016. We also look at publicly available project documentation from users during this period. We find that the Chibitronics user community confounds norms for traditional technology-making communities, especially in gender demographics. We explore the artifacts and types of documentation produced by users to learn about the various backgrounds, values, and goals of subcommunities, which includes educators, Makers, and crafters. In particular, we focus on artifacts from the craft community as a surprising and distinctive subset of technology creators. The diversity in public engagement shows how paper electronics tools like Chibitronics can be an effective approach for engaging new and broader audiences to participate in technology creation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {steam, chibitronics, do-it-yourself, hardware toolkits, education, maker movement, paper electronics, craft, stem, circuit stickers, inclusion, paper circuitry},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173827,
author = {Peng, Fengjiao and LaBelle, Veronica Crista and Yue, Emily Christen and Picard, Rosalind W.},
title = {A Trip to the Moon: Personalized Animated Movies for Self-Reflection},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173827},
doi = {10.1145/3173574.3173827},
abstract = {Self-tracking physiological and psychological data poses the challenge of presentation and interpretation. Insightful narratives for self-tracking data can motivate the user towards constructive self-reflection. One powerful form of narrative that engages audience across various culture and age groups is animated movies. We collected a week of self-reported mood and behavior data from each user and created in Unity a personalized animation based on their data. We evaluated the impact of their video in a randomized control trial with a non-personalized animated video as control. We found that personalized videos tend to be more emotionally engaging, encouraging greater and lengthier writing that indicated self-reflection about moods and behaviors, compared to non-personalized control videos.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {engagement, emotion, empathy, personalization, self-reflection, animation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173828,
author = {Hiniker, Alexis and Heung, Sharon S. and Hong, Sungsoo (Ray) and Kientz, Julie A.},
title = {Coco's Videos: An Empirical Investigation of Video-Player Design Features and Children's Media Use},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173828},
abstract = {In this study, we present Coco's Videos, a video-viewing platform for preschoolers designed to support them in learning to self-manage their media consumption. We report results from a three-week experimental deployment in 24 homes in which preschoolers used three different versions of the platform: one that is neutral to the limits they set, one that enforces the limits they set, and one that attempts to erode the limits they set by automatically playing additional content after the planned content is finished ("post-play"). We found that post-play significantly reduced children's autonomy and likelihood of self-regulation, extended video-viewing time, and led to increases in parent intervention. We found that the lock-out mechanism did not reduce video-viewing time or the likelihood of parent intervention. Together, our results suggest that avoiding platforms that work to undermine the user's intentions is more likely to help children self-regulate their media use than rigid parental controls.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173829,
author = {Buschek, Daniel and Bisinger, Benjamin and Alt, Florian},
title = {ResearchIME: A Mobile Keyboard Application for Studying Free Typing Behaviour in the Wild},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173829},
doi = {10.1145/3173574.3173829},
abstract = {We present a data logging concept, tool, and analyses to facilitate studies of everyday mobile touch keyboard use and free typing behaviour: 1) We propose a filtering concept to log typing without recording readable text and assess reactions to filters with a survey (N=349). 2) We release an Android keyboard app and backend that implement this concept. 3) Based on a three-week field study (N=30), we present the first analyses of keyboard use and typing biometrics on such free text typing data in the wild, including speed, postures, apps, auto correction, and word suggestions. We conclude that research on mobile keyboards benefits from observing free typing beyond the lab and discuss ideas for further studies.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {typing behaviour, biometrics, data logging, touch keyboard},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173830,
author = {Garcia, Brittany and Chu, Sharon Lynn and Nam, Beth and Banigan, Colin},
title = {Wearables for Learning: Examining the Smartwatch as a Tool for Situated Science Reflection},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173830},
doi = {10.1145/3173574.3173830},
abstract = {Relatively little research exists on the use of smartwatches to support learning. This paper presents an approach for commodity smartwatches as a tool for situated reflection in elementary school science. The approach was embodied in a smartwatch app called&nbsp;ScienceStories&nbsp;that allows students to voice record reflections about science concepts anytime, anywhere. We conducted a study with 18 fifth-grade children to investigate first, the effects of&nbsp;ScienceStories&nbsp;on students' science self-efficacy, and second the effects of different motivational structures (gamification, narrative-based, hybrid) designed into the smartwatch app on students' quality and quantity of use. Quantitative results showed&nbsp;ScienceStories&nbsp;increased science self-efficacy especially with a motivational structure. The gamified version had the highest quantity of use, while narrative performance performed worst. Qualitative findings described how students' recordings related to science topics and were contextualized. We discuss how our findings contribute to understanding of how to design smartwatch apps for educational purposes.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {science learning, everyday cognition, smartwatch, children, wearables, education, situated cognition},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173831,
author = {Hudson, Nathaniel and Lafreniere, Benjamin and Chilana, Parmit K. and Grossman, Tovi},
title = {Investigating How Online Help and Learning Resources Support Children's Use of 3D Design Software},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173831},
doi = {10.1145/3173574.3173831},
abstract = {3D design software is increasingly available to children through libraries, maker spaces, and for free on the web. This unprecedented availability has the potential to unleash children's creativity in cutting edge domains, but is limited by the steep learning curve of the software. Unfortunately, there is little past work studying the breakdowns faced by children in this domain-most past work has focused on adults in professional settings. In this paper, we present a study of online learning resources and help-seeking strategies available to children starting out with 3D design software. We find that children face a range of challenges when trying to learn 3D design independently-tutorials present instructions at a granularity that leads to overlooked and incorrectly-performed actions, and online help-seeking is largely ineffective due to challenges with query formulation and evaluating found information. Based on our findings, we recommend design directions for next-generation help and learning systems tailored to children.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {child-computer interaction, online help, software learning},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173832,
author = {Park, Gunhyuk and Choi, Seungmoon},
title = {Tactile Information Transmission by 2D Stationary Phantom Sensations},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173832},
abstract = {A phantom sensation refers to an illusory tactile sensation perceived midway between multiple distant stimulations on the skin. Phantom sensations have been used intensively in tactile interfaces owing to their simplicity and effectiveness. Despite that, the perceptual performance of phantom sensations is not completely understood, especially for 2D cases. This work is concerned with 2D stationary phantom sensations and their fundamental value as a means for information display. In User Study 1, we quantified the information transmission capacity using an absolute identification task of 2D phantom sensations. In User Study 2, we probed the distributions of the actual perceived positions of 2D phantom sensations. The investigations included both types of phantom sensations-within and out of the body. Our results provide general guidelines as to leveraging 2D phantom sensations in the design of spatial tactile display.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173833,
author = {Hoggenmueller, Marius and Tomitsch, Martin and Wiethoff, Alexander},
title = {Understanding Artefact and Process Challenges for Designing Low-Res Lighting Displays},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173833},
doi = {10.1145/3173574.3173833},
abstract = {Low-resolution (low-res) lighting displays are increasingly used by HCI researchers, designers, and in the industry as a versatile and aesthetic medium for deploying ambient interfaces in various contexts. These display types distinguish themselves from conventional high-res screens through: high contrasts, hi-power LED technology which allows visibility even in bright environments, and their ability to take on three-dimensional free forms. However, to date most work on low-res displays has been either of experimental nature or carried out in isolated industry contexts. This paper addresses this gap through an analysis of our own experiences from previous experimental design studies and related work, which led us to five domain challenges for designing low-res displays. We then describe how we approached these challenges in a deployment study, which involved the implementation of a prototype guided by a low-res prototyping toolkit. Based on an analysis of our design process and findings from the deployment study, we present ten design recommendations for low-res lighting displays.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {information design, low resolution display, ambient lighting systems},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173834,
author = {An, Byoungkwon and Tao, Ye and Gu, Jianzhe and Cheng, Tingyu and Chen, Xiang 'Anthony' and Zhang, Xiaoxiao and Zhao, Wei and Do, Youngwook and Takahashi, Shigeo and Wu, Hsiang-Yun and Zhang, Teng and Yao, Lining},
title = {Thermorph: Democratizing 4D Printing of Self-Folding Materials and Interfaces},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173834},
abstract = {We develop a novel method printing complex self-folding geometries. We demonstrated that with a desktop fused deposition modeling (FDM) 3D printer, off-the-shelf printing filaments and a design editor, we can print flat thermoplastic composites and trigger them to self-fold into 3D with arbitrary bending angles. This is a suitable technique, called Thermorph, to prototype hollow and foldable 3D shapes without losing key features. We describe a new curved folding origami design algorithm, compiling given arbitrary 3D models to 2D unfolded models in G-Code for FDM printers. To demonstrate the Thermorph platform, we designed and printed complex self-folding geometries (up to 70 faces), including 15 self-curved geometric primitives and 4 self-curved applications, such as chairs, the simplified Stanford Bunny and flowers. Compared to the standard 3D printing, our method saves up to 60% - 87% of the printing time for all shapes chosen.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173835,
author = {Newn, Joshua and Allison, Fraser and Velloso, Eduardo and Vetere, Frank},
title = {Looks Can Be Deceiving: Using Gaze Visualisation to Predict and Mislead Opponents in Strategic Gameplay},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173835},
doi = {10.1145/3173574.3173835},
abstract = {In competitive co-located gameplay, players use their opponents' gaze to make predictions about their plans while simultaneously managing their own gaze to avoid giving away their plans. This socially competitive dimension is lacking in most online games, where players are out of sight of each other. We conducted a lab study using a strategic online game; finding that (1) players are better at discerning their opponent's plans when shown a live visualisation of the opponent's gaze, and (2) players who are aware that their gaze is tracked will manipulate their gaze to keep their intentions hidden. We describe the strategies that players employed, to various degrees of success, to deceive their opponent through their gaze behaviour. This gaze-based deception adds an effortful and challenging aspect to the competition. Lastly, we discuss the various implications of our findings and its applicability for future game design.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {gaze visualisation, plan recognition, deception, nonverbal leakage, competitive gameplay, intent recognition},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173836,
author = {Thomas, Tyler W. and Tabassum, Madiha and Chu, Bill and Lipford, Heather},
title = {Security During Application Development: An Application Security Expert Perspective},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173836},
doi = {10.1145/3173574.3173836},
abstract = {Many of the security problems that people face today, such as security breaches and data theft, are caused by security vulnerabilities in application source code. Thus, there is a need to understand and improve the experiences of those who can prevent such vulnerabilities in the first place - software developers as well as application security experts. Several studies have examined developers' perceptions and behaviors regarding security vulnerabilities, demonstrating the challenges they face in performing secure programming and utilizing tools for vulnerability detection. We expand upon this work by focusing on those primarily responsible for application security - security auditors. In an interview study of 32 application security experts, we examine their views on application security processes, their workflows, and their interactions with developers in order to further inform the design of tools and processes to improve application security.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {software development, secure programming, security vulnerabilities, application security experts},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173837,
author = {Reinschluessel, Anke V. and Herrlich, Marc and D\"{o}ring, Tanja and Vangel, Mark and Tempany, Clare and Malaka, Rainer and Tokuda, Junichi},
title = {Insert Needle Here! A Custom Display for Optimized Biopsy Needle Placement},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173837},
abstract = {Needle-guiding templates are used for a variety of minimally invasive medical interventions. While physically supporting needle placement with a grid of holes, they lack integrated information where needles need to be inserted. Physicians must manually determine the correct holes based on the output of planning software - a workflow that is error-prone and lengthy. We address these issues by embedding a display into the template using electroluminescence (EL) screen printing. The EL display is connected to planning software and illuminates the correct hole. In an empirical evaluation with physicians and researchers from the medical domain, we compare the illuminated against the conventional template as used in magnetic resonance imaging (MRI) guided prostate biopsies. Our results show that the EL display significantly improves task completion time by 51%, task load by 47% and usability by 30%.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8}
}

@inproceedings{10.1145/3173574.3173838,
author = {Feldman, Molly Q. and Cho, Ji Yong and Ong, Monica and Gulwani, Sumit and Popovi\'{c}, Zoran and Andersen, Erik},
title = {Automatic Diagnosis of Students' Misconceptions in K-8 Mathematics},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173838},
doi = {10.1145/3173574.3173838},
abstract = {K-8 mathematics students must learn many procedures, such as addition and subtraction. Students frequently learn "buggy' variations of these procedures, which we ideally could identify automatically. This is challenging because there are many possible variations that reflect deep compositions of procedural thought. Existing approaches for K-8 math use manually specified variations which do not scale to new math algorithms or previously unseen misconceptions. Our system examines students' answers and infers how they incorrectly combine basic skills into complex procedures. We evaluate this approach on data from approximately 300 students. Our system replicates 86% of the answers that contain clear systematic mistakes (13%). Investigating further, we found 77% at least partially replicate a known misconception, with 53% matching exactly. We also present data from 29 participants showing that our system can demonstrate inferred incorrect procedures to an educator as successfully as a human expert.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {elementary education, programming by demonstration},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173839,
author = {Kariryaa, Ankit and Johnson, Isaac and Sch\"{o}ning, Johannes and Hecht, Brent},
title = {Defining and Predicting the Localness of Volunteered Geographic Information Using Ground Truth Data},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173839},
doi = {10.1145/3173574.3173839},
abstract = {Many applications of geotagged content are predicated on the concept of localness (e.g., local restaurant recommendation, mining social media for local perspectives on an issue). However, definitions of who is a "local" in a given area are typically informal and ad-hoc and, as a result, approaches for localness assessment that have been used in the past have not been formally validated. In this paper, we begin the process of addressing these gaps in the literature. Specifically, we (1) formalize definitions of "local" using themes identified in a 30-paper literature review, (2) develop the first ground truth localness dataset consisting of 132 Twitter users and 58,945 place-tagged tweets, and (3) use this dataset to evaluate existing localness assessment approaches. Our results provide important methodological guidance to the large body of research and practice that depends on the concept of localness and suggest means by which localness assessment can be improved.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {localness, twitter, geographic hci, placetag},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173840,
author = {Melcer, Edward F. and Isbister, Katherine},
title = {Bots &amp; (Main)Frames: Exploring the Impact of Tangible Blocks and Collaborative Play in an Educational Programming Game},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173840},
doi = {10.1145/3173574.3173840},
abstract = {While recent work has begun to evaluate the efficacy of educational programming games, many common design decisions in these games (e.g., single player gameplay using touchpad or mouse) have not been explored for learning outcomes. For instance, alternative design approaches such as collaborative play and embodied interaction with tangibles may also provide important benefits to learners. To better understand how these design decisions impact learning and related factors, we created an educational programming game that allows for systematically varying input method and mode of play. In this paper, we describe design rationale for mouse and tangible versions of our game, and report a 2x2 factorial experiment comparing efficacy of mouse and tangible input methods with individual and collaborative modes of play. Results indicate tangibles have a greater positive impact on learning, situational interest, enjoyment, and programming self-beliefs. We also found collaborative play helps further reduce programming anxiety over individual play.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {embodied interaction, collaborative play, tangibles, physical embodiment, educational programming game},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173841,
author = {McNaney, Roisin and Bull, Christopher and Mackie, Lynne and Dahman, Floriane and Stringer, Helen and Richardson, Dan and Welsh, Daniel},
title = {StammerApp: Designing a Mobile Application to Support Self-Reflection and Goal Setting for People Who Stammer},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173841},
doi = {10.1145/3173574.3173841},
abstract = {Stammering is a speech disorder affecting approximately 1% of the worldwide population. It can have associated impacts on daily life, such as loss of confidence in social situations and increased anxiety levels (particularly when speaking to strangers). Work exploring the development of digital tools to support people who stammer (PwS) is emerging. However, there is a paucity of research engaging PwS in the design process, with participation being facilitated mainly in testing phases. In this paper, we describe the user-centered design, development and evaluation of StammerApp, a mobile application to support PwS. We contribute insights into the challenges and barriers that PwS experience day-to-day and reflect on the complexities of designing with this diverse group. Finally, we present a set of design recommendations for the development of tools to support PwS in their everyday interactions, and provide an example of how these might be envisioned through the StammerApp prototype.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mobile applications, self-management, speech and language therapy, stammering, user-centered design},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173842,
author = {Wijesekera, Primal and Reardon, Joel and Reyes, Irwin and Tsai, Lynn and Chen, Jung-Wei and Good, Nathan and Wagner, David and Beznosov, Konstantin and Egelman, Serge},
title = {Contextualizing Privacy Decisions for Better Prediction (and Protection)},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173842},
abstract = {Modern mobile operating systems implement an ask-on-first-use policy to regulate applications' access to private user data: the user is prompted to allow or deny access to a sensitive resource the first time an app attempts to use it. Prior research shows that this model may not adequately capture user privacy preferences because subsequent requests may occur under varying contexts. To address this shortcoming, we implemented a novel privacy management system in Android, in which we use contextual signals to build a classifier that predicts user privacy preferences under various scenarios. We performed a 37-person field study to evaluate this new permission model under normal device usage. From our exit interviews and collection of over 5 million data points from participants, we show that this new permission model reduces the error rate by 75% (i.e., fewer privacy violations), while preserving usability. We offer guidelines for how platforms can better support user privacy decision making.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173843,
author = {Fender, Andreas and Herholz, Philipp and Alexa, Marc and M\"{u}ller, J\"{o}rg},
title = {OptiSpace: Automated Placement of Interactive 3D Projection Mapping Content},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173843},
doi = {10.1145/3173574.3173843},
abstract = {We present OptiSpace, a system for the automated placement of perspectively corrected projection mapping content. We analyze the geometry of physical surfaces and the viewing behavior of users over time using depth cameras. Our system measures user view behavior and simulates a virtual projection mapping scene users would see if content were placed in a particular way. OptiSpace evaluates the simulated scene according to perceptual criteria, including visibility and visual quality of virtual content. Finally, based on these evaluations, it optimizes content placement, using a two-phase procedure involving adaptive sampling and the covariance matrix adaptation algorithm. With our proposed architecture, projection mapping applications are developed without any knowledge of the physical layouts of the target environments. Applications can be deployed in different uncontrolled environments, such as living rooms and office spaces.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {view behavior, 3d projection mapping, multi-display environments, content placement},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173844,
author = {Kaptelinin, Victor},
title = {Technology and the Givens of Existence: Toward an Existential Inquiry Framework in HCI Research},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173844},
doi = {10.1145/3173574.3173844},
abstract = {The profound impact of digital technologies on human life makes it imperative for HCI research to deal with the most fundamental aspects of human existence. Arguably, insights from existential philosophy and psychology are highly relevant for addressing such issues. Building on previous attempts to bring in existential themes and terminology to HCI, this paper argues that Yalom's notion of "the givens of existence", as well as related work in experimental existential psychology, can inform the development of an existential inquiry framework in HCI. The envisioned framework is intended to complement current approaches in HCI by specifically focusing on the existential aspects of the design and use of technology. The paper reflects on possible ways, in which existential concepts can support HCI research, and maintains that adopting an existential framework in HCI would be consistent with the overall conceptual development of the field.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {immortality project, end-of-life studies, existentialism, authenticity, hci theory, identity, experimental existential psychology, givens of existence},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173845,
author = {Kosch, Thomas and Woundefinedniak, Pawe\l{} W. and Brady, Erin and Schmidt, Albrecht},
title = {Smart Kitchens for People with Cognitive Impairments: A Qualitative Study of Design Requirements},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173845},
abstract = {Individuals with cognitive impairments currently leverage extensive human resources during their transitions from assisted living to independent living. In Western Europe, many government-supported volunteer organizations provide sheltered living facilities; supervised environments in which people with cognitive impairments collaboratively learn daily living skills. In this paper, we describe communal cooking practices in sheltered living facilities and identify opportunities for supporting these with interactive technology to reduce volunteer workload. We conducted two contextual observations of twelve people with cognitive impairments cooking in sheltered living facilities and supplemented this data through interviews with four employees and volunteers who supervise them. Through thematic analysis, we identified four themes to inform design requirements for communal cooking activities: Work organization, community, supervision, and practicalities. Based on these, we present five design implications for assistive systems in kitchens for people with cognitive deficiencies.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3173846,
author = {Reda, Khairi and Nalawade, Pratik and Ansah-Koi, Kate},
title = {Graphical Perception of Continuous Quantitative Maps: The Effects of Spatial Frequency and Colormap Design},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173846},
abstract = {Continuous 'pseudocolor' maps visualize how a quantitative attribute varies smoothly over space. These maps are widely used by experts and lay citizens alike for communicating scientific and geographical data. A critical challenge for designers of these maps is selecting a color scheme that is both effective and aesthetically pleasing. Although there exist empirically grounded guidelines for color choice in segmented maps (e.g., choropleths), continuous maps are significantly understudies, and their color-coding guidelines are largely based on expert opinion and design heuristics--many of these guidelines have yet to be verified experimentally. We conducted a series of crowdsourced experiments to investigate how the perception of continuous maps is affected by colormap characteristics and spatial frequency (a measure of data complexity). We find that spatial frequency significantly impacts the effectiveness of color encodes, but the precise effect is task-dependent. While rainbow schemes afforded the highest accuracy in quantity estimation irrespective of spatial complexity, divergent colormaps significantly outperformed other schemes in tasks requiring the perception of high-frequency patterns. We interpret these results in relation to current practices, and devise new and more granular guidelines for color mapping in continuous maps.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173847,
author = {Zhang, Yang and Yang, Chouchang (Jack) and Hudson, Scott E. and Harrison, Chris and Sample, Alanson},
title = {Wall++: Room-Scale Interactive and Context-Aware Sensing},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173847},
doi = {10.1145/3173574.3173847},
abstract = {Human environments are typified by walls, homes, offices, schools, museums, hospitals and pretty much every indoor context one can imagine has walls. In many cases, they make up a majority of readily accessible indoor surface area, and yet they are static their primary function is to be a wall, separating spaces and hiding infrastructure. We present Wall++, a low-cost sensing approach that allows walls to become a smart infrastructure. Instead of merely separating spaces, walls can now enhance rooms with sensing and interactivity. Our wall treatment and sensing hardware can track users' touch and gestures, as well as estimate body pose if they are close. By capturing airborne electromagnetic noise, we can also detect what appliances are active and where they are located. Through a series of evaluations, we demonstrate Wall++ can enable robust room-scale interactive and context-aware applications.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {gestures, smart environments, indoor localization, context aware, touch sensing, internet of things, user identification, em sensing, pose estimation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173848,
author = {Chuang, Yaliang and Chen, Lin-Lin and Liu, Yoga},
title = {Design Vocabulary for Human--IoT Systems Communication},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173848},
abstract = {Digital devices and intelligent systems are becoming popular and ubiquitous all around us. However, they seldom provide sufficient feed-forwards and feedbacks to reassure users as to their current status and indicate what actions they are about to perform. In this study, we selected and analyzed nine concept videos on future IoT products/systems. Through systematic analysis of the interactions and communications of users with the machines and systems demonstrated in the films, we extracted 38 design vocabulary items and clustered them into 12 groups: Active, Request, Trigger functions, Approve, Reject, Notify, Recommend, Guide, Show problems, Express emotions, Exchange info, and Socialize. This framework can not only inspire designers to create self-explanatory intelligence, but also support developers to provide a language structure at different levels of the periphery of human attention. Through the enhancement of situated awareness, human IoT system interaction can become more seamless and graceful.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inproceedings{10.1145/3173574.3173849,
author = {Marshall, Matthew and Vines, John and Wright, Pete and Kirk, David S. and Lowe, Toby and Wilson, Rob},
title = {Accountability Work: Examining the Values, Technologies and Work Practices That Facilitate Transparency in Charities},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173849},
doi = {10.1145/3173574.3173849},
abstract = {Charities are subject to stringent transparency and accountability requirements from government and funders to ensure that they are conducting work and spending money appropriately. Charities are increasingly important to civic life and have unique characteristics as organisations. This provides a rich space in which HCI research may learn from and affect both held notions of transparency and accountability, and the relationships between these organisations and their stakeholders. We conducted ethnographic fieldwork and workshops over a seven month period at a charity. We aimed to understand how the transparency obligations of a charity manifest through work and how the workers of a charity reason about transparency and accountability as an everyday practice. Our findings highlight how organisations engage in presenting different accounts of their work; how workers view their legal transparency obligations in contrast with their accountability to their everyday community; and how their labour does not translate well to outcome measures or metrics. We discuss implications for the design of future systems that support organisations to produce accounts of their work as part of everyday practice.support organisations to produce accounts of their work as part of everyday practice.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {civics, third sector, work practice, accountability, ethnography, transparency},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173850,
author = {Hosio, Simo Johannes and Karppinen, Jaro and Takala, Esa-Pekka and Takatalo, Jani and Goncalves, Jorge and van Berkel, Niels and Konomi, Shin'ichi and Kostakos, Vassilis},
title = {Crowdsourcing Treatments for Low Back Pain},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173850},
doi = {10.1145/3173574.3173850},
abstract = {Low back pain (LBP) is a globally common condition with no silver bullet solutions. Further, the lack of therapeutic consensus causes challenges in choosing suitable solutions to try. In this work, we crowdsourced knowledge bases on LBP treatments. The knowledge bases were used to rank and offer best-matching LBP treatments to end users. We collected two knowledge bases: one from clinical professionals and one from non-professionals. Our quantitative analysis revealed that non-professional end users perceived the best treatments by both groups as equally good. However, the worst treatments by non-professionals were clearly seen as inferior to the lowest ranking treatments by professionals. Certain treatments by professionals were also perceived significantly differently by non-professionals and professionals themselves. Professionals found our system handy for self-reflection and for educating new patients, while non-professionals appreciated the reliable decision support that also respected the non-professional opinion.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {low back pain, health information, crowdsourcing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173851,
author = {Huber, Bernd and McDuff, Daniel and Brockett, Chris and Galley, Michel and Dolan, Bill},
title = {Emotional Dialogue Generation Using Image-Grounded Language Models},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173851},
doi = {10.1145/3173574.3173851},
abstract = {Computer-based conversational agents are becoming ubiquitous. However, for these systems to be engaging and valuable to the user, they must be able to express emotion, in addition to providing informative responses. Humans rely on much more than language during conversations; visual information is key to providing context. We present the first example of an image-grounded conversational agent using visual sentiment, facial expression and scene features. We show that key qualities of the generated dialogue can be manipulated by the features used for training the agent. We evaluate our model on a large and very challenging real-world dataset of conversations from social media (Twitter). The image-grounding leads to significantly more informative, emotional and specific responses, and the exact qualities can be tuned depending on the image features used. Furthermore, our model improves the objective quality of dialogue responses when evaluated on standard natural language metrics.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {conversational agents, emotion, computer vision, dialogue, conversation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173852,
author = {Ahn, June and Clegg, Tamara and Yip, Jason and Bonsignore, Elizabeth and Pauw, Daniel and Cabrera, Lautaro and Hernly, Kenna and Pitt, Caroline and Mills, Kelly and Salazar, Arturo and Griffing, Diana and Rick, Jeff and Marr, Rachael},
title = {Science Everywhere: Designing Public, Tangible Displays to Connect Youth Learning Across Settings},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173852},
doi = {10.1145/3173574.3173852},
abstract = {A major challenge in education is understanding how to connect learning experiences across settings (e.g., school, afterschool, and home) for youth. In this paper, we introduce and describe the participatory design process we undertook to develop Science Everywhere (SE), which is a sociotechnical system where children share their everyday science learning via social media. Public displays installed throughout the neighborhood invite parents, adults, peers, and community members to interact with children's ideas to better develop connections for learning across settings. Our case study of community interactions with the public displays illuminate how these technologies encouraged behaviors such as the noticing of children's ideas, recognition of people in the neighborhood, and bridging to new learning opportunities for youth.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pervasive displays, children, learning, public displays, community},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173853,
author = {Yoo, Daisy and Kantengwa, Odeth and Logler, Nick and Interayamahanga, Reverien and Nkurunziza, Joseph and Friedman, Batya},
title = {Collaborative Reflection: A Practice for Enriching Research Partnerships Spanning Culture, Discipline, and Time},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173853},
abstract = {All too often, research partnerships are project-driven and short-lived. Multi-lifespan design and other longer-term approaches offer alternative models. In this paper, we contribute one alternative model for cross-boundary research partnerships spanning longer timeframes and offer one best practice: collaborative reflection. Specifically, we provide an in-depth case study of a multi-lifespan design partnership (over nine years and ongoing) between a Rwandan NGO focused on peacebuilding and a US university research group focused on information design theory and method. First, we document our process for conducting a collaborative reflection that seeks balance among the contributors while navigating differences in culture, discipline, experience, and skills. Next, we reflect on five themes: (1) common ground: sensibilities and commitments; (2) trust; (3) research landscape: crossing nations and institutions; (4) research as a healing mechanism; and (5) multi-lifespan design partnership. We conclude with a discussion of overarching considerations for design researchers who engage in cross-boundary research partnership.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inproceedings{10.1145/3173574.3173854,
author = {Khamis, Mohamed and Baier, Anita and Henze, Niels and Alt, Florian and Bulling, Andreas},
title = {Understanding Face and Eye Visibility in Front-Facing Cameras of Smartphones Used in the Wild},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173854},
doi = {10.1145/3173574.3173854},
abstract = {Commodity mobile devices are now equipped with high-resolution front-facing cameras, allowing applications in biometrics (e.g., FaceID in the iPhone X), facial expression analysis, or gaze interaction. However, it is unknown how often users hold devices in a way that allows capturing their face or eyes, and how this impacts detection accuracy. We collected 25,726 in-the-wild photos, taken from the front-facing camera of smartphones as well as associated application usage logs. We found that the full face is visible about 29% of the time, and that in most cases the face is only partially visible. Furthermore, we identified an influence of users' current activity; for example, when watching videos, the eyes but not the entire face are visible 75% of the time in our dataset. We found that a state-of-the-art face detection algorithm performs poorly against photos taken from front-facing cameras. We discuss how these findings impact mobile applications that leverage face and eye detection, and derive practical implications to address state-of-the art's limitations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {eye tracking, face detection, front-facing camera, mobile device, in the wild study, gaze estimation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173855,
author = {Feick, Martin and Mok, Terrance and Tang, Anthony and Oehlberg, Lora and Sharlin, Ehud},
title = {Perspective on and Re-Orientation of Physical Proxies in Object-Focused Remote Collaboration},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173855},
doi = {10.1145/3173574.3173855},
abstract = {Remote collaborators working together on physical objects have difficulty building a shared understanding of what each person is talking about. Conventional video chat systems are insufficient for many situations because they present a single view of the object in a flattened image. To understand how this limited perspective affects collaboration, we designed the Remote Manipulator (ReMa), which can reproduce orientation manipulations on a proxy object at a remote site. We conducted two studies with ReMa, with two main findings. First, a shared perspective is more effective and preferred compared to the opposing perspective offered by conventional video chat systems. Second, the physical proxy and video chat complement one another in a combined system: people used the physical proxy to understand objects, and used video chat to perform gestures and confirm remote actions.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cscw, collaborative physical tasks, remote collaboration, physical telepresence, object-focused collaboration},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173856,
author = {Duchowski, Andrew T. and Krejtz, Krzysztof and Krejtz, Izabela and Biele, Cezary and Niedzielska, Anna and Kiefer, Peter and Raubal, Martin and Giannopoulos, Ioannis},
title = {The Index of Pupillary Activity: Measuring Cognitive Load <i>Vis-\`{a}-Vis</i> Task Difficulty with Pupil Oscillation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173856},
doi = {10.1145/3173574.3173856},
abstract = {A novel eye-tracked measure of the frequency of pupil diameter oscillation is proposed for capturing what is thought to be an indicator of cognitive load. The proposed metric, termed the Index of Pupillary Activity, is shown to discriminate task difficulty vis-a-vis cognitive load (if the implied causality can be assumed) in an experiment where participants performed easy and difficult mental arithmetic tasks while fixating a central target (a requirement for replication of prior work). The paper's contribution is twofold: full documentation is provided for the calculation of the proposed measurement which can be considered as an alternative to the existing proprietary Index of Cognitive Activity (ICA). Thus, it is possible for researchers to replicate the experiment and build their own software which implements this measurement. Second, several aspects of the ICA are approached in a more data-sensitive way with the goal of improving the measurement's performance.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {pupillometry, eye tracking, task difficulty},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173857,
author = {Fiannaca, Alexander J. and Paradiso, Ann and Campbell, Jon and Morris, Meredith Ringel},
title = {Voicesetting: Voice Authoring UIs for Improved Expressivity in Augmentative Communication},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173857},
abstract = {Alternative and augmentative communication (AAC) systems used by people with speech disabilities rely on text-to-speech (TTS) engines for synthesizing speech. Advances in TTS systems allowing for the rendering of speech with a range of emotions have yet to be incorporated into AAC systems, leaving AAC users with speech that is mostly devoid of emotion and expressivity. In this work, we describe voicesetting as the process of authoring the speech properties of text. We present the design and evaluation of two voicesetting user interfaces: the Expressive Keyboard, designed for rapid addition of expressivity to speech, and the Voicesetting Editor, designed for more careful crafting of the way text should be spoken. We evaluated the perceived output quality, requisite effort, and usability of both interfaces; the concept of voicesetting and our interfaces were highly valued by end-users as an enhancement to communication quality. We close by discussing design insights from our evaluations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3173858,
author = {Hitron, Tom and David, Idan and Ofer, Netta and Grishko, Andrey and Wald, Iddo Yehoshua and Erel, Hadas and Zuckerman, Oren},
title = {Digital Outdoor Play: Benefits and Risks from an Interaction Design Perspective},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173858},
abstract = {Outdoor play has been proven to be beneficial for children's development. HCI research on Heads-Up Games suggests that the well-known decline in outdoor play can be addressed by adding technology to such activities. However, outdoor play benefits such as social interaction, creative thinking, and physical activity may be compromised when digital features are added. We present the design &amp; implementation of a novel digitally-enhanced outdoor-play prototype. Our evaluation with 48 children revealed that a non-digital version of the novel outdoor play object afforded social play and game invention. Evaluation of the digitally-enhanced version showed reduced collaborative social interaction and reduced creative thinking when compared with baseline. However, we showed that specific sensing and feedback features better supported outdoor play benefits. For example non-accumulated feedback was shown to increase collaborative play and creative thinking in comparison to accumulated feedback. We provide evidence-based recommendations for designers of outdoor play technologies.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173859,
author = {Wang, Xu and Lafreniere, Benjamin and Grossman, Tovi},
title = {Leveraging Community-Generated Videos and Command Logs to Classify and Recommend Software Workflows},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173859},
doi = {10.1145/3173574.3173859},
abstract = {Users of complex software applications often rely on inefficient or suboptimal workflows because they are not aware that better methods exist. In this paper, we develop and validate a hierarchical approach combining topic modeling and frequent pattern mining to classify the workflows offered by an application, based on a corpus of community-generated videos and command logs. We then propose and evaluate a design space of four different workflow recommender algorithms, which can be used to recommend new workflows and their associated videos to software users. An expert validation of the task classification approach found that 82% of the time, experts agreed with the classifications. We also evaluate our workflow recommender algorithms, demonstrating their potential and suggesting avenues for future work.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {community-generated videos, application logs, topic modeling, workflow recommendation, software learning},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173860,
author = {Alvarado, Oscar and Waern, Annika},
title = {Towards Algorithmic Experience: Initial Efforts for Social Media Contexts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173860},
abstract = {Algorithms influence most of our daily activities, decisions, and they guide our behaviors. It has been argued that algorithms even have a direct impact on democratic societies. Human - Computer Interaction research needs to develop analytical tools for describing the interaction with, and experience of algorithms. Based on user participatory workshops focused on scrutinizing Facebook's newsfeed, an algorithm-influenced social media, we propose the concept of Algorithmic Experience (AX) as an analytic framing for making the interaction with and experience of algorithms explicit. Connecting it to design, we articulate five functional categories of AX that are particularly important to cater for in social media: profiling transparency and management, algorithmic awareness and control, and selective algorithmic memory.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3173861,
author = {Khamis, Mohamed and Becker, Christian and Bulling, Andreas and Alt, Florian},
title = {Which One is Me? Identifying Oneself on Public Displays},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173861},
abstract = {While user representations are extensively used on public displays, it remains unclear how well users can recognize their own representation among those of surrounding users. We study the most widely used representations: abstract objects, skeletons, silhouettes and mirrors. In a prestudy (N=12), we identify five strategies that users follow to recognize themselves on public displays. In a second study (N=19), we quantify the users' recognition time and accuracy with respect to each representation type. Our findings suggest that there is a significant effect of (1) the representation type, (2) the strategies performed by users, and (3) the combination of both on recognition time and accuracy. We discuss the suitability of each representation for different settings and provide specific recommendations as to how user representations should be applied in multi-user scenarios. These recommendations guide practitioners and researchers in selecting the representation that optimizes the most for the deployment's requirements, and for the user strategies that are feasible in that environment.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173862,
author = {Pfeuffer, Ken and Li, Yang},
title = {Analysis and Modeling of Grid Performance on Touchscreen Mobile Devices},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173862},
doi = {10.1145/3173574.3173862},
abstract = {Touchscreen mobile devices can afford rich interaction behaviors but they are complex to model. Scrollable two-dimensional grids are a common user interface on mobile devices that allow users to access a large number of items on a small screen by direct touch. By analyzing touch input and eye gaze of users during grid interaction, we reveal how multiple performance components come into play in such a task, including navigation, visual search and pointing. These findings inspired us to design a novel predictive model that combines these components for modeling grid tasks. We realized these model components by employing both traditional analytical methods and data-driven machine learning approaches. In addition to showing high accuracy achieved by our model in predicting human performance on a test dataset, we demonstrate how such a model can lead to a significant reduction in interaction time when used in a predictive user interface.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {predictive interfaces, machine learning, grid ui, performance modeling, touchscreen mobile device},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173863,
author = {Smith, Harrison Jesse and Neff, Michael},
title = {Communication Behavior in Embodied Virtual Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173863},
doi = {10.1145/3173574.3173863},
abstract = {Embodied virtual reality faithfully renders users' movements onto an avatar in a virtual 3D environment, supporting nuanced nonverbal behavior alongside verbal communication. To investigate communication behavior within this medium, we had 30 dyads complete two tasks using a shared visual workspace: negotiating an apartment layout and placing model furniture on an apartment floor plan. Dyads completed both tasks under three different conditions: face-to-face, embodied VR with visible full-body avatars, and no embodiment VR, where the participants shared a virtual space, but had no visible avatars. Both subjective measures of users' experiences and detailed annotations of verbal and nonverbal behavior are used to understand how the media impact communication behavior. Embodied VR provides a high level of social presence with conversation patterns that are very similar to face-to-face interaction. In contrast, providing only the shared environment was generally found to be lonely and appears to lead to degraded communication.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {embodiment, social presence, virtual reality, computer-mediated communication, vr},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173864,
author = {Giglitto, Danilo and Lazem, Shaimaa and Preston, Anne},
title = {In the Eye of the Student: An Intangible Cultural Heritage Experience, with a Human-Computer Interaction Twist},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173864},
abstract = {We critically engage with CHI communities emerging outside the global North (ArabHCI and AfriCHI) to explore how participation is configured and enacted within socio-cultural and political contexts fundamentally different from Western societies. We contribute to recent discussions about postcolonialism and decolonization of HCI by focusing on non-Western future technology designers. Our lens was a course designed to engage Egyptian students with a local yet culturally-distant community to design applications for documenting intangible heritage. Through an action research, the instructors reflect on selected students' activities. Despite deploying a flexible learning curriculum that encourages greater autonomy, the students perceived themselves with less agency than other institutional stakeholders involved in the project. Further, some of them struggled to empathize with the community as the impact of the cultural differences on configuring participation was profound. We discuss the implications of the findings on HCI education and in international cross-cultural design projects.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3173865,
author = {Siu, Alexa F. and Gonzalez, Eric J. and Yuan, Shenli and Ginsberg, Jason B. and Follmer, Sean},
title = {ShapeShift: 2D Spatial Manipulation and Self-Actuation of Tabletop Shape Displays for Tangible and Haptic Interaction},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173865},
abstract = {We explore interactions enabled by 2D spatial manipulation and self-actuation of a tabletop shape display. To explore these interactions, we developed shapeShift, a compact, high-resolution (7 mm pitch), mobile tabletop shape display. shapeShift can be mounted on passive rollers allowing for bimanual interaction where the user can freely manipulate the system while it renders spatially relevant content. shapeShift can also be mounted on an omnidirectional-robot to provide both vertical and lateral kinesthetic feedback, display moving objects, or act as an encountered-type haptic device for VR. We present a study on haptic search tasks comparing spatial manipulation of a shape display for egocentric exploration of a map versus exploration using a fixed display and a touch pad. Results show a 30% decrease in navigation path lengths, 24% decrease in task time, 15% decrease in mental demand and 29% decrease in frustration in favor of egocentric navigation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3173574.3173866,
author = {Sun, Na and Rosson, Mary Beth and Carroll, John M.},
title = {Where is Community Among Online Learners? Identity, Efficacy and Personal Ties},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173866},
abstract = {Research questions about community among online learners are gaining importance as enrollments in online programs explode. However, what community means for this context has not been studied in a comprehensive way. We contribute a quantitative study of learners' feelings and behavior expectations about online community, adapting scales for sense of community (SOC) and developing an instrument to assess community collective efficacy (CCE). Our analysis of students' responses to these scales revealed two factors underlying SOC (shared identity and interpersonal friendship) and three factors underlying CCE (identity regulation, coordination and social support). We used these factors to discuss contrasting definitions of community (shared identity versus ego networks). Exploratory data analyses also revealed relationships to other student variables that begin to articulate roles and mechanisms for online students' felt community, and raise design implications about what we might do with and for the community structure.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173867,
author = {Peng, Yi-Hao and Hsi, Ming-Wei and Taele, Paul and Lin, Ting-Yu and Lai, Po-En and Hsu, Leon and Chen, Tzu-chuan and Wu, Te-Yen and Chen, Yu-An and Tang, Hsien-Hui and Chen, Mike Y.},
title = {SpeechBubbles: Enhancing Captioning Experiences for Deaf and Hard-of-Hearing People in Group Conversations},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173867},
doi = {10.1145/3173574.3173867},
abstract = {Deaf and hard-of-hearing (DHH) individuals encounter difficulties when engaged in group conversations with hearing individuals, due to factors such as simultaneous utterances from multiple speakers and speakers whom may be potentially out of view. We interviewed and co-designed with eight DHH participants to address the following challenges: 1) associating utterances with speakers, 2) ordering utterances from different speakers, 3) displaying optimal content length, and 4) visualizing utterances from out-of-view speakers. We evaluated multiple designs for each of the four challenges through a user study with twelve DHH participants. Our study results showed that participants significantly preferred speechbubble visualizations over traditional captions. These design preferences guided our development of SpeechBubbles, a real-time speech recognition interface prototype on an augmented reality head-mounted display. From our evaluations, we further demonstrated that DHH participants preferred our prototype over traditional captions for group conversations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {augmented reality, word balloons, accessibility, deaf and hard of hearing, closed captions, text bubbles, hololens},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173868,
author = {Cambre, Julia and Klemmer, Scott and Kulkarni, Chinmay},
title = {Juxtapeer: Comparative Peer Review Yields Higher Quality Feedback and Promotes Deeper Reflection},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173868},
doi = {10.1145/3173574.3173868},
abstract = {Peer review asks novices to take on an evaluator's role, yet novices often lack the perspective to accurately assess the quality of others' work. To help learners give feedback on their peers' work through an expert lens, we present the Juxtapeer peer review system for structured comparisons. We build on theories of learning through contrasting cases, and contribute the first systematic evaluation of comparative peer review. In a controlled experiment, 476 consenting learners across four courses submitted 1,297 submissions, 4,102 reviews, and 846 self assessments. Learners assigned to compare submissions wrote reviews and self-reflections that were longer and received higher ratings from experts than those who evaluated submissions one at a time. A second study found that a ranking of submissions derived from learners' comparisons correlates well with staff ranking. These results demonstrate that comparing algorithmically-curated pairs of submissions helps learners write better feedback.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {comparative peer review, contrasting cases, feedback},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173869,
author = {Huang, Ting-Hao (Kenneth) and Chang, Joseph Chee and Bigham, Jeffrey P.},
title = {Evorus: A Crowd-Powered Conversational Assistant Built to Automate Itself Over Time},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173869},
doi = {10.1145/3173574.3173869},
abstract = {Crowd-powered conversational assistants have been shown to be more robust than automated systems, but do so at the cost of higher response latency and monetary costs. A promising direction is to combine the two approaches for high quality, low latency, and low cost solutions. In this paper, we introduce Evorus, a crowd-powered conversational assistant built to automate itself over time by (i) allowing new chatbots to be easily integrated to automate more scenarios, (ii) reusing prior crowd answers, and (iii) learning to automatically approve response candidates. Our 5-month-long deployment with 80 participants and 281 conversations shows that Evorus can automate itself without compromising conversation quality. Crowd-AI architectures have long been proposed as a way to reduce cost and latency for crowd-powered systems; Evorus demonstrates how automation can be introduced successfully in a deployed system. Its architecture allows future researchers to make further innovation on the underlying automated components in the context of a deployed open domain dialog system.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {conversational assistant, chatbot, real-time crowdsourcing, crowdsourcing, crowd-powered system},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173870,
author = {Springer, Aaron and Cramer, Henriette},
title = {"Play PRBLMS": Identifying and Correcting Less Accessible Content in Voice Interfaces},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173870},
doi = {10.1145/3173574.3173870},
abstract = {Voice interfaces often struggle with specific types of named content. Domain-specific terminology and naming may push the bounds of standard language, especially in domains like music where artistic creativity extends beyond the music itself. Artists may name themselves with symbols (e.g. M S C RA) that most standard automatic speech recognition (ASR) systems cannot transcribe. Voice interfaces also experience difficulty surfacing content whose titles include non-standard spellings, symbols or other ASCII characters in place of English letters, or are written using a non-standard dialect. We present a generalizable method to detect content that current voice interfaces underserve by leveraging differences in engagement across input modalities. Using this detection method, we develop a typology of content types and linguistic practices that can make content hard to surface. Finally, we present a process using crowdsourced annotations to make underserved content more accessible.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {bias, findability, voice, music},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173871,
author = {van Kollenburg, Janne and Bogers, Sander and Rutjes, Heleen and Deckers, Eva and Frens, Joep and Hummels, Caroline},
title = {Exploring the Value of Parent Tracked Baby Data in Interactions with Healthcare Professionals: A Data-Enabled Design Exploration},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173871},
doi = {10.1145/3173574.3173871},
abstract = {This paper presents a designerly exploration of the potential values of parent-tracked baby data in interactions between parents and healthcare professionals (HCPs). Where previous work has used parent-tracked data as part of the solution to a problem, we contribute by starting our design exploration from data, using it as creative material in our design process. As we intend to work towards a system that could be viable across different levels of care, we invited three different types of HCPs and five families with newborns, for a five-week situated design exploration. Facilitated by an open and dynamic data collection toolkit, parents and HCPs could together decide what data to collect. In a continuous dialogue, they reflected on the relevance of that data in their interaction. Based on this, we continuously and remotely developed two concepts.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data-enabled design, healthcare, situated explorations, personal informatics},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173872,
author = {Cherek, Christian and Brocker, Anke and Voelker, Simon and Borchers, Jan},
title = {Tangible Awareness: How Tangibles on Tabletops Influence Awareness of Each Other's Actions},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173872},
doi = {10.1145/3173574.3173872},
abstract = {Tangibles on multitouch tabletops increase speed, accuracy, and eyes-free operability for individual users, and verbal and behavioral social interaction among multiple users around smaller tables with a shared focus of attention. Modern multitouch tables, however, provide sizes and resolutions that let groups work alongside each other in separate workspaces. But how aware do these users remain of each other's actions, and what impact can tangibles have on their awareness? In our study, groups of 2--4 users around the table played an individual game grabbing their attention as primary task, while they also had to occasionally become aware of other players'actions and react as secondary task. We found that players were significantly more aware of other players'actions using tangibles than those using pure multitouch interaction, indicated by faster reaction times. This effect was especially strong with more players. We close with qualitative user feedback and design recommendations. We found that players were significantly more aware of other players'actions using tangibles than those using pure multitouch interaction, indicated by faster reaction times. This effect was especially strong with more players. We close with qualitative user feedback and design recommendations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {information processing, tangibles, large tabletops, secondary task awareness, tangible interaction vs. touch interaction, awareness, collocated group work},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173873,
author = {Alexander, Jason and Roudaut, Anne and Steimle, J\"{u}rgen and Hornb\ae{}k, Kasper and Bruns Alonso, Miguel and Follmer, Sean and Merritt, Timothy},
title = {Grand Challenges in Shape-Changing Interface Research},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173873},
doi = {10.1145/3173574.3173873},
abstract = {Shape-changing interfaces have emerged as a new method for interacting with computers, using dynamic changes in a device's physical shape for input and output. With the advances of research into shape-changing interfaces, we see a need to synthesize the main, open research questions. The purpose of this synthesis is to formulate common challenges across the diverse fields engaged in shape-change research, to facilitate progression from single prototypes and individual design explorations to grander scientific goals, and to draw attention to challenges that come with maturity, including those concerning ethics, theory-building, and societal impact. In this article we therefore present 12 grand challenges for research on shape-changing interfaces, derived from a three-day workshop with 25 shape-changing interface experts with backgrounds in design, computer science, human-computer interaction, engineering, robotics, and material science.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {shape-changing interfaces, research agenda, grand challenges},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173874,
author = {Brudy, Frederik and Budiman, Joshua Kevin and Houben, Steven and Marquardt, Nicolai},
title = {Investigating the Role of an Overview Device in Multi-Device Collaboration},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173874},
doi = {10.1145/3173574.3173874},
abstract = {The availability of mobile device ecologies enables new types of ad-hoc co-located decision-making and sensemaking practices in which people find, collect, discuss, and share information. However, little is known about what kind of device configurations are suitable for these types of tasks. This paper contributes new insights into how people use configurations of devices for one representative example task: collaborative co-located trip-planning. We present an empirical study that explores and compares three strategies to use multiple devices: no-overview, overview on own device, and a separate overview device. The results show that the overview facilitated decision- and sensemaking during a collaborative trip-planning task by aiding groups to iterate their itinerary, organize locations and timings efficiently, and discover new insights. Groups shared and discussed more opinions, resulting in more democratic decision-making. Groups provided with a separate overview device engaged more frequently and spent more time in closely-coupled collaboration.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobiles and tablets, ad-hoc collaboration, decision-making, multi-device interaction, co-located collaboration},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173875,
author = {Hofmann, Megan and Hann, Gabriella and Hudson, Scott E. and Mankoff, Jennifer},
title = {Greater than the Sum of Its PARTs: Expressing and Reusing Design Intent in 3D Models},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173875},
doi = {10.1145/3173574.3173875},
abstract = {With the increasing popularity of consumer-grade 3D printing, many people are creating, and even more using, objects shared on sites such as Thingiverse. However, our formative study of 962 Thingiverse models shows a lack of re-use of models, perhaps due to the advanced skills needed for 3D modeling. An end user program perspective on 3D modeling is needed. Our framework (PARTs) empowers amateur modelers to graphically specify design intent through geometry. PARTs includes a GUI, scripting API and exemplar library of assertions which test design expectations and integrators which act on intent to create geometry. PARTs lets modelers integrate advanced, model specific functionality into designs, so that they can be re-used and extended, without programming. In two workshops, we show that PARTs helps to create 3D printable models, and modify existing models more easily than with a standard tool.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3d printing, prototyping, fabrication},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173876,
author = {Fritsch, Ester and Shklovski, Irina and Douglas-Jones, Rachel},
title = {Calling for a Revolution: An Analysis of IoT Manifestos},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173876},
doi = {10.1145/3173574.3173876},
abstract = {Designers and developers are increasingly writing manifestos to express frustration and uncertainty as they struggle to negotiate between the possibilities that IoT technologies offer, and the ethical concerns they engender. Manifestos are defining of a 'moment of crisis' and their recent proliferation indicates a desire for change. We analyze the messages manifesto authors have for their readers. Emerging from a sense of uncertainty, these manifestos create publics for debate, demand attention and call for change. While manifestos provide potential roadmaps for a better future, they also express a deep concern and even fear of the state of the world and the role of technology in it. We highlight how practitioners are responding to unstable and rapidly changing times and detail what solutions they envision, and what conflicts these might bring about. Our analysis suggests new ways HCI might theorize and design for responsibility while attending to the perils of responsibilisation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {responsibility, iot, openness, manifesto, ethics, diversity, design, control, values, transparency},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173877,
author = {Niemantsverdriet, Karin and van de Werff, Thomas and van Essen, Harm and Eggen, Berry},
title = {Share and Share Alike? Social Information and Interaction Style in Coordination of Shared Use},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173877},
doi = {10.1145/3173574.3173877},
abstract = {Interfaces are commonly designed from the perspective of individual users, even though most of the systems we use in everyday life are in fact shared. We argue that more attention is needed for system sharing, especially because interfaces are known to influence coordination of shared use. In this work, we aim to deepen the understanding of this relation. To do so, we design three interfaces for a shared lighting system that vary in the type of social information they allow people to share with others and in their overall interaction style. We systematically compare longitudinal and real-life use of the interfaces, evaluating (1) people's appraisal of three types of social information and (2) the influence of an interaction style on coordination of shared use. The results disclose relations between the interface and the amount of verbal communication, consideration, and accountability. With this work, we urge the need for interaction designers to consider shared use.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {shared use, social translucence, awareness, connected lighting, multi-user interaction, interaction design},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173878,
author = {Srinivasan, Arjun and Brehmer, Matthew and Lee, Bongshin and Drucker, Steven M.},
title = {What's the Difference? Evaluating Variations of Multi-Series Bar Charts for Visual Comparison Tasks},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173878},
doi = {10.1145/3173574.3173878},
abstract = {An increasingly common approach to data analysis involves using information dashboards to visually compare changing data. However, layout constraints coupled with varying levels of visualization literacy among dashboard users make facilitating visual comparison in dashboards a challenging task. In this paper, we evaluate variants of bar charts, one of the most prevalent class of charts used in dashboards. We report an online experiment (N = 74) conducted to evaluate four alternative designs: 1) grouped bar chart, 2) grouped bar chart with difference overlays, 3) bar chart with difference overlays, and 4) difference bar chart. Results show that charts with difference overlays facilitate a wider range of comparison tasks while performing comparably to charts without them on individual tasks. Finally, we discuss the implications of our findings, with a focus on supporting visual comparison in dashboards.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online experiment, visualization dashboards, visual comparison, task-based evaluation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173879,
author = {Nov, Oded and Su, Han},
title = {Eliciting Users' Demand for Interface Features},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173879},
doi = {10.1145/3173574.3173879},
abstract = {How valuable are certain interface features to their users? How can users' demand for features be quantified? To address these questions, users' demand curve for the sorting feature was elicited in a controlled experiment, using personal finance as the user context. Users made ten rounds of investment allocation across up to 77 possible funds, thus encountering choice overload, typical of many online environments. Users were rewarded for positive investment returns. To overcome choice overload, users could sort the alternatives based on product attributes (fees, category, fund name, past performance). To elicit their demand for sorting, the experimental design enabled users to forgo 0%-9% of their reward in return for activating the sorting feature. The elicited downward sloping demand curve suggests a curvilinear relationship between sorting use and cost. More broadly, the study offers a way to quantify user demand of UI features, and a basis for comparison between features.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {features, revealed preference, choice overload, economics, user interface. feature economics, demand, cost-benefit},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173880,
author = {Csikszentmihalyi, Christopher and Mukundane, Jude and Rodrigues, Gemma F. and Mwesigwa, Daniel and Kasprzak, Michelle},
title = {The Space of Possibilities: Political Economies of Technology Innovation in Sub-Saharan Africa},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173880},
doi = {10.1145/3173574.3173880},
abstract = {HCI researchers work within spaces of possibility for potential designs of technology. New methods (e.g., user centrism); expected types of interaction (user with device); and potential applications (urban navigation) can extend the boundaries of these possibilities. However, structural and systemic factors can also foreclose them. A recent wide and shallow survey of 116 individuals involved in technology development across 26 countries in sub-Saharan Africa reveals how factors of political economy significantly impact upon technological possibilities. Monopolies, international power dynamics, race, and access to capital open or constrain technological possibilities at least as much as device-centric or user-focused constraints do. Though their thrust may have been anticipated by reference to political economic trends, the structural constraints we found were underestimated by technologists even a decade ago. We discuss the implications for technology development in Africa and beyond.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hci4d, m4d, africa, sub-saharan africa, postcolonial},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173881,
author = {Jaroszewski, Samantha and Lottridge, Danielle and Haimson, Oliver L. and Quehl, Katie},
title = {"Genderfluid" or "Attack Helicopter": Responsible HCI Research Practice with Non-Binary Gender Variation in Online Communities},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173881},
doi = {10.1145/3173574.3173881},
abstract = {As non-binary genders become increasingly prevalent, researchers face decisions in how to collect, analyze and interpret research participants' genders. We present two case studies on surveys with thousands of respondents, of which hundreds reported gender as something other than simply women or men. First, Tumblr, a blogging platform, resulted in a rich set of gender identities with very few aggressive or resistive responses; the second case study, online Fantasy Football, yielded opposite proportions. By focusing on variation rather than dismissing non-binary responses as noise, we suggest that researchers can better capture gender in a way that 1) addresses gender variation without othering or erasing non-binary respondents; and 2) minimizes "trolls'" opportunity to use surveys as a mischief platform. The analyses of these two distinct case studies find significant gender differences in community dimensions of participation in both networked spaces as well as offering a model for inclusive mixed-methods HCI research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {fantasy sports, social media, trolling, non-binary, survey research, gender, online communities, tumblr, lgbtq, transgender},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173882,
author = {Taylor, Jennyfer Lawrence and Soro, Alessandro and Roe, Paul and Lee Hong, Anita and Brereton, Margot},
title = {“Debrief O'Clock”: Planning, Recording, and Making Sense of a Day in the Field in Design Research},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173882},
doi = {10.1145/3173574.3173882},
abstract = {Design research is generative, intuitive, experiential, and tactical. Documenting the design research process helps to communicate these decisions, judgements, and values that are embodied in design products. Yet, practices for documenting design research are underreported in the CHI community, particularly for immersive design research field studies. We contribute the "Debrief O'Clock" fieldnote practice for documenting design research field studies, comprising collaborative discussion sessions and the production of written research accounts. We show how the Debrief O'Clock practice emerged in the context of a Digital Community Noticeboard project with a very remote Australian Aboriginal community, and explain three key purposes of Debrief O'Clock as: 1) an early stage data recording and analysis process; 2) a tactical manoeuvre in responsive project planning; and 3) a mechanism for personal debriefing and reflexivity. We conclude with a series of open practical, ethical, and methodological questions to advance the discussion of design research documentation practices.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {field studies, design research documentation, field data, qualitative analysis, fieldnotes},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173883,
author = {Saksono, Herman and Castaneda-Sceppa, Carmen and Hoffman, Jessica and Seif El-Nasr, Magy and Morris, Vivien and Parker, Andrea G.},
title = {Family Health Promotion in Low-SES Neighborhoods: A Two-Month Study of Wearable Activity Tracking},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173883},
doi = {10.1145/3173574.3173883},
abstract = {Low-socioeconomic status (SES) families face increased barriers to physical activity (PA)-a behavior critical for reducing and preventing chronic disease. Research has explored how wearable PA trackers can encourage increased activity, and how the adoption of such trackers is driven by people's emotions and social needs. However, more work is needed to understand how PA trackers are perceived and adopted by low-SES families, where PA may be deprioritized due to economic stresses, limited resources, and perceived crime. Accordingly, we conducted a two-month, in-depth qualitative study, exploring low-SES caregivers' perspectives on PA tracking and promotion. Our findings show how PA tracking was impacted by caregivers' attitudes toward safety, which were influenced by how they perceived social connections within their neighborhoods; and cognitive-emotional processes. We conclude that PA tracking tools for low-SES families should help caregivers and children to experience and celebrate progress.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wearables, places, personal health informatics, physical activity trackers, low-socioeconomic status, crime, neighborhoods, family, caregivers, self-monitoring},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173884,
author = {Alallah, Fouad and Neshati, Ali and Sheibani, Nima and Sakamoto, Yumiko and Bunt, Andrea and Irani, Pourang and Hasan, Khalad},
title = {Crowdsourcing vs Laboratory-Style Social Acceptability Studies? Examining the Social Acceptability of Spatial User Interactions for Head-Worn Displays},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173884},
doi = {10.1145/3173574.3173884},
abstract = {The use of crowdsourcing platforms for data collection in HCI research is attractive in their ability to provide rapid access to large and diverse participant samples. As a result, several researchers have conducted studies investigating the similarities and differences between data collected through crowdsourcing and more traditional, laboratory-style data collection. We add to this body of research by examining the feasibility of conducting social acceptability studies via crowdsourcing. Social acceptability can be a key determinant for the early adoption of emerging technologies, and as such, we focus our investigation on social acceptability for Head-Worn Display (HWD) input modalities. Our results indicate that data collected via a crowdsourced experiment and a laboratory-style setting did not differ at a statistically significant level. These results provide initial support for crowdsourcing platforms as viable options for conducting social acceptability research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {social acceptance, input modalities, head-worn displays, crowdsourcing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173885,
author = {Denny, Paul and McDonald, Fiona and Empson, Ruth and Kelly, Philip and Petersen, Andrew},
title = {Empirical Support for a Causal Relationship Between Gamification and Learning Outcomes},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173885},
doi = {10.1145/3173574.3173885},
abstract = {Preparing for exams is an important yet stressful time for many students. Self-testing is known to be an effective preparation strategy, yet some students lack motivation to engage or persist in self-testing activities. Adding game elements to a platform supporting self-testing may increase engagement and, by extension, exam performance. We conduct a randomized controlled experiment (n=701) comparing the effect of two game elements -- a points system and a badge system -- used individually and in combination. We find that the badge system elicits significantly higher levels of voluntary self-testing activity and this effect is particularly pronounced amongst a relatively small cohort. Importantly, this increased activity translates to a significant improvement in exam scores. Our data supports a causal relationship between gamification and learning outcomes, mediated by self-testing behavior. This provides empirical support for Landers' theory of gamified learning when the gamified activity is conducted prior to measuring learning outcomes.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gamification, badges, points, peerwise, self-testing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173886,
author = {Corbett, Eric and Le Dantec, Christopher A.},
title = {Going the Distance: <i>Trust Work</i> for Citizen Participation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173886},
doi = {10.1145/3173574.3173886},
abstract = {Trust is a vital component of citizen participation-whether citizens decide to engage in opportunities for participation in local government can hinge entirely on the existence of trust between citizens and public officials. Understanding the role of trust in this space is vital for HCI and the growing area of Digital Civics which works to improve or create new modes of citizen participation. Currently, however, trust is understudied from the perspectives of public officials. This gap creates a critical blind spot as technical interventions may be mismatched to the ways trust is put into action by public officials working to support citizen participation. We begin to address this gap by presenting a broad qualitative study of how public officials in a large US city operationalize trust in citizen participation. We found trust is enacted through ongoing practices that man-age distance in relationships between public officials and city residents.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {digital civics, trust, community engagement},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173887,
author = {Jung, Joshua D. A. and Vogel, Daniel},
title = {Methods for Intentional Encoding of High Capacity Human-Designable Visual Markers},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173887},
doi = {10.1145/3173574.3173887},
abstract = {Previous techniques for human-designable visual markers have focused on small encoding spaces, and assume artists do not need to encode specific bit representations. We present a general framework for human-designable visual markers for artists to encode specific bit representations in large spaces. A three-part study, conducted over three weeks, methodically evaluates the usability of different encoding methods when artists encode specific bit representations. The methods span different shape characteristics suitable for artist encoding (convexity, hollowness, number, size, and distance from centroid) and visualization tools are proposed to aid in this process. We further demonstrate that any of the methods presented may be practically used to encode a URL with the aid of a universally available database like TinyURL (rather than a task-specific database), making human-designable visual markers practical for applications such as advertisements.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {fiducial marker, user study, encoding, designable marker},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173888,
author = {Alharthi, Sultan A. and Torres, Ruth C. and Khalaf, Ahmed S. and Toups, Zachary O. and Dolgov, Igor and Nacke, Lennart E.},
title = {Investigating the Impact of Annotation Interfaces on Player Performance in Distributed Multiplayer Games},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173888},
doi = {10.1145/3173574.3173888},
abstract = {In distributed multiplayer games, it can be difficult to communicate strategic information for planning game moves and player interactions. Often, players spend extra time communicating, reducing their engagement in the game. Visual annotations in game maps and in the gameworld can address this problem and result in more efficient player communication. We studied the impact of real-time feedback on planning annotations, specifically two different annotation types, in a custom-built, third-person, multiplayer game and analyzed their effects on player performance, experience, workload, and annotation use. We found that annotations helped engage players in collaborative planning, which reduced frustration, and shortened goal completion times. Based on these findings, we discuss how annotating in virtual game spaces enables collaborative planning and improves team performance.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {annotation, collaboration, coordination, distributed multiplayer games, game design, planning, sensemaking},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173889,
author = {Schlesinger, Ari and O'Hara, Kenton P. and Taylor, Alex S.},
title = {Let's Talk About Race: Identity, Chatbots, and AI},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173889},
doi = {10.1145/3173574.3173889},
abstract = {Why is it so hard for chatbots to talk about race? This work explores how the biased contents of databases, the syntactic focus of natural language processing, and the opaque nature of deep learning algorithms cause chatbots difficulty in handling race-talk. In each of these areas, the tensions between race and chatbots create new opportunities for people and machines. By making the abstract and disparate qualities of this problem space tangible, we can develop chatbots that are more capable of handling race-talk in its many forms. Our goal is to provide the HCI community with ways to begin addressing the question, how can chatbots handle race-talk in new and improved ways?},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {artificial intelligence, chatbots, race},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173890,
author = {Truong, Anh and Chen, Sara and Yumer, Ersin and Salesin, David and Li, Wilmot},
title = {Extracting Regular FOV Shots from 360 Event Footage},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173890},
doi = {10.1145/3173574.3173890},
abstract = {Video summaries are a popular way to share important events, but creating good summaries is hard. It requires expertise in both capturing and editing footage. While hiring a professional videographer is possible, this is too costly for most casual events. An alternative is to place 360 video cameras around an event space to capture footage passively and then extract regular field-of-view (RFOV) shots for the summary. This paper focuses on the problem of extracting such RFOV shots. Since we cannot actively control the cameras or the scene, it is hard to create "ideal' shots that adhere strictly to traditional cinematography rules. To better understand the tradeoffs, we study human preferences for static and moving camera RFOV shots generated from 360 footage. From the findings, we derive design guidelines. As a secondary contribution, we use these guidelines to develop automatic algorithms that we demonstrate in a prototype user interface for extracting RFOV shots from 360 videos.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {video summaries, 360 video, event video, video editing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173891,
author = {Salminen, Joni and Nielsen, Lene and Jung, Soon-Gyo and An, Jisun and Kwak, Haewoon and Jansen, Bernard J.},
title = {“Is More Better?”: Impact of Multiple Photos on Perception of Persona Profiles},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173891},
doi = {10.1145/3173574.3173891},
abstract = {In this research, we investigate if and how more photos than a single headshot can heighten the level of information provided by persona profiles. We conduct eye-tracking experiments and qualitative interviews with variations in the photos: a single headshot, a headshot and images of the persona in different contexts, and a headshot with pictures of different people representing key persona attributes. The results show that more contextual photos significantly improve the information end users derive from a persona profile; however, showing images of different people creates confusion and lowers the informativeness. Moreover, we discover that choice of pictures results in various interpretations of the persona that are biased by the end users' experiences and preconceptions. The results imply that persona creators should consider the design power of photos when creating persona profiles.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online data representations, personas, user perceptions},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173892,
author = {Nanavati, Amal and Dias, M. Bernardine and Steinfeld, Aaron},
title = {Speak Up: A Multi-Year Deployment of Games to Motivate Speech Therapy in India},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173892},
doi = {10.1145/3173574.3173892},
abstract = {The ability to communicate is crucial to leading an independent life. Unfortunately, individuals from developing communities who are deaf and hard of hearing tend to encounter difficulty communicating, due to a lack of educational resources. We present findings from a two-year deployment of Speak Up, a suite of voice-powered games to motivate speech therapy, at a school for the deaf in India. Using ethnographic methods, we investigated the interplay between Speak Up and local educational practices. We found that teachers' speech therapy goals had evolved to differ from those encoded in the games, that the games influenced classroom dynamics, and that teachers had improved their computer literacy and developed creative uses for the games. We used these insights to further enhance Speak Up by creating an explicit teacher role in the games, making changes that encouraged teachers to build their computer literacy, and adding an embodied agent.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {speech therapy, assistive technologies, ethnography, capacity building, ictd},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173893,
author = {Shin, Hyungyu and Ko, Eun-Young and Williams, Joseph Jay and Kim, Juho},
title = {Understanding the Effect of In-Video Prompting on Learners and Instructors},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173893},
doi = {10.1145/3173574.3173893},
abstract = {Online instructional videos are ubiquitous, but it is difficult for instructors to gauge learners' experience and their level of comprehension or confusion regarding the lecture video. Moreover, learners watching the videos may become disengaged or fail to reflect and construct their own understanding. This paper explores instructor and learner perceptions of in-video prompting where learners answer reflective questions while watching videos. We conducted two studies with crowd workers to understand the effect of prompting in general, and the effect of different prompting strategies on both learners and instructors. Results show that some learners found prompts to be useful checkpoints for reflection, while others found them distracting. Instructors reported the collected responses to be generally more specific than what they have usually collected. Also, different prompting strategies had different effects on the learning experience and the usefulness of responses as feedback.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {feedback, in-video prompting, reflection, mooc, online education, instructors, learners},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173894,
author = {Delazio, Alexandra and Nakagaki, Ken and Klatzky, Roberta L. and Hudson, Scott E. and Lehman, Jill Fain and Sample, Alanson P.},
title = {Force Jacket: Pneumatically-Actuated Jacket for Embodied Haptic Experiences},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173894},
doi = {10.1145/3173574.3173894},
abstract = {Immersive experiences seek to engage the full sensory system in ways that words, pictures, or touch alone cannot. With respect to the haptic system, however, physical feedback has been provided primarily with handheld tactile experiences or vibration-based designs, largely ignoring both pressure receptors and the full upper-body area as conduits for expressing meaning that is consistent with sight and sound. We extend the potential for immersion along these dimensions with the Force Jacket, a novel array of pneumatically-actuated airbags and force sensors that provide precisely directed force and high frequency vibrations to the upper body. We describe the pneumatic hardware and force control algorithms, user studies to verify perception of airbag location and pressure magnitude, and subsequent studies to define full-torso, pressure and vibration-based feel effects such as punch, hug, and snake moving across the body. We also discuss the use of those effects in prototype virtual reality applications.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pneumatic actuation, vibrotactile, force feedback, haptics, virtual reality, wearable},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173895,
author = {Barbarin, Andrea M. and Saslow, Laura R. and Ackerman, Mark S. and Veinot, Tiffany C.},
title = {Toward Health Information Technology That Supports Overweight/Obese Women in Addressing Emotion- and Stress-Related Eating},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173895},
abstract = {Emotion- and stressed-related eating (ESRE) is associated with weight management difficulties and is more likely to affect women than men. Additionally, health information technology (HIT) for weight management tends to be less effective for women than it is for men, and less effective for people who engage in ESRE. Therefore, this study explores how HIT can support overweight/obese women curb ESRE behavior. Study participants, all adult overweight/obese women (BMI ' 25), logged dietary intake for 10 days with the Lose It! smartphone app as an elicitation exercise. Cross sectional, semi-structured interviews (N = 22) were then conducted to explore technology support needs concerning ESRE behavior. Findings revealed participants had the following needs: holistic health goal development, building motivation to achieve goals, and assistance with handling stress. Resulting HIT guidelines include supporting holistic health goals, developing and sustaining motivation, exchange of emotional support, understanding of behavior, and change in ESRE mindset.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3173574.3173896,
author = {Fox, Sarah E. and Lampe, Meredith and Rosner, Daniela K.},
title = {Parody in Place: Exposing Socio-Spatial Exclusions in Data-Driven Maps with Design Parody},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173896},
abstract = {This paper describes the development of Parody in Place, a design parody that depicts Seattle neighborhoods with typographic arrangements derived from data generated by technology platforms such as Yelp and Zillow. The project invites inquiry into what technology corporations make matter and where, in ways that challenge the neutrality of neighborhood-based data. We designed the subject of our parody, a mock company called Dork Posters, to explore how the modes of parody by which the system operates expose socio-spatial exclusions both contested and propagated by digital platforms. Our interventions reveal shifts in response toward mapping techniques, from ambivalence to curiosity. We used Dork Posters to question reductionist techniques of data aggregation and ad hoc theories of data provenance. Our engagements also prompted reflection on the politics of measurement: how data sources shape result- ing insights and valuations. We end by discussing possibilities for expanding the design research program within human-computer interaction through parody.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3173897,
author = {Merrill, Nick and Chuang, John},
title = {From Scanning Brains to Reading Minds: Talking to Engineers about Brain-Computer Interface},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173897},
doi = {10.1145/3173574.3173897},
abstract = {We presented software engineers in the San Francisco Bay Area with a working brain-computer interface (BCI) to surface the narratives and anxieties around these devices among technical practitioners. Despite this group's heterogeneous beliefs about the exact nature of the mind, we find a shared belief that the contents of the mind will someday be "read' or "decoded' by machines. Our findings help illuminate BCI's imagined futures among engineers. We highlight opportunities for researchers to involve themselves preemptively in this nascent space of intimate biosensing devices, suggesting our findings' relevance to long-term futures of privacy and cybersecurity.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {technology probe, mind-reading, brain-computer interface},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173898,
author = {Agapie, Elena and Chinh, Bonnie and Pina, Laura R. and Oviedo, Diana and Welsh, Molly C. and Hsieh, Gary and Munson, Sean},
title = {Crowdsourcing Exercise Plans Aligned with Expert Guidelines and Everyday Constraints},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173898},
doi = {10.1145/3173574.3173898},
abstract = {Exercise plans help people implement behavior change. Crowd workers can help create exercise plans for clients, but their work may result in lower quality plans than produced by experts. We built CrowdFit, a tool that provides feedback about compliance with exercise guidelines and leverages strengths of crowdsourcing to create plans made by non-experts. We evaluated CrowdFit in a comparative study with 46 clients using exercise plans for two weeks. Clients received plans from crowd planners using CrowdFit, crowd planners without CrowdFit, or from expert planners. Compared to crowd planners not using CrowdFit, crowd planners using CrowdFit created plans that are more actionable and more aligned with exercise guidelines. Compared to experts, crowd planners created more actionable plans, and plans that are not significantly different with respect to tailoring, strength and aerobic principles. They struggled, however, to satisfy exercise requirements of amount of exercise. We discuss opportunities for designing technology supporting physical activity planning by non-experts.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {exercise plans, crowdsourcing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173899,
author = {Freeman, Guo and Bardzell, Shaowen and Bardzell, Jeffrey},
title = {Bottom-Up Imaginaries: The Cultural-Technical Practice of Inventing Regional Advantage through IT R&amp;D},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173899},
abstract = {Recent HCI research on social creativity and bottom-up innovation has highlighted how concerted efforts by the government policy and business communities to develop innovation ecosystems are increasingly intertwined with IT research and development. We note that many such efforts focus on cultivating regional advantage [20] in the form of innovation hubs that are situated in and leverage distinct sociocultural histories and geographies. Cultivating regional advantage entails achieving broad consensus about what that region's advantage might be, that is, the construction of a regional advantage imaginary beyond the policies, IT supports, and practices to make it happen. Here, we document how an ongoing public debate among makers and manufacturers in Taiwan as a region-distinguished by direct engagement with design, fabrication, prototyping, and manufacturing processes-are proposing pathways toward a regional advantage that both reflects Taiwan's recent sociocultural and economic histories and also its near future aspirations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inbook{10.1145/3173574.3173900,
author = {Ragan, Eric D. and Kum, Hye-Chung and Ilangovan, Gurudev and Wang, Han},
title = {Balancing Privacy and Information Disclosure in Interactive Record Linkage with Visual Masking},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173900},
abstract = {Effective use of data involving personal or sensitive information often requires different people to have access to personal information, which significantly reduces the personal privacy of those whose data is stored and increases risk of identity theft, data leaks, or social engineering attacks. Our research studies the tradeoffs between privacy and utility of personal information for human decision making. Using a record-linkage scenario, this paper presents a controlled study of how varying degrees of information availability influences the ability to effectively use personal information. We compared the quality of human decision-making using a visual interface that controls the amount of personal information available using visual markup to highlight data discrepancies. With this interface, study participants who viewed only 30% of data content had decision quality similar to those who had full 100% access. The results demonstrate that it is possible to greatly limit the amount of personal information available to human decision makers without negatively affecting utility or human effectiveness. However, the findings also show there is a limit to how much data can be hidden before negatively influencing the quality of judgment in decisions involving person-level data. Despite the reduced accuracy with extreme data hiding, the study demonstrates that with proper interface designs, many correct decisions can be made with even legally de-identified data that is fully masked (74.5% accuracy with fully-masked data compared to 84.1% with full access). Thus, when legal requirements only allow for de-identified data access, use of well-designed interface can significantly improve data utility.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3173901,
author = {Peacock, Sean and Anderson, Robert and Crivellaro, Clara},
title = {Streets for People: Engaging Children in Placemaking Through a Socio-Technical Process},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173901},
abstract = {In this paper, we present a socio-technical process designed to engage children in an ongoing urban design project-Streets for People-in Newcastle, UK. We translated urban design proposals developed by residents and the local authority to enable children to contribute ideas to the project. Our process comprised three stages: situated explorations and evidence gathering through digitally supported neighbourhood walks; issue mapping and peer-to-peer discussions using an online engagement platform; and face-to-face dialogue between children, residents, and the local authority through a 'Town Hall' event. We report insights gained through our engagement and show how our activities facilitated issue advocacy and the development of children's capacities, but also surfaced tensions around the agency of children in political processes. We reflect on the challenges of working in this space, and discuss wider implications for technology design and ethical questions that 'scaling up' such work might pose.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.1145/3173574.3173902,
author = {Rogers, Katja and Ribeiro, Giovanni and Wehbe, Rina R. and Weber, Michael and Nacke, Lennart E.},
title = {Vanishing Importance: Studying Immersive Effects of Game Audio Perception on Player Experiences in Virtual Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173902},
doi = {10.1145/3173574.3173902},
abstract = {Sound and virtual reality (VR) are two important output modalities for creating an immersive player experience (PX). While prior research suggests that sounds might contribute to a more immersive experience in games played on screens and mobile displays, there is not yet evidence of these effects of sound on PX in VR. To address this, we conducted a within-subjects experiment using a commercial horror-adventure game to study the effects of a VR and monitor-display version of the same game on PX. Subsequently, we explored, in a between-subjects study, the effects of audio dimensionality on PX in VR. Results indicate that audio has a more implicit influence on PX in VR because of the impact of the overall sensory experience and that audio dimensionality in VR may not be a significant factor contributing to PX. Based on our findings and observations, we provide five design guidelines for VR games.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {player experience, sound effects, virtual reality, ambient noises, games, audio, background music},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173903,
author = {Zhao, Jian and Bhatt, Chidansh and Cooper, Matthew and Shamma, David A.},
title = {Flexible Learning with Semantic Visual Exploration and Sequence-Based Recommendation of MOOC Videos},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173903},
doi = {10.1145/3173574.3173903},
abstract = {Massive Open Online Course (MOOC) platforms have scaled online education to unprecedented enrollments, but remain limited by their rigid, predetermined curricula. To overcome this limitation, this paper contributes a visual recommender system called MOOCex. The system recommends lecture videos across different courses by considering both video contents and sequential inter-topic relationships mined from course syllabi; and more importantly, it allows for interactive visual exploration of the semantic space of recommendations within a learner's current context. When compared to traditional methods (e.g., content-based recommendation and ranked list representations), MOOCex suggests videos from more diverse perspectives and helps learners make better video playback decisions. Further, feedback from MOOC learners and instructors indicates that the system enhances both learning and teaching effectiveness.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visualization, recommender system, mooc videos},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173904,
author = {Bati, Ghassan F. and Singh, Vivek K.},
title = {“Trust Us”: Mobile Phone Use Patterns Can Predict Individual Trust Propensity},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173904},
abstract = {An individual's trust propensity - i.e., a dispositional willingness to rely on others" - mediates multiple socio-technical systems and has implications for their personal, and societal, well-being. Hence, understanding and modeling an individual's trust propensity is important for human-centered computing research. Conventional methods for understanding trust propensities have been surveys and lab experiments. We propose a new approach to model trust propensity based on long-term phone use metadata that aims to complement typical survey approaches with a lower-cost, faster, and scalable alternative. Based on analysis of data from a 10-week field study (mobile phone logs) and "ground truth" survey involving 50 participants, we: (1) identify multiple associations between phone-based social behavior and trust propensity; (2) define a machine learning model that automatically infers a person's trust propensity. The results pave way for understanding trust at a societal scale and have implications for personalized applications in the emerging social internet of things.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.1145/3173574.3173905,
author = {O'Leary, Kathleen and Schueller, Stephen M. and Wobbrock, Jacob O. and Pratt, Wanda},
title = {“Suddenly, We Got to Become Therapists for Each Other”: Designing Peer Support Chats for Mental Health},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173905},
doi = {10.1145/3173574.3173905},
abstract = {Talk therapy is a common, effective, and desirable form of mental health treatment. Yet, it is inaccessible to many people. Enabling peers to chat online using effective principles of talk therapy could help scale this form of mental health care. To understand how such chats could be designed, we conducted a two-week field experiment with 40 people experiencing mental illnesses comparing two types of online chats-chats guided by prompts, and unguided chats. Results show that anxiety was significantly reduced from pre-test to post-test. User feedback revealed that guided chats provided solutions to problems and new perspectives, and were perceived as "deep," while unguided chats offered personal connection on shared experiences and were experienced as "smooth." We contribute the design of an online guided chat tool and insights into the design of peer support chat systems that guide users to initiate, maintain, and reciprocate emotional support.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {health, peer counseling, behavioral interventions, mental health, peer support, psychotherapy},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173906,
author = {Kristiansen, Kristian Helbo and Valeur-Meller, Mathias A. and Dombrowski, Lynn and Holten Moller, Naja L..},
title = {Accountability in the Blue-Collar Data-Driven Workplace},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173906},
doi = {10.1145/3173574.3173906},
abstract = {This paper examines how mobile technology impacts employee accountability in the blue-collar data-driven workplace. We conducted an observation-based qualitative study of how electricians in an electrical company interact with data related to their work accountability, which comprises the information employees feel is reasonable to share and document about their work. The electricians we studied capture data both manually, recording the hours spent on a particular task, and automatically, as their mobile devices regularly track data such as location. First, our results demonstrate how work accountability manifests for employees' manual labor work that has become data-driven. We show how employees work through moments of transparency, privacy, and accountability using data focused on location, identification and time. Second, we demonstrate how this data production is interdependent with employees' beliefs about what is a reasonable level of detail and transparency to provide about their work. Lastly, we articulate specific design implications related to work accountability.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {transparence, mobile devices, privacy, data-driven work, technology in the workplace, datafication, accounting devices, blue-collar work, accountability, tracking},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173907,
author = {Prost, Sebastian and Crivellaro, Clara and Haddon, Andy and Comber, Rob},
title = {Food Democracy in the Making: Designing with Local Food Networks},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173907},
doi = {10.1145/3173574.3173907},
abstract = {This paper introduces the concept of 'food democracy' as a theoretical framing for HCI to engage in human-food interaction. Extending existing foci of health and environmental sustainability, food democracy requires thinking through aspects of social and economic justice, and democratic governance as directions for the study and design of technologies for alternative food movements. To exemplify food democracy, we report on field observations and interviews about the opportunities and challenges for supporting the development of local food networks with communities in deprived neighbourhoods using an online direct food marketing platform. Using a food democracy framing, we identify tensions around environmental, social, and economic goals; challenges of local food businesses operating within the existing economic paradigm; and differing perspectives on ownership and governance in the network. We discuss the need for HCI to design for systems change and propose a design space for HCI in supporting food democracy movements.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design, system change, local food networks, social justice, food democracy, modernism},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173908,
author = {Felberbaum, Yasmin and Lanir, Joel},
title = {Better Understanding of Foot Gestures: An Elicitation Study},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173908},
doi = {10.1145/3173574.3173908},
abstract = {We present a study aimed to better understand users' perceptions of foot gestures employed on a horizontal surface. We applied a user elicitation methodology, in which participants were asked to suggest foot gestures to actions (referents) in three conditions: standing up in front of a large display, sitting down in front of a desktop display, and standing on a projected surface. Based on majority count and agreement scores, we identified three gesture sets, one for each condition. Each gesture set shows a mapping between a common action and its chosen gesture. As a further contribution, we suggest a new measure called specification score, which indicates the degree to which a gesture is specific, preferable and intuitive to an action in a specific condition of use. Finally, we present measurable insights that can be implemented as guidelines for future development and research of foot interaction.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {foot gestures, foot interaction, elicitation study, user-defined gesture set},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3173909,
author = {Wang, Yun and Zhang, Haidong and Huang, He and Chen, Xi and Yin, Qiufeng and Hou, Zhitao and Zhang, Dongmei and Luo, Qiong and Qu, Huamin},
title = {InfoNice: Easy Creation of Information Graphics},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173909},
doi = {10.1145/3173574.3173909},
abstract = {Information graphics are widely used to convey messages and present insights in data effectively. However, creating expressive data-driven infographics remains a great challenge for general users without design expertise. We present InfoNice, a visualization design tool that enables users to easily create data-driven infographics. InfoNice allows users to convert unembellished charts into infographics with multiple visual elements through mark customization. We implement InfoNice into Microsoft Power BI to demonstrate the integration of InfoNice into data analysis workflow seamlessly, bridging the gap between data exploration and presentation. We evaluate the usability and usefulness of InfoNice through example infographics, an in-lab user study, and real-world user feedback. Our results show that InfoNice enables users to create a variety of infographics easily for common scenarios.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {design tools, infographics, visualization},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3173910,
author = {Ion, Alexandra and Kovacs, Robert and Schneider, Oliver S. and Lopes, Pedro and Baudisch, Patrick},
title = {Metamaterial Textures},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173910},
abstract = {We present metamaterial textures---3D printed surface geometries that can perform a controlled transition between two or more textures. Metamaterial textures are integrated into 3D printed objects and allow designing how the object interacts with the environment and the user's tactile sense. Inspired by foldable paper sheets ("origami") and surface wrinkling, our 3D printed metamaterial textures consist of a grid of cells that fold when compressed by an external global force. Unlike origami, however, metamaterial textures offer full control over the transformation, such as in between states and sequence of actuation. This allows for integrating multiple textures and makes them useful, e.g., for exploring parameters in the rapid prototyping of textures. Metamaterial textures are also robust enough to allow the resulting objects to be grasped, pushed, or stood on. This allows us to make objects, such as a shoe sole that transforms from flat to treaded, a textured door handle that provides tactile feedback to visually impaired users, and a configurable bicycle grip. We present an editor assists users in creating metamaterial textures interactively by arranging cells, applying forces, and previewing their deformation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3173911,
author = {Nordhoff, Manuel and August, Tal and Oliveira, Nigini A. and Reinecke, Katharina},
title = {A Case for Design Localization: Diversity of Website Aesthetics in 44 Countries},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173911},
doi = {10.1145/3173574.3173911},
abstract = {Adapting the visual designs of websites to a local target audience can be beneficial, because such design localization increases users' appeal, trust, and work efficiency. Yet designers often find it difficult to decide when to adapt and how to adapt the designs, mainly because there are currently no guidelines that describe common website designs in various countries. We contribute the first large-scale analysis of 80,901 website designs across 44 countries, made available via an interactive web-based design catalog. Using computational image metrics to compare the ~2,000 most visited websites per country, we found significant differences between several design aspects, such as a website's colorfulness, visual complexity, the number of text areas and the average saturation of colors. Our results contribute a snapshot of web designs that users in 44 countries frequently see, showing that the design of websites with a global reach are more homogenized compared to local websites between countries.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {localization, website design, quantified aesthetics},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174182,
author = {Ford, Denae and Lustig, Kristina and Banks, Jeremy and Parnin, Chris},
title = {"We Don't Do That Here": How Collaborative Editing with Mentors Improves Engagement in Social Q&amp;A Communities},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174182},
doi = {10.1145/3173574.3174182},
abstract = {Online question-and-answer (Q&amp;A) communities like Stack Overflow have norms that are not obvious to novice users. Novices create and post programming questions without feedback, and the community enforces site norms through public downvoting and commenting. This can leave novices discouraged from further participation. We deployed a month long, just-in-time mentorship program to Stack Overflow in which we redirected novices in the process of asking a question to an on-site Help Room. There, novices received feedback on their question drafts from experienced Stack Overflow mentors. We present examples and discussion of various question improvements including: question context, code formatting, and wording that adheres to on-site cultural norms. We find that mentored questions are substantially improved over non-mentored questions, with average scores increasing by 50%. We provide design implications that challenge how socio-technical communities onboard novices across domains.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social q&amp;a, collaborative editing, programming, e-mentoring},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174183,
author = {Antoine, Axel and Malacria, Sylvain and Casiez, G\'{e}ry},
title = {Using High Frequency Accelerometer and Mouse to Compensate for End-to-End Latency in Indirect Interaction},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174183},
doi = {10.1145/3173574.3174183},
abstract = {End-to-end latency corresponds to the temporal difference between a user input and the corresponding output from a system. It has been shown to degrade user performance in both direct and indirect interaction. If it can be reduced to some extend, latency can also be compensated through software compensation by trying to predict the future position of the cursor based on previous positions, velocities and accelerations. In this paper, we propose a hybrid hardware and software prediction technique specifically designed for partially compensating end-to-end latency in indirect pointing. We combine a computer mouse with a high frequency accelerometer to predict the future location of the pointer using Euler based equations. Our prediction method results in more accurate prediction than previously introduced prediction algorithms for direct touch. A controlled experiment also revealed that it can improve target acquisition time in pointing tasks.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {accelerometer, end-to-end latency, computer mouse, performance, prediction, jitter},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174184,
author = {Kerber, Frederic and Mauderer, Michael and Kr\"{u}ger, Antonio},
title = {Modeling Perceived Screen Resolution Based on Position and Orientation of Wrist-Worn Devices},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174184},
abstract = {This paper presents a model allowing inferences of perceivable screen content in relation to position and orientation of mobile or wearable devices with respect to their user. The model is based on findings from vision science and allows prediction of a value of effective resolution that can be perceived by a user. It considers distance and angle between the device and the eyes of the observer as well as the resulting retinal eccentricity when the device is not directly focused but observed in the periphery. To validate our model, we conducted a study with 12 participants. Based on our results, we outline implications for the design of mobile applications that are able to adapt themselves to facilitate information throughput and usability.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7}
}

@inbook{10.1145/3173574.3174185,
author = {Ferguson, Jamie and Brewster, Stephen A.},
title = {Investigating Perceptual Congruence between Data and Display Dimensions in Sonification},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174185},
abstract = {The relationships between sounds and their perceived meaning and connotations are complex, making auditory perception an important factor to consider when designing sonification systems. Listeners often have a mental model of how a data variable should sound during sonification and this model is not considered in most data:sound mappings. This can lead to mappings that are difficult to use and can cause confusion. To investigate this issue, we conducted a magnitude estimation experiment to map how roughness, noise and pitch relate to the perceived magnitude of stress, error and danger. These parameters were chosen due to previous findings which suggest perceptual congruency between these auditory sensations and conceptual variables. Results from this experiment show that polarity and scaling preference are dependent on the data:sound mapping. This work provides polarity and scaling values that may be directly utilised by sonification designers to improve auditory displays in areas such as accessible and mobile computing, process-monitoring and biofeedback.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9}
}

@inproceedings{10.1145/3173574.3174186,
author = {Distler, Verena and Lallemand, Carine and Bellet, Thierry},
title = {Acceptability and Acceptance of Autonomous Mobility on Demand: The Impact of an Immersive Experience},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174186},
doi = {10.1145/3173574.3174186},
abstract = {Autonomous vehicles have the potential to fundamentally change existing transportation systems. Beyond legal concerns, these societal evolutions will critically depend on user acceptance. As an emerging mode of public transportation [7], Autonomous mobility on demand (AMoD) is of particular interest in this context. The aim of the present study is to identify the main components of acceptability (before first use) and acceptance (after first use) of AMoD, following a user experience (UX) framework. To address this goal, we conducted three workshops (N=14) involving open discussions and a ride in an experimental autonomous shuttle. Using a mixed-methods approach, we measured pre-immersion acceptability before immersing the participants in an on-demand transport scenario, and eventually measured post-immersion acceptance of AMoD. Results show that participants were reassured about safety concerns, however they perceived the AMoD experience as ineffective. Our findings highlight key factors to be taken into account when designing AMoD experiences.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {human needs, acceptability, acceptance, mobility on demand, user experience, autonomous driving},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174187,
author = {Liang, Rong-Hao and Yu, Bin and Xue, Mengru and Hu, Jun and Feijs, Loe M. G.},
title = {BioFidget: Biofeedback for Respiration Training Using an Augmented Fidget Spinner},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174187},
doi = {10.1145/3173574.3174187},
abstract = {This paper presents BioFidget, a biofeedback system that integrates physiological sensing and display into a smart fidget spinner for respiration training. We present a simple yet novel hardware design that transforms a fidget spinner into 1) a nonintrusive heart rate variability (HRV) sensor, 2) an electromechanical respiration sensor, and 3) an information display. The combination of these features enables users to engage in respiration training through designed tangible and embodied interactions, without requiring them to wear additional physiological sensors. The results of this empirical user study prove that the respiration training method reduces stress, and the proposed system meets the requirements of sensing validity and engagement with 32 participants in a practical setting.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {stress, respiration training, physiological sensing, fidget spinner, biofeedback, tangible interaction},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174188,
author = {Metaxa-Kakavouli, Dana\"{e} and Wang, Kelly and Landay, James A. and Hancock, Jeff},
title = {Gender-Inclusive Design: Sense of Belonging and Bias in Web Interfaces},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174188},
doi = {10.1145/3173574.3174188},
abstract = {We interact with dozens of web interfaces on a daily basis, making inclusive web design practices more important than ever. This paper investigates the impacts of web interface design on ambient belonging, or the sense of belonging to a community or culture. Our experiment deployed two content-identical webpages for an introductory computer science course, differing only in aesthetic features such that one was perceived as masculine while the other was gender-neutral. Our results confirm that young women exposed to the masculine page are negatively affected, reporting significantly less ambient belonging, interest in the course and in studying computer science broadly. They also experience significantly more concern about others' perception of their gender relative to young women exposed to the neutral page, while no similar effect is seen in young men. These results suggest that gender biases can be triggered by web design, highlighting the need for inclusive user interface design for the web.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {inclusive design, gender-inclusive interfaces, ambient belonging, web interface psychology},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174189,
author = {Shin, In-geon and Seok, Jin-min and Lim, Youn-kyung},
title = {Too Close and Crowded: Understanding Stress on Mobile Instant Messengers Based on Proxemics},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174189},
doi = {10.1145/3173574.3174189},
abstract = {Nowadays, mobile instant messaging (MIM) is a necessity for our private and public lives, but it has also been the cause of stress. In South Korea, MIM stress has become a serious social problem. To understand this stress, we conducted four focus groups with 20 participants under MIM stress. We initially discovered that MIM stress relates to how people perceive the territory in MIM. We then applied proxemics-the theory of human use of space-to the thematic analysis as the rationale. The data revealed two main themes: too close and too crowded. The participants were stressed due to design features that let strangers or crowds into their MIM applications and forced them to interact and share their status with them. Based on this finding, we propose a set of implications for designing anti-stress MIM applications.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mobile instant messaging, design, stress, proxemics},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174190,
author = {Baumer, Eric P. S.},
title = {Socioeconomic Inequalities in the Non Use of Facebook},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174190},
doi = {10.1145/3173574.3174190},
abstract = {Use and non-use of technology can occur in a variety of forms. This paper analyzes data from a probabilistic sample of 1000 US households to identify predictors for four different types of use and non-use of the social media site Facebook. The results make three important contributions. First, they demonstrate that many demographic and socioeconomic predictors of social media use and non-use identified in prior studies hold with a larger, more diverse sample. Second, they show how going beyond a binary distinction between use and non-use reveals inequalities in social media use and non-use not identified in prior work. Third, they contribute to ongoing discussions about the representativeness of social media data by showing which populations are, and are not, represented in samples drawn from social media.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {demographics, socioeconomic status, social media, non-use, facebook},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174191,
author = {Kiss, Francisco and Boldt, Robin and Pfleging, Bastian and Schneegass, Stefan},
title = {Navigation Systems for Motorcyclists: Exploring Wearable Tactile Feedback for Route Guidance in the Real World},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174191},
doi = {10.1145/3173574.3174191},
abstract = {Current navigation systems for motor cyclists use visual or auditory cues for guidance. However, this poses a challenge to the motorcyclists since their visual and auditory channels are already occupied with controlling the motorbike, paying attention to other road users, and planing the next turn. In this work, we explore how tactile feedback can be used to guide motorcyclists. We present MOVING (MOtorbike VIbrational Navigation Guidance), a smart kidney belt that presents navigation cues through 12 vibration motors. In addition, we report on the design process of this wearable and on an evaluation with 16 participants in a real world riding setting. We show that MOVING outperforms off-the-shelf navigation systems in terms of turn errors and distraction.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {real world evaluations, motorcycle navigation, tactile feedback},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174192,
author = {Potluri, Venkatesh and Vaithilingam, Priyan and Iyengar, Suresh and Vidya, Y. and Swaminathan, Manohar and Srinivasa, Gopal},
title = {CodeTalk: Improving Programming Environment Accessibility for Visually Impaired Developers},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174192},
doi = {10.1145/3173574.3174192},
abstract = {In recent times, programming environments like Visual Studio are widely used to enhance programmer productivity. However, inadequate accessibility prevents Visually Impaired (VI) developers from taking full advantage of these environments. In this paper, we focus on the accessibility challenges faced by the VI developers in using Graphical User Interface (GUI) based programming environments. Based on a survey of VI developers and based on two of the authors' personal experiences, we categorize the accessibility difficulties into Discoverability, Glanceability, Navigability, and Alertability. We propose solutions to some of these challenges and implement these in CodeTalk, a plugin for Visual Studio. We show how CodeTalk improves developer experience and share promising early feedback from VI developers who used our plugin.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {accessibility, audio debugging, programming environments, visually impaired},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174193,
author = {Kim, Hyunyoung and Coutrix, Celine and Roudaut, Anne},
title = {Morphees+: Studying Everyday Reconfigurable Objects for the Design and Taxonomy of Reconfigurable UIs},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174193},
doi = {10.1145/3173574.3174193},
abstract = {Users interact with many reconfigurable objects in daily life. These objects embed reconfigurations and shape- changing features that users are familiar with. For this reason, everyday reconfigurable objects have informed the design and taxonomy of shape changing UI. However, they have never been explored systematically. In this paper, we present a data set of 82 everyday reconfigurable objects that we collected in a workshop. We discuss how they can inspire the design of reconfigurable interfaces. We particularly focus on taxonomies of reconfigurable interfaces. Taxonomies have been suggested to help design and communication among researchers, however despite their extensive use, taxonomies are rarely evaluated. This paper analyses two established taxonomies - Rasmussen's and Roudaut's - using daily reconfigurable objects. We show relationships between the taxonomies and area for improvements. We propose Morphees+, a refined taxonomy based on Roudaut's Shape Resolution Taxonomy.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {reconfigurable, shape-changing, shape resolution, taxonomy, deformable},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174194,
author = {Beck, Jordan and Ekbia, Hamid R.},
title = {The Theory-Practice Gap as Generative Metaphor},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174194},
abstract = {The theory-practice gap is a well-known concept in HCI research. It provides a way of describing a space that allegedly exists between the theory and practice of the field, and it has inspired many researchers to propose ways to "bridge the gap." In this paper, we propose a novel interpretation of the gap as a generative metaphor that frames problems and guides researchers towards possible solutions. We examine how the metaphor has emerged in HCI discourse, and what its limitations might be. Our examination raises concerns about treating the gap as given or obvious, which could reflect researchers' tendencies to adopt a problem-solving perspective. We discuss the value of considering problem setting in relation to the theory-practice gap, and then explore Derrida's strategy of "reversal" as a possible way to develop new metaphors to capture the relationship between theory and practice.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inproceedings{10.1145/3173574.3174195,
author = {Alharthi, Sultan A. and Alsaedi, Olaa and Toups, Zachary O. and Tanenbaum, Joshua and Hammer, Jessica},
title = {Playing to Wait: A Taxonomy of Idle Games},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174195},
doi = {10.1145/3173574.3174195},
abstract = {Idle games are a recent minimalist gaming phenomenon in which the game is left running with little player interaction. We deepen understanding of idle games and their characteristics by developing a taxonomy and identifying game features. This paper examines 66 idle games using a grounded theory approach to analyze play, game mechanics, rewards, interactivity, progress rate, and user interface. To establish a clearly bounded definition of idle games, we analyzed 10 non-idle games with the same approach. We discuss how idle games move players from playing to planning, how they question dominant assumptions about gameplay, and their unusual use of resources such as player attention and computer cycles. Our work illuminates opportunities for the design of idle games, suggests design implications, and provides a framework for researchers to clearly articulate questions about this genre.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {planning, clicker games, playing, idle games, taxonomy, game design, incremental games, waiting, grounded theory},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174196,
author = {Banerjee, Rahul and Liu, Leanne and Sobel, Kiley and Pitt, Caroline and Lee, Kung Jin and Wang, Meng and Chen, Sijin and Davison, Lydia and Yip, Jason C. and Ko, Andrew J. and Popovic, Zoran},
title = {Empowering Families Facing English Literacy Challenges to Jointly Engage in Computer Programming},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174196},
doi = {10.1145/3173574.3174196},
abstract = {Research suggests that parental engagement through Joint Media Engagement (JME) is an important factor in children's learning for coding and programming. Unfortunately, parents with limited technology background may have difficulty supporting their children's access to programming. English-language learning (ELL) families from marginalized communities face particular challenges in understanding and supporting programming, as code is primarily authored using English text. We present BlockStudio, a programming tool for empowering ELL families to jointly engage in introductory coding, using an environment embodying two design principles, text-free and visually concrete. We share a case study involving three community centers serving immigrant and refugee populations. Our findings show ELL families can jointly engage in programming without text, via co-creation and flexible roles, and can create a range of artifacts, indicating understanding of aspects of programming within this environment. We conclude with implications for coding together in ELL families and design ideas for text-free programming research.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {coding, text-free, joint media engagement (jme), programming, english-language learning (ell) families},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174197,
author = {Roberts, Jessica and Banerjee, Amartya and Hong, Annette and McGee, Steven and Horn, Michael and Matcuk, Matt},
title = {Digital Exhibit Labels in Museums: Promoting Visitor Engagement with Cultural Artifacts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174197},
abstract = {How can we use interactive displays in museums to help visitors appreciate authentic objects and artifacts that they can't otherwise touch or manipulate? This paper shares results from a design-based research study on the use of interactive displays to help visitors learn about artifacts in an exhibit on the history and culture of China. To explore the potential afforded by these displays, we unobtrusively video recorded 834 museum visitor groups who stopped in front of one collection of objects. Drawing on cognitive models of curiosity, we tested three redesigns of this display, each focusing on a different strategy to spark visitor curiosity, interest, and engagement. To understand the relative effectiveness of these designs, we analyzed visitor interaction and conversation. Our results uncovered significant differences across the conditions suggesting implications for the use of such technology in museums.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3174198,
author = {Zhang, Xucong and Huang, Michael Xuelin and Sugano, Yusuke and Bulling, Andreas},
title = {Training Person-Specific Gaze Estimators from User Interactions with Multiple Devices},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174198},
abstract = {Learning-based gaze estimation has significant potential to enable attentive user interfaces and gaze-based interaction on the billions of camera-equipped handheld devices and ambient displays. While training accurate person- and device-independent gaze estimators remains challenging, person-specific training is feasible but requires tedious data collection for each target device. To address these limitations, we present the first method to train person-specific gaze estimators across multiple devices. At the core of our method is a single convolutional neural network with shared feature extraction layers and device-specific branches that we train from face images and corresponding on-screen gaze locations. Detailed evaluations on a new dataset of interactions with five common devices (mobile phone, tablet, laptop, desktop computer, smart TV) and three common applications (mobile game, text editing, media center) demonstrate the significant potential of cross-device training. We further explore training with gaze locations derived from natural interactions, such as mouse or touch input.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inbook{10.1145/3173574.3174199,
author = {Katz, Dmitri S. and Price, Blaine A. and Holland, Simon and Dalton, Nicholas Sheep},
title = {Designing for Diabetes Decision Support Systems with Fluid Contextual Reasoning},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174199},
abstract = {Type 1 diabetes is a potentially life-threatening chronic condition that requires frequent interactions with diverse data to inform treatment decisions. While mobile technologies such as blood glucose meters have long been an essential part of this process, designing interfaces that explicitly support decision-making remains challenging. Dual-process models are a common approach to understanding such cognitive tasks. However, evidence from the first of two studies we present suggests that in demanding and complex situations, some individuals approach disease management in distinctive ways that do not seem to fit well within existing models. This finding motivated, and helped frame our second study, a survey (n=192) to investigate these behaviors in more detail. On the basis of the resulting analysis, we posit Fluid Contextual Reasoning to explain how some people with diabetes respond to particular situations, and discuss how an extended framework might help inform the design of user interfaces for diabetes management.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3174200,
author = {Vertanen, Keith and Fletcher, Crystal and Gaines, Dylan and Gould, Jacob and Kristensson, Per Ola},
title = {The Impact of Word, Multiple Word, and Sentence Input on Virtual Keyboard Decoding Performance},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174200},
doi = {10.1145/3173574.3174200},
abstract = {Entering text on non-desktop computing devices is often done via an onscreen virtual keyboard. Input on such keyboards normally consists of a sequence of noisy tap events that specify some amount of text, most commonly a single word. But is single word-at-a-time entry the best choice? This paper compares user performance and recognition accuracy of word-at-a-time, phrase-at-a-time, and sentence-at-a-time text entry on a smartwatch keyboard. We evaluate the impact of differing amounts of input in both text copy and free composition tasks. We found providing input of an entire sentence significantly improved entry rates from 26 wpm to 32 wpm while keeping character error rates below 4%. In offline experiments with more processing power and memory, sentence input was recognized with a much lower 2.0% error rate. Our findings suggest virtual keyboards can enhance performance by encouraging users to provide more input per recognition event.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual keyboard, decoder, text entry, smartwatch},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174201,
author = {Vaccaro, Kristen and Agarwalla, Tanvi and Shivakumar, Sunaya and Kumar, Ranjitha},
title = {Designing the Future of Personal Fashion},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174201},
doi = {10.1145/3173574.3174201},
abstract = {Advances in computer vision and machine learning are changing the way people dress and buy clothes. Given the vast space of fashion problems, where can data-driven technologies provide the most value? To understand consumer pain points and opportunities for technological interventions, this paper presents the results from two independent need-finding studies that explore the gold-standard of personalized shopping: interacting with a personal stylist. Through interviews with five personal stylists, we study the range of problems they address and their in-person processes for working with clients. In a separate study, we investigate how styling experiences map to online settings by building and releasing a chatbot that connects users to one-on-one sessions with a stylist, acquiring more than 70 organic users in three weeks. These conversations reveal that in-person and online styling sessions share similar goals, but online sessions often involve smaller problems that can be resolved more quickly. Based on these explorations, we propose future highly personalized, online interactions that address consumer trust and uncertainty, and discuss opportunities for automation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {chatbots, fashion, need-finding, conversational agents},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174202,
author = {Hong, Sungsoo (Ray) and Yoo, Min-Joon and Chinh, Bonnie and Han, Amy and Battersby, Sarah and Kim, Juho},
title = {To Distort or Not to Distort: Distance Cartograms in the Wild},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174202},
abstract = {Distance Cartograms (DC) distort geographical features so that the measured distance between a single location and any other location on a map indicates absolute travel time. Although studies show that users can efficiently assess travel time with DC, distortion applied in DC may confuse users, and its usefulness "in the wild" is unknown. To understand how real world users perceive DC's benefits and drawbacks, we devise techniques that improve DC's presentation (preserving topological relationships among map features while aiming at retaining shapes) and scalability (presenting accurate live travel time). We developed a DC-enabled system with these techniques, and deployed it to 20 participants for 4 weeks. During this period, participants spent, on average, more than 50% of their time with DC as opposed to a standard map. Participants felt DC to be intuitive and useful for assessing travel time. They indicated intent in adopting DC in their real-life scenarios.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3174203,
author = {Albouys-Perrois, J\'{e}r\'{e}my and Laviole, J\'{e}r\'{e}my and Briant, Carine and Brock, Anke M.},
title = {Towards a Multisensory Augmented Reality Map for Blind and Low Vision People: A Participatory Design Approach},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174203},
doi = {10.1145/3173574.3174203},
abstract = {Current low-tech Orientation &amp; Mobility (O&amp;M) tools for visually impaired people, e.g. tactile maps, possess limitations. Interactive accessible maps have been developed to overcome these. However, most of them are limited to exploration of existing maps, and have remained in laboratories. Using a participatory design approach, we have worked closely with 15 visually impaired students and 3 O&amp;M instructors over 6 months. We iteratively designed and developed an augmented reality map destined at use in O&amp;M classes in special education centers. This prototype combines projection, audio output and use of tactile tokens, and thus allows both map exploration and construction by low vision and blind people. Our user study demonstrated that all students were able to successfully use the prototype, and showed a high user satisfaction. A second phase with 22 international special education teachers allowed us to gain more qualitative insights. This work shows that augmented reality has potential for improving the access to education for visually impaired people.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {geographic maps, augmented reality, visual impairment, participatory design, accessibility},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174204,
author = {Joshi, Meghna and Joshi, Tanmay and Rangaswamy, Nimmi},
title = {Scaling Classroom IT Skill Tutoring: A Case Study from India},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174204},
doi = {10.1145/3173574.3174204},
abstract = {India is home to the largest under-25 demographic profile in the world, but lacks a job-ready educational system. It requires a wide-spread, skill-oriented educational model, equipping youth to thrive in highly dynamic job markets. As a response to the huge demand for technical education, a large private skill-tutoring ecosystem has sprung up in In-dia but remains geographically limited. This paper, drawn from a three-month ethnographic research conducted in Ameerpet (arguably India's largest IT skilling hub), probes the pedagogic style and characteristics of tutoring, and of-fers reasons why learners prefer to enroll into a physical model of classroom teaching over online courses. We make design suggestions for online learning platforms to attract students who are marginalized in the more formal and com-petitive education system, and opt for Ameerpet-like skill-hubs. Our primary offering is to suggest a shift in perspec-tive of online education platforms to include job readiness and accompanying changes in course content and delivery.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {technical education, it skills, india, ethnography, blended learning},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174205,
author = {Costa, Jean and Jung, Malte F. and Czerwinski, Mary and Guimbreti\`{e}re, Fran\c{c}ois and Le, Trinh and Choudhury, Tanzeem},
title = {Regulating Feelings During Interpersonal Conflicts by Changing Voice Self-Perception},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174205},
abstract = {Emotions play a major role in how interpersonal conflicts unfold. Although several strategies and technological approaches have been proposed for emotion regulation, they often require conscious attention and effort. This often limits their efficacy in practice. In this paper, we propose a different approach inspired by self-perception theory: noticing that people are often reacting to the perception of their own behavior, we artificially change their perceptions to influence their emotions. We conducted two studies to evaluate the potential of this approach by automatically and subtly altering how people perceive their own voice. In one study, participants that received voice feedback with a calmer tone during relationship conflicts felt less anxious. In the other study, participants who listened to their own voices with a lower pitch during contentious debates felt more powerful. We discuss the implications of our findings and the opportunities for designing automatic and less perceptible emotion regulation systems.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3173574.3174206,
author = {Kang, HyeongYeop and Lee, Geonsun and Kwon, Seongsu and Kwon, Ohung and Kim, Seongpil and Han, JungHyun},
title = {Flotation Simulation in a Cable-Driven Virtual Environment -- A Study with Parasailing},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174206},
abstract = {This paper presents flotation simulation in a cable-driven virtual environment. For this, a virtual parasailing system was developed, where the visual stimulus was provided through a VR headset and the physical stimulus was given by wires. In order to prevent the user from moving out of the limited workspace of the cable-driven system, the visual acceleration was washout-filtered to produce the physical acceleration. In the parasailing trajectory, we focused on the stages of vertical acceleration/deceleration and conducted an experiment to identify how much gain can be applied to the visual acceleration, which makes the user feel the natural self-motion when integrated with physical stimulus. Then, the results were tested using several types of full-course virtual parasailing. The results showed that fairly large differences between visual and physical stimuli would be accepted and different gains could be assigned depending on the user's altitudes.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11}
}

@inproceedings{10.1145/3173574.3174207,
author = {Dosono, Bryan and Semaan, Bryan},
title = {Identity Work as Deliberation: AAPI Political Discourse in the 2016 US Presidential Election},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174207},
doi = {10.1145/3173574.3174207},
abstract = {Asian Americans and Pacific Islanders (AAPIs) are perceived as the "model minority" with a monolithic identity, in contrast to other marginalized racial groups in the United States. In reality, they are composed of different ethnicities, socio-economic backgrounds, and political ideologies. AAPIs share their political views online, engaging in the public sphere through a collaborative process we coin, "identity work as deliberation." Using the 2016 US Presidential Election as a case study, we retrieved 4,406 Reddit comments posted between October 2016 to December 2016. We examine how users engage in an online community through a deliberation lens to understand the extent to which Reddit supports identity work as a deliberative process. Under the collective AAPI umbrella, we find that ethnic identifications complicate the types of discussion possible within r/asianamerican. We discuss how the expression of identity, and thereby solidarity, in a politicized online setting may lead to a social movement.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online identity, reddit, social network sites, deliberation, aapi, impression management},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174208,
author = {Singh, Gaganpreet and Delamare, William and Irani, Pourang},
title = {D-SWIME: A Design Space for Smartwatch Interaction Techniques Supporting Mobility and Encumbrance},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174208},
doi = {10.1145/3173574.3174208},
abstract = {Smartwatches enable rapid access to information anytime and anywhere. However, current smartwatch content navigation techniques, for panning and zooming, were directly adopted from those used on smartphones. These techniques are cumbersome when performed on small smartwatch screens and have not been evaluated for their support in mobility and encumbrance contexts (when the user's hands are busy). We studied the effect of mobility and encumbrance on common content navigation techniques and found a significant decrease in performance as the pace of mobility increases or when the user was encumbered with busy hands. Based on these initial findings, we proposed a design space which would improve efficiency when navigation techniques, such as panning and zooming, are employed in mobility contexts. Our results reveal that our design space can effectively be used to create novel interaction techniques that improve smartwatch content navigation in mobility and encumbrance contexts.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobility, encumbrance, navigation techniques, design space evaluation, pan, touch input, smartwatch input, zoom},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174209,
author = {Cavallo, Marco and Demiralp, \c{C}a\u{g}atay},
title = {A Visual Interaction Framework for Dimensionality Reduction Based Data Exploration},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174209},
abstract = {Dimensionality reduction is a common method for analyzing and visualizing high-dimensional data. However, reasoning dynamically about the results of a dimensionality reduction is difficult. Dimensionality-reduction algorithms use complex optimizations to reduce the number of dimensions of a dataset, but these new dimensions often lack a clear relation to the initial data dimensions, thus making them difficult to interpret. Here we propose a visual interaction framework to improve dimensionality-reduction based exploratory data analysis. We introduce two interaction techniques, forward projection and backward projection, for dynamically reasoning about dimensionally reduced data. We also contribute two visualization techniques, prolines and feasibility maps, to facilitate the effective use of the proposed interactions. We apply our framework to PCA and autoencoder-based dimensionality reductions. Through data-exploration examples, we demonstrate how our visual interactions can improve the use of dimensionality reduction in exploratory data analysis.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/3173574.3174210,
author = {Kou, Yubo and Nardi, Bonnie},
title = {Complex Mediation in the Formation of Political Opinions},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174210},
doi = {10.1145/3173574.3174210},
abstract = {The Internet plays an important role in the formation of political opinions by supporting citizens in discovering diverse political information and opinions. However, the echo chamber effect has become of increasing concern, referring to the tendency for people to encounter opinions and information similar to their own online. It remains poorly understood how ordinary citizens use the Internet in the formation of political opinions. To answer this question, we conducted an interview study with 32 Chinese citizens. We found that participants used complex strategies to coordinate personal networks and technologies in specific ways to better understand political events. To analyze this phenomenon, we draw on B\o{}dker and Andersen's model of complex mediation which describes how multiple mediators including people and artifacts work together to mediate an activity. We discuss how complex mediation supported participants in informing their political opinions. We derive design implications for supporting people to form political opinions.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {information seeking, activity theory, complex media environment, complex mediation, political opinion, political deliberation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174211,
author = {Heller, Florian and Sch\"{o}ning, Johannes},
title = {NavigaTone: Seamlessly Embedding Navigation Cues in Mobile Music Listening},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174211},
doi = {10.1145/3173574.3174211},
abstract = {As humans, we have the natural capability of localizing the origin of sounds. Spatial audio rendering leverages this skill by applying special filters to recorded audio to create the impression that a sound emanates from a certain position in the physical space. A main application for spatial audio on mobile devices is to provide non-visual navigation cues. Current systems require users to either listen to artificial beacon sounds, or the entire audio source (e.g., a song) is repositioned in space, which impacts the listening experience. We present NavigaTone, a system that takes advantage of multi-track recordings and provides directional cues by moving a single track in the auditory space. While minimizing the impact of the navigation component on the listening experience, a user study showed that participants could localize sources as good as with stereo panning while the listening experience was rated to be closer to common music listening.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {mobile devices, audio augmented reality, navigation, spatial audio, virtual audio spaces},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174212,
author = {M\'{e}ndez, Gonzalo Gabriel and Nacenta, Miguel A. and Hinrichs, Uta},
title = {Considering Agency and Data Granularity in the Design of Visualization Tools},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174212},
abstract = {Previous research has identified trade-offs when it comes to designing visualization tools. While constructive "bottom-up' tools promote a hands-on, user-driven design process that enables a deep understanding and control of the visual mapping, automated tools are more efficient and allow people to rapidly explore complex alternative designs, often at the cost of transparency. We investigate how to design visualization tools that support a user-driven, transparent design process while enabling efficiency and automation, through a series of design workshops that looked at how both visualization experts and novices approach this problem. Participants produced a variety of solutions that range from example-based approaches expanding constructive visualization to solutions in which the visualization tool infers solutions on behalf of the designer, e.g., based on data attributes. On a higher level, these findings highlight agency and granularity as dimensions that can guide the design of visualization tools in this space.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inbook{10.1145/3173574.3174213,
author = {Dye, Michaelanne and Nemer, David and Mangiameli, Josiah and Bruckman, Amy S. and Kumar, Neha},
title = {El Paquete Semanal: The Week's Internet in Havana},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174213},
abstract = {We contribute a case study of El Paquete Semanal or "The Weekly Package" -- the pervasive, offline internet in Cuba. We conducted a qualitative inquiry of El Paquete through extensive fieldwork---interviews and observations---in Havana, Cuba. Our findings highlight the human infrastructure that supports this offline internet, rendered visible through the lens of articulation work. By offering an in-depth perspective into these workings of El Paquete, we aim to challenge established notions of what an (or the) internet "should" look like in more and less "developed" contexts. We highlight how El Paquete is a non-standardized and non-neutral internet, but still human-centered. We also offer an enriched understanding of how an entirely offline internet can provide expansive information access to support leisure and livelihood, additionally serving as a locally relevant platform that affords local participation.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3174214,
author = {Porcheron, Martin and Fischer, Joel E. and Reeves, Stuart and Sharples, Sarah},
title = {Voice Interfaces in Everyday Life},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174214},
doi = {10.1145/3173574.3174214},
abstract = {Voice User Interfaces (VUIs) are becoming ubiquitously available, being embedded both into everyday mobility via smartphones, and into the life of the home via 'assistant' devices. Yet, exactly how users of such devices practically thread that use into their everyday social interactions remains underexplored. By collecting and studying audio data from month-long deployments of the Amazon Echo in participants' homes-informed by ethnomethodology and conversation analysis-our study documents the methodical practices of VUI users, and how that use is accomplished in the complex social life of the home. Data we present shows how the device is made accountable to and embedded into conversational settings like family dinners where various simultaneous activities are being achieved. We discuss how the VUI is finely coordinated with the sequential organisation of talk. Finally, we locate implications for the accountability of VUI interaction, request and response design, and raise conceptual challenges to the notion of designing 'conversational' interfaces.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {collocated interaction, conversational user interface, intelligent personal assistants, conversational agent, amazon echo, ethnomethodology, conversation analysis},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174215,
author = {Sharma, Eva and De Choudhury, Munmun},
title = {Mental Health Support and Its Relationship to Linguistic Accommodation in Online Communities},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174215},
doi = {10.1145/3173574.3174215},
abstract = {Many online communities cater to the critical and unmet needs of individuals challenged with mental illnesses. Generally, communities engender characteristic linguistic practices, known as norms. Conformance to these norms, or linguistic accommodation, encourages social approval and acceptance. This paper investigates whether linguistic accommodation impacts a specific social feedback: the support received by an individual in an online mental health community. We first quantitatively derive two measures for each post in these communities: 1) the linguistic accommodation it exhibits, and 2) the level of support it receives. Thereafter, we build a statistical framework to examine the relationship between these measures. Although the extent to which accommodation is associated with support varies, we find a positive link between the two, consistent across 55 Reddit communities serving various psychological needs. We discuss how our work surfaces a tension in the functioning of these sensitive communities, and present design implications for improving their support provisioning mechanisms.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mental health, linguistic accommodation, online communities, mental illness, social support},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174216,
author = {Correll, Michael and Moritz, Dominik and Heer, Jeffrey},
title = {Value-Suppressing Uncertainty Palettes},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174216},
doi = {10.1145/3173574.3174216},
abstract = {Understanding uncertainty is critical for many analytical tasks. One common approach is to encode data values and uncertainty values independently, using two visual variables. These resulting bivariate maps can be difficult to interpret, and interference between visual channels can reduce the discriminability of marks. To address this issue, we contribute Value-Suppressing Uncertainty Palettes (VSUPs). VSUPs allocate larger ranges of a visual channel to data when uncertainty is low, and smaller ranges when uncertainty is high. This non-uniform budgeting of the visual channels makes more economical use of the limited visual encoding space when uncertainty is low, and encourages more cautious decision-making when uncertainty is high. We demonstrate several examples of VSUPs, and present a crowdsourced evaluation showing that, compared to traditional bivariate maps, VSUPs encourage people to more heavily weight uncertainty information in decision-making tasks.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {color perception, thematic maps, semiotics, uncertainty visualization},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174217,
author = {Raza, Agha Ali and Saleem, Bilal and Randhawa, Shan and Tariq, Zain and Athar, Awais and Saif, Umar and Rosenfeld, Roni},
title = {Baang: A Viral Speech-Based Social Platform for Under-Connected Populations},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174217},
doi = {10.1145/3173574.3174217},
abstract = {Speech is more natural than text for a large part of the world including hard-to-reach populations (low-literate, poor, tech-novice, visually-impaired, marginalized) and oral cultures. Voice-based services over simple mobile phones are effective means to provide orality-driven social connectivity to such populations. We present Baang, a versatile and inclusive voice-based social platform that allows audio content creation and sharing among its open community of users. Within 8 months, Baang spread virally to 10,721 users (69% of them blind) who participated in 269,468 calls and shared their thoughts via 44,178 audio-posts, 343,542 votes, 124,389 audio-comments and 94,864 shares. We show that the ability to vote, comment and share leads to viral spread, deeper engagement, longer retention and emergence of true dialog among participants. Beyond connectivity, Baang provides its users with a voice and a social identity as well as means to share information and get community support.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ivr, mobile phone, telephone, speech-based social networks, ict4d, blind users, hci4d, low-literate, pakistan},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174218,
author = {Strasnick, Evan and Holz, Christian and Ofek, Eyal and Sinclair, Mike and Benko, Hrvoje},
title = {Haptic Links: Bimanual Haptics for Virtual Reality Using Variable Stiffness Actuation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174218},
doi = {10.1145/3173574.3174218},
abstract = {We present Haptic Links, electro-mechanically actuated physical connections capable of rendering variable stiffness between two commodity handheld virtual reality (VR) controllers. When attached, Haptic Links can dynamically alter the forces perceived between the user's hands to support the haptic rendering of a variety of two-handed objects and interactions. They can rigidly lock controllers in an arbitrary configuration, constrain specific degrees of freedom or directions of motion, and dynamically set stiffness along a continuous range. We demonstrate and compare three prototype Haptic Links: Chain, Layer-Hinge, and Ratchet-Hinge. We then describe interaction techniques and scenarios leveraging the capabilities of each. Our user evaluation results confirm that users can perceive many two-handed objects or interactions as more realistic with Haptic Links than with typical unlinked VR controllers.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {variable stiffness, virtual reality, haptic links, controller, two-handed, haptics},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174219,
author = {Frey, J\'{e}r\'{e}my and Grabli, May and Slyper, Ronit and Cauchard, Jessica R.},
title = {Breeze: Sharing Biofeedback through Wearable Technologies},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174219},
doi = {10.1145/3173574.3174219},
abstract = {Digitally presenting physiological signals as biofeedback to users raises awareness of both body and mind. This paper describes the effectiveness of conveying a physiological signal often overlooked for communication: breathing. We present the design and development of digital breathing patterns and their evaluation along three output modalities: visual, audio, and haptic. We also present Breeze, a wearable pendant placed around the neck that measures breathing and sends biofeedback in real-time. We evaluated how the breathing patterns were interpreted in a fixed environment and gathered qualitative data on the wearable device's design. We found that participants intentionally modified their own breathing to match the biofeedback, as a technique for understanding the underlying emotion. Our results describe how the features of the breathing patterns and the feedback modalities influenced participants' perception. We include guidelines and suggested use cases, such as Breeze being used by loved ones to increase connectedness and empathy.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {breathing, signal processing, affective computing, physiological computing, wearables},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174220,
author = {Dhakal, Vivek and Feit, Anna Maria and Kristensson, Per Ola and Oulasvirta, Antti},
title = {Observations on Typing from 136 Million Keystrokes},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174220},
abstract = {We report on typing behaviour and performance of 168,000 volunteers in an online study. The large dataset allows detailed statistical analyses of keystroking patterns, linking them to typing performance. Besides reporting distributions and confirming some earlier findings, we report two new findings. First, letter pairs that are typed by different hands or fingers are more predictive of typing speed than, for example, letter repetitions. Second, rollover-typing, wherein the next key is pressed before the previous one is released, is sur- prisingly prevalent. Notwithstanding considerable variation in typing patterns, unsupervised clustering using normalised inter-key intervals reveals that most users can be divided into eight groups of typists that differ in performance, accuracy, hand and finger usage, and rollover. The code and dataset are released for scientific use.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12}
}

@inproceedings{10.1145/3173574.3174221,
author = {Speicher, Marco and Feit, Anna Maria and Ziegler, Pascal and Kr\"{u}ger, Antonio},
title = {Selection-Based Text Entry in Virtual Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174221},
doi = {10.1145/3173574.3174221},
abstract = {In recent years, Virtual Reality (VR) and 3D User Interfaces (3DUI) have seen a drastic increase in popularity, especially in terms of consumer-ready hardware and software. While the technology for input as well as output devices is market ready, only a few solutions for text input exist, and empirical knowledge about performance and user preferences is lacking. In this paper, we study text entry in VR by selecting characters on a virtual keyboard. We discuss the design space for assessing selection-based text entry in VR. Then, we implement six methods that span different parts of the design space and evaluate their performance and user preferences. Our results show that pointing using tracked hand-held controllers outperforms all other methods. Other methods such as head pointing can be viable alternatives depending on available resources. We summarize our findings by formulating guidelines for choosing optimal virtual keyboard text entry methods in VR.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user experience, task performance, pointing, text entry, mid-air, virtual reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174222,
author = {Sumi, Yasuyuki and Suwa, Masaki and Hanaue, Koichi},
title = {Effects of Viewing Multiple Viewpoint Videos on Metacognition of Collaborative Experiences},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174222},
doi = {10.1145/3173574.3174222},
abstract = {This paper discusses the effects of multiple viewpoint videos for metacognition of experiences. We present a system for recording multiple users' collaborative experiences by wearable and environmental sensors, and another system for viewing multiple viewpoint videos automatically identified and extracted to associate to individual users. We designed an experiment to compare the metacognition of one's own experience between those based on memory and those supported by video viewing. The experimental results show that metacognitive descriptions related to one's own mind, such as feelings and preferences, are possible regardless whether a person is viewing videos, but such episodic descriptions as the content of someone's utterance and what s/he felt associated with it are strongly promoted by video viewing. We conducted another experiment where the same participants did identical metacognitive description tasks about half a year after the previous experiment. Through the experiments, we found the first-person view video is mostly used for confirming the episodic facts immediately after the experience, whereas after half a year, even one's own experience is often felt like the experiences of others therefore the videos capturing themselves from the conversation partners and environment become important for thinking back to the situations where they were placed.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {metacognition, experience capturing, multiple viewpoint videos},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174223,
author = {Oh, Changhoon and Song, Jungwoo and Choi, Jinhan and Kim, Seonghyeon and Lee, Sungwoo and Suh, Bongwon},
title = {I Lead, You Help but Only with Enough Details: Understanding User Experience of Co-Creation with Artificial Intelligence},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174223},
doi = {10.1145/3173574.3174223},
abstract = {Recent advances in artificial intelligence (AI) have increased the opportunities for users to interact with the technology. Now, users can even collaborate with AI in creative activities such as art. To understand the user experience in this new user--AI collaboration, we designed a prototype, DuetDraw, an AI interface that allows users and the AI agent to draw pictures collaboratively. We conducted a user study employing both quantitative and qualitative methods. Thirty participants performed a series of drawing tasks with the think-aloud method, followed by post-hoc surveys and interviews. Our findings are as follows: (1) Users were significantly more content with DuetDraw when the tool gave detailed instructions. (2) While users always wanted to lead the task, they also wanted the AI to explain its intentions but only when the users wanted it to do so. (3) Although users rated the AI relatively low in predictability, controllability, and comprehensibility, they enjoyed their interactions with it during the task. Based on these findings, we discuss implications for user interfaces where users can collaborate with AI in creative works.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-ai interaction, human computer collaboration, artificial intelligence},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174224,
author = {Mishra, Sonali R. and Miller, Andrew D. and Haldar, Shefali and Khelifi, Maher and Eschler, Jordan and Elera, Rashmi G. and Pollack, Ari H. and Pratt, Wanda},
title = {Supporting Collaborative Health Tracking in the Hospital: Patients' Perspectives},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174224},
doi = {10.1145/3173574.3174224},
abstract = {The hospital setting creates a high-stakes environment where patients' lives depend on accurate tracking of health data. Despite recent work emphasizing the importance of patients' engagement in their own health care, less is known about how patients track their health and care in the hospital. Through interviews and design probes, we investigated hospitalized patients' tracking activity and analyzed our results using the stage-based personal informatics model. We used this model to understand how to support the tracking needs of hospitalized patients at each stage. In this paper, we discuss hospitalized patients' needs for collaboratively tracking their health with their care team. We suggest future extensions of the stage-based model to accommodate collaborative tracking situations, such as hospitals, where data is collected, analyzed, and acted on by multiple people. Our findings uncover new directions for HCI research and highlight ways to support patients in tracking their care and improving patient safety.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {hospital, patient engagement, patient safety, health informatics, patient-clinician collaboration, personal informatics, self-tracking},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174225,
author = {Chen, Le and Ma, Ruijun and Hann\'{a}k, Anik\'{o} and Wilson, Christo},
title = {Investigating the Impact of Gender on Rank in Resume Search Engines},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174225},
abstract = {In this work we investigate gender-based inequalities in the context of resume search engines, which are tools that allow recruiters to proactively search for candidates based on keywords and filters. If these ranking algorithms take demographic features into account (directly or indirectly), they may produce rankings that disadvantage some candidates. We collect search results from Indeed, Monster, and CareerBuilder based on 35 job titles in 20 U. S. cities, resulting in data on 855K job candidates. Using statistical tests, we examine whether these search engines produce rankings that exhibit two types of indirect discrimination: individual and group unfairness. Furthermore, we use controlled experiments to show that these websites do not use inferred gender of candidates as explicit features in their ranking algorithms.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{10.1145/3173574.3174226,
author = {Fridman, Lex and Reimer, Bryan and Mehler, Bruce and Freeman, William T.},
title = {Cognitive Load Estimation in the Wild},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174226},
doi = {10.1145/3173574.3174226},
abstract = {Cognitive load has been shown, over hundreds of validated studies, to be an important variable for understanding human performance. However, establishing practical, non-contact approaches for automated estimation of cognitive load under real-world conditions is far from a solved problem. Toward the goal of designing such a system, we propose two novel vision-based methods for cognitive load estimation, and evaluate them on a large-scale dataset collected under real-world driving conditions. Cognitive load is defined by which of 3 levels of a validated reference task the observed subject was performing. On this 3-class problem, our best proposed method of using 3D convolutional neural networks achieves 86.1% accuracy at predicting task-induced cognitive load in a sample of 92 subjects from video alone. This work uses the driving context as a training and evaluation dataset, but the trained network is not constrained to the driving environment as it requires no calibration and makes no assumptions about the subject's visual appearance, activity, head pose, scale, and perspective.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {human-centered artificial intelligence, deep learning},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174227,
author = {Mayer, Sven and Schwind, Valentin and Schweigert, Robin and Henze, Niels},
title = {The Effect of Offset Correction and Cursor on Mid-Air Pointing in Real and Virtual Environments},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174227},
doi = {10.1145/3173574.3174227},
abstract = {Pointing at remote objects to direct others' attention is a fundamental human ability. Previous work explored methods for remote pointing to select targets. Absolute pointing techniques that cast a ray from the user to a target are affected by humans' limited pointing accuracy. Recent work suggests that accuracy can be improved by compensating systematic offsets between targets a user aims at and rays cast from the user to the target. In this paper, we investigate mid-air pointing in the real world and virtual reality. Through a pointing study, we model the offsets to improve pointing accuracy and show that being in a virtual environment affects how users point at targets. In the second study, we validate the developed model and analyze the effect of compensating systematic offsets. We show that the provided model can significantly improve pointing accuracy when no cursor is provided. We further show that a cursor improves pointing accuracy but also increases the selection time.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cursor, modeling, offset correction, ray casting, mid-air pointing, virtual environment},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174228,
author = {Choi, Inrak and Ofek, Eyal and Benko, Hrvoje and Sinclair, Mike and Holz, Christian},
title = {CLAW: A Multifunctional Handheld Haptic Controller for Grasping, Touching, and Triggering in Virtual Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174228},
doi = {10.1145/3173574.3174228},
abstract = {CLAW is a handheld virtual reality controller that augments the typical controller functionality with force feedback and actuated movement to the index finger. Our controller enables three distinct interactions (grasping virtual object, touching virtual surfaces, and triggering) and changes its corresponding haptic rendering by sensing the differences in the user's grasp. A servo motor coupled with a force sensor renders controllable forces to the index finger during grasping and touching. Using position tracking, a voice coil actuator at the index fingertip generates vibrations for various textures synchronized with finger movement. CLAW also supports a haptic force feedback in the trigger mode when the user holds a gun. We describe the design considerations for CLAW and evaluate its performance through two user studies. The first study obtained qualitative user feedback on the naturalness, effectiveness, and comfort when using the device. The second study investigated the ease of the transition between grasping and touching when using our device.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {touching, force feedback, trigger, haptics, controller design, texture, virtual reality, grasping},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174229,
author = {van Oosterhout, Anke and Bruns Alonso, Miguel and Jumisko-Pyykk\"{o}, Satu},
title = {Ripple Thermostat: Affecting the Emotional Experience through Interactive Force Feedback and Shape Change},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174229},
doi = {10.1145/3173574.3174229},
abstract = {Force feedback and shape change are modalities with a growing application potential beyond the more traditional GUIs. We present two studies that explored the effect of these modalities on the emotional experience when interacting with an intelligent thermostat. The first study compared visual feedback, force feedback, and a combination of force feedback and shape change. Results indicate that force feedback correlates to experienced dominance during interaction, while shape change mainly affects experienced arousal. The second study explored how force feedback and shape change could communicate affective meaning during interaction with the thermostat through a co-design study. Participants designed the thermostat behavior for three scenarios supporting energy savings. Results suggest that despite their abstractness, force feedback and shape change convey affective meaning during the user-system dialogue. The findings contribute to the design of intelligible and intuitive feedback.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {actuated interfaces, shape-changing interfaces, affective computing, haptic force feedback},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174230,
author = {Woodruff, Allison and Fox, Sarah E. and Rousso-Schindler, Steven and Warshaw, Jeffrey},
title = {A Qualitative Exploration of Perceptions of Algorithmic Fairness},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174230},
doi = {10.1145/3173574.3174230},
abstract = {Algorithmic systems increasingly shape information people are exposed to as well as influence decisions about employment, finances, and other opportunities. In some cases, algorithmic systems may be more or less favorable to certain groups or individuals, sparking substantial discussion of algorithmic fairness in public policy circles, academia, and the press. We broaden this discussion by exploring how members of potentially affected communities feel about algorithmic fairness. We conducted workshops and interviews with 44 participants from several populations traditionally marginalized by categories of race or class in the United States. While the concept of algorithmic fairness was largely unfamiliar, learning about algorithmic (un)fairness elicited negative feelings that connect to current national discussions about racial injustice and economic inequality. In addition to their concerns about potential harms to themselves and society, participants also indicated that algorithmic fairness (or lack thereof) could substantially affect their trust in a company or product.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {algorithmic fairness, algorithmic discrimination},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174231,
author = {Neustaedter, Carman and Jones, Brennan and O'Hara, Kenton and Sellen, Abigail},
title = {The Benefits and Challenges of Video Calling for Emergency Situations},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174231},
doi = {10.1145/3173574.3174231},
abstract = {In the coming years, emergency calling services in North America will begin to incorporate new modalities for reporting emergencies, including video-based calling. The challenge is that we know little of how video calling systems should be designed and what benefits or challenges video calling might bring. We conducted observations and contextual interviews within three emergency response call centres to investigate these points. We focused on the work practices of call takers and dispatchers. Results show that video calls could provide valuable contextual information about a situation and help to overcome call taker challenges with information ambiguity, location, deceit, and communication issues. Yet video calls have the potential to introduce issues around control, information overload, and privacy if systems are not designed well. These results point to the need to think about emergency video calling along a continuum of visual modalities ranging from audio calls accompanied with images or video clips to one-way video streams to two-way video streams where camera control and camera work need to be carefully designed.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {call takers, emergency calling, situation awareness, dispatchers, collaboration, mobile video calling},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174232,
author = {Gil, Hyunjae and Son, Hyungki and Kim, Jin Ryong and Oakley, Ian},
title = {Whiskers: Exploring the Use of Ultrasonic Haptic Cues on the Face},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174232},
doi = {10.1145/3173574.3174232},
abstract = {Haptic cues are a valuable feedback mechanism for smart glasses. Prior work has shown how they can support navigation, deliver notifications and cue targets. However, a focus on actuation technologies such as mechanical tactors or fans has restricted the scope of research to a small number of cues presented at fixed locations. To move beyond this limitation, we explore perception of in-air ultrasonic haptic cues on the face. We present two studies examining the fundamental properties of localization, duration and movement perception on three facial sites suitable for use with glasses: the cheek, the center of the forehead, and above the eyebrow. The center of the forehead led to optimal performance with a localization error of 3.77mm and accurate duration (80%) and movement perception (87%). We apply these findings in a study delivering eight different ultrasonic notifications and report mean recognition rates of up to 92.4% (peak: 98.6%). We close with design recommendations for ultrasonic haptic cues on the face.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {face, tactile, smartglasses, notifications, haptic},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inbook{10.1145/3173574.3174233,
author = {Hiniker, Alexis and Lee, Bongshin and Kientz, Julie A. and Radesky, Jenny S.},
title = {Let's Play! Digital and Analog Play between Preschoolers and Parents},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174233},
abstract = {Play is an enjoyable and developmentally useful part of early childhood, and parent-child play is a highly productive mechanism by which children learn to participate in the world. We conducted an observational lab study to examine how 15 parent-child pairs (children age 4-6) respond to and play with tablet apps as compared to analog toys. We found that parents and children were less likely to engage with each other or to respond to each other's bids for attention during play sessions with tab-lets versus play sessions with toys. We also observed that specific design features of tablet devices and children's apps-such as one-sided interfaces, game paradigms that demand continual attention, and lack of support for parallel interaction-are the primary mechanism shaping these differences. We provide guidance suggesting how children's apps might be re-designed to preserve the ad-vantages of digital play experiences while also evolving to build in the advantages of traditional toys.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13}
}

@inbook{10.1145/3173574.3174234,
author = {Birk, Max V. and Mandryk, Regan L.},
title = {Combating Attrition in Digital Self-Improvement Programs Using Avatar Customization},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174234},
abstract = {Digital self-improvement programs (e.g., interventions, training programs, self-help apps) are widely accessible, but can not employ the same degree of external regulation as programs delivered in controlled environments. As a result, they suffer from high attrition -- even the best programs won't work if people don't use them. We propose that volitional engagement -- facilitated through avatar customization -- can help combat attrition. We asked 250 participants to engage daily for 3 weeks in a one-minute breathing exercise for anxiety reduction, using either a generic avatar or one that they customized. Customizing an avatar resulted in significantly less attrition and more sustained engagement as measured through login counts. The problem of attrition affects self-improvement programs across a range of do-mains; we provide a subtle, versatile, and broadly-applicable solution.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15}
}

@inproceedings{10.1145/3173574.3174235,
author = {Corsten, Christian and Voelker, Simon and Link, Andreas and Borchers, Jan},
title = {Use the Force Picker, Luke: Space-Efficient Value Input on Force-Sensitive Mobile Touchscreens},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174235},
doi = {10.1145/3173574.3174235},
abstract = {Picking values from long ordered lists, such as when setting a date or time, is a common task on smartphones. However, the system pickers and tables used for this require significant screen space for spinning and dragging, covering other information or pushing it off-screen. The Force Picker reduces this footprint by letting users increase and decrease values over a wide range using force touch for rate-based control. However, changing input direction this way is difficult. We propose three techniques to address this. With our best candidate, Thumb-Roll, the Force Picker lets untrained users achieve similar accuracy as a standard picker, albeit less quickly. Shrinking it to a single table row, 20% of the iOS picker height, slightly affects completion time, but not accuracy. Intriguingly, after 70 minutes of training, users were significantly faster with this minimized Thumb-Roll Picker compared to the standard picker, at the same accuracy and only 6% of the gesture footprint. We close with application examples.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {rate-based control, value input, bidirectional, pressure, force},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174236,
author = {Su, Qingkun and Bai, Xue and Fu, Hongbo and Tai, Chiew-Lan and Wang, Jue},
title = {Live Sketch: Video-Driven Dynamic Deformation of Static Drawings},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174236},
doi = {10.1145/3173574.3174236},
abstract = {Creating sketch animations using traditional tools requires special artistic skills, and is tedious even for trained professionals. To lower the barrier for creating sketch animations, we propose a new system, emphLive Sketch,&lt;/i&gt; which allows novice users to interactively bring static drawings to life by applying deformation-based animation effects that are extracted from video examples. Dynamic deformation is first extracted as a sparse set of moving control points from videos and then transferred to a static drawing. Our system addresses a few major technical challenges, such as motion extraction from video, video-to-sketch alignment, and many-to-one motion-driven sketch animation. While each of the sub-problems could be difficult to solve fully automatically, we present reliable solutions by combining new computational algorithms with intuitive user interactions. Our pilot study shows that our system allows both users with or without animation skills to easily add dynamic deformation to static drawings.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {motion transfer, dynamic deformation, video examples, sketch animation, motion extraction},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174237,
author = {Xu, Ke and Guo, Shunan and Cao, Nan and Gotz, David and Xu, Aiwen and Qu, Huamin and Yao, Zhenjie and Chen, Yixin},
title = {ECGLens: Interactive Visual Exploration of Large Scale ECG Data for Arrhythmia Detection},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174237},
doi = {10.1145/3173574.3174237},
abstract = {The Electrocardiogram (ECG) is commonly used to detect arrhythmias. Traditionally, a single ECG observation is used for diagnosis, making it difficult to detect irregular arrhythmias. Recent technology developments, however, have made it cost-effective to collect large amounts of raw ECG data over time. This promises to improve diagnosis accuracy, but the large data volume presents new challenges for cardiologists. This paper introduces ECGLens, an interactive system for arrhythmia detection and analysis using large-scale ECG data. Our system integrates an automatic heartbeat classification algorithm based on convolutional neural network, an outlier detection algorithm, and a set of rich interaction techniques. We also introduce A-glyph, a novel glyph designed to improve the readability and comparison of ECG signals. We report results from a comprehensive user study showing that A-glyph improves the efficiency in arrhythmia detection, and demonstrate the effectiveness of ECGLens in arrhythmia detection through two expert interviews.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual design, health - clinical, interaction design, visualization, artifact or system},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174238,
author = {Wood, Matthew and Garbett, Andrew and Morrissey, Kellie and Hopkins, Peter and Balaam, Madeline},
title = {"Protection on That Erection?": Discourses of Accountability &amp; Compromising Participation in Digital Sexual Health},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174238},
doi = {10.1145/3173574.3174238},
abstract = {This paper analyses sexual health workers' 'talk' around their introduction of a digital platform to enhance a regionally managed condom distribution scheme for young people. In examining the discursive resources workers used in framing the sexual health service, their service users and digital technology, we argue that problematic ideologies around young people and sexuality were exercised and reproduced. Workers positioned themselves as the gatekeepers of young people's sexual health, who were in turn constructed as 'mischievous' and 'misguided', with technology having a corruptive role over what was considered to be 'healthy' and 'normal' sexual relationships. We suggest our findings indicate severe challenges in developing community-commissioned platforms alongside service providers, and questions how plausible user participation can be in attempting to conduct collaborative, participatory and engaged work in this context.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {discursive psychology, discourse, sexual health},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174239,
author = {Paredes, Pablo E. and Ordonez, Francisco and Ju, Wendy and Landay, James A.},
title = {Fast &amp; Furious: Detecting Stress with a Car Steering Wheel},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174239},
doi = {10.1145/3173574.3174239},
abstract = {Stress affects the lives of millions of people every day. In-situ sensing could enable just-in-time stress management interventions. We present the first work to detect stress using the movements of a car's existing steering wheel. We extend prior work on PC peripherals and demonstrate that stress, expressed through muscle tension in the limbs, can be measured through the way we drive a car. We collected data in a driving simulator under controlled circumstances to vary the levels of induced stress, within subjects. We analyze angular displacement data to estimate coefficients related to muscle tension using an inverse filtering technique. We prove that the damped frequency of a mass spring damper model representing the arm is significantly higher during stress. Stress can be detected with only a few turns during driving. We validate these measures against a known stressor and calibrate our sensor against known stress measurements.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {stress detection, stress management, stress measurement, driving, stressor, modeling, infrastructure mediated sensing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174240,
author = {Chancellor, Stevie and Hu, Andrea and De Choudhury, Munmun},
title = {Norms Matter: Contrasting Social Support Around Behavior Change in Online Weight Loss Communities},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174240},
doi = {10.1145/3173574.3174240},
abstract = {Online health communities (OHCs) provide support across conditions; for weight loss, OHCs offer support to foster positive behavior change. However, weight loss behaviors can also be subverted on OHCs to promote disordered eating practices. Using comments as proxies for support, we use computational linguistic methods to juxtapose similarities and differences in two Reddit weight loss communities, r/proED and r/loseit. We employ language modeling and find that word use in both communities is largely similar. Then, by building a word embedding model, specifically a deep neural network on comment words, we contrast the context of word use and find differences that imply different behavior change goals in these OHCs. Finally, these content and context norms predict whether a comment comes from r/proED or r/loseit. We show that norms matter in understanding how different OHCs provision support to promote behavior change and discuss the implications for design and moderation of OHCs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {reddit, online health communities, behavior change, social support, weight loss, social media},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174241,
author = {Freed, Diana and Palmer, Jackeline and Minchala, Diana and Levy, Karen and Ristenpart, Thomas and Dell, Nicola},
title = {“A Stalker's Paradise”: How Intimate Partner Abusers Exploit Technology},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174241},
doi = {10.1145/3173574.3174241},
abstract = {This paper describes a qualitative study with 89 participants that details how abusers in intimate partner violence (IPV) contexts exploit technologies to intimidate, threaten, monitor, impersonate, harass, or otherwise harm their victims. We show that, at their core, many of the attacks in IPV contexts are technologically unsophisticated from the perspective of a security practitioner or researcher. For example, they are often carried out by a UI-bound adversary - an adversarial but authenticated user that interacts with a victim»s device or account via standard user interfaces - or by downloading and installing a ready-made application that enables spying on a victim. Nevertheless, we show how the sociotechnical and relational factors that characterize IPV make such attacks both extremely damaging to victims and challenging to counteract, in part because they undermine the predominant threat models under which systems have been designed. We discuss the nature of these new IPV threat models and outline opportunities for HCI research and design to mitigate these attacks.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {safety, security, privacy, domestic violence, intimate partner violence, domestic abuse, violence against women, ipv},
location = {Montreal QC, Canada},
series = {CHI '18}
}

