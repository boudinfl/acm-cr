@inproceedings{10.1145/3025453.3025842,
author = {Zhang, Yang and Laput, Gierad and Harrison, Chris},
title = {Electrick: Low-Cost Touch Sensing Using Electric Field Tomography},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025842},
doi = {10.1145/3025453.3025842},
abstract = {Current touch input technologies are best suited for small and flat applications, such as smartphones, tablets and kiosks. In general, they are too expensive to scale to large surfaces, such as walls and furniture, and cannot provide input on objects having irregular and complex geometries, such as tools and toys. We introduce Electrick, a low-cost and versatile sensing technique that enables touch input on a wide variety of objects and surfaces, whether small or large, flat or irregular. This is achieved by using electric field tomography in concert with an electrically conductive material, which can be easily and cheaply added to objects and surfaces. We show that our technique is compatible with commonplace manufacturing methods, such as spray/brush coating, vacuum forming, and casting/molding enabling a wide range of possible uses and outputs. Our technique can also bring touch interactivity to rapidly fabricated objects, including those that are laser cut or 3D printed. Through a series of studies and illustrative example uses, we show that Electrick can enable new interactive opportunities on a diverse set of objects and surfaces that were previously static.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interactivity tools., rapid prototyping, electric field sensing, touch sensing, finger tracking, tomography},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025719,
author = {Sahdev, Sidharth and Forlines, Clifton and Jota, Ricardo and De Araujo, Bruno and Moseley, Braon and Deber, Jonathan and Sanders, Steven and Leigh, Darren and Wigdor, Daniel},
title = {GhostID: Enabling Non-Persistent User Differentiation in Frequency-Division Capacitive Multi-Touch Sensors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025719},
doi = {10.1145/3025453.3025719},
abstract = {Current touch devices are adept at tracking finger touches, but cannot distinguish if multiple touches are caused by different fingers on a single hand, by fingers from both hands of a single user, or by different users. This limitation significantly reduces the possibilities for interaction techniques in touch interfaces. We present GhostID, a capacitive sensor that can differentiate the origins of multiple simultaneous touches. Our approach analyzes the signal ghosting, already present as an artifact in a frequency-division touch controller, to differentiate touches from the same hand or different hands of a single user (77% reliability at 60 fps) or from two different users (95% reliability at 60 fps). In addition to GhostID, we also develop a framework of user-differentiation capabilities for touch input devices, and illustrate a set of interaction techniques enabled by GhostID.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {15–27},
numpages = {13},
keywords = {mobility, capacitive touch sensor, user differentiation, signal processing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026004,
author = {Amores, Judith and Maes, Pattie},
title = {Essence: Olfactory Interfaces for Unconscious Influence of Mood and Cognitive Performance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026004},
doi = {10.1145/3025453.3026004},
abstract = {The sense of smell is perhaps the most pervasive of all senses, but it is also one of the least understood and least exploited in HCI. We present Essence, the first olfactory computational necklace that can be remotely controlled through a smartphone and can vary the intensity and frequency of the released scent based on biometric or contextual data. This paper discusses the role of smell in designing pervasive systems that affect one's mood and cognitive performance while being asleep or awake. We present a set of applications for this type of technology as well as the implementation of the olfactory display and the supporting software. We also discuss the results of an initial test of the prototype that show the robustness and usability of Essence while wearing it for long periods of time in multiple environments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {28–34},
numpages = {7},
keywords = {smell, olfactory interfaces, fabrication, wearable computers, behavior change, pervasive, fashion/clothing, unconscious, prototyping/implementation, health - wellbeing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025793,
author = {Evans, Abigail C. and Davis, Katie and Fogarty, James and Wobbrock, Jacob O.},
title = {Group Touch: Distinguishing Tabletop Users in Group Settings via Statistical Modeling of Touch Pairs},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025793},
doi = {10.1145/3025453.3025793},
abstract = {We present Group Touch, a method for distinguishing among multiple users simultaneously interacting with a tabletop computer using only the touch information supplied by the device. Rather than tracking individual users for the duration of an activity, Group Touch distinguishes users from each other by modeling whether an interaction with the tabletop corresponds to either: (1) a new user, or (2) a change in users currently interacting with the tabletop. This reframing of the challenge as distinguishing users rather than tracking and identifying them allows Group Touch to support multi-user collaboration in real-world settings without custom instrumentation. Specifically, Group Touch examines pairs of touches and uses the difference in orientation, distance, and time between two touches to determine whether the same person performed both touches in the pair. Validated with field data from high-school students in a classroom setting, Group Touch distinguishes among users "in the wild" with a mean accuracy of 92.92% (SD=3.94%). Group Touch can imbue collaborative touch applications in real-world settings with the ability to distinguish among multiple users.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {35–47},
numpages = {13},
keywords = {distinguishing users, tabletop, "in the wild", modeling},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025642,
author = {Haimson, Oliver L. and Tang, John C.},
title = {What Makes Live Events Engaging on Facebook Live, Periscope, and Snapchat},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025642},
doi = {10.1145/3025453.3025642},
abstract = {Live streaming platforms bring events from all around the world to people's computing devices. We conducted a mixed methods study including interviews (N = 42) and a survey (N = 223) to understand how people currently experience events using Facebook Live, Periscope, and Snapchat Live Stories. We identified four dimensions that make remote event viewing engaging: immersion, immediacy, interaction, and sociality. We find that both live streams and the more curated event content found on Snapchat are immersive and immediate, yet Snapchat Live Stories enable quickly switching among different views of the event. Live streams, on the other hand, offer real time interaction and sociality in a way that Snapchat Live Stories do not. However, the interaction's impact depends on comment volume, comment content, and relationship between viewer and broadcaster. We describe how people experience events remotely using these social media, and identify design opportunities around detecting exciting content, leveraging multiple viewpoints, and enabling interactivity to create engaging user experiences for remotely participating in events.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {48–60},
numpages = {13},
keywords = {periscope, facebook live, live streams, events, video, social media, user engagement, snapchat},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025662,
author = {Z\"{u}ger, Manuela and Corley, Christopher and Meyer, Andr\'{e} N. and Li, Boyang and Fritz, Thomas and Shepherd, David and Augustine, Vinay and Francis, Patrick and Kraft, Nicholas and Snipes, Will},
title = {Reducing Interruptions at Work: A Large-Scale Field Study of FlowLight},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025662},
doi = {10.1145/3025453.3025662},
abstract = {Due to the high number and cost of interruptions at work, several approaches have been suggested to reduce this cost for knowledge workers. These approaches predominantly focus either on a manual and physical indicator, such as headphones or a closed office door, or on the automatic measure of a worker's interruptibilty in combination with a computer-based indicator. Little is known about the combination of a physical indicator with an automatic interruptibility measure and its long-term impact in the workplace. In our research, we developed the FlowLight, that combines a physical traffic-light like LED with an automatic interruptibility measure based on computer interaction data. In a large-scale and long-term field study with 449 participants from 12 countries, we found, amongst other results, that the FlowLight reduced the interruptions of participants by 46%, increased their awareness on the potential disruptiveness of interruptions and most participants never stopped using it.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {61–72},
numpages = {12},
keywords = {field study, awareness, physical indicator, automatic interruptibility measure, knowledge worker, interruption cost},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025954,
author = {Kokkalis, Nicolas and Fan, Chengdiao and Roith, Johannes and Bernstein, Michael S. and Klemmer, Scott},
title = {MyriadHub: Efficiently Scaling Personalized Email Conversations with Valet Crowdsourcing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025954},
doi = {10.1145/3025453.3025954},
abstract = {Email has scaled our ability to communicate with large groups, but has not equivalently scaled our ability to listen and respond. For example, emailing many people for feedback requires either impersonal surveys or manual effort to hold many similar conversations. To scale personalized conversations, we introduce techniques that exploit similarities across conversations to recycle relevant parts of previous conversations. These techniques reduce the authoring burden, save senders' time, and maintain recipient engagement through personalized responses. We introduce MyriadHub, a mail client where users start conversations and then crowd workers extract underlying conversational patterns and rules to accelerate responses to future similar emails. In a within-subjects experiment comparing MyriadHub to existing mass email techniques, senders spent significantly less time planning events with MyriadHub. In a second experiment comparing MyriadHub to a standard email survey, MyriadHub doubled the recipients' response rate and tripled the number of words in their responses.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {73–84},
numpages = {12},
keywords = {valet crowdsourcing, mail merge, email overload},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025613,
author = {Bentley, Frank and Daskalova, Nediyana and Andalibi, Nazanin},
title = {"If a Person is Emailing You, It Just Doesn't Make Sense": Exploring Changing Consumer Behaviors in Email},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025613},
doi = {10.1145/3025453.3025613},
abstract = {Much of the existing research literature on email use focuses on productivity or work settings. However, personal use of email has rarely been studied in depth. With the growth of messaging platforms being used for an increasing amount of personal communication, yet email use remaining high, we were interested in learning what Americans are using email for in their daily lives in 2016. To explore this topic, we use qualitative data from over 150 interviews with personal email users as well as quantitative data from several larger survey-based studies. We will show that personal email use is very different from what has been previously studied by workplace researchers and that daily use is largely focused on receiving and viewing B2C messages such as coupons, deals, receipts, and event notifications with personal communication over email diminished to a rarer, less-than-daily occurrence. We discuss the implications of this for the design of email and communications clients and present a design and prototype for an application that seeks to support these more frequent uses of consumer email.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {85–95},
numpages = {11},
keywords = {email, mobile devices, communication, b2c, messaging, deals, coupons, consumer},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025849,
author = {Somanath, Sowmya and Oehlberg, Lora and Hughes, Janette and Sharlin, Ehud and Sousa, Mario Costa},
title = { 'Maker' within Constraints: Exploratory Study of Young Learners Using Arduino at a High School in India},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025849},
doi = {10.1145/3025453.3025849},
abstract = {Do-it-yourself (DIY) inspired activities have gained popularity as a means of creative expression and self-directed learning. However, DIY culture is difficult to implement in places with limited technology infrastructure and traditional learning cultures. Our goal is to understand how learners in such a setting react to DIY activities. We present observations from a physical computing workshop with 12 students (13-15 years old) conducted at a high school in India. We observed unique challenges for these students when tackling DIY activities: a high monetary and psychological cost to exploration, limited independent learning resources, difficulties with finding intellectual courage and assumed technical language proficiency. Our participants, however, overcome some of these challenges by adopting their own local strategies: resilience, nonverbal and verbal learning techniques, and creating documentation and fallback circuit versions. Based on our findings, we discuss a set of lessons learned about makerspaces in a context with socio-technical challenges.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {96–108},
numpages = {13},
keywords = {young learners, DIY, maker culture, physical computing, HCI4D, India},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025458,
author = {Chu, Sharon Lynn and Schlegel, Rebecca and Quek, Francis and Christy, Andrew and Chen, Kaiyuan},
title = {<i>'I Make, Therefore I Am'</i>: The Effects of Curriculum-Aligned Making on Children's Self-Identity},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025458},
doi = {10.1145/3025453.3025458},
abstract = {Prior research investigating the effects of incorporating Making into educational contexts has been limited to snapshot studies. These studies however do not allow for the investigation of aspects that require longer-term development and nurture. We present a longitudinal study that investigates the effects of Making on children's degree of science self-efficacy, identity formation as possible scientists and engineers, and academic performance in science. Designed interactions with Making technology were integrated into the science curriculum of elementary school classrooms in a public school with a high proportion of students from minority populations for a year. Results showed significant differences between the "Making classrooms" and the control classrooms, and from pre- to post-test on the students' inclination towards science. The results support the promise and potential of incorporating Making into formal schooling on the growth and long-term attitudes of children towards science and STEM in general.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {109–120},
numpages = {12},
keywords = {maker movement, learning, self-identity, science, education, making, children, stem, self-efficacy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025529,
author = {Landwehr Sydow, Sophie and Tholander, Jakob and Jonsson, Martin},
title = {"It's a Bomb!" -- Material Literacy and Narratives of Making},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025529},
doi = {10.1145/3025453.3025529},
abstract = {This paper analyses a series of events in which a discarded box found in a garbage room is examined and taken apart in the context of a makerspace. The participants' inquiry provided a rich and multifaceted experience in various settings, including puzzle-solving, exploring physical and digital materials, engaging people with different skills. The social engagements with and around the artifacts brought certain interpretative aspects to the fore. Situated acts of interpretation worked as ways of building a coherent narrative and a meaningful experience. In the paper, we highlight the relationship between on the one hand the subjects' skills and motivations to understand and make sense of the technology at hand which we call material literacy, and on the other hand the specific material qualities that encourage or trigger certain interpretations and experiences. The qualities we discuss are: opacity, risk, authenticity, uniqueness, age, and hybridity. This study allows us to reposition the contemporary understanding of makerspaces beyond that of being places for innovation and learning.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {121–132},
numpages = {12},
keywords = {taking apart, experience, maker culture, material qualities, material literacy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025887,
author = {Kazemitabaar, Majeed and McPeak, Jason and Jiao, Alexander and He, Liang and Outing, Thomas and Froehlich, Jon E.},
title = {MakerWear: A Tangible Approach to Interactive Wearable Creation for Children},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025887},
doi = {10.1145/3025453.3025887},
abstract = {Wearable construction toolkits have shown promise in broadening participation in computing and empowering users to create personally meaningful computational designs. However, these kits present a high barrier of entry for some users, particularly young children (K-6). In this paper, we introduce MakerWear, a new wearable construction kit for children that uses a tangible, modular approach to wearable creation. We describe our participatory design process, the iterative development of MakerWear, and results from single- and multi-session workshops with 32 children (ages 5-12; M=8.3 years). Our findings reveal how children engage in wearable design, what they make (and want to make), and what challenges they face. As a secondary analysis, we also explore age-related differences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {133–145},
numpages = {13},
keywords = {e-textiles, stem, wearables, children, construction kits},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025931,
author = {Birbeck, Nataly and Lawson, Shaun and Morrissey, Kellie and Rapley, Tim and Olivier, Patrick},
title = {Self Harmony: Rethinking Hackathons to Design and Critique Digital Technologies for Those Affected by Self-Harm},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025931},
doi = {10.1145/3025453.3025931},
abstract = {In this paper we explore the opportunities, challenges and best practices around designing technologies for those affected by self-harm. Our work contributes to a growing HCI literature on mental health and wellbeing, as well as understandings of how to imbue appropriate value-sensitivity within the digital design process in these contexts. The first phase of our study was centred upon a hackathon during which teams of designers were asked to conceptualise and prototype digital products or services for those affected by self-harm. We discuss how value-sensitive actions and activities, including engagements with those with lived experiences of self-harm, were used to scaffold the conventional hackathon format in such a challenging context. Our approach was then extended through a series of critical engagements with clinicians and charity workers who provided appraisal of the prototypes and designs. Through analysis of these engagements we expose a number of design challenges for future HCI work that considers self-harm; moreover we offer insight into the role of stakeholder critiques in extending and rethinking hackathons as a design method in sensitive contexts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {146–157},
numpages = {12},
keywords = {mental health and wellbeing, self-harm, hackathons},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025843,
author = {Yamashita, Naomi and Kuzuoka, Hideaki and Hirata, Keiji and Kudo, Takashi and Aramaki, Eiji and Hattori, Kazuki},
title = {Changing Moods: How Manual Tracking by Family Caregivers Improves Caring and Family Communication},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025843},
doi = {10.1145/3025453.3025843},
abstract = {Previous research on healthcare technologies has shown how health tracking promotes desired behavior changes and effective health management. However, little is known about how the family caregivers' use of tracking technologies impacts the patient-caregiver relationship in the home. In this paper, we explore how health-tracking technologies could be designed to support family caregivers cope better with a depressed family member. Based on an interview study, we designed a simple tracking tool called Family Mood and Care Tracker (FMCT) and deployed it for six weeks in the homes of 14 family caregivers who were caring for a depressed family member. FMCT is a tracking tool designed specifically for family caregivers to record their caregiving activities and patient's conditions. Our findings demonstrate how caregivers used it to better understand the illness and cope with depressed family members. We also show how our tool improves family communication, despite the initial concerns about patient-caregiver conflicts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {158–169},
numpages = {12},
keywords = {family communication, tracking technology, depression, caregiving, informal caregiver, healthcare technology},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025932,
author = {Manikonda, Lydia and De Choudhury, Munmun},
title = {Modeling and Understanding Visual Attributes of Mental Health Disclosures in Social Media},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025932},
doi = {10.1145/3025453.3025932},
abstract = {Content shared on social media platforms has been identified to be valuable in gaining insights into people's mental health experiences. Although there has been widespread adoption of photo-sharing platforms such as Instagram in recent years, the role of visual imagery as a mechanism of self-disclosure is less understood. We study the nature of visual attributes manifested in images relating to mental health disclosures on Instagram. Employing computer vision techniques on a corpus of thousands of posts, we extract and examine three visual attributes: visual features (e.g., color), themes, and emotions in images. Our findings indicate the use of imagery for unique self-disclosure needs, quantitatively and qualitatively distinct from those shared via the textual modality: expressions of emotional distress, calls for help, and explicit display of vulnerability. We discuss the relationship of our findings to literature in visual sociology, in mental health self disclosure, and implications for the design of health interventions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {170–181},
numpages = {12},
keywords = {instagram, social media, mental health, visual attributes},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025784,
author = {Feuston, Jessica L. and Marshall-Fricker, Charlotte G. and Piper, Anne Marie},
title = {The Social Lives of Individuals with Traumatic Brain Injury},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025784},
doi = {10.1145/3025453.3025784},
abstract = {Traumatic Brain Injury (TBI) can affect all aspects of an individual's life, including physical ability, communication, and mental health, and present chronic health conditions that persist throughout the lifespan. Although prior work documents a decrease in social interaction following brain injury, little is known about how individuals with TBI engage in social behavior during their recovery, how others in their lives participate, and how these interactions occur in both online and offline contexts. We examine these issues through an interview study involving individuals with TBI, as well as caregivers and social contacts of individuals with TBI. Our analysis identifies the concept of social re-emergence, a non-linear process of developing a new social identity that involves withdrawing from social life, developing goals for social participation, disclosing health information for social support and acceptance, and attaining social independence.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {182–194},
numpages = {13},
keywords = {traumatic brain injury, recovery, social interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025467,
author = {Sarracino, John and Barrios-Arciga, Odaris and Zhu, Jasmine and Marcus, Noah and Lerner, Sorin and Wiedermann, Ben},
title = {User-Guided Synthesis of Interactive Diagrams},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025467},
doi = {10.1145/3025453.3025467},
abstract = {Interactive diagrams are expensive to build, requiring significant programming experience. The cost of building such diagrams often prevents novice programmers or non-programmers from doing so. In this paper, we present user-guided techniques that transform a static diagram into an interactive one without requiring the user to write code. We also present a tool called EDDIE that prototypes these techniques. We evaluate EDDIE through: (1) a case study in which we use EDDIE to implement existing real-world diagrams from the literature and (2) a usability session with target users in which subjects build several diagrams in EDDIE and provide feedback on EDDIE's user experience. Our experiments demonstrate that EDDIE is usable and expressive, and that EDDIE enables real-world diagrams to be implemented without requiring programming expertise.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {195–207},
numpages = {13},
keywords = {program synthesis, interactive diagrams},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025984,
author = {Gutwin, Carl and Cockburn, Andy and Coveney, Ashley},
title = {Peripheral Popout: The Influence of Visual Angle and Stimulus Intensity on Popout Effects},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025984},
doi = {10.1145/3025453.3025984},
abstract = {By exploiting visual popout effects, interface designers can rapidly draw a user's attention to salient information objects in a display. A variety of different visual stimuli can be used to achieve popout effects, including color, shape, size, motion, luminance, and flashing. However, there is a lack of understanding about how accurately different intensities of these effects support popout, particularly as targets move further from the center of the visual field. We therefore conducted a study to examine the accuracy of popout target identification using different visual variables, each at five different levels of intensity, and at a wide range of angles from the display center. Results show that motion is a strong popout stimulus, even at low intensities and wide angles. Identification accuracy decreases rapidly across visual angle with other popout stimuli, particularly with shape and color. The findings have relevance to a wide variety of applications, particularly as multi-display desktop environments increase in size and visual extent.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {208–219},
numpages = {12},
keywords = {peripheral vision, information visualization, popout},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025834,
author = {Deza, Arturo and Peters, Jeffrey R. and Taylor, Grant S. and Surana, Amit and Eckstein, Miguel P.},
title = {Attention Allocation Aid for Visual Search},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025834},
doi = {10.1145/3025453.3025834},
abstract = {This paper outlines the development and testing of a novel, feedback-enabled attention allocation aid (AAAD), which uses real-time physiological data to improve human performance in a realistic sequential visual search task. Indeed, by optimizing over search duration, the aid improves efficiency, while preserving decision accuracy, as the operator identifies and classifies targets within simulated aerial imagery. Specifically, using experimental eye-tracking data and measurements about target detectability across the human visual field, we develop functional models of detection accuracy as a function of search time, number of eye movements, scan path, and image clutter. These models are then used by the AAAD in conjunction with real time eye position data to make probabilistic estimations of attained search accuracy and to recommend that the observer either move on to the next image or continue exploring the present image. An experimental evaluation in a scenario motivated from human supervisory control in surveillance missions confirms the benefits of the AAAD.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {220–231},
numpages = {12},
keywords = {decision making, attention, cognitive load, visual search},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025836,
author = {Yamanaka, Shota and Stuerzlinger, Wolfgang and Miyashita, Homei},
title = {Steering Through Sequential Linear Path Segments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025836},
doi = {10.1145/3025453.3025836},
abstract = {The steering law models human motor performance and has been verified to hold for a single linear and/or circular path. Some extensions investigated steering around corners. Yet, little is known about human performance in navigating joined linear paths, i.e., successions of path segments with different widths. Such operations appear in graphical user interface tasks, including lasso operations in illustration software. In this work, we conducted several experiments involving joined paths. The results show that users significantly changed their behavior, and that this strategy change can be predicted beforehand. A simple model summing the two indexes of difficulty (IDs) for each path predicts movement time well, but more sophisticated models were also evaluated. The best model in terms of both of R2 and AIC values includes the ID of the crossing operation to enter the second path.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {232–243},
numpages = {12},
keywords = {motor control, modeling, human performance, graphical user interfaces, steering law, pointing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025951,
author = {Nancel, Mathieu and Lank, Edward},
title = {Modeling User Performance on Curved Constrained Paths},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025951},
doi = {10.1145/3025453.3025951},
abstract = {In 1997, Accot and Zhai presented seminal work analyzing the temporal cost and instantaneous speed profiles associated with movement along constrained paths. Their work posited and validated the emph{steering law}, which described the relationship between path constraint, path length and the temporal cost of path traversal using a computer input device (e.g. a mouse). In this paper, we argue that the steering law fails to correctly model constrained paths of varying, arbitrary curvature, propose a new form of the law that accommodates these curved paths, and empirically validate our model.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {244–254},
numpages = {11},
keywords = {steering law, movement, models.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025625,
author = {Horodniczy, Daniel and Cooperstock, Jeremy R.},
title = {Free the Hands! Enhanced Target Selection via a Variable-Friction Shoe},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025625},
doi = {10.1145/3025453.3025625},
abstract = {While several foot-controlled pointing devices have been explored as alternatives to conventional interfaces, we are interested in whether such devices can achieve higher performance with the addition of variable friction. Users wore our variable-friction prototype shoe on their right foot, which they slid on a low-friction surface to control a mouse cursor. Two interface modes were evaluated: constant (CF) and variable friction (VF), under the ISO 9241-9 standard for pointing device evaluation. For the variable-friction modality, target regions were high friction to provide sliding resistance cues. Our findings confirmed that variable-friction foot-controlled pointing can achieve throughput competitive with a range of hand-controlled devices. This suggests the potential for taking advantage of foot input for simple pointing tasks, in particular when the hands are overloaded. With respect to other foot-controlled pointing systems, our implementation offered improved performance and comparable error rates. In addition, the analysis provided further insight into the design of foot-controlled input devices.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {255–259},
numpages = {5},
keywords = {variable friction, foot-controlled input, fitts' law, haptic feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025660,
author = {Gori, Julien and Rioul, Olivier and Guiard, Yves},
title = {<i>To Miss is Human</i>: Information-Theoretic Rationale for Target Misses in Fitts' Law},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025660},
doi = {10.1145/3025453.3025660},
abstract = {In usual Fitts' law experiments the outcome of a pointing act can be either measured as an error, i.e., a distance from endpoint to target center, or categorized in an all-or-none way as a hit versus a miss. Information theory offers a useful distinction between transmission errors (the received symbol is wrong) and erasures (the received symbol is empty). Although Fitts' law research has been very much inspired by the information theoretic rationale, the error/erasure distinction has escaped attention so far: Target misses have always been treated as normally-distributed errors, through the effective index of difficulty IDe. The paper introduces a new index of difficulty based on the simple observation that a target miss conveys zero bit of information, i.e., it is an erasure. Not only is the new index more consistent with the fundamentals of information theory, it is much simpler to derive than the ISO-recommended IDe.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {260–264},
numpages = {5},
keywords = {human performance models, information theory, fitts' law},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025742,
author = {Lindley, Joseph and Coulton, Paul and Sturdee, Miriam},
title = {Implications for Adoption},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025742},
doi = {10.1145/3025453.3025742},
abstract = {In this paper we explore the motivations for, and practicalities of, incorporating "implications for adoption" into HCI research practice. Implications for adoption are speculations which may be used in research projects to scrutinize and explore the implications and requirements associated with a technology's potential adoption in the future. There is a rich tradition within the HCI community of implementing, demonstrating, and testing new interactions or technologies by building prototypes. User-centered design methods help us to develop prototypes to and move toward designs that are validated, efficient, and rewarding to use. However, these studies rarely shift their temporal focus to consider, in any significant detail, what it would mean for a technology to exist beyond its prototypical implementation, in other words how these prototypes might ultimately be adopted. Given the CHI community's increasing interest in technology-related human and social effects, the lack of attention paid to adoption represents a significant and relevant gap in current practices. It is this gap that the paper addresses and in doing so offers three contributions: (1) exploring and unpacking different notions of adoption from varying disciplinary perspectives; (2) discussing why considering adoption is relevant and useful, specifically in HCI research; (3) discussing methods for addressing this need, specifically design fiction, and understanding how utilizing these methods may provide researchers with means to better understand the myriad of nuanced, situated, and technologically-mediated relationships that innovative designs facilitate.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {265–277},
numpages = {13},
keywords = {prototyping, adoptability, implications for adoption., design fiction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025739,
author = {Dove, Graham and Halskov, Kim and Forlizzi, Jodi and Zimmerman, John},
title = {UX Design Innovation: Challenges for Working with Machine Learning as a Design Material},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025739},
doi = {10.1145/3025453.3025739},
abstract = {Machine learning (ML) is now a fairly established technology, and user experience (UX) designers appear regularly to integrate ML services in new apps, devices, and systems. Interestingly, this technology has not experienced a wealth of design innovation that other technologies have, and this might be because it is a new and difficult design material. To better understand why we have witnessed little design innovation, we conducted a survey of current UX practitioners with regards to how new ML services are envisioned and developed in UX practice. Our survey probed on how ML may or may not have been a part of their UX design education, on how they work to create new things with developers, and on the challenges they have faced working with this material. We use the findings from this survey and our review of related literature to present a series of challenges for UX and interaction design research and education. Finally, we discuss areas where new research and new curriculum might help our community unlock the power of design thinking to re-imagine what ML might be and might do.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {278–288},
numpages = {11},
keywords = {interaction design, ux practice, design material, machine learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025475,
author = {Gonzales, Amy},
title = {Technology Maintenance: A New Frame for Studying Poverty and Marginalization},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025475},
doi = {10.1145/3025453.3025475},
abstract = {This paper offers a new theoretical frame for those interested in poverty and design. As digital access rates peak, technology maintenance argues that the digital divide will increasingly manifest in the (in)ability to stay connected. As a novel and conservative test, open-ended data from a 748-person university student survey of technology maintenance were analyzed. Use and ownership were ubiquitous, but students demonstrated variability in coping with the inevitable; disconnection was more burdensome for low-resourced students. Findings extend technology maintenance and are leveraged as a starting point for three calls for action in HCI: 1) the CHI community should research the burdens of poverty in poor and wealthy contexts; 2) new HCI projects should accommodate inconsistent access; and, 3) new design choices should minimize disruption and optimize stability. This requires action at the individual and organizational level as designers create products that consider marginalization but also use expertise to influence policy.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {289–294},
numpages = {6},
keywords = {digital divide, technology maintenance, poverty, access},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025749,
author = {Koelle, Marion and El Ali, Abdallah and Cobus, Vanessa and Heuten, Wilko and Boll, Susanne CJ},
title = {All about Acceptability? Identifying Factors for the Adoption of Data Glasses},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025749},
doi = {10.1145/3025453.3025749},
abstract = {Innovations often trigger objections before becoming widely accepted. This paper assesses whether a familiarisation over time can be expected for data glasses, too. While user attitudes towards those devices have been reported to be prevalently negative [14], it is still unclear, to what extent this initial, negative user attitude might impede adoption. However, indepth understanding is crucial for reducing barriers early in order to gain access to potential benefits from the technology. With this paper we contribute to a better understanding of factors affecting data glasses adoption, as well as current trends and opinions. Our multiple-year case study (N=118) shows, against expectations, no significant change towards a more positive attitude between 2014 and 2016. We complement these findings with an expert survey (N=51) investigating prognoses, challenges and discussing the relevance of social acceptability. We elicit and contrast a controversial spectrum of expert opinions, and assess whether initial objections can be overwritten. Our analysis shows that while social acceptability is considered relevant for the time being, utility and usability are more valued for long-term adoption.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {295–300},
numpages = {6},
keywords = {Augmented Reality, Technology Adoption, User Acceptance, Data Glasses, Public Experiences, Social Acceptability},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025499,
author = {Michaelis, Joseph E. and Mutlu, Bilge},
title = {Someone to Read with: Design of and Experiences with an In-Home Learning Companion Robot for Reading},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025499},
doi = {10.1145/3025453.3025499},
abstract = {The development of literacy and reading proficiency is a building block of lifelong learning that must be supported both in the classroom and at home. While the promise of interactive learning technologies has widely been demonstrated, little is known about how an interactive robot might play a role in this development. We used eight design features based on recommendations from interest-development and human-robot-interaction literatures to design an in-home learning companion robot for children aged 11--12. The robot was used as a technology probe to explore families' (N=8) habits and views about reading, how a reading technology might be used, and how children perceived reading with the robot. Our results indicate reading with the learning companion to be a way to socially engage with reading, which may promote the development of reading interest and ability. We discuss design and research implications based on our findings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {301–312},
numpages = {12},
keywords = {design probes, reading education, interest development, human-robot interaction, educational robots},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025855,
author = {Rae, Irene and Neustaedter, Carman},
title = {Robotic Telepresence at Scale},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025855},
doi = {10.1145/3025453.3025855},
abstract = {Telepresence robots offer a relatively new way for people to project their presence remotely. However, these experiences have only been studied in controlled or small scale installations. To broaden our understanding of the successes and limitations of telepresence robots in large-scale venues, we conducted a study at CHI 2016 where five factors increased over past research: (1) number of local attendees; (2) ratio of remote users to systems; (3) variety of activities; (4) time zone differences; and, (5) environment size. Our results reveal that unlike small-scale venues and situations, remote users take a more socially isolated and functional approach to remote attendance while combating challenges around scheduling and large navigational spaces. Our results reveal new opportunities for thinking about the design of robot personalization, availability, and navigation for systems targeted at large-scale public contexts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {313–324},
numpages = {12},
keywords = {robots, telepresence, academic conferences},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025734,
author = {Choi, Mina and Kornfield, Rachel and Takayama, Leila and Mutlu, Bilge},
title = {Movement Matters: Effects of Motion and Mimicry on Perception of Similarity and Closeness in Robot-Mediated Communication},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025734},
doi = {10.1145/3025453.3025734},
abstract = {In face-to-face interaction, moving with and mimicking the body movements of communication partners has been widely demonstrated to affect interpersonal processes, including feel- ings of affiliation and closeness. In this paper, we examine effects of movement and mimicry in robot-mediated communication. Participants were instructed to get to know their partner, a confederate, who interacted with them via a telepresence robot. The robot either (a) mimicked the participant's body orientation (mimicry condition), (b) mimicked pre-recorded movements of another participant (random movement condition), or (c) did not move during the interaction (static condition). Results showed that mimicry and random movement had similar effects on participants' perceptions of similarity and closeness to their partners and that these effects depend on the participant's gender and level of self-monitoring. The findings suggest that the social movements of a telepresence robot affect interpersonal processes and that these effects are shaped by individual differences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {325–335},
numpages = {11},
keywords = {robot-mediated communication, closeness, similarity, movement, mimicry, telepresence robots, nonverbal behavior, affiliation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025995,
author = {Zaga, Cristina and de Vries, Roelof A.J. and Li, Jamy and Truong, Khiet P. and Evers, Vanessa},
title = {A Simple Nod of the Head: The Effect of Minimal Robot Movements on Children's Perception of a Low-Anthropomorphic Robot},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025995},
doi = {10.1145/3025453.3025995},
abstract = {In this note, we present minimal robot movements for robotic technology for children. Two types of minimal gaze movements were designed: social-gaze movements to communicate social engagement and deictic-gaze movements to communicate task-related referential information. In a two (social-gaze movements vs. none) by two (deictic-gaze movements vs. none) video-based study (n=72), we found that social-gaze movements significantly increased children's perception of animacy and likeability of the robot. Deictic-gaze and social-gaze movements significantly increased children's perception of helpfulness. Our findings show the compelling communicative power of social-gaze movements, and to a lesser extent deictic-gaze movements, and have implications for designers who want to achieve animacy, likeability and helpfulness with simple and easily implementable minimal robot movements. Our work contributes to human-robot interaction research and design by providing a first indication of the potential of minimal robot movements to communicate social engagement and helpful referential information to children.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {336–341},
numpages = {6},
keywords = {robot behavior, human-robot interaction design, children, nonverbal communication, non-anthropomorphic robot},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025809,
author = {Newhart, Veronica Ahumada and Olson, Judith S.},
title = {My Student is a Robot: How Schools Manage Telepresence Experiences for Students},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025809},
doi = {10.1145/3025453.3025809},
abstract = {Homebound students, those who can learn but have a serious health issue (e.g. cancer, heart disease, immune deficiency) that prevents physical attendance at school, are now able to go to school using telepresence robots. Telepresence robots are generally video conferencing units on remote-controlled robots. Previous research has shown that using these robots allows homebound students to interact with classmates and teachers as if they are physically present. But, what does this mean for teachers and administrators? We present a qualitative study of 22 teachers and school administrators who worked with telepresent students and 4 who decided against adopting the robot. Our goal was to learn how decisions are made to adopt the robot, what issues arise in its use, and what would make adoption easier. This study contributes new insights on teacher and administrator perspectives on what is needed for effective use of this technology in educational settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {342–347},
numpages = {6},
keywords = {education, robots, telepresence},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025999,
author = {Xu, Tianyin and Naing, Han Min and Lu, Le and Zhou, Yuanyuan},
title = {How Do System Administrators Resolve Access-Denied Issues in the Real World?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025999},
doi = {10.1145/3025453.3025999},
abstract = {The efficacy of access control largely depends on how system administrators (sysadmins) resolve access-denied issues. A correct resolution should only permit the expected access, while maintaining the protection against illegal access. However, anecdotal evidence suggests that correct resolutions are occasional---sysadmins often grant too much access (known as security misconfigurations) to allow the denied access, posing severe security risks. This paper presents a quantitative study on real-world practices of resolving access-denied issues, with a particular focus on how and why security misconfigurations are introduced during problem solving. We characterize the real-world security misconfigurations introduced in the field, and show that many of these misconfigurations were the results of trial-and-error practices commonly adopted by sysadmins to work around access denials. We argue that the lack of adequate feedback information is one fundamental reason that prevents sysadmins from developing precise understanding and thus induces trial and error. Our study on access-denied messages shows that many of today's software systems miss the opportunities for providing adequate feedback information, imposing unnecessary obstacles to correct resolutions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {348–361},
numpages = {14},
keywords = {security, access control, configuration, log messages},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025706,
author = {Micinski, Kristopher and Votipka, Daniel and Stevens, Rock and Kofinas, Nikolaos and Mazurek, Michelle L. and Foster, Jeffrey S.},
title = {User Interactions and Permission Use on Android},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025706},
doi = {10.1145/3025453.3025706},
abstract = {Android and other mobile operating systems ask users for authorization before allowing apps to access sensitive resources such as contacts and location. We hypothesize that such authorization systems could be improved by becoming more integrated with the app's user interface. In this paper, we conduct two studies to test our hypothesis. First, we use apptracer{}, a dynamic analysis tool we developed, to measure to what extent user interactions and sensitive resource use are related in existing apps. Second, we conduct an online survey to examine how different interactions with the UI affect users' expectations about whether an app accesses sensitive resources. Our results suggest that user interactions such as button clicks can be interpreted as authorization, reducing the need for separate requests; but that accesses not directly tied to user interactions should be separately authorized, possibly when apps are first launched.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {362–373},
numpages = {12},
keywords = {android, contextual security, permissions, apps},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025879,
author = {Liu, Can and Clark, Gradeigh D. and Lindqvist, Janne},
title = {Where Usability and Security Go Hand-in-Hand: Robust Gesture-Based Authentication for Mobile Systems},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025879},
doi = {10.1145/3025453.3025879},
abstract = {Gestures have recently gained interest as a secure and usable authentication method for mobile devices. Gesture authentication relies on recognition, wherein raw data is collected from user input and preprocessed into a more manageable form before applying recognition algorithms. Preprocessing is done to improve recognition accuracy, but little work has been done in justifying its effects on authentication. We examined the effects of three variables: location, rotation, and scale, on authentication accuracy. We found that an authentication-optimal combination (location invariant, scale variant, and rotation variant) can reduce the error rate by 45.3% on average compared to the recognition-optimal combination (all invariant). We analyzed 13 gesture recognizers and evaluated them with three criteria: authentication accuracy, and resistance against both brute-force and imitation attacks. Our novel multi-expert method (Garda) achieved the lowest error rate (0.015) in authentication accuracy, the lowest error rate (0.040) under imitation attacks, and resisted all brute-force attacks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {374–386},
numpages = {13},
keywords = {authentication, mobile device, gesture, security},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025788,
author = {Huh, Jun Ho and Kim, Hyoungshick and Rayala, Swathi S.V.P. and Bobba, Rakesh B. and Beznosov, Konstantin},
title = {I'm Too Busy to Reset My LinkedIn Password: On the Effectiveness of Password Reset Emails},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025788},
doi = {10.1145/3025453.3025788},
abstract = {A common security practice used to deal with a password breach is locking user accounts and sending out an email to tell users that they need to reset their password to unlock their account. This paper evaluates the effectiveness of this security practice based on the password reset email that LinkedIn sent out around May 2016, and through an online survey conducted on 249 LinkedIn users who received that email. Our evaluation shows that only about 46% of the participants reset their passwords. The mean time taken to reset password was 26.3 days, revealing that a significant proportion of the participants reset their password a few weeks, or even months after first receiving the email. Our findings suggest that more effective persuasive measures need to be added to convince users to reset their password in a timely manner, and further reduce the risks associated with delaying password resets.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {387–391},
numpages = {5},
keywords = {linkedin, password reset, reset email, password breach},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025507,
author = {van der Heiden, Remo M.A. and Iqbal, Shamsi T. and Janssen, Christian P.},
title = {Priming Drivers before Handover in Semi-Autonomous Cars},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025507},
doi = {10.1145/3025453.3025507},
abstract = {Semi-autonomous vehicles occasionally require control to be handed over to the driver in situations where the vehicle is unable to operate safely. Currently, such handover requests require the driver to take control almost instantaneously. We investigate how auditory pre-alerts that occur well before the handover request impact the success of the handover in a dual task scenario. In a study with a driving simulator, drivers perform tasks on their phone while the car is in an autonomous mode. They receive a repeated burst audio pre-alert or an increasing pulse audio pre-alert preceding the standard warning for immediate handover. Results show that pre-alerts caused people to look more at the road before the handover occurred, and to disengage from the secondary task earlier, compared to when there was no pre-alert. This resulted in safer handover situations. Increasing pulse pre-alerts show particular promise due to their communication of urgency. Our detailed analysis informs the design and evaluation of alerts in safety-critical systems with automation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {392–404},
numpages = {13},
keywords = {automation, handover, multitasking, autonomous cars},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025822,
author = {Sirkin, David and Martelaro, Nikolas and Johns, Mishel and Ju, Wendy},
title = {Toward Measurement of Situation Awareness in Autonomous Vehicles},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025822},
doi = {10.1145/3025453.3025822},
abstract = {Until vehicles are fully autonomous, safety, legal and ethical obligations require that drivers remain aware of the driving situation. Key decisions about whether a driver can take over when the vehicle is confused, or its capabilities are degraded, depend on understanding whether he or she is responsive and aware of external conditions. The leading techniques for measuring situation awareness in simulated environments are ill-suited to autonomous driving scenarios, and particularly to on-road testing. We have developed a technique, named Daze, to measure situation awareness through real-time, in-situ event alerts. The technique is ecologically valid: it resembles applications people use in actual driving. It is also flexible: it can be used in both simulator and on-road research settings. We performed simulator-based and on-road test deployments to (a) check that Daze could characterize drivers' awareness of their immediate environment and (b) understand practical aspects of the technique's use. Our contributions include the Daze technique, examples of collected data, and ways to analyze such data.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {405–415},
numpages = {11},
keywords = {measurement, interaction design, situation awareness, autonomous vehicles},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025462,
author = {Brown, Barry and Laurier, Eric},
title = {The Trouble with Autopilots: Assisted and Autonomous Driving on the Social Road},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025462},
doi = {10.1145/3025453.3025462},
abstract = {As self-driving cars have grown in sophistication and ability, they have been deployed on the road in both localised tests and as regular private vehicles. In this paper we draw upon publicly available videos of autonomous and assisted driving (specifically the Tesla autopilot and Google self-driving car) to explore how their drivers and the drivers of other cars interact with, and make sense of, the actions of these cars. Our findings provide an early perspective on human interaction with new forms of driving involving assisted-car drivers, autonomous vehicles and other road users. The focus is on social interaction on the road, and how drivers communicate through, and interpret, the movement of cars. We provide suggestions toward increasing the transparency of autopilots' actions for both their driver and other drivers.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {416–429},
numpages = {14},
keywords = {autonomous cars, self-driving, video analysis, human-robot-interaction, automobile interfaces, interaction, social road},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025686,
author = {Southern, Caleb and Cheng, Yunnuo and Zhang, Cheng and Abowd, Gregory D.},
title = {Understanding the Cost of Driving Trips},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025686},
doi = {10.1145/3025453.3025686},
abstract = {Driving is the second highest expense for the average American household. Yet few people know the total cost of owning and operating their vehicles, and most cannot estimate accurately how much a common driving trip (like a daily commute) costs. There are an increasing number of viable alternatives for personal transportation, such as car services (e.g. Uber, Lyft), in addition to ridesharing, transit, biking, and walking. Cost is one factor in transportation mode choice, and awareness of the cost of driving is useful in making better informed decisions. To bridge this awareness gap, we built and deployed a system that makes the total cost of each driving trip (including depreciation, maintenance, insurance, and fuel) visible to the user. After this intervention, participants were able to more accurately and confidently estimate costs of their driving commutes, and transfer this knowledge to other trips for which they had not seen a cost.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {430–434},
numpages = {5},
keywords = {transportation, personal informatics, driving, mode choice},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025630,
author = {Chatting, David and Kirk, David S. and Durrant, Abigail C. and Elsden, Chris and Yurman, Paulina and Bichard, Jo-Anne},
title = {Making Ritual Machines: The Mobile Phone as a Networked Material for Research Products},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025630},
doi = {10.1145/3025453.3025630},
abstract = {Viewing the mobile telephone as a networked material, we demonstrate the ways in which we have used it to make Research Products for the "Family Rituals 2.0" inquiry of families separated by work. Drawing from a diversity of sources we survey and deconstruct the phone as a material that can be worked to a vast range of technical effects, extended by hardware and configured by software. We demonstrate the transformations of hacking and prototyping practices necessary to construct complex Research Products through the case study of our machines. We offer the Interaction Design community seven specific and actionable techniques for using mobile telephones in Research Products. Finally, we open up a broader discussion for researchers and practitioners using mobile phones as a design material in their work.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {435–447},
numpages = {13},
keywords = {tangible, research product, prototype, mobile telephone},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025797,
author = {Cila, Nazli and Smit, Iskander and Giaccardi, Elisa and Kr\"{o}se, Ben},
title = {Products as Agents: Metaphors for Designing the Products of the IoT Age},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025797},
doi = {10.1145/3025453.3025797},
abstract = {Design-based inquiries into the networked products of the Internet of Things (IoT) lack a coherent understanding of the effect of such products on society. This paper proposes a new taxonomy for networked products, which would allow articulation on their current state and future, and provide insights to designers for creating meaningful and aesthetic products of IoT. Central to this framework is the proposition that our current product-scape should be understood as a distribution of material agencies and best analyzed through the metaphor of "agency". We identify three types of agencies, i.e., the Collector, the Actor, and the Creator, and discuss how this approach could create new design methodologies to create more meaningful networked products that would empower people in their everyday lives.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {448–459},
numpages = {12},
keywords = {interaction design, metaphor, internet of things, agency, networked products},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026031,
author = {Friedman, Batya and Yoo, Daisy},
title = {Pause: A Multi-Lifespan Design Mechanism},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026031},
doi = {10.1145/3025453.3026031},
abstract = {At times, inaction may be a wise course of action. This insight lies at the heart of the design mechanism of pause. In this note, we explore the construct of pause, its rhythms, and nuances of enacting pause. Throughout, we draw on our experience engaging with pause in the multi-lifespan design of information systems for transitional justice. Five rhythms are identified: periodic hiatus, pending future event, responding to the socio-political climate, (temporary) closure, and laying fallow. In addition, we provide heuristics for managing pause and then restarting the design process. We then explore the scalability of pause from longer (e.g., multi-lifespan design) to shorter timeframes. We conclude with reflections on the potential benefits and open questions about pause as a design mechanism.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {460–464},
numpages = {5},
keywords = {design mechanism, multi-lifespan design, pause},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025939,
author = {Isbister, Katherine and Abe, Kaho and Karlesky, Michael},
title = {Interdependent Wearables (for Play): A Strong Concept for Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025939},
doi = {10.1145/3025453.3025939},
abstract = {Typically wearable devices are conceived of and constructed as stand-alone, individually based technologies. However, in practice wearables become part of the social context and ecology of overall device use. We present a strong concept for design: Interdependent Wearables (for play): wearables designed to require shared attention and mutual awareness, with interdependent functionality that encourages and rewards collocated interaction. The concept arose through design, development, and public exhibition of Hotaru, a collocated social game that uses wearables as game controllers. Hotaru has been shown in festivals and also formally playtested with 62 individuals. To more fully articulate the Interdependent Wearables strong concept, we compared this system's design with wearable and embodied systems for play and other purposes, and drew upon relevant HCI theory. The work is of benefit to those in the HCI/UX community focused on the design and development of social wearable technologies, especially those interested in supporting collocated interaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {465–471},
numpages = {7},
keywords = {strong concept, embodied interaction, collocated interaction, interdependent wearables, social wearables},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025864,
author = {Avle, Seyram and Lindtner, Silvia and Williams, Kaiton},
title = {How Methods Make Designers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025864},
doi = {10.1145/3025453.3025864},
abstract = {Through their combination of lifestyle and method, Silicon Valley models for tech production such as design thinking, startup incubators, lean management, etc. are spreading across the globe. These paradigms are positioned by product designers, politicians, investors and corporations alike as replicable routes to individual and national empowerment. They are portrayed as universal templates, portable across national borders and applicable to local needs. We draw from our ethnographic engagements with tech entrepreneurial efforts in Ghana, China, and Jamaica to unpack the stakes involved in their uptake, showing that while local actors produce situated alternatives, their work nevertheless often results in a continued valorization of these seemingly universal methods. We argue that design methods shape not only use practices, but have consequences for the life worlds of professional designers. This includes how they impact personal and national identities, confer legitimacy in transnational innovation circles, and secure access to social and economic resources. Ultimately, we call for an inclusion of these factors in ongoing conversations about design and design methods.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {472–483},
numpages = {12},
keywords = {China, design methods, Ghana, ethnography, Jamaica, Silicon Valley},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025666,
author = {Lee, Bokyung and Han, Gyeol and Park, Jundong and Saakes, Daniel},
title = {Consumer to Creator: How Households Buy Furniture to Inform Design and Fabrication Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025666},
doi = {10.1145/3025453.3025666},
abstract = {Emerging technologies for digital design and fabrication let people participate in the making of objects that were previously dominated by professional designers. A growing body of work in HCI provides understanding in the activities of designing and making by novices and in maker communities. However, we know little about how casual users might employ these technologies with the goal of having an object in their home that satisfies a need. We present a long-term qualitative study in which we followed 16 households during a purchasing process of furniture items for their homes. We looked into how families discover what they need, find solutions, realize a solution in their house and put it to use. The results provide insights into their design activities and workflow and we identify two distinct stages: understanding needs and prototyping a solution. Based on the findings, we discuss the social practice of acquiring and appropriating furniture in the home and within families, and identify design opportunities for digital design and fabrication to support people as they create the objects they need, want and desire.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {484–496},
numpages = {13},
keywords = {fabrication, qualitative study, design, purchase, furniture},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025460,
author = {Rivera, Michael L. and Moukperian, Melissa and Ashbrook, Daniel and Mankoff, Jennifer and Hudson, Scott E.},
title = {Stretching the Bounds of 3D Printing with Embedded Textiles},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025460},
doi = {10.1145/3025453.3025460},
abstract = {Textiles are an old and well developed technology that have many desirable characteristics. They can be easily folded, twisted, deformed, or cut; some can be stretched; many are soft. Textiles can maintain their shape when placed under tension and can even be engineered with variable stretching ability. Conversely, 3D printing is a relatively new technology that can precisely produce functional, rigid objects with custom geometry. Combining 3D printing and textiles opens up new opportunities for rapidly creating rigid objects with embedded flexibility as well as soft materials imbued with additional functionality. In this paper, we introduce a suite of techniques for integrating 3D printing with textiles during the printing process, opening up a new design space that takes inspiration from both fields. We demonstrate how the malleability, stretchability and aesthetic qualities of textiles can enhance rigid printed objects, and how textiles can be augmented with functional properties enabled by 3D printing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {497–508},
numpages = {12},
keywords = {soft materials, additive manufacturing, textiles, interactive devices, 3d printing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025699,
author = {Tao, Ye and Wang, Guanyun and Zhang, Caowei and Lu, Nannan and Zhang, Xiaolian and Yao, Cheng and Ying, Fangtian},
title = {WeaveMesh: A Low-Fidelity and Low-Cost Prototyping Approach for 3D Models Created by Flexible Assembly},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025699},
doi = {10.1145/3025453.3025699},
abstract = {To meet the increasing requirements of HCI researchers who are prototyping a variety of forms to create novel interfaces under a ubiquitous situation, we present WeaveMesh, a low-fidelity and low-cost rapid prototyping system that produces 3D objects in a mesh structure. Inspired by hand-weaving craft, WeaveMesh supports a highly customizable software platform, which is applicable for simulating and facilitating freeform surface constructions composed of woven lines arranged in a regular grid, which can serve as a guide for easy assembly. In addition, mobilizable connectors are suggested to support flexible assembly, which can be revised, recycled, and reused to facilitate short iterations. Furthermore, compared to common additive and subtractive techniques, WeaveMesh has a better balance between time and material saving. In this paper, we will introduce the system in detail and demonstrate the feasibility of the technique through various 3D models in the area of interactive media, products and architecture.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {509–518},
numpages = {10},
keywords = {low-fidelity fabrication, uv mesh, rapid prototyping},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025560,
author = {Gorman, Benjamin M. and Flatla, David R.},
title = {A Framework for Speechreading Acquisition Tools},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025560},
doi = {10.1145/3025453.3025560},
abstract = {At least 360 million people worldwide have disabling hearing loss that frequently causes difficulties in day-to-day conversations. Traditional technology (e.g., hearing aids) often fails to offer enough value, has low adoption rates, and can result in social stigma. Speechreading can dramatically improve conversational understanding, but speechreading is a skill that can be challenging to learn. To address this, we developed a novel speechreading acquisition framework that can be used to design Speechreading Acquisition Tools (SATs) - a new type of technology to improve speechreading acquisition. We interviewed seven speechreading tutors and used thematic analysis to identify and organise the key elements of our framework. We then evaluated our framework by using it to: 1) categorise every tutor-identified speechreading teaching technique, 2) critically evaluate existing conversational aids, and 3) design three new SATs. Through the use of SATs designed using our framework, the speechreading abilities of people with hearing loss around the world should be enhanced, thereby improving the conversational foundation of their day-to-day lives.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {519–530},
numpages = {12},
keywords = {deafness, lipreading, speechreading, hearing loss},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025646,
author = {Chakraborty, Tusher and Khan, Taslim Arefin and Al Islam, A. B. M. Alim},
title = {FLight: A Low-Cost Reading and Writing System for Economically Less-Privileged Visually-Impaired People Exploiting Ink-Based Braille System},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025646},
doi = {10.1145/3025453.3025646},
abstract = {Reading printed documents and writing on a paper pose a great challenge for visually-impaired people. Existing studies that attempt to solve these challenges are expensive and not feasible in low-income context. Moreover, these studies solve reading and writing problems separately. On the contrary, in this study, we propose FLight, a low-cost reading and writing system for economically less-privileged people. FLight uses ink-based Braille characters as the medium of textual representation. This helps in keeping a compact spatial representation of texts, yet achieving a low-cost status. Additionally, FLight utilizes a low-cost wearable device to enhance ease of reading by visually-impaired people. We conduct a participatory design and iterative evaluation involving five visually-impaired children in Bangladesh for more than 18 months. Our user evaluation reveals that FLight is easy-to-use, and exhibits a potential low-cost solution for economically less-privileged visually-impaired people.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {531–540},
numpages = {10},
keywords = {assistive technology, wearable device, braille, economically less-privileged people},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025857,
author = {Cheng, Alan and Yang, Lei and Andersen, Erik},
title = {Teaching Language and Culture with a Virtual Reality Game},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025857},
doi = {10.1145/3025453.3025857},
abstract = {Many people want to learn a language but find it difficult to stay engaged. Ideally, we would have language learning tools that can make language learning more enjoyable by simulating immersion in a foreign language environment. Therefore, we adapted Crystallize, a 3D video game for learning Japanese, so that it can be played in virtual reality with the Oculus Rift. Specifically, we explored whether we could leverage virtual reality technology to teach embodied cultural interaction, such as bowing in Japanese greetings. To evaluate the impact of our virtual reality game designs, we conducted a formative user study with 68 participants. We present results showing that the virtual reality design trained players how and when to bow, and that it increased participants' sense of involvement in Japanese culture. Our results suggest that virtual reality technology provides an opportunity to leverage culturally-relevant physical interaction, which can enhance the design of language learning technology and virtual reality games.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {541–549},
numpages = {9},
keywords = {video games, virtual reality, language learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025582,
author = {Bardot, Sandra and Serrano, Marcos and Oriola, Bernard and Jouffrais, Christophe},
title = {Identifying How Visually Impaired People Explore Raised-Line Diagrams to Improve the Design of Touch Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025582},
doi = {10.1145/3025453.3025582},
abstract = {Raised-line diagrams are widely used by visually impaired (VI) people to read maps, drawings or graphs. While previous work has identified general exploration strategies for raised-line drawings, we have limited knowledge on how this exploration is performed in detail and how it extends to other types of diagrams such as maps or graphs, frequently used in specialized schools. Such information can be crucial for the design of accessible interfaces on touchscreens. We conducted a study in which participants were asked to explore five types of raised-line diagrams (common drawings, perspective drawings, mathematical graphs, neighborhood maps, and geographical maps) while tracking both hands fingers. Relying on a first set of results, we proposed a set of design guidelines for touch interfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {550–555},
numpages = {6},
keywords = {blind, tactile exploration, tactile drawings, finger tracking, tactile maps, bimanual exploration, raised-line diagram},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025469,
author = {Sun, Mingfei and Zhao, Zhenjie and Ma, Xiaojuan},
title = {Sensing and Handling Engagement Dynamics in Human-Robot Interaction Involving Peripheral Computing Devices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025469},
doi = {10.1145/3025453.3025469},
abstract = {When human partners attend to peripheral computing devices while interacting with conversational robots, the inability of the robots to determine the actual engagement level of the human partners after gaze shift may cause communication breakdown. In this paper, we propose a real-time perception model for robots to estimate human partners' engagement dynamics, and investigate different robot behavior strategies to handle ambiguities in humans' status and ensure the flow of the conversation. In particular, we define four novel types of engagement status and propose a real-time engagement inference model that weighs humans' social signals dynamically according to the involvement of the computing devices. We further design two robot behavior strategies (explicit and implicit) to help resolve uncertainties in engagement inference and mitigate the impact of uncoupling, based on an annotated human-human interaction video corpus. We conducted a within-subject experiment to assess the efficacy and usefulness of the proposed engagement inference model and behavior strategies. Results show that robots with our engagement model can deliver better service and smoother conversations as an assistant, and people find the implicit strategy more polite and appropriate.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {556–567},
numpages = {12},
keywords = {peripheral computing devices, human-robot interaction, engagement awareness, robot behaviors},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025674,
author = {Rong, Xin and Fourney, Adam and Brewer, Robin N. and Morris, Meredith Ringel and Bennett, Paul N.},
title = {Managing Uncertainty in Time Expressions for Virtual Assistants},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025674},
doi = {10.1145/3025453.3025674},
abstract = {"Remind me to get milk later this afternoon." In communications and planning, people often express uncertainty about time using imprecise temporal expressions (ITEs). Unfortunately, modern virtual assistants often lack system support to capture the intents behind these expressions. This can result in unnatural interactions and undesirable interruptions (e.g., having a work reminder delivered at 12pm when out at lunch, because the user said "this afternoon"). In this paper we explore existing practices, expectations, and preferences surrounding the use of ITEs. Our mixed methods approach employs surveys, interviews, and an analysis of a large corpus of written communications. We find that people frequently use a diverse set of ITEs in both communication and planning. These uses reflect a variety of motivations, such as conveying uncertainty or task priority. In addition, we find that people have a variety of expectations about time input and management when interacting with virtual assistants. We conclude with design implications for future virtual assistants.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {568–579},
numpages = {12},
keywords = {virtual assistants, time expressions, uncertainty management},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025786,
author = {Luria, Michal and Hoffman, Guy and Zuckerman, Oren},
title = {Comparing Social Robot, Screen and Voice Interfaces for Smart-Home Control},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025786},
doi = {10.1145/3025453.3025786},
abstract = {With domestic technology on the rise, the quantity and complexity of smart-home devices are becoming an important interaction design challenge. We present a novel design for a home control interface in the form of a social robot, commanded via tangible icons and giving feedback through expressive gestures. We experimentally compare the robot to three common smart-home interfaces: a voice-control loudspeaker; a wall-mounted touch-screen; and a mobile application. Our findings suggest that interfaces that rate higher on flow rate lower on usability, and vice versa. Participants' sense of control is highest using familiar interfaces, and lowest using voice control. Situation awareness is highest using the robot, and also lowest using voice control. These findings raise questions about voice control as a smart-home interface, and suggest that embodied social robots could provide for an engaging interface with high situation awareness, but also that their usability remains a considerable design challenge.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {580–628},
numpages = {49},
keywords = {domestic technology, smart-home control, social robots, interface modalities, human-robot interaction, embodied interaction, home automation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025750,
author = {Kelley, Christina and Lee, Bongshin and Wilcox, Lauren},
title = {Self-Tracking for Mental Wellness: Understanding Expert Perspectives and Student Experiences},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025750},
doi = {10.1145/3025453.3025750},
abstract = {Previous research suggests an important role for self-tracking in promoting mental wellness. Recent studies with college student populations have examined the feasibility of collecting everyday mood, activity, and social data. However, these studies do not account for students' experiences and challenges adopting self-tracking technologies to support mental wellness goals. We present two studies conducted to better understand self-tracking for stress management and mental wellness in student populations. First, focus groups and card sorting activities with 14 student health professionals reveal expert perspectives on the usefulness of tracking for three scenarios. Second, an online survey of 297 students examines personal experiences with self-tracking and attitudes toward sharing self-tracked data with others. We draw on findings from these studies to characterize students' motivations, challenges and preferences in collecting and viewing self-tracked data related to mental wellness, and we compare findings between students with diagnosed mental illnesses and those without. We conclude with a discussion of challenges and opportunities in leveraging self-tracking for mental wellness, highlighting several design considerations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {629–641},
numpages = {13},
keywords = {self-tracking, mental wellness, mental health, patient-clinician communication, personal informatics, health communication, quantified self, self-monitoring},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025591,
author = {Eikey, Elizabeth V. and Reddy, Madhu C.},
title = {"It's Definitely Been a Journey": A Qualitative Study on How Women with Eating Disorders Use Weight Loss Apps},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025591},
doi = {10.1145/3025453.3025591},
abstract = {Technology is often viewed as either positive or negative. On one hand, in HCI, weight loss apps are usually seen as a positive influence on users. From the sociocultural perspective, on the other hand, media and technology negatively impact body satisfaction and contribute to eating disorders; however, these studies fail to include weight loss apps. While these apps can be beneficial to users, they can also have negative effects on users with eating disorder behaviors. Yet few research studies have looked at weight loss apps in relation to eating disorders. In order to fill this gap, we conducted interviews with 16 women with a history of eating disorders who use(d) weight loss apps. While our findings suggest these apps can contribute to and exacerbate eating disorder behaviors, they also reveal a more complex picture of app usage. Women's use and perceptions of weight loss apps shift as they experience life and move to and from stages of change. This research troubles the binary view of technology and emphasizes the importance of looking at technology use as a dynamic process. Our study contributes to our understanding of weight loss app design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {642–654},
numpages = {13},
keywords = {quantified self, bulimia nervosa, weight loss apps, eating disorders, mobile applications, qualitative, anorexia nervosa, self-tracking, food journal, persuasive},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025902,
author = {Towne, W. Ben and Ros\'{e}, Carolyn P. and Herbsleb, James D.},
title = {Conflict in Comments: Learning but Lowering Perceptions, with Limits},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025902},
doi = {10.1145/3025453.3025902},
abstract = {Prior work and perception theory suggests that when exposed to discussion related to a particular piece of crowdsourced text content, readers generally perceive that content to be of lower quality than readers who do not see those comments, and that the effect is stronger if the comments display conflict. This paper presents a controlled experiment with over 1000 participants testing to see if this effect carries over to other documents from the same platform, including those with similar content or by the same author. Although we do generally find that perceived quality of the commented-on document is affected, effects do not carry over to the second item and readers are able to judge the second in isolation from the comment on the first. We confirm a prior finding about the negative effects conflict can have on perceived quality but note that readers report learning more from constructive conflict comments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {655–666},
numpages = {12},
keywords = {crowdsourcing, creative work, validation, social influence, comments, experiment, distributed evaluation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025690,
author = {Meyer, Jochen and Wasmann, Merlin and Heuten, Wilko and El Ali, Abdallah and Boll, Susanne C.J.},
title = {Identification and Classification of Usage Patterns in Long-Term Activity Tracking},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025690},
doi = {10.1145/3025453.3025690},
abstract = {Activity trackers are frequently used in health and well-being, but their application in effective interventions is challenging. While research for reasons of use and non-use is ongoing, little is known about the way activity trackers are used in everyday life and over longer periods. We analyzed data of 104 individuals over 14,413 use days, and in total over 2.5 years. We describe general tracker use, periodic changes and overall changes over time, and identify characteristic patterns. While the use of trackers shows large individual heterogeneity, from our findings we could identify and classify general patterns for activity tracker use such as try-and-drop, slow-starter, experimenter, hop-on hop-off, intermittent and power user. Our findings contribute to the body of knowledge towards the successful design of effective health technologies, health interventions, and long-term health applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {667–678},
numpages = {12},
keywords = {quantitative analysis, longitudinal use, activity tracker, activity monitoring, usage patterns},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026029,
author = {Hasan, Khalad and Ahlstr\"{o}m, David and Kim, Junhyeok and Irani, Pourang},
title = {AirPanes: Two-Handed Around-Device Interaction for Pane Switching on Smartphones},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026029},
doi = {10.1145/3025453.3026029},
abstract = {In recent years, around device input has emerged as a complement to standard touch input, albeit in limited tasks and contexts, such as for item selection or map navigation. We push the boundaries for around device interactions to facilitate an entire smartphone application: browsing through large information lists to make a decision. To this end, we present AirPanes, a novel technique that allows two-handed in-air interactions, conjointly with touch input to perform analytic tasks, such as making a purchase decision. AirPanes resolves the inefficiencies of having to switch between multiple views or panes in common smartphone applications. We explore the design factors that make AirPanes efficient. In a controlled study, we find that AirPanes is on average 50% more efficient that standard touch input for an analytic task. We offer recommendations for implementing AirPanes in a broad range of applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {679–691},
numpages = {13},
keywords = {around-device interaction, two-handed mobile interaction, m-commerce interfaces, analytic interfaces, in-air input},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026027,
author = {Sun, Ke and Wang, Yuntao and Yu, Chun and Yan, Yukang and Wen, Hongyi and Shi, Yuanchun},
title = {Float: One-Handed and Touch-Free Target Selection on Smartwatches},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026027},
doi = {10.1145/3025453.3026027},
abstract = {Touch interaction on smartwatches suffers from the awkwardness of having to use two hands and the "fat finger" problem. We present Float, a wrist-to-finger input approach that enables one-handed and touch-free target selection on smartwatches with high efficiency and precision using only commercially-available built-in sensors. With Float, a user tilts the wrist to point and performs an in-air finger tap to click. To realize Float, we first explore the appropriate motion space for wrist tilt and determine the clicking action (finger tap) through a user-elicitation study. We combine the photoplethysmogram (PPG) signal with accelerometer and gyroscope to detect finger taps with a recall of 97.9% and a false discovery rate of 0.4%. Experiments show that using just one hand, Float allows users to acquire targets with size ranging from 2mm to 10mm in less than 2s to 1s, meanwhile achieve much higher accuracy than direct touch in both stationary (&gt;98.9%) and walking (&gt;71.5%) contexts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {692–704},
numpages = {13},
keywords = {smartwatch, finger gesture, one-handed interaction, target selection, tilt},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025454,
author = {Yi, Xin and Yu, Chun and Xu, Weijie and Bi, Xiaojun and Shi, Yuanchun},
title = {COMPASS: Rotational Keyboard on Non-Touch Smartwatches},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025454},
doi = {10.1145/3025453.3025454},
abstract = {Entering text is very challenging on smartwatches, especially on non-touch smartwatches where virtual keyboards are unavailable. In this paper, we designed and implemented COMPASS, a non-touch bezel-based text entry technique. COMPASS positions multiple cursors on a circular keyboard, with the location of each cursor dynamically optimized during typing to minimize rotational distance. To enter text, a user rotates the bezel to select keys with any nearby cursors. The design of COMPASS was justified by an iterative design process and user studies. Our evaluation showed that participants achieved a pick-up speed around 10 WPM and reached 12.5 WPM after 90-minute practice. COMPASS allows users to enter text on non-touch smartwatches, and also serves as an alternative for entering text on touch smartwatches when touch is unavailable (e.g., wearing gloves).},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {705–715},
numpages = {11},
keywords = {non-touch, smartwatch, text entry, circular keyboard, multiple cursors},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025852,
author = {Wenig, Dirk and Sch\"{o}ning, Johannes and Olwal, Alex and Oben, Mathias and Malaka, Rainer},
title = {WatchThru: Expanding Smartwatch Displays with Mid-Air Visuals and Wrist-Worn Augmented Reality},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025852},
doi = {10.1145/3025453.3025852},
abstract = {We introduce WatchThru, an interactive method for extended wrist-worn display on commercially-available smartwatches. To address the limited visual and interaction space, WatchThru expands the device into 3D through a transparent display. This enables novel interactions that leverage and extend smartwatch glanceability. We describe three novel interaction techniques, Pop-up Visuals, Second Perspective and Peek-through, and discuss how they can complement interaction on current devices. We also describe two types of prototypes that helped us to explore standalone interactions, as well as, proof-of-concept AR interfaces using our platform.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {716–721},
numpages = {6},
keywords = {wearable devices, smartwatches, micro-interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025657,
author = {Ilinkin, Ivaylo and Kim, Sunghee},
title = {Evaluation of Korean Text Entry Methods for Smartwatches},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025657},
doi = {10.1145/3025453.3025657},
abstract = {This paper presents results from a user study designed to evaluate the effectiveness of Korean text entry methods for smartwatches. Specifically, the study compares the four popular text entry methods for smartphones in the context of smartwatch use (three multi-tap 3x4 keypad methods and a QWERTY-like method). A distinctive feature of text entry in Korea is that traditionally different manufacturers have developed their own text entry methods starting with particular physical layouts on feature phones that are now available as soft keypads on smartphones. This research considers the next step in this progression by studying the viability of adopting these text entry methods on smartwatches. The results from the user study indicate that existing methods can be effective for text entry on smartwatches; analysis of the data offers suggestions for improving the effectiveness of the methods.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {722–726},
numpages = {5},
keywords = {smartwatch, text entry, soft keyboard},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025484,
author = {Nouwens, Midas and Griggio, Carla F. and Mackay, Wendy E.},
title = {"WhatsApp is for Family; Messenger is for Friends": Communication Places in App Ecosystems},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025484},
doi = {10.1145/3025453.3025484},
abstract = {Today's users communicate via multiple apps, even when they offer almost identical functionality. We studied how and why users distribute their contacts within their app ecosystem. We found that the contacts in an app affect a user's conversations with other contacts, their communication patterns in the app, and the quality of their social relationships. Users appropriate the features and technical constraints of their apps to create idiosyncratic communication places, each with its own recursively defined membership rules, perceived purposes, and emotional connotations. Users also shift the boundaries of their communication places to accommodate changes in their contacts' behaviour, the dynamics of their relationships, and the restrictions of the technology. We argue that communication apps should support creating multiple communication places within the same app, relocating conversations across apps, and accessing functionality from other apps.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {727–735},
numpages = {9},
keywords = {contact management, communication ecosystem, computer-mediated communication (cmc), communication places, instant messaging},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025709,
author = {Deloatch, Robert and Bailey, Brian P. and Kirlik, Alex and Zilles, Craig},
title = {I Need Your Encouragement! Requesting Supportive Comments on Social Media Reduces Test Anxiety},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025709},
doi = {10.1145/3025453.3025709},
abstract = {Many students underperform on exams due to experiencing high test anxiety. We report on a study comparing a novel intervention of seeking support from one's social network to the more common approaches of expressive writing and studying task-relevant materials for simulated open-ended test questions. We measured in-the-moment (state) anxiety before and after each intervention, and correctness of the solutions. We also surveyed students to learn about their perceptions of the interventions. Our results showed that social support decreased the anxiety of high test-anxious students by 21% with the reduction in anxiety correlating with the number of messages received. Social support also allowed high test-anxious students to score at the level of low test-anxious students. Expressive writing showed a similar effect, but increased the anxiety of low test-anxious students by 61%. Studying task materials had no effect on anxiety and high test-anxious students performed worse than low test-anxious students. Despite benefiting from social support, we found that students were uncomfortable soliciting support from their online social network. Realizing the benefits of this approach may therefore require different formulations of social support in practice.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {736–747},
numpages = {12},
keywords = {social support, expressive writing, programming, anxiety},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025800,
author = {Zhou, Rui and Hentschel, Jasmine and Kumar, Neha},
title = {Goodbye Text, Hello Emoji: Mobile Communication on WeChat in China},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025800},
doi = {10.1145/3025453.3025800},
abstract = {We present a qualitative study of mobile communication via WeChat in Southern China, focusing on the rapid proliferation of emoji and stickers and the lessening dependence on text. We use interview and observation data from 30 participants to investigate how rural, small town, and urban Chinese adults creatively and innovatively balance the use of emoji, stickers, and text in their mobile communication practices. We also discuss design implications of our research for the field of HCI, offering ways of leveraging the non-textual communication practices that we uncover, in scenarios where purely text-based communication may not suffice.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {748–759},
numpages = {12},
keywords = {wechat, china, stickers, emoji, qualitative methods, mobile},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025839,
author = {Gao, Ge and Fussell, Susan R.},
title = {A Kaleidoscope of Languages: When and How Non-Native English Speakers Shift between English and Their Native Language during Multilingual Teamwork},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025839},
doi = {10.1145/3025453.3025839},
abstract = {Multilingual teams often include subgroups of members who share a native language different from the team's common language. Linguistic choices by members of these subgroups can have implications for information exchange at the team level. We reported a field study of language use in 3 multilingual teams, each of which consisted of some native English speakers (NS) and some non-native English speakers (NNS) who shared a native language with at least one other team member. We found that NNS often shifted between English and their native language. The way language shift happened differed for formal meetings, informal conversations, and instant messaging. Language variation was often associated with shifts in content, participants, and communication medium. Further analysis indicated that language shift had both benefits and costs for team communication, depending on the context in which it happened. Based on these findings, we outline suggestions for designing multilingual collaboration systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {760–772},
numpages = {13},
keywords = {computer-supported cooperative work (cscw), multilingual communication, diverse team, language shift},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025858,
author = {Pargman, Daniel and Eriksson, Elina and H\"{o}jer, Mattias and \"{O}stling, Ulrika Gunnarsson and Borges, Luciane Aguiar},
title = {The (Un)Sustainability of Imagined Future Information Societies},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025858},
doi = {10.1145/3025453.3025858},
abstract = {The pathway to a sustainable society is not clear, and we need to consider different developmental possibilities. This paper describes the results of a research project in the intersection of HCI and Futures Studies as well as in the intersection between "the future information society" and sustainability. We here present parts of the body of materials that were developed in a multi-year research project with the aim of describing and evaluating the sustainability impact of possible future information societies. We also discuss some of the lessons learned and what HCI and design fiction can learn from Futures Studies in general and from this project in particular. The main stakeholders in this project have been city administrators and corporate partners, and the overarching goal has primarily been to influence planning processes at the regional (Stockholm, Sweden) level.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {773–785},
numpages = {13},
keywords = {scenarios, sustainability, futures studies, design fiction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025542,
author = {Raghavan, Barath and Pargman, Daniel},
title = {Means and Ends in Human-Computer Interaction: Sustainability through Disintermediation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025542},
doi = {10.1145/3025453.3025542},
abstract = {There has been an increased interest in broader contexts from ecology and economics within the HCI community in recent years. These developments suggest that the HCI community should engage with and respond to concerns that are external to computing yet profoundly impact human society. In this paper we observe that taking these broader contexts into account yields a fundamentally different way to think about sustainable interaction design, one in which the designer's focus must be on a) ecological limits, b) creating designs and artifacts that do not further a cornucopian paradigm, and c) fundamental human needs.It can be hard to be responsive to these contexts in practical HCI work. To address this, we propose that the design rubric of disintermediation can serve as a unifying approach for work that aims to meet the ecological and economic challenges outlined in the literature. After discussing the potential use and impact of disintermedation, we perform an analysis using this design rubric to several key application areas.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {786–796},
numpages = {11},
keywords = {sustainable hci, complexity, disintermediation, sustainability, sustainable computing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025979,
author = {Light, Ann and Briggs, Jo},
title = {Crowdfunding Platforms and the Design of Paying Publics},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025979},
doi = {10.1145/3025453.3025979},
abstract = {Crowdfunding enables groups to self-fund the changes they want to make in the world. In other words, digital financial platforms are proving capable of supporting new relations between groups of people as well as offering new ways to organize money. Taking an HCI lens, we look at how some crowdfunding platform owners are approaching social innovation, not only at the level of supporting individual community initiatives, but at the broader level of using their platform to change societal behavior. Through four case studies, we show how crowdfunding has been chosen as a tool to redesign society by promoting environmental or social sustainability. We argue that the groups constituted through these interactions are not merely "crowds", but deliberate constellations built round a thing of interest (or "paying publics"). Our interviews with managers and owners explore how interactions with and around platforms work to achieve these ends and we conclude with design considerations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {797–809},
numpages = {13},
keywords = {paying publics, business models, infrastructure, social innovation, digital platforms, platform design, sustainability},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025637,
author = {Porter, Emily and Bopp, Chris and Gerber, Elizabeth and Voida, Amy},
title = {Reappropriating Hackathons: The Production Work of the CHI4Good Day of Service},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025637},
doi = {10.1145/3025453.3025637},
abstract = {The popularity of hackathons has increased as technology pervades more facets of our lives. Originally designed for programmers, hackathons are now being appropriated by new stakeholders across diverse sectors. Yet with this evolution in hackathons, we no longer adequately understand what is produced and, thereby, the value of these events. We conducted an interview study with 22 stakeholders - participants, representatives of nonprofit organizations, and organizers - of the CHI4Good Day of Service to understand what is produced through philanthropic hackathons. Whereas traditional hackathons are oriented around the production of code or prototypes, our analysis of interview data suggests that the production work of philanthropic hackathons also includes technical capacity and expertise, expanded social networks, an exposure to design process, affective experiences, and an opportunity for participants to shape their identities against a cross-sectoral, interdisciplinary backdrop. We conclude by reflecting on implications for the CHI community in carrying out philanthropic events styled after hackathons.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {810–814},
numpages = {5},
keywords = {design process, civic, social-issue, social networks, material production, hackathon},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025977,
author = {Padilla, Stefano and Methven, Thomas S. and Robb, David A. and Chantler, Mike J.},
title = {Understanding Concept Maps: A Closer Look at How People Organise Ideas},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025977},
doi = {10.1145/3025453.3025977},
abstract = {Research into creating visualisations that organise ideas into concise concept maps often focuses on implicit mathematical and statistical theories which are built around algorithmic efficacy or visual complexity. Although there are multiple techniques which attempt to mathematically optimise this multi-dimensional problem, it is still unknown how to create concept maps that are immediately understandable to people. In this paper, we present an in-depth qualitative study observing the behaviour and discussing the strategy used by non-expert participants to create, interact, update and communicate a concept map that represents a collection of research ideas. Our results show non-expert individuals create concept maps differently to visualisation algorithms. We found that our participants prioritised narrative, landmarks, abstraction, clarity, and simplicity. Finally, we derive design recommendations from our results which we hope will inspire future algorithms that automatically create more usable and compelling concept maps better suited to the natural behaviours and needs of users.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {815–827},
numpages = {13},
keywords = {concept maps, interaction, visualisation, information, design, organisation., knowledge, data, interfaces},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025998,
author = {Greis, Miriam and Avci, Emre and Schmidt, Albrecht and Machulla, Tonja},
title = {Increasing Users' Confidence in Uncertain Data by Aggregating Data from Multiple Sources},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025998},
doi = {10.1145/3025453.3025998},
abstract = {We often base our decisions on uncertain data - for instance, when consulting the weather forecast before deciding what to wear. Due to their uncertainty, such forecasts can differ by provider. To make an informed decision, many people compare several forecasts, which is a time-consuming and cumbersome task. To facilitate comparison, we identified three aggregation mechanisms for forecasts: manual comparison and two mechanisms of computational aggregation. In a survey, we compared the mechanisms using different representations. We then developed a weather application to evaluate the most promising candidates in a real-world study. Our results show that aggregation increases users' confidence in uncertain data, independent of the type of representation. Further, we find that for daily events, users prefer to use computationally aggregated forecasts. However, for high-stakes events, they prefer manual comparison. We discuss how our findings inform the design of improved interfaces for comparison of uncertain data, including non-weather purposes.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {828–840},
numpages = {13},
keywords = {uncertainty, multiple sources, comparison, aggregation, weather forecast},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025942,
author = {M\'{e}ndez, Gonzalo Gabriel and Hinrichs, Uta and Nacenta, Miguel A.},
title = {Bottom-up vs. Top-down: Trade-Offs in Efficiency, Understanding, Freedom and Creativity with InfoVis Tools},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025942},
doi = {10.1145/3025453.3025942},
abstract = {The emergence of tools that support fast-and-easy visualization creation by non-experts has made the benefits of InfoVis widely accessible. Key features of these tools include attribute-level operations, automated mappings, and visualization templates. However, these features shield people from lower-level visualization design steps, such as the specific mapping of data points to visuals. In contrast, recent research promotes constructive visualization where individual data units and visuals are directly manipulated. We present a qualitative study comparing people's visualization processes using two visualization tools: one promoting a top-down approach to visualization construction (Tableau Desktop) and one implementing a bottom-up constructive visualization approach (iVoLVER). Our results show how the two approaches influence: 1) the visualization process, 2) decisions on the visualization design, 3) the feeling of control and authorship, and 4) the willingness to explore alternative designs. We discuss the complex trade-offs between the two approaches and outline considerations for designing better visualization tools.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {841–852},
numpages = {12},
keywords = {iVoLVER, information visualization, tableau desktop},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025485,
author = {Castelli, Nico and Ogonowski, Corinna and Jakobi, Timo and Stein, Martin and Stevens, Gunnar and Wulf, Volker},
title = {What Happened in My Home? An End-User Development Approach for Smart Home Data Visualization},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025485},
doi = {10.1145/3025453.3025485},
abstract = {Smart home systems change the way we experience the home. While there are established research fields within HCI for visualizing specific use cases of a smart home, studies targeting user demands on visualizations spanning across multiple use cases are rare. Especially, individual data-related demands pose a challenge for usable visualizations. To investigate potentials of an end-user development (EUD) approach for flexibly supporting such demands, we developed a smart home system featuring both pre-defined visualizations and a visualization creation tool. To evaluate our concept, we installed our prototype in 12 households as part of a Living Lab study. Results are based on three interview studies, a design workshop and system log data. We identified eight overarching interests in home data and show how participants used pre-defined visualizations to get an overview and the creation tool to not only address specific use cases but also to answer questions by creating temporary visualizations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {853–866},
numpages = {14},
keywords = {domestic routines, data visualization, living lab, smart home, interface design, qualitative study},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026040,
author = {Haldar, Shefali and Mishra, Sonali R. and Khelifi, Maher and Pollack, Ari H. and Pratt, Wanda},
title = {Opportunities and Design Considerations for Peer Support in a Hospital Setting},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026040},
doi = {10.1145/3025453.3026040},
abstract = {Although research has demonstrated improved outcomes for outpatients who receive peer support-such as through online health communities, support groups, and mentoring systems-hospitalized patients have few mechanisms to receive such valuable support. To explore the opportunities for a hospital-based peer support system, we administered a survey to 146 pediatric patients and caregivers, and conducted semi-structured interviews with twelve patients and three caregivers in a children's hospital. Our analysis revealed that hospitalized individuals need peer support for five key purposes: (1) to ask about medical details-such as procedures, treatments, and medications; (2) to learn about healthcare providers; (3) to report and prevent medical errors; (4) to exchange emotional support; and (5) to manage their time in the hospital. In this paper, we examine these themes and describe potential barriers to using a hospital-based peer support system. We then discuss the unique opportunities and challenges that the hospital environment presents when designing for peer support in this setting.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {867–879},
numpages = {13},
keywords = {pediatric, peer support, peer-to-peer, hospital, patient, caregiver, health informatics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025978,
author = {Park, Sun Young and Chen, Yunan},
title = {Patient Strategies as Active Adaptation: Understanding Patient Behaviors During an Emergency Visit},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025978},
doi = {10.1145/3025453.3025978},
abstract = {Although the ability of patients to access their health information during ongoing care is considered crucial for better health outcomes and increased satisfaction, the current care model places patients in a passive role. To investigate the patient experience in the hospital environment where information is lacking and in accessible, we conducted an ethnographic study with patients, caregivers, and healthcare providers in the emergency care setting. We report the three types of information breakdowns ED patients encountered during their emergency visits and the strategies they developed to cope. Our findings reveal a rich picture of the coping mechanisms ED patients use to proactively adapt to the nature of the ED care context. This work expands upon our understanding of the unique information challenges ED patients face, as well as the important adapting behaviors they engage in; it also uncovers design opportunities for supporting crucial, yet unmet, patient information needs.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {880–892},
numpages = {13},
keywords = {health informatics, information technology, hci, hospital, adaptation, patient coping strategies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025569,
author = {Lee, Jongin and Cho, Daeki and Kim, Junhong and Im, Eunji and Bak, JinYeong and Lee, Kyung ho and Lee, Kwan Hong and Kim, John},
title = {Itchtector: A Wearable-Based Mobile System for Managing Itching Conditions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025569},
doi = {10.1145/3025453.3025569},
abstract = {Severe itching conditions such as eczema or atopic dermatitis can have a significant impact on one's quality of life. Unfortunately, many of these conditions cannot be cured, and the focus is often on properly controlling or managing the condition. Thus, it is important to understand or objectively monitor how one's scratching behavior changes, based on medication or treatment or environmental conditions. In this work, we explore how wearable devices can support people with itching conditions to better manage their conditions. We carried out a three-phase study with 40 participants and 2 dermatologists to understand the implications of various system features and designs. Based on interviews with patients and doctors, we incorporated medical guidelines for treatment and patients' needs in the proposed Itchtector - a smartwatch-based mobile system to monitor itching behaviors and provide objective information about the user's scratching behaviors. Using the Itchtector prototype, we evaluated performance and possible acceptance with subjects.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {893–905},
numpages = {13},
keywords = {mobile system, nocturnal scratching, itching management},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025961,
author = {Ahmed, Syed Ishtiaque and Haque, Md. Romael and Guha, Shion and Rifat, Md. Rashidujjaman and Dell, Nicola},
title = {Privacy, Security, and Surveillance in the Global South: A Study of Biometric Mobile SIM Registration in Bangladesh},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025961},
doi = {10.1145/3025453.3025961},
abstract = {With the rapid growth of ICT adoption in the Global South, crimes over and through digital technologies have also increased. Consequently, governments have begun to undertake a variety of different surveillance programs, which in turn provoke questions regarding citizens' privacy rights. However, both the concepts of privacy and of citizens' corresponding political rights have not been well-developed in HCI for non-Western contexts. This paper presents findings from a three-month long ethnography and online survey (n=606) conducted in Bangladesh, where the government recently imposed mandatory biometric registration for every mobile phone user. Our analysis surfaces important privacy and safety concerns regarding identity, ownership, and trust, and reveals the cultural and political challenges of imposing biometric registration program in Bangladesh. We also discuss how alternative designs of infrastructure, technology, and policy may better meet stakeholders' competing needs in the Global South.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {906–918},
numpages = {13},
keywords = {ictd, surveillance, privacy, hci4d, security, bangladesh},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025823,
author = {Hautea, Samantha and Dasgupta, Sayamindu and Hill, Benjamin Mako},
title = {Youth Perspectives on Critical Data Literacies},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025823},
doi = {10.1145/3025453.3025823},
abstract = {As contemporary youth learn, play, and socialize online, their activities are often being recorded and analyzed. What should young people know about these data collection and analysis efforts? Although critiques of these new forms of data collection and analysis have grown increasingly loud, the voices of users, and particularly youth, have largely been absent. This paper explores the critical perspectives of youth who are programming with public data about their own learning and social interaction in the Scratch online community. Using a bottom-up approach based on ethnographic observation of discussions among these young users, we identify a series of themes in how these youth critique, question, and debate the implications of data analytics. We connect these themes-framed in terms of critical data literacies-to expert critiques and discuss the implications of these findings for education and design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {919–930},
numpages = {12},
keywords = {critical data literacy, learning, big data, data science, youth, data literacy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025673,
author = {Redmiles, Elissa M. and Kross, Sean and Mazurek, Michelle L.},
title = {Where is the Digital Divide? A Survey of Security, Privacy, and Socioeconomics},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025673},
doi = {10.1145/3025453.3025673},
abstract = {The behavior of the least-secure user can influence security and privacy outcomes for everyone else. Thus, it is important to understand the factors that influence the security and privacy of a broad variety of people. Prior work has suggested that users with differing socioeconomic status (SES) may behave differently; however, no research has examined how SES, advice sources, and resources relate to the security and privacy incidents users report. To address this question, we analyze a 3,000 respondent, census-representative telephone survey. We find that, contrary to prior assumptions, people with lower educational attainment report equal or fewer incidents as more educated people, and that users' experiences are significantly correlated with their advice sources, regardless of SES or resources.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {931–936},
numpages = {6},
keywords = {usable security, digital divide, computer science education},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025841,
author = {Wang, Shuhan and He, Fang and Andersen, Erik},
title = {A Unified Framework for Knowledge Assessment and Progression Analysis and Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025841},
doi = {10.1145/3025453.3025841},
abstract = {Designing engaging learning content is important but difficult, and typically involves a lot of manual specification. We present a unified framework that utilizes automatic problem decomposition and partial ordering graph construction to facilitate multiple workflows: knowledge assessment and progression analysis and design. We present results from a study with 847 participants in an online Japanese-language assessment tool demonstrating that our framework can efficiently measure student ability and predict student performance on specific problems. We also present results from analysis of curricula showing that the progressions of two different textbooks are surprisingly similar, and that our framework can lead to the discovery of general principles of expert progression design. Finally, we demonstrate automatic progression generation with desired sequencing and pacing, allowing for tailoring of progressions and mapping of parameters extracted from one curriculum onto another.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {937–948},
numpages = {12},
keywords = {education, automatic problem decomposition, progression analysis and design, knowledge assessment},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025789,
author = {Furi\'{o}, David and Fleck, St\'{e}phanie and Bousquet, Bruno and Guillet, Jean-Paul and Canioni, Lionel and Hachet, Martin},
title = {HOBIT: Hybrid Optical Bench for Innovative Teaching},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025789},
doi = {10.1145/3025453.3025789},
abstract = {Practical work in optics allows supporting the construction of knowledge, in particular when the concept to be learned remains diffuse. To overcome the limitations of the current experimental setups, we have designed a hybrid system that combines physical interaction and numerical simulation. This system relies on 3D-printed replicas of optical elements, which are augmented with pedagogical information. In this paper, we focus on the well-known Michelson interferometer experiment, widely studied in undergraduate programs of Science. A 3-months user study with 101 students and 6 teachers showed that, beyond the practical aspects offered by this system, such an approach enhances the technical and scientific learning compared to a standard Michelson interferometer experiment.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {949–959},
numpages = {11},
keywords = {education and training, optics, simulation, augmented reality, michelson interferometer},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025819,
author = {Wang, Yiting and White, Walker M. and Andersen, Erik},
title = {PathViewer: Visualizing Pathways through Student Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025819},
doi = {10.1145/3025453.3025819},
abstract = {Analysis of student data is critical for improving education. In particular, educators need to understand what approaches their students are taking to solve a problem. However, identifying student strategies and discovering areas of confusion is difficult because an educator may not know what queries to ask or what patterns to look for in the data. In this paper, we present a visualization tool, PathViewer, to model the paths that students follow when solving a problem. PathViewer leverages ideas from flow diagrams and natural language processing to visualize the sequences of intermediate steps that students take. Using PathViewer, we analyzed how several students solved a Python assignment, discovering interesting and unexpected patterns. Our results suggest that PathViewer can allow educators to quickly identify areas of interest, drill down into specific areas, and identify student approaches to the problem as well as misconceptions they may have.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {960–964},
numpages = {5},
keywords = {programming education, data visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025619,
author = {Liu, Min and Zhang, Yunbo and Bai, Jing and Cao, Yuanzhi and Alperovich, Jeffrey M. and Ramani, Karthik},
title = {WireFab: Mix-Dimensional Modeling and Fabrication for 3D Mesh Models},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025619},
doi = {10.1145/3025453.3025619},
abstract = {Many rapid fabrication technologies are directed towards layer wise printing or laser based prototyping. We propose WireFab, a rapid modeling and prototyping system that uses bent metal wires as the structure framework. WireFab approximates both the skeletal articulation and the skin appearance of the corresponding virtual skin meshes, and it allows users to personalize the designs by (1) specifying joint positions and part segmentations, (2) defining joint types and motion ranges to build a wire-based skeletal model, and (3) abstracting the segmented meshes into mixed-dimensional appearance patterns or attachments.The WireFab is designed to allow the user to choose how to best preserve the fidelity of the topological structure and articulation motion while selectively maintaining the fidelity of the geometric appearance. Compared to 3D-printing based high-fidelity fabrication systems, WireFab increases prototyping speed by ignoring unnecessary geometric details while preserving structural integrity and articulation motion. In addition, other rapid or low-fidelity fabrication systems produce only static models, while WireFab produces posable articulated models and has the potential to enable personalized functional products larger than the machines that produce them.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {965–976},
numpages = {12},
keywords = {physical prototyping, interactive curve modeling, shape abstraction, mix-dimensional fabrication, skeletal deformation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025624,
author = {Ion, Alexandra and Wall, Ludwig and Kovacs, Robert and Baudisch, Patrick},
title = {Digital Mechanical Metamaterials},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025624},
doi = {10.1145/3025453.3025624},
abstract = {In this paper, we explore how to embody mechanical computation into 3D printed objects, i.e., without electronic sensors, actuators, or controllers typically used for this purpose. A key benefit of our approach is that the resulting objects can be 3D printed in one piece and thus do not require assembly. We are building on 3D printed cell structures, also known as metamaterials. We introduce a new type of cell that propagates a digital mechanical signal using an embedded bistable spring. When triggered, the embedded spring discharges and the resulting impulse triggers one or more neighboring cells, resulting in signal propagation. We extend this basic mechanism to implement simple logic functions. We demonstrate interactive objects based on this concept, such as a combination lock. We present a custom editor that allows users to model 3D objects, route signals, simulate signal flow, and synthesize cell patterns.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {977–988},
numpages = {12},
keywords = {metamaterials, programmable matter, fabrication},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025952,
author = {Kan, Viirj and Vargo, Emma and Machover, Noa and Ishii, Hiroshi and Pan, Serena and Chen, Weixuan and Kakehi, Yasuaki},
title = {Organic Primitives: Synthesis and Design of PH-Reactive Materials Using Molecular I/O for Sensing, Actuation, and Interaction},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025952},
doi = {10.1145/3025453.3025952},
abstract = {In this paper we present Organic Primitives, an enabling toolbox that expands upon the library of input-output devices in HCI and facilitates the design of interactions with organic, fluid-based systems. We formulated color, odor and shape changing material primitives which act as sensor-actuators that convert pH signals into human-readable outputs. Food-grade organic molecules anthocyanin, vanillin, and chitosan were employed as dopants to synthesize materials which output a spectrum of colors, degrees of shape deformation, and switch between odorous and non-odorous states. We evaluated the individual output properties of our sensor-actuators to assess the rate, range, and reversibility of the changes as a function of pH 2-10. We present a design space with techniques for enhancing the functionality of the material primitives, and offer passive and computational methods for controlling the material interfaces. Finally, we explore applications enabled by Organic Primitives under four contexts: environmental, cosmetic, edible, and interspecies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {989–1000},
numpages = {12},
keywords = {droplets, molecular design interactions, edible materials, color, shape change, chemical sensing, ph-reactive, multi-modal output, programmable food, odor, microfluidics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025663,
author = {Schmitz, Martin and Steimle, J\"{u}rgen and Huber, Jochen and Dezfuli, Niloofar and M\"{u}hlh\"{a}user, Max},
title = {Flexibles: Deformation-Aware 3D-Printed Tangibles for Capacitive Touchscreens},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025663},
doi = {10.1145/3025453.3025663},
abstract = {We introduce Flexibles: 3D-printed flexible tangibles that are deformation-aware and operate on capacitive touchscreens. Flexibles add expressive deformation input to interaction with on-screen tangibles. Based on different types of deformation mapping, we contribute a set of 3D-printable mechanisms that capture pressing, squeezing, and bending input with multiple levels of intensities. They can be integrated into 3D printed objects with custom geometries and on different locations. A Flexible is printed in a single pass on a consumer-level 3D printer without requiring further assembly. Through a series of interactive prototypes, example applications and a technical evaluation, we show the technical feasibility and the wide applicability of Flexibles.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1001–1014},
numpages = {14},
keywords = {deformation, 3d printing, capacitive sensing, printed electronics, touch, rapid prototyping, input, digital fabrication},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025577,
author = {Orji, Rita and Nacke, Lennart E. and Di Marco, Chrysanne},
title = {Towards Personality-Driven Persuasive Health Games and Gamified Systems},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025577},
doi = {10.1145/3025453.3025577},
abstract = {Persuasive games and gamified systems are effective tools for motivating behavior change using various persuasive strategies. Research has shown that tailoring these systems can increase their efficacy. However, there is little knowledge on how game-based persuasive systems can be tailored to individuals of various personality traits. To advance research in this area, we conducted a large-scale study of 660 participants to investigate how different personalities respond to various persuasive strategies that are used in persuasive health games and gamified systems. Our results reveal that people's personality traits play a significant role in the perceived persuasiveness of different strategies. Conscientious people tend to be motivated by goal setting, simulation, self-monitoring and feedback; people who are more open to experience are more likely to be demotivated by rewards, competition, comparison, and cooperation. We contribute to the CHI community by offering design guidelines for tailoring persuasive games and gamified designs to a particular group of personalities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1015–1027},
numpages = {13},
keywords = {personalization, risky health behavior, personality, persuasive game, serious games, behavior change, persuasive strategies, gamified design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025638,
author = {Lomas, J. Derek and Koedinger, Kenneth and Patel, Nirmal and Shodhan, Sharan and Poonwala, Nikhil and Forlizzi, Jodi L.},
title = {Is Difficulty Overrated? The Effects of Choice, Novelty and Suspense on Intrinsic Motivation in Educational Games},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025638},
doi = {10.1145/3025453.3025638},
abstract = {Many game designers aim to optimize difficulty to make games that are "not too hard, not too easy." However, recent experiments have shown that even moderate difficulty can reduce player engagement. The present work investigates other design factors that may account for the purported benefits of difficulty, such as choice, novelty and suspense. These factors were manipulated in three design experiments involving over 20,000 play sessions of an online educational game.The first experiment (n=10,472) randomly assigned some players to a particular level of difficulty but allowed other players to freely choose their difficulty. Moderately difficult levels were most motivating when self-selected; yet, when difficulty was blindly assigned, the easiest games were most motivating. The second experiment (n=5,065) randomly assigned players to differing degrees of novelty. Moderate novelty was optimal, while too much or too little novelty reduced intrinsic motivation. A final experiment (n=6,511) investigated the role of suspense in "close games", where it was found to be beneficial. If difficulty decreases motivation while novelty and suspense increase it, then an implication for educational game designers is to make easy, interesting games that are "not too hard, not too boring."},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1028–1039},
numpages = {12},
keywords = {learning, intrinsic motivation, education, games, theory, near win, novelty, a/b testing, experiments, suspense, difficulty, flow, challenge},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025648,
author = {Depping, Ansgar E. and Mandryk, Regan L.},
title = {Why is This Happening to Me? How Player Attribution Can Broaden Our Understanding of Player Experience},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025648},
doi = {10.1145/3025453.3025648},
abstract = {Games user research (GUR) measures the performance and preference of digital game players, and interprets these measurements in the context of theories that explain human behavior. There are many validated approaches for measuring player experience that are grounded in psychological theories on motivation and emotion. Attribution theory explains how people assign causes to events and how these attributions affect peoples' emotional reactions and motivations. In this paper we argue that attribution theory can provide additional value to the existing suite of GUR tools; however, there are currently no validated tools to assess player attribution in the context of games. This paper describes the conceptualization of player attribution based on literature, presents the development and validation of a scale to assess player attribution in games, and discusses the implications of adding player attribution to the toolbox of methods for the design and evaluation of digital games.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1040–1052},
numpages = {13},
keywords = {scale development, attribution theory, game user research},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025982,
author = {Zhao, Zhao and Arya, Ali and Whitehead, Anthony and Chan, Gerry and Etemad, S. Ali},
title = {Keeping Users Engaged through Feature Updates: A Long-Term Study of Using Wearable-Based Exergames},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025982},
doi = {10.1145/3025453.3025982},
abstract = {Gamification and exergames in particular have been broadly employed in health and fitness as an attempt to promote exercise and more active life styles. Motivated by popularity and availability of wearable activity trackers, we present the design and findings of a study on the motivational effects of using activity tracker-based games to promote daily exercise. Furthermore, we have investigated user behaviors, usage patterns, engagement, and parameters that affect them. An exergame was developed with an accompanying wearable device, for which different variations of application updates were pushed out periodically over a 70-day period. The results of this long-term study show that the usage of wearable activity trackers during exercise, even when gamified for increased entertainment, sees a consistent decline over time. This decline, however, is observed to be reversible with periodic updates to the game. This work, we believe, can make a significant contribution to solving the user retention problem of wearable-based exergames.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1053–1064},
numpages = {12},
keywords = {exercise, gamification, wearable device, fitness, game sustainability, exergames., motivation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025832,
author = {Adams, Phil and Murnane, Elizabeth L. and Elfenbein, Michael and Wethington, Elaine and Gay, Geri},
title = {Supporting the Self-Management of Chronic Pain Conditions with Tailored Momentary Self-Assessments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025832},
doi = {10.1145/3025453.3025832},
abstract = {To better support the self-management of chronic pain, this paper investigates how those living with the condition prefer to self-assess their pain levels using smartphones. Our work consists of three stages: design ideation and review, an in-lab user study with 10 participants resulting in nine candidate interfaces, and a 3 week field trial of two further honed measures with 12 participants. This research firstly yields a better understanding of participants' strong and sometimes contrasting preferences regarding their self-assessment of pain intensity. We additionally contribute two novel interfaces that support accurate, quick, and repeated use along with other participant-valued interactions (e.g., familiar, relatable, and highly usable). In particular, we focus on designing tailored measures that both enhance respondent motivation as well as minimize the difficulty of meaningful self-assessment by supporting the cognitive effort in translating a subjective experience into a single numerical value.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1065–1077},
numpages = {13},
keywords = {questionnaire design, pain assessment, smartphone},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025680,
author = {Davidson, Neil and Vines, John and Bartindale, Tom and Sutton, Selina and Green, David and Comber, Rob and Balaam, Madeline and Olivier, Patrick and Vance, Gillian},
title = {Supporting Self-Care of Adolescents with Nut Allergy Through Video and Mobile Educational Tools},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025680},
doi = {10.1145/3025453.3025680},
abstract = {Anaphylaxis is a life-threatening allergic reaction which is rapid in onset. Adolescents living with anaphylaxis risk often lack the knowledge and skills required to safely manage their condition or talk to friends about it. We designed an educational intervention comprising group discussion around videos of simulated anaphylaxis scenarios and a mobile application containing video-based branching anaphylaxis narratives. We trialed the intervention with 36 nut allergic adolescents. At 1-year follow-up participants had improved adrenaline auto-injector skills and carriage, disease- and age-specific Quality of Life and confidence in anaphylaxis management. At 3-year follow-up adrenaline carriage improved further and confidence remained higher. Participants expressed how the education session was a turning point in taking control of their allergy and how the app facilitated sharing about anaphylaxis with others. We contribute insights regarding design of mobile self-care and peer-support applications for health in adolescence, and discuss strengths and limitations of video-based mobile health interventions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1078–1092},
numpages = {15},
keywords = {video, mixed methods, mobile health, food allergy, health, adolescents, patient education, anaphylaxis},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026042,
author = {Correia, Nuno N. and Tanaka, Atau},
title = {AVUI: Designing a Toolkit for Audiovisual Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026042},
doi = {10.1145/3025453.3026042},
abstract = {The combined use of sound and image has a rich history, from audiovisual artworks to research exploring the potential of data visualization and sonification. However, we lack standard tools or guidelines for audiovisual (AV) interaction design, particularly for live performance. We propose the AVUI (AudioVisual User Interface), where sound and image are used together in a cohesive way in the interface; and an enabling technology, the ofxAVUI toolkit. AVUI guidelines and ofxAVUI were developed in a three-stage process, together with AV producers: 1) participatory design activities; 2) prototype development; 3) encapsulation of prototype as a plug-in, evaluation, and roll out. Best practices identified include: reconfigurable interfaces and mappings; object-oriented packaging of AV and UI; diverse sound visualization; flexible media manipulation and management. The toolkit and a mobile app developed using it have been released as open-source. Guidelines and toolkit demonstrate the potential of AVUI and offer designers a convenient framework for AV interaction design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1093–1104},
numpages = {12},
keywords = {interface builder, crossmodal interaction, participatory design, user interface, hackathons, prototyping, interaction design, audiovisual, toolkit},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025827,
author = {Ichinco, Michelle and Hnin, Wint Yee and Kelleher, Caitlin L.},
title = {Suggesting API Usage to Novice Programmers with the Example Guru},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025827},
doi = {10.1145/3025453.3025827},
abstract = {Programmers, especially novices, often have difficulty learning new APIs (Application Programming Interfaces). Existing research has not fully addressed novice programmers' unawareness of all available API methods. To help novices discover new and appropriate uses for API methods, we designed a system called the Example Guru. The Example Guru suggests context-relevant API methods based on each programmer's code. The suggestions provide contrasting examples to demonstrate how to use the API methods. To evaluate the effectiveness of the Example Guru, we ran a study comparing novice programmers' use of the Example Guru and documentation-inspired API information. We found that twice as many participants accessed the Example Guru suggestions compared to documentation and that participants used more than twice as many new API methods after accessing suggestions than documentation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1105–1117},
numpages = {13},
keywords = {programming support, APIs, novice programming, examples},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025599,
author = {Feit, Anna Maria and Williams, Shane and Toledo, Arturo and Paradiso, Ann and Kulkarni, Harish and Kane, Shaun and Morris, Meredith Ringel},
title = {Toward Everyday Gaze Input: Accuracy and Precision of Eye Tracking and Implications for Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025599},
doi = {10.1145/3025453.3025599},
abstract = {For eye tracking to become a ubiquitous part of our everyday interaction with computers, we first need to understand its limitations outside rigorously controlled labs, and develop robust applications that can be used by a broad range of users and in various environments. Toward this end, we collected eye tracking data from 80 people in a calibration-style task, using two different trackers in two lighting conditions. We found that accuracy and precision can vary between users and targets more than six-fold, and report on differences between lighting, trackers, and screen regions. We show how such data can be used to determine appropriate target sizes and to optimize the parameters of commonly used filters. We conclude with design recommendations and examples how our findings and methodology can inform the design of error-aware adaptive applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1118–1130},
numpages = {13},
keywords = {eye tracking, sensor noise, gaze filters, adaptive interfaces},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025965,
author = {Tewell, Jordan and Bird, Jon and Buchanan, George R.},
title = {Heat-Nav: Using Temperature Changes as Navigation Cues},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025965},
doi = {10.1145/3025453.3025965},
abstract = {HCI is increasingly exploring how temperature can be used as an interaction modality. One challenge is that temperature changes are perceived over the course of seconds. This can be attributed to both the slow response time of skin thermoreceptors and the latency of the technology used to heat and cool the skin. For this reason, thermal cues are typically used to communicate single states, such as an emotion, and then there is a pause of tens of seconds to allow the skin to re-adapt to a neutral temperature before sending another signal. In contrast, this paper presents the first experimental demonstration that continuous temperature changes can guide behaviour: significantly improving performance in a 2D maze navigation task, without having to return to a neutral state before a new signal is sent. We discuss how continuous thermal feedback may be used for real world navigational tasks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1131–1135},
numpages = {5},
keywords = {thermal feedback, thermal haptics, navigation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025876,
author = {Warner, Jeremy and Guo, Philip J.},
title = {CodePilot: Scaffolding End-to-End Collaborative Software Development for Novice Programmers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025876},
doi = {10.1145/3025453.3025876},
abstract = {Novice programmers often have trouble installing, configuring, and managing disparate tools (e.g., version control systems, testing infrastructure, bug trackers) that are required to become productive in a modern collaborative software development environment. To lower the barriers to entry into software development, we created a prototype IDE for novices called CodePilot, which is, to our knowledge, the first attempt to integrate coding, testing, bug reporting, and version control management into a real-time collaborative system. CodePilot enables multiple users to connect to a web-based programming session and work together on several major phases of software development. An eight-subject exploratory user study found that first-time users of CodePilot spontaneously used it to assume roles such as developer/tester and developer/assistant when creating a web application together in pairs. Users felt that CodePilot could aid in scaffolding for novices, situational awareness, and lowering barriers to impromptu collaboration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1136–1141},
numpages = {6},
keywords = {collaborative ide, novice programmers, pair programming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025917,
author = {Ikeda, Kazushi and Hoashi, Keiichiro},
title = {Crowdsourcing GO: Effect of Worker Situation on Mobile Crowdsourcing Performance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025917},
doi = {10.1145/3025453.3025917},
abstract = {The increasing popularity of mobile crowdsourcing platforms has enabled crowd workers to accept jobs wherever/whenever they are, and also provides opportunity for task requesters to order time/location specific tasks to workers. Since workers on mobile platforms are working on the go, the situation of the workers is expected to influence their performance. However, the effects of mobile worker situations to task performance is an uninvestigated area. In this paper, our research question is, "do worker situations affect task completion, price and quality on mobile crowdsourcing platforms?" We draw on economics and psychology research to examine whether worker situations such as busyness, fatigue and presence of companions affect their performance. Our three-week between-subjects field experiment revealed that worker busyness caused 30.1% relative decrease of task completion rate. Mean accepted task price increased by 7.6% when workers are with companions. Worker fatigue caused 37.4% relative decrease of task quality.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1142–1153},
numpages = {12},
keywords = {crowdsourcing, mobile crowdsourcing, worker performance, situational effect},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025737,
author = {Lin, Allen Yilun and Kuehl, Kate and Sch\"{o}ning, Johannes and Hecht, Brent},
title = {Understanding "Death by GPS": A Systematic Study of Catastrophic Incidents Associated with Personal Navigation Technologies},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025737},
doi = {10.1145/3025453.3025737},
abstract = {Catastrophic incidents associated with GPS devices and other personal navigation technologies are sufficiently common that these incidents have been given a colloquial nickname: "Death by GPS". While there is a significant body of work on the use of personal navigation technologies in everyday scenarios, no research has examined these technologies' roles in catastrophic incidents. In this paper, we seek to address this gap in the literature. Borrowing techniques from public health research and communication studies, we construct a corpus of 158 detailed news reports of unique catastrophic incidents associated with personal navigation technologies. We then identify key themes in these incidents and the roles that navigation technologies played in them, e.g. missing road characteristics data contributed to over 25% of these incidents. With the goal of reducing casualties associated with personal navigation technologies, we outline implications for design and research that emerge from our results, e.g. advancing "space usage rule" mapping, incorporating weather information in routing, and improving visual and audio instructions in complex situations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1154–1166},
numpages = {13},
keywords = {satnav, map apps, gps, personal navigation technologies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026015,
author = {Johnson, Isaac and McMahon, Connor and Sch\"{o}ning, Johannes and Hecht, Brent},
title = {The Effect of Population and "Structural" Biases on Social Media-Based Algorithms: A Case Study in Geolocation Inference Across the Urban-Rural Spectrum},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026015},
doi = {10.1145/3025453.3026015},
abstract = {Much research has shown that social media platforms have substantial population biases. However, very little is known about how these population biases affect the many algorithms that rely on social media data. Focusing on the case study of geolocation inference algorithms and their performance across the urban-rural spectrum, we establish that these algorithms exhibit significantly worse performance for underrepresented populations (i.e. rural users). We further establish that this finding is robust across both text- and network-based algorithm designs. However, we also show that some of this bias can be attributed to the design of algorithms themselves rather than population biases in the underlying data sources. For instance, in some cases, algorithms perform badly for rural users even when we substantially overcorrect for population biases by training exclusively on rural data. We discuss the implications of our findings for the design and study of social media-based algorithms.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1167–1178},
numpages = {12},
keywords = {geolocation inference, algorithmic accountability, population bias, social media},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025495,
author = {Colley, Ashley and Thebault-Spieker, Jacob and Lin, Allen Yilun and Degraen, Donald and Fischman, Benjamin and H\"{a}kkil\"{a}, Jonna and Kuehl, Kate and Nisi, Valentina and Nunes, Nuno Jardim and Wenig, Nina and Wenig, Dirk and Hecht, Brent and Sch\"{o}ning, Johannes},
title = {The Geography of Pok\'{e}Mon GO: Beneficial and Problematic Effects on Places and Movement},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025495},
doi = {10.1145/3025453.3025495},
abstract = {The widespread popularity of Pok\'{e}mon GO presents the first opportunity to observe the geographic effects of location-based gaming at scale. This paper reports the results of a mixed methods study of the geography of Pok\'{e}mon GO that includes a five-country field survey of 375 Pok\'{e}mon GO players and a large scale geostatistical analysis of game elements. Focusing on the key geographic themes of places and movement, we find that the design of Pok\'{e}mon GO reinforces existing geographically-linked biases (e.g. the game advantages urban areas and neighborhoods with smaller minority populations), that Pok\'{e}mon GO may have instigated a relatively rare large-scale shift in global human mobility patterns, and that Pok\'{e}mon GO has geographically-linked safety risks, but not those typically emphasized by the media. Our results point to geographic design implications for future systems in this space such as a means through which the geographic biases present in Pok\'{e}mon GO may be counteracted.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1179–1192},
numpages = {14},
keywords = {geography, geoHCI, location-based games, pok'mon GO, algorithmic bias, augmented reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025882,
author = {Dasgupta, Aritra and Burrows, Susannah and Han, Kyungsik and Rasch, Philip J.},
title = {Empirical Analysis of the Subjective Impressions and Objective Measures of Domain Scientists' Visual Analytic Judgments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025882},
doi = {10.1145/3025453.3025882},
abstract = {Scientists often use specific data analysis and presentation methods familiar within their domain. But does high familiarity drive better analytical judgment? This question is especially relevant when familiar methods themselves can have shortcomings: many visualizations used conventionally for scientific data analysis and presentation do not follow established best practices. This necessitates new methods that might be unfamiliar yet prove to be more effective. But there is little empirical understanding of the relationships between scientists' subjective impressions about familiar and unfamiliar visualizations and objective measures of their visual analytic judgments. To address this gap and to study these factors, we focus on visualizations used for comparison of climate model performance. We report on a comprehensive survey-based user study with 47 climate scientists and present an analysis of: i) relationships among scientists' familiarity, their perceived levels of comfort, confidence, accuracy, and objective measures of accuracy, and ii) relationships among domain experience, visualization familiarity, and post-study preference.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1193–1204},
numpages = {12},
keywords = {trust, climate, visual comparison, slope plot, information visualization, taylor plot, preference},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025596,
author = {Chen, Xiuli and Starke, Sandra Dorothee and Baber, Chris and Howes, Andrew},
title = {A Cognitive Model of How People Make Decisions Through Interaction with Visual Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025596},
doi = {10.1145/3025453.3025596},
abstract = {In this paper we report a cognitive model of how people make decisions through interaction. The model is based on the assumption that interaction for decision making is an example of a Partially Observable Markov Decision Process (POMDP) in which observations are made by limited perceptual systems that model human foveated vision and decisions are made by strategies that are adapted to the task. We illustrate the model by applying it to the task of determining whether to block a credit card given a number of variables including the location of a transaction, its amount, and the customer history. Each of these variables have a different validity and users may weight them accordingly. The model solves the POMDP by learning patterns of eye movements (strategies) adapted to different presentations of the data. We compare the model behavior to human performance on the credit card transaction task.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1205–1216},
numpages = {12},
keywords = {cognitive modeling, eye movements, visual search, decision making., reinforcement learning, markov decision process},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025850,
author = {Hull, Carmen and Willett, Wesley},
title = {Building with Data: Architectural Models as Inspiration for Data Physicalization},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025850},
doi = {10.1145/3025453.3025850},
abstract = {In this paper we analyze the role of physical scale models in the architectural design process and apply insights from architecture for the creation and use of data physicalizations. Based on a survey of the architecture literature on model making and ten interviews with practicing architects, we describe the role of physical models as a tool for exploration and communication. From these observations, we identify trends in the use of physical models in architecture, which have the potential to inform the design of data physicalizations. We identify four functions of architectural modeling that can be directly adapted for use in the process of building rich data models. Finally, we discuss how the visualization community can apply observations from architecture to the design of new data physicalizations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1217–1264},
numpages = {48},
keywords = {data visualization, design process, data physicalization, architectural models, embodied interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025626,
author = {Kery, Mary Beth and Horvath, Amber and Myers, Brad},
title = {Variolite: Supporting Exploratory Programming by Data Scientists},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025626},
doi = {10.1145/3025453.3025626},
abstract = {How do people ideate through code? Using semi-structured interviews and a survey, we studied data scientists who program, often with small scripts, to experiment with data. These studies show that data scientists frequently code new analysis ideas by building off of their code from a previous idea. They often rely on informal versioning interactions like copying code, keeping unused code, and commenting out code to repurpose older analysis code while attempting to keep those older analyses intact. Unlike conventional version control, these informal practices allow for fast versioning of any size code snippet, and quick comparisons by interchanging which versions are run. However, data scientists must maintain a strong mental map of their code in order to distinguish versions, leading to errors and confusion. We explore the needs for improving version control tools for exploratory tasks, and demonstrate a tool for lightweight local versioning, called Variolite, which programmers found usable and desirable in a preliminary usability study.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1265–1276},
numpages = {12},
keywords = {exploratory data analysis, end-user programming, variants, variations, version control systems (vcs)},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025838,
author = {Koesten, Laura M. and Kacprzak, Emilia and Tennison, Jenifer F. A. and Simperl, Elena},
title = {The Trials and Tribulations of Working with Structured Data: -A Study on Information Seeking Behaviour},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025838},
doi = {10.1145/3025453.3025838},
abstract = {Structured data such as databases, spreadsheets and web tables is becoming critical in every domain and professional role. Yet we still do not know much about how people interact with it. Our research focuses on the information seeking behaviour of people looking for new sources of structured data online, including the task context in which the data will be used, data search, and the identification of relevant datasets from a set of possible candidates. We present a mixed-methods study covering in-depth interviews with 20 participants with various professional backgrounds, supported by the analysis of search logs of a large data portal. Based on this study, we propose a framework for human structured-data interaction and discuss challenges people encounter when trying to find and assess data that helps their daily work. We provide design recommendations for data publishers and developers of online data platforms such as data catalogs and marketplaces. These recommendations highlight important questions for HCI research to improve how people engage and make use of this incredibly useful online resource.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1277–1289},
numpages = {13},
keywords = {data portal, human data interaction, data search},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025912,
author = {Matejka, Justin and Fitzmaurice, George},
title = {Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025912},
doi = {10.1145/3025453.3025912},
abstract = {Datasets which are identical over a number of statistical properties, yet produce dissimilar graphs, are frequently used to illustrate the importance of graphical representations when exploring data. This paper presents a novel method for generating such datasets, along with several examples. Our technique varies from previous approaches in that new datasets are iteratively generated from a seed dataset through random perturbations of individual data points, and can be directed towards a desired outcome through a simulated annealing optimization strategy. Our method has the benefit of being agnostic to the particular statistical properties that are to remain constant between the datasets, and allows for control over the graphical appearance of resulting output.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1290–1294},
numpages = {5},
keywords = {visualization, anscombe, scatter plots},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025576,
author = {Kangasr\"{a}\"{a}si\"{o}, Antti and Athukorala, Kumaripaba and Howes, Andrew and Corander, Jukka and Kaski, Samuel and Oulasvirta, Antti},
title = {Inferring Cognitive Models from Data Using Approximate Bayesian Computation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025576},
doi = {10.1145/3025453.3025576},
abstract = {An important problem for HCI researchers is to estimate the parameter values of a cognitive model from behavioral data. This is a difficult problem, because of the substantial complexity and variety in human behavioral strategies. We report an investigation into a new approach using approximate Bayesian computation (ABC) to condition model parameters to data and prior knowledge. As the case study we examine menu interaction, where we have click time data only to infer a cognitive model that implements a search behaviour with parameters such as fixation duration and recall probability. Our results demonstrate that ABC (i) improves estimates of model parameter values, (ii) enables meaningful comparisons between model variants, and (iii) supports fitting models to individual users. ABC provides ample opportunities for theoretical HCI research by allowing principled inference of model parameter values and their uncertainty.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1295–1306},
numpages = {12},
keywords = {approximate bayesian computation, cognitive models in hci, computational rationality, inverse modeling},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025707,
author = {Liu, Wanyu and Bailly, Gilles and Howes, Andrew},
title = {Effects of Frequency Distribution on Linear Menu Performance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025707},
doi = {10.1145/3025453.3025707},
abstract = {While it is well known that menu usage follows a Zipfian distribution, there has been little interest in the impact of menu item frequency distribution on user's behavior. In this note, we explore the effects of frequency distribution on average menu performance as well as individual item performance. We compare three frequency distributions of menu item usage: Uniform; Zipfian with s=1 and Zipfian with s=2. The results show that (1) user's behavior is sensitive to different frequency distributions at both menu and item level; (2) individual item selection time depends on, not only its frequency, but also the frequency of other items in the menu. Finally, we discuss how these findings might have impacts on menu design, empirical studies and menu modeling.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1307–1312},
numpages = {6},
keywords = {frequency distribution, menus, user performance},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025558,
author = {McNaney, Roisin and Vines, John and Mercer, Jamie and Mexter, Leon and Welsh, Daniel and Young, Tony},
title = {DemYouth: Co-Designing and Enacting Tools to Support Young People's Engagement with People with Dementia},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025558},
doi = {10.1145/3025453.3025558},
abstract = {There is a growing body of research examining the role of technology in supporting the care of--and relationships surrounding--people with dementia, yet little attention has been given to how this relates to younger family members. We conducted a qualitative study based on a series of 6 co-design workshops conducted with 14 young people who had personal experience with dementia. Initially, our workshops focused on understanding the difficulties that young people face when engaging, interacting and being with people with dementia. Initial analysis of workshop data informed the design of three digital tool concepts that were used as the basis for user enactment workshops. Our findings highlight the young people's desire to be more involved in their family discussions around dementia and a need for them to find new ways to connect with their loved ones with dementia. We offer a set of design considerations for future systems that support these needs and reflect on some of the complexities we faced around engaging young people in this difficult topic of discussion.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1313–1325},
numpages = {13},
keywords = {co-design, young people, dementia, mobile applications},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025527,
author = {Morrissey, Kellie and McCarthy, John and Pantidi, Nadia},
title = {The Value of Experience-Centred Design Approaches in Dementia Research Contexts},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025527},
doi = {10.1145/3025453.3025527},
abstract = {Experience-Centred Design (ECD) has been applied in numerous HCI projects to call attention to the particular and dialogical nature of people's experiences with technology. In this paper, we report on ECD within the context of publicly-funded, long-stay residential dementia care, where the approach helped to highlight aspects of participants' felt experience, and informed sensitive and meaningful design responses. This study contributes an extended understanding of the quality of experience and the means of making sense in dementia, as well as unpicking the potential of ECD to support enriched experience and contextual meaning-making for people with dementia. Finally, we delineate what it is about Experience-Centred Design that differentiates the approach from other often-used approaches in designing in dementia contexts: 1) explorative thinking, 2) working within 'cuttings-out of time and space', 3) careful yet expressive methodology and documentation, and 4) working together to imagine futures. We end with considerations of how the contributions of this research may extend to other experience-centred projects in challenging settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1326–1338},
numpages = {13},
keywords = {experience, design methods, dementia, experience-centred design, design approaches, embodiment},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025715,
author = {Long, Kiel and Bakewell, Lyndsey L. and McNaney, Roisin C. and Vasileiou, Konstantina and Atkinson, Mark and Barreto, Manuela and Barnett, Julie and Wilson, Michael and Lawson, Shaun and Vines, John},
title = {Connecting Those That Care: Designing for Transitioning, Talking, Belonging and Escaping},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025715},
doi = {10.1145/3025453.3025715},
abstract = {Care provision in many nations increasingly relies on the work of informal, or non-professional, carers. Often these carers experience substantial disruptions and reductions to their own sociality, weakened social support networks and, ultimately, a heightened risk of social isolation. We describe a qualitative study, comprised of interviews, design workshops and probes, that investigated the social and community support practices of carers. Our findings highlight issues related to becoming and recognising being a carer, and feelings of being ignored by, and isolated from, others. We also note the benefits that sharing between carers can bring, and routes to coping and relaxing from the burdens of care. We conclude with design considerations for facilitating new forms of digitally mediated support that connect those that care, emphasising design qualities related to transitioning, talking, belonging and escaping.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1339–1351},
numpages = {13},
keywords = {qualitative study, informal care, co-design, carers},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025676,
author = {Tabor, Aaron and Bateman, Scott and Scheme, Erik and Flatla, David R. and Gerling, Kathrin},
title = {Designing Game-Based Myoelectric Prosthesis Training},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025676},
doi = {10.1145/3025453.3025676},
abstract = {A myoelectric prosthesis (myo) is a dexterous artificial limb controlled by muscle contractions. Learning to use a myo can be challenging, so extensive training is often required to use a myo prosthesis effectively. Signal visualizations and simple muscle-controlled games are currently used to help patients train their muscles, but are boring and frustrating. Furthermore, current training systems require expensive medical equipment and clinician oversight, restricting training to infrequent clinical visits. To address these limitations, we developed a new game that promotes fun and success, and shows the viability of a low-cost myoelectric input device. We adapted a user-centered design (UCD) process to receive feedback from patients, clinicians, and family members as we iteratively addressed challenges to improve our game. Through this work, we introduce a free and open myo training game, provide new information about the design of myo training games, and reflect on an adapted UCD process for the practical iterative development of therapeutic games.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1352–1363},
numpages = {12},
keywords = {training, ucd, prosthetics, myoelectric, games},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026041,
author = {Bartram, Lyn and Patra, Abhisekh and Stone, Maureen},
title = {Affective Color in Visualization},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026041},
doi = {10.1145/3025453.3026041},
abstract = {Communicating the right affect, a feeling, experience or emotion, is critical in creating engaging visual communication. We carried out three studies examining how different color properties (lightness, chroma and hue) and different palette properties (combinations and distribution of colors) contribute to different affective interpretations in information visualization where the numbers of colors is typically smaller than the rich palettes used in design. Our results show how color and palette properties can be manipulated to achieve affective expressiveness even in the small sets of colors used for data encoding in information visualization.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1364–1374},
numpages = {11},
keywords = {design, affective visualization, color perception},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025592,
author = {Kim, Yea-Seul and Reinecke, Katharina and Hullman, Jessica},
title = {Explaining the Gap: Visualizing One's Predictions Improves Recall and Comprehension of Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025592},
doi = {10.1145/3025453.3025592},
abstract = {Information visualizations use interactivity to enable user-driven querying of visualized data. However, users' interactions with their internal representations, including their expectations about data, are also critical for a visualization to support learning. We present multiple graphically-based techniques for eliciting and incorporating a user's prior knowledge about data into visualization interaction. We use controlled experiments to evaluate how graphically eliciting forms of prior knowledge and presenting feedback on the gap between prior knowledge and the observed data impacts a user's ability to recall and understand the data. We find that participants who are prompted to reflect on their prior knowledge by predicting and self-explaining data outperform a control group in recall and comprehension. These effects persist when participants have moderate or little prior knowledge on the datasets. We discuss how the effects differ based on text versus visual presentations of data. We characterize the design space of graphical prediction and feedback techniques and describe design recommendations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1375–1386},
numpages = {12},
keywords = {prediction, information visualization, internal representations of data, self-explanation, mental models},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025922,
author = {Correll, Michael and Heer, Jeffrey},
title = {Regression by Eye: Estimating Trends in Bivariate Visualizations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025922},
doi = {10.1145/3025453.3025922},
abstract = {Observing trends and predicting future values are common tasks for viewers of bivariate data visualizations. As many charts do not explicitly include trend lines or related statistical summaries, viewers often visually estimate trends directly from a plot. How reliable are the inferences viewers draw when performing such regression by eye? Do particular visualization designs or data features bias trend perception? We present a series of crowdsourced experiments that assess the accuracy of trends estimated using regression by eye across a variety of bivariate visualizations, and examine potential sources of bias in these estimations. We find that viewers accurately estimate trends in many standard visualizations of bivariate data, but that both visual features (e.g., "within-the-bar" bias) and data features (e.g., the presence of outliers) can result in visual estimates that systematically diverge from standard least-squares regression models.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1387–1396},
numpages = {10},
keywords = {regression, information visualization, graphical perception},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026024,
author = {Chang, Chunlei and Bach, Benjamin and Dwyer, Tim and Marriott, Kim},
title = {Evaluating Perceptually Complementary Views for Network Exploration Tasks},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026024},
doi = {10.1145/3025453.3026024},
abstract = {We explore the relative merits of matrix, node-link and combined side-by-side views for the visualisation of weighted networks with three controlled studies: (1) finding the most effective visual encoding for weighted edges in matrix representations; (2) comparing matrix, node-link and combined views for static weighted networks; and (3) comparing MatrixWave, Sankey and combined views of both for event-sequence data. Our studies underline that node-link and matrix views are suited to different analysis tasks. For the combined view, our studies show that there is a perceptually complementary effect in terms of improved accuracy for some tasks, but that there is a cost in terms of longer completion time than the faster of the two techniques alone. Eye-movement data shows that for many tasks participants strongly favour one of the two views, after trying both in the training phase.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1397–1407},
numpages = {11},
keywords = {matrices, sankey diagrams, node-link diagrams, eye tracking, event sequence data, network visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025541,
author = {van Kollenburg, Janne and Bogers, Sander and Deckers, Eva and Frens, Joep and Hummels, Caroline},
title = {How Design-Inclusive UXR Influenced the Integration of Project Activities: Three Design Cases from Industry},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025541},
doi = {10.1145/3025453.3025541},
abstract = {In this paper, we discuss how the implementation of design-inclusive User Experience Research (UXR) has influenced the composition of UXR and design activities in the industrial setting of Philips Design. We present three design case studies that were executed in a time span of three years: a baby sleep project; a pregnancy project; and a baby bottle-feeding project. Through a retrospective analysis we conclude that the approach adopted in these cases progressed from complete separation of UXR and design activities to design-inclusive UXR in which design forms an integral part of research. This is reflected by a rearrangement of project activities to identify, envision, enable and evaluate user experiences. Previously the UXR (identify and evaluate) and design (envision and enable) activities were executed sequentially. Now, these four project activities merge in studying design interventions in context over a prolonged time, to iteratively explore and advance UX design qualities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1408–1418},
numpages = {11},
keywords = {case studies, design, industry, activities, design-inclusive user experience research, personalized systems, design processes, user experience research, design practice, philips},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025860,
author = {Hoang, Thuong and Reinoso, Martin and Joukhadar, Zaher and Vetere, Frank and Kelly, David},
title = {Augmented Studio: Projection Mapping on Moving Body for Physiotherapy Education},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025860},
doi = {10.1145/3025453.3025860},
abstract = {Physiotherapy students often struggle to translate anatomical knowledge from textbooks into a dynamic understanding of the mechanics of body movements in real life patients. We present the Augmented Studio, an augmented reality system that uses body tracking to project anatomical structures and annotations over moving bodies for physiotherapy education. Through a user and learner centered design approach, we established an understanding that through augmentation and annotation, augmented reality technology can enhance physiotherapy education. Augmented Studio enables augmentation through projection mapping to display anatomical information such as muscles and skeleton in real time on the body as it moves. We created a technique for annotation to create projected hand-drawing on the moving body, to enable explicit communication of the teacher's clinical reasoning strategies to the students. Findings from our pilot usability study demonstrate a more engaging learning and teaching experience and increased communication between teacher and students when using Augmented Studio.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1419–1430},
numpages = {12},
keywords = {projection mapping, annotation, spatial augmented reality, physiotherapy education},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025805,
author = {Culbertson, Gabriel and Shen, Solace and Jung, Malte and Andersen, Erik},
title = {Facilitating Development of Pragmatic Competence through a Voice-Driven Video Learning Interface},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025805},
doi = {10.1145/3025453.3025805},
abstract = {Authentic foreign language videos are effective for developing pragmatic competence, or sensitivity to meanings expressed by tone and word choice, and the ability to effectively express these meanings. However, established methods for learning from foreign language videos are primarily text-based (e.g.captioning). Using text, learners do not practice aspects of oral performance (e.g. intonation, pausing, and pitch) that are important to pragmatic competence. In this paper we present a voice-driven system where learners practice and learn a foreign language by repeating phrases out loud from any video. Utterances are transcribed and translated and, if captions are available, the system indicates the correctness of the utterance. In an evaluation with 27 participants, we show that participants more frequently used the voice-driven system than a comparison text-based system. Furthermore, ina field study of 130 independent learners, we show potential for community-driven resource collection.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1431–1440},
numpages = {10},
keywords = {video learning, speech-recognition, pragmatic competence, language learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025726,
author = {Vorvoreanu, Mihaela and Gray, Colin M. and Parsons, Paul and Rasche, Nancy},
title = {Advancing UX Education: A Model for Integrated Studio Pedagogy},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025726},
doi = {10.1145/3025453.3025726},
abstract = {The rapid growth of the UX profession has led to an increased need for qualified practitioners and a proliferation of UX educational programs offered in both academia and industry. In this note, we present the design and initial evaluation of a new studio-based undergraduate program in UX--the first of its kind at a large, research-intensive US university. The program includes several curricular innovations, such as an integrated studio pedagogy in which six topical strands are interwoven across two types of studios. These studios are interconnected and span five semesters of the undergraduate experience. We present the curriculum model and the foundational principles that informed its design. We describe the two types of studios and their interconnection, and present early evaluation data showing that students are building valuable skills. The program described in this note provides a trailblazing model for UX pedagogy at the undergraduate level.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1441–1446},
numpages = {6},
keywords = {studio education, hci pedagogy, ux competence},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025463,
author = {Shorey, Paden and Girouard, Audrey},
title = {Bendtroller: An Exploration of In-Game Action Mappings with a Deformable Game Controller},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025463},
doi = {10.1145/3025453.3025463},
abstract = {We explore controller input mappings for games using a deformable prototype that combines deformation gestures with standard button input. In study one, we tested discrete gestures using three simple games. We categorized the control schemes as binary (button only), action, and navigation, the latter two named based on the game mechanics mapped to the gestures. We found that the binary scheme performed the best, but gesture-based control schemes are stimulating and appealing. Results also suggest that the deformation gestures are best mapped to simple and natural tasks. In study two, we tested continuous gestures in a 3D racing game using the same control scheme categorization. Results were mostly consistent with study one but showed an improvement in performance and preference for the action control scheme.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1447–1458},
numpages = {12},
keywords = {deformable user interactions, games, bend, controller, novel input, twist},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025743,
author = {Roo, Joan Sol and Gervais, Renaud and Frey, Jeremy and Hachet, Martin},
title = {Inner Garden: Connecting Inner States to a Mixed Reality Sandbox for Mindfulness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025743},
doi = {10.1145/3025453.3025743},
abstract = {Digital technology has been completely integrated into our daily lives, yet the potential of technology to improve its users' life satisfaction is still largely untapped. Mindfulness, the act of paying a deliberate and non-judgmental attention to the present moment, has been shown to have a positive impact on a person's health and subjective well-being--commonly called "happiness". Based on an iterative process with meditation teachers and practitioners, we designed a new tool to support mindfulness practices. This tool takes the shape of an augmented sandbox, designed to inspire the user's self-motivation and curiosity. By shaping the sand, the user creates a living miniature world that is projected back onto the sand. The natural elements of the garden are connected to real-time physiological measurements, such as breathing, helping the user to stay focused on the body. Moreover, using a Virtual Reality headset, they can travel inside their garden for a dedicated meditation session. Preliminary results seem to indicate that the system is well suited for mindfulness and induces a calm and mindful state on the user. The meditation teachers envisioned the use of Inner Garden in their practice.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1459–1470},
numpages = {12},
keywords = {virtual reality, spatial augmented reality, mindfulness, calm technologies, tangible interaction, mixed reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025600,
author = {Lopes, Pedro and You, Sijing and Cheng, Lung-Pan and Marwecki, Sebastian and Baudisch, Patrick},
title = {Providing Haptics to Walls &amp; Heavy Objects in Virtual Reality by Means of Electrical Muscle Stimulation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025600},
doi = {10.1145/3025453.3025600},
abstract = {We explore how to add haptics to walls and other heavy objects in virtual reality. When a user tries to push such an object, our system actuates the user's shoulder, arm, and wrist muscles by means of electrical muscle stimulation, creating a counter force that pulls the user's arm backwards. Our device accomplishes this in a wearable form factor.In our first user study, participants wearing a head-mounted display interacted with objects provided with different types of EMS effects. The repulsion design (visualized as an electrical field) and the soft design (visualized as a magnetic field) received high scores on "prevented me from passing through" as well as "realistic".In a second study, we demonstrate the effectiveness of our approach by letting participants explore a virtual world in which all objects provide haptic EMS effects, including walls, gates, sliders, boxes, and projectiles.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1471–1482},
numpages = {12},
keywords = {haptics, virtual reality, proprioception, real-walking, muscle interfaces, force feedback, ems},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025761,
author = {Sobel, Kiley and Bhattacharya, Arpita and Hiniker, Alexis and Lee, Jin Ha and Kientz, Julie A. and Yip, Jason C.},
title = {It Wasn't Really about the Pok\'{e}Mon: Parents' Perspectives on a Location-Based Mobile Game},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025761},
doi = {10.1145/3025453.3025761},
abstract = {Though prior work shows parents worry about screen media experiences displacing physical activity and time outdoors, this research does not account for location-based mobile games like Pok\'{e}mon GO, which specifically facilitate outdoor activity. To fill this gap in the research, we surveyed and interviewed parents to understand (1) their values and perceptions of this type of gameplay and (2) how they co-play Pok\'{e}mon GO with their children. Our findings provide empirical evidence that, in addition to appreciating the increased exercise and time outdoors, parents valued how play led to family bonding experiences. Furthermore, some traditional concerns about screen time persisted in this context, and new concerns about safety in real-world environments emerged. Parents mitigated these concerns with rules and gameplay choices, such as maintaining control of the mobile device, to ensure children were safe. This work contributes an empirical understanding of families as co-users of technology and offers a generative lens to study and design for joint media engagement among family members where gameplay differs from normative notions of screen time.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1483–1496},
numpages = {14},
keywords = {location-based mobile games, children, augmented reality games, pokemon go, joint media engagement, parental mediation, families},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026030,
author = {Bergstrom-Lehtovirta, Joanna and Boring, Sebastian and Hornb\ae{}k, Kasper},
title = {Placing and Recalling Virtual Items on the Skin},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026030},
doi = {10.1145/3025453.3026030},
abstract = {The human skin provides an ample, always-on surface for input to smart watches, mobile phones, and remote displays. Using touch on bare skin to issue commands, however, requires users to recall the location of items without direct visual feedback. We present an in-depth study in which participants placed 30 items on the hand and forearm and attempted to recall their locations. We found that participants used a variety of landmarks, personal associations, and semantic groupings in placing the items on the skin. Although participants most frequently used anatomical landmarks (e.g., fingers, joints, and nails), recall rates were higher for items placed on personal landmarks, including scars and tattoos. We further found that personal associations between items improved recall, and that participants often grouped important items in similar areas, such as family members on the nails. We conclude by discussing the implications of our findings for design of skin-based interfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1497–1507},
numpages = {11},
keywords = {recall performance, interface design, skin input},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025981,
author = {Yoshino, Koichi and Obata, Koichi and Tokuhisa, Satoru},
title = {FLIPPIN': Exploring a Paper-Based Book UI Design in a Public Space},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025981},
doi = {10.1145/3025453.3025981},
abstract = {Digital information systems are increasingly being used in public spaces such as museums. Such systems should be easily accessible, arouse interest and offer useful information, and be easy to use. We present FLIPPIN' user interface (UI) system, which mimics the look, feel, and usability of traditional books. We explored how the paper-based book UI is designed to improve the usability problems in a public space while creating the prototypes with the aim of introducing Japanese cultural assets and conducting a field evaluation to compare the proposed system to a touch panel UI. The results of evaluation indicated the positive effects of the system, especially in terms of the usability and user's active appreciation derived from a physical book interaction. In addition, we present design guidelines derived from our findings. The suggested design guidelines are expected to facilitate the future development of effective interactive digital information systems in public spaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1508–1517},
numpages = {10},
keywords = {public space, design, tangible, paper computing, book user interface},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025531,
author = {Sahibzada, Hasibullah and Hornecker, Eva and Echtler, Florian and Fischer, Patrick Tobias},
title = {Designing Interactive Advertisements for Public Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025531},
doi = {10.1145/3025453.3025531},
abstract = {Although public displays are increasingly being deployed in everyday situations, they are still mostly used as auto-active information sources. Adding interactivity can help to attract and engage users. We report on the design and in-the-wild evaluation of an interactive advert for a public display in a tourist information center. We evaluate and compare 3 different variants - non-interactive, interaction using body tracking, and interaction using personal mobile devices - with respect to attracting the attention and interaction from passersby. We further compare these variants with an iterated version of the body tracking system with an extended tracking area. Our findings include an unexpected reluctance of passersby to use their mobile device in public, and the increased interactive area for body interaction resulting in increased engagement and spontaneous multi-user interaction, while removing the so-called 'landing effect'. Based on our findings, we suggest guidelines for interactive adverts on public displays.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1518–1529},
numpages = {12},
keywords = {public display, advertisements, kinect, in-the-wild study, mobile devices, full-body interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025563,
author = {Bowey, Jason T. and Depping, Ansgar E. and Mandryk, Regan L.},
title = {Don't Talk Dirty to Me: How Sexist Beliefs Affect Experience in Sexist Games},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025563},
doi = {10.1145/3025453.3025563},
abstract = {Research on sexism in digital games has suggested that women self-select out of playing sexist games; however, assuming a homogenous gender-based response does not account for the diversity of identities within a gender group. Gender-incongruent responses to recent events like #gamergate implies that the gender of the participant is not paramount to experience, but that their beliefs about gender roles are. To explore the role of sexist beliefs on experience in sexist games, we created three versions of a game that were identical except for the presence of sexist imagery and/or dialogue. We show that enjoyment of sexist games is not predicted by player gender, but by the player's pre-existing beliefs about gender. Furthermore, avatar identification is the pathway through which enjoyment is facilitated. Finally, sexist dialogue does not improve the play experience for anyone rather it harms experience for players of all genders who do not hold sexist beliefs.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1530–1543},
numpages = {14},
keywords = {sexism, digital games, #gamergate, play experience},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025623,
author = {Shaer, Orit and Westendorf, Lauren and Knouf, Nicholas A. and Pederson, Claudia},
title = {Understanding Gaming Perceptions and Experiences in a Women's College Community},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025623},
doi = {10.1145/3025453.3025623},
abstract = {Recent trends in gaming diversification have shown that women are both an increasingly significant pool of consumers and game producers, and regular victims of misogynistic harassment. Such observations stress the importance of investigating the complex relationships of women and gaming. In this paper, we draw upon perspectives from Feminist HCI to extend the current knowledge of issues in gaming that are specific to women. We present results from a mixed-methods study with 327 participants who are students and alumnae of a women's college. Our findings shed light on the complex relationships of women with games, with other gamers, and with gaming culture and industry. The results also indicate that in some cases gender-related negative experiences of gaming have lasting impact on the participation and self-confidence of young women. We conclude by discussing the implications of our findings for the design of games, game development education, and for the study of gaming.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1544–1557},
numpages = {14},
keywords = {gender, video games, feminism},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025813,
author = {Tekin, Burak S. and Reeves, Stuart},
title = {Ways of Spectating: Unravelling Spectator Participation in Kinect Play},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025813},
doi = {10.1145/3025453.3025813},
abstract = {We explore spectating on video game play as an interactional and participatory activity. Drawing on a corpus of video recordings capturing 'naturally occurring' Kinect gaming within home settings, we detail how the analytic 'work' of spectating is interactionally accomplished as a matter of collaborative action with players and engagement in the game. We examine: spectators supporting players with continuous 'scaffolding'; spectators critiquing player technique during and between moments of play; spectators recognising and complimenting competent player conduct; and spectators reflecting on prior play to build instructions for the player. From this we draw out a number of points that shift the conversation in HCI about 'the spectator' towards understanding and designing for spectating as an interactional activity; that is, sequentially ordered and temporally coordinated. We also discuss bodily conduct and the particular ways of 'seeing' involved in spectating, and conclude with remarks on conceptual and design implications for HCI.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1558–1570},
numpages = {13},
keywords = {video gaming, spectatorship, spectating, participation, kinect, ethnomethodology, conversation analysis},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025708,
author = {Lessel, Pascal and Vielhauer, Alexander and Kr\"{u}ger, Antonio},
title = {Expanding Video Game Live-Streams with Enhanced Communication Channels: A Case Study},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025708},
doi = {10.1145/3025453.3025708},
abstract = {Live-streaming of video games is a recent phenomenon. One driving factor is the direct communication between the streamer and the audience. Currently, besides the platform-integrated options such as text chats, streamers often use external sources to let their community better articulate their opinions. In this paper we present a case study with our tool Helpstone, a live-streaming tool for the card game Hearthstone. Helpstone provides several new communication channels that allow for a better viewer-streamer interaction. We evaluated the tool within a live-streaming session with 23 viewers using Helpstone, and interviewed the streamer. The results indicate that not every implemented interactivity option is relevant. However, in general, new communication channels appear to be valuable and novel influence options are appreciated.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1571–1576},
numpages = {6},
keywords = {audience influence, twitch, streaming, hearthstone},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025602,
author = {Schwind, Valentin and Knierim, Pascal and Tasci, Cagri and Franczak, Patrick and Haas, Nico and Henze, Niels},
title = {"These Are Not My Hands!": Effect of Gender on the Perception of Avatar Hands in Virtual Reality},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025602},
doi = {10.1145/3025453.3025602},
abstract = {Rendering the user's body in virtual reality increases immersion and presence the illusion of "being there". Recent technology enables determining the pose and position of the hands to render them accordingly while interacting within the virtual environment. Virtual reality applications often use realistic male or female hands, mimic robotic hands, or cartoon hands. However, it is unclear how users perceive different hand styles. We conducted a study with 14 male and 14 female participants in virtual reality to investigate the effect of gender on the perception of six different hands. Quantitative and qualitative results show that women perceive lower levels of presence while using male avatar hands and male perceive lower levels of presence using non-human avatar hands. While women dislike male hands, men accept and feel presence with avatar hands of both genders. Our results highlight the importance of considering the users' diversity when designing virtual reality experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1577–1582},
numpages = {6},
keywords = {virtual reality, avatars, uncanny valley, presence, immersion},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025479,
author = {Beheshti, Elham and Kim, David and Ecanow, Gabrielle and Horn, Michael S.},
title = {Looking Inside the Wires: Understanding Museum Visitor Learning with an Augmented Circuit Exhibit},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025479},
doi = {10.1145/3025453.3025479},
abstract = {Understanding electrical circuits can be difficult for novices of all ages. In this paper, we describe a science museum exhibit that enables visitors to make circuits on an interactive tabletop and observe a simulation of electrons flowing through the circuit. Our goal is to use multiple representations to help convey basic concepts of current and resistance. To study visitor interaction and learning, we tested the design at a popular science museum with 60 parent-child dyads in three conditions: a control condition with no electron simulation; a condition with the simulation displayed alongside the circuit on the same screen; and an augmented reality condition, with the simulation displayed on a tablet that acts as a lens to see into the circuit. Our findings show that children did significantly better on a post-test in both experimental conditions, with children performing best in the AR condition. However, analysis of session videos shows unexpected parent-child collaboration in the AR condition.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1583–1594},
numpages = {12},
keywords = {augmented reality, multiple representations, design, museum learning., agent-based modeling, electrical circuits, interactive surfaces},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025578,
author = {Snow, Stephen and Auffenberg, Frederik and schraefel, m. c.},
title = {Log It While It's Hot: Designing Human Interaction with Smart Thermostats for Shared Work Environments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025578},
doi = {10.1145/3025453.3025578},
abstract = {Smart thermostats offer impressive scope for adapting to users' thermal comfort preferences and saving energy in shared work environments. Yet human interactions with smart thermostats thus far amount to an assumption from designers that users are willing and able to provide unbiased data at regular intervals; which may be unrealistic. In this paper we highlight the variety of social factors which complicate users' relationships with smart thermostats in shared work environments. These include social dynamics, expectations, and contextually specific factors that influence motivations for interaction with the system. In response we outline our framework towards a Smarter Thermostat: one which better accounts for these messy social inevitabilities, is equipped for a decline in user feedback over time and one which augments rather than attempts to replaces human intelligence- thereby ensuring a smarter thermostat does not create dumber humans.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1595–1606},
numpages = {12},
keywords = {smart thermostat, participatory sensing, thermal comfort, shared work environments, office, reciprocity},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025853,
author = {Hsu, Yen-Chia and Dille, Paul and Cross, Jennifer and Dias, Beatrice and Sargent, Randy and Nourbakhsh, Illah},
title = {Community-Empowered Air Quality Monitoring System},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025853},
doi = {10.1145/3025453.3025853},
abstract = {Developing information technology to democratize scientific knowledge and support citizen empowerment is a challenging task. In our case, a local community suffered from air pollution caused by industrial activity. The residents lacked the technological fluency to gather and curate diverse scientific data to advocate for regulatory change. We collaborated with the community in developing an air quality monitoring system which integrated heterogeneous data over a large spatial and temporal scale. The system afforded strong scientific evidence by using animated smoke images, air quality data, crowdsourced smell reports, and wind data. In our evaluation, we report patterns of sharing smoke images among stakeholders. Our survey study shows that the scientific knowledge provided by the system encourages agonistic discussions with regulators, empowers the community to support policy making, and rebalances the power relationship between stakeholders.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1607–1619},
numpages = {13},
keywords = {data visualization, participatory design, sustainable hci, adversarial design, community engagement, air quality, citizen science},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025799,
author = {Jakobi, Timo and Ogonowski, Corinna and Castelli, Nico and Stevens, Gunnar and Wulf, Volker},
title = {The Catch(Es) with Smart Home: Experiences of a Living Lab Field Study},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025799},
doi = {10.1145/3025453.3025799},
abstract = {Smart home systems are becoming an integral feature of the emerging home IT market. Under this general term, products mainly address issues of security, energy savings and comfort. Comprehensive systems that cover several use cases are typically operated and managed via a unified dashboard. Unfortunately, research targeting user experience (UX) design for smart home interaction that spans several use cases or covering the entire system is scarce. Furthermore, existing comprehensive and user-centered longterm studies on challenges and needs throughout phases of information collection, installation and operation of smart home systems are technologically outdated. Our 18-month Living Lab study covering 14 households equipped with smart home technology provides insights on how to design for improving smart home appropriation. This includes a stronger sensibility for household practices during setup and configuration, flexible visualizations for evolving demands and an extension of smart home beyond the location.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1620–1633},
numpages = {14},
keywords = {living lab, design, user experience, qualitative study, smart home},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025909,
author = {Bagroy, Shrey and Kumaraguru, Ponnurangam and De Choudhury, Munmun},
title = {A Social Media Based Index of Mental Well-Being in College Campuses},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025909},
doi = {10.1145/3025453.3025909},
abstract = {Psychological distress in the form of depression, anxiety and other mental health challenges among college students is a growing health concern. Dearth of accurate, continuous, and multi-campus data on mental well-being presents significant challenges to intervention and mitigation efforts in college campuses. We examine the potential of social media as a new "barometer" for quantifying the mental well-being of college populations. Utilizing student-contributed data in Reddit communities of over 100 universities, we first build and evaluate a transfer learning based classification approach that can detect mental health expressions with 97% accuracy. Thereafter, we propose a robust campus-specific Mental Well-being Index: MWI. We find that MWI is able to reveal meaningful temporal patterns of mental well-being in campuses, and to assess how their expressions relate to university attributes like size, academic prestige, and student demographics. We discuss the implications of our work for improving counselor efforts, and in the design of tools that can enable better assessment of the mental health climate of college campuses.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1634–1646},
numpages = {13},
keywords = {social media, college mental health, reddit, transfer learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025654,
author = {Gui, Xinning and Chen, Yu and Caldeira, Clara and Xiao, Dan and Chen, Yunan},
title = {When Fitness Meets Social Networks: Investigating Fitness Tracking and Social Practices on WeRun},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025654},
doi = {10.1145/3025453.3025654},
abstract = {The last two decades have seen growing interest in promoting physical activities by using self-tracking technologies. Previous work has identified social interactions in self-tracking as a crucial factor in motivating users to exercise. However, it is unclear how integrating fitness features into complex pre-existing social network affects users' fitness tracking practices and social interactions. In this research, we address this gap through a qualitative study of 32 users of WeRun--a fitness plugin of the widely adopted Chinese mobile social networking service WeChat. Our findings indicate that sharing fitness data with pre-existing social networks motivates users to continue self-tracking and enhances their existing social relationships. Nevertheless, users' concerns about their online personal images lead to challenges around privacy. We discuss how our study could advance understanding of the effects of fitness applications built on top of pre-existing social networks. We present implications for future social fitness applications design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1647–1659},
numpages = {13},
keywords = {wearable, social influence, privacy, self-tracking, social network, social interaction, personal informatics, behavior change, wechat, sharing, fitness, physical activity, werun, motivation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025796,
author = {MacLeod, Haley and Bastin, Grace and Liu, Leslie S. and Siek, Katie and Connelly, Kay},
title = {"Be Grateful You Don't Have a Real Disease": Understanding Rare Disease Relationships},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025796},
doi = {10.1145/3025453.3025796},
abstract = {We characterize how people with rare diseases consider their support needs as being met or neglected by different sources. After a 22-week study with 11 participants, we found that people with rare diseases identify strongly with their conditions but demonstrate a range of outlooks on their condition (positive, negative, and accepting). We found that participants think of themselves as being in a separate "Rare World" from the "normal" people in their lives and that relationships with friends and family members are strained. On the other hand, online communities were described as valuable sources of many forms of support, but do not adequately compensate for the lack of tangible support in offline relationships. We propose an approach to facilitating tangible support that leverages existing research on social matching, towards facilitating support among people with different rare diseases to overcome geographic and symptomatic challenges of coordinating support between people with the same rare disease.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1660–1673},
numpages = {14},
keywords = {rare disease, social support, social matching, timebanking, online health communities, chronic illness},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025747,
author = {Chung, Chia-Fang and Agapie, Elena and Schroeder, Jessica and Mishra, Sonali and Fogarty, James and Munson, Sean A.},
title = {When Personal Tracking Becomes Social: Examining the Use of Instagram for Healthy Eating},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025747},
doi = {10.1145/3025453.3025747},
abstract = {Many people appropriate social media and online communities in their pursuit of personal health goals, such as healthy eating or increased physical activity. However, people struggle with impression management, and with reaching the right audiences when they share health information on these platforms. Instagram, a popular photo-based social media platform, has attracted many people who post and share their food photos. We aim to inform the design of tools to support healthy behaviors by understanding how people appropriate Instagram to track and share food data, the benefits they obtain from doing so, and the challenges they encounter. We interviewed 16 women who consistently record and share what they eat on Instagram. Participants tracked to support themselves and others in their pursuit of healthy eating goals. They sought social support for their own tracking and healthy behaviors and strove to provide that support for others. People adapted their personal tracking practices to better receive and give this support. Applying these results to the design of health tracking tools has the potential to help people better access social support.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1674–1687},
numpages = {14},
keywords = {social support, social media, health, personal informatics, self-tracking, food journals},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025745,
author = {Manuel, Jennifer and Vigar, Geoff and Bartindale, Tom and Comber, Rob},
title = {Participatory Media: Creating Spaces for Storytelling in Neighbourhood Planning},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025745},
doi = {10.1145/3025453.3025745},
abstract = {Neighbourhood planning devolves power to communities to create their own planning policy but traditional forms of participation are still relied upon. And despite the ubiquitous nature of technology in society, digital participation methods are rarely used. In this paper, we outline fieldwork with two neighbourhood planning groups who used participatory media technology to improve engagement though the art of storytelling. We focus on the configuration of participatory media as a way to widen participation and enable story creation and sharing amongst citizens. We highlight that storytelling using media technology can provide a model of and a model for the way we "do" neighbourhood planning whilst emphasising the challenges of ensuring processes are linked to tangible actions and encouraging the multiplicity of stories.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1688–1701},
numpages = {14},
keywords = {neighbourhood planning, new media, participatory media},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026035,
author = {Zhou, Huiyuan and Edrah, Aisha and MacKay, Bonnie and Reilly, Derek},
title = {Block Party: Synchronized Planning and Navigation Views for Neighbourhood Expeditions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026035},
doi = {10.1145/3025453.3026035},
abstract = {Mobile wayfinding and guide apps have become indispensable tools for navigating unfamiliar urban spaces. Such applications address targeted, "just-in-time" queries, but are not optimally designed for multi-point expeditions that can quickly build route and survey-level familiarity with a neighbourhood. We first conducted an experimental simulation involving a homebuying scenario to assess the usefulness of a popular mobile wayfinding and search application (Google Maps) for exploring a neighbourhood. We then designed a prototype application called Block Party that addresses a number of limitations of Google Maps for this purpose, and evaluated it in a second replica study. The results suggested that application designs that facilitate switching among distinct but synchronized navigation views such as Block Party might support more efficient usage and the selection of task-appropriate views, leading to better overall spatial awareness.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1702–1713},
numpages = {12},
keywords = {google maps, wayfinding, itinerary planning, neighbourhood expeditions, mobile guide},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025948,
author = {Smith, Nancy and Bardzell, Shaowen and Bardzell, Jeffrey},
title = {Designing for Cohabitation: Naturecultures, Hybrids, and Decentering the Human in Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025948},
doi = {10.1145/3025453.3025948},
abstract = {Recent research in urban informatics has presented the city as both a complex technological center and a diverse cultural, social, and political entity. However, there has been little research into the changing role that nature plays in urban space, particularly when it comes to understanding how animals have adapted to life in technological and networked cities. In the wake of urbanization, new kinds of cohabitation, including increased interactions between humans and animals, has resulted in new challenges for those working in urban informatics. We leverage key concepts in the Anthropocene-naturecultures, hybrids, and decentering the human in design-to unpack the entanglements of animal-human-computer interaction in two design cases: The Big Cat Behavioral Tracking Initiative and The Phenology Clock. We contribute to urban informatics and HCI research by reflecting on ways in which design can promote new forms of cohabitation and support a broader conception of the city that sees animals as an essential part of the urban landscape.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1714–1725},
numpages = {12},
keywords = {posthumanism, anthropocene, urban informatics, animal-computer interaction, cohabitation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025705,
author = {Johnson, Isaac and Sosik, Victoria Schwanda and Ballard, Kacey},
title = {Stranger Searching in a Strange Land: The Impact of Familiarity on Local Search},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025705},
doi = {10.1145/3025453.3025705},
abstract = {Local search entails looking for places, such as restaurants or hotels, in a geographically-constrained region. Within local search, it has been observed that an individual's familiarity with their environment (i.e. how well they know the area in a query of the form "{places} in {area}") impacts which places they are most interested in visiting. Less well-understood though is how people's information preferences differ during 1) different phases of the search process and 2) based on their level of familiarity. Through a series of surveys in the domain of dining, we explore how familiarity moderates what level of information is useful to an individual about restaurant location when choosing a place to visit. We further examine how these preferences vary between regions and phases of local search (deciding on a restaurant or determining how to go). We contribute an understanding of people's information preferences during search, building on prior research of how offline context impacts online needs.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1726–1730},
numpages = {5},
keywords = {dining, familiarity, localization, local search},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025723,
author = {Ranasinghe, Nimesha and Jain, Pravar and Karwita, Shienny and Tolley, David and Do, Ellen Yi-Luen},
title = {Ambiotherm: Enhancing Sense of Presence in Virtual Reality by Simulating Real-World Environmental Conditions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025723},
doi = {10.1145/3025453.3025723},
abstract = {In this paper, we present and evaluate Ambiotherm, a wearable accessory for Head Mounted Displays (HMD) that provides thermal and wind stimuli to simulate real-world environmental conditions, such as ambient temperatures and wind conditions, to enhance the sense of presence in Virtual Reality (VR). Ambiotherm consists of a Ambient Temperature Module that is attached to the user's neck, a Wind Simulation Module focused towards the user's face, and a Control Module utilizing Bluetooth communication. We demonstrate Ambiotherm with two VR environments, a hot desert, and a snowy mountain, to showcase the different types of simulated environmental conditions. We conduct several studies to 1) address design factors of the system and 2) evaluate Ambiotherm's effect on factors related to a user's sense of presence. Our findings show that the addition of wind and thermal stimuli significantly improves sensory and realism factors, contributing towards an enhanced sense of presence when compared to traditional VR experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1731–1742},
numpages = {12},
keywords = {ambient temperature, multimodal interaction, virtual wind, virtual reality, presence},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025614,
author = {Wilson, Graham and Brewster, Stephen A.},
title = {Multi-Moji: Combining Thermal, Vibrotactile &amp; Visual Stimuli to Expand the Affective Range of Feedback},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025614},
doi = {10.1145/3025453.3025614},
abstract = {This paper explores the combination of multiple concurrent modalities for conveying emotional information in HCI: temperature, vibration and abstract visual displays. Each modality has been studied individually, but can only convey a limited range of emotions within two-dimensional valence-arousal space. This paper is the first to systematically combine multiple modalities to expand the available affective range. Three studies were conducted: Study 1 measured the emotionality of vibrotactile feedback by itself; Study 2 measured the perceived emotional content of three bimodal combinations: vibrotactile + thermal, vibrotactile + visual and visual + thermal. Study 3 then combined all three modalities. Results show that combining modalities increases the available range of emotional states, particularly in the problematic top-right and bottom-left quadrants of the dimensional model. We also provide a novel lookup resource for designers to identify stimuli to convey a range of emotions},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1743–1755},
numpages = {13},
keywords = {visual feedback, vibration, emotion, thermal feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025844,
author = {Tewell, Jordan and Bird, Jon and Buchanan, George R.},
title = {The Heat is On: A Temperature Display for Conveying Affective Feedback},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025844},
doi = {10.1145/3025453.3025844},
abstract = {Previous research has investigated whether temperature can augment a range of media including music, images and video. We describe the first experiment to investigate whether temperature can augment emotion conveyed by text messages. A challenge in prior work has been ensuring users can discern different thermal signals. We present an improved technique for thermal feedback that uses an array of three thermal stimulators. We demonstrate that the Thermal Array Display (TAD) increases users' ability to identify temperatures within a narrower range, compared to using a single thermal stimulator. While text messages dominate valence in the absence of context for temperature, the TAD consistently conveys arousal, and can enhance arousal of text messages, especially those that are emotionally neutral. We discuss potential applications of augmenting text with temperature.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1756–1767},
numpages = {12},
keywords = {thermal haptics, affective computing, thermal feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025471,
author = {Mauriello, Matthew Louis and Saha, Manaswi and Brown, Erica Brown and Froehlich, Jon E.},
title = {Exploring Novice Approaches to Smartphone-Based Thermographic Energy Auditing: A Field Study},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025471},
doi = {10.1145/3025453.3025471},
abstract = {The recent integration of thermal cameras with commodity smartphones presents an opportunity to engage the public in evaluating energy-efficiency issues in the built environment. However, it is unclear how novice users without professional experience or training approach thermographic energy auditing activities. In this paper, we recruited 10 participants for a four-week field study of end-user behavior exploring novice approaches to semi-structured thermographic energy auditing tasks. We analyze thermographic imagery captured by participants as well as weekly surveys and post-study debrief interviews. Our findings suggest that while novice users perceived thermal cameras as useful in identifying energy-efficiency issues in buildings, they struggled with interpretation and confidence. We characterize how novices perform thermographic-based energy auditing, synthesize key challenges, and discuss implications for design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1768–1780},
numpages = {13},
keywords = {sustainable hci, field study, thermography, energy efficiency, mobile devices, formative inquiry},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025956,
author = {Ma, Xiao and Andalibi, Nazanin and Barkhuus, Louise and Naaman, Mor},
title = {"People Are Either Too Fake or Too Real": Opportunities and Challenges in Tie-Based Anonymity},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025956},
doi = {10.1145/3025453.3025956},
abstract = {In recent years, several mobile applications allowed individuals to anonymously share information with friends and contacts, without any persistent identity marker. The functions of these "tie-based" anonymity services may be notably different than other social media services. We use semi-structured interviews to qualitatively examine motivations, practices and perceptions in two tie-based anonymity apps: Secret (now defunct, in the US) and Mimi (in China). Among the findings, we show that: (1) while users are more comfortable in self-disclosure, they still have specific practices and strategies to avoid or allow identification; (2) attempts for deidentification of others are prevalent and often elaborate; and (3) participants come to expect both negativity and support in response to posts. Our findings highlight unique opportunities and potential benefits for tie-based anonymity apps, including serving disclosure needs and social probing. Still, challenges for making such applications successful, for example the prevalence of negativity and bullying, are substantial.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1781–1793},
numpages = {13},
keywords = {wumii, secret, social media, anonymity, mimi, cmc, self-disclosure},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025465,
author = {Whiting, Emily and Ouf, Nada and Makatura, Liane and Mousas, Christos and Shu, Zhenyu and Kavan, Ladislav},
title = {Environment-Scale Fabrication: Replicating Outdoor Climbing Experiences},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025465},
doi = {10.1145/3025453.3025465},
abstract = {Despite rapid advances in 3D printing, fabricating large, durable and robust artifacts is impractical with current technology. We focus on a particularly challenging environment-scale artifact: rock climbing routes. We propose a prototype fabrication method to replicate part of an outdoor climbing route and enable the same sensorimotor experience in an indoor gym. We start with 3D reconstruction of the rock wall using multi-view stereo and use reference videos of a climber in action to identify localized rock features that are necessary for ascent. We create 3D models akin to traditional indoor climbing holds, fabricated using rapid prototyping, molding and casting techniques. This results in robust holds accurately replicating the features and configuration of the original rock route. Validation was performed on two rock climbing sites in New Hampshire and Utah. We verified our results by comparing climbers' moves on the indoor replicas and original outdoor routes.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1794–1804},
numpages = {11},
keywords = {fabrication, sports technologies, rock climbing, 3d reconstruction, terrain modeling, rapid prototyping},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026048,
author = {Fan, Min and Antle, Alissa N. and Hoskyn, Maureen and Neustaedter, Carman and Cramer, Emily S.},
title = {Why Tangibility Matters: A Design Case Study of At-Risk Children Learning to Read and Spell},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026048},
doi = {10.1145/3025453.3026048},
abstract = {Tangibles may be effective for reading applications. Letters can be represented as 3D physical objects. Words are spatially organized collections of letters. We explore how tangibility impacts reading and spelling acquisition for young Anglophone children who have dyslexia. We describe our theory-based design rationale and present a mixed-methods case study of eight children using our PhonoBlocks system. All children made significant gains in reading and spelling on trained and untrained (new) words, and could apply all spelling rules a month later. We discuss the design features of our system that contributed to effective learning processes, resulting in successful learning outcomes: dynamic colour cues embedded in 3D letters, which can draw attention to how letter(s) position changes their sounds; and the form of 3D tangible letters, which can enforce correct letter orientation and enable epistemic strategies in letter organization that simplify spelling tasks. We conclude with design guidelines for tangible reading systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1805–1816},
numpages = {12},
keywords = {children, mixed-methods., tangible user interfaces, dyslexia, embedded interaction, reading acquisition},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026036,
author = {Fraser, C. Ailie and Grossman, Tovi and Fitzmaurice, George},
title = {WeBuild: Automatically Distributing Assembly Tasks Among Collocated Workers to Improve Coordination},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026036},
doi = {10.1145/3025453.3026036},
abstract = {Physical construction and assembly tasks are often carried out by groups of collocated workers, and they can be difficult to coordinate. Group members must spend time deciding how to split up the task, how to assign subtasks to each other, and in what order subtasks should be completed. Informed by an observational study examining group coordination challenges, we built a task distribution system called WeBuild. Our custom algorithm dynamically assigns subtasks to workers in a group, taking into account factors such as the dependencies between subtasks and the skills of each group member. Each worker views personalized step-by-step instructions on a mobile phone, while a dashboard visualizes the entire process. An initial study found that WeBuild reduced the start-up time needed to coordinate and begin a task, and provides direction for future research to build on toward improving group efficiency and coordination for complex tasks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1817–1830},
numpages = {14},
keywords = {collaboration, coordination, task distribution, assembly instructions},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025890,
author = {Besan\c{c}on, Lonni and Ammi, Mehdi and Isenberg, Tobias},
title = {Pressure-Based Gain Factor Control for Mobile 3D Interaction Using Locally-Coupled Devices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025890},
doi = {10.1145/3025453.3025890},
abstract = {We present the design and evaluation of pressure-based interactive control of 3D navigation precision. Specifically, we examine the control of gain factors in tangible 3D interactions using locally-coupled mobile devices. By focusing on pressure as a separate input channel we can adjust gain factors independently from other input modalities used in 3D navigation, in particular for the exploration of 3D visualisations. We present two experiments. First, we determined that people strongly preferred higher pressures to be mapped to higher gain factors. Using this mapping, we compared pressure with rate control, velocity control, and slider-based control in a second study. Our results show that pressure-based gain control allows people to be more precise in the same amount of time compared to established input modalities. Pressure-based control was also clearly preferred by our participants. In summary, we demonstrate that pressure facilitates effective and efficient precision control for mobile 3D navigation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1831–1842},
numpages = {12},
keywords = {TUI, 3D navigation, tangible interaction, pressure input},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025464,
author = {Girotto, Victor and Walker, Erin and Burleson, Winslow},
title = {The Effect of Peripheral Micro-Tasks on Crowd Ideation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025464},
doi = {10.1145/3025453.3025464},
abstract = {Research has explored different ways of improving crowd ideation, such as presenting examples or employing facilitators. While such support is usually generated through peripheral tasks delegated to crowd workers who are not part of the ideation, it is possible that the ideators themselves could benefit from the extra thought involved in doing them. Therefore, we iterate over an ideation system in which ideators can perform one of three peripheral tasks (rating originality and usefulness, similarity, or idea combination) on demand. In controlled experiments with workers on Mechanical Turk, we compare the effects of these secondary tasks to simple idea exposure or no support at all, examining usage of the inspirations, fluency, breadth, and depth of ideas generated. We find tasks to be as good or better than exposure, although this depends on the period of ideation and the fluency level. We also discuss implications of inspiration size, homogeneity, and frequency.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1843–1854},
numpages = {12},
keywords = {ideation, microtasks, creativity, crowdsourcing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025640,
author = {Vashistha, Aditya and Sethi, Pooja and Anderson, Richard},
title = {Respeak: A Voice-Based, Crowd-Powered Speech Transcription System},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025640},
doi = {10.1145/3025453.3025640},
abstract = {Speech transcription is an expensive service with high turnaround time for audio files containing languages spoken in developing countries and regional accents of well-represented languages. We present Respeak - a voice-based, crowd-powered system that capitalizes on the strengths of crowdsourcing and automatic speech recognition (instead of typing) to transcribe such audio files. We created Respeak and optimized its design through a series of cognitive experiments. We deployed it with 25 university students in India who completed 5464 micro-transcription tasks, transcribing 55 minutes of widely-varied audio content, and collectively earning USD 46 as mobile airtime. The Respeak engine aligned the transcript generated by five randomly selected users to transcribe Hindi and Indian English audio files with a word error rate (WER) of 8.6% and 15.2%, respectively. The cost of speech transcription was USD 0.83 per minute with a turnaround time of 39.8 hours, substantially less than industry standards. Using a mixed-methods analysis of cognitive experiments, system performance and qualitative interviews, we evaluate Respeak's design, user experience, strengths, and weaknesses. Our findings suggest that Respeak improves the quality of speech transcription while enhancing the earning potential of low-income populations in resource-constrained settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1855–1866},
numpages = {12},
keywords = {transcription, India, HCI4D, crowdsourcing, speech},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025687,
author = {Morris, Meredith Ringel and Bigham, Jeffrey P. and Brewer, Robin and Bragg, Jonathan and Kulkarni, Anand and Li, Jessie and Savage, Saiph},
title = {Subcontracting Microwork},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025687},
doi = {10.1145/3025453.3025687},
abstract = {Mainstream crowdwork platforms treat microtasks as indivisible units; however, in this article, we propose that there is value in re-examining this assumption. We argue that crowdwork platforms can improve their value proposition for all stakeholders by supporting subcontracting within microtasks. After describing the value proposition of subcontracting, we then define three models for microtask subcontracting: real-time assistance, task management, and task improvement, and reflect on potential use cases and implementation considerations associated with each. Finally, we describe the outcome of two tasks on Mechanical Turk meant to simulate aspects of subcontracting. We reflect on the implications of these findings for the design of future crowd work platforms that effectively harness the potential of subcontracting workflows.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1867–1876},
numpages = {10},
keywords = {subcontracting, task design, crowdsourcing, human computation, task selection, microwork},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025930,
author = {Gebru, Timnit and Krause, Jonathan and Deng, Jia and Fei-Fei, Li},
title = {Scalable Annotation of Fine-Grained Categories Without Experts},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025930},
doi = {10.1145/3025453.3025930},
abstract = {We present a crowdsourcing workflow to collect image annotations for visually similar synthetic categories without requiring experts. In animals, there is a direct link between taxonomy and visual similarity: e.g. a collie (type of dog) looks more similar to other collies (e.g. smooth collie) than a greyhound (another type of dog). However, in synthetic categories such as cars, objects with similar taxonomy can have very different appearance: e.g. a 2011 Ford F-150 Supercrew-HD looks the same as a 2011 Ford F-150 Supercrew-LL but very different from a 2011 Ford F-150 Supercrew-SVT. We introduce a graph based crowdsourcing algorithm to automatically group visually indistinguishable objects together. Using our workflow, we label 712,430 images by ~1,000 Amazon Mechanical Turk workers; resulting in the largest fine-grained visual dataset reported to date with 2,657 categories of cars annotated at 1/20th the cost of hiring experts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1877–1881},
numpages = {5},
keywords = {fine-grained dataset, crowdsourcing, human computation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025553,
author = {Huber, Bernd and Reinecke, Katharina and Gajos, Krzysztof Z.},
title = {The Effect of Performance Feedback on Social Media Sharing at Volunteer-Based Online Experiment Platforms},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025553},
doi = {10.1145/3025453.3025553},
abstract = {As an alternative to online labor markets, several platforms recruit unpaid online volunteers to participate in behavioral experiments that provide personalized feedback. These platforms rely on word-of-mouth sharing by previous participants for recruitment of new participants. We analyzed the impact of performance feedback provided at the end of an experiment on 81,131 participants' sharing behavior. We show that higher performing participants share significantly more. We also show that self-verification has a moderating effect: people who expected to do poorly are not affected by a high score, but people who expected to do as well as others or better, are. In a second experiment, we evaluate three distinct social comparison designs for the presentation of the results. As expected, the design that most emphasized participants' relative success led to most sharing. Contrary to our expectations, people who expected to do poorly benefited from the most optimistic social comparison more than participants who expected to do better than others.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1882–1886},
numpages = {5},
keywords = {volunteer-based online experiments, self-evaluation, social comparison},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025508,
author = {Krupka, Eyal and Karmon, Kfir and Bloom, Noam and Freedman, Daniel and Gurvich, Ilya and Hurvitz, Aviv and Leichter, Ido and Smolin, Yoni and Tzairi, Yuval and Vinnikov, Alon and Bar-Hillel, Aharon},
title = {Toward Realistic Hands Gesture Interface: Keeping It Simple for Developers and Machines},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025508},
doi = {10.1145/3025453.3025508},
abstract = {Development of a rich hand-gesture-based interface is currently a tedious process, requiring expertise in computer vision and/or machine learning. We address this problem by introducing a simple language for pose and gesture description, a set of development tools for using it, and an algorithmic pipeline that recognizes it with high accuracy. The language is based on a small set of basic propositions, obtained by applying four predicate types to the fingers and to palm center: direction, relative location, finger touching and finger folding state. This enables easy development of a gesture-based interface, using coding constructs, gesture definition files or an editing GUI. The language is recognized from 3D camera input with an algorithmic pipeline composed of multiple classification/regression stages, trained on a large annotated dataset. Our experimental results indicate that the pipeline enables successful gesture recognition with a very low computational load, thus enabling a gesture-based interface on low-end processors.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1887–1898},
numpages = {12},
keywords = {hand gesture nui development, hand gesture recognition},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026001,
author = {Zagermann, Johannes and Pfeil, Ulrike and Fink, Daniel and von Bauer, Philipp and Reiterer, Harald},
title = {Memory in Motion: The Influence of Gesture- and Touch-Based Input Modalities on Spatial Memory},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026001},
doi = {10.1145/3025453.3026001},
abstract = {People's ability to remember and recall spatial information can be harnessed to improve navigation and search performances in interactive systems. In this paper, we investigate how display size and input modality influence spatial memory, especially in relation to efficiency and user satisfaction. Based on an experiment with 28 participants, we analyze the effect of three input modalities (trackpad, direct touch, and gesture-based motion controller) and two display sizes (10.6" and 55") on people's ability to navigate to spatially spread items and recall their positions. Our findings show that the impact of input modality and display size on spatial memory is not straightforward, but characterized by trade-offs between spatial memory, efficiency, and user satisfaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1899–1910},
numpages = {12},
keywords = {output device, input modality, spatial memory},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025692,
author = {Matthies, Denys J. C. and Strecker, Bernhard A. and Urban, Bodo},
title = {<i>EarFieldSensing</i>: A Novel In-Ear Electric Field Sensing to Enrich Wearable Gesture Input through Facial Expressions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025692},
doi = {10.1145/3025453.3025692},
abstract = {EarFieldSensing (EarFS) is a novel input method for mobile and wearable computing using facial expressions. Facial muscle movements induce both electric field changes and physical deformations, which are detectable with electrodes placed inside the ear canal. The chosen ear-plug form factor is rather unobtrusive and allows for facial gesture recognition while utilizing the close proximity to the face. We collected 25 facial-related gestures and used them to compare the performance levels of several electric sensing technologies (EMG, CS, EFS, EarFS) with varying electrode setups. Our developed wearable fine-tuned electric field sensing employs differential amplification to effectively cancel out environmental noise while still being sensitive towards small facial-movement-related electric field changes and artifacts from ear canal deformations. By comparing a mobile with a stationary scenario, we found that EarFS continues to perform better in a mobile scenario. Quantitative results show EarFS to be capable of detecting a set of 5 facial gestures with a precision of 90% while sitting and 85.2% while walking. We provide detailed instructions to enable replication of our low-cost sensing device. Applying it to different positions of our body will also allow to sense a variety of other gestures and activities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1911–1922},
numpages = {12},
keywords = {wearable computing, facial expression control, hands-/eyes-free, electric field sensing, body potential sensing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025807,
author = {McIntosh, Jess and Marzo, Asier and Fraser, Mike and Phillips, Carol},
title = {EchoFlex: Hand Gesture Recognition Using Ultrasound Imaging},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025807},
doi = {10.1145/3025453.3025807},
abstract = {Recent improvements in ultrasound imaging enable new opportunities for hand pose detection using wearable devices. Ultrasound imaging has remained under-explored in the HCI community despite being non-invasive, harmless and capable of imaging internal body parts, with applications including smart-watch interaction, prosthesis control and instrument tuition. In this paper, we compare the performance of different forearm mounting positions for a wearable ultrasonographic device. Location plays a fundamental role in ergonomics and performance since the anatomical features differ among positions. We also investigate the performance decrease due to cross-session position shifts and develop a technique to compensate for this misalignment. Our gesture recognition algorithm combines image processing and neural networks to classify the flexion and extension of 10 discrete hand gestures with an accuracy above 98%. Furthermore, this approach can continuously track individual digit flexion with less than 5% NRMSE, and also differentiate between digit flexion at different joints.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1923–1934},
numpages = {12},
keywords = {interactive ultrasound imaging, computer vision, gesture recognition, machine learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026053,
author = {Ford, Colin M.},
title = {Virtuosos on the Screen: Playing Virtual Characters Like Instruments in Competitive Super Smash Bros. Melee},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026053},
doi = {10.1145/3025453.3026053},
abstract = {Previous research on virtual sociality in games suggests that players use custom avatars to reflect, alter, and perform new identities in digital spaces. However, this study explores an alternative theory of social performance by analyzing a competitive game, Super Smash Bros. Melee, where players face off in timed matches and interact through pre-designed characters. This study shows how Melee players treat virtual characters as performative instruments, similar to the violin or the piano. In forum posts and player-created media, Melee players emphasize the need to train one's hands, eyes, and mind in order to master a character's complexity and express style and skills in live matches. Instrumental embodiment in a competitive game like Melee thus positions players as virtuosos who perform for perceptive audiences. This research points to a range of ways that players may relate to virtual bodies, connected to distinct kinds of social activities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1935–1948},
numpages = {14},
keywords = {embodiment, avatar, play, instrument, performance, esports, player-character relationship},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025826,
author = {Jia, Yuan and Liu, Yikun and Yu, Xing and Voida, Stephen},
title = {Designing Leaderboards for Gamification: Perceived Differences Based on User Ranking, Application Domain, and Personality Traits},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025826},
doi = {10.1145/3025453.3025826},
abstract = {Leaderboards, a common gamification technique, are used to enhance engagement through social comparisons. Prior research has demonstrated the overall utility of leaderboards but has not examined their effectiveness when individuals are ranked at particular levels or when the technique is applied in different application domains, such as social networking, fitness, or productivity. In this paper, we present a survey study investigating how preferences for leaderboards change based on individual differences (personality traits), ranking, social scoping, and application domains. Our results show that a respondent's position on the leaderboard had important effects on their perception of the leaderboard and the surrounding app, and that participants rated leaderboards most favorably in fitness apps and least favorably in social networking contexts. More extraverted people reported more positive experiences with leaderboards despite their ranking or the application domain. We present design implications for creating leaderboards targeted at different domains and for different audiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1949–1960},
numpages = {12},
keywords = {motivational affordances, personality, user interface design, gamification, leaderboards},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025678,
author = {Qian, Kun and Wu, Chenshu and Zhou, Zimu and Zheng, Yue and Yang, Zheng and Liu, Yunhao},
title = {Inferring Motion Direction Using Commodity Wi-Fi for Interactive Exergames},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025678},
doi = {10.1145/3025453.3025678},
abstract = {In-air interaction acts as a key enabler for ambient intelligence and augmented reality. As an increasing popular example, exergames, and the alike gesture recognition applications, have attracted extensive research in designing accurate, pervasive and low-cost user interfaces. Recent advances in wireless sensing show promise for a ubiquitous gesture-based interaction interface with Wi-Fi. In this work, we extract complete information of motion-induced Doppler shifts with only commodity Wi-Fi. The key insight is to harness antenna diversity to carefully eliminate random phase shifts while retaining relevant Doppler shifts. We further correlate Doppler shifts with motion directions, and propose a light-weight pipeline to detect, segment, and recognize motions without training. On this basis, we present WiDance, a Wi-Fi-based user interface, which we utilize to design and prototype a contactless dance-pad exergame. Experimental results in typical indoor environment demonstrate a superior performance with an accuracy of 92%, remarkably outperforming prior approaches.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1961–1972},
numpages = {12},
keywords = {motion direction recognition, wireless sensing, exergame, off-the-shelf wi-fi},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025934,
author = {Kasunic, Anna and Kaufman, Geoff},
title = {Be Me or Be Mii? A Study of Self-Presentation and Interaction in the Miitomo Mobile Application},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025934},
doi = {10.1145/3025453.3025934},
abstract = {In this study, we consider what Nintendo's widely downloaded Miitomo mobile application, which simultaneously promotes non-idealized self-fictionalization and authentic self-presentation, can suggest to us about self-presentation and technology design. Ten groups of four friends each (N=40), all novice users, engaged with Miitomo for one week, and completed supplementary pre- and post-use surveys. The data were analyzed to assess the extent to which participants' engagement in Miitomo reflected their "real life" selves and correlated with in-app and "real life" features, respectively. Although most participants believed that their behaviors within the app accurately reflected their "true selves," we found that in-app traits generally correlated more strongly with Miitomo engagement patterns than did users' "real life" traits and qualities. We discuss implications for social network and online community design, and propose future plans to study authenticity and self-distancing in online self-presentation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1973–1977},
numpages = {5},
keywords = {fantasy, authenticity, self-presentation, social networks, self-distancing, personality, mobile application},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025967,
author = {Wuertz, Jason and Bateman, Scott and Tang, Anthony},
title = {Why Players Use Pings and Annotations in Dota 2},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025967},
doi = {10.1145/3025453.3025967},
abstract = {Groupware research has long focused on representing gestures as a means to facilitate collaboration. However, this work has not led to wide support of gesturing in commercial groupware systems. In contrast, Dota 2, a popular MOBA game, provides two frequently-used gesturing tools: annotations - freely drawn lines on top of the gamespace - and pings - a combination of animation and sound indicating a point of interest. While gesturing tools are important for quickly coordinating with teammates in Dota 2, there is little information about how and why people use them. To gather this information, we performed two complementary studies: an interaction analysis of eight game replays, and a survey of 167 experienced players. Our findings include: six distinct motivations for the use of gesturing tools; when and how frequently gesture motivations occur during games; and, that players find pings an essential tool for winning, but not annotations. Our findings provide new directions for the design of gesturing tools in groupware and online games.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {1978–2018},
numpages = {41},
keywords = {mobas, pings, online games, communication tools, groupware, gestures, motivation, dota 2, annotations},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025862,
author = {Windlin, Charles and Laaksolahti, Jarmo},
title = {Unpacking Visible Light Communication as a Material for Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025862},
doi = {10.1145/3025453.3025862},
abstract = {Communication through visible light (VLC) is gaining ground as an alternative to traditional radio communication in many settings. Effectively using VLC in creative design processes may however be difficult as the material properties of VLC can be hard to grasp and therefore to use. This paper presents a design exploration where a set of artifacts was created to enable designers to play around with VLC and better understand its properties and their potential use for design. Each artifact was designed to illustrate a particular property of light communication ranging from inner workings of transmission protocols to properties of light in itself. The set was used in two small scale workshops where users played around with the artifacts and afterward were interviewed about their experiences. Interviews and observations from the workshops suggest that users gained insights into the material properties of light communication and were also inspired to think of creative uses for VLC based on those insights},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2019–2023},
numpages = {5},
keywords = {interaction design, materiality, visual light communication},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025504,
author = {Harnett, C. K.},
title = {Tobiko: A Contact Array for Self-Configuring, Surface-Powered Sensors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025504},
doi = {10.1145/3025453.3025504},
abstract = {This paper describes a contact array that outputs the maximum and minimum voltages at its contacts. The goal is to extract power for a detachable touch sensor, display, or other human-computer interaction (HCI) device that is attached to a surface by a user, and that does not have its own power source. Experimental results are shown for an array that has positive and negative outputs and a pass-through at each contact position. It solves the startup problem for a randomly-placed batteryless sensor patch or sticker, which can scan its ports to discover neighboring devices only after it obtains power. Applications include user-configurable electronic textile circuits, and new methods for prototyping and repairing large-area flexible circuits. This note describes construction of a 7x7 array, provides design rules, and examines the signal quality on two kinds of electronic surfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2024–2028},
numpages = {5},
keywords = {self-configuring, e-textiles, wearables, contact array},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025987,
author = {Clegg, Tamara and Norooz, Leyla and Kang, Seokbin and Byrne, Virginia and Katzen, Monica and Velez, Rafael and Plane, Angelisa and Oguamanam, Vanessa and Outing, Thomas and Yip, Jason and Bonsignore, Elizabeth and Froehlich, Jon},
title = {Live Physiological Sensing and Visualization Ecosystems: An Activity Theory Analysis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025987},
doi = {10.1145/3025453.3025987},
abstract = {Wearable sensing poses new opportunities to enhance personal connections to learning and authentic scientific inquiry experiences. In our work, we leverage the body and physical action as an engaging platform for learning through live physiological sensing and visualization (LPSV). Prior research suggests the potential of this approach, but was limited to single-session evaluations in informal environments. In this paper, we examine LPSV tools in a classroom environment during a four-day deployment. To highlight the complex interconnections between space, teachers, curriculum, and tool use, we analyze our data through the lens of Activity Theory. Our findings show the importance of integrating model-based representations for supporting exploration and analytic representations for scaffolding scientific inquiry. Activity Theory highlights leveraging life-relevant connections available within a physical space and considering policies and norms related to learners' physical bodies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2029–2041},
numpages = {13},
keywords = {lpsv, wearables for learning, sbl, scientific inquiry},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025983,
author = {Soden, Robert and Sprain, Leah and Palen, Leysia},
title = {Thin Grey Lines: Confrontations With Risk on Colorado's Front Range},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025983},
doi = {10.1145/3025453.3025983},
abstract = {This paper reports on two years of ethnographic observation of the science and politics of flood risk in Colorado, as well as design research that examines citizen interaction with expert knowledge about flooding in the region. We argue that the 100-year floodplain standard that inform maps produced by the USA Federal Emergency Management Agency (FEMA)'s National Floodplain Insurance Program (NFIP) represent a problematic form of discursive closure of scientific understanding of flood hazard. We show that in order to meet the requirements of the NFIP, this standard acts as a closure that conveys a certainty that the underlying science does not warrant and foreshortens dialogue on disaster risk and public understanding of flood hazard. Engaging with literature in science and technology studies and human-centered computing, we investigate design opportunities for resisting closure and supporting public formation through encounters with the uncertainty and complexities of risk information.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2042–2053},
numpages = {12},
keywords = {design, science and technology studies., public engagement, human-centered computing, flood risk},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025893,
author = {Musabirov, Ilya and Bulygin, Denis and Okopny, Paul and Sirotkin, Alexander},
title = {Deconstructing Cosmetic Virtual Goods Experiences in Dota 2},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025893},
doi = {10.1145/3025453.3025893},
abstract = {Cosmetic items do not provide functional advantages in games, but, nevertheless, they play an important role in the overall player experience. Possessing predominantly socially-constructed dimensions of value, cosmetic items are chosen, discussed, assessed, and valuated in an ongoing iterative collaborative process by communities of players. In our study, we explore the case of Dota 2 and apply Topic Modeling to community-discussions data gathered from Reddit.com. We describe social experiences related to the valuation of cosmetic items in interaction and collision of various logics, including artificial scarcity, decomposition of visual effects, and connectedness to the game lore. Our findings connect the collective experience of players in the game and on online community platforms, suggesting that non-utility-based social value construction becomes an important part of game experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2054–2058},
numpages = {5},
keywords = {games/play, virtual goods, decorative items, cosmetic items, social media/online communities},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025944,
author = {Ghosh, Sanjay and Joshi, Anirudha and Joshi, Manjiri and Emmadi, Nagraj and Dalvi, Girish and Ahire, Shashank and Rangale, Swati},
title = {Shift+Tap or Tap+LongPress? The Upper Bound of Typing Speed on InScript},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025944},
doi = {10.1145/3025453.3025944},
abstract = {This paper presents the results of a within-subject longitudinal evaluation on Inscript keyboard, which is the national standard layout for Indian scripts. We studied the practical upper bound speed and accuracy as well as the effect of practice. Through longitudinal transcription task of 400 repeated attempts, we observed typing speeds for highly experienced users consistently peak close to 120 cpm i.e. 2.5 times that of fastest speeds reported in literature. Our analysis compared the lower bound times for Tap, Tap+LongPress and Shift+Tap, the three text input mechanisms in this keyboard. Among the two alternative methods, our findings established Tap+LongPress method to be faster than Shift+Tap method and almost equally accurate. Also, we derived a model which explains the influence of corrected errors and number of practice attempts on the typing speed.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2059–2063},
numpages = {5},
keywords = {virtual keyboards, error analysis, performance modelling, text input in indian language},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025658,
author = {Salovaara, Antti and Oulasvirta, Antti and Jacucci, Giulio},
title = {Evaluation of Prototypes and the Problem of Possible Futures},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025658},
doi = {10.1145/3025453.3025658},
abstract = {There is a blind spot in HCI's evaluation methodology: we rarely consider the implications of the fact that a prototype can never be fully evaluated in a study. A prototype under study exists firmly in the present world, in the circumstances created in the study, but its real context of use is a partially unknown future state of affairs. This present-future gap is implicit in any evaluation of prototypes, be they usability tests, controlled experiments, or field trials. A carelessly designed evaluation may inadvertently evaluate the wrong futures, contexts, or user groups, thereby leading to false conclusions and expensive design failures. The essay analyses evaluation methodology from this perspective, illuminating how to mitigate the present-future gap.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2064–2077},
numpages = {14},
keywords = {field trials, experiments, prototypes, evaluation methodology, future, usability studies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025696,
author = {Chen, Ko-Le and Clarke, Rachel and Almeida, Teresa and Wood, Matthew and Kirk, David S.},
title = {Situated Dissemination through an HCI Workplace},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025696},
doi = {10.1145/3025453.3025696},
abstract = {Researchers working in domains such as Research through Design and Feminist HCI have been questioning "dissemination practices" and their impact on our capacity to produce reflexive accounts of research in publications. This paper examines academic dissemination practices within HCI research communities from an institutional to individual level. We unpack the practice via a meta-review of recent literature published in CHI and other venues on 'What is HCI?'. We review the core text on this debate and other similar discussions on HCI methodologies and reflexive accounts of research in domains such as 'Research through Design' and 'Feminist HCI'. We highlight the importance of practicing reflexivity through dissemination and introduce 'Research Fictions' in the form of video essays and live performances, produced by the first author with her colleagues, based on their HCI submissions. Through experimenting with alternative dissemination formats, we argue that our exploratory processes engender a practice of reflexivity within a research lab.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2078–2090},
numpages = {13},
keywords = {situated dissemination, research fiction, research through design, reflexivity, feminist hci},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026022,
author = {Velt, Raphael and Benford, Steve and Reeves, Stuart},
title = {A Survey of the Trajectories Conceptual Framework: Investigating Theory Use in HCI},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026022},
doi = {10.1145/3025453.3026022},
abstract = {We present a case study of how Human-Computer Interaction (HCI) theory is reused within the field. We analyze the HCI literature in order to reveal the impact of one particular theory, the trajectories framework that has been cited as an example of both contemporary HCI theory and a strong concept that sits between theory and design practice. Our analysis of 60 papers that seriously engaged with trajectories reveals the purposes that the framework served and which parts of it they used. We compare our findings to the originally stated goals of trajectories and to subsequent claims of its status as both theory and strong concept. The results shed new light on what we mean by theory in HCI, including its relationship to practice and to other disciplines.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2091–2105},
numpages = {15},
keywords = {theory, trajectories, hci, strong concepts},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025498,
author = {Yamaoka, Junichi and Kakehi, Yasuaki},
title = {ProtoMold: An Interactive Vacuum Forming System for Rapid Prototyping},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025498},
doi = {10.1145/3025453.3025498},
abstract = {In this paper, we propose a novel fabrication machine called ProtoMold, which uses interactive vacuum forming system for rapid prototyping. ProtoMold combines a dynamical shape-changing surface that consists of 12 \texttimes{} 8 linear actuators and a vacuum forming system. According to the shape of the surface, this system can mold various 2.5 dimensional objects quickly. Another characteristic of this system is that users can reuse molded objects and change their design; by applying tension and heat to a molded object, the object becomes flat and can be molded again. We also designed user several interaction methods for manipulating ProtoMold. In addition to loading predesigned data, the user can control the shape of the pin display directly using gesture input or physical objects.We propose several use scenarios for ProtoMold: changing the design of a plate based on objects placed on it, fabricating a facemask with a printed texture, and fabricating electrical devices with printed electronic circuits. By using this system, we conducted a user test and discuss the known limitations and potential applications of our system.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2106–2115},
numpages = {10},
keywords = {design methods, prototyping, interactive fabrication},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025937,
author = {Hsu, Chen-Yu and Liu, Yuchen and Kabelac, Zachary and Hristov, Rumen and Katabi, Dina and Liu, Christine},
title = {Extracting Gait Velocity and Stride Length from Surrounding Radio Signals},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025937},
doi = {10.1145/3025453.3025937},
abstract = {Gait velocity and stride length are critical health indicators for older adults. A decade of medical research shows that they provide a predictor of future falls, hospitalization, and functional decline among seniors. However, currently these metrics are measured only occasionally during medical visits. Such infrequent measurements hamper the opportunity to detect changes and intervene early in the impairment process.In this paper, we develop a sensor that uses radio signals to continuously measure gait velocity and stride length at home. Our sensor hangs on a wall like a picture frame. It does not require the monitored person to wear or carry a device on her body. Our approach builds on recent advances in wireless systems which have shown that one can locate people based on how their bodies impact the surrounding radio signals. We demonstrate the accuracy of our method by comparing it to the gold standard in clinical tests, and the VICON motion tracking system. Our experience from deploying the sensor in 14 homes indicates comfort with the technology and a high acceptance rate.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2116–2126},
numpages = {11},
keywords = {wireless sensing, stride length, continuous monitoring, gait velocity, device-free sensing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026003,
author = {Jansen, Arne and Van Mechelen, Maarten and Slegers, Karin},
title = {Personas and Behavioral Theories: A Case Study Using Self-Determination Theory to Construct Overweight Personas},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026003},
doi = {10.1145/3025453.3026003},
abstract = {Personas are a widely used tool to keep real users in mind, while avoiding stereotypical thinking in the design process. Yet, creating personas can be challenging. Starting from Cooper's approach for constructing personas, this paper details how behavioral theory can contribute substantially to the development of personas. We describe a case study in which Self-Determination Theory (SDT) is used to develop five distinctive personas for the design of a digital coach for sustainable weight loss. We show how behavioral theories such as SDT can help to understand what genuinely drives and motivates users to sustainably change their behavior. In our study, we used SDT to prepare and analyze interviews with envisioned users of the coach and to create complex, yet engaging and highly realistic personas that make users' basic psychological needs explicit. The paper ends with a critical reflection on the use of behavioral theories to create personas, discussing both challenges and strengths.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2127–2136},
numpages = {10},
keywords = {personas, self-determination theory, behavioral theories, design methods, obesity},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025904,
author = {Hornof, Anthony and Whitman, Haley and Sutherland, Marah and Gerendasy, Samuel and McGrenere, Joanna},
title = {Designing for the "Universe of One": Personalized Interactive Media Systems for People with the Severe Cognitive Impairment Associated with Rett Syndrome},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025904},
doi = {10.1145/3025453.3025904},
abstract = {The needs and capabilities of a person with severe disabilities are often so specific that designing for the person is like designing for a "universe of one." This project addresses this problem for women with Rett syndrome, a disorder accompanied by severe cognitive, communication, and motor impairment. The research team adapted participatory design techniques to work with five such women, and their families, to design and evaluate new assistive technology for these women. The process suggests a class of media-playing devices that would be generally useful to women with Rett syndrome: systems that can load multiple audio or video segments; be activated by many different switches; and respond instantly to switch-hits. As well, the systems should permit a caregiver to set the start and end time of each segment, and how the system advances through a sequence of segments. The paper also discusses patterns that were observed when collaborating with the families. For example, parents shared longstanding but untried ideas for new assistive technology; and expressed a strong interest in any device that would help their daughters do things for themselves.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2137–2148},
numpages = {12},
keywords = {assistive technology, intellectual disability, user training, user-centered design, participatory design, rett syndrome, severe cognitive impairment, user observation studies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025586,
author = {Lazar, Amanda and Edasis, Caroline and Piper, Anne Marie},
title = {Supporting People with Dementia in Digital Social Sharing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025586},
doi = {10.1145/3025453.3025586},
abstract = {Sharing online is an important way in which people across the lifespan express themselves, maintain relationships, and connect with others. Yet, people with dementia are often not supported in engaging to the full extent of their abilities, particularly in their interaction with online technology. This paper presents a design case study that examines what it means to design for agency in online sharing involving individuals with dementia. Our work is situated in the context of art therapy for adults with dementia. We present the design and exploration of Moments, a system that allows individuals to share through artwork by manipulating their physical environment. We discuss how designing for agency calls attention to the ways in which the material workspace, including the tools we introduce, and the surrounding social context participate in the creation of agency.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2149–2162},
numpages = {14},
keywords = {agency, dementia, art therapy, sharing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025732,
author = {Morrissey, Kellie and Garbett, Andrew and Wright, Peter and Olivier, Patrick and Jenkins, Edward Ian and Brittain, Katie},
title = {Care and Connect: Exploring Dementia-Friendliness Through an Online Community Commissioning Platform},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025732},
doi = {10.1145/3025453.3025732},
abstract = {In this paper, we present "Care and Connect", a mobile application created through the App Movement platform that aims to identify and rate public places (e.g., parks, shops, cafes) on their 'dementia-friendliness' - their suitability for people with dementia and their carers. Care and Connect saw significant support in its early stages on the online platform, yet failed to engage participants in its design phase and deployment. To unpick this, we contribute an account of its initial use in the community, and then describe findings from research engagements with carers and people with dementia. These workshops used Care and Connect to structure discussions of participants' own experiences of dementia-friendliness, and uncovered themes of 1) trust, 2) exclusion versus inclusion, 3) duration and quality of time, and 4) empathy becoming action. Using this evidence, we advance an account of online community commissioning as a process which needs to understand not only the general issues ongoing in communities facing significant life challenges, but also the particularity of community members' experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2163–2174},
numpages = {12},
keywords = {dementia care, community information systems, dementia, mobile applications, community commissioning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025522,
author = {Lazar, Amanda and Edasis, Caroline and Piper, Anne Marie},
title = {A Critical Lens on Dementia and Design in HCI},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025522},
doi = {10.1145/3025453.3025522},
abstract = {Designing new technologies with and for individuals with dementia is a growing topic of interest within HCI. Yet, predominant societal views contribute to the positioning of individuals with dementia as deficient and declining, and treat technology as filling a gap left by impairment. We present the perspective of critical dementia as a way of reflecting on these views in the context of recent epistemological shifts in HCI. In addition to articulating how HCI can leverage the perspective of critical dementia, we present a case analysis of technology design in art therapy involving people with dementia aimed at challenging conventional narratives. This paper calls attention to and helps solidify an agenda for how the CHI community approaches dementia, design, and technology.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2175–2188},
numpages = {14},
keywords = {theory, disability, dementia, paradigm, design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025875,
author = {Matthews, Tara and O'Leary, Kathleen and Turner, Anna and Sleeper, Manya and Woelfer, Jill Palzkill and Shelton, Martin and Manthorne, Cori and Churchill, Elizabeth F. and Consolvo, Sunny},
title = {Stories from Survivors: Privacy &amp; Security Practices When Coping with Intimate Partner Abuse},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025875},
doi = {10.1145/3025453.3025875},
abstract = {We present a qualitative study of the digital privacy and security motivations, practices, and challenges of survivors of intimate partner abuse (IPA). This paper provides a framework for organizing survivors' technology practices and challenges into three phases: physical control, escape, and life apart. This three-phase framework combines technology practices with three phases of abuse to provide an empirically sound method for technology creators to consider how survivors of IPA can leverage new and existing technologies. Overall, our results suggest that the usability of and control over privacy and security functions should be or continue to be high priorities for technology creators seeking ways to better support survivors of IPA.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2189–2201},
numpages = {13},
keywords = {privacy, intimate partner abuse, user study, domestic violence, security},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025926,
author = {Sawaya, Yukiko and Sharif, Mahmood and Christin, Nicolas and Kubota, Ayumu and Nakarai, Akihiro and Yamada, Akira},
title = {Self-Confidence Trumps Knowledge: A Cross-Cultural Study of Security Behavior},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025926},
doi = {10.1145/3025453.3025926},
abstract = {Computer security tools usually provide universal solutions without taking user characteristics (origin, income level, ...) into account. In this paper, we test the validity of using such universal security defenses, with a particular focus on culture. We apply the previously proposed Security Behavior Intentions Scale (SeBIS) to 3,500 participants from seven countries. We first translate the scale into seven languages while preserving its reliability and structure validity. We then build a regression model to study which factors affect participants' security behavior. We find that participants from different countries exhibit different behavior. For instance, participants from Asian countries, and especially Japan, tend to exhibit less secure behavior. Surprisingly to us, we also find that actual knowledge influences user behavior much less than user self-confidence in their computer security knowledge. Stated differently, what people think they know affects their security behavior more than what they do know.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2202–2214},
numpages = {13},
keywords = {computer security, cross-cultural study},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025896,
author = {Vance, Anthony and Kirwan, Brock and Bjornn, Daniel and Jenkins, Jeffrey and Anderson, Bonnie Brinton},
title = {What Do We Really Know about How Habituation to Warnings Occurs Over Time? A Longitudinal FMRI Study of Habituation and Polymorphic Warnings},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025896},
doi = {10.1145/3025453.3025896},
abstract = {A major inhibitor of the effectiveness of security warnings is habituation: decreased response to a repeated warning. Although habituation develops over time, previous studies have examined habituation and possible solutions to its effects only within a single experimental session, providing an incomplete view of the problem. To address this gap, we conducted a longitudinal experiment that examines how habituation develops over the course of a five-day workweek and how polymorphic warnings decrease habituation. We measured habituation using two complementary methods simultaneously: functional magnetic resonance imaging (fMRI) and eye tracking.Our results show a dramatic drop in attention throughout the workweek despite partial recovery between workdays. We also found that the polymorphic warning design was substantially more resistant to habituation compared to conventional warnings, and it sustained this advantage throughout the five-day experiment. Our findings add credibility to prior studies by showing that the pattern of habituation holds across a workweek, and indicate that cross-sectional habituation studies are valid proxies for longitudinal studies. Our findings also show that eye tracking is a valid measure of the mental process of habituation to warnings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2215–2227},
numpages = {13},
keywords = {security warnings, longitudinal experiment, eye tracking, functional magnetic resonance imaging (fmri), polymorphic warnings, habituation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025911,
author = {Wash, Rick and Rader, Emilee and Fennell, Chris},
title = {Can People Self-Report Security Accurately? Agreement Between Self-Report and Behavioral Measures},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025911},
doi = {10.1145/3025453.3025911},
abstract = {It is common for researchers to use self-report measures (e.g. surveys) to measure people's security behaviors. In the computer security community, we don't know what behaviors people understand well enough to self-report accurately, or how well those self-reports correlate with what people actually do. In a six week field study, we collected both behavior data and survey responses from 122 subjects. We found that a relatively small number of behaviors -- mostly related to tasks that require users to take a specific, regular action -- have non-zero correlations. Since security is almost never a user's primary task for everyday computer users, several important security behaviors that we directly measured were not self-reported accurately. These results suggest that security research based on self-report is only reliable for certain behaviors. Additionally, a number of important security behaviors are not sufficiently salient to users that they can self-report accurately.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2228–2232},
numpages = {5},
keywords = {security, self-report, intentions},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025856,
author = {Singh, Vivek K. and Jain, Arushi},
title = {Toward Harmonizing Self-Reported and Logged Social Data for Understanding Human Behavior},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025856},
doi = {10.1145/3025453.3025856},
abstract = {While self-reporting remains the most common method to understand human behavior, recent advances in social networks, mobile technologies, and other computer-mediated communication technologies are allowing researchers to obtain detailed logs of human behavior with ease. While the logged data is very useful (and accurate) at capturing the structure of the user's social network, the self-reported data provides an insight into the user's cognitive map of her social network. Based on a field study involving 47 users for a period of ten weeks we report that combining the two sets of data (self-reported and logged) gives higher predictive power than using either one of them individually. Further, the difference between the two types of values captures the level of dissonance between a user's actual and perceived social behavior and is found to be an important predictor of the person's social outcomes including social capital, social support and trust.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2233–2238},
numpages = {6},
keywords = {social ties, bias, self-reported, dissonance coefficient, socio-mobile behavior, call-log data},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025758,
author = {Hassib, Mariam and Buschek, Daniel and Wozniak, Pawe\l{} W. and Alt, Florian},
title = {HeartChat: Heart Rate Augmented Mobile Chat to Support Empathy and Awareness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025758},
doi = {10.1145/3025453.3025758},
abstract = {Textual communication via mobile phones suffers from a lack of context and emotional awareness. We present a mobile chat application, HeartChat, which integrates heart rate as a cue to increase awareness and empathy. Through a literature review and a focus group, we identified design dimensions important for heart rate augmented chats. We created three concepts showing heart rate per message, in real-time, or sending it explicitly. We tested our system in a two week in-the-wild study with 14 participants (7 pairs). Interviews and questionnaires showed that HeartChat supports empathy between people, in particular close friends and partners. Sharing heart rate helped them to implicitly understand each other's context (e.g. location, physical activity) and emotional state, and sparked curiosity on special occasions. We discuss opportunities, challenges, and design implications for enriching mobile chats with physiological sensing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2239–2251},
numpages = {13},
keywords = {heart rate, instant messagingg, physiological sensing, affective computing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025833,
author = {Feltwell, Tom and Wood, Gavin and Long, Kiel and Brooker, Phillip and Schofield, Tom and Petridis, Ioannis and Barnett, Julie and Vines, John and Lawson, Shaun},
title = {"I've Been Manipulated!": Designing Second Screen Experiences for Critical Viewing of Reality TV},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025833},
doi = {10.1145/3025453.3025833},
abstract = {The recent proliferation of a reality TV genre that focusses on welfare recipients has led to concerns that prime-time media experiences are exacerbating misconceptions, and stifling critical debate, around major societal issues such as welfare reform and poverty. Motivated by arguments that 'second screening' practices offer opportunities to engage viewers with issues of political concern, we describe the design and evaluation of two smartphone apps that facilitate and promote more critical live-viewing of reality TV. Our apps, Spotting Guide and Moral Compass, encourage users to identify, categorise, tag and filter patterns and tropes within reality TV, as well as reinterpret social media posts associated with their broadcast. We show that such interactions encourage critical thinking around typical editing and production techniques and foster co-discussion and reflection amongst viewers. We discuss, more broadly, how these interactions encourage users to identify the wider consequences and framings of reality TV, and offer implications and considerations for design that provokes criticality and reflection in second screening contexts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2252–2263},
numpages = {12},
keywords = {tv, second screening, welfare, politics, social media},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025459,
author = {Dowell, John and Anstead, Edward},
title = {Interaction with a TV Companion App as Synopsis and Supplement},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025459},
doi = {10.1145/3025453.3025459},
abstract = {Television companion apps on tablets and smartphones provide interactive content synchronized with TV shows. A key design question raised by this novel, multi-display, multimedia interface is whether the app's role is to be a synopsis of the show or a supplement. In other words, should the app help viewers better follow what they are watching on TV, or offer additional enriching content to respond to interest created by the show? We developed a companion app for a documentary with both synoptic and supplementary content. A laboratory study with 28 participants examined the effect of these different types of content on the experience of using the companion and the effect on engagement with the show in terms of participants' recall. Engagement with the show was not affected by supplementary content in the app but coordinated viewing of both screens was more difficult. Design guidelines evident from these results are discussed.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2264–2268},
numpages = {5},
keywords = {second screen, television, companion apps, engagement, mobile devices},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025611,
author = {Gorkovenko, Katerina and Taylor, Nick and Rogers, Jon},
title = {Social Printers: A Physical Social Network for Political Debates},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025611},
doi = {10.1145/3025453.3025611},
abstract = {Social Printers are physical devices that create a pseudonymous social network between households during televised political debates. Through studies conducted around the Scottish Parliamentary Election and EU Referendum in 2016, we aimed to understand how physical devices could be used to engage viewers with televised political debates. By displacing the interaction from conventional social media and second screens we observed that the printers were successful in encouraging the participants to share their thoughts and create a personal social experience. Based on the results we discuss potential implications for conventional social media and second screens in the context of political television programs.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2269–2281},
numpages = {13},
keywords = {television, second screens, research products, political discourse, politics, social media.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025915,
author = {Balestrini, Mara and Rogers, Yvonne and Hassan, Carolyn and Creus, Javi and King, Martha and Marshall, Paul},
title = {A City in Common: A Framework to Orchestrate Large-Scale Citizen Engagement around Urban Issues},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025915},
doi = {10.1145/3025453.3025915},
abstract = {Citizen sensing is an approach that develops and uses lightweight technologies with local communities to collect, share and act upon data. In doing so it enables them to become more aware of how they can tackle local issues. We report here on the development and uptake of the 'City- Commons Framework for Citizen Sensing', a conceptual model that builds on Participatory Action Research with the aim of playing an integrating role: outlining the processes and mechanisms for ensuring sensing technologies are co-designed by citizens to address their concerns. At the heart of the framework is the idea of a city commons: a pool of community-managed resources. We discuss how the framework was used by communities in Bristol to measure and monitor the problem of damp housing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2282–2294},
numpages = {13},
keywords = {methods, smart cities, framework, citizen engagement, publics, commons, citizen sensing, open data},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025963,
author = {Asad, Mariam and Le Dantec, Christopher A. and Nielsen, Becky and Diedrick, Kate},
title = {Creating a Sociotechnical API: Designing City-Scale Community Engagement},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025963},
doi = {10.1145/3025453.3025963},
abstract = {Community engagement is to cities what user experience is to computing: it signifies a large category that simultaneously speaks to general qualities of interaction and to specific ways of doing that interaction. Recently, digital civics has emerged as a research area with a comprehensive approach to designing for civic encounters where community engagement is a primary concern for designing systems and processes that support broad civic interaction. In short, over the past year, we worked with municipal officials, service providers, and city residents to design a community engagement playbook detailing best practices for city-scale engagement. The playbook, as well as the collaborative process that produced it, provides a roadmap for thinking through the kinds of systems that might populate the design space of city-scale digital civics. This paper details our design-led research process and builds on emerging literature on designing for digital civic interaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2295–2306},
numpages = {12},
keywords = {digital civics, participatory design, publics, community engagement},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025996,
author = {Erete, Sheena and Burrell, Jennifer O.},
title = {Empowered Participation: How Citizens Use Technology in Local Governance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025996},
doi = {10.1145/3025453.3025996},
abstract = {The partnership between local residents and city officials to inform policy and decision-making about government resources, or participatory governance, has been extensively studied. In addition to numerous ethnographic studies about how citizens engage in-person, there has been increased focus in HCI to understand the impact of technology on citizen participation in local governance. Building upon those studies, this paper provides unique insight from a 3-year longitudinal study on the use of online tools that were organically adapted by citizens to engage in local governance in three diverse Chicago neighborhoods. Though the responsiveness of government officials varied across communities, our results suggest that citizens use technology to heighten the visibility of their concerns, to support mechanisms of government accountability, and to provide various options for resident participation in local governance. We argue that while communities may be effective in their use of ICTs, technology may not increase their political power.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2307–2319},
numpages = {13},
keywords = {participatory governance, low income, civic engagement},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025559,
author = {Johnson, Ian G. and MacDonald, Alistair and Briggs, Jo and Manuel, Jennifer and Salt, Karen and Flynn, Emma and Vines, John},
title = {Community Conversational: Supporting and Capturing Deliberative Talk in Local Consultation Processes},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025559},
doi = {10.1145/3025453.3025559},
abstract = {The development of platforms for community decision-making has been of growing interest to the HCI community, yet the ways technology might be woven into traditional consultation processes has been under-studied. We conducted fieldwork at consultation events where residents were invited to discuss and map assets related to their neighbourhoods to inform community decision-making. The fieldwork highlighted problems with equality, turn taking, the evidencing and elaborating on opinions by residents, and challenges related to capturing and documenting the events. We developed Community Conversational-a hybrid table-top game and digital capture and review platform-in response to these issues. Community Conversational was designed to provide a flexible structure to consultation events related to 'place', and support the production, capture and review of deliberative 'talk' to support decision-making. We study how the platform was used in two consultation events, and discuss the implications of capturing and evidencing local people's opinions for the accountability of decision-makers and community organisations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2320–2333},
numpages = {14},
keywords = {civic technology, deliberation, consultation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026044,
author = {Chang, Joseph Chee and Amershi, Saleema and Kamar, Ece},
title = {Revolt: Collaborative Crowdsourcing for Labeling Machine Learning Datasets},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026044},
doi = {10.1145/3025453.3026044},
abstract = {Crowdsourcing provides a scalable and efficient way to construct labeled datasets for training machine learning systems. However, creating comprehensive label guidelines for crowdworkers is often prohibitive even for seemingly simple concepts. Incomplete or ambiguous label guidelines can then result in differing interpretations of concepts and inconsistent labels. Existing approaches for improving label quality, such as worker screening or detection of poor work, are ineffective for this problem and can lead to rejection of honest work and a missed opportunity to capture rich interpretations about data. We introduce Revolt, a collaborative approach that brings ideas from expert annotation workflows to crowd-based labeling. Revolt eliminates the burden of creating detailed label guidelines by harnessing crowd disagreements to identify ambiguous concepts and create rich structures (groups of semantically related items) for post-hoc label decisions. Experiments comparing Revolt to traditional crowdsourced labeling show that Revolt produces high quality labels without requiring label guidelines in turn for an increase in monetary cost. This up front cost, however, is mitigated by Revolt's ability to produce reusable structures that can accommodate a variety of label boundaries without requiring new data to be collected. Further comparisons of Revolt's collaborative and non-collaborative variants show that collaboration reaches higher label accuracy with lower monetary cost.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2334–2346},
numpages = {13},
keywords = {crowdsourcing, real-time, collaboration, machine learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026025,
author = {Barowy, Daniel W. and Berger, Emery D. and Goldstein, Daniel G. and Suri, Siddharth},
title = {VoxPL: Programming with the Wisdom of the Crowd},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026025},
doi = {10.1145/3025453.3026025},
abstract = {Having a crowd estimate a numeric value is the original inspiration for the notion of "the wisdom of the crowd." Quality control for such estimated values is challenging because prior, consensus-based approaches for quality control in labeling tasks are not applicable in estimation tasks. We present VoxPL, a high-level programming framework that automatically obtains high-quality crowdsourced estimates of values. The VoxPL domain-specific language lets programmers concisely specify complex estimation tasks with a desired level of confidence and budget. VoxPL's runtime system implements a novel quality control algorithm that automatically computes sample sizes and obtains high quality estimates from the crowd at low cost. To evaluate VoxPL, we implement four estimation applications, ranging from facial feature recognition to calorie counting. The resulting programs are concise---under 200 lines of code---and obtain high quality estimates from the crowd quickly and inexpensively.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2347–2358},
numpages = {12},
keywords = {crowdsourcing, domain-specific languages, wisdom of the crowd, quality control, scalability, crowdprogramming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025551,
author = {Curmi, Franco and Ferrario, Maria Angela and Whittle, Jon},
title = {Embedding a Crowd inside a Relay Baton: A Case Study in a Non-Competitive Sporting Activity},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025551},
doi = {10.1145/3025453.3025551},
abstract = {This paper presents a digital relay baton that connects long-distance runners with distributed online spectators. The baton broadcasts athletes? live locative data to a social network and communicates back remote-crowd support through haptic and audible cheers. Our work takes an exploratory design approach to bring new insights into the design of real-time techno-mediated social support. The prototype was deployed during a 170-mile charity relay race across the UK with 13 participants, 261 on-line supporters, and gathered a total of 3,153 'cheers'. We report on the insights collected during the design and deployment process and identify three fundamental design considerations: the degree of spectator expression that the design affords, the context applicability, and the data flow within the social network.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2359–2370},
numpages = {12},
keywords = {social support, cheering, sports, relay race, social networks, broadcast, spectators, relay baton},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025647,
author = {Gonzales, Amy and Fritz, Nicole},
title = {Prioritizing Flexibility and Intangibles: Medical Crowdfunding for Stigmatized Individuals},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025647},
doi = {10.1145/3025453.3025647},
abstract = {HCI research on crowdfunding has primarily focused on creative or organizational endeavors. Yet a majority of crowdfunding campaigns are conducted by individuals in need, often for healthcare. To better understand and improve this common crowdfunding experience, especially for those that inhabit a vulnerable social status, we conducted 20 interviews with transmen crowdfunding for top-surgery. Design choices that optimize site flexibility (e.g. control of personal information; enable cross-site communication) and foreground intangibles, such as political values and emotional support, are priorities for individuals from a stigmatized community. Findings differed from previous crowdfunding research and contribute to limited research on transgender identities in HCI. Overall they provide unique insights into how design choices can facilitate marginalized identity management in highly public online spaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2371–2375},
numpages = {5},
keywords = {vulnerable populations, identity, transmen, crowdfunding, healthcare, privacy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025763,
author = {Dey, Sanorita and Karahalios, Karrie and Fu, Wai-Tat},
title = {Understanding the Effects of Endorsements in Scientific Crowdfunding},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025763},
doi = {10.1145/3025453.3025763},
abstract = {Understanding the factors that persuade backers to donate to research projects has become increasingly important with the rising popularity of scientific crowdfunding. Although there are many similarities between enterprise and scientific crowdfunding, some factors differentiate these two forms of crowdfunding. One such factor is the use of endorsements. The endorsement helps backers gain trust based on expert opinions about the competency of the researchers and the usefulness of the projects. We analyzed 810 endorsements from scientific campaigns posted on Experiment.com and derived a taxonomy of topics discussed in the endorsements. A regression analysis revealed that when endorsers explained the skills of the campaign owners, the probability of success of the campaign improved; on the contrary, when endorsers reiterated the goal of the project, the campaign was less likely to succeed. We conclude with design implications formulated from our findings to better support scientific crowdfunding.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2376–2381},
numpages = {6},
keywords = {crowdfunding, endorsement, scientific crowdfunding},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025780,
author = {Cranshaw, Justin and Elwany, Emad and Newman, Todd and Kocielnik, Rafal and Yu, Bowen and Soni, Sandeep and Teevan, Jaime and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {Calendar.Help: Designing a Workflow-Based Scheduling Agent with Humans in the Loop},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025780},
doi = {10.1145/3025453.3025780},
abstract = {Although we may complain about meetings, they are an essential part of an information worker's work life. Consequently, busy people spend a significant amount of time scheduling meetings. We present Calendar.help, a system that provides fast, efficient scheduling through structured workflows. Users interact with the system via email, delegating their scheduling needs to the system as if it were a human personal assistant. Common scheduling scenarios are broken down using well-defined workflows and completed as a series of microtasks that are automated when possible and executed by a human otherwise. Unusual scenarios fall back to a trained human assistant executing an unstructured macrotask. We describe the iterative approach we used to develop Calendar.help, and share the lessons learned from scheduling thousands of meetings during a year of real-world deployments. Our findings provide insight into how complex information tasks can be broken down into repeatable components that can be executed efficiently to improve productivity.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2382–2393},
numpages = {12},
keywords = {microtask, assistant, macrotask, crowdsourcing, scheduling, conversational agent},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025621,
author = {Miller, Matthew K. and Tang, John C. and Venolia, Gina and Wilkinson, Gerard and Inkpen, Kori},
title = {Conversational Chat Circles: Being All Here Without Having to Hear It All},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025621},
doi = {10.1145/3025453.3025621},
abstract = {Live streaming services are a growing form of social media. Most live streaming platforms allow viewers to communicate with each other and the broadcaster via a text chat. However, interaction in a text chat does not work well with too many users. Existing techniques to make text chat work with a larger number of participants often limit who can participate or how much users can participate. In this paper, we describe a new design for a text chat system that allows more people to participate without overwhelming users with too many messages. Our design strategically limits the number of messages a user sees based on the concept of neighborhoods, and emphasizes important messages through upvoting. We present a study comparing our system to a chat system similar to those found in commercial streaming services. Results of the study indicate that the Conversational Circle system is easier to understand and interact with, while supporting community among viewers and highlighting important content for the streamer.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2394–2404},
numpages = {11},
keywords = {text chat, live streaming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025700,
author = {Fong, Allan and Hettinger, A. Zachary and Ratwani, Raj M.},
title = {A Predictive Model of Emergency Physician Task Resumption Following Interruptions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025700},
doi = {10.1145/3025453.3025700},
abstract = {Interruptions in the emergency department (ED) can have serious patient safety consequences, and few solutions exist to mitigate the disruptiveness of interruptions. We developed a theoretically motivated model to predict the likelihood of emergency physicians returning to an interrupted task. Eighteen emergency physicians were observed individually for two-hour blocks of time, resulting in a total of 2160 minutes of observation and 231 interruptions. We used a mixed effects logistic regression model to predict the likelihood of primary task resumption after interruptions. The likelihood of primary task resumption was predicted by memory decay, measured by the duration of the interruption, workload, measured by the patient volume during the shift, and whether shift was day or night. With a better understanding of these interruptions, we can help design interventions to manage interruptions, minimize medical errors, and improve patient safety.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2405–2410},
numpages = {6},
keywords = {predictive modeling, emergency department, patient safety, logistic mixed-effects model, task resumption, interruption},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025552,
author = {Xiao, Xiang and Wang, Jingtao},
title = {Undertanding and Detecting Divided Attention in Mobile MOOC Learning},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025552},
doi = {10.1145/3025453.3025552},
abstract = {The emergence of mobile apps for Massive Open Online Courses (MOOCs) allows learners to access quality learning materials at low cost and "to control where, what, how and with whom they learn". Unfortunately, when compared with traditional classroom education, learners face more distractions and are more likely to multitask when they study alone in an informal learning environment. In this paper, we investigate the impact of divided attention (DA) on both the learning process and learning outcomes in the context of mobile MOOC learning. We propose OneMind, a system and algorithm for detecting divided attention on unmodified mobile phones via implicit, camera-based heart rate tracking. In an 18-participant study, we found that internal divided attention has a significant negative impact on learning outcomes; and that the photoplethysmography (PPG) waveforms implicitly captured by OneMind can be used to detect the presence, type, and intensity of divided attention in mobile MOOC learning.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2411–2415},
numpages = {5},
keywords = {divided attention, ppg, mobile interfaces, mooc},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025971,
author = {Jung, Jingun and Youn, Eunhye and Lee, Geehyuk},
title = {PinPad: Touchpad Interaction with Fast and High-Resolution Tactile Output},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025971},
doi = {10.1145/3025453.3025971},
abstract = {We explored new interaction scenarios that can be realized when a touchpad outputs fast and high-resolution spatio-temporal tactile patterns to the touch-sensitive skin on the fingertips of a user. We first constructed a special tactile multi-touch touchpad called PinPad, which was capable of outputting fast and high-resolution tactile patterns using a 40 x 25 array of actuated pins. We then developed various interaction scenarios that could be realized using the prototype: 1) Tactile Target, 2) Guide and Constraint, 3) Multi-finger Output, and 4) Dynamic Partition. To evaluate the PinPad scenarios, we implemented demo applications, and conducted interviews with users to collect feedback about their experiences with PinPad and the PinPad scenarios. The participants confirmed the effectiveness of spatio-temporal outputs of PinPad in the scenarios. In particular, they provided diverse feedback regarding the unique tactile experiences of the fast and high-resolution outputs of PinPad.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2416–2425},
numpages = {10},
keywords = {pinpad, tactile touchpad interaction, fast and high-resolution tactile output},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025457,
author = {Cornelio Martinez, Patricia Ivette and De Pirro, Silvana and Vi, Chi Thanh and Subramanian, Sriram},
title = {Agency in Mid-Air Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025457},
doi = {10.1145/3025453.3025457},
abstract = {Touchless interfaces allow users to view, control and manipulate digital content without physically touching an interface. They are being explored in a wide range of application scenarios from medical surgery to car dashboard controllers. One aspect of touchless interaction that has not been explored to date is the Sense of Agency (SoA). The SoA refers to the subjective experience of voluntary control over actions in the external world. In this paper, we investigated the SoA in touchless systems using the intentional binding paradigm. We first compare touchless systems with physical interactions and then augmented different types of haptic feedback to explore how different outcome modalities influence intentional binding. From our experiments, we demonstrated that an intentional binding effect is observed in both physical and touchless interactions with no statistical difference. Additionally, we found that haptic and auditory feedback help to increase SoA compared with visual feedback in touchless interfaces. We discuss these findings and identify design opportunities that take agency into consideration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2426–2439},
numpages = {14},
keywords = {gestures, haptics, touchless interfaces, intentional binding, the sense of agency},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025655,
author = {Al Maimani, Ahmed and Roudaut, Anne},
title = {Frozen Suit: Designing a Changeable Stiffness Suit and Its Application to Haptic Games},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025655},
doi = {10.1145/3025453.3025655},
abstract = {We present the concept of Frozen Suit, a type of clothing that restricts users' movements at joint positions (e.g. elbow, knee) via a changeable stiffness jamming material. The suit can "freeze" users' body parts, for example during a game in order to provide the physical sensation of being frozen by an enemy. In this paper we first present the Frozen Suit concept and its potential applications. We then systematically investigate how to design jamming patches in order to sufficiently restrict an arm or a leg. In particular we used low-fidelity prototypes to explore the restricting power of different material and particles. In order to push this analysis further we conducted a controlled experiment in order to compare the perceived stiffness of different patches sizes attached to the elbow. We performed a paired comparison experience and used a Bradley-Terry-Luce model to analyze the subjective feedback from participants. We found that 20cm long x 7cm large is the most restrictive patch and that an increase in patch area correlates with an increase in perceived stiffness (quadratic). We finish by presenting a use case application with a game that we implemented where enemies can freeze the player.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2440–2448},
numpages = {9},
keywords = {haptic feedback, clothing, wearable, paired comparison experiment, changeable stiffness, jamming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025994,
author = {\"{O}zg\"{u}r, Ayberk and Johal, Wafa and Mondada, Francesco and Dillenbourg, Pierre},
title = {Haptic-Enabled Handheld Mobile Robots: Design and Analysis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025994},
doi = {10.1145/3025453.3025994},
abstract = {The Cellulo robots are small tangible robots that are designed to represent virtual interactive point-like objects that reside on a plane within carefully designed learning activities. In the context of these activities, our robots not only display autonomous motion and act as tangible interfaces, but are also usable as haptic devices in order to exploit, for instance, kinesthetic learning. In this article, we present the design and analysis of the haptic interaction module of the Cellulo robots. We first detail our hardware and controller design that is low-cost and versatile. Then, we describe the task-based experimental procedure to evaluate the robot's haptic abilities. We show that our robot is usable in most of the tested tasks and extract perceptive and manipulative guidelines for the design of haptic elements to be integrated in future learning activities. We conclude with limitations of the system and future work.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2449–2461},
numpages = {13},
keywords = {mobile robots, handheld robots, haptic interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025816,
author = {van Delden, Robby and Moreno, Alejandro and Poppe, Ronald and Reidsma, Dennis and Heylen, Dirk},
title = {A Thing of Beauty: Steering Behavior in an Interactive Playground},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025816},
doi = {10.1145/3025453.3025816},
abstract = {Interactive playgrounds are spaces where players engage in collocated, playful activities, in which added digital technology can be designed to promote cognitive, social, and motor skills development. To promote such development, different strategies can be used to implement game mechanics that change player's in-game behavior. One of such strategies is enticing players to take action through incentives akin to game achievements. We explored if this strategy could be used to influence players' proxemic behavior in the Interactive Tag Playground, an installation that enhances the traditional game of tag. We placed the ITP in an art gallery, observed hundreds of play sessions, and refined the mechanics, which consisted in projecting collectible particles around the tagger that upon collection by runners resulted only in the embellishment of their circles. We implemented the refined mechanics in a study with 48 children. The playground automatically collected the players' positions, and analyses show that runners got closer to and moved more towards taggers when using our enticing strategy. This suggests an enticing strategy can be used to influence physical in-game behavior.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2462–2472},
numpages = {11},
keywords = {entice, interactive floor, play, interactive playgrounds, proxemics, persuasion, social, steering behavior, augmented reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025746,
author = {Mueller, Florian 'Floyd' and Young, Damon},
title = {Five Lenses for Designing Exertion Experiences},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025746},
doi = {10.1145/3025453.3025746},
abstract = {The field of HCI has increasingly looked at ways to support the physically active human being, however, new work suggests that the field has only begun to understand the many virtues of exertion. To further the field, we present a set of five design lenses extended primarily from sports philosophy literature to help approach exertion not just as a means of deferring death, but also as an opportunity for personal growth. The lenses facilitate learning how to appreciate a void (Reverie), welcome pleasure (Pleasure), become humble (Humility), as well as be fearful and excited simultaneously (Sublime), whilst being more carefully aware of one's own body (Oneness). Using these lenses, we articulate associated technology opportunities through related work as well as our own craft knowledge. With our work, we aim to support designers who want to facilitate the many virtues of exertion so that ultimately more people profit from the many benefits of being physically active.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2473–2487},
numpages = {15},
keywords = {exergame, whole-body interaction, movement-based interaction, exertion games, sport, exertion interface},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025476,
author = {Park, Hyung Kun and Yi, HyeonBeom and Lee, Woohun},
title = {Recording and Sharing Non-Visible Information on Body Movement While Skateboarding},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025476},
doi = {10.1145/3025453.3025476},
abstract = {Knowing your own body movement is an essential element of sports. Recently, the popularization of smartphones has enabled people to easily record their performance in most situations. However, these observations have limited applicability in assisting with a clear understanding of body movement. In this paper, we propose the Motion Log Skateboard, which records and shares non-visible information about body movement that is difficult to obtain through current observation methods in skateboarding. A pressure-sensor matrix on a skateboard deck is used to record the pressure distribution data, which are then played using the video function of a smartphone camera. With this logged data, a user can access the feet positions, pressure intensity, and timing of the foot movements. To verify the proposed concept and determine the specific context of its use, an experimental session and interviews were conducted with skateboarders of various skill levels. Based on the results of this research, the shared experiences of non-visible information, which is perceived differently depending on the individual, are expected to become a standard for exploring and training body movement.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2488–2492},
numpages = {5},
keywords = {sports interaction, sports learning, body movement, representation, body perception, skateboarding},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025871,
author = {Paavilainen, Janne and Korhonen, Hannu and Alha, Kati and Stenros, Jaakko and Koskinen, Elina and Mayra, Frans},
title = {The Pok\'{e}Mon GO Experience: A Location-Based Augmented Reality Mobile Game Goes Mainstream},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025871},
doi = {10.1145/3025453.3025871},
abstract = {Pok\'{e}mon GO is a location-based augmented reality mobile game based on the Pok\'{e}mon franchise. After the game was launched globally in July 2016, it quickly became the most successful mobile game in both popularity and revenue generation at the time, and the first location-based augmented reality game to reach a mainstream status. We explore the game experiences through a qualitative survey (n=1000) in Finland focusing on the positive and the negative aspects of Pok\'{e}mon GO as told by the players. The positive experiences are related to movement, sociability, game mechanics, and brand while the negative experiences emerge from technical problems, unequal gaming opportunities, bad behavior of other players and non-players, and unpolished game design. Interestingly, the augmented reality features, safety issues or the free-to-play revenue model did not receive considerable feedback. The findings are useful for academics and industry practitioners for studying and designing location-based augmented reality game experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2493–2498},
numpages = {6},
keywords = {location-based, augmented reality, mobile game, Pokemon GO, game design, game experience, qualitative study, pervasive game},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025629,
author = {Britton, Lauren M. and Semaan, Bryan},
title = {Manifesting the Cyborg through Techno-Body Modification: From Human-Computer Interaction to Integration},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025629},
doi = {10.1145/3025453.3025629},
abstract = {A community of DIY cyborgs has emerged, known as 'grinders', who practice techno-body modification-the embedding of computing technology into the body. This paper reports on an ethnographic study following GrinderTech, an organization working to design, build and sell these technological artifacts, as it shifts from hacker collective to biotech startup. As technologies are embedded in the body, the boundary between human and machine starts to blur. We find that GrinderTech members, through the design and making of technologies for embedding, do so as a means to move beyond social and gendered binary constructions-or, societal norms that are practiced and performed, and re-enforced through language, as a way of creating power differentials in society, e.g. citizen/scientist and man/woman. Moreover, their motivations for designing and making these devices reflects their desire to re-imagine society. Finally, we re-conceptualize Human-Computer Interaction to include Integration-when technology is embedded in the human body-and discuss the theoretical and design implications of human-computer integration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2499–2510},
numpages = {12},
keywords = {cyborg, human computer integration, fsts},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025968,
author = {Hou, Youyang and Lampe, Cliff and Bulinski, Maximilian and Prescott, J.J.},
title = {Factors in Fairness and Emotion in Online Case Resolution Systems},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025968},
doi = {10.1145/3025453.3025968},
abstract = {Courts are increasingly adopting online information and communication technology, creating a need to consider the potential consequences of these tools for the justice system. Using survey responses from 209 litigants who had recently used an online case resolution system, we investigate factors that influenced litigants' experiences of fairness and emotional feelings toward court officials. Our results show that ease of using the online case resolution system, the outcome of the case, and a litigant's perceptions of procedural justice are positively associated both with whether the litigant views the process as fair and whether the litigant ultimately feels positive emotions toward court officials. We also analyze the online explanations litigants offer in their arguments to courts and litigant answers to an open-ended question about their court experiences, and highlight design and practical implications for online systems seeking to improve access to justice.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2511–2522},
numpages = {12},
keywords = {justice, cscw, courts, e-government, procedural justice, fairness, judicial systems},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025539,
author = {Oh, Changhoon and Lee, Taeyoung and Kim, Yoojung and Park, SoHyun and Kwon, Saebom and Suh, Bongwon},
title = {Us vs. Them: Understanding Artificial Intelligence Technophobia over the Google DeepMind Challenge Match},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025539},
doi = {10.1145/3025453.3025539},
abstract = {Various forms of artificial intelligence (AI), such as Apple's Siri and Google Now, have permeated our everyday lives. However, the advent of such "human-like" technology has stirred both awe and a great deal of fear. Many consider it a woe to have an unimaginable future where human intelligence is exceeded by AI. This paper investigates how people perceive and understand AI with a case study of the Google DeepMind Challenge Match, a Go match between Lee Sedol and AlphaGo, in March 2016. This study explores the underlying and changing perspectives toward AI as users experienced this historic event. Interviews with 22 participants show that users tacitly refer to AlphaGo as an "other" as if it were comparable to a human, while dreading that it would come back to them as a potential existential threat. Our work illustrates a confrontational relationship between users and AI, and suggests the need to prepare for a new kind of user experience in this nascent socio- technological change. It calls for a collaborative research effort from the HCI community to study and accommodate users for a future where they interact with algorithms, not just interfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2523–2534},
numpages = {12},
keywords = {algorithm, anthropomorphism, technophobia, alienation, artificial intelligence, algorithmic experience},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025757,
author = {Lin, Yen-Chen and Chang, Yung-Ju and Hu, Hou-Ning and Cheng, Hsien-Tzu and Huang, Chi-Wen and Sun, Min},
title = {Tell Me Where to Look: Investigating Ways for Assisting Focus in 360° Video},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025757},
doi = {10.1145/3025453.3025757},
abstract = {360° videos give viewers a spherical view and immersive experience of surroundings. However, one challenge of watching 360° videos is continuously focusing and re-focusing intended targets. To address this challenge, we developed two Focus Assistance techniques: Auto Pilot (directly bringing viewers to the target), and Visual Guidance (indicating the direction of the target). We conducted an experiment to measure viewers' video-watching experience and discomfort using these techniques and obtained their qualitative feedback. We showed that: 1) Focus Assistance improved ease of focus. 2) Focus Assistance techniques have specificity to video content. 3) Participants' preference of and experience with Focus Assistance depended not only on individual difference but also on their goal of watching the video. 4) Factors such as view-moving-distance, salience of the intended target and guidance, and language comprehension affected participants' video-watching experience. Based on these findings, we provide design implications for better 360° video focus assistance.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2535–2545},
numpages = {11},
keywords = {video experience, 360-degree videos, auto pilot, visual guidance, focus assistance},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025794,
author = {Huang, Michael Xuelin and Li, Jiajia and Ngai, Grace and Leong, Hong Va},
title = {ScreenGlint: Practical, In-Situ Gaze Estimation on Smartphones},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025794},
doi = {10.1145/3025453.3025794},
abstract = {Gaze estimation has widespread applications. However, little work has explored gaze estimation on smartphones, even though they are fast becoming ubiquitous. This paper presents ScreenGlint, a novel approach which exploits the glint (reflection) of the screen on the user's cornea for gaze estimation, using only the image captured by the front-facing camera. We first conduct a user study on common postures during smartphone use. We then design an experiment to evaluate the accuracy of ScreenGlint under varying face-to-screen distances. An in-depth evaluation involving multiple users is conducted and the impact of head pose variations is investigated. ScreenGlint achieves an overall angular error of 2.44º without head pose variations, and 2.94º with head pose variations. Our technique compares favorably to state-of-the-art research works, indicating that the glint of the screen is an effective and practical cue to gaze estimation on the smartphone platform. We believe that this work can open up new possibilities for practical and ubiquitous gaze-aware applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2546–2557},
numpages = {12},
keywords = {mobile eye tracker, glint, gaze estimation, screen reflection},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025517,
author = {Mott, Martez E. and Williams, Shane and Wobbrock, Jacob O. and Morris, Meredith Ringel},
title = {Improving Dwell-Based Gaze Typing with Dynamic, Cascading Dwell Times},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025517},
doi = {10.1145/3025453.3025517},
abstract = {We present cascading dwell gaze typing, a novel approach to dwell-based eye typing that dynamically adjusts the dwell time of keys in an on-screen keyboard based on the likelihood that a key will be selected next, and the location of the key on the keyboard. Our approach makes unlikely keys more difficult to select and likely keys easier to select by increasing and decreasing their required dwell times, respectively. To maintain a smooth typing rhythm for the user, we cascade the dwell time of likely keys, slowly decreasing the minimum allowable dwell time as a user enters text. Cascading the dwell time affords users the benefits of faster dwell times while causing little disruption to users' typing cadence. Results from a longitudinal study with 17 non-disabled participants show that our dynamic cascading dwell technique was significantly faster than a static dwell approach. Participants were able to achieve typing speeds of 12.39 WPM on average with our cascading technique, whereas participants were able to achieve typing speeds of 10.62 WPM on average with a static dwell time approach. In a small evaluation conducted with five people with ALS, participants achieved average typing speeds of 9.51 WPM with our cascading dwell approach. These results show that our dynamic cascading dwell technique has the potential to improve gaze typing for users with and without disabilities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2558–2570},
numpages = {13},
keywords = {gaze typing, text entry, eye typing, accessibility},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026033,
author = {Andrist, Sean and Gleicher, Michael and Mutlu, Bilge},
title = {Looking Coordinated: Bidirectional Gaze Mechanisms for Collaborative Interaction with Virtual Characters},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026033},
doi = {10.1145/3025453.3026033},
abstract = {Successful collaboration relies on the coordination and alignment of communicative cues. In this paper, we present mechanisms of bidirectional gaze - the coordinated production and detection of gaze cues - by which a virtual character can coordinate its gaze cues with those of its human user. We implement these mechanisms in a hybrid stochastic/heuristic model synthesized from data collected in human-human interactions. In three lab studies wherein a virtual character instructs participants in a sandwich-making task, we demonstrate how bidirectional gaze can lead to positive outcomes in error rate, completion time, and the agent's ability to produce quick, effective nonverbal references. The first study involved an on-screen agent and the participant wearing eye-tracking glasses. The second study demonstrates that these positive outcomes can be achieved using head-pose estimation in place of full eye tracking. The third study demonstrates that these effects also transfer into virtual-reality interactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2571–2582},
numpages = {12},
keywords = {joint attention, interactive gaze, bidirectional gaze, dyadic gaze, gaze coordination, verbal referencing, embodied agents},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025652,
author = {Ledo, David and Anderson, Fraser and Schmidt, Ryan and Oehlberg, Lora and Greenberg, Saul and Grossman, Tovi},
title = {Pineal: Bringing Passive Objects to Life with Embedded Mobile Devices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025652},
doi = {10.1145/3025453.3025652},
abstract = {Interactive, smart objects-customized to individuals and uses-are central to many movements, such as tangibles, the internet of things (IoT), and ubiquitous computing. Yet, rapid prototyping both the form and function of these custom objects can be problematic, particularly for those with limited electronics or programming experience. Designers often need to embed custom circuitry; program its workings; and create a form factor that not only reflects the desired user experience but can also house the required circuitry and electronics. To mitigate this, we created Pineal, a design tool that lets end-users: (1) modify 3D models to include a smart watch or phone as its heart; (2) specify high-level interactive behaviours through visual programming; and (3) have the phone or watch act out such behaviours as the objects' "smarts". Furthermore, a series of prototypes show how Pineal exploits mobile sensing and output, and automatically generates 3D printed form-factors for rich, interactive, objects.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2583–2593},
numpages = {11},
keywords = {smart objects, fabrication, rapid prototyping, 3d printing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025950,
author = {Santini, Thiago and Fuhl, Wolfgang and Kasneci, Enkelejda},
title = {CalibMe: Fast and Unsupervised Eye Tracker Calibration for Gaze-Based Pervasive Human-Computer Interaction},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025950},
doi = {10.1145/3025453.3025950},
abstract = {As devices around us become smart, our gaze is poised to become the next frontier of human-computer interaction (HCI). State-of-the-art mobile eye tracker systems typically rely on eye-model-based gaze estimation approaches, which do not require a calibration. However, such approaches require specialized hardware (e.g., multiple cameras and glint points), can be significantly affected by glasses, and, thus, are not fit for ubiquitous gaze-based HCI. In contrast, regression-based gaze estimations are straightforward approaches requiring solely one eye and one scene camera but necessitate a calibration. Therefore, a fast and accurate calibration is a key development to enable ubiquitous gaze-based HCI. In this paper, we introduce CalibMe, a novel method that exploits collection markers (automatically detected fiducial markers) to allow eye tracker users to gather a large array of calibration points, remove outliers, and automatically reserve evaluation points in a fast and unsupervised manner. The proposed approach is evaluated against a nine-point calibration method, which is typically used due to its relatively short calibration time and adequate accuracy. CalibMe reached a mean angular error of 0.59 (0=0.23) in contrast to 0.82 (0=0.15) for a nine-point calibration, attesting for the efficacy of the method. Moreover, users are able to calibrate the eye tracker anywhere and independently in - 10 s using a cellphone to display the collection marker.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2594–2605},
numpages = {12},
keywords = {gaze-based interaction, eye tracking, usability, calibration, fiducial markers},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026016,
author = {Kovacs, Robert and Seufert, Anna and Wall, Ludwig and Chen, Hsiang-Ting and Meinel, Florian and M\"{u}ller, Willi and You, Sijing and Brehm, Maximilian and Striebel, Jonathan and Kommana, Yannis and Popiak, Alexander and Bl\"{a}sius, Thomas and Baudisch, Patrick},
title = {TrussFab: Fabricating Sturdy Large-Scale Structures on Desktop 3D Printers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026016},
doi = {10.1145/3025453.3026016},
abstract = {We present TrussFab, an integrated end-to-end system that allows users to fabricate large scale structures that are sturdy enough to carry human weight. TrussFab achieves the large scale by complementing 3D print with plastic bottles. It does not use these bottles as "bricks" though, but as beams that form structurally sound node-link structures, also known as trusses, allowing it to handle the forces resulting from scale and load. TrussFab embodies the required engineering knowledge, allowing non-engineers to design such structures and to validate their design using integrated structural analysis. We have used TrussFab to design and fabricate tables and chairs, a 2.5 m long bridge strong enough to carry a human, a functional boat that seats two, and a 5 m diameter dome.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2606–2616},
numpages = {11},
keywords = {fabrication, 3d printing, truss structure},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025938,
author = {Vogl, Anita and Parzer, Patrick and Babic, Teo and Leong, Joanne and Olwal, Alex and Haller, Michael},
title = {StretchEBand: Enabling Fabric-Based Interactions through Rapid Fabrication of Textile Stretch Sensors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025938},
doi = {10.1145/3025453.3025938},
abstract = {The increased interest in interactive soft materials, such as smart clothing and responsive furniture, means that there is a need for flexible and deformable electronics. In this paper, we focus on stitch-based elastic sensors, which have the benefit of being manufacturable with textile craft tools that have been used in homes for centuries. We contribute to the understanding of stitch-based stretch sensors through four experiments and one user study that investigate conductive yarns from textile and technical perspectives, and analyze the impact of different stitch types and parameters. The insights informed our design of new stretch-based interaction techniques that emphasize eyes-free or causal interactions. We demonstrate with StretchEBand how soft, continuous sensors can be rapidly fabricated with different parameters and capabilities to support interaction with a wide range of performance requirements across wearables, mobile devices, clothing, furniture, and toys.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2617–2627},
numpages = {11},
keywords = {stretching sensor, fabrication, DIY, interactive textiles, smart textiles, smart car seat, deformation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025866,
author = {Kim, Younghoon and Wongsuphasawat, Kanit and Hullman, Jessica and Heer, Jeffrey},
title = {GraphScape: A Model for Automated Reasoning about Visualization Similarity and Sequencing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025866},
doi = {10.1145/3025453.3025866},
abstract = {We present GraphScape, a directed graph model of the vi- sualization design space that supports automated reasoning about visualization similarity and sequencing. Graph nodes represent grammar-based chart specifications and edges rep- resent edits that transform one chart to another. We weight edges with an estimated cost of the difficulty of interpreting a target visualization given a source visualization. We con- tribute (1) a method for deriving transition costs via a partial ordering of edit operations and the solution of a resulting lin- ear program, and (2) a global weighting term that rewards consistency across transition subsequences. In a controlled experiment, subjects rated visualization sequences covering a taxonomy of common transition types. In all but one case, GraphScape's highest-ranked suggestion aligns with subjects' top-rated sequences. Finally, we demonstrate applications of GraphScape to automatically sequence visualization presen- tations, elaborate transition paths between visualizations, and recommend design alternatives (e.g., to improve scalability while minimizing design changes).},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2628–2638},
numpages = {11},
keywords = {sequence, automated design, transition, model, visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026006,
author = {von Zadow, Ulrich and Dachselt, Raimund},
title = {GIAnT: Visualizing Group Interaction at Large Wall Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026006},
doi = {10.1145/3025453.3026006},
abstract = {Large interactive displays are increasingly important and a relevant research topic, and several studies have focused on wall interaction. However, in many cases, thorough user studies currently require time-consuming video analysis and coding. We present the Group Interaction Analysis Toolkit GIAnT, which provides a rich set of visualizations supporting investigation of multi-user interaction at large display walls. GIAnT focuses on visualizing time periods, making it possible to gain overview-level insights quickly. The toolkit is designed to be extensible and features several carefully crafted visualizations: A novel timeline visualization shows movement in front of the wall over time, a wall visualization shows interactions on the wall and gaze data, and a floor visualization displays user positions. In addition, GIAnT shows the captured video stream along with basic statistics. We validate our tool by analyzing how it supports investigating major research topics and by practical use in evaluating a cooperative game.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2639–2647},
numpages = {9},
keywords = {collaborative work, coupling, multitouch, awareness, territoriality, physical navigation, visualization, visual analysis},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025768,
author = {Wongsuphasawat, Kanit and Qu, Zening and Moritz, Dominik and Chang, Riley and Ouk, Felix and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
title = {Voyager 2: Augmenting Visual Analysis with Partial View Specifications},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025768},
doi = {10.1145/3025453.3025768},
abstract = {Visual data analysis involves both open-ended and focused exploration. Manual chart specification tools support question answering, but are often tedious for early-stage exploration where systematic data coverage is needed. Visualization recommenders can encourage broad coverage, but irrelevant suggestions may distract users once they commit to specific questions. We present Voyager 2, a mixed-initiative system that blends manual and automated chart specification to help analysts engage in both open-ended exploration and targeted question answering. We contribute two partial specification interfaces: wildcards let users specify multiple charts in parallel, while related views suggest visualizations relevant to the currently specified chart. We present our interface design and applications of the CompassQL visualization query language to enable these interfaces. In a controlled study we find that Voyager 2 leads to increased data field coverage compared to a traditional specification tool, while still allowing analysts to flexibly drill-down and answer specific questions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2648–2659},
numpages = {12},
keywords = {mixed-initiative interfaces, partial specification, exploratory analysis, visualization recommendation, data visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025752,
author = {Jo, Jaemin and L'Yi, Sehi and Lee, Bongshin and Seo, Jinwook},
title = {TouchPivot: Blending WIMP &amp; Post-WIMP Interfaces for Data Exploration on Tablet Devices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025752},
doi = {10.1145/3025453.3025752},
abstract = {Recent advancements in tablet technology pose a great opportunity for information visualization to expand its horizons beyond desktops. In this paper, we present TouchPivot, a novel interface that assists visual data exploration on tablet devices. With novices in mind, TouchPivot supports data transformations, such as pivoting and filtering, with simple pen and touch interactions, and facilitates understanding of the transformations through tight coupling between a data table and visualization. We bring in WIMP interfaces to TouchPivot, leveraging their familiarity and accessibility to novices. We report on a user study conducted to compare TouchPivot with two commercial interfaces, Tableau and Microsoft Excel's PivotTable. Our results show that novices not only answered data-driven questions faster, but also created a larger number of meaningful charts during freeform exploration with TouchPivot than others. Finally, we discuss the main hurdles novices encountered during our study and possible remedies for them.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2660–2671},
numpages = {12},
keywords = {pen and touch interaction, novices, natural interaction, information visualization, data exploration, table devices, pivot},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025914,
author = {Salehzadeh Niksirat, Kavous and Silpasuwanchai, Chaklam and Mohamed Hussien Ahmed, Mahmoud and Cheng, Peng and Ren, Xiangshi},
title = {A Framework for Interactive Mindfulness Meditation Using Attention-Regulation Process},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025914},
doi = {10.1145/3025453.3025914},
abstract = {We are often overwhelmed by everyday stressors. Mindfulness meditation can help slow things down and bring one's attention into the present moment. Given the prevalence of smartphones, mindfulness-based mobile applications (MBMAs) have received much attention. Current MBMAs mainly use the guided meditation method which may not be always effective, e.g., users may not be able to follow the pace of instructions and they need a private environment. This paper presents a framework for interactive MBMAs which allows users to self-regulate their attention according to their abilities and conditions. The framework is described by an Attention-Regulation Process and has two components: (1) Relaxation Response and (2) Attention Restoration Theory. The framework is validated by our experiment. It also informs future development for interactive meditation and has broad implications for designing mindfulness and well-being.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2672–2684},
numpages = {13},
keywords = {attention-regulation process, mobile applications, meditation, framework, relaxation response, attention restoration theory, mindfulness, interactivity},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025590,
author = {Zhu, Bin and Hedman, Anders and Li, Haibo},
title = {Designing Digital Mindfulness: Presence-In and Presence-With versus Presence-Through},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025590},
doi = {10.1145/3025453.3025590},
abstract = {The digital health and wellbeing movement has led to development of digital mindfulness applications that aim to help people to become mindful. In this paper we suggest a broad scheme for classifying and ordering apps intended to support mindfulness. This scheme consists of four levels of what we here term digital mindfulness. One crucial aspect of the fourth level is that artifacts at this level allow for what we term as presence-with and presence-in as opposed to presence-through, which occurs at the first three levels. We articulate our four levels along with specific design qualities through concrete examples of existing mindfulness apps and through research through design (RtD) work conducted with design fiction examples. We then use a working design case prototype to further illustrate the possibilities of presence-with and presence-in. We hope our four levels of digital mindfulness framework will be found useful by other researchers in discussing and planning the design of their own mindfulness apps and digital artifacts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2685–2695},
numpages = {11},
keywords = {design, presence, research through design, digital mindfulness, awareness, wellbeing, interaction, being, aesthetics, attention},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025516,
author = {Slov\'{a}k, Petr and Frauenberger, Christopher and Fitzpatrick, Geraldine},
title = {Reflective Practicum: A Framework of Sensitising Concepts to Design for Transformative Reflection},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025516},
doi = {10.1145/3025453.3025516},
abstract = {Designing for reflection is becoming an increasingly important part of many HCI systems in a wide range of application domains. However, there is a gap in our understanding of how the process of reflection can be supported through technology. In fact, an implicit assumption in the majority of existing work is that, just by providing access to well-selected data, in-depth reflection can and will occur. To counter this view, we draw on Sch\"{o}n's notion of reflective practicum and apply it as a sensitising concept to identify the complex interplay of factors that support transformative reflection in the context of two social-emotional learning (SEL) studies. The results highlight the need to carefully scaffold the process of reflection, rather than simply assume that the capability to reflect is a broadly available trait to be 'triggered' through data. Building on this analysis, we develop a conceptual framework that extends the concept of the reflective practicum towards identifying appropriate roles of technology to support transformative reflection. While our case is within the context of SEL, we argue that a deeper understanding of these opportunities can also benefit designing for reflection in other areas.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2696–2707},
numpages = {12},
keywords = {sel, social-emotional skills, reflection, personal informatics, reflective informatics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025918,
author = {Barry, Marguerite and Doherty, Kevin and Marcano Belisario, Jose and Car, Josip and Morrison, Cecily and Doherty, Gavin},
title = {MHealth for Maternal Mental Health: Everyday Wisdom in Ethical Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025918},
doi = {10.1145/3025453.3025918},
abstract = {Health and wellbeing applications increasingly raise ethical issues for design. User-centred and participatory design approaches, while grounded in everyday wisdom, cannot be expected to address ethical reflection consistently, as multiple value systems come into play. We explore the potential of phronesis, a concept from Aristotelian virtue ethics, for mHealth design. Phronesis describes wisdom and judgment garnered from practical experience of specific situations in context. Applied phronesis contributes everyday wisdom to challenging issues for vulnerable target users. Drawing on research into mHealth technologies for psychological wellbeing, we explore how phronesis can inform ethical design. Using a case study on an app for self-reporting symptoms of depression during pregnancy, we present a framework for incorporating a phronetic approach into design, involving: (a) a wide feedback net to capture phronetic input early in design; (b) observing the order of feedback, which directly affects value priorities in design; (c) ethical pluralism recognising different coexisting value systems; (d) acknowledging subjectivity in the disclosure and recognition of individual researcher and participant values. We offer insights into how a phronetic approach can contribute everyday wisdom to designing mHealth technologies to help designers foster the values that promote human flourishing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2708–2756},
numpages = {49},
keywords = {human flourishing, phronesis, mHealth, psychological wellbeing, ethical design, maternal mental health, virtue ethics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025470,
author = {Dillahunt, Tawanna R. and Kameswaran, Vaishnav and Li, Linfeng and Rosenblat, Tanya},
title = {Uncovering the Values and Constraints of Real-Time Ridesharing for Low-Resource Populations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025470},
doi = {10.1145/3025453.3025470},
abstract = {Real-time ridesharing services (e.g., Uber and Lyft) are often touted as sharing-economy leaders and dramatically lower the cost of transportation. However, how to make these services work better among low-income and transportation-scarce households, how these individuals experience these services, and whether they encounter barriers in enlisting these services is unknown. To address these questions, we onboarded 13 low-income individuals living in transportation-scarce environments to Uber as passengers. Our participants found these services to be reliable and benefited from rich social interactions with drivers; however, barriers such as cost, limited payment methods, and low digital literacy can make such services infeasible. We contribute platform designs that could lead to increased digital literacy and application transparency. To be more inclusive and to reach critical mass, we suggest that these companies foster belief in commons and community trust by coordinating with local businesses in low-resource areas with lower digital literacy.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2757–2769},
numpages = {13},
keywords = {transportation scarcity, low-income populations, mobility, real-time ridesharing services, sharing economy, uber},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025514,
author = {DeRenzi, Brian and Dell, Nicola and Wacksman, Jeremy and Lee, Scott and Lesh, Neal},
title = {Supporting Community Health Workers in India through Voice- and Web-Based Feedback},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025514},
doi = {10.1145/3025453.3025514},
abstract = {Our research aims to support community health workers (CHWs) in low-resource settings by providing them with personalized information regarding their work. This information is delivered through a combination of voice- and web-based feedback that is derived from data already collected by CHWs. We describe the in situ participatory design approach used to create usable and appropriate feedback for low-literate CHWs and present usage data from a 12-month study with 71 CHWs in India. We show how the system supported and motivated CHWs, and how they used both the web- and voice-based systems, and each of the visualizations, for different reasons. We also show that the comparative feedback provided by the system introduced elements of competition that discouraged some CHWs while motivating others. Taken together, our findings suggest that providing personalized voice- and web-based feedback could be an effective way to support and motivate CHWs in low-resource settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2770–2781},
numpages = {12},
keywords = {ictd, chw, asha, community health, hci4d, mhealth},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025593,
author = {Lazem, Shaimaa and Jad, Hussein Aly},
title = {We Play We Learn: Exploring the Value of Digital Educational Games in Rural Egypt},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025593},
doi = {10.1145/3025453.3025593},
abstract = {The Egyptian education system faces urgent challenges. Proposed governmental reforms tend to focus on increasing access to physical and digital resources. There is insufficient understanding as to how the provided resources are currently used in rural areas. We explored the extent to which digital technology could motivate primary students to collaboratively learn a challenging topic in the National Mathematics Curriculum. We designed and researched a digital game to support memorizing multiplication facts. We used an incentive structure that encouraged individual learning with rewarding teamwork. The game was tested with mixed ability and gender groups of students using the Teams-Game-Tournament collaboration technique. A key outcome was that the students with educationally disadvantaged backgrounds benefited from using the game format. They devised their own play and study strategies. We discuss implications on future designs of the game, and considerations for its integration in Egyptian schools.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2782–2791},
numpages = {10},
keywords = {HCI4D, game-based learning, ICT4D, collaborative learning, Egypt, games, edutainment, ICTD, play},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025958,
author = {Sorcar, Piya and Strauber, Benjamin and Loyalka, Prashant and Kumar, Neha and Goldman, Shelley},
title = {Sidestepping the Elephant in the Classroom: Using Culturally Localized Technology To Teach Around Taboos},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025958},
doi = {10.1145/3025453.3025958},
abstract = {Cultural taboos can restrict student learning on topics of critical importance. In India, such taboos have led multiple states to ban materials intended to educate youth about HIV, putting millions at risk. We present the design of TeachAIDS, a software application that leverages cultural insights, learning science, and affordances of technology to provide comprehensive HIV education while circumventing taboos. Using a mixed-methods evaluation, we demonstrate that this software leaves students with significantly increased knowledge about HIV and reduced stigma toward individuals infected with the virus. Validating the effectiveness of TeachAIDS in circumventing taboos, students report comfort in learning from the software, and it has since been deployed in tens of thousands of schools throughout India. The methodology presented here has broader implications for the design and implementation of interactive technologies for providing education on sensitive topics in health and other areas.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2792–2804},
numpages = {13},
keywords = {hiv, education, taboo topics, india, hci4d, aids},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025929,
author = {Fridman, Lex and Toyoda, Heishiro and Seaman, Sean and Seppelt, Bobbie and Angell, Linda and Lee, Joonbum and Mehler, Bruce and Reimer, Bryan},
title = {What Can Be Predicted from Six Seconds of Driver Glances?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025929},
doi = {10.1145/3025453.3025929},
abstract = {We consider a large dataset of real-world, on-road driving from a 100-car naturalistic study to explore the predictive power of driver glances and, specifically, to answer the following question: what can be predicted about the state of the driver and the state of the driving environment from a 6-second sequence of macro-glances? The context-based nature of such glances allows for application of supervised learning to the problem of vision-based gaze estimation, making it robust, accurate, and reliable in messy, real-world conditions. So, it's valuable to ask whether such macro-glances can be used to infer behavioral, environmental, and demographic variables? We analyze 27 binary classification problems based on these variables. The takeaway is that glance can be used as part of a multi-sensor real-time system to predict radio-tuning, fatigue state, failure to signal, talking, and several environment variables.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2805–2813},
numpages = {9},
keywords = {hidden markov models, gaze patterns, naturalistic on-road study, driver state prediction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025634,
author = {Wang, MinJuan and Lyckvi, Sus Lundgren and Chen, Chenhui and Dahlstedt, Palle and Chen, Fang},
title = {Using Advisory 3D Sound Cues to Improve Drivers' Performance and Situation Awareness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025634},
doi = {10.1145/3025453.3025634},
abstract = {Within vehicle Human Machine Interface design, visual displays are predominant, taking up more and more of the visual channel for each new system added to the car, e.g. navigation systems, blind spot information and forward collision warnings. Sounds however, are mainly used to alert or warn drivers together with visual information. In this study we investigated the design of auditory displays for advisory information, by designing a 3D auditory advisory traffic information system (3DAATIS) which was evaluated in a drive simulator study with 30 participants. Our findings indicate that overall, drivers' performance and situation awareness improved when using this system. But, more importantly, the results also point towards the advantages and limitations of the use of advisory 3D-sounds in cars, e.g. attention capture vs. limited auditory resolution. These findings are discussed and expressed as design implications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2814–2825},
numpages = {12},
keywords = {in-vehicle design, drive behavior, auditory display, 3d auditory advisory traffic information system},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025511,
author = {Steinberger, Fabius and Schroeter, Ronald and Foth, Marcus and Johnson, Daniel},
title = {Designing Gamified Applications That Make Safe Driving More Engaging},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025511},
doi = {10.1145/3025453.3025511},
abstract = {Low levels of engagement while driving can pose road safety risks, e.g., inattention during low traffic or routine trips. Interactive technologies that increase task engagement could therefore offer safety benefits, e.g., through performance feedback, increased challenge, and incentives. As a means to build upon these notions, we chose to explore gamification of the driving task. The research aim was to study how to design gamified applications that make safe driving more engaging. We present six design lenses which bring into focus considerations most relevant to creating engaging car applications. A user study enhanced our understanding of design requirements and revealed user personas to support the development of such applications. These lenses and personas informed two prototypes, which we evaluated in driving simulator studies. Our results indicate that the gamified conditions increased driver engagement and reduced driving speeds. As such, our work contributes towards the design of engaging applications that are both appropriate to the safety-critical driving context and compelling to users.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2826–2839},
numpages = {14},
keywords = {task engagement, gamification, road safety},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025713,
author = {Mok, Brian and Johns, Mishel and Miller, David and Ju, Wendy},
title = {Tunneled In: Drivers with Active Secondary Tasks Need More Time to Transition from Automation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025713},
doi = {10.1145/3025453.3025713},
abstract = {In partially automated driving, rapid transitions of control present a severe hazard. How long does it take a driver to take back control of the vehicle when engaged with other non-driving tasks? In this driving simulator study, we examined the performance of participants (N=30) after an abrupt loss of automated vehicle control. We tested three transition time conditions, with an unstructured transition of control occurring 2s, 5s, or 8s before entering a curve. As participants were occupied with an active secondary task (playing a game on a tablet) while the automated driving mode was enabled, they needed to disengage from the task and regain control of the car when the transition occurred. Few drivers in the 2 second condition were able to safely negotiate the road hazard situation, while the majority of drivers in the 5 or 8 second conditions were able to navigate the hazard situation safely.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2840–2844},
numpages = {5},
keywords = {human machine interaction, autonomous vehicles, transition of control, car simulator, controlled study},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025736,
author = {Ng, Alexander and Brewster, Stephen A. and Beruscha, Frank and Krautter, Wolfgang},
title = {An Evaluation of Input Controls for In-Car Interactions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025736},
doi = {10.1145/3025453.3025736},
abstract = {The way drivers operate in-car systems is rapidly changing as traditional physical controls, such as buttons and dials, are being replaced by touchscreens and touch-sensing surfaces. This has the potential to increase driver distraction and error as controls may be harder to find and use. This paper presents an in-car, on the road driving study which examined three key types of input controls to investigate their effects: a physical dial, pressure-based input on a touch surface and touch input on a touchscreen. The physical dial and pressure-based input were also evaluated with and without haptic feedback. The study was conducted with users performing a list-based targeting task using the different controls while driving on public roads. Eye-gaze was recorded to measure distraction from the primary task of driving. The results showed that target accuracy was high across all input methods (greater than 94%). Pressure-based targeting was the slowest while directly tapping on the targets was the faster selection method. Pressure-based input also caused the largest number of glances towards to the touchscreen but the duration of each glance was shorter than directly touching the screen. Our study will enable designers to make more appropriate design choices for future in-car interactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2845–2852},
numpages = {8},
keywords = {touchscreens, haptic feedback, touch input, pressure-based input, in-car interactions},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025785,
author = {Spiel, Katta and Frauenberger, Christopher and Hornecker, Eva and Fitzpatrick, Geraldine},
title = {When Empathy Is Not Enough: Assessing the Experiences of Autistic Children with Technologies},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025785},
doi = {10.1145/3025453.3025785},
abstract = {Capturing and describing the multi-faceted experiences autistic children have with technologies provides a unique research challenge. Approaches based on pragmatist notions of experience, which mostly rely on empathy, are particularly limited if used alone. To address this we have developed an approach that combines Actor-Network Theory and Critical Discourse Analysis. Drawing on this approach, we discuss the experiences autistic children had with technologies resulting from the collaborative design process in the OutsideTheBox project. We construct a holistic picture of the experience by drawing on diverse data sources ranging from interviews to log-data, and most importantly, the first-hand perspective of autistic children. In four case studies, we demonstrate how this approach allowed us to develop unique individual and structural insights into the experiences of autistic children with technology.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2853–2864},
numpages = {12},
keywords = {co-design evaluation, autism, children, experience},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026014,
author = {Boyd, LouAnne E. and Jiang, Xinlong and Hayes, Gillian R.},
title = {ProCom: Designing and Evaluating a Mobile and Wearable System to Support Proximity Awareness for People with Autism},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026014},
doi = {10.1145/3025453.3026014},
abstract = {People with autism are at risk for social isolation due to differences in their perception and engagement with the social world. In this work, we aim to address one specific concern related to socialization the understanding, awareness, and use of interpersonal space. Over the course of a year, we iteratively designed and tested a series of concepts for supporting children with autism in perceiving, understanding, and responding to physical proximity with other people. During this process, we developed ProCom, a prototype system for measuring proximity without requiring instrumentation of the environment or another person. We used a variety of low and high fidelity prototypes, culminating in ProCom, to assess the feasibility, utility, and challenges of this approach. The results of these iterative design engagements indicate that wearable assistive technologies can support people in developing awareness of physical proximity in social settings. However, challenges related to both personal and collective use remain},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2865–2877},
numpages = {13},
keywords = {proximity, autism, wearable computing, social skills, self-monitoring, children, parallel design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025790,
author = {Zhang, Xiaoyi and Kulkarni, Harish and Morris, Meredith Ringel},
title = {Smartphone-Based Gaze Gesture Communication for People with Motor Disabilities},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025790},
doi = {10.1145/3025453.3025790},
abstract = {Current eye-tracking input systems for people with ALS or other motor impairments are expensive, not robust under sunlight, and require frequent re-calibration and substantial, relatively immobile setups. Eye-gaze transfer (e-tran) boards, a low-tech alternative, are challenging to master and offer slow communication rates. To mitigate the drawbacks of these two status quo approaches, we created GazeSpeak, an eye gesture communication system that runs on a smartphone, and is designed to be low-cost, robust, portable, and easy-to-learn, with a higher communication bandwidth than an e-tran board. GazeSpeak can interpret eye gestures in real time, decode these gestures into predicted utterances, and facilitate communication, with different user interfaces for speakers and interpreters. Our evaluations demonstrate that GazeSpeak is robust, has good user satisfaction, and provides a speed improvement with respect to an e-tran board; we also identify avenues for further improvement to low-cost, low-effort gaze-based communication technologies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2878–2889},
numpages = {12},
keywords = {accessibility, amyotrophic lateral sclerosis (ALS), augmentative and alternative communication (AAC), eye gesture},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025610,
author = {Sobel, Kiley and Fiannaca, Alexander and Campbell, Jon and Kulkarni, Harish and Paradiso, Ann and Cutrell, Ed and Morris, Meredith Ringel},
title = {Exploring the Design Space of AAC Awareness Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025610},
doi = {10.1145/3025453.3025610},
abstract = {Augmentative and alternative communication (AAC) devices are a critical technology for people with disabilities that affect their speech. One challenge with AAC systems is their inability to portray aspects of nonverbal communication that typically accent, complement, regulate, or substitute for verbal speech. In this paper, we explore the design space of awareness displays that can supplement AAC devices, considering their output features and their effects on the perceptions of interlocutors. Through designing prototypes and getting feedback on our designs from people with ALS, their primary caregivers, and other communication partners, we consider (1) the consistent tensions that arose between abstractness and clarity in meaning for these designs and (2) the ways in which these designs can further mark users as "other." Overall, we contribute a generative understanding of designing AAC awareness displays to augment and contextualize communication.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2890–2903},
numpages = {14},
keywords = {emotion expression, aac, disability., awareness displays, als, nonverbal communication, conversational flow, conversational awareness, accessibility},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025456,
author = {Moritz, Dominik and Fisher, Danyel and Ding, Bolin and Wang, Chi},
title = {Trust, but Verify: Optimistic Visualizations of Approximate Queries for Exploring Big Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025456},
doi = {10.1145/3025453.3025456},
abstract = {Analysts need interactive speed for exploratory analysis, but big data systems are often slow. With sampling, data systems can produce approximate answers fast enough for exploratory visualization, at the cost of accuracy and trust. We propose optimistic visualization, which approaches these issues from a user experience perspective. This method lets analysts explore approximate results interactively, and provides a way to detect and recover from errors later. Pangloss implements these ideas. We discuss design issues raised by optimistic visualization systems. We test this concept with five expert visualizers in a laboratory study and three case studies at Microsoft. Analysts reported that they felt more confident in their results, and used optimistic visualization to check that their preliminary results were correct.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2904–2915},
numpages = {12},
keywords = {data visualization, approximation, uncertainty, exploratory analysis, optimistic visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025628,
author = {Du, Fan and Cao, Nan and Lin, Yu-Ru and Xu, Panpan and Tong, Hanghang},
title = {ISphere: Focus+Context Sphere Visualization for Interactive Large Graph Exploration},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025628},
doi = {10.1145/3025453.3025628},
abstract = {Interactive exploration plays a critical role in large graph visualization. Existing techniques, such as zoom-and-pan on a 2D plane and hyperbolic browser facilitate large graph exploration by showing both the details of a focal area and its surrounding context that guides the exploration process. However, existing techniques for large graph exploration are limited in either providing too little context or presenting graphs with too much distortion. In this paper, we propose a novel focus+context technique, iSphere, to address the limitation. iSphere maps a large graph onto a Riemann Sphere that better preserves graph structures and shows greater context information. We conduct extensive experiment studies on different graph exploration tasks under various conditions. The results show that iSphere performs the best in task completion time compared to the baseline techniques in link and path exploration tasks. This research also contributes to understanding large graph exploration on small screens.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2916–2927},
numpages = {12},
keywords = {graph exploration, focus+context, graph visualization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025868,
author = {Kralj, Christoph and Kamalzadeh, Mohsen and M\"{o}ller, Torsten},
title = {TagRefinery: A Visual Tool for Tag Wrangling},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025868},
doi = {10.1145/3025453.3025868},
abstract = {We present TagRefinery, an interactive visual application aiding the cleaning and processing of open tag spaces, such as those in Last.fm or YouTube. Our pre-design analysis showed a need to support a spectrum of user expertise from novice to advanced, which resulted in two distinct interface modes. Summative evaluations of TagRefinery showed that it could effectively guide the novice users through the workflow by giving them brief but helpful explanations on why each step was required, and providing visual and statistical aids to help them in making important decisions. This is while our more expert users greatly appreciated the amount of control and granularity over the workflow that our more advanced interface mode offered. Both the underlying tag cleaning workflow and the interface were designed iteratively in a participatory design process in collaboration with research on a music recommendation interface based on Last.fm tags.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2928–2939},
numpages = {12},
keywords = {social tags, visual data analysis, user centred design, data cleaning, folksonomy, graphical interface, data wrangling},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025801,
author = {Zhang, Jiawei and Malik, Abish and Ahlbrand, Benjamin and Elmqvist, Niklas and Maciejewski, Ross and Ebert, David S.},
title = {TopoGroups: Context-Preserving Visual Illustration of Multi-Scale Spatial Aggregates},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025801},
doi = {10.1145/3025453.3025801},
abstract = {Spatial datasets, such as tweets in a geographic area, often exhibit different distribution patterns at multiple levels of scale, such as live updates about events occurring in very specific locations on the map. Navigating in such multi-scale data-rich spaces is often inefficient, requires users to choose between overview or detail information, and does not support identifying spatial patterns at varying scales. In this paper, we propose TopoGroups, a novel context-preserving technique that aggregates spatial data into hierarchical clusters to improve exploration and navigation at multiple spatial scales. The technique uses a boundary distortion algorithm to minimize the visual clutter caused by overlapping aggregates. Our user study explores multiple visual encoding strategies for TopoGroups including color, transparency, shading, and shapes in order to convey the hierarchical and statistical information of the geographical aggregates at different scales.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2940–2951},
numpages = {12},
keywords = {context preservation, geospatial visualization, multi-scale analysis, social media},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025837,
author = {Feinberg, Melanie},
title = {A Design Perspective on Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025837},
doi = {10.1145/3025453.3025837},
abstract = {Empirical studies invariably show that data generation is situationally contingent and interpretively flexible, even when data is collected automatically. This essay situates data generation within a design perspective, demonstrating how data creation can be understood as a multilayered set of interlocking design activities. By showing how data is infused with design, this paper argues that any "use" of data represents a continuation of its design. We are always designers of data, never its mere appropriators.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2952–2963},
numpages = {12},
keywords = {design, data, metadata, materiality, infrastructure},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025878,
author = {Pschetz, Larissa and Tallyn, Ella and Gianni, Rory and Speed, Chris},
title = {Bitbarista: Exploring Perceptions of Data Transactions in the Internet of Things},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025878},
doi = {10.1145/3025453.3025878},
abstract = {We are surrounded by a proliferation of connected devices performing increasingly complex data transactions. Traditional design methods tend to simplify or conceal this complexity to improve ease of use. However, the hidden nature of data is causing increasing discomfort. This paper presents BitBarista, a coffee machine designed to explore perceptions of data processes in the Internet of Things. BitBarista reveals social, environmental, qualitative and economic aspects of coffee supply chains. It allows people to choose a source of future coffee beans, situating their choices within the pool of decisions previously made. In doing so, it attempts to engage them in the transactions that are required to produce coffee. Initial studies of BitBarista with 42 participants reveal challenges of designing for connected systems, particularly in terms of perceptions of data gathering and sharing, as well as assumptions generated by current models of consumption. A discussion is followed by a series of suggestions for increasing positive attitudes towards data use in interactive systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2964–2975},
numpages = {12},
keywords = {supply chains, design, data transactions, internet of things, privacy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026012,
author = {Krafft, Peter and Zhou, Kaitlyn and Edwards, Isabelle and Starbird, Kate and Spiro, Emma S.},
title = {Centralized, Parallel, and Distributed Information Processing during Collective Sensemaking},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026012},
doi = {10.1145/3025453.3026012},
abstract = {Widespread rumoring can hinder attempts to make sense of what is going on during disaster scenarios. Understanding how and why rumors spread in these contexts could assist in the design of systems that facilitate timely and accurate sensemaking. We address a basic question in this line: To what extent does rumor evolution occur (1) through reliance on a centralized information source, (2) in parallel information silos, or (3) through a web of complex informational interactions? We develop a conceptual model and associated analysis algorithms that allow us to distinguish between these possibilities. We analyze a case of rumoring on Twitter during the Boston Marathon Bombing. We find that rumor spreading was predominantly a parallel process in this case, which is consistent with a hypothesis that information silos may underlie the persistence of false rumors. Special attention towards detecting and resolving parallel information threads during collective sensemaking may hence be warranted.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2976–2987},
numpages = {12},
keywords = {collective sensemaking, computational social science, computational modeling, rumor evolution, social media, rumor spreading, sociotechnical systems, rumoring, twitter, collective intelligence},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025670,
author = {Lee, Kyung-Ryong and Goh, Geon-il and Park, Young-Woo},
title = {Quietto: An Interactive Timepiece Molded in Concrete and Milled Wood},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025670},
doi = {10.1145/3025453.3025670},
abstract = {We introduce Quietto: an interactive timepiece made of molded concrete and milled wood. It shows upcoming daily schedules and the time through the quiet, ambient motions of a clock hand and light through the concrete touch interface. The results of an in-field user observation of 10 participants over 3 days showed the possibilities of using concrete as a unique and attractive material for designing a tangible interface due to its unexpected haptic feeling. We also found that Quietto provides an intuitive and effective representation of its users' daily schedules and can be used as a private, personal device. Through its distinctive design, Quietto can provide a new way of understanding scheduling through its concrete texture and amusing interaction qualities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2988–2992},
numpages = {5},
keywords = {schedule, concrete, interactive timepiece, ambient},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025617,
author = {Yarosh, Svetlana and Zave, Pamela},
title = {Locked or Not? Mental Models of IoT Feature Interaction},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025617},
doi = {10.1145/3025453.3025617},
abstract = {Internet of Things (IoT) frequently involves conflicting interactions between devices and features that must be resolved to a single system state. The problem of feature interaction (FI) resolution has been investigated in Software Engineering through approaches that focus on verifiability but usually do not include the user in the evaluation. This paper bridges the gap between IoT approaches in HCI and Software Engineering by applying qualitative methods to understanding users' mental models of one representative FI resolution mechanism. Our contributions are in identifying common mental model errors and biases and how these may inform future IoT systems and research.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2993–2997},
numpages = {5},
keywords = {feature interaction, home automation, iot, mental models},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025601,
author = {Karolus, Jakob and Wozniak, Pawe\l{} W. and Chuang, Lewis L. and Schmidt, Albrecht},
title = {Robust Gaze Features for Enabling Language Proficiency Awareness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025601},
doi = {10.1145/3025453.3025601},
abstract = {We are often confronted with information interfaces designed in an unfamiliar language, especially in an increasingly globalized world, where the language barrier inhibits interaction with the system. In our work, we explore the design space for building interfaces that can detect the user's language proficiency. Specifically, we look at how a user's gaze properties can be used to detect whether the interface is presented in a language they understand. We report a study (N=21) where participants were presented with questions in multiple languages, whilst being recorded for gaze behavior. We identified fixation and blink durations to be effective indicators of the participants' language proficiencies. Based on these findings, we propose a classification scheme and technical guidelines for enabling language proficiency awareness on information displays using gaze data.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2998–3010},
numpages = {13},
keywords = {machine learning, language-aware interfaces, adaptive interfaces, eye-tracking},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025644,
author = {Ding, Yu and Zhang, Yuting and Xiao, Meihua and Deng, Zhigang},
title = {A Multifaceted Study on Eye Contact Based Speaker Identification in Three-Party Conversations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025644},
doi = {10.1145/3025453.3025644},
abstract = {To precisely understand human gaze behaviors in three-party conversations, this work is dedicated to look into whether the speaker can be reliably identified from the interlocutors in a three-party conversation on the basis of the interactive behaviors of eye contact, where speech signals are not provided. Derived from a pre-recorded, multimodal, and three-party conversational behavior dataset, a statistical framework is pro- posed to determine who is the speaker from the interactive behaviors of eye contact. Additionally, with the aid of virtual human technologies, a user study is conducted to study whether subjects are capable of distinguishing the speaker from the listeners according to the gaze behaviors of the interlocutors alone. Our results show that eye contact provides a reliable cue for the identification of the speaker in three-party conversations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3011–3021},
numpages = {11},
keywords = {human-human interaction, multiparty conversation, nonverbal behaviors, eye contact, perception of gaze, eye gaze, eye-head coordination, face-to-face communication, head gestures},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025920,
author = {Istance, Howell and Hyrskykari, Aulikki I.},
title = {Supporting Making Fixations and the Effect on Gaze Gesture Performance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025920},
doi = {10.1145/3025453.3025920},
abstract = {Gaze gestures are deliberate patterns of eye movements that can be used to invoke commands. These are less reliant on accurate measurement and calibration than other gaze-based interaction techniques. These may be used with wearable displays fitted with eye tracking capability, or as part of an assistive technology. The visual stimuli in the information on the display that can act as fixation targets may or may not be sparse and will vary over time. The paper describes an experiment to investigate how the amount of information provided on a display to assist making fixations affects gaze gesture performance. The impact of providing visualization guides and small fixation targets on the time to complete gestures and error rates is presented. The number and durations of fixations made during gesture completion is used to explain differences in performance as a result of practice and direction of eye movement.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3022–3033},
numpages = {12},
keywords = {fixation targets, gaze gestures, fixation duration, gaze gesture performance},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025455,
author = {Schenk, Simon and Dreiser, Marc and Rigoll, Gerhard and Dorr, Michael},
title = {GazeEverywhere: Enabling Gaze-Only User Interaction on an Unmodified Desktop PC in Everyday Scenarios},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025455},
doi = {10.1145/3025453.3025455},
abstract = {Eye tracking is becoming more and more affordable, and thus gaze has the potential to become a viable input modality for human-computer interaction. We present the GazeEverywhere solution that can replace the mouse with gaze control by adding a transparent layer on top of the system GUI. It comprises three parts: i) the SPOCK interaction method that is based on smooth pursuit eye movements and does not suffer from the Midas touch problem; ii) an online recalibration algorithm that continuously improves gaze-tracking accuracy using the SPOCK target projections as reference points; and iii) an optional hardware setup utilizing head-up display technology to project superimposed dynamic stimuli onto the PC screen where a software modification of the system is not feasible. In validation experiments, we show that GazeEverywhere's throughput according to ISO 9241-9 was improved over dwell time based interaction methods and nearly reached trackpad level. Online recalibration reduced interaction target ('button') size by about 25%. Finally, a case study showed that users were able to browse the internet and successfully run Wikirace using gaze only, without any plug-ins or other modifications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3034–3044},
numpages = {11},
keywords = {smooth pursuit, gaze-based interaction, mouse replacement, eye tracking},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026054,
author = {Smith, Wally and Ploderer, Bernd and Wadley, Greg and Webber, Sarah and Borland, Ron},
title = {Trajectories of Engagement and Disengagement with a Story-Based Smoking Cessation App},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026054},
doi = {10.1145/3025453.3026054},
abstract = {Strong user engagement with digital technologies for behaviour change is often taken as a precursor to their longer-term efficacy. We critically examine this assumption through a qualitative study of a smoking cessation app, called NewLeaf, which allows quitters to swap personal stories. The study examined what influenced people to engage or disengage with NewLeaf, and how the app was deployed in quit attempts during a four week trial. Several properties of swapped stories were reported to promote engagement, including: authenticity, currency, contextualization of advice, and evoking a sense of community. But while the resulting engagement was sometimes productive in supporting quitting, other trajectories of use were observed involving counterproductive engagement, and a surprising pattern of productive disengagement especially among stronger quitters. We discuss how this analysis of different trajectories problematizes any simple interpretation of user engagement as an early indicator of success for behaviour change technologies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3045–3056},
numpages = {12},
keywords = {qualitative research, engagement, smoking cessation, health behavior change},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025725,
author = {Bhattacharya, Arpita and Vilardaga, Roger and Kientz, Julie A. and Munson, Sean A.},
title = {Lessons from Practice: Designing Tools to Facilitate Individualized Support for Quitting Smoking},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025725},
doi = {10.1145/3025453.3025725},
abstract = {Many health care providers, with a variety of trainings, counsel clients on quitting smoking on a day-to-day basis. In their clinical practice, they draw from and adapt guidelines and research-based strategies to fit individual client situations and challenges. Designers of technologies to support quitting smoking can learn from these real world practices to create tools that better adapt to individual differences. We present findings from interviews with 28 providers with diverse experiences in smoking cessation counselling. Through analysis of their individualization strategies, challenges, and perceptions of technology, we find that providers: (1) individualize context appropriate coping strategies by involving clients in brainstorming, (2) emphasize the need to support nicotine withdrawal in clients, (3) mitigate social triggers and mediate social support for clients, and (4) need to navigate dependencies with other providers for managing medications and comorbid health conditions of clients. With this empirical understanding, we extend the discussion on the design of technology to support quitting smoking, highlight current barriers to individualization, and suggest future opportunities to address these barriers.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3057–3070},
numpages = {14},
keywords = {smoking cessation, counseling practice, personalization, health, smoking, individualization, behavior change},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026013,
author = {Klasnja, Predrag and Hekler, Eric B. and Korinek, Elizabeth V. and Harlow, John and Mishra, Sonali R.},
title = {Toward Usable Evidence: Optimizing Knowledge Accumulation in HCI Research on Health Behavior Change},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026013},
doi = {10.1145/3025453.3026013},
abstract = {Over the last ten years, HCI researchers have introduced a range of novel ways to support health behavior change, from glanceable displays to sophisticated game dynamics. Yet, this research has not had as much impact as its originality warrants. A key reason for this is that common forms of evaluation used in HCI make it difficult to effectively accumulate-and use-knowledge across research projects. This paper proposes a strategy for HCI research on behavior change that retains the field's focus on novel technical contributions while enabling accumulation of evidence that can increase impact of individual research projects both in HCI and the broader behavior-change science. The core of this strategy is an emphasis on the discovery of causal effects of individual components of behavior-change technologies and the precise ways in which those effects vary with individual differences, design choices, and contexts in which those technologies are used.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3071–3082},
numpages = {12},
keywords = {health informatics, user studies, evaluation methods, behavior change},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025501,
author = {Sato, Yuka and Ueoka, Ryoko},
title = {Investigating Haptic Perception of and Physiological Responses to Air Vortex Rings on a User's Cheek},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025501},
doi = {10.1145/3025453.3025501},
abstract = {Haptic perception is one of the primary means of interaction with the world. Recent research on affective haptics suggests that it can affect emotional and behavioral responses. In this study, we evaluate user perceptions of haptic stimuli generated by air vortex rings on the cheek and investigate the effects on their physiological responses. To develop a cheek haptic display, we investigated and found that the cheek had enough resolution to perceive the differences in haptic stimuli in a two-point discrimination threshold test of the face. Additionally, the intensities of the haptic stimuli for experiments were determined by investigating the subjective impressions of different stimuli pairs. Finally, we conducted experiments to evaluate quantitatively the effects of four different combinations of haptic stimuli on the physiological responses in terms of stress modification, brainwave activities, task performance, and subjective assessment. The results suggest that different stimuli affect physiological responses and task performance.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3083–3094},
numpages = {12},
keywords = {haptic perception, cheek haptic interface, subjective impression, air vortex rings, physiological responses},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025704,
author = {Weigel, Martin and Nittala, Aditya Shekhar and Olwal, Alex and Steimle, J\"{u}rgen},
title = {SkinMarks: Enabling Interactions on Body Landmarks Using Conformal Skin Electronics},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025704},
doi = {10.1145/3025453.3025704},
abstract = {The body provides many recognizable landmarks due to the underlying skeletal structure and variations in skin texture, elasticity, and color. The visual and spatial cues of such body landmarks can help in localizing on-body interfaces, guide input on the body, and allow for easy recall of mappings. Our main contribution are SkinMarks, novel skin-worn I/O devices for precisely localized input and output on fine body landmarks. SkinMarks comprise skin electronics on temporary rub-on tattoos. They conform to fine wrinkles and are compatible with strongly curved and elastic body locations. We identify five types of body landmarks and demonstrate novel interaction techniques that leverage SkinMarks' unique touch, squeeze and bend sensing with integrated visual output. Finally, we detail on the conformality and evaluate sub-millimeter electrodes for touch sensing. Taken together, SkinMarks expands the on-body interaction space to more detailed, highly curved and challenging areas on the body.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3095–3105},
numpages = {11},
keywords = {flexible display., fabrication, on-skin sensing, electronic tattoos, epidermal electronics, on-body interaction, on-skin display},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025703,
author = {Je, Seungwoo and Rooney, Brendan and Chan, Liwei and Bianchi, Andrea},
title = {TactoRing: A Skin-Drag Discrete Display},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025703},
doi = {10.1145/3025453.3025703},
abstract = {Smart rings are an emerging wearable technology particularly suitable for discrete notifications based on haptic cues. Previous work mostly focused on tactile actuators that stimulate only specific skin receptors on the finger, resulting in limited information expressiveness. We propose tactoRing, a novel tactile display that, by dragging a small tactor on the skin around the finger, excites multiple skin areas resulting in more accurate cue recognition. In this paper, we present the hardware and a perception study to understand the ability of users to recognize eight distinct points around the finger. Moreover, we show two different techniques to encode information through skin-dragging motion with accuracy up to 94%. We finally showcase a set of applications that, by combining sequences of tactile stimuli, achieve higher expressiveness than prior methods.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3106–3114},
numpages = {9},
keywords = {wearable, haptics, skin-drag, eyes-free, ring},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025744,
author = {Schorr, Samuel B. and Okamura, Allison M.},
title = {Fingertip Tactile Devices for Virtual Object Manipulation and Exploration},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025744},
doi = {10.1145/3025453.3025744},
abstract = {One of the main barriers to immersivity during object manipulation in virtual reality is the lack of realistic haptic feedback. Our goal is to convey compelling interactions with virtual objects, such as grasping, squeezing, pressing, lifting, and stroking, without requiring a bulky, world-grounded kinesthetic feedback device (traditional haptics) or the use of predetermined passive objects (haptic retargeting). To achieve this, we use a pair of finger-mounted haptic feedback devices that deform the skin on the fingertips to convey cutaneous force information from object manipulation. We show that users can perceive differences in virtual object weight and that they apply increasing grasp forces when lifting virtual objects as rendered mass is increased. Moreover, we show how naive users perceive changes of a virtual object's physical properties when we use skin deformation to render objects with varying mass, friction, and stiffness. These studies demonstrate that fingertip skin deformation devices can provide a compelling haptic experience appropriate for virtual reality scenarios involving object manipulation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3115–3119},
numpages = {5},
keywords = {haptics, mass perception, virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025759,
author = {Strasnick, Evan and Cauchard, Jessica R. and Landay, James A.},
title = {BrushTouch: Exploring an Alternative Tactile Method for Wearable Haptics},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025759},
doi = {10.1145/3025453.3025759},
abstract = {Haptic interfaces are ideal in situations where visual/auditory attention is impossible, unsafe, or socially unacceptable. However, conventional (vibrotactile) wearable interfaces often possess a limited bandwidth for expressing information. We explore a novel form of tactile stimulation through brushing, and demonstrate BrushTouch, a wearable prototype for brushing haptics. We also present schemes for conveying information such as time and direction through multi-tactor wrist-worn haptic interfaces. To evaluate BrushTouch, two user studies were run, comparing it to a conventional vibrotactile wristband across a number of tasks in both lab and mobile conditions. We show that for certain cues brushing can be more accurately recognized than vibration, enabling more effective spatial schemes for presenting information through haptic means. We then show that BrushTouch is capable of greater information transfer using such cues. We believe that brushing, as with other non-vibrotactile haptic techniques, merits further investigation as potential vehicles for richer haptic feedback.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3120–3125},
numpages = {6},
keywords = {haptics, tactile, wearables, vibrotactile, wayfinding, brush, brushtouch},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025490,
author = {Vlachokyriakos, Vasillis and Crivellaro, Clara and Wright, Pete and Karamagioli, Evika and Staiou, Eleni-Revekka and Gouscos, Dimitris and Thorpe, Rowan and Kr\"{u}ger, Antonio and Sch\"{o}ning, Johannes and Jones, Matt and Lawson, Shaun and Olivier, Patrick},
title = {HCI, Solidarity Movements and the Solidarity Economy},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025490},
doi = {10.1145/3025453.3025490},
abstract = {The financial crisis and austerity politics in Europe has had a devastating impact on public services, social security and vulnerable populations. Greek civil society responded quickly by establishing solidarity structures aimed at helping vulnerable citizens to meet their basic needs and empower them to co-create an anti-austerity movement. While digital technology and social media played an important role in the initiation of the movement, it has a negligible role in the movement's on-going practices. Through embedded work with several solidarity structures in Greece, we have begun to understand the "solidarity economy" (SE) as an experiment in direct democracy and self-organization. Working with a range of solidarity structures we are developing a vision for a "Solidarity HCI" committed to designing to support personal, social and institutional transformation through processes of agonistic pluralism and contestation, where the aims and objectives of the SE are continuously re-formulated and put into practice.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3126–3137},
numpages = {12},
keywords = {digital civics, social movements, solidarity economy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025667,
author = {Aoki, Paul and Woodruff, Allison and Yellapragada, Baladitya and Willett, Wesley},
title = {Environmental Protection and Agency: Motivations, Capacity, and Goals in Participatory Sensing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025667},
doi = {10.1145/3025453.3025667},
abstract = {In this paper we consider various genres of citizen science from the perspective of citizen participants. As a mode of scientific inquiry, citizen science has the potential to "scale up" scientific data collection efforts and increase lay engagement with science. However, current technological directions risk losing sight of the ways in which citizen science is actually practiced. As citizen science is increasingly used to describe a wide range of activities, we begin by presenting a framework of citizen science genres. We then present findings from four interlocking qualitative studies and technological interventions of community air quality monitoring efforts, examining the motivations and capacities of citizen participants and characterizing their alignment with different types of citizen science. Based on these studies, we suggest that data acquisition involves complex multi-dimensional tradeoffs, and the commonly held view that citizen science systems are a win-win for citizens and science may be overstated.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3138–3150},
numpages = {13},
keywords = {citizen science, environmental sensing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025627,
author = {Chauhan, Apoorva and Hughes, Amanda L.},
title = {Providing Online Crisis Information: An Analysis of Official Sources during the 2014 Carlton Complex Wildfire},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025627},
doi = {10.1145/3025453.3025627},
abstract = {Using the 2014 Carlton Complex Wildfire as a case study, we examine who contributes official information online during a crisis event, and the timeliness and relevance of the information provided. We identify and describe the communication behaviors of four types of official information sources (Event Based Resources, Local Responders, Local News Media, and Cooperating Agencies), and collect message data from each source's website, public Facebook page, and/or Twitter account. The data show that the Local News Media provided the highest quantity of relevant information and the timeliest information. Event Based Resources shared the highest percentage of relevant information, however, it was often unclear who managed these resources and the credibility of the information. Based on these findings, we offer suggestions for how providers of official crisis information might better manage their online communications and ways that the public can find more timely and relevant online crisis information from official sources.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3151–3162},
numpages = {12},
keywords = {social computing, social media, wildfire, risk communication, crisis informatics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025659,
author = {DeVito, Michael A. and Gergle, Darren and Birnholtz, Jeremy},
title = {"Algorithms Ruin Everything": #RIPTwitter, Folk Theories, and Resistance to Algorithmic Change in Social Media},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025659},
doi = {10.1145/3025453.3025659},
abstract = {As algorithmically-driven content curation has become an increasingly common feature of social media platforms, user resistance to algorithmic change has become more frequent and visible. These incidents of user backlash point to larger issues such as inaccurate understandings of how algorithmic systems work as well as mismatches between designer and user intent. Using a content analysis of 102,827 tweets from #RIPTwitter, a recent hashtag-based backlash to rumors about introducing algorithmic curation to Twitter's timeline, this study addresses the nature of user resistance in the form of the complaints being expressed, folk theories of the algorithmic system espoused by users, and how these folk theories potentially frame user reactions. We find that resistance to algorithmic change largely revolves around expectation violation, with folk theories acting as frames for reactions such that more detailed folk theories are expressed through more specific reactions to algorithmic change.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3163–3174},
numpages = {12},
keywords = {algorithms, user resistance, machine classification, expectation violation, social media, algorithm awareness, technology continuance, folk theories, algorithmic curation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026018,
author = {Chandrasekharan, Eshwar and Samory, Mattia and Srinivasan, Anirudh and Gilbert, Eric},
title = {The Bag of Communities: Identifying Abusive Behavior Online with Preexisting Internet Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026018},
doi = {10.1145/3025453.3026018},
abstract = {Since its earliest days, harassment and abuse have plagued the Internet. Recent research has focused on in-domain methods to detect abusive content and faces several challenges, most notably the need to obtain large training corpora. In this paper, we introduce a novel computational approach to address this problem called Bag of Communities (BoC)---a technique that leverages large-scale, preexisting data from other Internet communities. We then apply BoC toward identifying abusive behavior within a major Internet community. Specifically, we compute a post's similarity to 9 other communities from 4chan, Reddit, Voat and MetaFilter. We show that a BoC model can be used on communities "off the shelf" with roughly 75% accuracy---no training examples are needed from the target community. A dynamic BoC model achieves 91.18% accuracy after seeing 100,000 human-moderated posts, and uniformly outperforms in-domain methods. Using this conceptual and empirical work, we argue that the BoC approach may allow communities to deal with a range of common problems, like abusive behavior, faster and with fewer engineering resources.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3175–3187},
numpages = {13},
keywords = {abusive behavior, machine learning, social computing, moderation, online communities},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025631,
author = {Adar, Eytan and Gearig, Carolyn and Balasubramanian, Ayshwarya and Hullman, Jessica},
title = {PersaLog: Personalization of News Article Content},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025631},
doi = {10.1145/3025453.3025631},
abstract = {Content personalization automatically modifying text and multimedia features within articles based on the reader's individual features'is evolving as a new form of journalism. Informed by constraints articulated through a survey of journalists, we have implemented PersaLog, a novel system for creating personalized content (e.g., text and interactive visualizations). Because crafting, and validating, personalized content can be challenging to scale across articles (unlike feed personalization), we offer a simple Domain Specific Language (DSL), and editing environment, to support this task. PersaLog is particularly designed to support the personalization of existing text and visualizations. Our work provides guidelines for personalization as well as a system that allows for both subtle and dramatic personalization-driven content changes. We validate PersaLog using case and lab studies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3188–3200},
numpages = {13},
keywords = {guidelines, news personalization, personalized content},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026011,
author = {Jahanbakhsh, Farnaz and Fu, Wai-Tat and Karahalios, Karrie and Marinov, Darko and Bailey, Brian},
title = {You Want Me to Work with <i>Who</i>? Stakeholder Perceptions of Automated Team Formation in Project-Based Courses},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026011},
doi = {10.1145/3025453.3026011},
abstract = {Instructors are increasingly using algorithmic tools for team formation, yet little is known about how these tools are applied or how students and instructors perceive their use. We studied a representative team formation tool (CATME) in eight project-based courses. An instructor uses the tool to form teams by surveying students' working styles, skills, and demographics; then configuring these criteria as input into an algorithm that assigns teams. We surveyed students (N=277) in the courses to gauge their perceptions of the strengths and weaknesses of the tool and ideas for improving it. We also interviewed instructors (N=13) different from those who taught the eight courses to learn about their criteria selections and perceptions of the tool. Students valued the rational basis for forming teams but desired a stronger voice in criteria selection and explanations as to why they were assigned to a particular team. Instructors appreciated the efficiency of team formation but wanted to view exemplars of criteria used in similar courses. This work contributes recommendations for deploying team formation tools in educational settings and for better satisfying the goals of all stakeholders.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3201–3212},
numpages = {12},
keywords = {education, algorithms, catme, team formation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025985,
author = {Chancellor, Stevie and Kalantidis, Yannis and Pater, Jessica A. and De Choudhury, Munmun and Shamma, David A.},
title = {Multimodal Classification of Moderated Online Pro-Eating Disorder Content},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025985},
doi = {10.1145/3025453.3025985},
abstract = {Social media sites are challenged by both the scale and variety of deviant behavior online. While algorithms can detect spam and obscenity, behaviors that break community guidelines on some sites are difficult because they have multimodal subtleties (images and/or text). Identifying these posts is often regulated to a few moderators. In this paper, we develop a deep learning classifier that jointly models textual and visual characteristics of pro-eating disorder content that violates community guidelines. Using a million Tumblr photo posts, our classifier discovers deviant content efficiently while also maintaining high recall (85%). Our approach uses human sensitivity throughout to guide the creation, curation, and understanding of this approach to challenging, deviant content. We discuss how automation might impact community moderation, and the ethical and social obligations of this area.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3213–3226},
numpages = {14},
keywords = {tumblr, computer vision, social media, deep learning, pro-eating disorder, content moderation, deviant behavior},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025664,
author = {Xia, Haijun and Hinckley, Ken and Pahud, Michel and Tu, Xiao and Buxton, Bill},
title = {<i>WritLarge</i>: Ink Unleashed by Unified Scope, Action, &amp; Zoom},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025664},
doi = {10.1145/3025453.3025664},
abstract = {WritLarge is a freeform canvas for early-stage design on electronic whiteboards with pen+touch input. The system aims to support a higher-level flow of interaction by 'chunking' the traditionally disjoint steps of selection and action into unified selection-action phrases. This holistic goal led us to address two complementary aspects: SELECTION, for which we devise a new technique known as the Zoom-Catcher that integrates pinch-to-zoom and selection in a single gesture for fluidly selecting and acting on content; plus: ACTION, where we demonstrate how this addresses the combined issues of navigating, selecting, and manipulating content. In particular, the designer can transform select ink strokes in flexible and easily-reversible representations via semantic, structural, and temporal axes of movement that are defined as conceptual 'moves' relative to the specified content.This approach dovetails zooming with lightweight specification of scope as well as the evocation of context-appropriate commands, at-hand, in a location-independent manner. This establishes powerful new primitives that can help to scaffold higher-level tasks, thereby unleashing the expressive power of ink in a compelling manner.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3227–3240},
numpages = {14},
keywords = {pen+touch, electronic whiteboard, bimanual input, toolglass},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025716,
author = {Riche, Yann and Henry Riche, Nathalie and Hinckley, Ken and Panabaker, Sheri and Fuelling, Sarah and Williams, Sarah},
title = {As We May Ink? Learning from Everyday Analog Pen Use to Improve Digital Ink Experiences},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025716},
doi = {10.1145/3025453.3025716},
abstract = {This paper sheds light on gaps and discrepancies between the experiences afforded by analog pens and their digital counterparts. Despite the long history (and recent renaissance) of digital pens, the literature still lacks a comprehensive survey of what types of marks people make and what motivates them to use ink-both analog and digital in daily life. To capture the diversity of inking behaviors and tease out the unique affordances of pen-and ink, we conducted a diary study with 26 participants from diverse backgrounds. From analysis of 493 diary entries we identified 8 analog pen-and-ink activities, and 9 affordances of pens. We contextualized and contrasted these findings using a survey with 1,633 respondents and a follow-up diary study with 30 participants, observing digital pens. Our analysis reveals gaps and research opportunities based on pen affordances not yet fully explored in the literature.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3241–3253},
numpages = {13},
keywords = {pen interaction, diary studies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025567,
author = {Pfeuffer, Ken and Hinckley, Ken and Pahud, Michel and Buxton, Bill},
title = {Thumb + Pen Interaction on Tablets},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025567},
doi = {10.1145/3025453.3025567},
abstract = {Modern tablets support simultaneous pen and touch input, but it remains unclear how to best leverage this capability for bimanual input when the nonpreferred hand holds the tablet. We explore Thumb + Pen interactions that support simultaneous pen and touch interaction, with both hands, in such situations. Our approach engages the thumb of the device-holding hand, such that the thumb interacts with the touch screen in an indirect manner, thereby complementing the direct input provided by the preferred hand. For instance, the thumb can determine how pen actions (articulated with the opposite hand) are interpreted. Alternatively, the pen can point at an object, while the thumb manipulates one or more of its parameters through indirect touch. Our techniques integrate concepts in a novel way that derive from marking menus, spring-loaded modes, indirect input, and multi-touch conventions. Our overall approach takes the form of a set of probes, each representing a meaningfully distinct class of application. They serve as an initial exploration of the design space at a level which will help determine the feasibility of supporting bimanual interaction in such contexts, and the viability of the Thumb + Pen techniques in so doing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3254–3266},
numpages = {13},
keywords = {postures of use, pen+touch, thumb, bimanual input, tablet},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025865,
author = {Surale, Hemant Bhaskar and Matulic, Fabrice and Vogel, Daniel},
title = {Experimental Analysis of Mode Switching Techniques in Touch-Based User Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025865},
doi = {10.1145/3025453.3025865},
abstract = {This paper presents the results of a 36 participant empirical comparison of touch mode-switching. Six techniques are evaluated, spanning current and future techniques: long press, non-dominant hand, two-fingers, hard press, knuckle, and thumb-on-finger. Two poses are controlled for, seated with the tablet on a desk and standing with the tablet held on the forearm. Findings indicate pose has no effect on mode switching time and little effect on error rate; using two-fingers is fastest while long press is much slower; non-preferred hand and thumb-on-finger also rate highly in subjective scores. The experiment protocol is based on Li et al.'s pen mode-switching study, enabling a comparison of touch and pen mode switching. Among the common techniques, the non-dominant hand is faster than pressure with touch, whereas no significant difference had been found for pen. Our work addresses the lack of empirical evidence comparing touch mode-switching techniques and provides guidance to practitioners when choosing techniques and to researchers when designing new mode-switching methods.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3267–3280},
numpages = {14},
keywords = {multi-touch, mode switching, touch input},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025605,
author = {Antoine, Axel and Malacria, Sylvain and Casiez, G\'{e}ry},
title = {ForceEdge: Controlling Autoscroll on Both Desktop and Mobile Computers Using the Force},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025605},
doi = {10.1145/3025453.3025605},
abstract = {Operating systems support autoscroll to allow users to scroll a view while in dragging mode: the user moves the pointer near the window's edge to trigger an "automatic" scrolling whose rate is typically proportional to the distance between the pointer and the window's edge. This approach suffers from several problems, especially when the window is maximized, resulting in a very limited space around it. Another problem is that for some operations, such as object drag-and-drop, the source and destination might be located in different windows, making it complicated for the computer to understand user's intention. In this paper, we present ForceEdge, a novel autoscroll technique relying on touch surfaces with force-sensing capabilities to alleviate the problems related to autoscroll. We report on the results of three controlled experiments showing that it improves over macOS and iOS systems baselines for top-to-bottom select and move tasks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3281–3292},
numpages = {12},
keywords = {autoscroll, touchscreen, trackpad, scrolling, force control},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025808,
author = {Grosse-Puppendahl, Tobias and Holz, Christian and Cohn, Gabe and Wimmer, Raphael and Bechtold, Oskar and Hodges, Steve and Reynolds, Matthew S. and Smith, Joshua R.},
title = {Finding Common Ground: A Survey of Capacitive Sensing in Human-Computer Interaction},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025808},
doi = {10.1145/3025453.3025808},
abstract = {For more than two decades, capacitive sensing has played a prominent role in human-computer interaction research. Capacitive sensing has become ubiquitous on mobile, wearable, and stationary devices - enabling fundamentally new interaction techniques on, above, and around them. The research community has also enabled human position estimation and whole-body gestural interaction in instrumented environments. However, the broad field of capacitive sensing research has become fragmented by different approaches and terminology used across the various domains. This paper strives to unify the field by advocating consistent terminology and proposing a new taxonomy to classify capacitive sensing approaches. Our extensive survey provides an analysis and review of past research and identifies challenges for future work. We aim to create a common understanding within the field of human-computer interaction, for researchers and practitioners alike, and to stimulate and facilitate future research in capacitive sensing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3293–3315},
numpages = {23},
keywords = {capacitive sensing, survey, electric field sensing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025829,
author = {Nishida, Jun and Suzuki, Kenji},
title = {BioSync: A Paired Wearable Device for Blending Kinesthetic Experience},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025829},
doi = {10.1145/3025453.3025829},
abstract = {We present a novel, paired, wearable system for combining the kinesthetic experiences of two persons. These devices allow users to sense and combine muscle contraction and joint rigidity bi-directionally. This is achieved through kinesthetic channels based on electromyogram (EMG) measurement and electrical muscle stimulation (EMS). We developed a pair of wearable kinesthetic input-output (I/O) devices called bioSync that uses specially designed electrodes to perform biosignal measurement and stimulation simultaneously on the same electrodes.In a user study, participants successfully evaluated the strength of their partners' muscle contractions while exerting their own muscles. We confirmed that the pair of devices could help participants synchronize their hand movements through tapping, without visual and auditory feedback. The proposed interpersonal kinesthetic communication system can be used to enhance interactions such as clinical gait rehabilitation and sports training, and facilitate sharing of physical experiences with Parkinson's patients, thereby enhancing understanding of the physical challenges they face in daily life.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3316–3327},
numpages = {12},
keywords = {rehabilitation, electrical muscle stimulation, blending kinesthetic experience, electromyogram signals},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025523,
author = {Jang, Sujin and Stuerzlinger, Wolfgang and Ambike, Satyajit and Ramani, Karthik},
title = {Modeling Cumulative Arm Fatigue in Mid-Air Interaction Based on Perceived Exertion and Kinetics of Arm Motion},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025523},
doi = {10.1145/3025453.3025523},
abstract = {Quantifying cumulative arm muscle fatigue is a critical factor in understanding, evaluating, and optimizing user experience during prolonged mid-air interaction. A reasonably accurate estimation of fatigue requires an estimate of an individual's strength. However, there is no easy-to-access method to measure individual strength to accommodate inter-individual differences. Furthermore, fatigue is influenced by both psychological and physiological factors, but no current HCI model provides good estimates of cumulative subjective fatigue. We present a new, simple method to estimate the maximum shoulder torque through a mid-air pointing task, which agrees with direct strength measurements. We then introduce a cumulative fatigue model informed by subjective and biomechanical measures. We evaluate the performance of the model in estimating cumulative subjective fatigue in mid-air interaction by performing multiple cross-validations and a comparison with an existing fatigue metric. Finally, we discuss the potential of our approach for real-time evaluation of subjective fatigue as well as future challenges.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3328–3339},
numpages = {12},
keywords = {mid-air interaction, biomechanical arm model, perceived exertion, cumulative fatigue model, maximum arm strength},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025532,
author = {Karusala, Naveena and Kumar, Neha},
title = {Women's Safety in Public Spaces: Examining the Efficacy of Panic Buttons in New Delhi},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025532},
doi = {10.1145/3025453.3025532},
abstract = {We present a qualitative inquiry through the lens of feminist Human-Computer Interaction (HCI) into women's perceptions of personal safety in New Delhi, India. Since a brutal gang-rape incident took place in Delhi in December 2012 and received global attention, women's safety has been the focus of much attention India-wide. In April 2016, the Indian government issued a mandate that all mobile phones sold in India 2017 onwards must include a panic button for women's safety. We draw on interview and survey data to examine women's responses to the mandate, also investigating what factors influence their perceptions of safety, positively and negatively. Our findings indicate that women's sense of safety may be deconstructed into a multitude of factors--personal, public, social, technological--that must align for this sense of safety to be preserved. We then discuss the implications these factors have for the success and (re-)design of the panic button and similar interventions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3340–3351},
numpages = {12},
keywords = {india, safety, gender, feminist hci, hci4d},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025615,
author = {Strohmayer, Angelika and Laing, Mary and Comber, Rob},
title = {Technologies and Social Justice Outcomes in Sex Work Charities: Fighting Stigma, Saving Lives},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025615},
doi = {10.1145/3025453.3025615},
abstract = {Sex workers' rights are human rights, and as such are an issue inherently based in social, criminal, and political justice debates. As HCI continues to move towards feminist and social justice oriented research and design approaches, we argue that we need to take into consideration the difficulties faced by sex workers; and explore how technology can and does mediate social justice outcomes for them. We contribute directly to this challenge by providing an empirical account of a charity whose work is built on the underlying move towards social and criminal justice for sex workers in the UK. Through ethnographic fieldwork, meetings, interviews, surveys, and creative workshops we describe the different points of view associated with the charity from a variety of stakeholders. We discuss their service provision and the ways in which HCI is uniquely positioned to be able respond to the needs of and to support sex work support services.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3352–3364},
numpages = {13},
keywords = {social justice, sex work, activism, feminist hci, ethnography, charities},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025884,
author = {Lee, Min Kyung and Kim, Ji Tae and Lizarondo, Leah},
title = {A Human-Centered Approach to Algorithmic Services: Considerations for Fair and Motivating Smart Community Service Management That Allocates Donations to Non-Profit Organizations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025884},
doi = {10.1145/3025453.3025884},
abstract = {Algorithms are increasingly being incorporated into diverse services that orchestrate multiple stakeholders' needs and interests. How can we design these algorithmic services to make decisions that are not only efficient, but also fair and motivating? We take a human-centered approach to identify and address challenges in building human-centered algorithmic services. We are in the process of building an allocation algorithm for 412 Food Rescue, an organization that matches food donations with non-profit organizations. As part of this ongoing project, we conducted interviews with multiple stakeholders in the service-organization staff, donors, volunteers, recipient non-profits and their clients, and everyday citizens-in order to understand how the allocation algorithm, interfaces, and surrounding work practices should be designed. The findings suggest that we need to understand and account for varying fairness notions held by stakeholders; consider people, contexts, and interfaces for algorithms to work fairly in the real world; and preserve meaningfulness and social interaction in automation in order to build fair and motivating algorithmic services.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3365–3376},
numpages = {12},
keywords = {service design, fairness, algorithmic services, allocation, automation, community service, motivation, donation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025921,
author = {Rho, Eugenia Ha Rim and Haimson, Oliver L. and Andalibi, Nazanin and Mazmanian, Melissa and Hayes, Gillian R.},
title = {Class Confessions: Restorative Properties in Online Experiences of Socioeconomic Stigma},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025921},
doi = {10.1145/3025453.3025921},
abstract = {In this paper, we examine stigma related to class identity online through an empirical examination of Elite University Class Confessions (EUCC). EUCC is an online space that includes a Facebook page and a surrounding sociotechnical ecosystem. It is a community of, for, and about low-income and first generation students at an elite university. By bringing in a community that learns and engages with users' socioeconomic struggles, EUCC engenders unique restorative properties for students experiencing class stigma. EUCC's restorative properties foster new ways of understanding one's stigmatized identity through meaning- making interactions in a networked sociotechnical system. We discuss how EUCC's design shapes the nature of user interactions around class stigma, and explore in depth how people experience stigma differently through the restorative properties of EUCC.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3377–3389},
numpages = {13},
keywords = {restorative properties, networked publics, low-income, low-ses, stigma, social networking sites, identity},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025990,
author = {Waern, Annika and Back, Jon},
title = {Activity as the Ultimate Particular of Interaction Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025990},
doi = {10.1145/3025453.3025990},
abstract = {In the turn towards practice-oriented research in interaction design, one of the most important proposals has been the emphasis on the 'ultimate particulars' produced by design, as embodiments of design knowledge. In current HCI research, those particulars are almost always taken to be 'things' artefacts or singular systems. We argue that this emphasis may have come at a cost that can be described as a loss of identity; interaction design research was never primarily concerned with the design of artefacts, but with how humans act and interact with each other with and through artefacts. We propose a complementary perspective by looking at design projects and traditions where the 'ultimate particulars' can be considered to be activities rather than things. The article is concerned with how knowledge needs to be articulated in the scholarly engagement with such design practices. We argue that engagement with activity-centric design gets design research one step closer towards understanding salient contemporary design practices and what Buchanan calls 'environmental design'.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3390–3402},
numpages = {13},
keywords = {second order design, third wave hci, activity-centric design, ultimate particular, environmental design, research through design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025534,
author = {Faste, Haakon},
title = {Intuition in Design: Reflections on the Iterative Aesthetics of Form},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025534},
doi = {10.1145/3025453.3025534},
abstract = {Curious to reflect on the factors contributing to the internal decision-making processes of intuitive design, a reflective study was established to systematically examine and document the practice of intuition while performing an iterative aesthetic task. Autoethnographic techniques were used to document the reflective practices that occurred over numerous iterations spanning several weeks of activity. Our analysis concludes with a summary of reflections on how intuition informs judgment in design cognition. We examine four dimensions of intuition in design - efficiency, inspiration, curiosity, and insight - and the reflective and sensory inputs that drive intuitive speculation and impulse.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3403–3413},
numpages = {11},
keywords = {intuition, decision-making, iteration, self-reflection, design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025598,
author = {Williamson, Julie R. and Williamson, John},
title = {Understanding Public Evaluation: Quantifying Experimenter Intervention},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025598},
doi = {10.1145/3025453.3025598},
abstract = {Public evaluations are popular because some research questions can only be answered by turning "to the wild." Different approaches place experimenters in different roles during deployment, which has implications for the kinds of data that can be collected and the potential bias introduced by the experimenter. This paper expands our understanding of how experimenter roles impact public evaluations and provides an empirical basis to consider different evaluation approaches. We completed an evaluation of a playful gesture-controlled display not to understand interaction at the display but to compare different evaluation approaches. The conditions placed the experimenter in three roles, steward observer, overt observer, and covert observer, to measure the effect of experimenter presence and analyse the strengths and weaknesses of each approach.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3414–3425},
numpages = {12},
keywords = {public displays, in the wild methods, public evaluation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025798,
author = {M\"{a}kel\"{a}, Ville and Sharma, Sumita and Hakulinen, Jaakko and Heimonen, Tomi and Turunen, Markku},
title = {Challenges in Public Display Deployments: A Taxonomy of External Factors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025798},
doi = {10.1145/3025453.3025798},
abstract = {Public display deployments are often subjected to various surprising and unwanted effects. These effects are frequently due to external factors properties and phenomena that are unrelated to the deployment. Therefore, we conducted a literature review within the public display domain to investigate the causes behind the reported issues. This work presents a taxonomy of external factors affecting deployments, consisting of six categories: weather, events, surroundings, space, inhabitants, and vandalism. Apart from a few positive examples, we predominantly found negative effects arising from these factors. We then identified four ways of addressing the effects: ignoring, adapting, solving, and embracing. Of these, ignoring and adapting are substantially more frequent responses than solving and embracing emphasizing the need for researchers to adapt. We present real-world examples and insights on how researchers and practitioners can address the effects to better manage their deployments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3426–3475},
numpages = {50},
keywords = {challenges, taxonomy, deployments, pervasive displays, literature review, public displays, external factors},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025919,
author = {Candello, Heloisa and Pinhanez, Claudio and Figueiredo, Flavio},
title = {Typefaces and the Perception of Humanness in Natural Language Chatbots},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025919},
doi = {10.1145/3025453.3025919},
abstract = {How much do visual aspects influence the perception of users about whether they are conversing with a human being or a machine in a mobile-chat environment? This paper describes a study on the influence of typefaces using a blind Turing test-inspired approach. The study consisted of two user experiments. First, three different typefaces (OCR, Georgia, Helvetica) and three neutral dialogues between a human and a financial adviser were shown to participants. The second experiment applied the same study design but OCR font was substituted by Bradley font. For each of our two independent experiments, participants were shown three dialogue transcriptions and three typefaces counterbalanced. For each dialogue typeface pair, participants had to classify adviser conversations as human or chatbot-like. The results showed that machine-like typefaces biased users towards perceiving the adviser as machines but, unexpectedly, handwritten-like typefaces had not the opposite effect. Those effects were, however, influenced by the familiarity of the user to artificial intelligence and other participants' characteristics.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3476–3487},
numpages = {12},
keywords = {chatbots, user experience, typography, dialogue systems},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025830,
author = {Long, Kiel and Vines, John and Sutton, Selina and Brooker, Phillip and Feltwell, Tom and Kirman, Ben and Barnett, Julie and Lawson, Shaun},
title = {"Could You Define That in Bot Terms"? Requesting, Creating and Using Bots on Reddit},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025830},
doi = {10.1145/3025453.3025830},
abstract = {Bots are estimated to account for well over half of all web traffic, yet they remain an understudied topic in HCI. In this paper we present the findings of an analysis of 2284 submissions across three discussion groups dedicated to the request, creation and discussion of bots on Reddit. We set out to examine the qualities and functionalities of bots and the practical and social challenges surrounding their creation and use. Our findings highlight the prevalence of misunderstandings around the capabilities of bots, misalignments in discourse between novices who request and more expert members who create them, and the prevalence of requests that are deemed to be inappropriate for the Reddit community. In discussing our findings, we suggest future directions for the design and development of tools that support more carefully guided and reflective approaches to bot development for novices, and tools to support exploring the consequences of contextually-inappropriate bot ideas.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3488–3500},
numpages = {13},
keywords = {bots, online communities, Reddit, co-creation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025649,
author = {Komatsu, Takanori and Kobayashi, Kazuki and Yamada, Seiji and Funakoshi, Kotaro and Nakano, Mikio},
title = {Response Times When Interpreting Artificial Subtle Expressions Are Shorter than with Human-like Speech Sounds},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025649},
doi = {10.1145/3025453.3025649},
abstract = {Artificial subtle expressions (ASEs) are machine-like expressions used to convey a system's confidence level to users intuitively. In this paper, we focus on the cognitive loads of users in interpreting ASEs in this study. Specifically, we assume that a shorter response time indicates less cognitive load, and we hypothesize that users will show a shorter response time when interpreting ASEs compared with speech sounds. We succeeded in verifying our hypothesis in a web-based investigation done to comprehend participants' cognitive loads by measuring their response times in interpreting ASEs and speeches.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3501–3505},
numpages = {5},
keywords = {speech, artificial subtle expressions (ases), response time, cognitive loads},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025496,
author = {Xu, Anbang and Liu, Zhe and Guo, Yufan and Sinha, Vibha and Akkiraju, Rama},
title = {A New Chatbot for Customer Service on Social Media},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025496},
doi = {10.1145/3025453.3025496},
abstract = {Users are rapidly turning to social media to request and receive customer service; however, a majority of these requests were not addressed timely or even not addressed at all. To overcome the problem, we create a new conversational system to automatically generate responses for users requests on social media. Our system is integrated with state-of-the-art deep learning techniques and is trained by nearly 1M Twitter conversations between users and agents from over 60 brands. The evaluation reveals that over 40% of the requests are emotional, and the system is about as good as human agents in showing empathy to help users cope with emotional situations. Results also show our system outperforms information retrieval system based on both human judgments and an automatic evaluation metric.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3506–3510},
numpages = {5},
keywords = {social media, customer service, deep learning, chatbot},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025781,
author = {Gurari, Danna and Grauman, Kristen},
title = {CrowdVerge: Predicting If People Will Agree on the Answer to a Visual Question},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025781},
doi = {10.1145/3025453.3025781},
abstract = {Visual question answering systems empower users to ask any question about any image and receive a valid answer. However, existing systems do not yet account for the fact that a visual question can lead to a single answer or multiple different answers. While a crowd often agrees, disagreements do arise for many reasons including that visual questions are ambiguous, subjective, or difficult. We propose a model, CrowdVerge, for automatically predicting from a visual question whether a crowd would agree on one answer. We then propose how to exploit these predictions in a novel application to efficiently collect all valid answers to visual questions. Specifically, we solicit fewer human responses when answer agreement is expected and more human responses otherwise. Experiments on 121,811 visual questions asked by sighted and blind people show that, compared to existing crowdsourcing systems, our system captures the same answer diversity with typically 14-23% less crowd involvement.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3511–3522},
numpages = {12},
keywords = {crowdsourcing, machine learning, visual question answering},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025811,
author = {Valentine, Melissa A. and Retelny, Daniela and To, Alexandra and Rahmati, Negar and Doshi, Tulsee and Bernstein, Michael S.},
title = {Flash Organizations: Crowdsourcing Complex Work by Structuring Crowds As Organizations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025811},
doi = {10.1145/3025453.3025811},
abstract = {This paper introduces flash organizations: crowds structured like organizations to achieve complex and open-ended goals. Microtask workflows, the dominant crowdsourcing structures today, only enable goals that are so simple and modular that their path can be entirely pre-defined. We present a system that organizes crowd workers into computationally-represented structures inspired by those used in organizations - roles, teams, and hierarchies - which support emergent and adaptive coordination toward open-ended goals. Our system introduces two technical contributions: 1) encoding the crowd's division of labor into de-individualized roles, much as movie crews or disaster response teams use roles to support coordination between on-demand workers who have not worked together before; and 2) reconfiguring these structures through a model inspired by version control, enabling continuous adaptation of the work and the division of labor. We report a deployment in which flash organizations successfully carried out open-ended and complex goals previously out of reach for crowdsourcing, including product design, software development, and game production. This research demonstrates digitally networked organizations that flexibly assemble and reassemble themselves from a globally distributed online workforce to accomplish complex work.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3523–3537},
numpages = {15},
keywords = {flash organizations, crowdsourcing, expert crowd work},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025867,
author = {Park, Sangkeun and Ilincai, Emilia-Stefania and Oh, Jeungmin and Kwon, Sujin and Mizouni, Rabeb and Lee, Uichin},
title = {Facilitating Pervasive Community Policing on the Road with Mobile Roadwatch},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025867},
doi = {10.1145/3025453.3025867},
abstract = {We consider community policing on the road with pervasive recording technologies such as dashcams and smartphones where citizens are actively volunteering to capture and report various threats to traffic safety to the police via mobile apps. This kind of novel community policing has recently gained significant popularity in Korea and India. In this work, we identify people's general attitude and concerns toward community policing on the road through an online survey. We then address the major concerns by building a mobile app that supports easy event capture/access, context tagging, and privacy preservation. Our two-week user study (n = 23) showed Roadwatch effectively supported community policing activities on the road. Further, we found that the critical factors for reporting are personal involvement and seriousness of risks, and participants were mainly motivated by their contribution to traffic safety. Finally, we discuss several practical design implications to facilitate community policing on the road.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3538–3550},
numpages = {13},
keywords = {privacy, mobile, community policing, traffic, neighborhood watch},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025969,
author = {Chen, Chen and Meng, Xiaojun and Zhao, Shengdong and Fjeld, Morten},
title = {ReTool: Interactive Microtask and Workflow Design through Demonstration},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025969},
doi = {10.1145/3025453.3025969},
abstract = {In addition to simple form filling, there is an increasing need for crowdsourcing workers to perform freeform interactions directly on content in microtask crowdsourcing (e.g. proofreading articles or specifying object boundary in an image). Such microtasks are often organized within well-designed workflows to optimize task quality and workload distribution. However, designing and implementing the interface and workflow for such microtasks is challenging because it typically requires programming knowledge and tedious manual effort. We present ReTool, a web-based tool for requesters to design and publish interactive microtasks and workflows by demonstrating the microtasks for text and image content. We evaluated ReTool against a task-design tool from a popular crowdsourcing platform and showed the advantages of ReTool over the existing approach.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3551–3556},
numpages = {6},
keywords = {retool, programming by demonstration, workflow, freeform interactive microtasks, crowdsourcing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025538,
author = {Cecchinato, Marta E. and Cox, Anna L. and Bird, Jon},
title = {Always On(Line)? User Experience of Smartwatches and Their Role within Multi-Device Ecologies},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025538},
doi = {10.1145/3025453.3025538},
abstract = {Users have access to a growing ecosystem of devices (desktop, mobile and wearable) that can deliver notifications and help people to stay in contact. Smartwatches are gaining popularity, yet little is known about the user experience and their impact on our increasingly always online culture. We report on a qualitative study with existing users on their everyday use of smartwatches to understand both the added value and the challenges of being constantly connected at the wrist. Our findings show that users see a large benefit in receiving notifications on their wrist, especially in terms of helping manage expectations of availability. Moreover, we find that response rates after viewing a notification on a smartwatch change based on the other devices available: laptops prompt quicker replies than smartphones. Finally, there are still many costs associated with using smartwatches, thus we make a series of design recommendations to improve the user experience of smartwatches.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3557–3568},
numpages = {12},
keywords = {user experience, notifications, wearable, autoethnography, smartwatches, device ecologies, multi-device experience, cross-device interaction, context-aware},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025817,
author = {Visuri, Aku and Sarsenbayeva, Zhanna and van Berkel, Niels and Goncalves, Jorge and Rawassizadeh, Reza and Kostakos, Vassilis and Ferreira, Denzil},
title = {Quantifying Sources and Types of Smartwatch Usage Sessions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025817},
doi = {10.1145/3025453.3025817},
abstract = {We seek to quantify smartwatch use, and establish differences and similarities to smartphone use. Our analysis considers use traces from 307 users that include over 2.8 million notifications and 800,000 screen usage events, and we compare our findings to previous work that quantifies smartphone use. The results show that smartwatches are used more briefly and more frequently throughout the day, with half the sessions lasting less than 5 seconds. Interaction with notifications is similar across both types of devices, both in terms of response times and preferred application types. We also analyse the differences between our smartwatch dataset and a dataset aggregated from four previously conducted smartphone studies. The similarities and differences between smartwatch and smartphone use suggest effect on usage that go beyond differences in form factor.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3569–3581},
numpages = {13},
keywords = {session, smartphones, interactions, applications, usage, smartwatches},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025993,
author = {McMillan, Donald and Brown, Barry and Lampinen, Airi and McGregor, Moira and Hoggan, Eve and Pizza, Stefania},
title = {Situating Wearables: Smartwatch Use in Context},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025993},
doi = {10.1145/3025453.3025993},
abstract = {Drawing on 168 hours of video recordings of smartwatch use, this paper studies how context influences smartwatch use. We explore the effects of the presence of others, activity, location and time of day on 1,009 instances of use. Watch interaction is significantly shorter when in conversation than when alone. Activity also influences watch use with significantly longer use while eating than when socialising or performing domestic tasks. One surprising finding is that length of use is similar at home and work. We note that usage peaks around lunchtime, with an average of 5.3 watch uses per hour throughout a day. We supplement these findings with qualitative analysis of the videos, focusing on how use is modified by the presence of others, and the lack of impact of watch glances on conversation. Watch use is clearly a context-sensitive activity and in discussion we explore how smartwatches could be designed taking this into consideration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3582–3594},
numpages = {13},
keywords = {wearable, video analysis, smartwatch},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026021,
author = {Cambo, Scott A. and Avrahami, Daniel and Lee, Matthew L.},
title = {BreakSense: Combining Physiological and Location Sensing to Promote Mobility during Work-Breaks},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026021},
doi = {10.1145/3025453.3026021},
abstract = {Work breaks can play an important role in the mental and physical well-being of workers and contribute positively to productivity. In this paper we explore the use of activity-, physiological-, and indoor-location sensing to promote mobility during work-breaks. While the popularity of devices and applications to promote physical activity is growing, prior research highlights important constraints when designing for the workplace. With these constraints in mind, we developed BreakSense, a mobile application that uses a Bluetooth beacon infrastructure, a smartphone and a smartwatch to encourage mobility during breaks with a game-like design. We discuss constraints imposed by design for work and the workplace, and highlight challenges associated with the use of noisy sensors and methods to overcome them. We then describe a short deployment of BreakSense within our lab that examined bound vs. unbound augmented breaks and how they affect users' sense of completion and readiness to work.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3595–3607},
numpages = {13},
keywords = {activity recognition, workplace, wellbeing, context aware, work breaks, indoor location},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025694,
author = {Bopp, Chris and Harmon, Ellie and Voida, Amy},
title = {Disempowered by Data: Nonprofits, Social Enterprises, and the Consequences of Data-Driven Work},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025694},
doi = {10.1145/3025453.3025694},
abstract = {Organizations across many sectors are under intense pressure to become data-driven. Yet, for mission-driven organizations, the path to becoming and value of being data-driven is not always clear. We present results from an interview-based study of the role of data in the monitoring and evaluation practices of mission-driven organizations. Instead of leading to productive and empowering data-driven decision making, monitoring and evaluation work is characterized by the erosion of autonomy, data drift, and data fragmentation. Together, these consequences of monitoring and evaluation practices play into a cycle of increasing disempowerment for the mission-driven organization. These findings suggest that the design of information systems should work towards empowering organizations in ways that make sense for their unique data needs and those of their constituents.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3608–3619},
numpages = {12},
keywords = {mission-driven, accountability, nonprofit organization, data, social enterprise, metrics, monitoring and evaluation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025847,
author = {Dasgupta, Sayamindu and Hill, Benjamin Mako},
title = {Scratch Community Blocks: Supporting Children as Data Scientists},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025847},
doi = {10.1145/3025453.3025847},
abstract = {In this paper, we present Scratch Community Blocks, a new system that enables children to programmatically access, analyze, and visualize data about their participation in Scratch, an online community for learning computer programming. At its core, our approach involves a shift in who analyzes data: from adult data scientists to young learners themselves. We first introduce the goals and design of the system and then demonstrate it by describing example projects that illustrate its functionality. Next, we show through a series of case studies how the system engages children in not only representing data and answering questions with data but also in self-reflection about their own learning and participation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3620–3631},
numpages = {12},
keywords = {computers and children, block-based programming, social computing and social navigation, learning, creativity support tools, data science},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025892,
author = {Tolmie, Peter and Procter, Rob and Randall, David William and Rouncefield, Mark and Burger, Christian and Wong Sak Hoi, Geraldine and Zubiaga, Arkaitz and Liakata, Maria},
title = {Supporting the Use of User Generated Content in Journalistic Practice},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025892},
doi = {10.1145/3025453.3025892},
abstract = {Social media and user-generated content (UGC) are increasingly important features of journalistic work in a number of different ways. However, their use presents major challenges, not least because information posted on social media is not always reliable and therefore its veracity needs to be checked before it can be considered as fit for use in the reporting of news. We report on the results of a series of in-depth ethnographic studies of journalist work practices undertaken as part of the requirements gathering for a prototype of a social media verification 'dashboard' and its subsequent evaluation. We conclude with some reflections upon the broader implications of our findings for the design of tools to support journalistic work.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3632–3644},
numpages = {13},
keywords = {social media verification, dashboard design, collaborative work practices, ethnography, journalism},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025738,
author = {Boukhelifa, Nadia and Perrin, Marc-Emmanuel and Huron, Samuel and Eagan, James},
title = {How Data Workers Cope with Uncertainty: A Task Characterisation Study},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025738},
doi = {10.1145/3025453.3025738},
abstract = {Uncertainty plays an important and complex role in data analysis, where the goal is to find pertinent patterns, build robust models, and support decision making. While these endeavours are often associated with professional data scientists, many domain experts engage in such activities with varying skill levels. To understand how these domain experts (or "data workers") analyse uncertain data we conducted a qualitative user study with 12 participants from a variety of domains. In this paper, we describe their various coping strategies to understand, minmise, exploit or even ignore this uncertainty. The choice of the coping strategy is influenced by accepted domain practices, but appears to depend on the types and sources of uncertainty and whether participants have access to support tools. Based on these findings, we propose a new process model of how data workers analyse various types of uncertain data and conclude with design considerations for uncertainty-aware data analytics.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3645–3656},
numpages = {12},
keywords = {uncertainty, data science, qualitative study, data analysis},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025491,
author = {Peek, Nadya and Coleman, James and Moyer, Ilan and Gershenfeld, Neil},
title = {Cardboard Machine Kit: Modules for the Rapid Prototyping of Rapid Prototyping Machines},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025491},
doi = {10.1145/3025453.3025491},
abstract = {Digital fabrication machines (such as laser cutters or 3D printers) can be instructed to produce any part geometry within their application space. However, machines' application spaces are not easily modified or extended. How can we enable the production of application-specific computer-controlled machines by machine building novices? How can we facilitate rapid prototyping of rapid prototyping tools? We propose a novel set of modules, the Cardboard Machine Kit, for the construction of digital fabrication machines. These open-source modules are implemented using cardboard frames, stepper motors, and networked electronics controlled through a Python library. We evaluated the kit both through machine building workshops and by studying the usage of the kit in the wild. In the wild we observed more than 500 novice machine builders who built 125 different machines for 15 different application types. We argue that this breadth demonstrates the efficacy of this modular approach. Finally we discuss the limitations of the Cardboard Machine Kit and discuss how it could inform future machine building infrastructure.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3657–3668},
numpages = {12},
keywords = {prototyping, CAD/CAM, digital fabrication, machine building, CNC, cardboard},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025898,
author = {Sareen, Harpreet and Umapathi, Udayan and Shin, Patrick and Kakehi, Yasuaki and Ou, Jifei and Ishii, Hiroshi and Maes, Pattie},
title = {Printflatables: Printing Human-Scale, Functional and Dynamic Inflatable Objects},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025898},
doi = {10.1145/3025453.3025898},
abstract = {Printflatables is a design and fabrication system for human-scale, functional and dynamic inflatable objects. We use inextensible thermoplastic fabric as the raw material with the key principle of introducing folds and thermal sealing. Upon inflation, the sealed object takes the expected three dimensional shape. The workflow begins with the user specifying an intended 3D model which is decomposed to two dimensional fabrication geometry. This forms the input for a numerically controlled thermal contact iron that seals layers of thermoplastic fabric. In this paper, we discuss the system design in detail, the pneumatic primitives that this technique enables and merits of being able to make large, functional and dynamic pneumatic artifacts. We demonstrate the design output through multiple objects which could motivate fabrication of inflatable media and pressure-based interfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3669–3680},
numpages = {12},
keywords = {3D printing, digital fabrication, radical atoms, shape changing, inflatables, human-material interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025774,
author = {Bucci, Paul and Cang, Xi Laura and Valair, Anasazi and Marino, David and Tseng, Lucia and Jung, Merel and Rantala, Jussi and Schneider, Oliver S. and MacLean, Karon E.},
title = {Sketching CuddleBits: Coupled Prototyping of Body and Behaviour for an Affective Robot Pet},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025774},
doi = {10.1145/3025453.3025774},
abstract = {Social robots that physically display emotion invite natural communication with their human interlocutors, enabling applications like robot-assisted therapy where a complex robot's breathing influences human emotional and physiological state. Using DIY fabrication and assembly, we explore how simple 1-DOF robots can express affect with economy and user customizability, leveraging open-source designs.We developed low-cost techniques for coupled iteration of a simple robot's body and behaviour, and evaluated its potential to display emotion. Through two user studies, we (1) validated these CuddleBits' ability to express emotions (N=20); (2) sourced a corpus of 72 robot emotion behaviours from participants (N=10); and (3) analyzed it to link underlying parameters to emotional perception (N=14).We found that CuddleBits can express arousal (activation), and to a lesser degree valence (pleasantness). We also show how a sketch-refine paradigm combined with DIY fabrication and novel input methods enable parametric design of physical emotion display, and discuss how mastering this parsimonious case can give insight into layering simple behaviours in more complex robots.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3681–3692},
numpages = {12},
keywords = {do-it-yourself (DIY), affective computing, human-robot interaction (HRI), physical prototyping, haptics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025792,
author = {Yue, Ya-Ting and Zhang, Xiaolong and Yang, Yongliang and Ren, Gang and Choi, Yi-King and Wang, Wenping},
title = {WireDraw: 3D Wire Sculpturing Guided with Mixed Reality},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025792},
doi = {10.1145/3025453.3025792},
abstract = {The availability of commodity 3D extruder pen allows direct drawing of 3D wire sculptures for novice users, enabling many novel applications such as intuitive spatial intelligence development for school students. However, the lack of spatial and structural cues among individual pen strokes makes the 3D drawing process challenging, which often leads to highly distorted and even incomplete wire sculptures. We present a mixed reality system, called `WireDraw', to immersively guide the 3D drawing for easy wire sculpturing. The system design is based on novel 3D drawing principles and the subsequent optimization, making the stroke sequence of the wire model drawable and easy to draw. On-the-fly edits on unsatisfactory strokes are also allowed for creative design. We demonstrate the effectiveness of our system by testing on a variety of wire models and a user study. The results show that the visual guidance provided by our system is extremely helpful for drawing high-quality wire sculptures.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3693–3704},
numpages = {12},
keywords = {drawing optimization, wire sculpture, mixed reality, 3D extruder pen, stroke generation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025782,
author = {Spelmezan, Daniel and Sahoo, Deepak Ranjan and Subramanian, Sriram},
title = {Sparkle: Hover Feedback with Touchable Electric Arcs},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025782},
doi = {10.1145/3025453.3025782},
abstract = {Many finger sensing input devices now support proximity input, enabling users to perform in-air gestures. While near-surface interactions increase the input vocabulary, they lack tactile feedback, making it hard for users to perform gestures or to know when the interaction takes place. Sparkle stimulates the fingertip with touchable electric arcs above a hover sensing device to give users in-air tactile or thermal feedback, sharper and more feelable than acoustic mid-air haptic devices. We present the design of a high voltage resonant transformer with a low-loss soft ferrite core and self-tuning driver circuit, with which we create electric arcs 6 mm in length, and combine this technology with infrared proximity sensing in two proof-of-concept devices with form factor and functionality similar to a button and a touchpad. We provide design guidelines for Sparkle devices and examples of stimuli in application scenarios, and report the results of a user study on the perceived sensations. Sparkle is the first step towards providing a new type of hover feedback, and it does not require users to wear tactile stimulators.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3705–3717},
numpages = {13},
keywords = {electric discharge, hover input, infrared proximity sensor., in-air feedback, high voltage resonant transformer},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025753,
author = {Cheng, Lung-Pan and Ofek, Eyal and Holz, Christian and Benko, Hrvoje and Wilson, Andrew D.},
title = {Sparse Haptic Proxy: Touch Feedback in Virtual Environments Using a General Passive Prop},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025753},
doi = {10.1145/3025453.3025753},
abstract = {We propose a class of passive haptics that we call Sparse Haptic Proxy: a set of geometric primitives that simulate touch feedback in elaborate virtual reality scenes. Unlike previous passive haptics that replicate the virtual environment in physical space, a Sparse Haptic Proxy simulates a scene's detailed geometry by redirecting the user's hand to a matching primitive of the proxy. To bridge the divergence of the scene from the proxy, we augment an existing Haptic Retargeting technique with an on-the-fly target remapping: We predict users' intentions during interaction in the virtual space by analyzing their gaze and hand motions, and consequently redirect their hand to a matching part of the proxy. We conducted three user studies on haptic retargeting technique and implemented a system from three main results: 1) The maximum angle participants found acceptable for retargeting their hand is 40°, with an average rating of 4.6 out of 5. 2) Tracking participants' eye gaze reliably predicts their touch intentions (97.5%), even while simultaneously manipulating the user's hand-eye coordination for retargeting. 3) Participants preferred minimized retargeting distances over better-matching surfaces of our Sparse Haptic Proxy when receiving haptic feedback for single-finger touch input. We demonstrate our system with two virtual scenes: a flight cockpit and a room quest game. While their scene geometries differ substantially, both use the same sparse haptic proxy to provide haptic feedback to the user during task completion.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3718–3728},
numpages = {11},
keywords = {perception, retargeting, passive haptics, virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025684,
author = {Kaul, Oliver Beren and Rohs, Michael},
title = {HapticHead: A Spherical Vibrotactile Grid around the Head for 3D Guidance in Virtual and Augmented Reality},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025684},
doi = {10.1145/3025453.3025684},
abstract = {Current virtual and augmented reality head-mounted displays usually include no or only a single vibration motor for haptic feedback and do not use it for guidance. We present HapticHead, a system utilizing multiple vibrotactile actuators distributed in three concentric ellipses around the head for intuitive haptic guidance through moving tactile cues. We conducted three experiments, which indicate that HapticHead vibrotactile feedback is both faster (2.6 s vs. 6.9 s) and more precise (96.4% vs. 54.2% success rate) than spatial audio (generic head-related transfer function) for finding visible virtual objects in 3D space around the user. The baseline of visual feedback is as expected more precise (99.7% success rate) and faster (1.3 s) in comparison, but there are many applications in which visual feedback is not desirable or available due to lighting conditions, visual overload, or visual impairments. Mean final precision with HapticHead feedback on invisible targets is 2.3° compared to 0.8° with visual feedback. We successfully navigated blindfolded users to real household items at different heights using HapticHead vibrotactile feedback independently of a head-mounted display.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3729–3740},
numpages = {12},
keywords = {3d output, guidance, vibrotactile, spatial interaction, navigation, augmented reality, haptic feedback, virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025894,
author = {Morales Gonz\'{a}lez, Rafael and Appert, Caroline and Bailly, Gilles and Pietriga, Emmanuel},
title = {Passive yet Expressive TouchTokens},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025894},
doi = {10.1145/3025453.3025894},
abstract = {TouchTokens are passive tokens that can be recognized on any capacitive surface based on the spatial configuration of the fingers that hold them. However, interaction with these tokens is confined to the basic two-state model of touch interaction as the system only knows the tokens' position and cannot detect tokens that are not touched. We increase the expressive power of TouchTokens by introducing laser-cut lattice hinges in their design, so as to make them flexible. A new recognizer, that analyzes the micro-movements of the fingers that hold the tokens, enables the system to detect when a token is left on the surface rather than taken off it. It can also detect bend events that can be mapped to command triggers, and a squeezed state that can be used for quasi-modal interaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3741–3745},
numpages = {5},
keywords = {tangible interaction, multi-touch input, micro-movements},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025555,
author = {Wang, Qinglong and Ren, Xiangshi and Sun, Xiaoying},
title = {Enhancing Pen-Based Interaction Using Electrovibration and Vibration Haptic Feedback},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025555},
doi = {10.1145/3025453.3025555},
abstract = {This paper presents the EV2-Pen which leverages electrovibration technology and vibration technology in pen interaction. Electrovibration technology can produce multisensory feedback when the pen is in motion (sliding/moving on the screen), and vibration technology can provide vibrative feedback when the pen is stationary (pointing/resting on the screen). We conducted an experiment to investigate user performance with the EV2-Pen. The results indicated that the EV2-Pen outperformed the EV-Pen [18, 19] in pointing-steering tasks. Finally, we discuss the characteristics of the EV2-Pen, and explore some possible applications and scenarios.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3746–3750},
numpages = {5},
keywords = {electrovibration, haptic feedback, pen-based interaction, vibration},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025461,
author = {Abdelrahman, Yomna and Khamis, Mohamed and Schneegass, Stefan and Alt, Florian},
title = {Stay Cool! Understanding Thermal Attacks on Mobile-Based User Authentication},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025461},
doi = {10.1145/3025453.3025461},
abstract = {PINs and patterns remain among the most widely used knowledge-based authentication schemes. As thermal cameras become ubiquitous and affordable, we foresee a new form of threat to user privacy on mobile devices. Thermal cameras allow performing thermal attacks, where heat traces, resulting from authentication, can be used to reconstruct passwords. In this work we investigate in details the viability of exploiting thermal imaging to infer PINs and patterns on mobile devices. We present a study (N=18) where we evaluated how properties of PINs and patterns influence their thermal attacks resistance. We found that thermal attacks are indeed viable on mobile devices; overlapping patterns significantly decrease successful thermal attack rate from 100% to 16.67%, while PINs remain vulnerable (&gt;72% success rate) even with duplicate digits. We conclude by recommendations for users and designers of authentication schemes on how to resist thermal attacks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3751–3763},
numpages = {13},
keywords = {touchscreens, mobile authentication, thermal imaging},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025991,
author = {Das, Sauvik and Laput, Gierad and Harrison, Chris and Hong, Jason I.},
title = {Thumprint: Socially-Inclusive Local Group Authentication Through Shared Secret Knocks},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025991},
doi = {10.1145/3025453.3025991},
abstract = {Small, local groups who share protected resources (e.g., families, work teams, student organizations) have unmet authentication needs. For these groups, existing authentication strategies either create unnecessary social divisions (e.g., biometrics), do not identify individuals (e.g., shared passwords), do not equitably distribute security responsibility (e.g., individual passwords), or make it difficult to share or revoke access (e.g., physical keys). To explore an alternative, we designed Thumprint: inclusive group authentication with a shared secret knock. All group members share one secret knock, but individual expressions of the secret are discernible. We evaluated the usability and security of our concept through two user studies with 30 participants. Our results suggest that (1) individuals who enter the same shared thumprint are distinguishable from one another, (2) that people can enter thumprints consistently over time, and (3) that thumprints are resilient to casual adversaries.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3764–3774},
numpages = {11},
keywords = {socially-inclusive authentication, sensors, authentication, usable security, social cybersecurity, hci},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026050,
author = {Ur, Blase and Alfieri, Felicia and Aung, Maung and Bauer, Lujo and Christin, Nicolas and Colnago, Jessica and Cranor, Lorrie Faith and Dixon, Henry and Emami Naeini, Pardis and Habib, Hana and Johnson, Noah and Melicher, William},
title = {Design and Evaluation of a Data-Driven Password Meter},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026050},
doi = {10.1145/3025453.3026050},
abstract = {Despite their ubiquity, many password meters provide inaccurate strength estimates. Furthermore, they do not explain to users what is wrong with their password or how to improve it. We describe the development and evaluation of a data-driven password meter that provides accurate strength measurement and actionable, detailed feedback to users. This meter combines neural networks and numerous carefully combined heuristics to score passwords and generate data-driven text feedback about the user's password. We describe the meter's iterative development and final design. We detail the security and usability impact of the meter's design dimensions, examined through a 4,509-participant online study. Under the more common password-composition policy we tested, we found that the data-driven meter with detailed feedback led users to create more secure, and no less memorable, passwords than a meter with only a bar as a strength indicator.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3775–3786},
numpages = {12},
keywords = {feedback, data-driven, usable security, meter, passwords},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025733,
author = {Tan, Joshua and Bauer, Lujo and Bonneau, Joseph and Cranor, Lorrie Faith and Thomas, Jeremy and Ur, Blase},
title = {Can Unicorns Help Users Compare Crypto Key Fingerprints?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025733},
doi = {10.1145/3025453.3025733},
abstract = {Many authentication schemes ask users to manually compare compact representations of cryptographic keys, known as fingerprints. If the fingerprints do not match, that may signal a man-in-the-middle attack. An adversary performing an attack may use a fingerprint that is similar to the target fingerprint, but not an exact match, to try to fool inattentive users. Fingerprint representations should thus be both usable and secure. We tested the usability and security of eight fingerprint representations under different configurations. In a 661-participant between-subjects experiment, participants compared fingerprints under realistic conditions and were subjected to a simulated attack. The best configuration allowed attacks to succeed 6% of the time; the worst 72%. We find the seemingly effective compare-and-select approach performs poorly for key fingerprints and that graphical fingerprint representations, while intuitive and fast, vary in performance. We identify some fingerprint representations as particularly promising.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3787–3798},
numpages = {12},
keywords = {key fingerprints, usability, authentication, secure messaging},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025903,
author = {Gonz\'{a}lez Caba\~{n}as, Jos\'{e} and Cuevas, \'{A}ngel and Cuevas, Rub\'{e}n},
title = {FDVT: Data Valuation Tool for Facebook Users},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025903},
doi = {10.1145/3025453.3025903},
abstract = {The OECD, the European Union and other public and private initiatives are claiming for the necessity of tools that create awareness among Internet users about the monetary value associated to the commercial exploitation of their online personal information. This paper presents the first tool addressing this challenge, the Facebook Data Valuation Tool (FDVT). The FDVT provides Facebook users with a personalized and real-time estimation of the revenue they generate for Facebook. Relying on the FDVT, we are able to shed light into several relevant HCI research questions that require a data valuation tool in place. The obtained results reveal that (i) there exists a deep lack of awareness among Internet users regarding the monetary value of personal information, (ii) data valuation tools such as the FDVT are useful means to reduce such knowledge gap, (iii) 1/3 of the users testing the FDVT show a substantial engagement with the tool.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3799–3809},
numpages = {11},
keywords = {facebook, data valuation, personal data, privacy, FDVT},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025901,
author = {Usmani, Wali Ahmed and Marques, Diogo and Beschastnikh, Ivan and Beznosov, Konstantin and Guerreiro, Tiago and Carri\c{c}o, Lu\'{\i}s},
title = {Characterizing Social Insider Attacks on Facebook},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025901},
doi = {10.1145/3025453.3025901},
abstract = {Facebook accounts are secured against unauthorized access through passwords and device-level security. Those defenses, however, may not be sufficient to prevent social insider attacks, where attackers know their victims, and gain access to a victim's account by interacting directly with their device. To characterize these attacks, we ran two MTurk studies. In the first (n = 1,308), using the list experiment method, we estimated that 24% of participants had perpetrated social insider attacks and that 21% had been victims (and knew about it). In the second study (n = 45), participants wrote stories detailing personal experiences with such attacks. Using thematic analysis, we typified attacks around five motivations (fun, curiosity, jealousy, animosity, and utility), and explored dimensions associated with each type. Our combined findings indicate that social insider attacks are common, often have serious emotional consequences, and have no simple mitigation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3810–3820},
numpages = {11},
keywords = {facebook, privacy, insider attack, usable security},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025668,
author = {Such, Jose M. and Porter, Joel and Preibusch, S\"{o}ren and Joinson, Adam},
title = {Photo Privacy Conflicts in Social Media: A Large-Scale Empirical Study},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025668},
doi = {10.1145/3025453.3025668},
abstract = {Items in social media such as photos may be co-owned by multiple users, i.e., the sharing decisions of the ones who upload them have the potential to harm the privacy of the others. Previous works uncovered coping strategies by co-owners to manage their privacy, but mainly focused on general practices and experiences. We establish an empirical base for the prevalence, context and severity of privacy conflicts over co-owned photos. To this aim, a parallel survey of pre-screened 496 uploaders and 537 co-owners collected occurrences and type of conflicts over co-owned photos, and any actions taken towards resolving them. We uncover nuances and complexities not known before, including co-ownership types, and divergences in the assessment of photo audiences. We also find that an all-or-nothing approach seems to dominate conflict resolution, even when parties actually interact and talk about the conflict. Finally, we derive key insights for designing systems to mitigate these divergences and facilitate consensus.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3821–3832},
numpages = {12},
keywords = {conflicts, privacy, online social networks, social media, co-ownership, photo sharing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025698,
author = {Bullek, Brooke and Garboski, Stephanie and Mir, Darakhshan J. and Peck, Evan M.},
title = {Towards Understanding Differential Privacy: When Do People Trust Randomized Response Technique?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025698},
doi = {10.1145/3025453.3025698},
abstract = {As a consequence of living in a data ecosystem, we often relinquish personal information to be used in contexts in which we have no control. In this paper, we begin to examine the usability of differential privacy, a mechanism that proposes to promise privacy with a mathematical "proof" to the data donor. Do people trust this promise and adjust their privacy decisions if the interfaces through which they interact make differential privacy less opaque? In a study with 228 participants, we measured comfort, understanding, and trust using a variant of differential privacy known as Randomized Response Technique (RRT). We found that allowing individuals to see the amount of obfuscation applied to their responses increased their trust in the privacy-protecting mechanism. However, participants who associated obfuscating privacy mechanisms with deception did not make the "safest" privacy decisions, even as they demonstrated an understanding of RRT. We demonstrate that prudent privacy-related decisions can be cultivated with simple explanations of usable privacy.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3833–3837},
numpages = {5},
keywords = {user-centered differential privacy, randomized response},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025925,
author = {Hoyle, Roberto and Das, Srijita and Kapadia, Apu and Lee, Adam J. and Vaniea, Kami},
title = {Was My Message Read? Privacy and Signaling on Facebook Messenger},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025925},
doi = {10.1145/3025453.3025925},
abstract = {Major online messaging services such as Facebook Messenger and WhatsApp are starting to provide users with real-time information about when people read their messages, while useful, the feature has the potential to negatively impact privacy as well as cause concern over access to self. We report on two surveys using Mechanical Turk which looked at senders' (N=402) use of and reactions to the `message seen' feature, and recipients' (N=316) privacy and signaling behaviors in the face of such visibility. Our findings indicate that senders experience a range of emotions when their message is not read, or is read but not answered immediately. Recipients also engage in various signaling behaviors in the face of visibility by both replying or not replying immediately.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3838–3842},
numpages = {5},
keywords = {social networks, anonymous access, privacy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025497,
author = {Uddin, Md. Sami and Gutwin, Carl and Cockburn, Andy},
title = {The Effects of Artificial Landmarks on Learning and Performance in Spatial-Memory Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025497},
doi = {10.1145/3025453.3025497},
abstract = {Spatial memory is a powerful way for users to become expert with an interface, because remembering item locations means that users do not have to carry out slow visual search. Spatial learning in the real world benefits greatly from landmarks in the environment, but user interfaces often provide very few visual landmarks. In this paper we explore the use of artificial landmarks as a way to improve people's spatial memory in spatially-stable grid menus called CommandMaps. We carried out three studies to test the effects of three types of artificial landmarks (standard grid, simple anchor marks, and a transparent image) on spatial learning. We found that for small grid menus, the artificial landmarks had little impact on performance, whereas for medium and large grids, the simple anchor marks significantly improved performance. The simple visual anchors were faster and less error-prone than the visually richer transparent image. Our studies show that artificial landmarks can be a valuable addition to spatial interfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3843–3855},
numpages = {13},
keywords = {landmarks, expertise, command selection, spatial memory},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026055,
author = {Verma, Himanshu and Alavi, Hamed S. and Lalanne, Denis},
title = {Studying Space Use: Bringing HCI Tools to Architectural Projects},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026055},
doi = {10.1145/3025453.3026055},
abstract = {Understanding how people use different spaces in a building can inform design interventions aimed at improving the utility of that building, but can also inform the design of future buildings. We studied space use in an office building following a method we have designed to reveal the occupancy rate and navigational patterns. Our method involves two key components: 1) a pervasive sensing system that is scalable for large buildings, and high number of occupants, and 2) participatory data analysis engaging stakeholders including interior architects and building performance engineers, to refine the questions and define the needs for further analyses through multiple iterations.In this paper, we describe our method in detail, and exemplify how HCI methods and approaches can contribute to professional building design projects.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3856–3866},
numpages = {11},
keywords = {human-building interaction, post-occupancy evaluation, participatory data analysis, hci in architecture},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025728,
author = {Dye, Michaelanne and Nemer, David and Pina, Laura R. and Sambasivan, Nithya and Bruckman, Amy S. and Kumar, Neha},
title = {Locating the Internet in the Parks of Havana},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025728},
doi = {10.1145/3025453.3025728},
abstract = {Since March 2015, the public squares of Havana have been transformed from places where people stroll and children play to places where crowds gather to try to connect to the internet at all hours of the day and night. We present a field investigation of public WiFi hotspots in Havana, Cuba, and examine the possibilities of internet access these limited and expensive hotspots present to individuals, many of who are experiencing the internet for the first time. Drawing on fieldwork conducted in 2015-2016, we underscore the reconfigurations that have resulted from this access, as evolving internet users reconfigure their interactions with place, time, and individuals in their efforts to locate the internet. We also discuss the implications our findings have for the design of internet access interventions in Cuba and in other low-resource environments across the world, as well as the broader implications for social computing across diverse geographies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3867–3878},
numpages = {12},
keywords = {social computing, place, internet, hci4d, cuba, wifi},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025561,
author = {Gil, Hyunjae and Lee, DoYoung and Im, Seunggyu and Oakley, Ian},
title = {TriTap: Identifying Finger Touches on Smartwatches},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025561},
doi = {10.1145/3025453.3025561},
abstract = {The small screens of smartwatches provide limited space for input tasks. Finger identification is a promising technique to address this problem by associating different functions with different fingers. However, current technologies for finger identification are unavailable or unsuitable for smartwatches. To address this problem, this paper observes that normal smartwatch use takes places with a relatively static pose between the two hands. In this situation, we argue that the touch and angle profiles generated by different fingers on a standard smartwatch touch screen will differ sufficiently to support reliable identification. The viability of this idea is explored in two studies that capture touches in natural and exaggerated poses during tapping and swiping tasks. Machine learning models report accuracies of up to 93% and 98% respectively, figures that are sufficient for many common interaction tasks. Furthermore, the exaggerated poses show modest costs (in terms of time/errors) compared to the natural touches. We conclude by presenting examples and discussing how interaction designs using finger identification can be adapted to the smartwatch form factor.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3879–3890},
numpages = {12},
keywords = {finger identification, smartwatch, touch contact profile},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026005,
author = {Sridhar, Srinath and Markussen, Anders and Oulasvirta, Antti and Theobalt, Christian and Boring, Sebastian},
title = {WatchSense: On- and Above-Skin Input Sensing through a Wearable Depth Sensor},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026005},
doi = {10.1145/3025453.3026005},
abstract = {This paper contributes a novel sensing approach to support on- and above-skin finger input for interaction on the move. WatchSense uses a depth sensor embedded in a wearable device to expand the input space to neighboring areas of skin and the space above it. Our approach addresses challenging camera-based tracking conditions, such as oblique viewing angles and occlusions. It can accurately detect fingertips, their locations, and whether they are touching the skin or hovering above it. It extends previous work that supported either mid-air or multitouch input by simultaneously supporting both. We demonstrate feasibility with a compact, wearable prototype attached to a user's forearm (simulating an integrated depth sensor). Our prototype---which runs in real-time on consumer mobile devices---enables a 3D input space on the back of the hand. We evaluated the accuracy and robustness of the approach in a user study. We also show how WatchSense increases the expressiveness of input by interweaving mid-air and multitouch for several interactive applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3891–3902},
numpages = {12},
keywords = {depth sensor, smartwatch, finger tracking, skin interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025947,
author = {Singh, Aneesha and Bianchi-Berthouze, Nadia and Williams, Amanda CdeC},
title = {Supporting Everyday Function in Chronic Pain Using Wearable Technology},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025947},
doi = {10.1145/3025453.3025947},
abstract = {While most rehabilitation technologies target situated exercise sessions and associated performance metrics, physiotherapists recommend physical activities that are integrated with everyday functioning. We conducted a 1-2 week home study to explore how people with chronic pain use wearable technology that senses and sonifies movement (i.e., movement mapped to sound in real-time) to do functional activity (e.g., loading the dishwasher). Our results show that real-time movement sonification led to an increased sense of control during challenging everyday tasks. Sonification calibrated to functional activity facilitated application of pain management techniques such as pacing. When calibrated to individual needs, sonification enabled serendipitous discovery of physical capabilities otherwise obscured by a focus on pain or a dysfunctional proprioceptive system. A physiotherapist was invited to comment on the implications of our findings. We conclude by discussing opportunities provided by wearable sensing technology to enable better functioning, the ultimate goal of physical rehabilitation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3903–3915},
numpages = {13},
keywords = {wearables, chronic pain, ubiquitous technology., sonification, home rehabilitation, feedback, everyday function},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025489,
author = {Aggarwal, Deepti and Zhang, Weiyi and Hoang, Thuong and Ploderer, Bernd and Vetere, Frank and Bradford, Mark},
title = {SoPhy: A Wearable Technology for Lower Limb Assessment in Video Consultations of Physiotherapy},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025489},
doi = {10.1145/3025453.3025489},
abstract = {Physiotherapists are increasingly using video conferencing tools for their teleconsultations. Yet, the assessment of subtle differences in body movements remains a challenge. To support lower limb assessment in video consultations, we present SoPhy, a wearable technology consisting of a pair of socks with embedded sensors for patients to wear; and a web interface that displays information about range of weight distribution, foot movement, and foot orientation for physiotherapists in real-time. We conducted a laboratory study of 40 video consultations, in which postgraduate physiotherapy students assessed lower limb function. We compare assessment with and without SoPhy. Findings show that SoPhy increased the confidence in assessing squats exercise and fewer repetitions were required to assess patients when using SoPhy. We discuss the significance of SoPhy to address the challenges of assessing bodily information over video, and present considerations for its integration with clinical practices and tools.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3916–3928},
numpages = {13},
keywords = {physiotherapy, bodily communication, video communication, wearable technology, clinical consultation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025562,
author = {Wu, Chi-Jui and Houben, Steven and Marquardt, Nicolai},
title = {EagleSense: Tracking People and Devices in Interactive Spaces Using Real-Time Top-View Depth-Sensing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025562},
doi = {10.1145/3025453.3025562},
abstract = {Real-time tracking of people's location, orientation and activities is increasingly important for designing novel ubiquitous computing applications. Top-view camera-based tracking avoids occlusion when tracking people while collaborating, but often requires complex tracking systems and advanced computer vision algorithms. To facilitate the prototyping of ubiquitous computing applications for interactive spaces, we developed EagleSense, a real-time human posture and activity recognition system with a single top-view depth-sensing camera. We contribute our novel algorithm and processing pipeline, including details for calculating silhouette-extremities features and applying gradient tree boosting classifiers for activity recognition optimized for top-view depth sensing. EagleSense provides easy access to the real-time tracking data and includes tools for facilitating the integration into custom applications. We report the results of a technical evaluation with 12 participants and demonstrate the capabilities of EagleSense with application case studies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3929–3942},
numpages = {14},
keywords = {phone and tablet recognition, depth-infrared sensing, real-time top-view tracking, posture and activity recognition},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025685,
author = {Wagemakers, Andrew John and Fafard, Dylan Brodie and Stavness, Ian},
title = {Interactive Visual Calibration of Volumetric Head-Tracked 3D Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025685},
doi = {10.1145/3025453.3025685},
abstract = {Head-tracked 3D displays can provide a compelling 3D effect, but even small inaccuracies in the calibration of the participant's viewpoint to the display can disrupt the 3D illusion. We propose a novel interactive procedure for a participant to easily and accurately calibrate a head-tracked display by visually aligning patterns across a multi-screen display. Head-tracker measurements are then calibrated to these known viewpoints. We conducted a user study to evaluate the effectiveness of different visual patterns and different display shapes. We found that the easiest to align shape was the spherical display and the best calibration pattern was the combination of circles and lines. We performed a quantitative camera-based calibration of a cubic display and found visual calibration outperformed manual tuning and generated viewpoint calibrations accurate to within a degree. Our work removes the usual, burdensome step of manual calibration when using head-tracked displays and paves the way for wider adoption of this inexpensive and effective 3D display technology.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3943–3953},
numpages = {11},
keywords = {calibration, fish tank virtual reality, head tracking, visual perception},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025795,
author = {Lindlbauer, David and Mueller, J\"{o}rg and Alexa, Marc},
title = {Changing the Appearance of Real-World Objects By Modifying Their Surroundings},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025795},
doi = {10.1145/3025453.3025795},
abstract = {We present an approach to alter the perceived appearance of physical objects by controlling their surrounding space. Many real-world objects cannot easily be equipped with displays or actuators in order to change their shape. While common approaches such as projection mapping enable changing the appearance of objects without modifying them, certain surface properties (e.g. highly reflective or transparent surfaces) can make employing these techniques difficult. In this work, we present a conceptual design exploration on how the appearance of an object can be changed by solely altering the space around it, rather than the object itself. In a proof-of-concept implementation, we place objects onto a tabletop display and track them together with users to display perspective-corrected 3D graphics for augmentation. This enables controlling properties such as the perceived size, color, or shape of objects. We characterize the design space of our approach and demonstrate potential applications. For example, we change the contour of a wallet to notify users when their bank account is debited. We envision our approach to gain in importance with increasing ubiquity of display surfaces.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3954–3965},
numpages = {12},
keywords = {augmented reality, dynamic appearance},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025533,
author = {Grubert, Jens and Kranz, Matthias},
title = {HeadPhones: Ad Hoc Mobile Multi-Display Environments through Head Tracking},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025533},
doi = {10.1145/3025453.3025533},
abstract = {We present HeadPhones (Headtracking + smartPhones), a novel approach for the spatial registration of multiple mobile devices into an ad hoc multi-display environment. We propose to employ the user's head as external reference frame for the registration of multiple mobile devices into a common coordinate system. Our approach allows for dynamic repositioning of devices during runtime without the need for external infrastructure such as separate cameras or fiducials. Specifically, our only requirements are local network connections and mobile devices with built-in front facing cameras. This way, HeadPhones enables spatially-aware multi-display applications in mobile contexts. A user study and accuracy evaluation indicate the feasibility of our approach.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3966–3971},
numpages = {6},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025536,
author = {Sato, Munehiko and Puri, Rohan S. and Olwal, Alex and Ushigome, Yosuke and Franciszkiewicz, Lukas and Chandra, Deepak and Poupyrev, Ivan and Raskar, Ramesh},
title = {Zensei: Embedded, Multi-Electrode Bioimpedance Sensing for Implicit, Ubiquitous User Recognition},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025536},
doi = {10.1145/3025453.3025536},
abstract = {Interactions and connectivity is increasingly expanding to shared objects and environments, such as furniture, vehicles, lighting, and entertainment systems. For transparent personalization in such contexts, we see an opportunity for embedded recognition, to complement traditional, explicit authentication. We introduce Zensei, an implicit sensing system that leverages bio-sensing, signal processing and machine learning to classify uninstrumented users by their body's electrical properties. Zensei could allow many objects to recognize users. E.g., phones that unlock when held, cars that automatically adjust mirrors and seats, or power tools that restore user settings. We introduce wide-spectrum bioimpedance hardware that measures both amplitude and phase. It extends previous approaches through multi-electrode sensing and high-speed wireless data collection for embedded devices. We implement the sensing in devices and furniture, where unique electrode configurations generate characteristic profiles based on user's unique electrical properties. Finally, we discuss results from a comprehensive longitudinal 22-day data collection experiment with 46 subjects. Our analysis shows promising classification accuracy and low false acceptance rate.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3972–3985},
numpages = {14},
keywords = {bio-sensing, embedded devices, electrical sensing, user recognition, ubiquitous computing, implicit sensing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025773,
author = {Laput, Gierad and Zhang, Yang and Harrison, Chris},
title = {Synthetic Sensors: Towards General-Purpose Sensing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025773},
doi = {10.1145/3025453.3025773},
abstract = {The promise of smart environments and the Internet of Things (IoT) relies on robust sensing of diverse environmental facets. Traditional approaches rely on direct and distributed sensing, most often by measuring one particular aspect of an environment with a special purpose sensor. This approach can be costly to deploy, hard to maintain, and aesthetically and socially obtrusive. In this work, we explore the notion of general purpose sensing, wherein a single enhanced sensor can indirectly monitor a large context, without direct instrumentation of objects. Further, through what we call Synthetic Sensors, we can virtualize raw sensor data into actionable feeds, whilst simultaneously mitigating immediate privacy issues. A series of structured, formative studies informed the development of our new sensor hardware and accompanying information architecture. We deployed our system across many months and environments, the results of which show the versatility, accuracy and potential utility of our approach.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3986–3999},
numpages = {14},
keywords = {IoT, universal sensor, smart home, internet-of-things},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025828,
author = {Xiao, Robert and Laput, Gierad and Zhang, Yang and Harrison, Chris},
title = {Deus EM Machina: On-Touch Contextual Functionality for Smart IoT Appliances},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025828},
doi = {10.1145/3025453.3025828},
abstract = {Homes, offices and many other environments will be increasingly saturated with connected, computational appliances, forming the "Internet of Things" (IoT). At present, most of these devices rely on mechanical inputs, webpages, or smartphone apps for control. However, as IoT devices proliferate, these existing interaction methods will become increasingly cumbersome. Will future smart-home owners have to scroll though pages of apps to select and dim their lights? We propose an approach where users simply tap a smartphone to an appliance to discover and rapidly utilize contextual functionality. To achieve this, our prototype smartphone recognizes physical contact with uninstrumented appliances, and summons appliance-specific interfaces. Our user study suggests high accuracy 98.8% recognition accuracy among 17 appliances. Finally, to underscore the immediate feasibility and utility of our system, we built twelve example applications, including six fully functional end-to-end demonstrations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4000–4008},
numpages = {9},
keywords = {smart appliances, object sensing, context sensing, internet of things, smart home, EMI, IoT, recognition},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025530,
author = {Fdili Alaoui, Sarah and Fran\c{c}oise, Jules and Schiphorst, Thecla and Studd, Karen and Bevilacqua, Frederic},
title = {Seeing, Sensing and Recognizing Laban Movement Qualities},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025530},
doi = {10.1145/3025453.3025530},
abstract = {Human movement has historically been approached as a functional component of interaction within human computer interaction. Yet movement is not only functional, it is also highly expressive. In our research, we explore how movement expertise as articulated in Laban Movement Analysis (LMA) can contribute to the design of computational models of movement's expressive qualities as defined in the framework of Laban Efforts. We include experts in LMA in our design process, in order to select a set of suitable multimodal sensors as well as to compute features that closely correlate to the definitions of Efforts in LMA. Evaluation of our model shows that multimodal data combining positional, dynamic and physiological information allows for a better characterization of Laban Efforts. We conclude with implications for design that illustrate how our methodology and our approach to multimodal capture and recognition of Effort qualities can be integrated to design interactive applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4009–4020},
numpages = {12},
keywords = {movement observation, movement-based interaction, laban movement analysis, movement qualities, multimodal measures, movement recognition},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025683,
author = {Gugenheimer, Jan and Stemasov, Evgeny and Frommel, Julian and Rukzio, Enrico},
title = {ShareVR: Enabling Co-Located Experiences for Virtual Reality between HMD and Non-HMD Users},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025683},
doi = {10.1145/3025453.3025683},
abstract = {Virtual reality (VR) head-mounted displays (HMD) allow for a highly immersive experience and are currently becoming part of the living room entertainment. Current VR systems focus mainly on increasing the immersion and enjoyment for the user wearing the HMD (HMD user), resulting in all the bystanders (Non-HMD users) being excluded from the experience. We propose ShareVR, a proof-of-concept prototype using floor projection and mobile displays in combination with positional tracking to visualize the virtual world for the Non-HMD user, enabling them to interact with the HMD user and become part of the VR experience. We designed and implemented ShareVR based on the insights of an initial online survey (n=48) with early adopters of VR HMDs. We ran a user study (n=16) comparing ShareVRto a baseline condition showing how the interaction using ShareVR led to an increase of enjoyment, presence and social interaction. In a last step we implemented several experiences for ShareVR, exploring its design space and giving insights for designers of co-located asymmetric VR experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4021–4033},
numpages = {13},
keywords = {consumer virtual reality, asymmetric virtual reality, multi-user virtual reality, sharevr, co-located virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025665,
author = {Hock, Philipp and Benedikter, Sebastian and Gugenheimer, Jan and Rukzio, Enrico},
title = {CarVR: Enabling In-Car Virtual Reality Entertainment},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025665},
doi = {10.1145/3025453.3025665},
abstract = {Mobile virtual reality (VR) head-mounted displays (HMDs) allow users to experience highly immersive entertainment whilst being in a mobile scenario. Long commute times make casual gaming in public transports and cars a common occupation. However, VR HMDs can currently not be used in moving vehicles since the car's rotation affects the HMD's sensors and simulator sickness occurs when the visual and vestibular system are stimulated with incongruent information. We present CarVR, a solution to enable VR in moving vehicles by subtracting the car's rotation and mapping vehicular movements with the visual information. This allows the user to actually feel correct kinesthetic forces during the VR experience. In a user study (n = 21), we compared CarVR inside a moving vehicle with the baseline of using VR without vehicle movements. We show that the perceived kinesthetic forces caused by CarVR increase enjoyment and immersion significantly while simulator sickness is reduced compared to a stationary VR experience. Finally, we explore the design space of in-car VR entertainment applications using real kinesthetic forces and derive design considerations for practitioners.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4034–4044},
numpages = {11},
keywords = {entertainment, motion platform, force-feedback, virtual reality, automotive, immersion, gaming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026028,
author = {Dey, Arindam and Piumsomboon, Thammathip and Lee, Youngho and Billinghurst, Mark},
title = {Effects of Sharing Physiological States of Players in a Collaborative Virtual Reality Gameplay},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026028},
doi = {10.1145/3025453.3026028},
abstract = {Interfaces for collaborative tasks, such as multiplayer games can enable more effective and enjoyable collaboration. However, in these systems, the emotional states of the users are often not communicated properly due to their remoteness from one another. In this paper, we investigate the effects of showing emotional states of one collaborator to the other during an immersive Virtual Reality (VR) gameplay experience. We created two collaborative immersive VR games that display the real-time heart-rate of one player to the other. The two different games elicited different emotions, one joyous and the other scary. We tested the effects of visualizing heart-rate feedback in comparison with conditions where such a feedback was absent. The games had significant main effects on the overall emotional experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4045–4056},
numpages = {12},
keywords = {physiological sensors, emotions, virtual reality, empathic computing, collaborative gameplay, user study.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025566,
author = {Sousa, Maur\'{\i}cio and Mendes, Daniel and Paulo, Soraia and Matela, Nuno and Jorge, Joaquim and Lopes, Daniel Sim\~{o}es},
title = {VRRRRoom: Virtual Reality for Radiologists in the Reading Room},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025566},
doi = {10.1145/3025453.3025566},
abstract = {Reading room conditions such as illumination, ambient light, human factors and display luminance, play an important role on how radiologists analyze and interpret images. Indeed, serious diagnostic errors can appear when observing images through everyday monitors. Typically, these occur whenever professionals are ill-positioned with respect to the display or visualize images under improper light and luminance conditions. In this work, we show that virtual reality can assist radiodiagnostics by considerably diminishing or cancel out the effects of unsuitable ambient conditions. Our approach combines immersive head-mounted displays with interactive surfaces to support professional radiologists in analyzing medical images and formulating diagnostics. We evaluated our prototype with two senior medical doctors and four seasoned radiology fellows. Results indicate that our approach constitutes a viable, flexible, portable and cost-efficient option to traditional radiology reading rooms.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4057–4062},
numpages = {6},
keywords = {multitouch surfaces, medical visualization, virtual reality, interaction design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025521,
author = {Tregillus, Sam and Al Zayer, Majed and Folmer, Eelke},
title = {Handsfree Omnidirectional VR Navigation Using Head Tilt},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025521},
doi = {10.1145/3025453.3025521},
abstract = {Navigating mobile virtual reality (VR) is a challenge due to limited input options and/or a requirement for handsfree interaction. Walking-in-place (WIP) is considered to offer a higher presence than controller input but only allows unidirectional navigation in the direction of the user's gaze--which impedes navigation efficiency. Leaning input enables omnidirectional navigation but currently relies on bulky controllers, which aren't feasible in mobile VR contexts. This note evaluates the use of head-tilt - implemented using inertial sensing - to allow for handsfree omnidirectional VR navigation on mobile VR platforms. A user study with 24 subjects compared three input methods using an obstacle avoidance navigation task: (1) head-tilt alone (TILT) (2) a hybrid method (WIP-TILT) that uses head tilting for direction and WIP to control speed; and (3) traditional controller input. TILT was significantly faster than WIP-TILT and joystick input, while WIP-TILT and TILT offered the highest presence. There was no difference in cybersickness between input methods.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4063–4068},
numpages = {6},
keywords = {mobile vr, inertial sensing, virtual reality, games, locomotion, simulator-sickness, walking-in-place, head-tilt},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025656,
author = {Hentschel, Jasmine and Sherugar, Samyukta Manjayya and Zhou, Rui and Kameswaran, Vaishnav and Chandwani, Rajesh and Kumar, Neha},
title = {Rice Today, Roti Tomorrow: Diets and Diabetes in Urban Indian Households},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025656},
doi = {10.1145/3025453.3025656},
abstract = {In India, where diabetes is a growing concern and approximately 69 million are affected, we investigate the factors that influence diet management, a critical component of living with the disease. Taking the middle-income diabetes-affected household as our unit of analysis, we use a combination of semi-structured interviews and a design probe to understand if and how diets are monitored, tailored, and balanced. We research the various information-seeking behaviors of our participants and their culturally situated approaches to food and eating. Our findings illuminate how contextual nuances shape individuals' beliefs around dealing with diabetes and the ways in which family, friends, and broader social networks influence dietary decisions. We conclude by offering a framework of Learning-Being-Doing to inform the holistic design of technologies for managing diets and diabetes.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4069–4081},
numpages = {13},
keywords = {diabetes, india, qualitative methods, diets},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026052,
author = {Hwang, Maria L. and Mamykina, Lena},
title = {Monster Appetite: Effects of Subversive Framing on Nutritional Choices in a Digital Game Environment},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026052},
doi = {10.1145/3025453.3026052},
abstract = {Americans' health has reached a dangerous obesity epidemic from overconsumption and unhealthy food choices. In response, persuasive games for health encourage healthier lifestyles typically by providing positive reinforcement for the desired behaviors. However, positive reinforcement is only one of the many possibly effective approaches. We explore two types of message framing in a nutrition game, Monster Appetite (MA). In MA, players' choices of high or low calorie snacks impact visual appearance of their monster avatar. MA utilizes two types of health messages: subversive, which encourages players to make unhealthy choices and focuses on costs, and inoculation, which encourages players to eventually defend healthy choices and focuses on benefits. We test message framing's effect by tracking users' purchasing behavior in our online snack shop, Snackazon. The study showed that when positive messages were embedded in MA mixed with negative visuals through the monster avatars, participants exhibited better snack choices post-gameplay.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4082–4096},
numpages = {15},
keywords = {nutritional choices., persuasive games, two-sided inoculation, subversive approach, behavior modification, framing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025874,
author = {Burgermaster, Marissa and Gajos, Krzysztof Z. and Davidson, Patricia and Mamykina, Lena},
title = {The Role of Explanations in Casual Observational Learning about Nutrition},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025874},
doi = {10.1145/3025453.3025874},
abstract = {The ubiquity of internet-based nutrition information sharing indicates an opportunity to use social computing platforms to promote nutrition literacy and healthy nutritional choices. We conducted a series of experiments with unpaid volunteers using an online Nutrition Knowledge Test. The test asked participants to examine pairs of photographed meals and identify meals higher in a specific macronutrient (e.g., carbohydrate). After each answer, participants received no feedback on the accuracy of their answers, viewed proportions of peers choosing each response, received correctness feedback from an expert dietitian with or without expert-generated explanations, or received correctness feedback with crowd-generated explanations. The results showed that neither viewing peer responses nor correctness feedback alone improved learning. However, correctness feedback with explanations (i.e., modeling) led to significant learning gains, with no significant difference between explanations generated by experts or peers. This suggests the importance of explanations in social computing-based casual learning about nutrition and the potential for scaling this approach via crowdsourcing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4097–4145},
numpages = {49},
keywords = {crowdsourcing, casual learning, observational learning, nutrition literacy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025518,
author = {Freeman, Euan and Wilson, Graham and Brewster, Stephen and Baud-Bovy, Gabriel and Magnusson, Charlotte and Caltenco, Hector},
title = {Audible Beacons and Wearables in Schools: Helping Young Visually Impaired Children Play and Move Independently},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025518},
doi = {10.1145/3025453.3025518},
abstract = {Young children with visual impairments tend to engage less with their surroundings, limiting the benefits from activities at school. We investigated novel ways of using sound from a bracelet, such as speech or familiar noises, to tell children about nearby people, places and activities, to encourage them to engage more during play and help them move independently. We present a series of studies, the first two involving visual impairment educators, that give insight into challenges faced by visually impaired children at school and how sound might help them. We then present a focus group with visually impaired children that gives further insight into the effective use of sound. Our findings reveal novel ways of combining sounds from wearables with sounds from the environment, motivating audible beacons, devices for audio output and proximity estimation. We present scenarios, findings and a design space that show the novel ways such devices could be used alongside wearables to help visually impaired children at school.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4146–4157},
numpages = {12},
keywords = {visual impairment, wearables, beacons, play, children},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025528,
author = {Abdolrahmani, Ali and Easley, William and Williams, Michele and Branham, Stacy and Hurst, Amy},
title = {Embracing Errors: Examining How Context of Use Impacts Blind Individuals' Acceptance of Navigation Aid Errors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025528},
doi = {10.1145/3025453.3025528},
abstract = {Prevention of errors has been an orienting goal within the field of Human-Computer Interaction since its inception, with particular focus on minimizing human errors through appropriate technology design. However, there has been relatively little exploration into how designers can best support users of technologies that will inevitably make errors. We present a mixed-methods study in the domain of navigation technology for visually impaired individuals. We examined how users respond to device errors made in realistic scenarios of use. Contrary to conventional wisdom that usable systems must be error-free, we found that 42% of errors were acceptable to users. Acceptance of errors depends on error type, building feature, and environmental context. Further, even when a technical error is acceptable to the user, the misguided social responses of others nearby can negatively impact user experience. We conclude with design recommendations that embrace errors while also supporting user management of errors in technical systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4158–4169},
numpages = {12},
keywords = {assistive technology, disability, stigmatization, visual impairments, blindness, navigation, device errors},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025949,
author = {Zhao, Yuhang and Hu, Michele and Hashash, Shafeka and Azenkot, Shiri},
title = {Understanding Low Vision People's Visual Perception on Commercial Augmented Reality Glasses},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025949},
doi = {10.1145/3025453.3025949},
abstract = {People with low vision have a visual impairment that affects their ability to perform daily activities. Unlike blind people, low vision people have functional vision and can potentially benefit from smart glasses that provide dynamic, always-available visual information. We sought to determine what low vision people could see on mainstream commercial augmented reality (AR) glasses, despite their visual limitations and the device's constraints. We conducted a study with 20 low vision participants and 18 sighted controls, asking them to identify virtual shapes and text in different sizes, colors, and thicknesses. We also evaluated their ability to see the virtual elements while walking. We found that low vision participants were able to identify basic shapes and read short phrases on the glasses while sitting and walking. Identifying virtual elements had a similar effect on low vision and sighted people's walking speed, slowing it down slightly. Our study yielded preliminary evidence that mainstream AR glasses can be powerful accessibility tools. We derive guidelines for presenting visual output for low vision people and discuss opportunities for accessibility applications on this platform.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4170–4181},
numpages = {12},
keywords = {accessibility, user study, low vision, augmented reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025906,
author = {Leiva, Luis A. and Mart\'{\i}n-Albo, Daniel and Vatavu, Radu-Daniel},
title = {Synthesizing Stroke Gestures Across User Populations: A Case for Users with Visual Impairments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025906},
doi = {10.1145/3025453.3025906},
abstract = {We introduce a new principled method grounded in the Kinematic Theory of Rapid Human Movements to automatically generate synthetic stroke gestures across user populations in order to support ability-based design of gesture user interfaces. Our method is especially useful when the target user population is difficult to sample adequately and, consequently, when there is not enough data to train gesture recognizers to deliver high levels of accuracy. To showcase the relevance and usefulness of our method, we collected gestures from people without visual impairments and successfully synthesized gestures with the articulation characteristics of people with visual impairments. We also show that gesture recognition accuracy improves significantly when using our synthetic gesture samples for training. Our contributions will benefit researchers and practitioners that wish to design gesture user interfaces for people with various abilities by helping them prototype, evaluate, and predict gesture recognition performance without having to expressly recruit and involve people with disabilities in long, time-consuming gesture collection experiments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4182–4193},
numpages = {12},
keywords = {bootstrapping, sigma-lognormal model, gesture synthesis, touch gestures, kinematic theory, rapid prototyping},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025520,
author = {Yeo, Hui-Shyong and Phang, Xiao-Shen and Castellucci, Steven J. and Kristensson, Per Ola and Quigley, Aaron},
title = {Investigating Tilt-Based Gesture Keyboard Entry for Single-Handed Text Entry on Large Devices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025520},
doi = {10.1145/3025453.3025520},
abstract = {The popularity of mobile devices with large screens is making single-handed interaction difficult. We propose and evaluate a novel design point around a tilt-based text entry technique which supports single handed usage. Our technique is based on the gesture keyboard (shape writing). However, instead of drawing gestures with a finger or stylus, users articulate a gesture by tilting the device. This can be especially useful when the user's other hand is otherwise encumbered or unavailable. We show that novice users achieve an entry rate of 15 words-per-minute (wpm) after minimal practice. A pilot longitudinal study reveals that a single participant achieved an entry rate of 32 wpm after approximate 90 minutes of practice. Our data indicate that tilt-based gesture keyboard entry enables walk-up use and provides a suitable text entry rate for occasional use and can act as a promising alternative to single-handed typing in certain situations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4194–4202},
numpages = {9},
keywords = {text entry, phablets, single-handed, gesture keyboard, tilt, shape writing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025580,
author = {Jokinen, Jussi P. P. and Sarcar, Sayan and Oulasvirta, Antti and Silpasuwanchai, Chaklam and Wang, Zhenxin and Ren, Xiangshi},
title = {Modelling Learning of New Keyboard Layouts},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025580},
doi = {10.1145/3025453.3025580},
abstract = {Predicting how users learn new or changed interfaces is a long-standing objective in HCI research. This paper contributes to understanding of visual search and learning in text entry. With a goal of explaining variance in novices' typing performance that is attributable to visual search, a model was designed to predict how users learn to locate keys on a keyboard: initially relying on visual short-term memory but then transitioning to recall-based search. This allows predicting search times and visual search patterns for completely and partially new layouts. The model complements models of motor performance and learning in text entry by predicting change in visual search patterns over time. Practitioners can use it for estimating how long it takes to reach the desired level of performance with a given layout.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4203–4215},
numpages = {13},
keywords = {models of learning, keyboard layouts, visual search},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025701,
author = {Yi, Xin and Yu, Chun and Shi, Weinan and Bi, Xiaojun and Shi, Yuanchun},
title = {Word Clarity as a Metric in Sampling Keyboard Test Sets},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025701},
doi = {10.1145/3025453.3025701},
abstract = {Test sets play an essential role in evaluating text entry techniques. In this paper, we argue that in addition to the widely adopted metric of bigram representativeness and memorability, word clarity should also be considered as a metric when creating test sets from the target dataset. Word clarity quantifies the extent to which a word is likely to confuse with other words on a keyboard. We formally define word clarity, derive equations calculating it, and both theoretically and empirically show that word clarity has a significant effect on text entry performance: it can yield up to 26.4% difference in error rate, and 25% difference in input speed. We later propose a Pareto optimization method for sampling test sets with different sizes, which optimizes the word clarity and bigram representativeness, and memorability of the test set. The obtained test sets are published on the Internet.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4216–4228},
numpages = {13},
keywords = {phrase set, sampling, word clarity, text entry evaluation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025695,
author = {Banovic, Nikola and Rao, Varun and Saravanan, Abinaya and Dey, Anind K. and Mankoff, Jennifer},
title = {Quantifying Aversion to Costly Typing Errors in Expert Mobile Text Entry},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025695},
doi = {10.1145/3025453.3025695},
abstract = {Text entry is an increasingly important activity for mobile device users. As a result, increasing text entry speed of expert typists is an important design goal for physical and soft keyboards. Mathematical models that predict text entry speed can help with keyboard design and optimization. Making typing errors when entering text is inevitable. However, current models do not consider how typists themselves reduce the risk of making typing errors (and lower error frequency) by typing more slowly. We demonstrate that users respond to costly typing errors by reducing their typing speed to minimize typing errors. We present a model that estimates the effects of risk aversion to errors on typing speed. We estimate the magnitude of this speed change, and show that disregarding the adjustments to typing speed that expert typists use to reduce typing errors leads to overly optimistic estimates of maximum errorless expert typing speeds.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4229–4241},
numpages = {13},
keywords = {error cost, speed-accuracy tradeoff, typing speed},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025509,
author = {Vitale, Francesco and McGrenere, Joanna and Tabard, Aur\'{e}lien and Beaudouin-Lafon, Michel and Mackay, Wendy E.},
title = {High Costs and Small Benefits: A Field Study of How Users Experience Operating System Upgrades},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025509},
doi = {10.1145/3025453.3025509},
abstract = {Users must manage frequent software and operating system upgrades across multiple computing devices. While current research focuses primarily on the security aspect, we investigate the user's perspective of upgrading software. Our first study (n=65) found that users delay major upgrades by an average of 80 days. We then ran a field study (n=14), beginning with in-depth observations during an operating system upgrade, followed by a four-week diary study. Very few participants prepared for upgrades (e.g., backing up files), and over half had negative reactions to the upgrade process and other changes (e.g., bugs, lost settings, unwanted features). During the upgrade process, waiting times were too long, feedback was confusing or misleading, and few had clear mental models of what was happening. Users almost never mentioned security as a concern or reason for upgrading. By contrast, interviews (n=3) with technical staff responsible for one organization's upgrades focused only on security and licensing, not user interface changes. We conclude with recommendations to improve the user's upgrade experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4242–4253},
numpages = {12},
keywords = {qualitative analysis, observational study, software upgrades},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025636,
author = {Eiband, Malin and Khamis, Mohamed and von Zezschwitz, Emanuel and Hussmann, Heinrich and Alt, Florian},
title = {Understanding Shoulder Surfing in the Wild: Stories from Users and Observers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025636},
doi = {10.1145/3025453.3025636},
abstract = {Research has brought forth a variety of authentication systems to mitigate observation attacks. However, there is little work about shoulder surfing situations in the real world. We present the results of a user survey (N=174) in which we investigate actual stories about shoulder surfing on mobile devices from both users and observers. Our analysis indicates that shoulder surfing mainly occurs in an opportunistic, non-malicious way. It usually does not have serious consequences, but evokes negative feelings for both parties, resulting in a variety of coping strategies. Observed data was personal in most cases and ranged from information about interests and hobbies to login data and intimate details about third persons and relationships. Thus, our work contributes evidence for shoulder surfing in the real world and informs implications for the design of privacy protection mechanisms.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4254–4265},
numpages = {12},
keywords = {privacy, shoulder surfing, mobile devices},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025764,
author = {Malloch, Joseph and Griggio, Carla F. and McGrenere, Joanna and Mackay, Wendy E.},
title = {Fieldward and Pathward: Dynamic Guides for Defining Your Own Gestures},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025764},
doi = {10.1145/3025453.3025764},
abstract = {Although users accomplish ever more tasks on touch-enabled mobile devices, gesture-based interaction remains limited and almost never customizable by users. Our goal is to help users create gestures that are both personally memorable and reliably recognized by a touch-enabled mobile device. We address these competing requirements with two dynamic guides that use progressive feedforward to interactively visualize the "negative space" of unused gestures: the Pathward technique suggests four possible completions to the current gesture, and the Fieldward technique uses color gradients to reveal optimal directions for creating recognizable gestures. We ran a two-part experiment in which 27 participants each created 42 personal gesture shortcuts on a smartphone, using Pathward, Fieldward or No Feedforward. The Fieldward technique best supported the most common user strategy, i.e. to create a memorable gesture first and then adapt it to be recognized by the system. Users preferred the Fieldward technique to Pathward or No Feedforward, and remembered gestures more easily when using the technique. Dynamic guides can help developers design novel gesture vocabularies and support users as they design custom gestures for mobile applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4266–4277},
numpages = {12},
keywords = {progressive feedforward, personalized gestures, gesture recognition, dynamic guides, controlled experiment.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025513,
author = {Liu, Xiaoxing and Thomas, Geb W.},
title = {Gesture Interfaces: Minor Change in Effort, Major Impact on Appeal},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025513},
doi = {10.1145/3025453.3025513},
abstract = {Making gestures easy for imaging systems to reliably recognize often comes at the expense of user effort. But what is the impact of increasing a gesture's effort, even slightly, on user preference? We investigate physical effort, system reliability, and user satisfaction in two experiments. The first explores eight basic command gestures. Participants preferred the less effortful gestures in two of the three easy-difficult gesture pairs when they perceived the difference in effort to be significantly different. The second experiment explores two separate three-dimensional pointing and selection conditions that differ only in the movement distance required to finish the task. In both experiments, there is a significant negative correlation between a gesture's effort and its appeal. The results show the great impact that effort has on a user's willingness to utilize the system. The findings provide evidence that the trade-off between user effort and system reliability must be carefully considered to build an effective gesture interface.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4278–4283},
numpages = {6},
keywords = {gesture interfaces, user experience, effort-based measurement, usability evaluation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025653,
author = {Sun, Emily and McLachlan, Ross and Naaman, Mor},
title = {MoveMeant: Anonymously Building Community Through Shared Location Histories},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025653},
doi = {10.1145/3025453.3025653},
abstract = {Awareness of and connections to a local community are important for building social capital, sharing resources, and providing physical support, but have been elusive to create in dense urban environments. We describe the design and implementation of MoveMeant, a system aimed to increase local community awareness through shared location traces. MoveMeant securely uses anonymized location data generated automatically by mobile devices to display aggregate, community-level location data. We report findings from interviews with residents in the Bronx, New York City who participated in a deployment of MoveMeant over a 6-week period. Our findings show that people use the anonymous information to make judgments about the people and places in their community, while opting to reveal their identity for third places where there is an opportunity to connect socially.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4284–4289},
numpages = {6},
keywords = {movemeant, third places, local community, location traces},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025505,
author = {Maezawa, Akira and Yamamoto, Kazuhiko},
title = {MuEns: A Multimodal Human-Machine Music Ensemble for Live Concert Performance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025505},
doi = {10.1145/3025453.3025505},
abstract = {Musical ensemble between human musicians and computers is a challenging task. We achieve this with a concert-quality synchronization using machine learning. Our system recognizes the position in a given song from the human performance using the microphone and camera inputs, and responds in real-time with audio and visual feedback as a music ensemble. We address three crucial requirements in a musical ensemble system. First, our system interacts with human players through both audio and visual cues, the conventional modes of coordination for musicians. Second, our system synchronizes with human performances while retaining its intended musical expression. Third, our system prevents failures during a concert due to bad tracking, by displaying an internal confidence measure and allowing a backstage human operator to "intervene" if the system is unconfident. We show the feasibility of the system with several experiments, including a professional concert.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4290–4301},
numpages = {12},
keywords = {machine learning, multimodal interaction, human-machine music ensemble, score following, live concert system},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025900,
author = {Greenhalgh, Chris and Benford, Steve and Hazzard, Adrian and Chamberlain, Alan},
title = {Playing Fast and Loose with Music Recognition},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025900},
doi = {10.1145/3025453.3025900},
abstract = {We report lessons from iteratively developing a music recognition system to enable a wide range of musicians to embed musical codes into their typical performance practice. The musician composes fragments of music that can be played back with varying levels of embellishment, disguise and looseness to trigger digital interactions. We collaborated with twenty-three musicians, spanning professionals to amateurs and working with a variety of instruments. We chart the rapid evolution of the system to meet their needs as they strove to integrate music recognition technology into their performance practice, introducing multiple features to enable them to trade-off reliability with musical expression. Collectively, these support the idea of deliberately introducing "looseness" into interactive systems by addressing the three key challenges of control, feedback and attunement, and highlight the potential role for written notations in other recognition-based systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4302–4313},
numpages = {12},
keywords = {notation, attunement, H-metaphor, sensing systems, looseness, casual interactions, performance, music recognition},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025989,
author = {Ochiai, Yoichi and Hoshi, Takayuki and Suzuki, Ippei},
title = {Holographic Whisper: Rendering Audible Sound Spots in Three-Dimensional Space by Focusing Ultrasonic Waves},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025989},
doi = {10.1145/3025453.3025989},
abstract = {We propose a novel method of spatial audio rendering using ultrasound. An ultrasonic phased array generates one or more focal points in air, and they act as point sources of audible sound when the ultrasound waves are modulated. Our sound-point loudspeaker has two major advantages over conventional ultrasound-based sound-beam (superdirectional) loudspeakers. The higher audience selectivity means that our sound-point loudspeaker can deliver sound to the ears of the target person, whereas a sound-beam loudspeaker delivers sound to not only the target person but also other persons standing in the same direction. The other advantage is lower exposure to ultrasound; while an audible sound beam travels along an ultrasonic beam in a soundbeam loudspeaker, audible sound can be heard along the direction perpendicular to the ultrasonic beam in our soundpoint loudspeaker. This paper reports the principles of our sound-point loudspeaker, prototype construction, evaluation, and applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4314–4325},
numpages = {12},
keywords = {self-demodulation effect, ultrasound, point source, aerial interaction, spatial sound control, phased-array focusing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025583,
author = {Lyu, Fei and Tian, Feng and Feng, Wenxin and Cao, Xiang and Zhang, Xiaolong (Luke) and Dai, Guozhong and Wang, Hongan},
title = {EnseWing: Creating an Instrumental Ensemble Playing Experience for Children with Limited Music Training},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025583},
doi = {10.1145/3025453.3025583},
abstract = {While instrumental ensemble playing can benefit children's music education and collaboration skill development, it requires extensive training on music and instruments, which many school children lack. To help children with limited music training experience instrumental ensemble playing, we created EnseWing, an interactive system that offers such an experience. In this paper, we report the design of the EnseWing experience and a two-month field study. Our results show that EnseWing preserves the music and ensemble skills from traditional instrumental ensemble and provides more collaboration opportunities for children.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4326–4330},
numpages = {5},
keywords = {children, collaboration, music, instrumental ensemble},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025515,
author = {Lampinen, Airi and Brown, Barry},
title = {Market Design for HCI: Successes and Failures of Peer-to-Peer Exchange Platforms},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025515},
doi = {10.1145/3025453.3025515},
abstract = {This paper explores an HCI approach to designing markets, with a primary focus on peer-to peer exchange platforms. We draw on&nbsp;recent work in economics that has documented how markets function, how they can be evaluated, and what can be done to fix them when they fail. We introduce five key concepts from market design: thickness, congestion, stability, safety, and repugnance. These lend HCI an analytic vocabulary for understanding why markets may succeed or struggle. Building on prior empirical work, we apply these concepts to compare two well-known network hospitality platforms, Couchsurfing and Airbnb. As a second illustrative case, we use market design to shed light on the challenges experienced by smaller-scale peer-to-peer marketplaces for lending, renting, and selling physical goods. To conclude, we discuss how this kind of analysis can make conceptual, evaluative, and generative contributions to the study and design of exchange platforms and other socio-technical systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4331–4343},
numpages = {13},
keywords = {matching market, market design, sharetribe, platform economy, sharing economy, couchsurfing, airbnb},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025550,
author = {Moser, Carol and Resnick, Paul and Schoenebeck, Sarita},
title = {Community Commerce: Facilitating Trust in Mom-to-Mom Sale Groups on Facebook},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025550},
doi = {10.1145/3025453.3025550},
abstract = {Consumers are turning to Facebook Groups to buy and sell with strangers in their local communities. This trend is counter-intuitive given Facebook's lack of conventional e-commerce features, such as sophisticated search engines and reputation systems. We interviewed 18 members of two Mom-to-Mom Facebook sale groups. Despite a lack of commerce tools, members perceived sale groups as an easy-to-use way to quickly and conveniently buy and sell. Most important to members was that the groups felt safe and trustworthy. Drawing on these insights, we contribute a novel framing, community commerce, which explains the trust mechanisms that enable transactions between strangers in some groups. Community commerce fosters trust through (a) exclusive membership to a closed group, (b) regulation and sanctioning of behavior at the admin, member, and group level, and (c) a shared group identity or perceived similarity (though, surprisingly, not through social bonding). We discuss how community commerce affords unique and sometimes superior trust assurances and propose design implications for platforms hoping to foster trust between members who buy, sell, or share amongst themselves.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4344–4357},
numpages = {14},
keywords = {online communities, consumer-to-consumer, e-commerce, community commerce, trust, facebook},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025778,
author = {Moser, Carol and Phelan, Chanda and Resnick, Paul and Schoenebeck, Sarita Y. and Reinecke, Katharina},
title = {No Such Thing as Too Much Chocolate: Evidence Against Choice Overload in E-Commerce},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025778},
doi = {10.1145/3025453.3025778},
abstract = {E-commerce designers must decide how many products to display at one time. Choice overload research has demonstrated the surprising finding that more choice is not necessarily better?selecting from larger choice sets can be more cognitively demanding and can result in lower levels of choice satisfaction. This research tests the choice overload effect in an e-commerce context and explores how the choice overload effect is influenced by an individual's tendency to maximize or satisfice decisions. We conducted an online experiment with 611 participants randomly assigned to select a gourmet chocolate bar from either 12, 24, 40, 50, 60, or 72 different options. Consistent with prior work, we find that maximizers are less satisfied with their product choice than satisficers. However, using Bayesian analysis, we find that it's unlikely that choice set size affects choice satisfaction by much, if at all. We discuss why the decision-making process may be different in e-commerce contexts than the physical settings used in previous choice overload experiments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4358–4369},
numpages = {12},
keywords = {choice overload, maximizing, experiment, e-commerce},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025815,
author = {Bellotti, Victoria and Turner, Dan and Demkova, Kamila and Ambard, Alexander and Waterman, Amanda},
title = {Why Users Disintermediate Peer-to-Peer Marketplaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025815},
doi = {10.1145/3025453.3025815},
abstract = {This paper reports on a study of the prevalence of and possible reasons for peer-to-peer transaction marketplace (P2PM) users turning to out-of-market (OOM) transactions after finding transaction partners within a P2P system. We surveyed 97 P2PM users and interviewed 22 of 58 who reported going OOM. We did not find any evidence of predisposing personality factors for OOM activity; instead, it seems to be a rational response to circumstances, with a variety of situationally rational motivations at play, such as liking the transaction partner and trusting that good quality repeat transactions will occur in the future.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4370–4382},
numpages = {13},
keywords = {peer-to-peer marketplaces, motivations, disincentives},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025608,
author = {Tokuda, Yutaka and Norasikin, Mohd Adili and Subramanian, Sriram and Martinez Plasencia, Diego},
title = {MistForm: Adaptive Shape Changing Fog Screens},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025608},
doi = {10.1145/3025453.3025608},
abstract = {We present MistForm, a shape changing fog display that can support one or two users interacting with either 2D or 3D content. Mistform combines affordances from both shape changing interfaces and mid-air displays. For example, a concave display can maintain content in comfortable reach for a single user, while a convex shape can support several users engaged on individual tasks. MistForm also enables unique interaction possibilities by exploiting the synergies between shape changing interfaces and mid-air fog displays. For instance, moving the screen will affect the brightness and blurriness of the screen at specific locations around the display, creating spaces with similar (collaboration) or different visibility (personalized content). We describe the design of MistForm and analyse its inherent challenges, such as image distortion and uneven brightness on dynamic curved surfaces. We provide a machine learning approach to characterize the shape of the screen and a rendering algorithm to remove aberrations. We finally explore novel interactive possibilities and reflect on their potential and limitations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4383–4395},
numpages = {13},
keywords = {shape changing displays, 3d displays, non-solid diffusers.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025806,
author = {Berard, Francois and Louis, Thibault},
title = {The Object Inside: Assessing 3D Examination with a Spherical Handheld Perspective-Corrected Display},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025806},
doi = {10.1145/3025453.3025806},
abstract = {Handheld Perspective Corrected Displays (HPCDs) can create the feeling of holding a virtual 3D object. They offer a direct interaction that is isomorphic to the manipulation of physical objects. This illusion depends on the ability to provide a natural visuomotor coupling. High performances systems are thus required to evaluate the fundamental merits of HPCDs. We built a spherical HPCD using external projection. The system offers a lightweight wireless seamless display with head-coupled stereo, robust tracking, and low latency. We compared users' performances with this HPCD and two other interactions that used a fixed planar display and either a touchpad or the spherical display as an indirect input. The task involved the inspection of complex virtual 3D puzzles. Physical puzzles were also tested as references. Contrary to expectations, all virtual interactions were found to be more efficient than a more "natural" physical puzzle. The HPCD yielded lower performances than the touchpad. This study indicates that the object examination task did not benefit from the accurate and precise rotations offered by the HPCD, but benefited from the high C/D gain of the touchpad.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4396–4404},
numpages = {9},
keywords = {isomorphic rotation, handheld perspective corrected display (hpcd), depth perception, 3d display, object examination, evaluation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025677,
author = {Serrano, Marcos and Roudaut, Anne and Irani, Pourang},
title = {Visual Composition of Graphical Elements on Non-Rectangular Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025677},
doi = {10.1145/3025453.3025677},
abstract = {Graphical user interfaces are composed of varying elements (text, images, etc.) whose visual arrangement has been relatively well established in the context of rectangular interfaces. The advent of non-rectangular displays questions this knowledge. In this paper we study how traditional content layouts can be adapted to fit different non-rectangular displays. We performed a first qualitative study where graphic designers fitted text and images into different non-rectangular displays. From the analysis of their output we generalize and adapt ten composition principles that have been proposed in the literature for rectangular displays. We evaluate the revised principles through a paired comparison questionnaire where 57 participants compared pairs of layouts. Using the Bradley-Terry-Luce model to analyze our data we show that some results contradict current conventions on visual design for rectangular displays. We then extracted the most interesting cases and conducted a follow up study with additional shapes to investigate how the principles generalize. From these results we propose a set of guidelines for designing visual content for non-rectangular displays.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4405–4416},
numpages = {12},
keywords = {freeform display, non-rectangular display, visual design guidelines},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025488,
author = {Carrascal, Juan Pablo and Vertegaal, Roel},
title = {Effects of Tactile Feedback on the Perception of Virtual Shapes on Non-Planar DisplayObjects},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025488},
doi = {10.1145/3025453.3025488},
abstract = {In this paper, we report on a study investigating a novel haptic illusion for altering the perception of 3D shapes using a non-planar screen and vibrotactile friction. In our study, we presented an image of a rectangular prism on a cylindrical and a flat display. Participants were asked to move their index finger horizontally along the surface of the displays towards the edge of the rectangular prism. Participants were asked whether they were experiencing a flat, cylindrical or rectangular shape. In one condition, a vibrotactile stimulus simulated increasing friction towards the visible edge of the rectangular prism, with a sudden drop-off when this edge was crossed by the finger. Results suggest that presenting an image of a rectangular prism, and applying vibrotactile friction, particularly on a cylindrical display, significantly increased participant ratings stating that they were experiencing a physical rectangular shape.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4417–4423},
numpages = {7},
keywords = {vibrotactile feedback, shaped displays, organic user interfaces, displayobjects},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025973,
author = {Alak\"{a}rpp\"{a}, Ismo and Jaakkola, Elisa and Colley, Ashley and H\"{a}kkil\"{a}, Jonna},
title = {BreathScreen: Design and Evaluation of an Ephemeral UI},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025973},
doi = {10.1145/3025453.3025973},
abstract = {We present BreathScreen, a concept where clouds created by breathing are used as a projection surface for a picoprojector, creating an ephemeral user interface. In cold weather conditions the clouds are created naturally by warm breath condensing, but in other conditions an electric vaporizer may be used. We present an initial evaluation of the concept in a user study (n = 8), utilising a vaporizer-based BreathScreen prototype. The concept was positively received by study participants as a natural, hands-free interface and considered magical and aesthetically beautiful. Additionally, we provide guidance on the quantity of content that may be displayed on a BreathScreen, which is limited both by the length of a human breath and the contrast of the system.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4424–4429},
numpages = {6},
keywords = {ephemeral user interfaces, fog screen, evanescent screen, picoprojector},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025575,
author = {Hale, Scott A. and Eleta, Irene},
title = {Foreign-Language Reviews: Help or Hindrance?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025575},
doi = {10.1145/3025453.3025575},
abstract = {The number and quality of user reviews greatly affects consumer purchasing decisions. While reviews in all languages are increasing, it is still often the case (especially for non-English speakers) that there are only a few reviews in a person's first language. Using an online experiment, we examine the value that potential purchasers receive from interfaces showing additional reviews in a second language. The results paint a complicated picture with both positive and negative reactions to the inclusion of foreign-language reviews. Roughly 26-28% of subjects clicked to see translations of the foreign-language content when given the opportunity, and those who did so were more likely to select the product with foreign-language reviews than those who did not.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4430–4442},
numpages = {13},
keywords = {user-generated content, multilingualism, e-commerce, internationalization and localization, product reviews, bilingualism, experiment},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026017,
author = {Hupfeld, Annika and Speed, Chris},
title = {Getting Something for Nothing? A User-Centric Perspective on Loyalty Card Schemes},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026017},
doi = {10.1145/3025453.3026017},
abstract = {Loyalty cards are a form of tracking and recording technology (TRT) that enables retailers to collect data about their customers' demographic and purchase behaviours. As recompense for sharing their data consumers receive 'loyalty points' which they can redeem for exclusive discounts and rewards. The design of loyalty schemes, and TRTs more generally, plays a key role in defining the economic terms of that exchange, and ultimately the economic value of personal data. In this paper we present findings from an interview study with 12 loyalty cardholders in the UK explicating the ways in which they create (and lose) value through the everyday practice of shopping with loyalty cards and the orientations associated with them. Based on our findings we suggest cardholders are less concerned with the protection of their privacy than with leveraging its value, only some of which was economic. We provide design guidelines for TRTs that may enable consumers to derive greater value from the data they produce and share.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4443–4453},
numpages = {11},
keywords = {personal data, interview study, tracking and recording technologies, digital economy, retail shopping, loyalty cards},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025791,
author = {Foong, Eureka and Dow, Steven P. and Bailey, Brian P. and Gerber, Elizabeth M.},
title = {Online Feedback Exchange: A Framework for Understanding the Socio-Psychological Factors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025791},
doi = {10.1145/3025453.3025791},
abstract = {To meet the demand for authentic, timely, and affordable feedback, researchers have explored technologies to connect designers with feedback providers online. While researchers have implemented mechanisms to improve the content of feedback, most systems for online feedback exchange do not support an end-to-end cycle, from help-seeking to sense-making to action. Building on extant literature in learning sciences, design, organizational behavior, and online communities, we propose a conceptual framework to highlight critical processes that affect online feedback exchange. We contribute research questions for future feedback systems and argue that online feedback systems must be able to support designers through five activities that happen before, during, and after the feedback exchange. Our framework suggests that systems should address broader socio-psychological factors, such as how intent should be communicated online, how dialogue can support the interpretation of feedback, and how to balance the tradeoffs of anonymizing feedback providers.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4454–4467},
numpages = {14},
keywords = {social networks, online communities, design methods, crowdsourcing, online feedback exchange, feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025581,
author = {Pope, Vanessa C. and Dawes, Robert and Schweiger, Florian and Sheikh, Alia},
title = {The Geometry of Storytelling: Theatrical Use of Space for 360-Degree Videos and Virtual Reality},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025581},
doi = {10.1145/3025453.3025581},
abstract = {360-degree filming and head-mounted displays (HMDs) give recorded media a new sense of space. Theatre practitioners' expertise in manipulating spatial interactions has much to contribute to immersive recorded content. Four theatre directors led teams of three actors to stage the same scene for both immersive theatre and for 360-degree filming. Each team was recorded performing the scene at least six times, three in each condition, to extract actors' coordinates. This study establishes how to quantify theatre practitioners' use of spatial interactions and examines the spatial adaptations made when transferring these relationships to 360-degree filming.Staging for a 360-degree camera compared to staging for an audience member had shorter distances from the camera and between performers, along with fewer instances of the camera being in the middle of the action. Across all groups, interpersonal distance between characters and between the audience/camera dropped at the end of the scene when the characters come together as a team, suggesting that elements of Proxemics may be applicable to narrative performance.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4468–4478},
numpages = {11},
keywords = {narrative, cinematic vr, head-mounted display, performance, theatre, interpersonal space, workflow, virtual reality, 360-degree video},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025964,
author = {Yu, Chun and Gu, Yizheng and Yang, Zhican and Yi, Xin and Luo, Hengliang and Shi, Yuanchun},
title = {Tap, Dwell or Gesture? Exploring Head-Based Text Entry Techniques for HMDs},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025964},
doi = {10.1145/3025453.3025964},
abstract = {Despite the increasing popularity of head mounted displays (HMDs), development of efficient text entry methods on these devices has remained under explored. In this paper, we investigate the feasibility of head-based text entry for HMDs, by which, the user controls a pointer on a virtual keyboard using head rotation. Specifically, we investigate three techniques: TapType, DwellType, and GestureType. Users of TapType select a letter by pointing to it and tapping a button. Users of DwellType select a letter by pointing to it and dwelling over it for a period of time. Users of GestureType perform word-level input using a gesture typing style. Two lab studies were conducted. In the first study, users typed 10.59 WPM, 15.58 WPM, and 19.04 WPM with DwellType, TapType, and GestureType, respectively. Users subjectively felt that all three of the techniques were easy to learn and considered the induced fatigue to be acceptable. In the second study, we further investigated GestureType. We improved its gesture-word recognition algorithm by incorporating the head movement pattern obtained from the first study. This resulted in users reaching 24.73 WPM after 60 minutes of training. Based on these results, we argue that head-based text entry is feasible and practical on HMDs, and deserves more attention.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4479–4488},
numpages = {10},
keywords = {dwelling, gesture keyboard, head-based text entry, hmd},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025748,
author = {Oogjes, Doenja and Wakkary, Ron},
title = {Videos of Things: Speculating on, Anticipating and Synthesizing Technological Mediations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025748},
doi = {10.1145/3025453.3025748},
abstract = {In this paper we present Videos of Things: videos that portray the mediated, lived world of computational artifacts informed by postphenomenology. In a post-phenomenological understanding, things and us are interdependent in that they mutually shape each other. And as a whole, technology or designed things mediate the relations between our world and us. This can be a challenge for designers. Through the making of design videos, we explored narrative strategies for creating stories featuring technological mediation. These include humanness, patterns in time, and non-human ensembles. We reflect on how the videos at different stages of the design process have helped to a) speculate on technological mediated relationships, b) synthesize and reflect on qualitative data on technological mediation and c) anticipate technological mediation. The paper contributes different narrative strategies for design videos and the role these videos can play within a design process aimed at elaborating the mediated qualities of technologies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4489–4500},
numpages = {12},
keywords = {mediation theory, post-phenomenology, design videos, speculative design., material speculation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025519,
author = {Tang, Anthony and Fakourfar, Omid},
title = {Watching 360° Videos Together},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025519},
doi = {10.1145/3025453.3025519},
abstract = {360° videos are made using omnidirectional cameras that capture a sphere around the camera. Viewers get an immersive experience by freely changing their field of view around the sphere. The problem is that current interfaces are designed for a single user, and we do not know what challenges groups of people will have when viewing these videos together. We report on the findings of a study where 16 pairs of participants watched 360° videos together in a "guided tour" scenario. Our findings indicate that while participants enjoyed the ability to view the scene independently, this caused challenges establishing joint references, leading to breakdowns in conversation. We conclude by discussing how gaze awareness widgets and gesturing mechanisms may support smoother collaborative interaction around collaborative viewing of 360° videos.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4501–4506},
numpages = {6},
keywords = {360° videos, omnidirectional videos, shared experience},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025543,
author = {Le, Huyen T. and Boynton, G. R. and Mejova, Yelena and Shafiq, Zubair and Srinivasan, Padmini},
title = {Revisiting The American Voter on Twitter},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025543},
doi = {10.1145/3025453.3025543},
abstract = {The American Voter - a seminal work in political science - uncovered the multifaceted nature of voting behavior which has been corroborated in electoral research for decades since. In this paper, we leverage The American Voter as an analysis framework in the realm of computational political science, employing the factors of party, personality, and policy to structure the analysis of public discourse on online social media during the 2016 U.S. presidential primaries. Our analysis of 50 million tweets reveals the continuing importance of these three factors; our understanding is also enriched by the application of sentiment analysis techniques. The overwhelmingly negative sentiment of conversations surrounding 10 major presidential candidates reveals more "crosstalk" from Democratic leaning users towards Republican candidates, and less vice-versa. We uncover the lack of moderation as the most discussed personality dimension during this campaign season, as the political field becomes more extreme - Clinton and Rubio are perceived as moderate, while Trump, Sanders, and Cruz are not. While the most discussed issues are foreign policy and immigration, Republicans tweet more about abortion than Democrats who tweet more about gay rights than Republicans. Finally, we illustrate the importance of multifaceted political discourse analysis by applying regression to quantify the impact of party, personality, and policy on national polls.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4507–4519},
numpages = {13},
keywords = {election, sentiment analysis, twitter, political affiliation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025891,
author = {Gui, Xinning and Kou, Yubo and Pine, Kathleen H. and Chen, Yunan},
title = {Managing Uncertainty: Using Social Media for Risk Assessment during a Public Health Crisis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025891},
doi = {10.1145/3025453.3025891},
abstract = {Recently, diseases like H1N1 influenza, Ebola, and Zika virus have created severe crises, requiring public resources and personal behavior adaptation. Crisis Informatics literature examines interconnections of people, organizations, and IT during crisis events. However, how people use technology to cope with disease crises (outbreaks, epidemics, and pandemics) remains understudied. We investigate how individuals used social media in response to the outbreak of Zika, focusing on travel-related decisions. We found that extreme uncertainty and ambiguity characterized the Zika virus crisis. To cope, people turned to social media for information gathering and social learning geared towards personal risk assessment and modifying decisions when dealing with partial and conflicting information about Zika. In particular, individuals sought local information and used socially informed logical reasoning to deduce the risk at a specific locale. We conclude with implications for designing information systems to support individual risk assessment and decision-making when faced with uncertainty and ambiguity during public health crises.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4520–4533},
numpages = {14},
keywords = {online forums, social media, public health, decision-making, uncertainty reduction, Zika virus, risk assessment, crisis informatics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025885,
author = {Nelimarkka, Matti and Salovaara, Antti and Semaan, Bryan and Jacucci, Giulio},
title = {Theory-Driven Collocated CMC: A Study of Collocated Mediated Interaction as a Public Sphere},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025885},
doi = {10.1145/3025453.3025885},
abstract = {Computer-mediated communication (CMC) tools are used to increase social interaction in collocated settings. Recent research has been primarily constructive (oriented to building of systems) or phenomenon-driven (serving attempts to understand interactions in collocated CMC). The paper contributes a theory-driven approach and examines collocated CMC as a Habermasean "public sphere": a space that supports inclusive, civil, and rational discussion. An in-the-wild experimental study comparing CMC with face-to-face (F2F) communication enabled ascertaining that CMC is more inclusive than F2F communication. Respectfulness levels did not differ but were established differently: via collective construction of a common narrative in F2F and through quick reactions in CMC. Similarly, while rationality figures were on a par, F2F communication allowed participants to justify their claims better. The article discusses how a theory-based approach can strengthen phenomenon-driven research with new conceptual frames and measurement tools, and steer constructive research with a normative framework.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4534–4547},
numpages = {14},
keywords = {deliberative democracy, collocated computer mediated communication, public sphere},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025537,
author = {Plank, Thomas and Jetter, Hans-Christian and R\"{a}dle, Roman and Klokmose, Clemens N. and Luger, Thomas and Reiterer, Harald},
title = {Is Two Enough? ! Studying Benefits, Barriers, and Biases of Multi-Tablet Use for Collaborative Visualization},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025537},
doi = {10.1145/3025453.3025537},
abstract = {A sizable part of HCI research on cross-device interaction is driven by the vision of users conducting complex knowledge work seamlessly across multiple mobile devices. This is based on the Weiserian assumption that people will be inclined to distribute their work across multiple ``pads' if such are available. We observed that this is not the reality today, even when devices were in abundance. We present a study with 24 participants in 12 dyads completing a collaborative visualization task with up to six tablets. They could choose between three different visualization types to answer questions about economic data. Tasks were designed to afford simultaneous use of tablets, either with linked or independent views. We found that users typically utilized only one tablet per user. A quantitative and qualitative analysis revealed a ``legacy bias' that introduced barriers for using more tablets and reduced the overall benefit of multi-device visualization.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4548–4560},
numpages = {13},
keywords = {cross-device interaction, tablets, group work, information visualization, multiple coordinated views},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025693,
author = {Kim, Auk and Kang, Sungjoon and Lee, Uichin},
title = {LetsPic: Supporting In-Situ Collaborative Photography over a Large Physical Space},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025693},
doi = {10.1145/3025453.3025693},
abstract = {Recent advances in mobile computing technology have made it increasingly common for collocated users to perform collaborative photography over a large physical space in various group activity scenarios such as field trips, site surveys, and group tours. Unlike traditional collocated interactions in a shared physical space, we find that mobility and group dynamics make awareness of group activities over a large physical space very challenging. In this work, we design LetsPic, a group photoware that supports group awareness for in-situ collaborative photography over the large physical space. We have iteratively built the app and performed user studies in site survey and group tour scenarios (n = 31, n = 24). Our results confirmed that LetsPic effectively promotes group awareness, facilitates group coordination, and encourages collaboration in both scenarios. We discuss practical design implications based on our findings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4561–4573},
numpages = {13},
keywords = {awareness, photoware, collaborative photowork, collocated interaction, photography},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025547,
author = {Nebeling, Michael},
title = {XDBrowser 2.0: Semi-Automatic Generation of Cross-Device Interfaces},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025547},
doi = {10.1145/3025453.3025547},
abstract = {Several recent studies have highlighted the need to support parallel usage of multiple devices for cross-device use. Yet, most interfaces today are still designed for single-device use and require re-authoring to enable cross-device interaction. This paper presents two studies to inform the design of a new web browser with support for semi-automatic generation of cross-device interfaces. Based on the results of a recent study in which users manually customized web pages for cross-device use, our first study elicits from users how they might want to trigger popular cross-device patterns to transform single-device designs with relatively little effort. Our second study then examines how the emerging design patterns could be applied to the Alexa top 50 sites from 10 different genres. Based on these studies, we design semi-automatic techniques for page segmentation and distribution between multiple devices that can work on many existing web sites and require only minimal user input to switch between different cross-device designs. Finally, we discuss possible extensions to the Chrome web browser to make the techniques available for a wide range of desktop, mobile, and wearable devices, and successfully test them on popular web sites.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4574–4584},
numpages = {11},
keywords = {cross-device interaction, semi-automatic page segmentation, distributed user interfaces},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025633,
author = {Dombrowski, Lynn and Alvarado Garcia, Adriana and Despard, Jessica},
title = {Low-Wage Precarious Workers' Sociotechnical Practices Working Towards Addressing Wage Theft},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025633},
doi = {10.1145/3025453.3025633},
abstract = {Nearly 40 million workers in the USA, a third of the working population, are low-wage, meaning they make less than $11.65 per hour. These workers face the pervasive and detrimental challenge of wage violations, also known as wage theft, which is any illegal activity by an employer that denies benefits or wages to employees. We interviewed 24 low-wage workers who experienced wage theft and sought justice about their work practices, challenges, and information technology usage. Based on these interviews, we identify three key sociotechnical practices these workers engaged in to address their wage theft: 1) identifying wage and payment discrepancies; 2) tracking and documenting work; and 3) pursuing wage claims. Seeking to leverage HCI research to interrupt uneven social, economic, and information relations in the low-wage workplace, we ultimately reflect on the possibility and limits of several key design recommendations.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4585–4598},
numpages = {14},
keywords = {technologies in the workplace, wage theft, work practice, workplace studies, wage and hourly violations, precarious workers, wage disputes, labor, low-wage workers},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025974,
author = {Alkhatib, Ali and Bernstein, Michael S. and Levi, Margaret},
title = {Examining Crowd Work and Gig Work Through The Historical Lens of Piecework},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025974},
doi = {10.1145/3025453.3025974},
abstract = {The internet is empowering the rise of crowd work, gig work, and other forms of on-demand labor. A large and growing body of scholarship has attempted to predict the socio-technical outcomes of this shift, especially addressing three questions: 1) What are the complexity limits of on-demand work?, 2) How far can work be decomposed into smaller microtasks?, and 3) What will work and the place of work look like for workers? In this paper, we look to the historical scholarship on piecework — a similar trend of work decomposition, distribution, and payment that was popular at the turn of the 20th century — to understand how these questions might play out with modern on-demand work. We identify the mechanisms that enabled and limited piecework historically, and identify whether on-demand work faces the same pitfalls or might differentiate itself. This approach introduces theoretical grounding that can help address some of the most persistent questions in crowd work, and suggests design interventions that learn from history rather than repeat it.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4599–4616},
numpages = {18},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026032,
author = {Huang, Yun and Huang, Yifeng and Xue, Na and Bigham, Jeffrey P.},
title = {Leveraging Complementary Contributions of Different Workers for Efficient Crowdsourcing of Video Captions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026032},
doi = {10.1145/3025453.3026032},
abstract = {Hearing-impaired people and non-native speakers rely on captions for access to video content, yet most videos remain uncaptioned or have machine-generated captions with high error rates. In this paper, we present the design, implementation and evaluation of BandCaption, a system that combines automatic speech recognition with input from crowd workers to provide a cost-efficient captioning solution for accessible online videos. We consider four stakeholder groups as our source of crowd workers: (i) individuals with hearing impairments, (ii) second-language speakers with low proficiency, (iii) second-language speakers with high proficiency, and (iv) native speakers. Each group has different abilities and incentives, which our workflow leverages. Our findings show that BandCaption enables crowd workers who have different needs and strengths to accomplish micro-tasks and make complementary contributions. Based on our results, we outline opportunities for future research and provide design suggestions to deliver cost-efficient captioning solutions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4617–4626},
numpages = {10},
keywords = {complementary contributions, crowdsourcing, video caption},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025883,
author = {Krause, Markus and Garncarz, Tom and Song, JiaoJiao and Gerber, Elizabeth M. and Bailey, Brian P. and Dow, Steven P.},
title = {Critique Style Guide: Improving Crowdsourced Design Feedback with a Natural Language Model},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025883},
doi = {10.1145/3025453.3025883},
abstract = {Designers are increasingly leveraging online crowds; yet, online contributors may lack the expertise, context, and sensitivity to provide effective critique. Rubrics help feedback providers but require domain experts to write them and may not generalize across design domains. This paper introduces and tests a novel semi-automated method to support feedback providers by analyzing feedback language. In our first study, 52 students from two design courses created design solutions and received feedback from 176 online providers. Instructors, students, and crowd contributors rated the helpfulness of each feedback response. From this data, an algorithm extracted a set of natural language features (e.g., specificity, sentiment etc.) that correlated with the ratings. The features accurately predicted the ratings and remained stable across different raters and design solutions. Based on these features, we produced a critique style guide with feedback examples - automatically selected for each feature - to help providers revise their feedback through self-assessment. In a second study, we tested the validity of the guide through a between-subjects experiment (n=50). Providers wrote feedback on design solutions with or without the guide. Providers generated feedback with higher perceived helpfulness when using our style-based guidance.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4627–4639},
numpages = {13},
keywords = {machine learning, natural language model, online education, artificial intelligence, feedback, review, peer feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025502,
author = {Buschek, Daniel and Alt, Florian},
title = {ProbUI: Generalising Touch Target Representations to Enable Declarative Gesture Definition for Probabilistic GUIs},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025502},
doi = {10.1145/3025453.3025502},
abstract = {We present ProbUI, a mobile touch GUI framework that merges ease of use of declarative gesture definition with the benefits of probabilistic reasoning. It helps developers to handle uncertain input and implement feedback and GUI adaptations. ProbUI replaces today's static target models (bounding boxes) with probabilistic gestures ("bounding behaviours"). It is the first touch GUI framework to unite concepts from three areas of related work: 1) Developers declaratively define touch behaviours for GUI targets. As a key insight, the declarations imply simple probabilistic models (HMMs with 2D Gaussian emissions). 2) ProbUI derives these models automatically to evaluate users' touch sequences. 3) It then infers intended behaviour and target. Developers bind callbacks to gesture progress, completion, and other conditions. We show ProbUI's value by implementing existing and novel widgets, and report developer feedback from a survey and a lab study.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4640–4653},
numpages = {14},
keywords = {touch gestures, probabilistic modelling, gui framework},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025565,
author = {Corsten, Christian and Daehlmann, Bjoern and Voelker, Simon and Borchers, Jan},
title = {BackXPress: Using Back-of-Device Finger Pressure to Augment Touchscreen Input on Smartphones},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025565},
doi = {10.1145/3025453.3025565},
abstract = {When people hold their smartphone in landscape orientation, they use their thumbs for input on the frontal touchscreen, while their remaining fingers rest on the back of the device (BoD) to stabilize the grip. We present BackXPress, a new interaction technique that lets users create BoD pressure input with these remaining fingers to augment their interaction with the touchscreen on the front: Users can apply various pressure levels with each of these fingers to enter different temporary "quasi-modes" that are only active as long as that pressure is applied. Both thumbs can then interact with the frontal screen in that mode. We illustrate the practicality of BackXPress with several sample applications, and report our results from three user studies: Study 1 investigated which fingers can be used to exert BoD pressure and found index, middle, and ring finger from both hands to be practical. Study 2 revealed how pressure touches from these six fingers are distributed across the BoD. Study 3 examined user performance for applying BoD pressure (a) during single touches at the front and (b) for 20 seconds while touching multiple consecutive frontal targets. Participants achieved up to 92% pressure accuracy for three separate pressure levels above normal resting pressure, with the middle fingers providing the highest accuracy. BoD pressure did not affect frontal touch accuracy. We conclude with design guidelines for BoD pressure input.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4654–4666},
numpages = {13},
keywords = {pressure, smartphone, back-of-device, bimanual input},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025941,
author = {Vatavu, Radu-Daniel},
title = {Improving Gesture Recognition Accuracy on Touch Screens for Users with Low Vision},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025941},
doi = {10.1145/3025453.3025941},
abstract = {We contribute in this work on gesture recognition to improve the accessibility of touch screens for people with low vision. We examine the accuracy of popular recognizers for gestures produced by people with and without visual impairments, and we show that the user-independent accuracy of $P, the best recognizer among those evaluated, is small for people with low vision (83.8%), despite $P being very effective for gestures produced by people without visual impairments (95.9%). By carefully analyzing the gesture articulations produced by people with low vision, we inform key algorithmic revisions for the P recognizer, which we call P+. We show significant accuracy improvements of $P+ for gestures produced by people with low vision, from 83.8% to 94.7% on average and up to 98.2%, and 3x faster execution times compared to P.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4667–4679},
numpages = {13},
keywords = {P, touch gestures, recognition accuracy, recognition, 1, point clouds, low vision, gesture recognition, evaluation, visual impairments, touch screens, algorithms, P+},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025835,
author = {Eardley, Rachel and Roudaut, Anne and Gill, Steve and Thompson, Stephen J.},
title = {Understanding Grip Shifts: How Form Factors Impact Hand Movements on Mobile Phones},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025835},
doi = {10.1145/3025453.3025835},
abstract = {In this paper we present an investigation into how hand usage is affected by different mobile phone form factors. Our initial (qualitative) study explored how users interact with various mobile phone types (touchscreen, physical keyboard and stylus). The analysis of the videos revealed that each type of mobile phone affords specific handgrips and that the user shifts these grips and consequently the tilt and rotation of the phone depending on the context of interaction. In order to further investigate the tilt and rotation effects we conducted a controlled quantitative study in which we varied the size of the phone and the type of grips (Symmetric bimanual, Asymmetric bimanual with finger, Asymmetric bimanual with thumb and Single handed) to better understand how they affect the tilt and rotation during a dual pointing task. The results showed that the size of the phone does have a consequence and that the distance needed to reach action items affects the phones' tilt and rotation. Additionally, we found that the amount of tilt, rotation and reach required corresponded with the participant's grip preference. We finish the paper by discussing the design lessons for mobile UI and proposing design guidelines and applications for these insights.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4680–4691},
numpages = {12},
keywords = {interaction, mobile device, grasp, handgrip, design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025468,
author = {Kang, Bo and LaViola Jr., Joseph J. and Wisniewski, Pamela},
title = {Structured Input Improves Usability and Precision for Solving Geometry-Based Algebraic Problems},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025468},
doi = {10.1145/3025453.3025468},
abstract = {Previous research has shown that sketch-based input is efficient and preferable in the context of algebraic equation solving. However, research has not been conducted to evaluate whether this holds true when involving geometry input to facilitate quantitative problem-solving. We developed a bimodal (graphing geometric shapes and writing algebraic expressions) user interface, in order to conduct a within-subject, controlled experiment with 24 college students and varied two types of geometry input: 1) sketch-based input and 2) structured input. The sketch-based input was significantly faster than the structured input, but there were no significant differences based on perception and cognition. However, after a post-hoc analysis, we found a significant interaction effect on perception between prior knowledge and geometry input. Novice students preferred the sketch-based input, but advanced students preferred the structured input. Our study implies that natural sketch-based input may be less preferable than structured input for geometry-based interfaces toward math problem-solving.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4692–4702},
numpages = {11},
keywords = {math learning environment, sketch input, geometry editing, gesture input},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025506,
author = {Swearngin, Amanda and Ko, Andrew J. and Fogarty, James},
title = {Genie: Input Retargeting on the Web through Command Reverse Engineering},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025506},
doi = {10.1145/3025453.3025506},
abstract = {Most web applications are designed as one-size-fits-all, despite considerable variation in people's expertise, physical abilities, and other factors that impact interaction. For example, some web applications require the use of a mouse, precluding use by many people with severe motor disabilities. Other applications require laborious manual input that a skilled developer could automate if the application were scriptable. This paper presents Genie, a system that automatically reverse engineers an abstract model of the underlying commands in a web application, then enables interaction with that functionality through alternative interfaces and other input modalities (e.g., speech, keyboard, or command line input). Genie comprises an abstract model of command properties, behaviors, and dependencies as well as algorithms that reverse engineer this model from an existing web application through static and dynamic program analysis. We evaluate Genie by developing several interfaces that automatically add support for speech, keyboard, and command line input to arbitrary web applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4703–4714},
numpages = {12},
keywords = {program analysis, reverse engineering, web applications},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025595,
author = {Giannisakis, Emmanouil and Bailly, Gilles and Malacria, Sylvain and Chevalier, Fanny},
title = {IconHK: Using Toolbar Button Icons to Communicate Keyboard Shortcuts},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025595},
doi = {10.1145/3025453.3025595},
abstract = {We propose a novel perspective on the design of toolbar buttons that aims to increase keyboard shortcut accessibility. IconHK implements this perspective by blending visual cues that convey keyboard shortcut information into toolbar buttons without denaturing the pictorial representation of their command. We introduce three design strategies to embed the hotkey, a visual encoding to convey the modifiers, and a magnification factor that determines the blending ratio between the pictogram of the button and the visual representation of the keyboard shortcut. Two studies examine the benefits of IconHK for end-users and provide insights from professional designers on the practicality of our approach for creating iconsets. Building on these insights, we develop a tool to assist designers in applying the IconHK design principle.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4715–4726},
numpages = {12},
keywords = {icons, hotkeys, gui design, keyboard shortcuts},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025863,
author = {Besan\c{c}on, Lonni and Issartel, Paul and Ammi, Mehdi and Isenberg, Tobias},
title = {Mouse, Tactile, and Tangible Input for 3D Manipulation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025863},
doi = {10.1145/3025453.3025863},
abstract = {We evaluate the performance and usability of mouse-based, touch-based, and tangible interaction for manipulating objects in a 3D virtual environment. This comparison is a step toward a better understanding of the limitations and benefits of these existing interaction techniques, with the ultimate goal of facilitating an easy transition between the different 3D data exploration environments. For this purpose we analyze participants' performance in 3D manipulation using a docking task. We measured completion times, docking accuracy, as well as subjective criteria such as fatigue, workload, and preference. Our results show that the three input modalities provide similar levels of precision but require different completion times. We also discuss our qualitative observations as well as people's preferences and put our findings into context of the application domain of 3D data analysis environments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4727–4740},
numpages = {14},
keywords = {TUI, usability study, mouse, 3D interaction, tactile interaction, tangible interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025970,
author = {Chandra, Priyank and Ahmed, Syed Ishtiaque and Pal, Joyojeet},
title = {Market Practices and the Bazaar: Technology Consumption in ICT Markets in the Global South},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025970},
doi = {10.1145/3025453.3025970},
abstract = {Local informal markets or bazaars play a central role in embedding the adoption, consumption, and reproduction of digital technologies within the economic and cultural fabric of the Global South. This paper presents ethnographic accounts of informal ICT markets in two sites, one in India and the other in Bangladesh, and assesses how technology consumption unfolds within local practices. Building on social practice theory, this paper depicts the role of materiality, relationships, and situated knowledge in the functioning of a bazaar. We discuss how this knowledge expands our understanding of the evaluation of technology and technical expertise, and the persistence of these informal spaces despite the uptake of corporatized technology marketplaces. We argue that the bazaar represents a special kind of local voice that enriches the HCI scholarship in postcolonial computing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4741–4752},
numpages = {12},
keywords = {markets, postcolonial, practice theory, bazaars, global south, informality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025481,
author = {Green, David Philip and Schofield, Guy and Pritchard, Gary and Olivier, Patrick and Wright, Peter},
title = {Cinehacking Cape Town - Embracing Informality in Pursuit of High Quality Media},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025481},
doi = {10.1145/3025453.3025481},
abstract = {Although many common tools of media making such as video cameras have become more accessible in recent years, many remain inaccessible. Cinematography, lighting and sound-recording equipment for example can be prohibitively expensive to obtain, complex to configure, and/or require specialist knowledge to operate effectively. These barriers can prevent non-professionals who want to produce high-quality media from being able to. Cinehack is an ongoing project to research ways to overcome these barriers. In this paper, we specifically report on Cinehack: Cape Town, a participatory media making project. By co-producing hip hop videos within a community for whom media making is often a "means-to-an-end", we were able gain insights into the kinds of support needed to enable high quality media making by non-professionals. Specifically, we highlight ways to meet users' needs by embracing informal codes of practice via experimental making and peer-support.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4753–4764},
numpages = {12},
keywords = {africa, hip-hop, hacking, diy, media, making},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025643,
author = {Chandra, Priyank},
title = {Informality and Invisibility: Traditional Technologies as Tools for Collaboration in an Informal Market},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025643},
doi = {10.1145/3025453.3025643},
abstract = {This paper explores how actors in local markets in the Global South adapt traditional communication technologies to successfully collaborate to sustain the markets and their business practices. Drawing on ethnographic observations at a local technology goods market in Bangalore, India, the study details the use of a landline telephone intercom system as the primary tool for business communication in the market. Through analyzing how the intercom system relates to informality and physical space, the paper argues that it bridges the formal with the informal, and helps facilitate informal business practices while also allowing them to remain hidden from the formal regulatory gaze of the state.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4765–4775},
numpages = {11},
keywords = {infrastructure, development, informal markets, HCI4D, telephone, intercom},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025910,
author = {Singh, Ranjit and Jackson, Steven J.},
title = {From Margins to Seams: Imbrication, Inclusion, and Torque in the Aadhaar Identification Project},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025910},
doi = {10.1145/3025453.3025910},
abstract = {Problems of marginalization and inclusion are central to HCI scholarship and impact in the world, but are badly named in the binary models of access that currently dominate the field. Building on prior work in ICTD and infrastructure studies, this paper explores the problem of inclusion through historical and ethnographic study of Aadhaar, India's biometrics-based national identification project. We illustrate tensions between Aadhaar users' ability to register, authenticate and successfully deploy their registered identity to participate in the Public Distribution System (PDS), a government scheme that provides subsidized food grains to the Indian poor. We argue that rather than an all-or-nothing state, inclusion in ICTD infrastructures is an ongoing and fragile process, achieved (unevenly) at the seams of multiple interconnected systems. Finally, we show that questions of (effective) inclusion are determined not just at margins of a system (who is in and who is out) but also through the artful and often challenging negotiation of the seams that run through and connect complex distributed infrastructures.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4776–4824},
numpages = {49},
keywords = {materiality, access, India, bureaucracy, biometrics, infrastructure, ICTD, inclusion},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025751,
author = {Taylor, Robyn and Spence, Jocelyn and Walker, Brendan and Nissen, Bettina and Wright, Peter},
title = {Performing Research: Four Contributions to HCI},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025751},
doi = {10.1145/3025453.3025751},
abstract = {This paper identifies a body of HCI research wherein the researchers take part in digitally mediated creative experiences alongside participants. We present our definition and rationale for "self-situated performance research" based on theories in both the HCI and performance literatures. We then analyse four case studies of this type of work, ranging from overtly "performative" staged events to locative audio and public making.We argue that by interrogating experience from within the context of self-situated performance, the 'performer/researcher' extends traditional practices in HCI in the following four ways: developing an intimate relationship between researchers and participants, providing new means of making sense of interactions, shaping participants' relationship to the research, and enabling researchers to refine their work as it is being conducted.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4825–4837},
numpages = {13},
keywords = {performing research, public making, sense-making, performance, practice, self-situated research, design from within},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025722,
author = {Javornik, Ana and Rogers, Yvonne and Gander, Delia and Moutinho, Ana},
title = {MagicFace: Stepping into Character through an Augmented Reality Mirror},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025722},
doi = {10.1145/3025453.3025722},
abstract = {Augmented Reality (AR) is coming of age and appearing in various smartphone apps. One emerging AR type uses the front-facing camera and overlays a user's face with digital features that transform the physical appearance, making the user look like someone else, such as a popstar or a historical character. However, little is known about how people react to such stepping into character and how convincing they perceive it to be. We developed an app with two Egyptian looks, MagicFace, which was situated both in an opera house and a museum. In the first setting, people were invited to use the app, while in the second setting they came across it on their own when visiting the exhibition. Our findings show marked differences in how people approach and experience the MagicFace in these different contexts. We discuss how realistic and compelling this kind of AR technology is, as well as its implications for educational and cultural settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4838–4849},
numpages = {12},
keywords = {opera characters, augmented reality, interface design, in-the-wild study},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025897,
author = {Rossitto, Chiara and Normark, Maria and Barkhuus, Louise},
title = {Interactive Performance as a Means of Civic Dialogue},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025897},
doi = {10.1145/3025453.3025897},
abstract = {This paper presents a case study of an interactive performance that was produced and designed to encourage civic engagement and reflection in relation to the social tensions in a low-income suburb, mostly inhabited by people with immigrant backgrounds. The design of the technological setup in the performance encouraged participation by means of text entries that audience members could share with others. The analysis draws on the corpus of interview and observational data collected, as well as the related text messages that were shared during the performance. We illustrate the different levels at which citizens make sense of societal issues they are concerned about, as well as the audience-citizens' perception of participating in such an artistic experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4850–4862},
numpages = {13},
keywords = {qualitative studies, mobile technology., interactive performance, digital civics, social participation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025854,
author = {Pellicone, Anthony J. and Ahn, June},
title = {The Game of Performing Play: Understanding Streaming as Cultural Production},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025854},
doi = {10.1145/3025453.3025854},
abstract = {Live streaming has become pervasive in digital game culture. Previous work has focused largely on technological considerations in streaming platforms. However, little is known about how streamers enter the practice, gain skills, and operate as content producers. We present a qualitative study of an online forum dedicated to streaming. By observing the conversations between veterans and newcomers to the practice, we develop an understanding of how streamers must tie together technological, social, and gameplay-based skills to craft an appealing performance of play. We find that a key skill in streaming is the development of a unique attitude and persona as a gamer, which permeates into every element of a streamer's performance. As individual identity becomes important in streaming practice, design considerations for platform features such as community moderation and stream metrics may help improve equitable participation in this increasingly important aspect of game culture.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4863–4874},
numpages = {12},
keywords = {games studies, games and learning, streaming media, digital games},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025510,
author = {Chung, Chia-Fang and Gorm, Nanna and Shklovski, Irina A. and Munson, Sean},
title = {Finding the Right Fit: Understanding Health Tracking in Workplace Wellness Programs},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025510},
doi = {10.1145/3025453.3025510},
abstract = {Workplace health and wellness programs are increasingly integrating personal health tracking technologies, such as Fitbit and Apple Watch. Many question whether these technologies truly support employees in their pursuit of better wellness levels, raising objections about workplace surveillance and further blurring of boundaries between work and personal life. We conducted a study to understand how tracking tools are adopted in wellness programs and employees' opinions about these programs. We find that employees are generally positive about incentivized health tracking in the workplace, as it helps raise awareness of activity levels. However, there is a gap between the intentions of the programs and individual experiences and health goals. This sometimes results in confusion and creates barriers to participation. Even if this gap can be addressed, health tracking in the workplace will not be for everyone; this has implications for the design of both workplace wellness programs and tracking technologies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4875–4886},
numpages = {12},
keywords = {workplace, self-tracking, health and wellness program},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025544,
author = {Fan, Xiangmin and Luo, Wencan and Wang, Jingtao},
title = {Mastery Learning of Second Language through Asynchronous Modeling of Native Speakers in a Collaborative Mobile Game},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025544},
doi = {10.1145/3025453.3025544},
abstract = {Acquiring Chinese tones is often considered as the most difficult task in learning Chinese as a Second Language (CSL). Recently, ToneWars, a collaborative mobile learning game, demonstrated the feasibility and efficacy of connecting CSL learners with native speakers for tone learning. However, the synchronous gameplay nature in ToneWars can be hard to scale due to the time constraint and limited availability of native speakers. We present principled research to make ToneWars scalable and sustainable. First, we address the scalability issue via asynchronous modeling of native speakers. Second, we quantify whether a CSL learner achieves native level mastery for a specific phrase, and explore the use of fine-grained feedback on language mastery as a sustainable motivator for language learning. The insights in this research are generalizable to designing second language learning technologies beyond Chinese. In a longitudinal study with 18 CSL learners, we found that asynchronous gameplay significantly improved learning with an average gain of 29.7 tones and 16.4 syllables, and helped participants achieve native level mastery on 58.2 out of 69 phrases.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4887–4898},
numpages = {12},
keywords = {mobile learning, serious games, mandarin tones, evaluation, collaborative learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025691,
author = {Marshall, Joe and Linehan, Conor},
title = {Misrepresentation of Health Research in Exertion Games Literature},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025691},
doi = {10.1145/3025453.3025691},
abstract = {HCI often requires scholars to build upon research from fields outside their expertise, creating the risk that foundational work is misunderstood and misrepresented. The prevailing goal of "exergames" research towards ameliorating obesity appears to be built on just such a misunderstanding of health research. In this paper, we analyse all citations to a single influential study, which has been extensively cited to justify research on exergames. We categorise the 375 citations based on whether they represent the findings of that study accurately or inaccurately. Our findings suggest that 69% of exergames papers citing this study misrepresent the findings, demonstrating a systematic failure of scholarship in exergames research. We argue that exergaming research should cease focusing on games as treatment for obesity, and that HCI publications should demand more critical and scholarly engagement with research from outside HCI.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4899–4910},
numpages = {12},
keywords = {health, games, exertion games, obesity, exertion},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025711,
author = {Arawjo, Ian and Wang, Cheng-Yao and Myers, Andrew C. and Andersen, Erik and Guimbreti\`{e}re, Fran\c{c}ois},
title = {Teaching Programming with Gamified Semantics},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025711},
doi = {10.1145/3025453.3025711},
abstract = {Dominant approaches to programming education emphasize program construction over language comprehension. We present Reduct, an educational game embodying a new, comprehension-first approach to teaching novices core programming concepts which include functions, Booleans, equality, conditionals, and mapping functions over sets. In this novel teaching strategy, the player executes code using reduction-based operational semantics. During gameplay, code representations fade from concrete, block-based graphics to the actual syntax of JavaScript ES2015. We describe our design rationale and report on the results of a study evaluating the efficacy of our approach on young adults (18+) without prior coding experience. In a short timeframe, novices demonstrated promising learning of core concepts expressed in actual JavaScript. We also present results from an online deployment. Finally, we discuss ramifications for the design of future computational thinking games.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4911–4923},
numpages = {13},
keywords = {novice programming, concreteness fading, educational games, block-based programming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025546,
author = {Prabhakar, Annu Sible and Guerra-Reyes, Lucia and Kleinschmidt, Vanessa M. and Jelen, Ben and MacLeod, Haley and Connelly, Kay and Siek, Katie A.},
title = {Investigating the Suitability of the Asynchronous, Remote, Community-Based Method for Pregnant and New Mothers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025546},
doi = {10.1145/3025453.3025546},
abstract = {Traditional qualitative research methods, such as, interviews and focus groups, may not be feasible for certain populations- who face time, mobility, and availability constraints. We adapted the Asynchronous, Remote, Community-based (ARC) method that used closed Facebook groups to study people with rare diseases, to study a different population - pregnant and new mothers. During the course of eight weeks, we engaged 48 participants in 19 study activities using three closed Facebook groups. We added new activities to the original ARC method, informed by past HCI research, to triangulate participant input. We carefully analyzed participation patterns and activity engagement, to assess the suitability of the ARC method for engaging pregnant and new mothers in remote, group-based, qualitative research. We provide an in-depth analysis of the ARC method, noting participation characteristics, activity preferences, and the suitability of the ARC method as an online focus group.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4924–4934},
numpages = {11},
keywords = {maternal health, remote populations, facebook groups, socialsupport, focus groups},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025928,
author = {Le Moignan, Effie and Lawson, Shaun and Rowland, Duncan A. and Mahoney, Jamie and Briggs, Pam},
title = {Has Instagram Fundamentally Altered the 'Family Snapshot'?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025928},
doi = {10.1145/3025453.3025928},
abstract = {This paper considers how parents use the social media platform Instagram to facilitate the capture, curation and sharing of 'family snapshots'. Our work draws upon established cross-disciplinary literature relating to film photography and the composition of family albums in order to establish whether social media has changed the way parents visually present their families. We conducted a qualitative visual analysis of a sample of 4,000 photographs collected from Instagram using hashtags relating to children and parenting. We show that the style and composition of snapshots featuring children remains fundamentally unchanged and continues to be dominated by rather bland and idealised images of the happy family and the cute child. In addition, we find that the frequent taking and sharing of photographs via Instagram has inevitably resulted in a more mundane visual catalogue of daily life. We note a tension in the desire to use social media as a means to evidence good parenting, while trying to effectively manage the social identity of the child and finally, we note the reluctance of parents to use their own snapshots to portray family tension or disharmony, but their willingness to use externally generated content for this purpose.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4935–4947},
numpages = {13},
keywords = {photo-sharing, social media, families, parenting, instagram},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025572,
author = {Kim, Jinyoung and McNally, Brenna and Norooz, Leyla and Druin, Allison},
title = {Internet Search Roles of Adults in Their Homes},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025572},
doi = {10.1145/3025453.3025572},
abstract = {Internet search is one of the major activities that American adults engage in online. Building on studies of youth Internet search roles, this paper investigates adults' online information seeking processes within the home. Through in-home interviews and observations of search task performance with 40 adult participants, we identify and describe characteristics of 9 search roles. By comparing these roles with those of youths, we explain how previously identified roles, such as Power Searcher and Social Searcher, have evolved in adult populations, and how new roles, such as Efficient Searcher and Interest-driven Searcher, have emerged. We also review the challenges and benefits associated with search roles and their potential impacts on search performance. The findings of this study provide a better understanding of how contextual factors influence search roles in relation to ELIS, what can be learned from search roles, and opportunities to support different search roles.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4948–4959},
numpages = {12},
keywords = {home internet search, search strategies, everyday life information seeking, search roles, adult searchers},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026000,
author = {Hussien Ahmed, Mahmoud Mohamed and Silpasuwanchai, Chaklam and Salehzadeh Niksirat, Kavous and Ren, Xiangshi},
title = {Understanding the Role of Human Senses in Interactive Meditation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026000},
doi = {10.1145/3025453.3026000},
abstract = {In our fast-paced society, stress and anxiety have become increasingly common. Meditation for relaxation has received much attention. Meditation apps exploit various senses, e.g., touch, audio and vision, but the relationship between human senses and interactive meditation is not well understood. This paper empirically evaluates the effects of single and combined human senses on interactive meditation. We found that the effectiveness of human senses can be defined by their respective roles in maintaining the balance between relaxation and focus. This work is the first to attempt to understand these relationships. The findings have broad implications for the field of multi-modal interaction and interactive meditation applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4960–4965},
numpages = {6},
keywords = {"human senses, focus", interactive meditation, mindfulness, relaxation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025767,
author = {Lukoff, Kai and Moser, Carol and Schoenebeck, Sarita},
title = {Gender Norms and Attitudes about Childcare Activities Presented on Father Blogs},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025767},
doi = {10.1145/3025453.3025767},
abstract = {Father involvement is important for child well-being. However, fathers still do significantly less childcare than mothers, due in part to traditional gender norms. This research investigates whether incorporating do-it-yourself (DIY) language and imagery into parenting blogs is an effective mechanism for boosting fathers' willingness to perform childcare activities. We conducted a between-subjects experiment with 374 participants in the U.S. who responded to ten parenting blog posts. Subjects were randomized to view posts with either DIY or neutral language and either routine childcare activities (e.g., changing diapers) or interactive ones (e.g., finger painting). Results show that DIY language actually decreases a father's willingness to do a childcare activity. Further, fathers underestimate how socially appropriate it is for them to perform childcare activities and this misperception relates to their willingness to get involved. We draw on social norms literature to recommend next steps for designing interfaces to support father involvement in childrearing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4966–4971},
numpages = {6},
keywords = {masculinity, diy, norms, fathers, childcare, blogs},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025741,
author = {Culbertson, Heather and Walker, Julie M. and Raitor, Michael and Okamura, Allison M.},
title = {WAVES: A Wearable Asymmetric Vibration Excitation System for Presenting Three-Dimensional Translation and Rotation Cues},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025741},
doi = {10.1145/3025453.3025741},
abstract = {WAVES, a Wearable Asymmetric Vibration Excitation System, is a novel wearable haptic device for presenting three dimensions of translation and rotation guidance cues. In contrast to traditional vibration feedback, which usually requires that users learn to interpret a binary cue, asymmetric vibrations have been shown to induce a pulling sensation in a desired direction. When attached to the fingers, a single voicecoil actuator presents a translation guidance cue and a pair of voicecoil actuators presents a rotation guidance cue. The directionality of mechanoreceptors in the skin led to our choice of the location and orientation of the actuators in order to elicit very strong sensations in certain directions. For example, users distinguished a "left" cue versus a "right" cue 94.5% of the time. When presented with one of six possible direction cues, users on average correctly identified the direction of translation cues 86.1% of the time and rotation cues 69.0% of the time.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4972–4982},
numpages = {11},
keywords = {haptics, vibration, haptic guidance, wearable devices},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025702,
author = {Yasu, Kentaro},
title = {Magnetic Plotter: A Macrotexture Design Method Using Magnetic Rubber Sheets},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025702},
doi = {10.1145/3025453.3025702},
abstract = {This paper presents a method for designing tactile macrotextures with magnetic rubber sheets. In the method, named "Magnetic Plotter", a desktop digital plotting machine combined with a tiny neodymium magnet writes fine magnetic patterns on the surface of the magnetic rubber sheets. This method enables users to design magnetic fields freely with inexpensive commercially available materials as if they are drawing pictures. Moreover, when the magnetic sheets are rubbed together, unique haptic stimuli are displayed on the fingers. The haptic stimuli can be changed by the magnetic patterns designed on the rubber sheets. We developed a prototype of the Magnetic Plotter and investigated the range of the generated haptic stimuli and the texture design possibilities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4983–4993},
numpages = {11},
keywords = {diy, digital fabrication, magnets, interactive devices, home, haptic, tactile, rapid prototyping},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025812,
author = {Strohmeier, Paul and Hornb\ae{}k, Kasper},
title = {Generating Haptic Textures with a Vibrotactile Actuator},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025812},
doi = {10.1145/3025453.3025812},
abstract = {Vibrotactile actuation is mainly used to deliver buzzing sensations. But if vibrotactile actuation is tightly coupled to users' actions, it can be used to create much richer haptic experiences. It is not well understood, however, how this coupling should be done or which vibrotactile parameters create which experiences. To investigate how actuation parameters relate to haptic experiences, we built a physical slider with minimal native friction, a vibrotactile actuator and an integrated position sensor. By vibrating the slider as it is moved, we create an experience of texture between the sliding element and its track. We conducted a magnitude estimation experiment to map how granularity, amplitude and timbre relate to the experiences of roughness, adhesiveness, sharpness and bumpiness. We found that amplitude influences the strength of the perceived texture, while variations in granularity and timbre create distinct experiences. Our study underlines the importance of action in haptic perception and suggests strategies for deploying such tightly coupled feedback in everyday devices.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {4994–5005},
numpages = {12},
keywords = {magnitude estimation, haptic feedback, texture perception},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026010,
author = {Rekik, Yosra and Vezzoli, Eric and Grisoni, Laurent and Giraud, Fr\'{e}d\'{e}ric},
title = {Localized Haptic Texture: A Rendering Technique Based on Taxels for High Density Tactile Feedback},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026010},
doi = {10.1145/3025453.3026010},
abstract = {We investigate the relevance of surface haptic rendering techniques for tactile devices. We focus on the two major existing techniques and show that they have complementary benefits. The first one, called textsc{S}urface textsc{H}aptic textsc{O}bject (textsc{SHO}), which is based on finger position, is shown to be more suitable to render sparse textures; while the second one, called textsc{S}urface textsc{H}aptic textsc{T}exture (textsc{SHT}), which is based on finger velocity, is shown to be more suitable for dense textures and fast finger movements. We hence propose a new rendering technique, called textsc{L}ocalized textsc{H}aptic textsc{T}exture (textsc{LHT}), which is based on the concept of textit{taxel} considered as an elementary tactile information that is rendered on the screen. By using a grid of taxels to encode a texture, textsc{LHT} is shown to provide a consistent tactile rendering across different velocities for high density textures, and is found to reduce user textit{error rate} by up to 77.68% compared to textsc{SHO}.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5006–5015},
numpages = {10},
keywords = {rendering techniques, sht, sho, density, tactile feedback, taxel, texture, identification, velocity, lht},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025494,
author = {Gai, Wei and Yang, Chenglei and Bian, Yulong and Shen, Chia and Meng, Xiangxu and Wang, Lu and Liu, Juan and Dong, Mingda and Niu, Chengjie and Lin, Cheng},
title = {Supporting Easy Physical-to-Virtual Creation of Mobile VR Maze Games: A New Genre},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025494},
doi = {10.1145/3025453.3025494},
abstract = {With the fast development of virtual reality games, one of the key research questions is how players may express their creativity and participate in the process of game design. In this paper, we present a new game genre which combines user-controlled game design in physical space with game play in virtual space on a mobile device. The new system supports authoring by anyone, creating virtual reality games that can be easily modified or developed for physical space, and be used anywhere by novice end-users without any knowledge of tracking technology. We present the design and implementation of the system, as well as a user experiment. Findings illustrate that the proposed system promotes participation and provides a richer, more interactive and engaging experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5016–5028},
numpages = {13},
keywords = {natural interaction, mobile 3d, head-mounted display, virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026020,
author = {McArthur, Victoria},
title = {The UX of Avatar Customization},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026020},
doi = {10.1145/3025453.3026020},
abstract = {Avatar customization is a feature that is offered in many computer and video games. Customization options are presented to users via Character Creation Interfaces or CCIs. CCIs differ greatly between games, independent of genre, with regard to the quantity and quality of customization options available. In addition, the way in which these options are presented to users differs from game to game. Research on avatar customization is typically focused on user-avatar identity or self-representation. In general, we have found that the User Experience (UX) of avatar customization has been greatly overlooked in academic literature. As such, we look to existing research on UX in order to propose how its methodologies may be used to study the impact of CCI affordances on player experience in games.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5029–5033},
numpages = {5},
keywords = {user experience, identity, affordances, interface, avatars},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025997,
author = {Gaston, Jacqueline and Cooper, Seth},
title = {To Three or Not to Three: Improving Human Computation Game Onboarding with a Three-Star System},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025997},
doi = {10.1145/3025453.3025997},
abstract = {While many popular casual games use three-star systems, which give players up to three stars based on their performance in a level, this technique has seen limited application in human computation games (HCGs). This gives rise to the question of what impact, if any, a three-star system will have on the behavior of players in HCGs. In this work, we examined the impact of a three-star system implemented in the protein folding HCG Foldit. We compared the basic game's introductory levels with two versions using a three-star system, where players were rewarded with more stars for completing levels in fewer moves. In one version, players could continue playing levels for as many moves as they liked, and in the other, players were forced to reset the level if they used more moves than required to achieve at least one star on the level. We observed that the three-star system encouraged players to use fewer moves, take more time per move, and replay completed levels more often. We did not observe an impact on retention. This indicates that three-star systems may be useful for re-enforcing concepts introduced by HCG levels, or as a flexible means to encourage desired behaviors.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5034–5039},
numpages = {6},
keywords = {analytics, design, games, human computation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025765,
author = {Hornb\ae{}k, Kasper and Oulasvirta, Antti},
title = {What Is Interaction?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025765},
doi = {10.1145/3025453.3025765},
abstract = {The term interaction is field-defining, yet surprisingly confused. This essay discusses what interaction is. We first argue that only few attempts to directly define interaction exist. Nevertheless, we extract from the literature distinct and highly developed concepts, for instance viewing interaction as dialogue, transmission, optimal behavior, embodiment, and tool use. Importantly, these concepts are associated with different scopes and ways of construing the causal relationships between the human and the computer. This affects their ability to inform empirical studies and design. Based on this discussion, we list desiderata for future work on interaction, emphasizing the need to improve scope and specificity, to better account for the effects and agency that computers have in interaction, and to generate strong propositions about interaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5040–5052},
numpages = {13},
keywords = {concepts, scientific progress, models, theories, interaction, human-computer interaction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025718,
author = {Maudet, Nolwenn and Jalal, Ghita and Tchernavskij, Philip and Beaudouin-Lafon, Michel and Mackay, Wendy E.},
title = {Beyond Grids: Interactive Graphical Substrates to Structure Digital Layout},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025718},
doi = {10.1145/3025453.3025718},
abstract = {Traditional graphic design tools emphasize the grid for structuring layout. Interviews with professional graphic designers revealed that they use surprisingly sophisticated structures that go beyond the grid, which we call graphical substrates. We present a framework to describe how designers establish graphical substrates based on properties extracted from concepts, content and context, and use them to compose layouts in both space and time. We developed two technology probes to explore how to embed graphical substrates into tools. Contextify lets designers tailor layouts according to each reader's intention and context; while Linkify lets designers create dynamic layouts based on relationships among content properties. We tested the probes with professional graphic designers, who all identified novel uses in their current projects. We incorporated their suggestions into StyleBlocks, a prototype that reifies CSS declarations into interactive graphical substrates. Graphical substrates offer an untapped design space for tools that can help graphic designers generate personal layout structures.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5053–5064},
numpages = {12},
keywords = {creativity support tools., graphic design, layout},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025933,
author = {Takahashi, Haruki and Miyashita, Homei},
title = {Expressive Fused Deposition Modeling by Controlling Extruder Height and Extrusion Amount},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025933},
doi = {10.1145/3025453.3025933},
abstract = {Fused deposition modeling (FDM) 3D printers form objects by stacking layers having a linear structure. To print fine structures, an appropriate choice of parameters is necessary, or printing error occurs. On the other hand, the printing error is exploited as an expression technique. However, the relation between the printed structure and the parameters causing the printing error is unclear. In this paper, we focus on the height position of the extruder and the amount of extruded material, and explore the combination of these parameters to enhance the capability of FDM. By extending an equation that calculates the amount of material from the layer height, we investigate the behavior and structure of material extruded from various height positions. On the basis of experimental results, the printed structure is classified into six categories according to the structural feature. We describe these structural features and demonstrate examples with new inherent expressions for FDM.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5065–5074},
numpages = {10},
keywords = {fabrication, 3D printing, fused deposition modeling, expression, printing error},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025988,
author = {Strasnick, Evan and Yang, Jackie and Tanner, Kesler and Olwal, Alex and Follmer, Sean},
title = {ShiftIO: Reconfigurable Tactile Elements for Dynamic Affordances and Mobile Interaction},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025988},
doi = {10.1145/3025453.3025988},
abstract = {Currently, virtual (i.e. touchscreen) controls are dynamic, but lack the advantageous tactile feedback of physical controls. Similarly, devices may also have dedicated physical controls, but they lack the flexibility to adapt for different contexts and applications. On mobile and wearable devices in particular, space constraints further limit our input and output capabilities. We propose utilizing reconfigurable tactile elements around the edge of a mobile device to enable dynamic physical controls and feedback. These tactile elements can be used for physical touch input and output, and can reposition according to the application both around the edge of and hidden within the device. We present shiftIO, two implementations of such a system which actuate physical controls around the edge of a mobile device using magnetic locomotion. One version utilizes PCB-manufactured electromagnetic coils, and the other uses switchable permanent magnets. We perform a technical evaluation of these prototypes and compare their advantages in various applications. Finally, we demonstrate several mobile applications which leverage shiftIO to create novel mobile interactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5075–5086},
numpages = {12},
keywords = {dynamic affordance, magnetically-actuated buttons, mobile haptics, tactile display},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026047,
author = {Petralito, Serge and Br\"{u}hlmann, Florian and Iten, Glena and Mekler, Elisa D. and Opwis, Klaus},
title = {A Good Reason to Die: How Avatar Death and High Challenges Enable Positive Experiences},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026047},
doi = {10.1145/3025453.3026047},
abstract = {Appropriate challenges and challenge-skill balance are usually key to positive player experiences. However, some games such as the successful series Dark Souls are notorious for their excessive difficulty. Yet, there has been little empirical investigation of why players enjoy games they constantly struggle and fail with. We surveyed 95 participants right after the release of Dark Souls III about their experiences with the game, employing both open questions and different player experience measures. Players generally enjoyed challenging play sessions and mostly reported positive experiences, with achievement and learning moments strongly contributing to positive experiences. However, these factors themselves were enabled by negative events such as difficulties and avatar death. Our findings showcase that negative events bear a potential for forming positive and meaningful experiences, thus expanding previous knowledge about the role of challenge and failing in games. Moreover, the significance of hard-earned achievements extends present design conventions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5087–5097},
numpages = {11},
keywords = {player experience, games, failure, challenge, enjoyment, avatar death},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026043,
author = {Mustafa, Maryam and Guthe, Stefan and Tauscher, Jan-Philipp and Goesele, Michael and Magnor, Marcus},
title = {How Human Am I? EEG-Based Evaluation of Virtual Characters},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026043},
doi = {10.1145/3025453.3026043},
abstract = {There is a continuous effort by animation experts to create increasingly realistic and more human-like digital characters. However, as virtual characters become more human they risk evoking a sense of unease in their audience. This sensation, called the Uncanny Valley effect, is widely acknowledged both in the popular media and scientific research but empirical evidence for the hypothesis has remained inconsistent. In this paper, we investigate the neural responses to computer-generated faces in a cognitive neuroscience study. We record brain activity from participants (N = 40) using electroencephalography (EEG) while they watch videos of real humans and computer-generated virtual characters. Our results show distinct differences in neural responses for highly realistic computer-generated faces such as Digital Emily compared with real humans. These differences are unique only to agents that are highly photorealistic, i.e. the `uncanny' response. Based on these specific neural correlates we train a support vector machine~(SVM) to measure the probability of an uncanny response for any given computer-generated character from EEG data. This allows the ordering of animated characters based on their level of `uncanniness'.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5098–5108},
numpages = {11},
keywords = {uncanny valley, virtual humans, computer graphics, eeg},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025697,
author = {Wehbe, Rina R. and Mekler, Elisa D. and Schaekermann, Mike and Lank, Edward and Nacke, Lennart E.},
title = {Testing Incremental Difficulty Design in Platformer Games},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025697},
doi = {10.1145/3025453.3025697},
abstract = {Designing difficulty levels in platformer games is a challenge for game designers. It is important because design decisions that affect difficulty also directly affect player experience. Consequently, design strategies for balancing game difficulty are discussed by both academics and game designers. In this paper, we study how manipulating the following design decisions, commonly found in platformers, moderates difficulty: Scroll Speed, Target Size, Jump Task Complexity, and Perspective. Results for Scroll Speed and Target Size indicate that errors increase as speed increases and platform size decreases. However, results for jump task complexity demonstrate a separation of errors from task complexity. Specifically, while double-jump tasks are harder than single-jump tasks, triple-jump tasks appear to be as difficult as double-jump tasks. Additionally, the study demonstrates how changes in perspective affect the errors made by players in gameplay. The study results are applicable both to automatic level generation and dynamic difficulty adjustment in platformer games.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5109–5113},
numpages = {5},
keywords = {games user research (gur), game design, difficulty},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025669,
author = {Hassib, Mariam and Schneegass, Stefan and Eiglsperger, Philipp and Henze, Niels and Schmidt, Albrecht and Alt, Florian},
title = {EngageMeter: A System for Implicit Audience Engagement Sensing Using Electroencephalography},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025669},
doi = {10.1145/3025453.3025669},
abstract = {Obtaining information about audience engagement in presentations is a valuable asset for presenters in many domains. Prior literature mostly utilized explicit methods of collecting feedback which induce distractions, add workload on audience and do not provide objective information to presenters. We present EngageMeter - a system that allows fine-grained information on audience engagement to be obtained implicitly from multiple brain-computer interfaces (BCI) and to be fed back to presenters for real time and post-hoc access. Through evaluation during an HCI conference (Naudience=11, Npresenters=3) we found that EngageMeter provides value to presenters (a) in real-time, since it allows reacting to current engagement scores by changing tone or adding pauses, and (b) in post-hoc, since presenters can adjust their slides and embed extra elements. We discuss how EngageMeter can be used in collocated and distributed audience sensing as well as how it can aid presenters in long term use.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5114–5119},
numpages = {6},
keywords = {eeg, bci, audience feedback, physiological sensing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026037,
author = {Evain, And\'{e}ol and Argelaguet, Ferran and Roussel, Nicolas and Casiez, G\'{e}ry and L\'{e}cuyer, Anatole},
title = {Can I Think of Something Else When Using a BCI? Cognitive Demand of an SSVEP-Based BCI},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026037},
doi = {10.1145/3025453.3026037},
abstract = {BCIs are presumably supposed to require the full attention of their users and to lose accuracy if they pay attention to another task. This assertion has been verified with several BCI paradigms (e.g. P300). But the cognitive demand of the promising SSVEP paradigm had never been specifically assessed yet. We measured the accuracy of an SSVEP-based BCI used by 26 participants in various conditions of mental workload. Our analysis revealed that surprisingly, for this type of BCI, little attention is actually needed from participants to reach optimal accuracy: participants were able to successfully perform a complex secondary task (N-back) without degrading the BCI accuracy. The same observation was made whether visual or auditive attention was solicited. These results indicate that SSVEP is a low-demanding paradigm in terms of cognitive resources, and are encouraging for its use in complex interaction settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5120–5125},
numpages = {6},
keywords = {cognitive load, ssvep, bci, n-back task},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025721,
author = {Spiel, Katta and Bertel, Sven and Kayali, Fares},
title = {"Not Another Z Piece!": Adaptive Difficulty in TETRIS},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025721},
doi = {10.1145/3025453.3025721},
abstract = {Difficulty in TETRIS is adjusted by adapting the speed with which blocks fall. In this contribution, we describe results of an exploratory study in which we investigated relationships between players' performance and their subjective assessment of difficulty and fun. We tested five different algorithms that, instead of adjusting game speed, adjust difficulty by choosing blocks based on the current game state. With our results, we establish pile height and bumpiness as parameters that indicate the performance of a player during a live game, discuss the inherent difficulty of different block choosing algorithms and show how the relationship between fun and perceived difficulty varies for distinct player groups. With regard to adapting difficulty, we argue that one can still teach an old dog such a TETRIS a lot of new tricks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5126–5131},
numpages = {6},
keywords = {perceived difficulty, fun, tetris, user study},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025955,
author = {Malinverni, Laura and Maya, Julian and Schaper, Marie-Monique and Pares, Narcis},
title = {The World-as-Support: Embodied Exploration, Understanding and Meaning-Making of the Augmented World},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025955},
doi = {10.1145/3025453.3025955},
abstract = {Current technical capabilities of mobile technologies are consolidating the interest in developing context-aware Augmented/Mixed Reality applications. Most of these applications are designed based on the Window-on-the-World (WoW) interaction paradigm. A significant decrease in cost of projection technology and advances in pico-sized projectors have spurred applications of Projective Augmented Reality. This research has focused mainly on technological development. However, there is still a need to fully understand its communicational and expressive potential. Hence, we define a conceptual paradigm that we call World-as-Support (WaS). We compare the WaS and WoW paradigms by contrasting their assumptions and cultural values, as well as through a study of an application aimed at supporting the collaborative improvisation of site-specific narratives by children. Our analysis of children's understanding of the physical and social environment and of their imaginative play allowed us to identify the affordances, strengths and weaknesses of these two paradigms.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5132–5144},
numpages = {13},
keywords = {window-on-the-world, augmented reality, meaning making, embodied interaction, mixed reality, world-as-support., embodied cognition},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025689,
author = {Feuchtner, Tiare and M\"{u}ller, J\"{o}rg},
title = {Extending the Body for Interaction with Reality},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025689},
doi = {10.1145/3025453.3025689},
abstract = {In this paper, we explore how users can control remote devices with a virtual long arm, while preserving the perception that the artificial arm is actually part of their own body. Instead of using pointing, speech, or a remote control, the users' arm is extended in augmented reality, allowing access to devices that are out of reach. Thus, we allow users to directly manipulate real-world objects from a distance using their bare hands. A core difficulty we focus on is how to maintain ownership for the unnaturally long virtual arm, which is the strong feeling that one's limbs are actually part of the own body. Fortunately, what the human brain experiences as being part of the own body is very malleable and we find that during interaction the user's virtual arm can be stretched to more than twice its real length, without breaking the user's sense of ownership for the virtual limb.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5145–5157},
numpages = {13},
keywords = {ownership, augmented reality, virtual hand illusion, ubiquitous computing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025873,
author = {Wilde, Danielle and Vallg\r{a}rda, Anna and Tomico, Oscar},
title = {Embodied Design Ideation Methods: Analysing the Power of Estrangement},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025873},
doi = {10.1145/3025453.3025873},
abstract = {Embodied design ideation practices work with relationships between body, material and context to enliven design and research potential. Methods are often idiosyncratic and due to their physical nature not easily transferred. This presents challenges for designers wishing to develop and share techniques or contribute to research. We present a framework that enables designers to understand, describe and contextualise their embodied design ideation practices in ways that can be understood by peers, as well as those new to embodied ideation. Our framework developed over two conference workshops provides a frame for discussion of embodied design actions that leverage the power of estrangement. We apply our framework to eight embodied design ideation methods. Our contribution is thus twofold: (1) a framework to understand and leverage the power of estrangement in embodied design ideation, and (2) an inspirational catalogue demonstrating the diversity of ideas that embodied design ideation methods can foster.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5158–5170},
numpages = {13},
keywords = {design methods, ideation, design research, embodiment, disruption, estrangement},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025714,
author = {Fran\c{c}oise, Jules and Candau, Yves and Fdili Alaoui, Sarah and Schiphorst, Thecla},
title = {Designing for Kinesthetic Awareness: Revealing User Experiences through Second-Person Inquiry},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025714},
doi = {10.1145/3025453.3025714},
abstract = {We consider kinesthetic awareness, the perception of our own body position and movement in space, as a critical value for embodied design within third wave HCI. We designed an interactive sound installation that supports kinesthetic awareness of a participant's micro-movements. The installation's interaction design uses continuous auditory feedback and leverages an adaptive mapping strategy, refining its sensitivity to increase sonic resolution at lower levels of movement activity. The installation uses field recordings as rich source materials to generate a sound environment that attunes to a participant's micro-movements. Through a qualitative study using a second-person interview technique, we gained nuanced insights into the participants' subjective experiences of the installation. These reveal consistent temporal patterns, as participants build on a gradual process of integration to increase the complexity and capacity of their kinesthetic awareness during interaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5171–5183},
numpages = {13},
keywords = {second person interviewing, qualitative methods, sound, movement, user experience, auditory feedback, interaction design, kinesthetic awareness},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025482,
author = {Pearson, Jennifer and Robinson, Simon and Jones, Matt and Joshi, Anirudha and Ahire, Shashank and Sahoo, Deepak and Subramanian, Sriram},
title = {Chameleon Devices: Investigating More Secure and Discreet Mobile Interactions via Active Camouflaging},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025482},
doi = {10.1145/3025453.3025482},
abstract = {Many users value the ability to have quick and frequent sight of their mobiles when in public settings. However, in doing so, they expose themselves to potential risks, ranging from being targets of robbery to the more subtle social losses through being seen to be rude or inattentive to those around them. In nature, some animals can blend into their environments to avoid being eaten or to reduce their impact on the ecosystem around them. Taking inspiration from these evolved systems we investigate the notion of chameleon approaches for mobile interaction design. Our probes were motivated, inspired and refined through extended interactions with people drawn from contexts with differing ranges of security and privacy concerns. Through deployments on users' own devices, our prototypes show the value of the concept. The encouraging results motivate further research in materials and form factors that can provide more effective automatic plain-sight hiding.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5184–5196},
numpages = {13},
keywords = {subtle notifications, camouflaging devices, mobiles},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025735,
author = {McReynolds, Emily and Hubbard, Sarah and Lau, Timothy and Saraf, Aditya and Cakmak, Maya and Roesner, Franziska},
title = {Toys That Listen: A Study of Parents, Children, and Internet-Connected Toys},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025735},
doi = {10.1145/3025453.3025735},
abstract = {Hello Barbie, CogniToys Dino, and Amazon Echo are part of a new wave of connected toys and gadgets for the home that listen. Unlike the smartphone, these devices are always on, blending into the background until needed. We conducted interviews with parent-child pairs in which they interacted with Hello Barbie and CogniToys Dino, shedding light on children's expectations of the toys' "intelligence'" and parents' privacy concerns and expectations for parental controls. We find that children were often unaware that others might be able to hear what was said to the toy, and that some parents draw connections between the toys and similar tools not intended as toys (e.g., Siri, Alexa) with which their children already interact. Our findings illuminate people's mental models and experiences with these emerging technologies and will help inform the future designs of interactive, connected toys and gadgets. We conclude with recommendations for parents, designers, and policy makers.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5197–5207},
numpages = {11},
keywords = {children, privacy, connected toys, parents},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025556,
author = {Van Kleek, Max and Liccardi, Ilaria and Binns, Reuben and Zhao, Jun and Weitzner, Daniel J. and Shadbolt, Nigel},
title = {Better the Devil You Know: Exposing the Data Sharing Practices of Smartphone Apps},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025556},
doi = {10.1145/3025453.3025556},
abstract = {Most users of smartphone apps remain unaware of what data about them is being collected, by whom, and how these data are being used. In this mixed methods investigation, we examine the question of whether revealing key data collection practices of smartphone apps may help people make more informed privacy-related decisions. To investigate this question, we designed and prototyped a new class of privacy indicators, called Data Controller Indicators (DCIs), that expose previously hidden information flows out of the apps. Our lab study of DCIs suggests that such indicators do support people in making more confident and consistent choices, informed by a more diverse range of factors, including the number and nature of third-party companies that access users' data. Furthermore, personalised DCIs, which are contextualised against the other apps an individual already uses, enable them to reason effectively about the differential impacts on their overall information exposure.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5208–5220},
numpages = {13},
keywords = {privacy indicators, mobile apps, personal data, decision-making},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025587,
author = {Moser, Carol and Chen, Tianying and Schoenebeck, Sarita Y.},
title = {Parents? And Children?S Preferences about Parents Sharing about Children on Social Media},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025587},
doi = {10.1145/3025453.3025587},
abstract = {Prior research shows that parents receive a number of benefits through sharing about their children online, but little is known about children?s perspectives about parent sharing. We conducted a survey with 331 parent-child pairs to examine parents? and children?s preferences about what parents share about their children on social media. We find that parents and children are in agreement in their perception of how often and how much information parents share about their children on social media. However, there is disagreement about the permission-seeking process: children believe their parents should ask permission more than parents think they should, and parents believe they should ask for permission more often than they actually do, especially younger parents. We describe two categories of content that children are okay, or not okay, with their parents sharing about them. We offer design directions for managing parent sharing.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5221–5225},
numpages = {5},
keywords = {social media, parent, child, permission, privacy, sharing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025986,
author = {Sailaja, Neelima and Crabtree, Andy and Stenton, Phil},
title = {Challenges of Using Personal Data to Drive Personalised Electronic Programme Guides},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025986},
doi = {10.1145/3025453.3025986},
abstract = {Media researchers are adopting personalisation in diverse ways to deliver increasingly context-sensitive and customised media experiences. This paper explores user attitudes towards a personalised Electronic Programme Guide which tailors media recommendations based on users' personal data. We used scenario based exploration enabled by the use of probes to convey the functionalities of data-driven personalised EPGs and to facilitate user discussions around its potential use. Users preferred personalised EPGs over current popular EPGs but expressed a significant lack of trust in the personal data collection that drives personalisation. Users appreciated the functionalities afforded by personalisation of media but were apprehensive about the implications of the personal data being collected about them, particularly in the context of their homes. This calls for the need to design future personalised media experiences that help enhance trust in these socio-technical settings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5226–5231},
numpages = {6},
keywords = {personal data, media, interaction, focus groups, epg},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025651,
author = {Saksono, Herman and Parker, Andrea G.},
title = {Reflective Informatics Through Family Storytelling: Self-Discovering Physical Activity Predictors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025651},
doi = {10.1145/3025453.3025651},
abstract = {HCI research has increasingly examined how sensing technologies can help people capture and visualize data about their health-related behaviors. Yet, few systems help people reflect more fundamentally on the factors that influence behaviors such as physical activity (PA). To address this research gap, we take a novel approach, examining how such reflections can be stimulated through a medium that generations of families have used for reflection and teaching: storytelling. Through observations and interviews, we studied how 13 families interacted with a low-fidelity prototype, and their attitudes towards this tool. Our prototype used storytelling and interactive prompts to scaffold reflection on factors that impact children's PA. We contribute to HCI research by characterizing how families interacted with a story-driven reflection tool, and how such a tool can encourage critical processes for behavior change. Informed by the Transtheoretical Model, we present design implications for reflective informatics systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5232–5244},
numpages = {13},
keywords = {families, children, storytelling, personal health informatics, sensemaking, physical activity, reflective informatics, technology-mediated reflection},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025754,
author = {Hong, Matthew K. and Feustel, Clayton and Agnihotri, Meeshu and Silverman, Max and Simoneaux, Stephen F. and Wilcox, Lauren},
title = {Supporting Families in Reviewing and Communicating about Radiology Imaging Studies},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025754},
doi = {10.1145/3025453.3025754},
abstract = {Diagnostic radiology reports are increasingly being made available to patients and their family members. However, these reports are not typically comprehensible to lay recipients, impeding effective communication about report findings. In this paper, we present three studies informing the design of a prototype to foster patient-clinician communication about radiology report content. First, analysis of questions posted in online health forums helped us identify patients' information needs. Findings from an elicitation study with seven radiologists provided necessary domain knowledge to guide prototype design. Finally, a clinical field study with 14 pediatric patients, their parents and clinicians, revealed positive responses of each stakeholder when using the prototype to interact with and discuss the patient's current CT or MRI report and allowed us to distill three use cases: co-located communication, preparing for the consultation, and reviewing radiology data. We draw on our findings to discuss design considerations for supporting each of these use cases.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5245–5256},
numpages = {12},
keywords = {radiology report, adolescents, patient-doctor communication, families},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025923,
author = {Berry, Andrew B. L. and Lim, Catherine and Hartzler, Andrea L. and Hirsch, Tad and Wagner, Edward H. and Ludman, Evette and Ralston, James D.},
title = {How Values Shape Collaboration Between Patients with Multiple Chronic Conditions and Spousal Caregivers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025923},
doi = {10.1145/3025453.3025923},
abstract = {Individuals with multiple chronic conditions (MCC) collaborate with spousal caregivers daily to pursue what is most important to their health and well-being. Previous research in human-computer interaction has supported individuals with chronic conditions or their caregivers, but little has supported both as a unit. We conducted a field study with 12 patient-caregiver dyads, all married and living together, to identify partners' values and how they shape collaborative management of MCC. Partners' coinciding values motivated them to empathize with and support each other in the face of challenges related to health and well-being. When their values were asymmetric, they perceived tensions between individual autonomy and their ability to coordinate with their partner. Systems to support partners in this context could help them overcome asymmetric values, but should balance this with support for individual autonomy.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5257–5270},
numpages = {14},
keywords = {patient, collaboration, self-care, caregiver, multiple chronic conditions, coordination, self-management},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025548,
author = {Miller, Matthew K. and Mandryk, Regan L. and Birk, Max V. and Depping, Ansgar E. and Patel, Tushita},
title = {Through the Looking Glass: The Effects of Feedback on Self-Awareness and Conversational Behaviour during Video Chat},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025548},
doi = {10.1145/3025453.3025548},
abstract = {Video chat is a popular form of computer-mediated communication in a range of contexts from online job interviews to chatting with friends. Although seeing your own video feedback is the predominant interface design, self-awareness research suggests that seeing oneself could induce self-consciousness and affect interaction. We created a custom video chat application and asked pairs of strangers to engage in an online personal information exchange task with or without video feedback. Feedback increased self-awareness and the use of socially-focused words, and decreased the use of words expressing certainty. In addition, mixed-gender dyads rated themselves as more socially orientated with feedback than without, which was reflected in an increased use of inclusive pronouns and affiliation words, and fewer words expressing discrepancy. However, with feedback, same-gender dyads reported greater task orientation than mixed-gender dyads reflected in increased use of task-relevant words. We discuss design implications in contexts from remote therapy to online dating.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5271–5283},
numpages = {13},
keywords = {cscw, cmc, video chat, self-awareness, gender, feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025641,
author = {Krekhov, Andrey and Emmerich, Katharina and Babinski, Maxim and Kr\"{u}ger, Jens},
title = {Gestures From the Point of View of an Audience: Towards Anticipatable Interaction of Presenters With 3D Content.},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025641},
doi = {10.1145/3025453.3025641},
abstract = {Presenting content to an audience is important in several fields, including education, marketing, and entertainment. Therefore, the main goal of the presenter is to transport messages to the audience.The paper aims to improve the process of message transportation by providing audience-friendly and anticipatable gestures for the presenter to be used for 3D interaction with the content. For this purpose, we first gathered input from a potential audience through a Wizard of Oz experiment and implemented three coherent gesture sets using the Kinect. We conducted an online survey to evaluate the hypotheses regarding the anticipation rate and perceived user experience. In particular, two of our three gesture sets show tendencies to be intuitively predictable by an untrained, uninformed audience. As the three sets differ significantly in the anticipation level, we conclude that future improvements of such gestures would enhance the audience's ability to predict the intended actions even further.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5284–5294},
numpages = {11},
keywords = {presentation, kinect, gestures, audience},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025848,
author = {Licoppe, Christian and Luff, Paul K. and Heath, Christian and Kuzuoka, Hideaki and Yamashita, Naomi and Tuncer, Sylvaine},
title = {Showing Objects: Holding and Manipulating Artefacts in Video-Mediated Collaborative Settings},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025848},
doi = {10.1145/3025453.3025848},
abstract = {In this paper we report on a pervasive practice in video-mediated communication: where participants show one another one or more objects. This is a distinct activity from others considered by researchers of video-mediated technologies that focus on a face-to-face orientation, or just on the support necessary to help people to refer to objects. We first present examples of this pervasive phenomenon in naturally occurring Skype conversations, revealing how this conduct is configured and organized within the interaction between participants. We reveal how the subtle adjustment of the position of the body, the head and gaze with respect to the handheld objects offers crucial resources for participants to achieve joint seeing. Then we report on a quite different setting, a naturalistic experiment where participants collaborate on a collective task with remote colleagues through maneuverable, orientable devices (Kubis). Again, in these experiments participants frequently show objects, and at times the devices provide additional resources to support these activities. But at other times they also involve some difficulties. We conclude by suggesting possible technological developments, some quite simple, others more radical, that might support participants to show objects, whether they are in domestic settings or undertaking work activities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5295–5306},
numpages = {12},
keywords = {video-mediated interaction, objects, embodied interaction, domestic, Skype},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025681,
author = {Otsuki, Mai and Kawano, Taiki and Maruyama, Keita and Kuzuoka, Hideaki and Suzuki, Yusuke},
title = {ThirdEye: Simple Add-on Display to Represent Remote Participant's Gaze Direction in Video Communication},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025681},
doi = {10.1145/3025453.3025681},
abstract = {A long-standing challenge in video-mediated communication systems is to represent a remote participant's gaze direction in local environments correctly. To address this issue, we developed ThirdEye, an add-on eye-display for a video communication system. This display is made from an artificial ulexite (TV rock) that is cut into a hemispherical shape, enabling light from the bottom surface to be projected onto the hemisphere surface. By drawing an appropriate ellipse on an LCD and placing ThirdEye over it, this system simulates an eyeball. Our experiment proved that an observer could perceive a remote Looker's gaze direction more precisely when the gaze was presented using ThirdEye compared to the case in which the gaze was presented using the Looker's face on a flat display.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5307–5312},
numpages = {6},
keywords = {telecommunication, gaze awareness},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025574,
author = {Suzuki, Keita and Yokoyama, Masanori and Yoshida, Shigeo and Mochizuki, Takayoshi and Yamada, Tomohiro and Narumi, Takuji and Tanikawa, Tomohiro and Hirose, Michitaka},
title = {FaceShare: Mirroring with Pseudo-Smile Enriches Video Chat Communications},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025574},
doi = {10.1145/3025453.3025574},
abstract = {"Mirroring" refers to the unconscious mimicry of another person's behaviors, such as their facial expressions. Mirroring has many positive effects, such as enhancing closeness and improving the flow of a conversation, which enriches the quality of communication. Our study set out to devise a means of evoking these positive effects in a video chat without any conscious effort of participants. We constructed a videophone system, called FaceShare, which can deform the user's face into a smile in response to their partner's smiling. That is, our system generates mirroring by producing a pseudo-smile through image processing. We conducted an experiment in which pairs of participants had brief conversations via FaceShare. The results implied that mirroring using the pseudo-smile lets the mimicker, whose face is deformed according to the expressions of their partner, feel a closeness, and improves the flow of the conversation for both the mimicker and the mimickee, who sees the mimicker's deformed face.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5313–5317},
numpages = {5},
keywords = {transcendent telepresence, facial expression, cscw, telepresence, mirroring},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025526,
author = {Pohl, Henning and Brandes, Peter and Ngo Quang, Hung and Rohs, Michael},
title = {Squeezeback: Pneumatic Compression for Notifications},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025526},
doi = {10.1145/3025453.3025526},
abstract = {Current mobile devices commonly use vibration feedback to signal incoming notifications. However, vibration feedback exhibits strong attention capture, limiting its use to short periods and prominent notifications. Instead, we investigate the use of compression feedback for notifications, which scales from subtle stimuli to strong ones and can provide sustained stimuli over longer periods. Compression feedback utilizes inflatable straps around a user's limbs, a form factor allowing for easy integration into many common wearables. We explore technical aspects of compression feedback and investigate its psychophysical properties with several lab and in situ studies. Furthermore, we show how compression feedback enables reactive feedback. Here, deflation patterns are used to reveal further information on a user's query. We also compare compression and vibrotactile feedback and find that they have similar performance.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5318–5330},
numpages = {13},
keywords = {notifications, pressure feedback, blood pressure, mobile haptics, pneumatics, wearable, compression feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025568,
author = {Gong, Jun and Li, Lan and Vogel, Daniel and Yang, Xing-Dong},
title = {Cito: An Actuated Smartwatch for Extended Interactions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025568},
doi = {10.1145/3025453.3025568},
abstract = {We propose and explore actuating a smartwatch face to enable extended interactions. Five face movements are defined: rotation, hinging, translation, rising, and orbiting. These movements are incorporated into interaction techniques to address limitations of a fixed watch face. A 20-person study uses concept videos of a passive low fidelity prototype to confirm the usefulness of the actuated interaction techniques. A second 20-person study uses 3D rendered animations to access social acceptability and perceived comfort for different actuation dynamics and usage contexts. Finally, we present Cito, a high-fidelity proof-of-concept hardware prototype that investigates technical challenges.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5331–5345},
numpages = {15},
keywords = {interaction techniques, actuated ui, smartwatch},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025946,
author = {Yuan, Fengpeng and Gao, Xianyi and Lindqvist, Janne},
title = {How Busy Are You? Predicting the Interruptibility Intensity of Mobile Users},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025946},
doi = {10.1145/3025453.3025946},
abstract = {Smartphones frequently notify users about newly available messages or other notifications. It can be very disruptive when these notifications interrupt users while they are busy. Our work here is based on the observation that people usually exhibit different levels of busyness at different contexts. This means that classifying users' interruptibility as a binary status, interruptible or not interruptible, is not sufficient to accurately measure their availability towards smartphone interruptions. In this paper, we propose, implement and evaluate a two-stage hierarchical model to predict people's interruptibility intensity. Our work is the first to introduce personality traits into interruptibility prediction model, and we found that personality data improves the prediction significantly. Our model bootstraps the prediction with similar people's data, and provides a good initial prediction for users whose individual models have not been trained on their own data yet. Overall prediction accuracy of our model can reach 66.1%.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5346–5360},
numpages = {15},
keywords = {context, interruptibility, notifications, predictive models},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025730,
author = {Widdicks, Kelly and Bates, Oliver and Hazas, Mike and Friday, Adrian and Beresford, Alastair R.},
title = {Demand Around the Clock: Time Use and Data Demand of Mobile Devices in Everyday Life},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025730},
doi = {10.1145/3025453.3025730},
abstract = {Motivated by mobile devices' growing demand for connectivity, and concern in HCI with the energy intensity and sustainability of networked services, in this paper we reveal the impact of applications on smartphones and tablets in terms of network demand and time use. Using a detailed mixed methods study with eight participants, we first provide an account of how data demand has meaning and utility in our participants' social practices, and the timing and relative impacts of these. We then assess the scale of this demand by drawing comparison between our fine-grained observations and a more representative dataset of 398 devices from the Device Analyzer corpus. Our results highlight the significant categories of data demanding practice, and the identification of where changes in app time and duration of use might reduce or shift demand to reduce services' impacts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5361–5372},
numpages = {12},
keywords = {ict, sustainability, data demand, demand designed into practices},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026051,
author = {Khovanskaya, Vera and Sengers, Phoebe and Mazmanian, Melissa and Darrah, Charles},
title = {Reworking the Gaps between Design and Ethnography},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026051},
doi = {10.1145/3025453.3026051},
abstract = {Since Dourish's critique of 'implications for design' [15], researchers have asked how design and ethnography should or could relate in HCI. Here we reflect on two experiences with cross-informing ongoing ethnographic investigation with the early stages of research through design. One uses speculative design to reflect on and inform ethnographic fieldwork on busyness in middle-class familes; the other uses speculative design to complement late-stage analysis of a historical ethnography of rural technological infrastructure. Rather than trying to do away with the gap between ethnography and design by seamlessly integrating the two processes, we reworked the relationship between ethnography and design by closing the gap in the temporal workflows while simultaneously maintaining a distinction in the performance of the two roles. We found that this new gap resulted in a series of misunderstandings; but by putting the two roles in active dialogue, we were able leverage misunderstandings into mutual benefit.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5373–5385},
numpages = {13},
keywords = {speculative design, ethnography, inventive methods},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025503,
author = {Elsden, Chris and Chatting, David and Durrant, Abigail C. and Garbett, Andrew and Nissen, Bettina and Vines, John and Kirk, David S.},
title = {On Speculative Enactments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025503},
doi = {10.1145/3025453.3025503},
abstract = {Speculative Enactments are a novel approach to speculative design research with participants. They invite the empirical analysis of participants acting amidst speculative but consequential circumstances. HCI as a broadly pragmatic, experience-centered, and participant-focused field is well placed to innovate methods that invite first-hand interaction and experience with speculative design projects. We discuss three case studies of this approach in practice, based on our own work: Runner Spotters, Metadating and a Quantified Wedding. In distinguishing Speculative Enactments we offer not just practical guidelines, but a set of conceptual resources for researchers and practitioners to critique the different contributions that speculative approaches make to HCI discourse.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5386–5399},
numpages = {14},
keywords = {research through design, speculative design, design fiction, critical futures, design methods, data-driven life},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026023,
author = {Blythe, Mark},
title = {Research Fiction: Storytelling, Plot and Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026023},
doi = {10.1145/3025453.3026023},
abstract = {What kind of stories and plots do researchers of Human Computer Interaction draw on when they make fictions? This paper applies the "basic plots" identified in the study of literature to scenarios, speculative design and design fiction. Traditional HCI scenarios employ the plot of "Overcoming the Monster" where the monster is some problem to be solved. Much of the commentary on critical, speculative or adversarial design also draws on this plot as it attempts to overcome monsters like public apathy or a lack of debate. Design Fiction more frequently takes the form of a "Voyage and Return" or a "Quest". The paper argues that a better understanding of plot and storytelling could contribute to more reflective research fiction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5400–5411},
numpages = {12},
keywords = {personas, critical design, adversarial design, solutionism, speculative design, scenarios, design fiction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025766,
author = {Schlesinger, Ari and Edwards, W. Keith and Grinter, Rebecca E.},
title = {Intersectional HCI: Engaging Identity through Gender, Race, and Class},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025766},
doi = {10.1145/3025453.3025766},
abstract = {Understanding users becomes increasingly complicated when we grapple with various overlapping attributes of an individual's identity. In this paper we introduce intersectionality as a framework for engaging with the complexity of users' "and authors" "identities", and situating these identities in relation to their contextual surroundings. We conducted a meta-review of identity representation in the CHI proceedings, collecting a corpus of 140 manuscripts on gender, ethnicity, race, class, and sexuality published between 1982-2016. Drawing on this corpus, we analyze how identity is constructed and represented in CHI research to examine intersectionality in a human-computer interaction (HCI) context. We find that previous identity-focused research tends to analyze one facet of identity at a time. Further, research on ethnicity and race lags behind research on gender and socio-economic class. We conclude this paper with recommendations for incorporating intersectionality in HCI research broadly, encouraging clear reporting of context and demographic information, inclusion of author disclosures, and deeper engagement with identity complexities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5412–5427},
numpages = {16},
keywords = {identity, ethnicity, intersectionality, socio-economic status, gender, intersectional hci, class, race},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025675,
author = {Nguyen, Cuong and DiVerdi, Stephen and Hertzmann, Aaron and Liu, Feng},
title = {Vremiere: In-Headset Virtual Reality Video Editing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025675},
doi = {10.1145/3025453.3025675},
abstract = {Creative professionals are creating Virtual Reality (VR) experiences today by capturing spherical videos, but video editing is still done primarily in traditional 2D desktop GUI applications such as Premiere. These interfaces provide limited capabilities for previewing content in a VR headset or for directly manipulating the spherical video in an intuitive way. As a result, editors must alternate between editing on the desktop and previewing in the headset, which is tedious and interrupts the creative process. We demonstrate an application that enables a user to directly edit spherical video while fully immersed in a VR headset. We first interviewed professional VR filmmakers to understand current practice and derived a suitable workflow for in-headset VR video editing. We then developed a prototype system implementing this new workflow. Our system is built upon a familiar timeline design, but is enhanced with custom widgets to enable intuitive editing of spherical video inside the headset. We conducted an expert review study and found that with our prototype, experts were able to edit videos entirely within the headset. Experts also found our interface and widgets useful, providing intuitive controls for their editing needs.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5428–5438},
numpages = {11},
keywords = {virtual reality, video editing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025762,
author = {Wood, Matthew and Wood, Gavin and Balaam, Madeline},
title = {"They're Just Tixel Pits, Man": Disputing the 'Reality' of Virtual Reality Pornography through the Story Completion Method},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025762},
doi = {10.1145/3025453.3025762},
abstract = {Pornography is a substantial part of humans' everyday interaction with computers, yet to date the topic has been underconsidered by HCI. Here, we examine some of the common cultural ideals non-experts constructed of a "new" pornographic experience - Virtual Reality (VR) Porn - through use of the "Story Completion Method". Forty five participants completed a story stem about a male character who was about to have his "very first virtual reality porn experience". Through our analysis, we demonstrate a narrative of a "perfect", idealised sexual experience, as well as one which emphasised the imagined "precarious" and dangerous consequences around this technology use. We indicate how the stories reproduced ideals around heteronormativity and hegemonic masculinity, suggesting an agenda of "Designing for Eroticism" as a tactic which could avoid such problematic discourses. We also suggest the opportunities and challenges presented through use of the "Story Completion Method".},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5439–5451},
numpages = {13},
keywords = {speculative design, virtual reality, thematic analysis, porn, pornography, design fiction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025824,
author = {Peiris, Roshan Lalintha and Peng, Wei and Chen, Zikun and Chan, Liwei and Minamizawa, Kouta},
title = {ThermoVR: Exploring Integrated Thermal Haptic Feedback with Head Mounted Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025824},
doi = {10.1145/3025453.3025824},
abstract = {Head Mounted Displays (HMDs) provide a promising opportunity for providing haptic feedback on the head for an enhanced immersive experience. In ThermoVR, we integrated five thermal feedback modules on the HMD to provide thermal feedback directly onto the user's face. We conducted evaluations with 15 participants using two approaches: Firstly, we provided simultaneously actuated thermal stimulations (hot and cold) as directional cues and evaluated the accuracy of recognition; secondly, we evaluated the overall immersive thermal experience that the users experience when provided with thermal feedback on the face. Results indicated that the recognition accuracy for cold stimuli were of approx. 89.5% accuracy while the accuracy for hot stimuli were 68.6%. Also, participants reported that they felt a higher level of immersion on the face when all modules were simultaneously stimulated (hot and cold). The presented applications demonstrate the ThermoVR's directional cueing and immersive experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5452–5456},
numpages = {5},
keywords = {thermal display, thermal haptics, head mounted display},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025783,
author = {Walker, James and Li, Bochao and Vertanen, Keith and Kuhl, Scott},
title = {Efficient Typing on a Visually Occluded Physical Keyboard},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025783},
doi = {10.1145/3025453.3025783},
abstract = {The rise of affordable head-mounted displays (HMDs) has raised questions about how to best design user interfaces for this technology. This paper focuses on the use of HMDs for home and office applications that require substantial text input. A physical keyboard is a familiar and effective text input device in normal desktop computing. But without additional camera technology, an HMD occludes all visual feedback about a user's hand position over the keyboard. We describe a system that assists HMD users in typing on a physical keyboard. Our system has a virtual keyboard assistant that provides visual feedback inside the HMD about a user's actions on the physical keyboard. It also provides powerful automatic correction of typing errors by extending a state-of-the-art touchscreen decoder. In a study with 24 participants, we found our virtual keyboard assistant enabled users to type more accurately on a visually-occluded keyboard. We found users wearing an HMD could type at over 40 words-per-minute while obtaining an error rate of less than 5%.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5457–5461},
numpages = {5},
keywords = {decoder, physical keyboard, head-mounted display, text entry},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025512,
author = {Boy, Jeremy and Pandey, Anshul Vikram and Emerson, John and Satterthwaite, Margaret and Nov, Oded and Bertini, Enrico},
title = {Showing People Behind Data: Does Anthropomorphizing Visualizations Elicit More Empathy for Human Rights Data?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025512},
doi = {10.1145/3025453.3025512},
abstract = {We investigate the impact of using anthropomorphized data graphics over standard charts on viewers' empathy for, and prosocial behavior toward suffering populations, in the context of human rights narratives. We present a series of experiments conducted on Amazon Mechanical Turk, in which we compare various forms of anthropomorphized data graphics-ranging from a single human figure that "fills up" to show proportional data, to separated groups of individual human beings-with a standard chart baseline. Each experiment uses two carefully crafted human rights data-driven stories to present the graphics. Contrary to our expectations, we consistently find that anthropomorphized data graphics and standard charts have very similar effects on empathy and prosocial behavior.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5462–5474},
numpages = {13},
keywords = {information visualization for the people, prosocial behavior, anthropographics, empathy, human rights},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025870,
author = {Dimara, Evanthia and Bezerianos, Anastasia and Dragicevic, Pierre},
title = {Narratives in Crowdsourced Evaluation of Visualizations: A Double-Edged Sword?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025870},
doi = {10.1145/3025453.3025870},
abstract = {We explore the effects of providing task context when evaluating visualization tools using crowdsourcing. We gave crowdsource workers i) abstract information visualization tasks without any context, ii) tasks where we added semantics to the dataset, and iii) tasks with two types of backstory narratives: an analytic narrative and a decision-making narrative. Contrary to our expectations, we did not find evidence that adding data semantics increases accuracy, and further found that our backstory narratives can even decrease accuracy. Adding dataset semantics can however increase attention and provide subjective benefits in terms of confidence, perceived easiness, task enjoyability and perceived usefulness of the visualization. Nevertheless, our backstory narratives did not appear to provide additional subjective benefits. These preliminary findings suggest that narratives may have complex and unanticipated effects, calling for more studies in this area.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5475–5484},
numpages = {10},
keywords = {crowdsource, information visualization, narrative, evaluation, instructions, decision making},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025877,
author = {Alper, Basak and Riche, Nathalie Henry and Chevalier, Fanny and Boy, Jeremy and Sezgin, Metin},
title = {Visualization Literacy at Elementary School},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025877},
doi = {10.1145/3025453.3025877},
abstract = {This work advances our understanding of children's visualization literacy, and aims to improve it through a novel approach for teaching visualization at elementary school. We first contribute an analysis of data graphics and activities employed in grade K to 4 educational materials, and the results of a survey conducted with 16 elementary school teachers. We find that visualization education could benefit from integrating pedagogical strategies for teaching abstract concepts with established interactive visualization techniques. Building on these insights, we develop and study design principles for novel interactive teaching material aimed at increasing children's visualization literacy. We specifically contribute C'est La Vis, an online platform for teachers and students to respectively teach and learn about pictographs and bar charts, and report on our initial observations of its use in grades K and 2.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5485–5497},
numpages = {13},
keywords = {qualitative analysis, visualization literacy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025777,
author = {Du, Fan and Plaisant, Catherine and Spring, Neil and Shneiderman, Ben},
title = {Finding Similar People to Guide Life Choices: Challenge, Design, and Evaluation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025777},
doi = {10.1145/3025453.3025777},
abstract = {People often seek examples of similar individuals to guide their own life choices. For example, students making academic plans refer to friends; patients refer to acquaintances with similar conditions, physicians mention past cases seen in their practice. How would they want to search for similar people in databases? We discuss the challenge of finding similar people to guide life choices and report on a need analysis based on 13 interviews. Our PeerFinder prototype enables users to find records that are similar to a seed record, using both record attributes and temporal events found in the records. A user study with 18 participants and four experts shows that users are more engaged and more confident about the value of the results to provide useful evidence to guide life choices when provided with more control over the search process and more context for the results, even at the cost of added complexity.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5498–5544},
numpages = {47},
keywords = {temporal visualization, visual analytics, decision making, temporal event analytics, similarity},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025564,
author = {Shannon, Amy and Sciuto, Alex and Hu, Danielle and Dow, Steven P. and Hammer, Jessica},
title = {Better Organization or a Source of Distraction? Introducing Digital Peer Feedback to a Paper-Based Classroom},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025564},
doi = {10.1145/3025453.3025564},
abstract = {Peer feedback is a central activity for project-based design education. The prevalence of devices carried by students and the emergence of novel peer feedback systems enables the possibility of collecting and sharing feedback immediately between students during class. However, pen and paper is thought to be more familiar, less distracting for students, and easier for instructors to implement and manage. To evaluate the efficacy of in-class digital feedback systems, we conducted a within-subjects study with 73 students during two weeks of a game design course. After short student presentations, while instructors provided verbal feedback, peers provided feedback either on paper or through a device. The study found that both methods yielded comments of similar quality and quantity, but the digital approach provided additional ways for students to participate and required less effort from the instructors. While both methods produced similar behaviors, students held inaccurate perceptions about their behavior with each method. We discuss design implications for technologies to support in-class feedback exchange.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5545–5555},
numpages = {11},
keywords = {in-class activities, peer feedback, interactive learning techniques, computer-supported collaborative learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025679,
author = {Kharrufa, Ahmed and Rix, Sally and Osadchiy, Timur and Preston, Anne and Olivier, Patrick},
title = {Group Spinner: Recognizing and Visualizing Learning in the Classroom for Reflection, Communication, and Planning},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025679},
doi = {10.1145/3025453.3025679},
abstract = {Group Spinner is a digital visual tool intended to help teachers observe and reflect on children's collaborative technology-enhanced learning activities in the classroom. We describe the design of Group Spinner, which was informed by activity theory, previous work and teachers' focus group feedback. Based on a radar chart and a set of indicators, Group Spinner allows teachers to record in-class observations as to different aspects of group learning and learning behaviors, beyond the limited knowledge acquisition measures. Our exploratory study involved 6 teachers who used the tool for a total of 23 classes in subjects ranging from Maths and Geography to Sociology and Art. Semi-structured interviews with these teachers revealed a number of different uses of the tool. Depending on their experience and pedagogy, teachers considered Group Spinner to be a valuable tool to support awareness, reflection, communication, and/or planning.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5556–5567},
numpages = {12},
keywords = {schools/educational setting, reflection, collaboration, observation, radar-chart, technology enhanced learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025779,
author = {Zhu, Yeshuang and Wang, Yuntao and Yu, Chun and Shi, Shaoyun and Zhang, Yankai and He, Shuang and Zhao, Peijun and Ma, Xiaojuan and Shi, Yuanchun},
title = {ViVo: Video-Augmented Dictionary for Vocabulary Learning},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025779},
doi = {10.1145/3025453.3025779},
abstract = {Research on Computer-Assisted Language Learning (CALL) has shown that the use of multimedia materials such as images and videos can facilitate interpretation and memorization of new words and phrases by providing richer cues than text alone. We present ViVo, a novel video-augmented dictionary that provides an inexpensive, convenient, and scalable way to exploit huge online video resources for vocabulary learning. ViVo automatically generates short video clips from existing movies with the target word highlighted in the subtitles. In particular, we apply a word sense disambiguation algorithm to identify the appropriate movie scenes with adequate contextual information for learning. We analyze the challenges and feasibility of this approach and describe our interaction design. A user study showed that learners were able to retain nearly 30% more new words with ViVo than with a standard bilingual dictionary days after learning. They preferred our video-augmented dictionary for its benefits in memorization and enjoyable learning experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5568–5579},
numpages = {12},
keywords = {vocabulary learning, dictionary, movie clips, subtitles},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025477,
author = {Wauck, Helen and Yen, Yu-Chun (Grace) and Fu, Wai-Tat and Gerber, Elizabeth and Dow, Steven P. and Bailey, Brian P.},
title = {From in the Class or in the Wild? Peers Provide Better Design Feedback Than External Crowds},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025477},
doi = {10.1145/3025453.3025477},
abstract = {As demand for design education increases, instructors are struggling to provide timely, personalized feedback for student projects. Gathering feedback from classroom peers and external crowds offer scalable approaches, but there is little evidence of how they compare. We report on a study in which students (n=127) created early- and late-stage prototypes as part of nine-week projects. At each stage, students received feedback from peers and external crowds: their own social networks, online communities, and a task market. We measured the quality, quantity and valence of the feedback and the actions taken on it, and categorized its content using a taxonomy of critique discourse. The study found that peers produced feedback that was of higher perceived quality, acted upon more, and longer compared to the crowds. However, crowd feedback was found to be a viable supplement to peer feedback and students preferred it for projects targeting specialized audiences. Feedback from all sources spanned only a subset of the critique categories. Instructors may fill this gap by further scaffolding feedback generation. The study contributes insights for how to best utilize different feedback sources in project-based courses.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5580–5591},
numpages = {12},
keywords = {design methods, crowdsourcing, learning, feedback},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025554,
author = {Xia, Haijun and Araujo, Bruno and Wigdor, Daniel},
title = {Collection Objects: Enabling Fluid Formation and Manipulation of Aggregate Selections},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025554},
doi = {10.1145/3025453.3025554},
abstract = {Despite the long development of Graphical User Interfaces, working with multiple graphical objects remains a challenge, due to the difficulties of forming complex selections, ambiguities of operations, and tediousness of repetitively unselect-reselect or ungroup-regroup objects. Instead of tackling them as individual problems, we attribute it to the lack of system support to the general selection-action cycles. We propose Collection Objects to not only support a single fast selection-action cycle but also allow multiple cycles to be chained together into a fluid workflow. Collection Objects unifies selection, grouping, and manipulation of aggregate selections into a single object, with which selection can be composed with various techniques, modified for later actions, grouped with objects inside still directly accessible, and quasi-moded for less context switching. We implemented Collection Object in the context of a vector drawing application with simultaneous pen and touch input. Results of an expert evaluation show that Collection Objects holds considerable promises for fluid interaction with multiple objects.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5592–5604},
numpages = {13},
keywords = {object-oriented interaction, collection object, pen and touch},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025525,
author = {Klamka, Konstantin and Dachselt, Raimund},
title = {IllumiPaper: Illuminated Interactive Paper},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025525},
doi = {10.1145/3025453.3025525},
abstract = {Due to their simplicity and flexibility, digital pen-and-paper solutions have a promising potential to become a part of our daily work. Unfortunately, they lack dynamic visual feedback and thereby restrain advanced digital functionalities. In this paper, we investigate new forms of paper-integrated feedback, which build on emerging paper-based electronics and novel thin-film display technologies. Our approach focuses on illuminated elements, which are seamlessly integrated into standard paper. For that, we introduce an extended design space for paper-integrated illuminations. As a major contribution, we present a systematic feedback repertoire for real-world applications including feedback components for innovative paper interaction tasks in five categories. Furthermore, we contribute a fully-functional research platform including a paper-controller, digital pen and illuminated, digitally controlled papers that demonstrate the feasibility of our techniques. Finally, we report on six interviews, where experts rated our approach as intuitive and very usable for various applications, in particular educational ones.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5605–5618},
numpages = {14},
keywords = {pen interaction, digital pen and paper, augmented paper, thin-film display, electro-luminescence, visual feedback, anoto},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025585,
author = {Cattan, Elie and Rochet-Capellan, Am\'{e}lie and Perrier, Pascal and B\'{e}rard, Fran\c{c}ois},
title = {Does Practice Make Perfect?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025585},
doi = {10.1145/3025453.3025585},
abstract = {Touch latency has been shown to deteriorate users' performances at levels as low as 25 ms, but this was tested only in short experimental sessions. Real life usage of touchscreens covers much longer periods. It provides training which could lead to reduce the impact of latency.We investigate users' ability to compensate for touch latency with training. Two groups of participants were trained on a tracking task during ten different days over two weeks with either high or low latency. The gap of performances between the two groups, observed at the beginning of the experiment, was reduced by 54 % after training. Users can thus compensate for latency, at least partially. These results nuance the negative effects of touch latency reported in previous work. They suggest that long-term studies could provide better insights on users' behaviors when dealing with touch latency.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5619–5629},
numpages = {11},
keywords = {training, direct-touch, learning, user performances, tracking task, latency},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025486,
author = {Fruchard, Bruno and Lecolinet, Eric and Chapuis, Olivier},
title = {MarkPad: Augmenting Touchpads for Command Selection},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025486},
doi = {10.1145/3025453.3025486},
abstract = {We present MarkPad, a novel interaction technique taking advantage of the touchpad. MarkPad allows creating a large number of size-dependent gestural shortcuts that can be spatially organized as desired by the user. It relies on the idea of using visual or tactile marks on the touchpad or a combination of them. Gestures start from a mark on the border and end on another mark anywhere. MarkPad does not conflict with standard interactions and provides a novice mode that acts as a rehearsal of the expert mode. A first study showed that an accuracy of 95% could be achieved for a dense configuration of tactile and/or visual marks allowing many gestures. Performance was 5% lower in a second study where the marks were only on the borders. A last study showed that borders are rarely used, even when the users are unaware of the technique. Finally, we present a working prototype and briefly report on how it was used by two users for a few months.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5630–5642},
numpages = {13},
keywords = {user-defined gestures, bezel gestures, gestural interaction, marking menus, tactile feedback, spatial memory, touchpad},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025474,
author = {Arora, Rahul and Kazi, Rubaiat Habib and Anderson, Fraser and Grossman, Tovi and Singh, Karan and Fitzmaurice, George},
title = {Experimental Evaluation of Sketching on Surfaces in VR},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025474},
doi = {10.1145/3025453.3025474},
abstract = {Sketching in immersive 3D virtual reality (VR) environments has great potential for a variety of interactive 3D design applications. Precisely sketching the intended strokes in mid-air, however, can be a challenge. In this paper, we present a set of controlled studies to analyze the factors affecting human ability to sketch freely in a 3D VR environment. In our first study, we directly compare traditional sketching on a physical surface to sketching in VR, with and without a physical surface to rest the stylus on. Our results indicate that the lack of a physical drawing surface is a major cause of inaccuracies in VR drawing, and that the effect is dependent on the orientation of the drawing surface. In a second experiment, we evaluate the extent to which visual guidance can compensate for the loss of sketching precision in VR. We found that while additional visual guidance improves positional accuracy, it can be detrimental to the aesthetic quality of strokes. We conclude by distilling our experimental findings into design guidelines for sketching tools in immersive 3D environments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5643–5654},
numpages = {12},
keywords = {motor ability, 3d drawing, visual factors, virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026046,
author = {McGill, Mark and Ng, Alexander and Brewster, Stephen},
title = {I Am The Passenger: How Visual Motion Cues Can Influence Sickness For In-Car VR},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026046},
doi = {10.1145/3025453.3026046},
abstract = {This paper explores the use of VR Head Mounted Displays (HMDs) in-car and in-motion for the first time. Immersive HMDs are becoming everyday consumer items and, as they offer new possibilities for entertainment and productivity, people will want to use them during travel in, for example, autonomous cars. However, their use is confounded by motion sickness caused in-part by the restricted visual perception of motion conflicting with physically perceived vehicle motion (accelerations/rotations detected by the vestibular system). Whilst VR HMDs restrict visual perception of motion, they could also render it virtually, potentially alleviating sensory conflict. To study this problem, we conducted the first on-road and in motion study to systematically investigate the effects of various visual presentations of the real-world motion of a car on the sickness and immersion of VR HMD wearing passengers. We established new baselines for VR in-car motion sickness, and found that there is no one best presentation with respect to balancing sickness and immersion. Instead, user preferences suggest different solutions are required for differently susceptible users to provide usable VR in-car. This work provides formative insights for VR designers and an entry point for further research into enabling use of VR HMDs, and the rich experiences they offer, when travelling.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5655–5668},
numpages = {14},
keywords = {autonomous car, hmd, mixed reality, motion sickness, passenger, virtual reality, in-car, automobile, in-motion},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026009,
author = {Rietzler, Michael and Plaumann, Katrin and Kr\"{a}nzle, Taras and Erath, Marcel and Stahl, Alexander and Rukzio, Enrico},
title = {VaiR: Simulating 3D Airflows in Virtual Reality},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026009},
doi = {10.1145/3025453.3026009},
abstract = {The integration of multi-sensory stimuli, e.g. haptic airflow, in virtual reality (VR) has become an important topic of VR research and proved to enhance the feeling of presence. VaiR focuses on an accurate and realistic airflow simulation that goes far beyond wind. While previous works on the topic of airflow in VR are restricted to wind, while focusing on the feeling of presence, there is to the best of our knowledge no work considering the conceptual background or on the various application areas. Our pneumatic prototype emits short and long term flows with a minimum delay and is able to animate wind sources in 3D space around the user's head. To get insights on how airflow can be used in VR and how such a device should be designed, we arranged focus groups and discussed the topic. Based on the gathered knowledge, we developed a prototype which proved to increase presence, as well as enjoyment and realism, while not disturbing the VR experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5669–5677},
numpages = {9},
keywords = {airflow, evaluation, presence, virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025535,
author = {Lee, Hee Rin and \v{S}abanovi\'{c}, Selma and Kwak, Sonya S.},
title = {Collaborative Map Making: A Reflexive Method for Understanding Matters of Concern in Design Research},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025535},
doi = {10.1145/3025453.3025535},
abstract = {HCI researchers investigating the politics of technology design have recently focused on how design practice can tackle "Matters of Concern" - complex social issues perceived and experienced in multiple ways. These researchers suggest design research can generate new networks of human and non-human actors to express and act on these issues. Prior studies, however, tend to restrict their networks within traditional boundaries (e.g. existing organizations, local communities) and categories (e.g. human/nonhuman binary) without examining their significance for participants. We suggest collaborative map making as a reflexive method for understanding current Matters of Concern from the perspectives of diverse actors, not just researchers. As case studies of the method's use, we present two studies of domestic computing technologies in the US and South Korea, which show how collaborative map making allows salient networks to expand beyond the individual actors in the home to local and global power issues outside of boundaries (e.g. physical house) and categories (e.g. private/public space) commonly recognized in HCI. Our methodology provides HCI researchers with a way to understand existing Matters of Concern, so they can position themselves to address and act on these issues.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5678–5689},
numpages = {12},
keywords = {home, situational analysis, actor network, matters of concern, reflexivity, collaborative mapping},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025645,
author = {Henley, Austin Z. and Fleming, Scott D. and Luong, Maria V.},
title = {Toward Principles for the Design of Navigation Affordances in Code Editors: An Empirical Investigation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025645},
doi = {10.1145/3025453.3025645},
abstract = {Design principles are a key tool for creators of interactive systems; however, a cohesive set of principles has yet to emerge for the design of code editors. In this paper, we conducted a between-subjects empirical study comparing the navigation behaviors of 32 professional LabVIEW programmers using two different code-editor interfaces: the ubiquitous tabbed editor and the experimental Patchworks editor. Our analysis focused on how the programmers arranged and navigated among open information patches (i.e., code modules and program output). Key findings of our study included that Patchworks users made significantly fewer click actions per navigation, juxtaposed patches side by side significantly more, and exhibited significantly fewer navigation mistakes than tabbed-editor users. Based on these findings and more, we propose five general principles for the design of effective navigation affordances in code editors.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5690–5702},
numpages = {13},
keywords = {programming environments, navigation, user study, visual programming languages, design principles},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025976,
author = {Roy, Quentin and Perrault, Simon T. and Zhao, Shengdong and Davis, Richard C. and Pattena Vaniyar, Anuroop and Vechev, Velko and Lee, Youngki and Misra, Archan},
title = {Follow-My-Lead: Intuitive Indoor Path Creation and Navigation Using Interactive Videos},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025976},
doi = {10.1145/3025453.3025976},
abstract = {We present Follow-My-Lead, an alternative indoor navigation technique that uses visual information recorded on an actual navigation path as a navigational guide. Its design revealed a trade-off between the fidelity of information provided to users and their effort to acquire it. Our first experiment revealed that scrolling through a continuous image stream of the navigation path is highly informative, but it becomes tedious with constant use. Discrete image checkpoints require less effort, but can be confusing. A balance may be struck by adding fast video transitions between image checkpoints, but precise control is required to handle difficult situations. Authoring still image checkpoints is also difficult, and this inspired us to invent a new technique using video checkpoints. We conducted a second experiment on authoring and navigation performance and found video checkpoints plus fast video transitions to be better than both image checkpoints plus fast video transitions and traditional written instructions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5703–5715},
numpages = {13},
keywords = {mobile computing, smartglasses, video, indoor navigation, wearable computing, leader-follower, egocentric visual navigation.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025672,
author = {Stein, Martin and Meurer, Johanna and Boden, Alexander and Wulf, Volker},
title = {Mobility in Later Life: Appropriation of an Integrated Transportation Platform},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025672},
doi = {10.1145/3025453.3025672},
abstract = {We present the results of a design case study focusing on supporting the daily transportation of elderly in Germany. We conceptualized, developed and studied the appropriation of a transportation information system intended to ease switching between different transportation modes. Based on a literature review and a context study with 21 interviews we explored routinized transport mode usage and barriers when switching between modes. Iteratively, we co-designed a transport platform accessible via a website, a mobile app, and an iTV app. We further looked at the appropriation of the platform into the daily lives of 19 persons. Studying the appropriation highlighted different factors that facilitate the adoption of alternative transport options. The factors included reducing uncertainty, complementing transport information with context information (e.g. weather) and providing informational access based on the user's preferences as well as fitting in with the situational needs (activity related).},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5716–5729},
numpages = {14},
keywords = {transportation, participatory design, elderly, qualitative research, mobility},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025622,
author = {McNally, Brenna and Mauriello, Matthew Louis and Guha, Mona Leigh and Druin, Allison},
title = {Gains from Participatory Design Team Membership as Perceived by Child Alumni and Their Parents},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025622},
doi = {10.1145/3025453.3025622},
abstract = {The direct gains children perceive from their membership on Participatory Design (PD) teams are seldom the focus of research studies. Yet, how HCI practitioners choose to include children in PD methods may influence the value participants see in their participation, and thereafter the outcomes of PD processes. To understand what gains former child members of a PD team perceive from their participation we conducted a two-part study. In Study 1 we surveyed and interviewed child alumni of a PD team to determine gains that are perceived first-hand. In Study 2 we obtained a secondary perspective by surveying and interviewing parents of alumni. We report on the perceived gains to former participants that were identified and described in these two studies-including collaboration, communication, design process knowledge, and confidence. We reflect on our findings through discussions of the continued applicability of gains, new opportunities, and implications for PD practitioners and methods.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5730–5741},
numpages = {12},
keywords = {gains, participant perspective, children, co-design, participatory design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025787,
author = {Yip, Jason C. and Sobel, Kiley and Pitt, Caroline and Lee, Kung Jin and Chen, Sijin and Nasu, Kari and Pina, Laura R.},
title = {Examining Adult-Child Interactions in Intergenerational Participatory Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025787},
doi = {10.1145/3025453.3025787},
abstract = {Prior studies have focused on child interactions in participatory design (PD) with adults and children, but less is known about what specific adult-child interactions constitute a partnership. In this study, we unpack what constitutes an "equal partnership" in PD between adults and children. On the basis of prior literature, we created a new framework that examines the complementary roles between children and adults. Next, we analyzed a case study of a year-long intergenerational design team of children (ages 7-11) and adults. From this analysis, we determined that design partnerships are composed of four dimensions that span from unbalanced to balanced interactions: facilitation, relationship building, design-by-doing, and elaborating together. Finally, to demonstrate its utility, we analyzed two focal co-design sessions using our framework. Our analysis suggests that equal partnership in PD is not a single static interaction but a development over time of design interactions influenced by context, experience, and participants.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5742–5754},
numpages = {13},
keywords = {design methods, cooperative inquiry, co-design, children, youth, participatory design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025851,
author = {Spiel, Katta and Malinverni, Laura and Good, Judith and Frauenberger, Christopher},
title = {Participatory Evaluation with Autistic Children},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025851},
doi = {10.1145/3025453.3025851},
abstract = {Participatory Design (PD) has become a standard methodology in HCI, however, the evaluation of the outcomes of participatory processes is often exclusively driven by researcher defined measures of success. Through our work with autistic children, who have radically different life worlds from our own, it became evident that their criteria for the success of a project are most likely also very different. In order to address the limitations of researcher defined and led evaluations in this context, we developed an approach for participatory evaluation called PEACE (Participatory Evaluation with Autistic ChildrEn). Using this approach, we were able to include autistic children in dedicated evaluation phases through the co-definition of goals and methods, joint processes of data gathering and the co-interpretation of results. We discuss three case studies in which we successfully applied our approach and conclude with a reflection on the novel insights created through participatory evaluation and researchers' roles in such a process.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5755–5766},
numpages = {12},
keywords = {participatory evaluation, children, autism},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025588,
author = {Hiniker, Alexis and Sobel, Kiley and Lee, Bongshin},
title = {Co-Designing with Preschoolers Using Fictional Inquiry and Comicboarding},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025588},
doi = {10.1145/3025453.3025588},
abstract = {In this case study, we describe a design workshop with 7 children age 4-6 using existing co-design techniques known to elicit design insights in older individuals. We found that our 5- and 6-year-old participants successfully generated design ideas using these methods, while 4-year-olds were unable to use create solutions in a traditional format. How-ever, these younger children enthusiastically offered opportunities where, with methodological guidance, the research-er could have followed the child's lead and shifted the design question to one that was potentially more meaningful for the participant. We propose a future work to examine the effectiveness of giving these younger participants great-er authority in defining and scoping the problem space.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5767–5772},
numpages = {6},
keywords = {participatory design, early childhood, comicboarding, fictional inquiry, design workshop},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025549,
author = {Zhu, Haining and Luo, Yuhan and Choe, Eun Kyoung},
title = {Making Space for the Quality Care: Opportunities for Technology in Cognitive Behavioral Therapy for Insomnia},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025549},
doi = {10.1145/3025453.3025549},
abstract = {Insomnia can drastically affect individuals' overall well-being and work performance, with substantial costs to society and industry. Cognitive behavioral therapy for insomnia (CBT-I) is a psychotherapeutic treatment, which requires patients to track sleep and share the data with CBT-I clinicians. However, the number of specialists who can provide CBT-I limits the number of patients who can receive it. In this paper, we aim to identify opportunities to leverage technology to assist clinicians in delivering quality and effective CBT-I services to broader populations. Toward this goal, we conducted formative studies, including 11 CBT-I clinic observations and 17 semi-structured interviews, to understand the current workflow of CBT-I and associated challenges. We discuss how technology can assist clinicians and patients throughout the various steps of CBT-I workflow while addressing some of the identified challenges, and more broadly, how technology can make space for clinicians and patients to build quality therapeutic relationships.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5773–5786},
numpages = {14},
keywords = {self- monitoring data, patient-generated data, observation, clinical workflow, patient engagement, interview, cognitive behavioral therapy for insomnia (cbt-i)},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025570,
author = {Kim, Yoojung and Heo, Eunyoung and Lee, Hyunjeong and Ji, Sookyoung and Choi, Jueun and Kim, Jeong-Whun and Lee, Joongseek and Yoo, Sooyoung},
title = {Prescribing 10,000 Steps Like Aspirin: Designing a Novel Interface for Data-Driven Medical Consultations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025570},
doi = {10.1145/3025453.3025570},
abstract = {Due to the prevalence of personal health tracking, cases of self-logged data being utilized in the clinic are gradually increasing. However, obstacles to clinicians' ability to further adopt such data-driven medical consultations in the existing workflow remain, such as lack of time and poor interoperability. In this paper, we conducted a workshop to design a clinician interface supporting the integration of data-driven consultation into the existing workflow and investigate the role of the interface in situ. After implementing the clinician interface designed based on the workshop results, we observed 32 cases of actual use within the clinical context. We found that our interface, DataMD, helped the clinician construct a new workflow, enhanced the clinician's counseling skills, and facilitated more in-depth conversation. This paper contributes to empirically identifying the role of a clinician interface through a user-centered design approach.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5787–5799},
numpages = {13},
keywords = {design workshop, clinician interface, data-driven medical consultation, self-logged data, patient-generated data},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025589,
author = {Mentis, Helena M. and Komlodi, Anita and Schrader, Katrina and Phipps, Michael and Gruber-Baldini, Ann and Yarbrough, Karen and Shulman, Lisa},
title = {Crafting a View of Self-Tracking Data in the Clinical Visit},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025589},
doi = {10.1145/3025453.3025589},
abstract = {When self-tracking encounters clinical practices, the data is reshaped by goals and expertise that exist within a healthcare framework. To uncover these shaping practices, we provided a Fitbit Zip step-count sensor to nine patients with Parkinson's disease. Each patient wore the sensor for four weeks and then returned for a clinical visit with their neurologist. Our analysis focuses on this first clinical visit after four weeks of data had been collected. Our use of conversation analysis of both talk and action makes visible the practices engaged in by both collaborative members to 'craft a view' of the data toward shared decision making. Our findings reveal the deliberate guiding of attention to specific interpretations of the data through both talk and actions and we explain how our systematic analysis has uncovered tools for the mutually beneficial crafting practices of the clinician and patient.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5800–5812},
numpages = {13},
keywords = {self-tracking, perception, quantified self, activity tracker},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025943,
author = {Dow, Andy and Vines, John and Lowe, Toby and Comber, Rob and Wilson, Rob},
title = {What Happens to Digital Feedback? Studying the Use of a Feedback Capture Platform by Care Organisations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025943},
doi = {10.1145/3025453.3025943},
abstract = {In this paper we report on a four-month long field trial of ThoughtCloud, a feedback collection platform that allows people to leave ratings and audio or video responses to simple prompts. ThoughtCloud was trialled with four organisations providing care services for people with disabilities. We conducted interviews with staff and volunteers that used ThoughtCloud before, during and after its deployment, and workshops with service users and staff. While the collection of feedback was high, only one organisation regularly reviewed and responded to collected opinions. Furthermore, tensions arose around data access and sharing, and the mismatch of values between "giving voice" and the capacity for staff to engage in feedback practices. We contribute insights into the challenges faced in using novel technologies in resource constrained organisations, and discuss opportunities for designs that give greater agency to service users to engage those that care for them in reflecting and responding to their opinions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5813–5825},
numpages = {13},
keywords = {feedback, health, social care, democracy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025845,
author = {Guo, Anhong and Kim, Jeeeun and Chen, Xiang 'Anthony' and Yeh, Tom and Hudson, Scott E. and Mankoff, Jennifer and Bigham, Jeffrey P.},
title = {Facade: Auto-Generating Tactile Interfaces to Appliances},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025845},
doi = {10.1145/3025453.3025845},
abstract = {Common appliances have shifted toward flat interface panels, making them inaccessible to blind people. Although blind people can label appliances with Braille stickers, doing so generally requires sighted assistance to identify the original functions and apply the labels. We introduce Facade - a crowdsourced fabrication pipeline to help blind people independently make physical interfaces accessible by adding a 3D printed augmentation of tactile buttons overlaying the original panel. Facade users capture a photo of the appliance with a readily available fiducial marker (a dollar bill) for recovering size information. This image is sent to multiple crowd workers, who work in parallel to quickly label and describe elements of the interface. Facade then generates a 3D model for a layer of tactile and pressable buttons that fits over the original controls. Finally, a home 3D printer or commercial service fabricates the layer, which is then aligned and attached to the interface by the blind person. We demonstrate the viability of Facade in a study with 11 blind participants.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5826–5838},
numpages = {13},
keywords = {visually impaired, non-visual interfaces, computer vision, accessibility, crowdsourcing, 3d printing, blind, fabrication},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025899,
author = {Kacorri, Hernisa and Kitani, Kris M. and Bigham, Jeffrey P. and Asakawa, Chieko},
title = {People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025899},
doi = {10.1145/3025453.3025899},
abstract = {Blind people often need to identify objects around them, from packages of food to items of clothing. Automatic object recognition continues to provide limited assistance in such tasks because models tend to be trained on images taken by sighted people with different background clutter, scale, viewpoints, occlusion, and image quality than in photos taken by blind users. We explore personal object recognizers, where visually impaired people train a mobile application with a few snapshots of objects of interest and provide custom labels. We adopt transfer learning with a deep learning system for user-defined multi-label k-instance classification. Experiments with blind participants demonstrate the feasibility of our approach, which reaches accuracies over 90% for some participants. We analyze user data and feedback to explore effects of sample size, photo-quality variance, and object shape; and contrast models trained on photos by blind participants to those by sighted participants and generic recognizers.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5839–5849},
numpages = {11},
keywords = {object recognition, computer vision, blind, accessibility, photographs},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026002,
author = {Taranta II, Eugene M. and Samiei, Amirreza and Maghoumi, Mehran and Khaloo, Pooya and Pittman, Corey R. and LaViola Jr., Joseph J.},
title = {Jackknife: A Reliable Recognizer with Few Samples and Many Modalities},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026002},
doi = {10.1145/3025453.3026002},
abstract = {Despite decades of research, there is yet no general rapid prototyping recognizer for dynamic gestures that can be trained with few samples, work with continuous data, and achieve high accuracy that is also modality-agnostic. To begin to solve this problem, we describe a small suite of accessible techniques that we collectively refer to as the Jackknife gesture recognizer. Our dynamic time warping based approach for both segmented and continuous data is designed to be a robust, go-to method for gesture recognition across a variety of modalities using only limited training samples. We evaluate pen and touch, Wii Remote, Kinect, Leap Motion, and sound-sensed gesture datasets as well as conduct tests with continuous data. Across all scenarios we show that our approach is able to achieve high accuracy, suggesting that Jackknife is a capable recognizer and good first choice for many endeavors.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5850–5861},
numpages = {12},
keywords = {user evaluation, rapid prototyping, gesture customization, gesture recognition, dynamic time warping},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025731,
author = {Billah, Syed Masum and Ashok, Vikas and Porter, Donald E. and Ramakrishnan, I.V.},
title = {Ubiquitous Accessibility for People with Visual Impairments: Are We There Yet?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025731},
doi = {10.1145/3025453.3025731},
abstract = {Ubiquitous access is an increasingly common vision of computing, wherein users can interact with any computing device or service from anywhere, at any time. In the era of personal computing, users with visual impairments required special-purpose, assistive technologies, such as screen readers, to interact with computers. This paper investigates whether technologies like screen readers have kept pace with, or have created a barrier to, the trend toward ubiquitous access, with a specific focus on desktop computing as this is still the primary way computers are used in education and employment. Towards that, the paper presents a user study with 21 visually-impaired participants, specifically involving the switching of screen readers within and across different computing platforms, and the use of screen readers in remote access scenarios. Among the findings, the study shows that, even for remote desktop access - an early forerunner of true ubiquitous access - screen readers are too limited, if not unusable. The study also identifies several accessibility needs, such as uniformity of navigational experience across devices, and recommends potential solutions. In summary, assistive technologies have not made the jump into the era of ubiquitous access, and multiple, inconsistent screen readers create new practical problems for users with visual impairments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5862–5868},
numpages = {7},
keywords = {mobile computing, remote access, multiple screen readers, ubiquitous accessibility, visually impaired users},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025524,
author = {Liu, Wanyu and D'Oliveira, Rafael Lucas and Beaudouin-Lafon, Michel and Rioul, Olivier},
title = {BIGnav: Bayesian Information Gain for Guiding Multiscale Navigation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025524},
doi = {10.1145/3025453.3025524},
abstract = {This paper introduces BIGnav, a new multiscale navigation technique based on Bayesian Experimental Design where the criterion is to maximize the information-theoretic concept of mutual information, also known as information gain. Rather than simply executing user navigation commands, BIGnav interprets user input to update its knowledge about the user's intended target. Then it navigates to a new view that maximizes the information gain provided by the user's expected subsequent input. We conducted a controlled experiment demonstrating that BIGnav is significantly faster than conventional pan and zoom and requires fewer commands for distant targets, especially in non-uniform information spaces. We also applied BIGnav to a realistic application and showed that users can navigate to highly probable points of interest on a map with only a few steps. We then discuss the tradeoffs of BIGnav--including efficiency vs. increased cognitive load--and its application to other interaction tasks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5869–5880},
numpages = {12},
keywords = {guided navigation, multiscale navigation, bayesian experimental design, mutual information},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025935,
author = {Grandi, Jer\^{o}nimo Gustavo and Debarba, Henrique Galvan and Nedel, Luciana and Maciel, Anderson},
title = {Design and Evaluation of a Handheld-Based 3D User Interface for Collaborative Object Manipulation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025935},
doi = {10.1145/3025453.3025935},
abstract = {Object manipulation in 3D virtual environments demands a combined coordination of rotations, translations and scales, as well as the camera control to change the user's viewpoint. Then, for many manipulation tasks, it would be advantageous to share the interaction complexity among team members. In this paper we propose a novel 3D manipulation interface based on a collaborative action coordination approach. Our technique explores a smartphone -- the touchscreen and inertial sensors -- as input interface, enabling several users to collaboratively manipulate the same virtual object with their own devices. We first assessed our interface design on a docking and an obstacle crossing tasks with teams of two users. Then, we conducted a study with 60 users to understand the influence of group size in collaborative 3D manipulation. We evaluated teams in combinations of one, two, three and four participants. Experimental results show that teamwork increases accuracy when compared with a single user. The accuracy increase is correlated with the number of individuals in the team and their work division strategy.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5881–5891},
numpages = {11},
keywords = {collaborative manipulation, user studies, 3D user interfaces},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025661,
author = {Saidi, Houssem and Serrano, Marcos and Irani, Pourang and Dubois, Emmanuel},
title = {TDome: A Touch-Enabled 6DOF Interactive Device for Multi-Display Environments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025661},
doi = {10.1145/3025453.3025661},
abstract = {The rapid evolution of multi-display environments (MDEs) has created a vacuum in need of novel input devices to optimize interaction in MDEs. In this paper, we propose TDome, a novel touch-enabled 6DOF input and output device to facilitate interactions in MDEs. TDome offers a private display as output, and multiple degrees of freedom as input by combining touch gestures on the display with physical rotation, roll and translation manipulations of the device. TDome allows versatile interactions that address major MDE tasks, which we illustrate through various proof-of-concept implementations: detect surrounding displays, select one display, transfer data across displays, reach distant displays and perform private interactions. We explore TDome's usability and suitability for MDEs through three user studies. First we explore combined physical+touch gestures from which we discard uncomfortable combinations. We experimentally validate their feasibility and come up with a set of 71 combined gestures that are comfortable and ensure a high success rate, i.e. that can be easily performed and efficiently detected. Finally, we collect user feedback to identify natural mappings between gestures and MDE interactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5892–5904},
numpages = {13},
keywords = {touch input, rolling device, input device, multi-display environments},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025905,
author = {Gutwin, Carl and Cockburn, Andy and Gough, Nickolas},
title = {A Field Experiment of Spatially-Stable Overviews for Document Navigation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025905},
doi = {10.1145/3025453.3025905},
abstract = {Finding (and re-finding) locations in text documents is a common activity for most computer users -- but tools for document navigation are still limited in many ways. Previous research has shown that a spatially-stable overview of the entire document can be substantially faster than any other navigation technique -- particularly when revisiting previous locations. However, the overview technique has only been tested in a limited laboratory study, so little is known about whether it works in more realistic contexts. To answer this question, we developed a PDF viewer that incorporates several document-navigation techniques, and carried out two studies. First, we ran a field experiment in which users carried out search tasks using an overview and other techniques -- on their own computers in a non-laboratory environment. Second, we ran a smaller field study in which people used our viewer (with choice of navigation techniques) for their own PDF tasks. In the field experiment, the overview was significantly and substantially faster than other techniques, and in the field study, the technique was frequently used for a wide variety of documents. Our work provides confirmation of the value of spatially stable overviews as a basis for document navigation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5905–5916},
numpages = {12},
keywords = {space-filling thumbnails, scrolling, document navigation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025545,
author = {Sambasivan, Nithya and Aoki, Paul M.},
title = {Imagined Connectivities: Synthesized Conceptions of Public Wi-Fi in Urban India},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025545},
doi = {10.1145/3025453.3025545},
abstract = {India and other economies in the Global South are undergoing a proliferation in public Wi-Fi, with large-scale deployments from industry and government. In this paper, we report on a qualitative study on public Wi-Fi conceptions as held by urban Indians, textit{a priori} to connecting to a network. Our findings show that prior public Wi-Fi users and non-users alike raised a surprising range and depth of conceptions---ranging from suspicion of operators' intentions to monetize, to concerns about sexual image morphing, to fears of phone wipeouts, to aspiration---which were informed by popular media, BlueTooth cultures, and social learning. We found these conceptions of Wi-Fi networks to significantly influence adoption of public Wi-Fi. With enormous investments in public Wi-Fi initiatives, we call for network providers to address these deep conceptions among emerging users; by suggesting ways to build public awareness, better user experiences, and business model innovation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5917–5928},
numpages = {12},
keywords = {access, imaginaries, hci4d, public wi-fi, internet, media studies, ictd, india},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025895,
author = {Pal, Joyojeet and Viswanathan, Anandhi and Chandra, Priyank and Nazareth, Anisha and Kameswaran, Vaishnav and Subramonyam, Hariharan and Johri, Aditya and Ackerman, Mark S. and O'Modhrain, Sile},
title = {Agency in Assistive Technology Adoption: Visual Impairment and Smartphone Use in Bangalore},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025895},
doi = {10.1145/3025453.3025895},
abstract = {Studies on technology adoption typically assume that a user's perception of usability and usefulness of technology are central to its adoption. Specifically, in the case of accessibility and assistive technology, research has traditionally focused on the artifact rather than the individual, arguing that individual technologies fail or succeed based on their usability and fit for their users. Using a mixed-methods field study of smartphone adoption by 81 people with visual impairments in Bangalore, India, we argue that these positions are dated in the case of accessibility where a non-homogeneous population must adapt to technologies built for sighted people. We found that many users switch to smartphones despite their awareness of significant usability challenges with smartphones. We propose a nuanced understanding of perceived usefulness and actual usage based on need-related social and economic functions, which is an important step toward rethinking technology adoption for people with disabilities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5929–5940},
numpages = {12},
keywords = {mobile phones, India, iOS, android, bangalore, accessibility},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025960,
author = {Rifat, Md. Rashidujjaman and Chen, Jay and Toyama, Kentaro},
title = {Money, God, and SMS: Explorations in Supporting Social Action Through a Bangladeshi Mosque},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025960},
doi = {10.1145/3025453.3025960},
abstract = {Religious institutions hold a significant place in daily life for the vast majority of people in the world, especially in developing countries. Yet despite their social prominence, and despite HCI's emphasis on the social context of technology, organized religion is neglected in both the HCI and ICTD literature. This paper explores the relationship that mosques in Bangladesh have with their constituencies and with technology, with an eye toward the integration of technology with existing religious institutions as a way to achieve positive social ends. We first describe a qualitative exploration of several mosque communities in Bangladesh, where we find that skepticism and pragmatism about modern technology interact in a complex way that nevertheless leaves room for technical interventions. We then describe a randomized controlled trial to study the relative value of SMS messages infused with overtly religious or secularly altruistic frames for the purpose of mosque fundraising. We find that SMS messages increase donations overall, but that their framing is significant. Messages with secular altruistic framing increased donations by 9.5%, while those with religious sentiment increased donations by 57.3%. Our findings demonstrate how technologies like SMS amplify underlying religious forces and suggest the possibility of working with religious institutions in applying positive ICT interventions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5941–5953},
numpages = {13},
keywords = {religion, donation, sms, ict4d, techno-spirituality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026039,
author = {Kandathil, George and Wagner, Erica L.},
title = {Negotiating Absent Practices and Dormant Features: Discourse as a Means of Shaping the Implementation of a Global Enterprise System to Meet Local Work Culture},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026039},
doi = {10.1145/3025453.3026039},
abstract = {The introduction of a new enterprise system to an organization often necessitates the accommodation of standardized practices, which may be in conflict with local users' practices and their work culture. We explore such a conflict in an India-based multinational organization using an eight-month interpretive case study. Based on grounded analysis, we present a narrative account of how consultants, on contract for managing the deployment and making necessary adjustments, used discourse as a means of shaping user understanding about the features and practices embedded in the underlying system, which were not initially realized through the interface. Sustained user resistance to this shaping led to a negotiated compromise and adaptation of the system to incorporate local work culture. Our findings allow us to explore the under-theorized role of discursive power within an implementer-user-technology trio, and illustrate the feedback utility of user resistance in developing culturally-inclusive designs.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5954–5965},
numpages = {12},
keywords = {hci4d, culture, cscw, enterprise system, cross-cultural design, appropriation, workplace studies, critical design, discursive, hci, affordance},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025478,
author = {Lu, Jiajun and Benko, Hrvoje and Wilson, Andrew D.},
title = {Hybrid HFR Depth: Fusing Commodity Depth and Color Cameras to Achieve High Frame Rate, Low Latency Depth Camera Interactions},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025478},
doi = {10.1145/3025453.3025478},
abstract = {The low frame rate and high latency of consumer depth cameras limits their use in interactive applications. We propose combining the Kinect depth camera with an ordinary color camera to synthesize a high frame rate and low latency depth image. We exploit common CMOS camera region of interest (ROI) functionality to obtain a high frame rate image over a small ROI. Motion in the ROI is computed by a fast optical flow implementation. The resulting flow field is used to extrapolate Kinect depth images to achieve high frame rate and low latency depth, and optionally predict depth to further reduce latency. Our "Hybrid HFR Depth" prototype generates useful depth images at maximum 500Hz with minimum 20ms latency. We demonstrate Hybrid HFR Depth in tracking fast moving objects, handwriting in the air, and projecting onto moving hands. Based on commonly available cameras and image processing implementations, Hybrid HFR Depth may be useful to HCI practitioners seeking to create fast, fluid depth camera-based interactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5966–5975},
numpages = {10},
keywords = {configurable, kinect, frame rate, depth camera, latency},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025607,
author = {Chen, Wen and Crandall, David J. and Su, Norman Makoto},
title = {Understanding the Aesthetic Evolution of Websites: Towards a Notion of Design Periods},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025607},
doi = {10.1145/3025453.3025607},
abstract = {In art and music, time periods like "classical" and "impressionist" are powerful means for academics and practitioners to compare and contrast artifacts that share aesthetics or philosophies. While web designs have undergone changes for 25 years, we lack theories to describe or explain these changes. In this paper, we take a first step towards identifying and understanding the design periods of websites. Drawing from humanistic HCI methods, we asked subject experts of web design to critically analyze a dataset of prominent websites whose lifetimes span over a decade. These informed judgments reveal a set of key markers that signal shifts in design periods. For instance, advances in display technologies and changes in company strategies help explain how design periods demarcated by particular layout templates and navigation models arise. We suggest that designers and marketers can draw inspiration from website designs curated into design periods. Future work should examine the utility of applying design periods to any computationally embedded artifact that is an interaction design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5976–5987},
numpages = {12},
keywords = {interaction design criticism, art, websites, design periods},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025814,
author = {MacLeod, Haley and Bennett, Cynthia L. and Morris, Meredith Ringel and Cutrell, Edward},
title = {Understanding Blind People's Experiences with Computer-Generated Captions of Social Media Images},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025814},
doi = {10.1145/3025453.3025814},
abstract = {Research advancements allow computational systems to automatically caption social media images. Often, these captions are evaluated with sighted humans using the image as a reference. Here, we explore how blind and visually impaired people experience these captions in two studies about social media images. Using a contextual inquiry approach (n=6 blind/visually impaired), we found that blind people place a lot of trust in automatically generated captions, filling in details to resolve differences between an image's context and an incongruent caption. We built on this in-person study with a second, larger online experiment (n=100 blind/visually impaired) to investigate the role of phrasing in encouraging trust or skepticism in captions. We found that captions emphasizing the probability of error, rather than correctness, encouraged people to attribute incongruence to an incorrect caption, rather than missing details. Where existing research has focused on encouraging trust in intelligent systems, we conclude by challenging this assumption and consider the benefits of encouraging appropriate skepticism.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5988–5999},
numpages = {12},
keywords = {automatic image captioning, twitter, accessibility, blindness, alt text, social media},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025810,
author = {Peng, Yilang},
title = {Time Travel with One Click: Effects of Digital Filters on Perceptions of Photographs},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025810},
doi = {10.1145/3025453.3025810},
abstract = {Today's digital photographs are being heavily "filtered." By simple clicks on mobile apps like Hipstamatic and Instagram, users can easily apply digital filters to their pictures to create effects such as faux-vintage and light leaks. To understand the potential impacts of photo filters, we conducted an online experiment and investigated how the use of the black-and-white and film-style photo filters changed viewers' perceptions and descriptions of photographs. We found that photo filters substantially increased viewers' perceived temporal distances to photographs. Participants also tended to describe analogue-style photos more interpretively and tentatively than unfiltered ones, indicating an increase in construal levels. We suggest that the widely used photo filter is not just a tool to change aesthetics; it also adds a layer of history, meaning, and defamiliarization to photographs, allowing users to construct a mental distance in images that deviates from everyday experiences. We offer insights into the psychology of visual styles and implications for designing filter apps and photo-sharing platforms.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6000–6011},
numpages = {12},
keywords = {mobile app, construal level theory, visual style, computational text analysis, digital filter},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025888,
author = {Jamieson, Matthew and O'Neill, Brian and Cullen, Breda and Lennon, Marilyn and Brewster, Stephen and Evans, Jonathan},
title = {ForgetMeNot: Active Reminder Entry Support for Adults with Acquired Brain Injury},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025888},
doi = {10.1145/3025453.3025888},
abstract = {Smartphone reminding apps can compensate for memory impairment after acquired brain injury (ABI). In the absence of a caregiver, users must enter reminders themselves if the apps are going to help them. Poor memory and apathy associated with ABI can result in failure to initiate such configuration behaviour and the benefits of reminder apps are lost. ForgetMeNot takes a novel approach to address this problem by periodically encouraging the user to enter reminders with unsolicited prompts (UPs). An in situ case study investigated the experience of using a reminding app for people with ABI and tested UPs as a potential solution to initiating reminder entry. Three people with severe ABI living in a post-acute rehabilitation hospital used the app in their everyday lives for four weeks to collect real usage data. Field observations illustrated how difficulties with motivation, insight into memory difficulties and anxiety impact reminder app use in a rehabilitation setting. Results showed that when 6 UPs were presented throughout the day, reminder-setting increased, showing UPs are an important addition to reminder applications for people with ABI. This study demonstrates that barriers to technology use can be resolved in practice when software is developed with an understanding of the issues experienced by the user group.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6012–6023},
numpages = {12},
keywords = {smartphone reminding, memory rehabilitation, acquired brain injury, assistive technology, in situ study, field study},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025846,
author = {Zhang, Xiaoyi and Ross, Anne Spencer and Caspi, Anat and Fogarty, James and Wobbrock, Jacob O.},
title = {Interaction Proxies for Runtime Repair and Enhancement of Mobile Application Accessibility},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025846},
doi = {10.1145/3025453.3025846},
abstract = {We introduce interaction proxies as a strategy for runtime repair and enhancement of the accessibility of mobile applications. Conceptually, interaction proxies are inserted between an application's original interface and the manifest interface that a person uses to perceive and manipulate the application. This strategy allows third-party developers and researchers to modify an interaction without an application's source code, without rooting the phone, without otherwise modifying an application, while retaining all capabilities of the system (e.g., Android's full implementation of the TalkBack screen reader). This paper introduces interaction proxies, defines a design space of interaction re-mappings, identifies necessary implementation abstractions, presents details of implementing those abstractions in Android, and demonstrates a set of Android implementations of interaction proxies from throughout our design space. We then present a set of interviews with blind and low-vision people interacting with our prototype interaction proxies, using these interviews to explore the seamlessness of interaction, the perceived usefulness and potential of interaction proxies, and visions of how such enhancements could gain broad usage. By allowing third-party developers and researchers to improve an interaction, interaction proxies offer a new approach to personalizing mobile application accessibility and a new approach to catalyzing development, deployment, and evaluation of mobile accessibility enhancements.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6024–6037},
numpages = {14},
keywords = {accessibility, runtime modification, interaction proxies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025483,
author = {Li, Toby Jia-Jun and Azaria, Amos and Myers, Brad A.},
title = {SUGILITE: Creating Multimodal Smartphone Automation by Demonstration},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025483},
doi = {10.1145/3025453.3025483},
abstract = {SUGILITE is a new programming-by-demonstration (PBD) system that enables users to create automation on smartphones. SUGILITE uses Android's accessibility API to support automating arbitrary tasks in any Android app (or even across multiple apps). When the user gives verbal commands that SUGILITE does not know how to execute, the user can demonstrate by directly manipulating the regular apps' user interface. By leveraging the verbal instructions, the demonstrated procedures, and the apps? UI hierarchy structures, SUGILITE can automatically generalize the script from the recorded actions, so SUGILITE learns how to perform tasks with different variations and parameters from a single demonstration. Extensive error handling and context checking support forking the script when new situations are encountered, and provide robustness if the apps change their user interface. Our lab study suggests that users with little or no programming knowledge can successfully automate smartphone tasks using SUGILITE.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6038–6049},
numpages = {12},
keywords = {end-user development, programming by demonstration, smartphone automation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025472,
author = {Ahmed, Alex A. and Goodwin, Matthew S.},
title = {Automated Detection of Facial Expressions during Computer-Assisted Instruction in Individuals on the Autism Spectrum},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025472},
doi = {10.1145/3025453.3025472},
abstract = {It has been suggested that computer-assisted instruction (CAI) is a promising method for educating students on the autism spectrum. We aimed to determine whether automated recognition of facial expressions aided in predicting CAI engagement and learning performance. Seven youth with autism (mean age = 12.7, SD = 4.2) interacted with a CAI program, TeachTown Basics, for 15 consecutive sessions. Video recordings of the participants' faces were collected during these sessions and facial expressions from these videos were analyzed using CERT, an algorithm that automatically outputs intensity values for each facial action unit (AU). Using these data, we attempted to operationally define two engagement indices: (1) behavioral engagement, the proportion of time a participant had their face oriented to the computer screen; and (2) emotional engagement, the activation of AUs previously associated with CAI. Our results suggest that both indices strongly correlated with one another, but that emotional (not behavioral) engagement predicted test performance. CAI knowledge domain, participant sex, and developmental age also contributed to the prediction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6050–6055},
numpages = {6},
keywords = {individuals with disabilities &amp; assistive technologies, computer vision, quantitative methods, emotion/affective computing, education/learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025603,
author = {Findlater, Leah and Moffatt, Karyn and Froehlich, Jon E. and Malu, Meethu and Zhang, Joan},
title = {Comparing Touchscreen and Mouse Input Performance by People With and Without Upper Body Motor Impairments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025603},
doi = {10.1145/3025453.3025603},
abstract = {Controlled studies of touchscreen input performance for users with upper body motor impairments remain relatively sparse. To address this gap, we present a controlled lab study of mouse vs. touchscreen performance with 32 participants (16 with upper body motor impairments and 16 without). Our study examines: (1) how touch input compares to an indirect pointing device (a mouse); (2) how performance compares across a range of standard interaction techniques; and (3) how these answers differ for users with and without motor impairments. While the touchscreen was faster than the mouse overall, only participants without motor impairments benefited from a lower error rate on the touchscreen. Indeed, participants with motor impairments had a three-fold increase in pointing (tapping) errors on the touchscreen compared to the mouse. Our findings also highlight the high frequency of spurious touches for users with motor impairments and update past accessibility recommendations for minimum touchscreen target sizes to at least 18mm.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6056–6061},
numpages = {6},
keywords = {motor impairments, accessibility, mouse, human performance, touchscreen, input devices},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025908,
author = {Muntean, Reese and Antle, Alissa N. and Matkin, Brendan and Hennessy, Kate and Rowley, Susan and Wilson, Jordan},
title = {Designing Cultural Values into Interaction},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025908},
doi = {10.1145/3025453.3025908},
abstract = {In this paper, we highlight possibilities for designing intangible cultural values into interactions with technologies in heritage spaces. We do this specifically through the design of elwkw -- Belongings, an interactive tangible table installed in a cultural heritage museum. The tabletop was collaboratively designed to communicate complex and narrative information and values about Musqueam culture. Rather than focusing only on content and interface design, we wanted visitors to also experience Musqueam values through their interactions with the system. We describe our value-sensitive design process, present five interdependent design goals, discuss the design strategies that enabled us to meet these goals, and evaluate our approach through a user study. From our design process and evaluation we offer recommendations for designing values into interactions more generally and for tangible interactions specifically in ways that support visitors' experience and understanding of specific cultural values through technology.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6062–6074},
numpages = {13},
keywords = {indigenous heritage, digital tabletops, museums, intangible cultural heritage, value sensitive design, tangibles},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025729,
author = {Webber, Sarah and Carter, Marcus and Sherwen, Sally and Smith, Wally and Joukhadar, Zaher and Vetere, Frank},
title = {Kinecting with Orangutans: Zoo Visitors' Empathetic Responses to Animals' Use of Interactive Technology},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025729},
doi = {10.1145/3025453.3025729},
abstract = {Animal conservation organisations occasionally harness depictions of animals using digital technology to inspire interest in, and concern for animals. To better understand the forms of empathy experienced by people observing animal-computer interaction, we designed and studied an interactive installation for orangutans at a zoo. Through collaborative design we established an understanding of zoos' objectives and strategies related to empathy in the zoo context. We deployed a prototype installation, and observed and interviewed visitors who watched orangutans use the installation. Analysis of observations and interviews revealed that visitors responded with cognitive, affective and motor empathy for the animals. We propose that these empathetic responses are prompted by the visibility of orangutans' bodily movements, by the "anthropic frame" provided by digital technology, and by prompting reflection on animals' cognitive processes and affective states. This paper contributes new evidence and understanding of people's empathetic responses to observing animal-computer interaction and confirms the value of designing for empathy in its various forms},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6075–6088},
numpages = {14},
keywords = {animal-computer interaction, conservation, empathy, primates, zoos},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025966,
author = {Su, Norman Makoto and Cheon, EunJeong},
title = {Reconsidering Nature: The Dialectics of Fair Chase in the Practices of American Midwest Hunters},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025966},
doi = {10.1145/3025453.3025966},
abstract = {In this paper, we describe an ethnographic study consisting of 14 interviews with hunters and participant observations in the American Midwest. We find that the ethos of "fair chase" serves to unite an eclectic group of hunters under a single moral compass. Fair chase posits, for example, that hunters must not have an improper advantage over animals. The actual practices of hunters in different communities (e.g., communities revolving around different weapons or professions), however, reveals a series of opposing points of view among hunters at large on what actually constitutes fair chase. We suggest that an understanding of fair chase and its dialectics can constructively problematize nature for human-computer interaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6089–6100},
numpages = {12},
keywords = {nature, hunters, hunting, fair chase, ethics, values, dialectics, rural},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025803,
author = {McGookin, David and Tahiro\u{a}lu, Koray and Vaittinen, Tuomas and Kyt\"{o}, Mikko and Monastero, Beatrice and Vasquez, Juan Carlos},
title = {Exploring Seasonality in Mobile Cultural Heritage},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025803},
doi = {10.1145/3025453.3025803},
abstract = {We present results of an investigation into the role of seasonality in mobile cultural heritage applications. 45 participants in 26 groups used one of two applications when visiting the Finnish recreational island of Seurasaari. Each provided summer and winter content, but varied in how this was presented. We uncovered how users consider seasonality in content, seasonal preferences, as well as how different media becomes more or less interesting if shown in or out of season. We present design considerations for future researchers to consider seasonality in cultural heritage applications.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6101–6105},
numpages = {5},
keywords = {seasonality, outdoor heritage site, open-air museum, mixed reality, location-based interaction, cultural heritage},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025720,
author = {Yin, Kodlee and Aragon, Cecilia and Evans, Sarah and Davis, Katie},
title = {Where No One Has Gone Before: A Meta-Dataset of the World's Largest Fanfiction Repository},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025720},
doi = {10.1145/3025453.3025720},
abstract = {With its roots dating to popular television shows of the 1960s such as Star Trek, fanfiction has blossomed into an extremely widespread form of creative expression. The transition from printed zines to online fanfiction repositories has facilitated this growth in popularity, with millions of fans writing stories and adding daily to sites such as Archive Of Our Own, Fanfiction.net, FIMfiction.net, and many others. Enthusiasts are sharing their writing, reading stories written by others, and helping each other to grow as writers. Yet, this domain is often undervalued by society and understudied by researchers. To facilitate the study of this large but often marginalized community, we present a fully anonymized data release (via differential privacy) of the metadata from a large fanfiction site (to protect author privacy, story, profile, and review text is excluded, and only metadata is provided). We use visual analytics techniques to draw several intriguing insights from the data and show the potential for future research. We hope other researchers can use this data to explore further questions related to online fanfiction communities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6106–6110},
numpages = {5},
keywords = {online communities, youth, fanfiction},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025466,
author = {Torres, Cesar and O'Leary, Jasper and Nicholas, Molly and Paulos, Eric},
title = {Illumination Aesthetics: Light as a Creative Material within Computational Design},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025466},
doi = {10.1145/3025453.3025466},
abstract = {Recent digital fabrication tools have enabled new form-giving using a wide range of physical materials. However, light as a first class creative material has been largely ignored within the design of our electronic objects. Our work expands the illumination design space by treating light as a physical material. We introduce a digital design tool that simulates and visualizes physical light interactions with a variety of materials for creating custom luminaires. We further develop a computational design and fabrication process for creating custom secondary optics elements (SOEs), which provides additional handles for users to physically shape and redirect light to compose, fill, and evenly diffuse planar and volumetric geometries. Through a workshop study with novice electronic designers, we show how incorporating physical techniques to shape light alters how users view the role and function of LEDs and electronics. We produce example pieces that showcase how our approach expands the electronics aesthetic and discuss how viewing light as material can engender novel, expressive artifacts.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6111–6122},
numpages = {12},
keywords = {displays, lighting, digital fabrication, new media, lamp, luminaire},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026019,
author = {Wang, Wen and Yao, Lining and Zhang, Teng and Cheng, Chin-Yi and Levine, Daniel and Ishii, Hiroshi},
title = {Transformative Appetite: Shape-Changing Food Transforms from 2D to 3D by Water Interaction through Cooking},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026019},
doi = {10.1145/3025453.3026019},
abstract = {We developed a concept of transformative appetite, where edible 2D films made of common food materials (protein, cellulose or starch) can transform into 3D food during cooking. This transformation process is triggered by water adsorption, and it is strongly compatible with the 'flat packaging' concept for substantially reducing shipping costs and storage space. To develop these transformable foods, we performed material-based design, established a hybrid fabrication strategy, and conducted performance simulation. Users can customize food shape transformations through a pre-defined simulation platform, and then fabricate these designed patterns using additive manufacturing. Three application techniques are provided - 2D-to-3D folding, hydration-induced wrapping, and temperature-induced self-fragmentation, to present the shape, texture, and interaction with food materials. Based on this concept, several dishes were created in the kitchen, to demonstrate the futuristic dining experience through materials-based interaction design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6123–6132},
numpages = {10},
keywords = {dish design, interactive edibles, 2d-to-3d, anisotropic swelling, water interaction, transformable food, autonomous shape-changing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025953,
author = {Hassib, Mariam and Pfeiffer, Max and Schneegass, Stefan and Rohs, Michael and Alt, Florian},
title = {Emotion Actuator: Embodied Emotional Feedback through Electroencephalography and Electrical Muscle Stimulation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025953},
doi = {10.1145/3025453.3025953},
abstract = {The human body reveals emotional and bodily states through measurable signals, such as body language and electroencephalography. However, such manifestations are difficult to communicate to others remotely. We propose EmotionActuator, a proof-of-concept system to investigate the transmission of emotional states in which the recipient performs emotional gestures to understand and interpret the state of the sender.We call this kind of communication embodied emotional feedback, and present a prototype implementation. To realize our concept we chose four emotional states: amused, sad, angry, and neutral. We designed EmotionActuator through a series of studies to assess emotional classification via EEG, and create an EMS gesture set by comparing composed gestures from the literature to sign-language gestures. Through a final study with the end-to-end prototype interviews revealed that participants like implicit sharing of emotions and find the embodied output to be immersive, but want to have control over shared emotions and with whom. This work contributes a proof of concept system and set of design recommendations for designing embodied emotional feedback systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6133–6146},
numpages = {14},
keywords = {affect display, emotion, affective computing, ems, emotion sharing, eeg.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025493,
author = {Boyd, LouAnne E. and Rector, Kyle and Profita, Halley and Stangl, Abigale J. and Zolyomi, Annuska and Kane, Shaun K. and Hayes, Gillian R.},
title = {Understanding the Role Fluidity of Stakeholders During Assistive Technology Research "In the Wild"},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025493},
doi = {10.1145/3025453.3025493},
abstract = {Deploying novel technologies requires the coordinated efforts of the research team, research participants, and a variety of community members and project stakeholders. To ensure that the project is completed successfully, these disparate groups of people engage in articulation work, which is the meta-work that supports the use of collaborative systems. In this paper, we examine the articulation work surrounding the deployment of systems that have found limited long-term adoption: assistive technology. Specifically, we examine three research deployments of a collaborative game for children with autism. Analysis of the articulation work performed during these studies demonstrates how research deployments of technologies create conditions in which stakeholders must take on additional roles to make the deployment work. By understanding the articulation work surrounding deployment studies engendered in this role fluidity, we can improve both research design and the analysis of data emergent from these studies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6147–6158},
numpages = {12},
keywords = {articulation work, autism, assistive technology, deployment, collaboration, role fluidity},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025616,
author = {Molapo, Maletsabisa and Densmore, Melissa and DeRenzi, Brian},
title = {Video Consumption Patterns for First Time Smartphone Users: Community Health Workers in Lesotho},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025616},
doi = {10.1145/3025453.3025616},
abstract = {There is already strong evidence that mobile videos are a good vehicle for public health information dissemination, but there remain open questions around sustainability, appropriate target users, consumption patterns, content, and usage models. We analyse log and interview data of 42 community health workers (who were first time smartphone users) from a longitudinal 17-month deployment to better understand how the utility of mobile videos played out over time in rural Lesotho. During the study period, videos were viewed at an average of 170 times per month, for a total of 2898 views. Through this data we draw these primary findings: a) pausing is not contextually necessary, b) age is not a barrier to usage, c) the primary predictor of popularity of a given video is topical relevance and national campaigns, d) there is no apparent relationship between video length, popularity and completion rates, and e) new videos have only a short-lived novelty effect. Furthermore, we affirm that regular engagement with CHWs has an impact on continued usage, in addition to being important for reducing attrition due to technical issues.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6159–6170},
numpages = {12},
keywords = {community health workers, lesotho, consumption patterns, understanding users., mobile health video},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025881,
author = {Simpson, Emma and Comber, Rob and Garbett, Andrew and Jenkins, Ed Ian and Balaam, Madeline},
title = {Experiences of Delivering a Public Health Data Service},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025881},
doi = {10.1145/3025453.3025881},
abstract = {The turn to in-the-wild within HCI has given rise to an increasing concern around designing technologies which are available at large scale. Uniquely, at the intersection of public health and HCI, our work has supported the deployment of a mobile application, FeedFinder, over the last three years. We delineate the ground-work that was required to sustain this mobile application over the long-term. Focussing in particular on efforts made to engage institutions in taking ownership over FeedFinder and the data it provides, we reflect on the tensions that arose between users and civic institutions, particularly around "what matters". We provide a reflection on key requirements when designing a health data service and provide three lessons learnt which can guide researchers toward their own successful and productive long-term research deployments.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6171–6183},
numpages = {13},
keywords = {user-centred design, public health, citizen-led data, breastfeeding},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026045,
author = {Parry-Hill, Jeremiah and Shih, Patrick C. and Mankoff, Jennifer and Ashbrook, Daniel},
title = {Understanding Volunteer AT Fabricators: Opportunities and Challenges in DIY-AT for Others in e-NABLE},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026045},
doi = {10.1145/3025453.3026045},
abstract = {We present the results of a study of e-NABLE, a distributed, collaborative volunteer effort to design and fabricate upper-limb assistive technology devices for limb-different users. Informed by interviews with 14 stakeholders in e-NABLE, including volunteers and clinicians, we discuss differences and synergies among each group with respect to motivations, skills, and perceptions of risks inherent in the project. We found that both groups are motivated to be involved in e-NABLE by the ability to use their skills to help others, and that their skill sets are complementary, but that their different perceptions of risk may result in uneven outcomes or missed expectations for end users. We offer four opportunities for design and technology to enhance the stakeholders' abilities to work together.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6184–6194},
numpages = {11},
keywords = {accessibility, prosthetics, limb difference, assistive technology, 3d printing, diy, making, digital fabrication},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025776,
author = {Foong, Pin Sym and Zhao, Shengdong and Carlson, Kelsey and Liu, Zhe},
title = {VITA: Towards Supporting Volunteer Interactions with Long-Term Care Residents with Dementia},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025776},
doi = {10.1145/3025453.3025776},
abstract = {Volunteers are an important resource at long-term care homes because they can supply services, such as engagement activities, that over-burdened care staff struggle to provide. However, volunteers without sufficient training are often challenged in responding to dementia-linked behaviors, which can lead to frustrating difficulties during interaction. Additionally, short-staffed care homes have difficulties in training and maintaining volunteers. To better support volunteers in providing engagement activities for people with dementia without a high training burden, we created VITA, a tablet-based system that supplies carefully designed profiling and guidance using our dementia-appropriate engagement activity kit. Our evaluation indicated that the instructional guide supplied by VITA significantly improves volunteers' ability to facilitate engagement activities with people with dementia, approaching the level of engagement achievable by professional therapists.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6195–6207},
numpages = {13},
keywords = {engagement activity, nursing homes, dementia, volunteers, tablets, dementia care.},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025597,
author = {Mikami, Hiroaki and Sakamoto, Daisuke and Igarashi, Takeo},
title = {Micro-Versioning Tool to Support Experimentation in Exploratory Programming},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025597},
doi = {10.1145/3025453.3025597},
abstract = {Experimentation plays an essential role in exploratory programming, and programmers apply version control operations when switching the part of the source code back to the past state during experimentation. However, these operations, which we refer to as micro-versioning, are not well supported in current programming environments. We first examined previous studies to clarify the requirements for a micro-versioning tool. We then developed a micro-versioning tool that displays visual cues representing possible micro-versioning operations in a textual code editor. Our tool includes a history model that generates meaningful candidates by combining a regional undo model and tree-structured undo model. The history model uses code executions as a delimiter to segment text edit operations into meaning groups. A user study involving programmers indicated that our tool satisfies the above-mentioned requirements and that it is useful for exploratory programming.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6208–6219},
numpages = {12},
keywords = {develpment environment, micro-versioning, version control system},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025972,
author = {Chen, Yan and Lee, Sang Won and Xie, Yin and Yang, YiWei and Lasecki, Walter S. and Oney, Steve},
title = {Codeon: On-Demand Software Development Assistance},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025972},
doi = {10.1145/3025453.3025972},
abstract = {Software developers rely on support from a variety of resources---including other developers---but the coordination cost of finding another developer with relevant experience, explaining the context of the problem, composing a specific help request, and providing access to relevant code is prohibitively high for all but the largest of tasks. Existing technologies for synchronous communication (e.g. voice chat) have high scheduling costs, and asynchronous communication tools (e.g. forums) require developers to carefully describe their code context to yield useful responses. This paper introduces Codeon, a system that enables more effective task hand-off between end-user developers and remote helpers by allowing asynchronous responses to on-demand requests. With Codeon, developers can request help by speaking their requests aloud within the context of their IDE. Codeon automatically captures the relevant code context and allows remote helpers to respond with high-level descriptions, code annotations, code snippets, and natural language explanations. Developers can then immediately view and integrate these responses into their code. In this paper, we describe Codeon, the studies that guided its design, and our evaluation that its effectiveness as a support tool. In our evaluation, developers using Codeon completed nearly twice as many tasks as those who used state-of-the-art synchronous video and code sharing tools, by reducing the coordination costs of seeking assistance from other developers.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6220–6231},
numpages = {12},
keywords = {crowdsourcing, intelligent assistants, development support},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025818,
author = {Ragavan, Sruti Srinivasa and Pandya, Bhargav and Piorkowski, David and Hill, Charles and Kuttal, Sandeep Kaur and Sarma, Anita and Burnett, Margaret},
title = {PFIS-V: Modeling Foraging Behavior in the Presence of Variants},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025818},
doi = {10.1145/3025453.3025818},
abstract = {Foraging among similar variants of the same artifact is a common activity, but computational models of Information Foraging Theory (IFT) have not been developed to take such variants into account. Without being able to computationally predict people's foraging behavior with variants, our ability to harness the theory in practical ways--such as building and systematically assessing tools for people who forage different variants of an artifact--is limited. Therefore, in this paper, we introduce a new predictive model, PFIS-V, that builds upon PFIS3, the most recent of the PFIS family of modeling IFT in programming situations. Our empirical results show that PFIS-V is up to 25% more accurate than PFIS3 in predicting where a forager will navigate in a variationed information space.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6232–6244},
numpages = {13},
keywords = {information foraging theory, variants},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025573,
author = {D'Angelo, Sarah and Begel, Andrew},
title = {Improving Communication Between Pair Programmers Using Shared Gaze Awareness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025573},
doi = {10.1145/3025453.3025573},
abstract = {Remote collaboration can be more difficult than collocated collaboration for a number of reasons, including the inability to easily determine what your collaborator is looking at. This impedes a pair's ability to efficiently communicate about on-screen locations and makes synchronous coordination difficult. We designed a novel gaze visualization for remote pair programmers which shows where in the code their partner is currently looking, and changes color when they are looking at the same thing. Our design is unobtrusive, and transparently depicts the imprecision inherent in eye tracking technology. We evaluated our design with an experiment in which pair programmers worked remotely on code refactoring tasks. Our results show that with the visualization, pairs spent a greater proportion of their time concurrently looking at the same code locations. Pairs communicated using a larger ratio of implicit to explicit references, and were faster and more successful at responding to those references.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6245–6290},
numpages = {46},
keywords = {collaboration, eye-tracking, pair programming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025740,
author = {Baumer, Eric P. S. and Brubaker, Jed R.},
title = {Post-Userism},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025740},
doi = {10.1145/3025453.3025740},
abstract = {HCI is focused on improving the interactions we have with technology and innovating new types of interactions, as well as expanding the types of people for whom those interactions are designed. Central to these efforts is the simultaneously empowering and contested construct of the "user." This paper examines what the construct of the user highlights, as well as what it conceals. We introduce post-userism, a perspective that simultaneously acknowledges the limits of, and proposes alternatives to, the central construct of the user as proxy for the "human" in HCI. Drawing on developments across the historical trajectory of HCI, we articulate how the user is enacted across four different levels of representation-systems, interface, design process, and the ideology and identify situations where the user breaks down. Synthesizing prior work, we offer a series of strategies for grappling with such situations. In doing so, we seek to overcome the limitations imposed by the user and develop a language that will aid in evolving the foundations of HCI by asking what, exactly, we place at the center of our scholarship and design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6291–6303},
numpages = {13},
keywords = {interaction design, post-userism, post-user, use, hci, theory},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026034,
author = {Asad, Mariam and Le Dantec, Christopher A.},
title = {Tap the "Make This Public" Button: A Design-Based Inquiry into Issue Advocacy and Digital Civics},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026034},
doi = {10.1145/3025453.3026034},
abstract = {This paper examines the strategies of cycling advocates when deploying digital tools in their advocacy work as they support and create better cycling infrastructure and policies. Over the course of two years, we interviewed and conducted design-based fieldwork in two large U.S. cities with individuals and advocacy organizations, learning about the goals, motivations, and constraints that inform their work in their respective urban homes. Our design-based investigation and fieldwork advance a deeper, situated understanding of the role that computing technology plays when engaging across multiple sites of advocacy work. From this, we add detail to the connections across resources, identities, and issues and continue to advance the emerging area of digital civics, which seeks to design tools that support relational civic interactions across multiple categories of civic actors.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6304–6316},
numpages = {13},
keywords = {publics, digital advocacy, community computing, civic engagement, digital civics, cycling., participatory design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025606,
author = {Green, David Philip and Bowen, Simon and Hook, Jonathan and Wright, Peter},
title = {Enabling Polyvocality in Interactive Documentaries through "Structural Participation"},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025606},
doi = {10.1145/3025453.3025606},
abstract = {Recent innovations in online, social and interactive media have led to the emergence of new forms of documentary, such as interactive documentaries ('i-Docs'), with qualities that lend themselves to more open and inclusive production structures. Still, little is known about the experience of making and/or participating-in these kinds of documentary. Our two-year in-the-wild study engaged a large community-of-interest in the production of an i-Doc to explore the ethically-desirable yet challenging aim of enabling multiple subjects to have agency and control over their representation in a documentary. Our study reveals insights into the experiences of participating in an i-Doc and highlights key sociotechnical challenges. We argue that new sociotechnical infrastructure is needed, that frames both "executory" and "structural" forms of participation as symbiotic elements of a co-design process.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6317–6329},
numpages = {13},
keywords = {authorship, narrative, interactivity, documentary, i-docs, co-design, participation, grassroots},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025927,
author = {Jacobs, Jennifer and Gogia, Sumit and Mundefinedch, Radom\'{\i}r and Brandt, Joel R.},
title = {Supporting Expressive Procedural Art Creation through Direct Manipulation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025927},
doi = {10.1145/3025453.3025927},
abstract = {Computation is a powerful artistic medium. Artists with experience in programming have demonstrated the unique creative opportunities of using code to make art. Currently, manual artists interested in using procedural techniques must undergo the difficult process of learning to program, and must adopt tools and practices far removed from those to which they are accustomed. We hypothesize that, through the right direct manipulation interface, we can enable accessible and expressive procedural art creation. To explore this, we developed Para, a digital illustration tool that supports the creation of declarative constraints in vector artwork. Para's constraints enable procedural relationships while facilitating live manual control and non-linear editing. Constraints can be combined with duplication behaviors and ordered collections of artwork to produce complex, dynamic compositions. We use the results of two open-ended studies with professional artists and designers to provide guidelines for accessible tools that integrate manual and procedural expression.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6330–6341},
numpages = {12},
keywords = {generative art, programming, procedural art},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025992,
author = {Ren, Ruqin and Yan, Bei},
title = {Crowd Diversity and Performance in Wikipedia: The Mediating Effects of Task Conflict and Communication},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025992},
doi = {10.1145/3025453.3025992},
abstract = {Crowd diversity is a key attribute that impacts crowd performance in online collaboration systems. As a structural composition of a crowd, diversity is likely to influence crowd performance through communication processes during collaboration. This study examined how diversity influenced crowd performance under different conditions of task conflict and communication in Wikipedia article production. With a sample of 5,899 articles, we found that contribution diversity positively predicted crowd performance, whereas experience diversity was negatively related to performance. In addition, task communication and conflict partially mediated the relationship between crowd diversity and performance. Task communication positively predicted performance for both forms of diversity. Task conflict, on the other hand, was positively predicted by expertise diversity, but had negative associations with contribution diversity and performance. The findings help unpack the reasons for differential effects of diversity on crowd performance, and demonstrate the importance of including communication variables when studying online crowd collaboration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6342–6351},
numpages = {10},
keywords = {wikipedia, communication, crowd performance, conflict, diversity},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025940,
author = {Hall, Andrew and McRoberts, Sarah and Thebault-Spieker, Jacob and Lin, Yilun and Sen, Shilad and Hecht, Brent and Terveen, Loren},
title = {Freedom versus Standardization: Structured Data Generation in a Peer Production Community},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025940},
doi = {10.1145/3025453.3025940},
abstract = {In addition to encyclopedia articles and software, peer production communities produce structured data, e.g., Wikidata and OpenStreetMap's metadata. Structured data from peer production communities has become increasingly important due to its use by computational applications, such as CartoCSS, MapBox, and Wikipedia infoboxes. However, this structured data is usable by applications only if it follows standards. We did an interview study focused on OpenStreetMap's knowledge production processes to investigate how -- and how successfully -- this community creates and applies its data standards. Our study revealed a fundamental tension between the need to produce structured data in a standardized way and OpenStreetMap's tradition of contributor freedom. We extracted six themes that manifested this tension and three overarching concepts, correctness, community, and code, which help make sense of and synthesize the themes. We also offered suggestions for improving OpenStreetMap's knowledge production processes, including new data models, sociotechnical tools, and community practices (e.g. stronger leadership).},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6352–6362},
numpages = {11},
keywords = {peer-production communities, openstreetmap, structured data, standardization},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026008,
author = {Yang, Diyi and Kraut, Robert and Levine, John M.},
title = {Commitment of Newcomers and Old-Timers to Online Health Support Communities},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026008},
doi = {10.1145/3025453.3026008},
abstract = {For online communities to be successful, they must retain an adequate number of members who contribute to the community. The amount and type of communication members receive can play an important role in generating and sustaining members' commitment to it. However, the communication that members find valuable may change with their tenure in the community. This paper examines how the communication members receive in an health support community influences their commitment and how this influence changes with their tenure in the community. Commitment was operationalized with three measures: self-reported attachment, continued participation in the community, and responding to others. Results show that receiving communication was generally associated with increased commitment across the three measures, with its impact increasing with members' tenure. However, the average amount of informational and emotional support members received per message was associated with decreased commitment. Results have implications for interventions to encourage members' commitment to their communities throughout their history in the community.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6363–6375},
numpages = {13},
keywords = {social support, onlinehealth support communities, group socialization, communication, commitment},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025639,
author = {Foote, Jeremy and Gergle, Darren and Shaw, Aaron},
title = {Starting Online Communities: Motivations and Goals of Wiki Founders},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025639},
doi = {10.1145/3025453.3025639},
abstract = {Why do people start new online communities? Previous research has studied what helps communities to grow and what motivates contributors, but the reasons that people create new communities in the first place remain unclear. We present the results of a survey of over 300 founders of new communities on the online wiki hosting site Wikia.com. We analyze the motivations and goals of wiki creators, finding that founders have diverse reasons for starting wikis and diverse ways of defining their success. Many founders see their communities as occupying narrow topics, and neither seek nor expect a large group of contributors. We also find that founders with differing goals approach community building differently. We argue that community platform designers can create interfaces that support the diverse goals of founders more effectively.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6376–6380},
numpages = {5},
keywords = {wikis, peer production, motivation, survey, online communities},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026057,
author = {Balestra, Martina and Cheshire, Coye and Arazy, Ofer and Nov, Oded},
title = {Investigating the Motivational Paths of Peer Production Newcomers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026057},
doi = {10.1145/3025453.3026057},
abstract = {Maintaining participation beyond the initial period of engagement is critical for peer production systems. Theory suggests that an increase in motivation is expected with contributors' movement from the community periphery to the core. Less is known, however, about how specific motivations change over time. We fill this gap by focusing on individual motivational paths in the formative periods of engagement, exploring which motivations change and how. We collected data on various instrumental and non-instrumental motivations at two points in study participants? Wikipedia career: when they started editing and again after six months. We found that non-instrumental motivations (including collective and intrinsic motives) decreased significantly over time, in contrast with socially-driven motivations such as norm-oriented motivates which did not change and social motives which increased marginally. The findings offer new insights into newcomers' evolving motivations, with implications for designing and managing peer-production systems.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6381–6385},
numpages = {5},
keywords = {peer production, motivation, wikipedia, newcomers},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025618,
author = {Nassir, Soud and Leong, Tuck Wah},
title = {Traversing Boundaries: Understanding the Experiences of Ageing Saudis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025618},
doi = {10.1145/3025453.3025618},
abstract = {This is a methods paper that draws from our fieldwork conducted in Saudi Arabia to understand ageing people's experiences. This paper focuses on insights gained when using qualitative methods to understand the experiences of ageing Saudis. The aim is to highlight some of the cultural considerations, opportunities, challenges, and issues that influenced our approach and deployment of interviews and probes. Influences of social-cultural practices and religion led to interesting challenges for recruitment, conducting cross-gender communications, and how participants reported their experiences. This paper offers methodological considerations that include the influences of local culture, gender, religion, etc. We also discuss how we shaped our fieldwork tools based upon considerations of local cultural and religious contexts. In particular, we highlight the usefulness of probes in traversing cultural boundaries.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6386–6397},
numpages = {12},
keywords = {saudi arabia, social media, gender, hci, interviews, ageing, methods, cultural considerations, privacy, probes},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025913,
author = {Durrant, Abigail and Kirk, David and Trujillo Pisanty, Diego and Moncur, Wendy and Orzech, Kathryn and Schofield, Tom and Elsden, Chris and Chatting, David and Monk, Andrew},
title = {Transitions in Digital Personhood: Online Activity in Early Retirement},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025913},
doi = {10.1145/3025453.3025913},
abstract = {We present findings from a qualitative study about how Internet use supports self-functioning following the life transition of retirement from work. This study recruited six recent retirees and included the deployment of OnLines, a design research artifact that logged and visualized key online services used by participants at home over four-weeks. The deployment was supported by pre- and post-deployment interviews. OnLines prompted participants' reflection on their patterns of Internet use. Position Exchange Theory was used to understand retirees' sense making from a lifespan perspective, informing the design of supportive online services. This paper delivers a three-fold contribution to the field of human-computer interaction, advancing a lifespan-oriented approach by conceptualizing the self as a dialogical phenomenon that develops over time, advancing the ageing discourse by reporting on retirees' complex identities in the context of their life histories, and advancing discourse on research through design by developing OnLines to foster participant-researcher reflection informed by Self Psychology.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6398–6411},
numpages = {14},
keywords = {position exchange theory, lifespan-oriented research, retirement, research through design, personhood, ageing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025831,
author = {Oliveira, Daniela and Rocha, Harold and Yang, Huizi and Ellis, Donovan and Dommaraju, Sandeep and Muradoglu, Melis and Weir, Devon and Soliman, Adam and Lin, Tian and Ebner, Natalie},
title = {Dissecting Spear Phishing Emails for Older vs Young Adults: On the Interplay of Weapons of Influence and Life Domains in Predicting Susceptibility to Phishing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025831},
doi = {10.1145/3025453.3025831},
abstract = {Spear phishing emails are key in many cyber attacks. Successful emails employ psychological weapons of influence and relevant life domains. This paper investigates spear phishing susceptibility as a function of Internet user age (old vs young), weapon of influence, and life domain. A 21-day study was conducted with 158 participants (younger and older Internet users). Data collection took place at the participants' homes to increase ecological validity. Our results show that older women were the most vulnerable group to phishing attacks. While younger adults were most susceptible to scarcity, older adults were most susceptible to reciprocation. Further, there was a discrepancy, particularly among older users, between self-reported susceptibility awareness and their behavior during the intervention. Our results show the need for demographic personalization for warnings, training and educational tools in targeting the specifics of the older adult population.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6412–6424},
numpages = {13},
keywords = {spear phishing, principles of influence, susceptibility, aging},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025861,
author = {McNeill, Andrew R. and Coventry, Lynne and Pywell, Jake and Briggs, Pam},
title = {Privacy Considerations When Designing Social Network Systems to Support Successful Ageing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025861},
doi = {10.1145/3025453.3025861},
abstract = {A number of interventions exist to support older adults in ageing well and these typically involve support for an active and sociable ageing process. We set out to examine the privacy implications of an intervention that would monitor mobility and share lifestyle and health data with a community of trusted others. We took a privacy-by-design approach to the system in the early stages of its development, working with older adults to firstly understand their networks of trust and secondly understand their privacy concerns should information be exchanged across that network. We used a Johari Windows framework in the thematic analysis of our data, concluding that the social sharing of information in later life carried significant risk. Our participants worried about the social signaling associated with data sharing and were cautious about a system that had the potential to disrupt established networks.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6425–6437},
numpages = {13},
keywords = {older adults, privacy, social networks, health, trust},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025962,
author = {Kasahara, Shunichi and Konno, Keina and Owaki, Richi and Nishi, Tsubasa and Takeshita, Akiko and Ito, Takayuki and Kasuga, Shoko and Ushiba, Junichi},
title = {Malleable Embodiment: Changing Sense of Embodiment by Spatial-Temporal Deformation of Virtual Human Body},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025962},
doi = {10.1145/3025453.3025962},
abstract = {We hypothesize that replacing the visual perception of one's body with a spatial-temporal deformed state would change sensations associated with the body. We developed a system that captures full-body movement and generates estimated past and future body movement by deformation. With a head mounted display, people could see their bodies as slightly deformed. We then investigated 1) how human movement is physically changed, and 2) how humans feel about the change in physical and emotional views of the body due to virtual body deformation. Our results show that spatial-temporal deformation of a virtual body actually changes the sense of body as well as physical movement. For instance, a body image generated at approximately 25-100 ms in the future induced a "lighter weight" sensation. On the basis of our findings, we discuss the design implication of computational control for the physical and emotional sense of body.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6438–6448},
numpages = {11},
keywords = {"embodiment", "motion", "body ownership", "perception", "virtual reality"},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025756,
author = {Krogh, Peter Gall and Petersen, Marianne Graves and O'Hara, Kenton and Groenbaek, Jens Emil},
title = {Sensitizing Concepts for Socio-Spatial Literacy in HCI},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025756},
doi = {10.1145/3025453.3025756},
abstract = {People inherently share spaces with other people. Congenitally, interactive technologies and ubiquitous environments shape our opportunities for enacting social relations. Proxemics and Spatial Sharing have been suggested as foundations for our understanding of the socio-spatial aspects of computing. By tandeming these theoretical perspectives in a set of cases in the office domain, we develop a contribution comprised of 3 key sensitizing concepts: Proxemic Malleability, Proxemic Threshold and Proxemic Gravity articulating socio-spatial qualities at the interplay between interactive systems, spaces, interior elements and co-located people. The sensitizing concepts qualify interaction designers in considering proxemic consequences of technology design; they serve both as analytic lenses and as generative instruments in a design process. The proposed sensitizing concepts and the theoretical work of the paper contribute to enhanced Socio-spatial literacy in HCI.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6449–6460},
numpages = {12},
keywords = {ubiquitous computing, socio-spatial, spatiality, literacy, space, proxemics, architecture., interaction design},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025936,
author = {Taylor, Jennyfer Lawrence and Soro, Alessandro and Roe, Paul and Lee Hong, Anita and Brereton, Margot},
title = {Situational When: Designing for Time Across Cultures},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025936},
doi = {10.1145/3025453.3025936},
abstract = {We propose the concept of "Situational When", an approach to understanding time in interface design not as a point on a calendar or clock, but as a set of converging circumstances that constitute "the time" for happenings to take place. Time is encoded both explicitly and implicitly in designed products. However, many technologies propagate business-centric, modernist values such as scheduling and efficiency, and marginalize broader socio-cultural aspects on which many activities are nonetheless contingent, e.g. the right people, the right weather conditions, and the right vibe. We derive our reflections from a case study of a cross-cultural digital noticeboard designed with an Australian Aboriginal community. Attention to the situational when opens up new possibilities for design that put greater emphasis on the social and relational aspects of time, the situational insights embodied in local narratives, and the tangible (e.g. people) and intangible (e.g. energy) circumstances that together make up the "right" time.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6461–6474},
numpages = {14},
keywords = {temporality, calendar, storytelling, breaching experiments, noticeboard, aboriginal, cross-cultural, time},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025916,
author = {Grusky, Max and Jahani, Jeiran and Schwartz, Josh and Valente, Dan and Artzi, Yoav and Naaman, Mor},
title = {Modeling Sub-Document Attention Using Viewport Time},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025916},
doi = {10.1145/3025453.3025916},
abstract = {Website measures of engagement captured from millions of users, such as in-page scrolling and viewport position, can provide deeper understanding of attention than possible with simpler measures, such as dwell time. Using data from 1.2M news reading sessions, we examine and evaluate three increasingly sophisticated models of sub-document attention computed from viewport time, the time a page component is visible on the user display. Our modeling incorporates prior eye-tracking knowledge about onscreen reading, and we validate it by showing how, when used to estimate user reading rate, it aligns with known empirical measures. We then show how our models reveal an interaction between article topic and attention to page elements. Our approach supports refined large-scale measurement of user engagement at a level previously available only from lab-based eye-tracking studies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6475–6480},
numpages = {6},
keywords = {attention, user modeling, web analytics, news articles, reading},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025717,
author = {M\"{u}ller, Jens and R\"{a}dle, Roman and Reiterer, Harald},
title = {Remote Collaboration With Mixed Reality Displays: How Shared Virtual Landmarks Facilitate Spatial Referencing},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025717},
doi = {10.1145/3025453.3025717},
abstract = {HCI research has demonstrated Mixed Reality (MR) as being beneficial for co-located collaborative work. For remote collaboration, however, the collaborators' visual contexts do not coincide due to their individual physical environments. The problem becomes apparent when collaborators refer to physical landmarks in their individual environments to guide each other's attention. In an experimental study with 16 dyads, we investigated how the provisioning of shared virtual landmarks (SVLs) influences communication behavior and user experience. A quantitative analysis revealed that participants used significantly less ambiguous spatial expressions and reported an improved user experience when SVLs were provided. Based on these findings and a qualitative video analysis we provide implications for the design of MRs to facilitate remote collaboration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6481–6486},
numpages = {6},
keywords = {virtual landmarks, remote collaboration, mixed reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025959,
author = {Jabbar, Karim and Bj\o{}rn, Pernille},
title = {Growing the Blockchain Information Infrastructure},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025959},
doi = {10.1145/3025453.3025959},
abstract = {In this paper, we present ethnographic data that unpacks the everyday work of some of the many infrastructuring agents who contribute to creating, sustaining and growing the Blockchain information infrastructure. We argue that this infrastructuring work takes the form of entrepreneurial actions, which are self-initiated and primarily directed at sustaining or increasing the initiator's stake in the emerging information infrastructure. These entrepreneurial actions wrestle against the affordances of the installed base of the Blockchain infrastructure, and take the shape of engaging or circumventing activities. These activities purposefully aim at either influencing or working around the enablers and constraints afforded by the Blockchain information infrastructure, as its installed base is gaining inertia. This study contributes to our understanding of the purpose of infrastructuring, seen from the perspective of heterogeneous entrepreneurial agents. It supplements existing accounts of the "when" and "how" of infrastructure, with a lens for examining the "why" of infrastructure.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6487–6498},
numpages = {12},
keywords = {bitcoin, open-source, blockchain, information infrastructures, sociomateriality, entrepreneurship},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025886,
author = {Sas, Corina and Khairuddin, Irni Eliana},
title = {Design for Trust: An Exploration of the Challenges and Opportunities of Bitcoin Users},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025886},
doi = {10.1145/3025453.3025886},
abstract = {Bitcoin is a cryptocurrency which has received increasing interest over the last five years. Built upon a decentralized peer to peer system, it supports transparent, fast, cost effective, and irreversible transactions, without the need for trusting third party financial institutions. We know however little about people's motivation and experience with bitcoin currency. This paper reports on interviews with 20 bitcoin users in Malaysia about their experience and trust challenges. Findings show that bitcoins are used more as store of value for speculative investment or savings' protection. The paper advances the HCI theories on trust by identifying main bitcoin characteristics and their impact on trust, such as decentralization, unregulation, embedded expertise, and reputation, as well as transactions' transparency, low cost, and easiness to complete. We discuss insecure transactions, the risk of dishonest traders and its mitigating strategies. The paper concludes with design implications including support for the transparency of two-way transactions, tools for materializing trust, and tools for supporting reversible transactions.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6499–6510},
numpages = {12},
keywords = {risks, dishonest traders, blockchain, bitcoin users, trust},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025889,
author = {Jack, Margaret and Chen, Jay and Jackson, Steven J.},
title = {Infrastructure as Creative Action: Online Buying, Selling, and Delivery in Phnom Penh},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025889},
doi = {10.1145/3025453.3025889},
abstract = {This paper describes a complex global sales and logistics network based in Phnom Penh, Cambodia, which utilizes Internet tools (particularly Facebook) as well as a suite of offline tools such as feature phones, paper receipts, and motorcycles to facilitate the buying and selling of clothes and other commodities. Against the gap or import models that sometimes limit HCI understandings of computational change in non-Western environments, we argue that the consumers, business owners, delivery drivers, and call center staff play active and formative roles in producing this infrastructure, integrating new tools into older cultural practices and determining how they work within the limits and conventions of the environment. We argue that resourceful and imaginative activities such as these constitute a form of creative infrastructural action and are central to the ways that new tools circulate in the world, though they often go unrecognized by HCI as innovation.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6511–6522},
numpages = {12},
keywords = {infrastructure, logistics, postcolonial computing, ICTD, ethnography, e-commerce},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025975,
author = {Bardzell, Shaowen and Bardzell, Jeffrey and Ng, Sarah},
title = {Supporting Cultures of Making: Technology, Policy, Visions, and Myths},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025975},
doi = {10.1145/3025453.3025975},
abstract = {Recent HCI research has linked social policy to design, e.g., in issues such as public safety, privacy, and social justice. One area where policy, technology, and design intersect is in the vision of the creative economy. In that vision, creativity, distinct local/regional cultural practices, technology, and entrepreneurship synergistically produce social innovation on a scale sufficient to drive economies. Culture and creative industries (CCI) policy specifies how governments intervene to support such clusters. Maker cultures are seen as central to this vision, but comparatively little is known about how makers produce culture. We offer a critical analysis of several encounters between CCI policy in Taiwan and its maker scene. These encounters reveal misalignments that undercut efforts intended to support making. We propose that supporting any creative culture, including making, entails a serious commitment to understanding its culture, including its cultural contents and their means of production. We further argue that scholarly rigor in cultivating cultural appreciation is just as fundamental as scholarly rigor in empirically representing cultural practices when it comes to pursuing such a cultural understanding.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6523–6535},
numpages = {13},
keywords = {hackerspaces, maker cultures, culture and creative industries, taiwan, making, policy, east asia, creativity support, social innovation, critical computing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025821,
author = {Higuchi, Keita and Yonetani, Ryo and Sato, Yoichi},
title = {EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025821},
doi = {10.1145/3025453.3025821},
abstract = {This work presents EgoScanning, a novel video fast-forwarding interface that helps users to find important events from lengthy first-person videos recorded with wearable cameras continuously. This interface is featured by an elastic timeline that adaptively changes playback speeds and emphasizes egocentric cues specific to first-person videos, such as hand manipulations, moving, and conversations with people, based on computer-vision techniques. The interface also allows users to input which of such cues are relevant to events of their interests. Through our user study, we confirm that users can find events of interests quickly from first-person videos thanks to the following benefits of using the EgoScanning interface: 1) adaptive changes of playback speeds allow users to watch fast-forwarded videos more easily; 2) Emphasized parts of videos can act as candidates of events actually significant to users; 3) Users are able to select relevant egocentric cues depending on events of their interests.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6536–6546},
numpages = {11},
keywords = {first-person videos, content-aware video fast-forwarding},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025688,
author = {Mohr, Peter and Mandl, David and Tatzgern, Markus and Veas, Eduardo and Schmalstieg, Dieter and Kalkofen, Denis},
title = {Retargeting Video Tutorials Showing Tools With Surface Contact to Augmented Reality},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025688},
doi = {10.1145/3025453.3025688},
abstract = {A video tutorial effectively conveys complex motions, but may be hard to follow precisely because of its restriction to a predetermined viewpoint. Augmented reality (AR) tutorials have been demonstrated to be more effective. We bring the advantages of both together by interactively retargeting conventional, two-dimensional videos into three-dimensional AR tutorials. Unlike previous work, we do not simply overlay video, but synthesize 3D-registered motion from the video. Since the information in the resulting AR tutorial is registered to 3D objects, the user can freely change the viewpoint without degrading the experience. This approach applies to many styles of video tutorials. In this work, we concentrate on a class of tutorials which alter the surface of an object.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6547–6558},
numpages = {12},
keywords = {video tutorial, retargeting, augmented reality, virtual reality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025772,
author = {Kurzhals, Kuno and Cetinkaya, Emine and Hu, Yongtao and Wang, Wenping and Weiskopf, Daniel},
title = {Close to the Action: Eye-Tracking Evaluation of Speaker-Following Subtitles},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025772},
doi = {10.1145/3025453.3025772},
abstract = {The incorporation of subtitles in multimedia content plays an important role in communicating spoken content. For example, subtitles in the respective language are often preferred to expensive audio translation of foreign movies. The traditional representation of subtitles displays text centered at the bottom of the screen. This layout can lead to large distances between text and relevant image content, causing eye strain and even that we miss visual content. As a recent alternative, the technique of speaker-following subtitles places subtitle text in speech bubbles close to the current speaker. We conducted a controlled eye-tracking laboratory study (n = 40) to compare the regular approach (center-bottom subtitles) with content-sensitive, speaker-following subtitles. We compared different dialog-heavy video clips with the two layouts. Our results show that speaker-following subtitles lead to higher fixation counts on relevant image regions and reduce saccade length, which is an important factor for eye strain.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6559–6568},
numpages = {10},
keywords = {eye tracking, video, subtitle layout},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025880,
author = {Ilisescu, Corneliu and Kanaci, Halil Aytac and Romagnoli, Matteo and Campbell, Neill D. F. and Brostow, Gabriel J.},
title = {Responsive Action-Based Video Synthesis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025880},
doi = {10.1145/3025453.3025880},
abstract = {We propose technology to enable a new medium of expression, where video elements can be looped, merged, and triggered, interactively. Like audio, video is easy to sample from the real world, but hard to segment into clean reusable elements. Reusing a video clip means non-linear editing, and compositing with novel footage. The new context dictates how carefully a clip must be prepared, so our end-to-end approach enables previewing and easy iteration. We convert static-camera videos into loopable sequences, synthesizing them in response to simple end-user requests. This is hard because a) users want essentially semantic-level control over the synthesized video content, and b) automatic loop-finding is brittle and leaves users limited opportunity to work through problems. We propose a human-in-the-loop system where adding effort gives the user progressively more creative control. Artists help us evaluate how our trigger interfaces can be used for authoring of videos and video-performances.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6569–6580},
numpages = {12},
keywords = {video editing, video textures, cinemagraphs, interactive machine learning, sprites},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025825,
author = {Piya, Cecil and -, Vinayak and Chandrasegaran, Senthil and Elmqvist, Niklas and Ramani, Karthik},
title = {Co-3Deator: A Team-First Collaborative 3D Design Ideation Tool},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025825},
doi = {10.1145/3025453.3025825},
abstract = {We present Co-3Deator, a sketch-based collaborative 3D modeling system based on the notion of "team-first" ideation tools, where the needs and processes of the entire design team come before that of an individual designer. Co-3Deator includes two specific team-first features: a concept component hierarchy which provides a design representation suitable for multi-level sharing and reusing of design information, and a collaborative design explorer for storing, viewing, and accessing hierarchical design data during collaborative design activities. We conduct two controlled user studies, one with individual designers to elicit the form and functionality of the collaborative design explorer, and the other with design teams to evaluate the utility of the concept component hierarchy and design explorer towards collaborative design ideation. Our results support our rationale for both of the proposed team-first collaboration mechanisms and suggest further ways to streamline collaborative design.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6581–6592},
numpages = {12},
keywords = {collaborative design, creative ideation, early-stage design, 3D modeling},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025980,
author = {Khot, Rohit Ashok and Aggarwal, Deepti and Pennings, Ryan and Hjorth, Larissa and Mueller, Florian 'Floyd'},
title = {<i>EdiPulse</i>: Investigating a Playful Approach to Self-Monitoring through 3D Printed Chocolate Treats},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025980},
doi = {10.1145/3025453.3025980},
abstract = {Self-monitoring offers benefits in facilitating awareness about physical exercise, but such data-centric activity may not always lead to an enjoyable experience. We introduce EdiPulse a novel system that creates activity treats to offer playful reflections on everyday physical activity through the appealing medium of chocolate. EdiPulse translates self-monitored data from physical activity into small 3D printed chocolate treats. These treats (&lt; 20 grams of chocolate in total) embody four forms: Graph, Flower, Slogan and Emoji. We deployed our system across 7 households and studied its use with 13 participants for 2 weeks per household. The field study revealed positive aspects of our approach along with some open challenges, which we disseminate across five themes: Reflection, Positivity, Determination, Affection, and Co-experience. We conclude by highlighting key implications of our work for future playful food-based technology design in supporting the experience of being physically active},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6593–6607},
numpages = {15},
keywords = {human food interaction, food printing, quantified self, playful interactions, physical activity, chocolate printing, self-monitoring},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025724,
author = {Paay, Jeni and Raptis, Dimitrios and Kjeldskov, Jesper and Skov, Mikael B. and Ruder, Eric V. and Lauridsen, Bjarke M.},
title = {Investigating Cross-Device Interaction between a Handheld Device and a Large Display},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025724},
doi = {10.1145/3025453.3025724},
abstract = {There is a growing interest in HCI research to explore cross-device interaction, giving rise to an interest in different approaches facilitating interaction between handheld devices and large displays. Contributing to this, we have investigated the use of four existing approaches combining touch and mid-air gestures, pinching, swiping, swinging and flicking. We look specifically at their relative efficiency, effectiveness and accuracy in bi-directional interaction between a smartphone and large display in a point-click context. We report findings from two user studies, which show that swiping is both most effective, fastest and most accurate, closely followed by swinging. What these two approaches have in common is the ability to keep the pointer steady on the large display, unaffected by concurrent gestures or body movements used to complete the interaction, suggesting that this is an important factor for designing effective cross-device interaction with large displays.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6608–6619},
numpages = {12},
keywords = {handheld devices, touch, cross-device interaction, mid-air gestures, large displays, kinect},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025727,
author = {Otterbacher, Jahna and Bates, Jo and Clough, Paul},
title = {Competent Men and Warm Women: Gender Stereotypes and Backlash in Image Search Results},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025727},
doi = {10.1145/3025453.3025727},
abstract = {There is much concern about algorithms that underlie information services and the view of the world they present. We develop a novel method for examining the content and strength of gender stereotypes in image search, inspired by the trait adjective checklist method. We compare the gender distribution in photos retrieved by Bing for the query "person" and for queries based on 68 character traits (e.g., "intelligent person") in four regional markets. Photos of men are more often retrieved for "person," as compared to women. As predicted, photos of women are more often retrieved for warm traits (e.g., "emotional") whereas agentic traits (e.g., "rational") are represented by photos of men. A backlash effect, where stereotype-incongruent individuals are penalized, is observed. However, backlash is more prevalent for "competent women" than "warm men." Results underline the need to understand how and why biases enter search algorithms and at which stages of the engineering process.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6620–6631},
numpages = {12},
keywords = {image search, gender stereotypes, algorithmic bias, "big two" dimensions of social perception},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025770,
author = {Ambe, Aloha Hufana and Brereton, Margot and Soro, Alessandro and Roe, Paul},
title = {Technology Individuation: The Foibles of Augmented Everyday Objects},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025770},
doi = {10.1145/3025453.3025770},
abstract = {This paper presents the concept of technology individuation and explores its role in design. Individuation expresses how, over time, a technology becomes personal and intimate, unique in purpose, orchestrated in place, and how people eventually come to rely on it to sustain connection with others. We articulate this concept as a critical vantage point for designing augmented everyday objects and the Internet of Things. Individuation foregrounds aspects of habituation, routines and arrangements that through everyday practices reveal unique meaning, reflect self-identity and support agency.The concept is illustrated through three long term case studies of technology in use, involving tangible and embodied interaction with devices that afford communication, monitoring, and awareness in the home setting. The cases are analysed using Hornecker and Buur's Tangible Interaction Framework. We further extend upon this framework to better reveal the role played by personal values, history of use, and arrangements, as they develop over time in the home setting, in shaping tangible and embodied interaction with individuated technologies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6632–6644},
numpages = {13},
keywords = {tangible, communication, framework, embodied, smart, situated., individuation, internet of things, design, objects, connection, things, habituation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025775,
author = {Taylor, Samuel Hardman and Hutson, Jevan Alexander and Alicea, Tyler Richard},
title = {Social Consequences of Grindr Use: Extending the Internet-Enhanced Self-Disclosure Hypothesis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025775},
doi = {10.1145/3025453.3025775},
abstract = {Grindr, a location-based real-time dating application, provides sexual-minority men (SMM) a space through which they can identify, access, and communicate with one another. Although previous research has examined user motivations and public self-disclosure patterns on Grindr, we investigate the effects intimate self-disclosure and sexting via the application's private messaging on internalized homophobia and loneliness. Using the Internet-enhanced self-disclosure hypothesis (ISDH) as a framework, we conducted an online survey of 274 Grindr users. Serial mediation analysis showed support for the ISDH, suggesting that Grindr use was negatively associated with loneliness. Intimate self-disclosure and internalized homophobia mediated the relationship between Grindr use and loneliness, but sexting had no relationship with internalized homophobia or loneliness. We discuss implications for the ISDH, Grindr, self-disclosure, and sexting.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6645–6657},
numpages = {13},
keywords = {sexting, loneliness, internalized homophobia, grindr, self-disclosure},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025609,
author = {Hill, Charles G. and Haag, Maren and Oleson, Alannah and Mendez, Chris and Marsden, Nicola and Sarma, Anita and Burnett, Margaret},
title = {Gender-Inclusiveness Personas vs. Stereotyping: Can We Have It Both Ways?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025609},
doi = {10.1145/3025453.3025609},
abstract = {Personas often aim to improve product designers' ability to "see through the eyes of" target users through the empathy personas can inspire - but personas are also known to promote stereotyping. This tension can be particularly problematic when personas (who, of course as "people" have genders) are used to promote gender inclusiveness - because reinforcing stereotypical perceptions can run counter to gender inclusiveness. In this paper we explicitly investigate this tension through a new approach to personas: one that includes multiple photos (of males and females) for a single persona. We compared this approach to an identical persona with only one photo using a controlled laboratory study and an eye-tracking study. Our goal was to answer the following question: is it possible for personas to encourage product designers to engage with personas while at the same avoiding promoting gender stereotyping? Our results are encouraging about the use of personas with multiple pictures as a way to expand participants' consideration of multiple genders without reducing their engagement with the persona.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6658–6671},
numpages = {14},
keywords = {gendermag, personas, lab study, stereotypes, gender},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025540,
author = {Hanafi, Maeda F. and Abouzied, Azza and Chiticariu, Laura and Li, Yunyao},
title = {SEER: Auto-Generating Information Extraction Rules from User-Specified Examples},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025540},
doi = {10.1145/3025453.3025540},
abstract = {Time-consuming and complicated best describe the current state of the Information Extraction (IE) field. Machine learning approaches to IE require large collections of labeled datasets that are difficult to create and use obscure mathematical models, occasionally returning unwanted results that are unexplainable. Rule-based approaches, while resulting in easy-to-understand IE rules, are still time-consuming and labor-intensive. SEER combines the best of these two approaches: a learning model for IE rules based on a small number of user-specified examples. In this paper, we explain the design behind SEER and present a user study comparing our system against a commercially available tool in which users create IE rules manually. Our results show that SEER helps users complete text extraction tasks more quickly, as well as more accurately.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6672–6682},
numpages = {11},
keywords = {data extraction, example-driven learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025571,
author = {Banovic, Nikola and Wang, Anqi and Jin, Yanfeng and Chang, Christie and Ramos, Julian and Dey, Anind and Mankoff, Jennifer},
title = {Leveraging Human Routine Models to Detect and Generate Human Behaviors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025571},
doi = {10.1145/3025453.3025571},
abstract = {An ability to detect behaviors that negatively impact people's wellbeing and show people how they can correct those behaviors could enable technology that improves people's lives. Existing supervised machine learning approaches to detect and generate such behaviors require lengthy and expensive data labeling by domain experts. In this work, we focus on the domain of routine behaviors, where we model routines as a series of frequent actions that people perform in specific situations. We present an approach that bypasses labeling each behavior instance that a person exhibits. Instead, we weakly label instances using people's demonstrated routine. We classify and generate new instances based on the probability that they belong to the routine model. We illustrate our approach on an example system that helps drivers become aware of and understand their aggressive driving behaviors. Our work enables technology that can trigger interventions and help people reflect on their behaviors when those behaviors are likely to negatively impact them.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6683–6694},
numpages = {12},
keywords = {maximum entropy, inverse reinforcement learning},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025872,
author = {Xie, Jun and Winnem\"{o}ller, Holger and Li, Wilmot and Schiller, Stephen},
title = {Interactive Vectorization},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025872},
doi = {10.1145/3025453.3025872},
abstract = {Vectorization turns photographs into vector art. Manual vectorization, where the artist traces over the image by hand, requires skill and time. On the other hand, automatic approaches allow users to generate a result by setting a few global parameters. However, global settings often leave too much detail/complexity in some parts of the image while missing important details in others. We propose interactive vectorization tools that offer more local control than automatic systems, but are more powerful and high-level than simple curve editing. Our system enables novices to vectorize images significantly faster than even experts with state-of-the-art tools.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6695–6705},
numpages = {11},
keywords = {user interaction, image vectorization, image analysis},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025957,
author = {Jung, Daekyoung and Kim, Wonjae and Song, Hyunjoo and Hwang, Jeong-in and Lee, Bongshin and Kim, Bohyoung and Seo, Jinwook},
title = {ChartSense: Interactive Data Extraction from Chart Images},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025957},
doi = {10.1145/3025453.3025957},
abstract = {Charts are commonly used to present data in digital documents such as web pages, research papers, or presentation slides. When the underlying data is not available, it is necessary to extract the data from a chart image to utilize the data for further analysis or improve the chart for more accurate perception. In this paper, we present ChartSense, an interactive chart data extraction system. ChartSense first determines the chart type of a given chart image using a deep learning based classifier, and then extracts underlying data from the chart image using semi-automatic, interactive extraction algorithms optimized for each chart type. To evaluate chart type classification accuracy, we compared ChartSense with ReVision, a system with the state-of-the-art chart type classifier. We found that ChartSense was more accurate than ReVision. In addition, to evaluate data extraction performance, we conducted a user study, comparing ChartSense with WebPlotDigitizer, one of the most effective chart data extraction tools among publicly accessible ones. Our results showed that ChartSense was better than WebPlotDigitizer in terms of task completion time, error rate, and subjective preference.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6706–6717},
numpages = {12},
keywords = {deep learning, mixed-initiative interaction, chart recognition, data extraction, chart classification},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025604,
author = {Avellino, Ignacio and Fleury, C\'{e}dric and Mackay, Wendy E. and Beaudouin-Lafon, Michel},
title = {CamRay: Camera Arrays Support Remote Collaboration on Wall-Sized Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025604},
doi = {10.1145/3025453.3025604},
abstract = {Remote collaboration across wall-sized displays creates a key challenge: how to support audio-video communication among users as they move in front of the display. We present CamRay, a platform that uses camera arrays embedded in wall-sized displays to capture video of users and present it on remote displays according to the users' positions. We investigate two settings: in Follow-Remote, the position of the video window follows the position of the remote user; in Follow-Local, the video window always appears in front of the local user. We report the results of a controlled experiment showing that with Follow-Remote, participants are faster, use more deictic instructions, interpret them more accurately, and use fewer words. However, some participants preferred the virtual face-to-face created by Follow-Local when checking for their partners' understanding. We conclude with design recommendations to support remote collaboration across wall-sized displays.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6718–6729},
numpages = {12},
keywords = {camera array, wall-sized displays, remote collaboration, telepresence},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025594,
author = {Liu, Can and Chapuis, Olivier and Beaudouin-Lafon, Michel and Lecolinet, Eric},
title = {CoReach: Cooperative Gestures for Data Manipulation on Wall-Sized Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025594},
doi = {10.1145/3025453.3025594},
abstract = {Multi-touch wall-sized displays afford collaborative exploration of large datasets and re-organization of digital content. However, standard touch interactions, such as dragging to move content, do not scale well to large surfaces and were not designed to support collaboration, such as passing an object around. This paper introduces CoReach, a set of collaborative gestures that combine input from multiple users in order to manipulate content, facilitate data exchange and support communication. We conducted an observational study to inform the design of CoReach, and a controlled study showing that it reduced physical fatigue and facilitated collaboration when compared with traditional multi-touch gestures. A final study assessed the value of also allowing input through a handheld tablet to manipulate content from a distance.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6730–6741},
numpages = {12},
keywords = {shared interaction, wall display, co-located collaboration},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025584,
author = {Cockburn, Andy and Gutwin, Carl and Palanque, Philippe and Deleris, Yannick and Trask, Catherine and Coveney, Ashley and Yung, Marcus and MacLean, Karon},
title = {Turbulent Touch: Touchscreen Input for Cockpit Flight Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025584},
doi = {10.1145/3025453.3025584},
abstract = {Touchscreen input in commercial aircraft cockpits offers potential advantages, including ease of use, modifiability, and reduced weight. However, tolerance to turbulence is a challenge for their deployment. To better understand the impact of turbulence on cockpit input methods we conducted a comparative study of user performance with three input methods -- touch, trackball (as currently used in commercial aircraft), and a touchscreen stencil overlay designed to assist finger stabilization. These input methods were compared across a variety of interactive tasks and at three levels of simulated turbulence (none, low, and high). Results showed that performance degrades and subjective workload increases as vibration increases. Touch-based interaction was faster than the trackball when precision requirements were low (at all vibrations), but it was slower and less accurate for more precise pointing, particularly at high vibrations. The stencil did not improve touch selection times, although it did reduce errors on small targets at high vibrations, but only when finger lift-off errors had been eliminated by a timeout. Our work provides new information on the types of tasks affected by turbulence and the input mechanisms that perform best under different levels of vibration.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6742–6753},
numpages = {12},
keywords = {aviation, touch interaction, turbulence},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025924,
author = {Dierk, Christine and Vega G\'{a}lvez, Tom\'{a}s and Paulos, Eric},
title = {AlterNail: Ambient, Batteryless, Stateful, Dynamic Displays at Your Fingertips},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025924},
doi = {10.1145/3025453.3025924},
abstract = {Beyond phones, watches, and activity tracking devices, a new ecosystem of functional and fashionable wearable technologies can easily, safely, and economically be designed, prototyped, and integrated directly on the body. In this paper, we present AlterNail, a fingernail form factor, ambient, low-power, stateful, wireless, dynamic display with onboard vibrational sensing. AlterNail integrates a batteryless design using inductive coupling with e-ink technology to enable both quick dynamic and long-term static fingernail based visual designs without the need for power. We also detail the use of simple vibrational signals to uniquely identify everyday objects as they are handled using AlterNails. The intentionally limited interactional functionality of AlterNails, coupled with the rich personal and dynamic expressive potential, combine to present a compelling range of opportunities for designers of new interactive wearable technologies. We detail a range of practical and playful applications using this technology.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6754–6759},
numpages = {6},
keywords = {wearables, fingernails, ambient devices, cosmetic computing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025500,
author = {Wallace, James R. and Weingarten, Ariel and Lank, Edward},
title = {Subtle and Personal Workspace Requirements for Visual Search Tasks on Public Displays},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025500},
doi = {10.1145/3025453.3025500},
abstract = {We explore how users approach and define personal space on large, public displays. Our results show that users of public displays use one of two strategies for visual search tasks: minimizers create a small window and work up close to the display, and maximizers expand content to its full resolution and work at a distance. We show that these interaction styles match predicted 'personal' and 'subtle' interaction zones, characterize typical width and height requirements for these interactions, and show that these requirements are independent of the on-screen content's dimensions. Finally, we suggest practical guidelines for defining workspaces during personal and subtle interaction on large, public displays.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6760–6764},
numpages = {5},
keywords = {large public displays, visual search, personal workspace},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025632,
author = {Chang, Victoria and Chundury, Pramod and Chetty, Marshini},
title = {Spiders in the Sky: User Perceptions of Drones, Privacy, and Security},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025632},
doi = {10.1145/3025453.3025632},
abstract = {Drones are increasingly being used for various purposes from recording footage in inaccessible areas to delivering packages. A rise in drone usage introduces privacy and security concerns about flying boundaries, what data drones collect in public and private spaces, and how that data is stored and disseminated. However, commercial and personal drone regulations focusing on privacy and security have been fairly minimal in the USA. To inform privacy and security guidelines for drone design and regulation, we need to understand users' perceptions about drones, privacy and security. In this paper, we describe a laboratory study with 20 participants who interacted with a real or model drone to elicit user perceptions of privacy and security issues around drones. We present our results, discuss the implications of our work and make recommendations to improve drone design and regulations that enhance individual privacy and security.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6765–6776},
numpages = {12},
keywords = {quadcopter, usable security, drones, users, privacy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025907,
author = {Yao, Yaxing and Xia, Huichuan and Huang, Yun and Wang, Yang},
title = {Privacy Mechanisms for Drones: Perceptions of Drone Controllers and Bystanders},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025907},
doi = {10.1145/3025453.3025907},
abstract = {Drones pose privacy concerns such as surveillance and stalking. Many technology-based or policy-based mechanisms have been proposed to mitigate these concerns. However, it is unclear how drone controllers and bystanders perceive these mechanisms and whether people intend to adopt them. In this paper, we report results from two rounds of online survey with 169 drone controllers and 717 bystanders in the U.S. We identified respondents' perceived pros and cons of eight privacy mechanisms. We found that owner registration and automatic face blurring individually received most support from both controllers and bystanders. Our respondents also suggested using varied combinations of mechanisms under different drone usage scenarios, highlighting their context-dependent preferences. We outline a set of important questions for future privacy designs and public policies of drones.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6777–6788},
numpages = {12},
keywords = {privacy mechanisms, drone, perceptions, UAV, UAS},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026049,
author = {Yao, Yaxing and Xia, Huichuan and Huang, Yun and Wang, Yang},
title = {Free to Fly in Public Spaces: Drone Controllers' Privacy Perceptions and Practices},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026049},
doi = {10.1145/3025453.3026049},
abstract = {Prior research has discovered various privacy concerns that bystanders have about drones. However, little is known about drone controllers' privacy perceptions and practices of drones. Understanding controllers' perspective is important because it will inform whether controllers' current practices protect or infringe on bystanders' privacy and what mechanisms could be designed to better address the potential privacy issues of drones. In this paper, we report results from interviews of 12 drone controllers in the US. Our interviewees treated safety as their top priority but considered privacy issues of drones exaggerated. Our results also highlight many significant differences in how controllers and bystanders think about drone privacy, for instance, how they determine public vs. private spaces and whether notice and consent of bystanders are needed.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6789–6793},
numpages = {5},
keywords = {privacy, perceptions, uas, surveillance, drone, uav},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025755,
author = {E, Jane L. and E, Ilene L. and Landay, James A. and Cauchard, Jessica R.},
title = {Drone &amp; Wo: Cultural Influences on Human-Drone Interaction Techniques},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025755},
doi = {10.1145/3025453.3025755},
abstract = {As drones become ubiquitous, it is important to understand how cultural differences impact human-drone interaction. A previous elicitation study performed in the USA illustrated how users would intuitively interact with drones. We replicated this study in China to gain insight into how these user-defined interactions vary across the two cultures. We found that as per the US study, Chinese participants chose to interact primarily using gesture. However, Chinese participants used multi-modal interactions more than their US counterparts. Agreement for many proposed interactions was high within each culture. Across cultures, there were notable differences despite similarities in interaction modality preferences. For instance, culturally-specific gestures emerged in China, such as a T-shape gesture for stopping the drone. Participants from both cultures anthropomorphized the drone, and welcomed it into their personal space. We describe the implications of these findings on designing culturally-aware and intuitive human-drone interaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6794–6799},
numpages = {6},
keywords = {elicitation study, cross-cultural design, gesture, quadcopter, human-drone interaction, uav, drone},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025473,
author = {Oliveira, Nigini and Jun, Eunice and Reinecke, Katharina},
title = {Citizen Science Opportunities in Volunteer-Based Online Experiments},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025473},
doi = {10.1145/3025453.3025473},
abstract = {Online experimentation with volunteers could be described as a form of citizen science in which participants take part in behavioral studies without financial compensation. However, while citizen science projects aim to improve scientific understanding, volunteer-based online experiment platforms currently provide minimal possibilities for research involvement and learning. The goal of this paper is to uncover opportunities for expanding participant involvement and learning in the research process. Analyzing comments from 8,288 volunteers who took part in four online experiments on LabintheWild, we identified six themes that reveal needs and opportunities for closer interaction between researchers and participants. Our findings demonstrate opportunities for research involvement, such as engaging participants in refining experiment implementations, and learning opportunities, such as providing participants with possibilities to learn about research aims. We translate these findings into ideas for the design of future volunteer-based online experiment platforms that are more mutually beneficial to citizen scientists and researchers.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6800–6812},
numpages = {13},
keywords = {open science, online experimentation, citizen science},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025820,
author = {Findlater, Leah and Zhang, Joan and Froehlich, Jon E. and Moffatt, Karyn},
title = {Differences in Crowdsourced vs. Lab-Based Mobile and Desktop Input Performance Data},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025820},
doi = {10.1145/3025453.3025820},
abstract = {Research on the viability of using crowdsourcing for HCI performance experiments has concluded that online results are similar to those achieved in the lab---at least for desktop interactions. However, mobile devices, the most popular form of online access today, may be more problematic due to variability in the user's posture and in movement of the device. To assess this possibility, we conducted two experiments with 30 lab-based and 303 crowdsourced participants using basic mouse and touchscreen tasks. Our findings show that: (1) separately analyzing the crowd and lab data yields different study conclusions-touchscreen input was significantly less error prone than mouse input in the lab but more error prone online; (2) age-matched crowdsourced participants were significantly faster and less accurate than their lab-based counterparts, contrasting past work; (3) variability in mobile device movement and orientation increased as experimenter control decreased--a potential factor affecting the touchscreen error differences. This study cautions against assuming that crowdsourced data for performance experiments will directly reflect lab-based data, particularly for mobile devices.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6813–6824},
numpages = {12},
keywords = {mobile, input devices, crowdsourcing, human performance},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025769,
author = {Pandey, Vineet and Amir, Amnon and Debelius, Justine and Hyde, Embriette R. and Kosciolek, Tomasz and Knight, Rob and Klemmer, Scott},
title = {Gut Instinct: Creating Scientific Theories with Online Learners},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025769},
doi = {10.1145/3025453.3025769},
abstract = {Learners worldwide collectively spend millions of hours per week testing their skills on assignments with known answers. Might some of this time fruitfully be spent posing and exploring novel questions? This paper investigates an approach for learners to contribute scientific ideas. The Gut Instinct system embodies this approach, hosting online learning materials and invites learners to collaboratively brainstorm potential influences on people's microbiome. A between-subjects experiment compared the performance of participants who engaged in just learning, just contributing, or a combination. Participants in the learning condition scored highest on a summative test. Participants in both the contribution and combined conditions generated novel, useful questions; there was not a significant difference between the two. Though participants in the combined condition both learned and contributed, this setting did not exhibit an additive benefit, such as better learning in the combined condition. These results highlight the promise and difficulty of double-bottom-line learning experiences.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6825–6836},
numpages = {12},
keywords = {online learning, social computing systems, citizen science, crowdsourcing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026038,
author = {Lee, Jisoo and Walker, Erin and Burleson, Winslow and Kay, Matthew and Buman, Matthew and Hekler, Eric B.},
title = {Self-Experimentation for Behavior Change: Design and Formative Evaluation of Two Approaches},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026038},
doi = {10.1145/3025453.3026038},
abstract = {Desirable outcomes such as health are tightly linked to behaviors, thus inspiring research on technologies that support people in changing those behaviors. Many behavior-change technologies are designed by HCI experts but this approach can make it difficult to personalize support to each user's unique goals and needs. This paper reports on the iterative design of two complementary support strategies for helping users create their own personalized behavior-change plans via self-experimentation: One emphasized the use of interactive instructional materials, and the other additionally introduced context-aware computing to enable user creation of "just in time" home-based interventions. In a formative trial with 27 users, we compared these two approaches to an unstructured sleep education control. Results suggest great promise in both strategies and provide insights on how to develop personalized behavior-change technologies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6837–6849},
numpages = {13},
keywords = {context-aware computing, behavior change, just-in-time interventions, self-experimentation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025480,
author = {Karkar, Ravi and Schroeder, Jessica and Epstein, Daniel A. and Pina, Laura R. and Scofield, Jeffrey and Fogarty, James and Kientz, Julie A. and Munson, Sean A. and Vilardaga, Roger and Zia, Jasmine},
title = {TummyTrials: A Feasibility Study of Using Self-Experimentation to Detect Individualized Food Triggers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025480},
doi = {10.1145/3025453.3025480},
abstract = {Diagnostic self-tracking, the recording of personal information to diagnose or manage a health condition, is a common practice, especially for people with chronic conditions. Unfortunately, many who attempt diagnostic self tracking have trouble accomplishing their goals. People often lack knowledge and skills needed to design and conduct scientifically rigorous experiments, and current tools provide little support. To address these shortcomings and explore opportunities for diagnostic self tracking, we designed, developed, and evaluated a mobile app that applies a self experimentation framework to support patients suffering from irritable bowel syndrome (IBS) in identifying their personal food triggers. TummyTrials aids a person in designing, executing, and analyzing self experiments to evaluate whether a specific food triggers their symptoms. We examined the feasibility of this approach in a field study with 15 IBS patients, finding that participants could use the tool to reliably undergo a self-experiment. However, we also discovered an underlying tension between scientific validity and the lived experience of self experimentation. We discuss challenges of applying clinical research methods in everyday life, motivating a need for the design of self experimentation systems to balance rigor with the uncertainties of everyday life.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6850–6863},
numpages = {14},
keywords = {food, irritable bowel syndrome, self-tracking, self-experimentation, symptom triggers, personal informatics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025557,
author = {Ravichandran, Ruth and Sien, Sang-Wha and Patel, Shwetak N. and Kientz, Julie A. and Pina, Laura R.},
title = {Making Sense of Sleep Sensors: How Sleep Sensing Technologies Support and Undermine Sleep Health},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025557},
doi = {10.1145/3025453.3025557},
abstract = {Sleep is an important aspect of our health, but it is difficult for people to track manually because it is an unconscious activity. The ability to sense sleep has aimed to lower the barriers of tracking sleep. Although sleep sensors are widely available, their usefulness and potential to promote healthy sleep behaviors has not been fully realized. To understand people's perspectives on sleep sensing devices and their potential for promoting sleep health, we surveyed 87 and interviewed 12 people who currently use or have previously used sleep sensors, interviewed 5 sleep medical experts, and conducted an in-depth qualitative analysis of 6986 reviews of the most popular commercial sleep sensing technologies. We found that the feedback provided by current sleep sensing technologies affects users' perceptions of their sleep and encourages goals that are in tension with evidence-based methods for promoting good sleep health. Our research provides design recommendations for improving the feedback of sleep sensing technologies by bridging the gap between expert and user goals.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6864–6875},
numpages = {12},
keywords = {quantified self, personal informatics, sleep tracking, sleep sensing, sleep, behavior change, health monitoring},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025635,
author = {Epstein, Daniel A. and Lee, Nicole B. and Kang, Jennifer H. and Agapie, Elena and Schroeder, Jessica and Pina, Laura R. and Fogarty, James and Kientz, Julie A. and Munson, Sean},
title = {Examining Menstrual Tracking to Inform the Design of Personal Informatics Tools},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025635},
doi = {10.1145/3025453.3025635},
abstract = {We consider why and how women track their menstrual cycles, examining their experiences to uncover design opportunities and extend the field's understanding of personal informatics tools. To understand menstrual cycle tracking practices, we collected and analyzed data from three sources: 2,000 reviews of popular menstrual tracking apps, a survey of 687 people, and follow-up interviews with 12 survey respondents. We find that women track their menstrual cycle for varied reasons that include remembering and predicting their period as well as informing conversations with healthcare providers. Participants described six methods of tracking their menstrual cycles, including use of technology, awareness of their premenstrual physiological states, and simply remembering. Although women find apps and calendars helpful, these methods are ineffective when predictions of future menstrual cycles are inaccurate. Designs can create feelings of exclusion for gender and sexual minorities. Existing apps also generally fail to consider life stages that women experience, including young adulthood, pregnancy, and menopause. Our findings encourage expanding the field's conceptions of personal informatics.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6876–6888},
numpages = {13},
keywords = {lived informatics, inclusivity, period, menstrual cycle, personal informatics, women's health, menstrual tracking},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inbook{10.1145/3025453.3025869,
author = {Ayobi, Amid and Marshall, Paul and Cox, Anna L. and Chen, Yunan},
title = {Quantifying the Body and Caring for the Mind: Self-Tracking in Multiple Sclerosis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025869},
abstract = {Consumer health technologies have an enormous potential to transform the self-management of chronic conditions. However, it is unclear how individuals use self-tracking technologies to manage them. This in-depth interview study explores self-tracking practices in multiple sclerosis (MS), a complex neurological disease that causes physical, cognitive, and psychological symptoms. Our findings illustrate that when faced the unpredictable and degenerative nature of MS, individuals regained a sense of control by intertwining self-care practices with different self-tracking technologies. They engaged in disease monitoring, fitness tracking, and life journaling to quantify the body and care for the mind. We focus attention on the role of emotional wellbeing and the experience of control in self-tracking and managing MS. Finally, we discuss in which ways self-tracking technologies could support the experiential nature of control and foster mindful experiences rather than focusing only on tracking primary disease indicators.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6889–6901},
numpages = {13}
}

@inproceedings{10.1145/3025453.3025771,
author = {McRoberts, Sarah and Ma, Haiwei and Hall, Andrew and Yarosh, Svetlana},
title = {Share First, Save Later: Performance of Self through Snapchat Stories},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025771},
doi = {10.1145/3025453.3025771},
abstract = {As the third most popular social network among millennials, Snapchat is well known for its picture and video messaging system that deletes content after it is viewed. However, the Stories feature of Snapchat offers a different perspective of ephemeral content sharing, with pictures and videos that are available for friends to watch an unlimited number of times for 24 hours. We conduct-ed an in-depth qualitative investigation by interviewing 18 participants and reviewing 14 days of their Stories posts. We identify five themes focused on how participants perceive and use the Stories feature, and apply a Goffmanesque metaphor to our analysis. We relate the Stories medium to other research on self-presentation and identity curation in social media.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6902–6911},
numpages = {10},
keywords = {snapchat, presentation of self, social media, millennials, ephemerality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025682,
author = {Schlesinger, Ari and Chandrasekharan, Eshwar and Masden, Christina A. and Bruckman, Amy S. and Edwards, W. Keith and Grinter, Rebecca E.},
title = {Situated Anonymity: Impacts of Anonymity, Ephemerality, and Hyper-Locality on Social Media},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025682},
doi = {10.1145/3025453.3025682},
abstract = {Anonymity, ephemerality, and hyper-locality are an uncommon set of features in the design of online communities. However, these features were key to Yik Yak's initial success and popularity. In an interview-based study, we found that these three features deeply affected the identity of the community as a whole, the patterns of use, and the ways users committed to this community. We conducted interviews with 18 Yik Yak users on an urban American university campus and found that these three focal design features contributed to casual commitment, transitory use, and emergent community identity. We describe situated anonymity, which is the result of anonymity, ephemerality, and hyper-locality coexisting as focal design features of an online community. This work extends our understanding of use and identity-versus-bond based commitment, which has implications for the design and study of other atypical online communities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6912–6924},
numpages = {13},
keywords = {transitory use, community identity, commitment, anonymity, online communities, ephemerality, hyper-locality},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026026,
author = {Carpenter, Christopher J. and Tong, Stephanie Tom},
title = {Relational Distancing and Termination between Online Friends: An Application of the Investment Model},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026026},
doi = {10.1145/3025453.3026026},
abstract = {This research examined the relational maintenance versus termination of online friendships in Facebook. Guided by Rusbult's [33] investment model (IM), the study constructed a model to examine 55 matched pairs of Facebook friends consisting of one "primary user" and one "annoyer." Results indicated that primary users' judgments of relational satisfaction with annoyers were influenced by annoyers' narcissistic personality and their overall propensity for posting overly self-focused content. Commitment affected primary users' use of both passive "unfollowing" and active "unfriending" in response to annoyers' behavior. Decisions to maintain or terminate online friendships are related to judgments and actions of both partners. Overall, these results emphasize the dyadic nature of relational maintenance and termination processes in online environments, and the importance of studying them as such.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6925–6935},
numpages = {11},
keywords = {unfriending, relational termination, investment model, social network websites, narcissism},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025804,
author = {Puussaar, Aare and Clear, Adrian K. and Wright, Peter},
title = {Enhancing Personal Informatics Through Social Sensemaking},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025804},
doi = {10.1145/3025453.3025804},
abstract = {Personal informatics practices are increasingly common, with a range of consumer technologies available to support, largely individual, interactions with data (e.g., performance measurement and activity/health monitoring). In this paper, we explore the concept of social sensemaking. In contrast to high-level statistics, we posit that social networking and reciprocal sharing of fine-grained self-tracker data can provide valuable context for individuals in making sense of their data. We present the design of an online platform called Citizense Makers (CM), which facilitates group sharing, annotating and discussion of self-tracker data. In a field trial of CM, we explore design issues around willingness to share data reciprocally; the importance of familiarity between individuals; and understandings of common activities in contextualising one's own data.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6936–6942},
numpages = {7},
keywords = {data sharing, social sensemaking, personal informatics},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026007,
author = {Samory, Mattia and Peserico, Enoch},
title = {Sizing Up the Troll: A Quantitative Characterization of Moderator-Identified Trolling in an Online Forum},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026007},
doi = {10.1145/3025453.3026007},
abstract = {A few troublemakers often spoil online environments for everyone else. An extremely disruptive type of abuser is the troll, whose malicious activities are relatively non-obvious, and thus difficult to detect and contain -- particularly by automated systems. A growing corpus of qualitative research focuses on trolling, and differentiates it from other forms of abuse; however, its findings are not directly actionable into automated systems. On the other hand, quantitative research uses definitions of "troll" that mostly fail to capture what moderators and users consider trolling. We address this gap by giving a quantitative analysis of posts, conversations, and users, specifically sanctioned for trolling in an online forum. Although trolls (unlike most other abusers) hardly stand out in a conversation e.g. in terms of vocabulary, textit{how} they interact, rather than textit{what} they contribute, provides cues of their malicious intent.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6943–6947},
numpages = {5},
keywords = {trolls, online forums, social computing},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3026056,
author = {Morreale, Fabio and Moro, Giulio and Chamberlain, Alan and Benford, Steve and McPherson, Andrew P.},
title = {Building a Maker Community Around an Open Hardware Platform},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3026056},
doi = {10.1145/3025453.3026056},
abstract = {This paper reflects on the dynamics and practices of building a maker community around a new hardware platform. We examine the factors promoting the successful uptake of a maker platform from two perspectives: first, we investigate the technical and user experience considerations that users identify as the most important. Second, we explore the specific activities that help attract a community and encourage sustained participation. We present an inductive approach based on the case study of Bela, an embedded platform for creating interactive audio systems. The technical design and community building processes are detailed, culminating in a successful crowdfunding campaign. To further understand the community dynamics, the paper also presents an intensive three-day workshop with eight digital musical instrument designers. From observations and interviews, we reflect on the relationship between the platform and the community and offer suggestions for HCI researchers and practitioners interested in establishing their own maker communities.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6948–6959},
numpages = {12},
keywords = {maker community, diy, embedded hardware, digital musical instruments, pluggable communities, crowdfunding},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025492,
author = {Ferdous, Hasan Shahid and Vetere, Frank and Davis, Hilary and Ploderer, Bernd and O'Hara, Kenton and Comber, Rob and Farr-Wharton, Geremy},
title = {Celebratory Technology to Orchestrate the Sharing of Devices and Stories during Family Mealtimes},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025492},
doi = {10.1145/3025453.3025492},
abstract = {While the idea of "celebratory technologies" during family mealtimes to support positive interactions at the dinner table is promising, there are few studies that investigate how these technologies can be meaningfully integrated into family practices. This paper presents the deployment of Chorus - a mealtime technology that orchestrates the sharing of personal devices and stories during family mealtimes, explores related content from all participants' devices, and supports revisiting previously shared content. A three-week field deployment with seven families shows that Chorus augments family interactions through sharing contents of personal and familial significance, supports togetherness and in-depth discussion by combining resources from multiple devices, helps to broach sensitive topics into familial conversation, and encourages participation from all family members including children. We discuss implications of this research and reflect on design choices and opportunities that can further enhance the family mealtime experience.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6960–6972},
numpages = {13},
keywords = {smartphones, commensality, mealtimes, family, collocated interactions, collaborative use},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025840,
author = {Sleeper, Manya and Cranor, Lorrie Faith and Pearman, Sarah K.},
title = {Exploring Topic-Based Sharing Mechanisms},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025840},
doi = {10.1145/3025453.3025840},
abstract = {General-purpose content-sharing platforms make it difficult for users to limit sharing to people interested in particular topics. Additional topic-based controls may allow users to better reach desired audiences. Designing such tools requires understanding current interest-based targeting techniques and the potential impact of additional mechanisms. We present an exploratory, interview-based study (n = 16) that addresses these dynamics for Facebook. We use diary-driven probes to explore general topic-based sharing across applications. We then use Facebook-based mockups to probe use cases and design tensions around adding topic-based sharing mechanisms to Facebook. We find that participants currently draw on various audience-limiting and reaching strategies to target interest-based audiences. Participants felt additional topic-based sharing mechanisms on Facebook might allow them to avoid oversharing or offending others and allow them to target improved audiences or share improved content. Usable topic-based sharing tools would also need to account, however, for participants' varied desired engagement strategies.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6973–6985},
numpages = {13},
keywords = {access control, topic-based sharing, selective sharing, topics, facebook, targeting strategies},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025579,
author = {Thomas, Vanessa and Remy, Christian and Hazas, Mike and Bates, Oliver},
title = {HCI and Environmental Public Policy: Opportunities for Engagement},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025579},
doi = {10.1145/3025453.3025579},
abstract = {This note discusses opportunities for the HCI community to engage with environmental public policy. It draws on insights and observations made during the primary author's recent work for a policy unit at Global Affairs Canada, which is a federal ministry of the Government of Canada. During that work, the primary author identified several domains of environmental public policy that are of direct relevance to the HCI community. This note contributes a preliminary discussion of how, why, with whom, and in what capacity HCI researchers and practitioners might engage with three types of environmental public policy: climate change, waste electrical and electronic equipment, and green ICT procurement policies. This builds on existing public policy and environmental knowledge within the HCI community and responds directly to calls from some members to engage with environmental public policy.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6986–6992},
numpages = {7},
keywords = {sustainable hci, government, public policy, climate change, environmental public policy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025620,
author = {Roto, Virpi and Kaasinen, Eija and Heimonen, Tomi and Karvonen, Hannu and Jokinen, Jussi P. P. and Mannonen, Petri and Nousu, Hannu and Hakulinen, Jaakko and Lu, Yichen and Saariluoma, Pertti O. and Kym\"{a}l\"{a}inen, Tiina and Keskinen, Tuuli and Turunen, Markku and Koskinen, Hanna Maria Kaarina},
title = {Utilizing Experience Goals in Design of Industrial Systems},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025620},
doi = {10.1145/3025453.3025620},
abstract = {The core idea of experience-driven design is to define the intended experience before functionality and technology. This is a radical idea for companies that have built their competences around specific technologies. Although many technology companies are willing to shift their focus towards experience-driven design, reports on real-life cases about the utilization of this design approach are rare. As part of an industry-led research program, we introduced experience-driven design to metal industry companies with experience goals as the key technique. Four design cases in three companies showed that the goals are useful in keeping the focus on user experience, but several challenges are still left for future research to tackle. This exploratory research lays ground for future research by providing initial criteria for assessing experience design tools. The results shed light on utilizing experience goals in industrial design projects and help practitioners in planning and managing the product design process with user experience in mind.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6993–7004},
numpages = {12},
keywords = {experience design tools, industrial systems, user experience, experience-driven design, experience goal},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025712,
author = {Maiden, Neil and Zachos, Konstantinos and Lockerbie, James and Levis, Sergio and Camargo, Kasia and Hoddy, Shaun and Allemandi, Gianluca},
title = {Evaluating Digital Creativity Support To Improve Health-and-Safety in a Manufacturing Plant},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025712},
doi = {10.1145/3025453.3025712},
abstract = {This paper reports an evaluation of digital support for human creativity to improve health-and-safety in one manufacturing plant. It reports the use of this support as part of the plant's risk management process over 66 working days. Results revealed that this use led to more complete, more useful and more novel risk resolutions, compared with the original paper process, and informed how digital creativity support can be rolled out across manufacturing plants, as well as to other domains not recognized as creative.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {7005–7014},
numpages = {10},
keywords = {health-and-safety, risk management, creativity, mobile},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025650,
author = {Harmon, Ellie and Bopp, Chris and Voida, Amy},
title = {The Design Fictions of Philanthropic IT: Stuck Between an Imperfect Present and an Impossible Future},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025650},
doi = {10.1145/3025453.3025650},
abstract = {In this paper, we examine the stories about philanthropic IT that circulate via product websites, marketing materials, and third-party news articles. Through a series of product-centered case studies, we surface these texts' implicit and explicit visions about the (near) future of philanthropy. We detail their prescriptions about how, why, and in service of what ends nonprofit organizations could, should, and ought to leverage IT. We also examine their underlying assumptions about philanthropy: how social good is accomplished, how philanthropic organizations are - and might be more - effective, to whom organizations and beneficiaries should be accountable, and the terms of that accountability. Analyzing these visions as design fictions, we argue that they help cultivate unrealistic anticipatory relationships to the present and entail concomitantly unrealistic imperatives for the philanthropic sector. We conclude by arguing for the crucial role of HCI scholars in disrupting these impossible futures, and by highlighting areas needing further, re-imagined, research.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {7015–7028},
numpages = {14},
keywords = {discourse analysis, nonprofits, design fiction, philanthropy},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025487,
author = {Gr\o{}nb\ae{}k, Jens Emil and Korsgaard, Henrik and Petersen, Marianne Graves and Birk, Morten Henriksen and Krogh, Peter Gall},
title = {Proxemic Transitions: Designing Shape-Changing Furniture for Informal Meetings},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025487},
doi = {10.1145/3025453.3025487},
abstract = {The field of Shape-Changing Interfaces explores the qualities of physically dynamic artifacts. At furniture-scale, such artifacts have the potential of changing the ways we collaborate and engage with interiors and physical spaces. Informed by theories of proxemics, empirical studies of informal meetings and design work with shape-changing furniture, we develop the notion of proxemic transitions. We present three design aspects of proxemic transitions: transition speed, stepwise reconfiguration, and radical shifts. The design aspects focus on how to balance between physical and digital transformations in designing for proxemic transitions. Our contribution is three-fold: 1) the notion of proxemic transitions, 2) three design aspects to consider in designing for proxemic transitions, and 3) initial exploration of how these design aspects might generate designs of dynamic furniture. These contributions outline important aspects to consider when designing shape-changing furniture for informal workplace meetings.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {7029–7041},
numpages = {13},
keywords = {proxemic transitions, augmented furniture, interaction proxemics, shape-changing interfaces, f-formations},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025802,
author = {Lazar, Amanda and Nguyen, David H.},
title = {Successful Leisure in Independent Living Communities: Understanding Older Adults' Motivations to Engage in Leisure Activities},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025802},
doi = {10.1145/3025453.3025802},
abstract = {Leisure activities are a source of meaning and enjoyment for individuals across the lifespan. In this study, we conducted interviews with twenty-four older adults living in four different independent living communities. We present societal and ecological factors and motivations that influenced the way people participated in and decided what constitutes leisure activities. The goal of maintaining physical and cognitive health was often intertwined with motivations to engage in leisure activities. We discuss how this fits into the broader framework of successful aging and implications for technology design. We also provide an example of how findings from this study can be applied to a specific leisure activity: watching television.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {7042–7056},
numpages = {15},
keywords = {leisure, ageism, aging, successful aging, older adults},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025859,
author = {Hornung, Dominik and M\"{u}ller, Claudia and Shklovski, Irina and Jakobi, Timo and Wulf, Volker},
title = {Navigating Relationships and Boundaries: Concerns around ICT-Uptake for Elderly People},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025859},
doi = {10.1145/3025453.3025859},
abstract = {Despite a proliferation of research in the use of ICTs to support active and healthy ageing, few have considered the privacy and security concerns particular to the elderly. We investigated the appropriation of tablet devices and a neighborhood portal as well as emerging privacy and security issues through ethnographic and action research in a long-term participatory design (PD) project with elderly participants. We discuss two major themes: a) the tensions related to perceived digital threats and the social pressures of online disclosure to the social environment; and b) the relation of these issues to the ICT appropriation process and the referring challenges we encountered. We argue that there is a need to understand the interleaving of physical and virtual habitats, the various ways resulting in discomfort and the senior citizens' actions -- which at first glance appear contradictory. We consider the implications of the issues observed for examining privacy and security concerns more broadly as well as discussing implications for the design of the portal and the shaping of social measures for appropriation support.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {7057–7069},
numpages = {13},
keywords = {participatory design, action research, design case studies, elderly people, disclosure, appropriation, communities of practice, privacy, ethnography},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3025453.3025945,
author = {Guo, Philip J.},
title = {Older Adults Learning Computer Programming: Motivations, Frustrations, and Design Opportunities},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025945},
doi = {10.1145/3025453.3025945},
abstract = {Computer programming is a highly in-demand skill, but most learn-to-code initiatives and research target some of the youngest members of society: children and college students. We present the first known study of older adults learning computer programming. Using an online survey with 504 respondents aged 60 to 85 who are from 52 different countries, we discovered that older adults were motivated to learn to keep their brains challenged as they aged, to make up for missed opportunities during youth, to connect with younger family members, and to improve job prospects. They reported frustrations including a perceived decline in cognitive abilities, lack of opportunities to interact with tutors and peers, and trouble dealing with constantly-changing software technologies. Based on these findings, we propose a learner-centered design of techniques and tools for motivating older adults to learn programming and discuss broader societal implications of a future where more older adults have access to computer programming -- not merely computer literacy -- as a skill set.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {7070–7083},
numpages = {14},
keywords = {computational literacy, older adults, learning programming},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

