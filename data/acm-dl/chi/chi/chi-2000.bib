@inproceedings{10.1145/332040.332042,
author = {McClard, Anne and Somers, Patricia},
title = {Unleashed: Web Tablet Integration into the Home},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332042},
doi = {10.1145/332040.332042},
abstract = {To understand how web access from a portable tablet appliance changes the way people use the Internet, MediaOne gave families pen-based tablet computers with a wireless connection to our high-speed data network. We used ethnographic and usability methods to understand how tablets would be integrated into household activities and to define user requirements for such devices. Participants viewed the tablet as conceptually different from a PC. The tablet enabled a high degree of multitasking with household activities, yet flaws in form and function affected use. Results suggest that correctly designed portable Internet appliances will fill a special role in peoples' daily lives, particularly if these devices share information with each other. They will allow spontaneous access to information and communication anywhere.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {pen-based computing, ethnography, Internet appliances, ergonomics, hand-held computer},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332044,
author = {Silfverberg, Miika and MacKenzie, I. Scott and Korhonen, Panu},
title = {Predicting Text Entry Speed on Mobile Phones},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332044},
doi = {10.1145/332040.332044},
abstract = {We present a model for predicting expert text entry rates for several input methods on a 12-key mobile phone keypad. The model includes a movement component based on Fitts' law and a linguistic component based on digraph, or letter-pair, probabilities. Predictions are provided for one-handed thumb and two-handed index finger input. For the traditional multi-press method or the lesser-used two-key method, predicted expert rates vary from about 21 to 27 words per minute (wpm). The relatively new T9 method works with a disambiguating algorithm and inputs each character with a single key press. Predicted expert rates vary from 41 wpm for one-handed thumb input to 46 wpm for two-handed index finger input. These figures are degraded somewhat depending on the user's strategy in coping with less-than-perfect disambiguation. Analyses of these strategies are presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {9–16},
numpages = {8},
keywords = {mobile phones, Fitts' law, digraph frequencies, mobile systems, text entry, human performance modeling, keypad input},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332047,
author = {Cheverst, Keith and Davies, Nigel and Mitchell, Keith and Friday, Adrian and Efstratiou, Christos},
title = {Developing a Context-Aware Electronic Tourist Guide: Some Issues and Experiences},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332047},
doi = {10.1145/332040.332047},
abstract = {In this paper, we describe our experiences of developing and evaluating GUIDE, an intelligent electronic tourist guide. The GUIDE system has been built to overcome many of the limitations of the traditional information and navigation tools available to city visitors. For example, group-based tours are inherently inflexible with fixed starting times and fixed durations and (like most guidebooks) are constrained by the need to satisfy the interests of the majority rather than the specific interests of individuals. Following a period of requirements capture, involving experts in the field of tourism, we developed and installed a system for use by visitors to Lancaster. The system combines mobile computing technologies with a wireless infrastructure to present city visitors with information tailored to both their personal and environmental contexts. In this paper we present an evaluation of GUIDE, focusing on the quality of the visitor's experience when using the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {17–24},
numpages = {8},
keywords = {context-awareness, mobile computing, adaptive hypermedia, evaluation, user interface design},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332403,
author = {Masliah, Maurice R. and Milgram, Paul},
title = {Measuring the Allocation of Control in a 6 Degree-of-Freedom Docking Experiment},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332403},
doi = {10.1145/332040.332403},
abstract = {Coordination definitions and metrics are reviewed from the motor control, biomedical, and human factors literature. This paper presents an alternative measurement called the M-metric, the product of the simultaneity and efficiency of a trajectory, as a means of quantifying allocation of control within a docking task. A 6 degree-of-freedom (DOF) longitudinal virtual docking task experiment was conducted to address how control is allocated across six DOFs, how allocation of control changes with extended practice, and if differences in the allocation of control are input device dependent. The results show that operators, rather than controlling all 6 DOFs equally, allocate their control to the rotational and translational DOFs separately, and switch control between the two groups. With practice, allocation of control within the translational and rotational subsets increases at a faster rate than across all 6 DOFs together.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {25–32},
numpages = {8},
keywords = {motor control, evaluation methods, allocation of control, input devices, the M-metric, virtual docking task, coordination, 6 degree-of-freedom control, interaction techniques},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332404,
author = {Balakrishnan, Ravin and Hinckley, Ken},
title = {Symmetric Bimanual Interaction},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332404},
doi = {10.1145/332040.332404},
abstract = {We present experimental work that explores the factors governing symmetric bimanual interaction in a two-handed task that requires the user to track a pair of targets, one target with each hand. A symmetric bimanual task is a two-handed task in which each hand is assigned an identical role. In this context, we explore three main experimental factors. We vary the distance between the pair of targets to track: as the targets become further apart, visual diversion increases, forcing the user to divide attention between the two targets. We also vary the demands of the task by using both a slow and a fast tracking speed. Finally, we explore visual integration of sub-tasks: in one condition, the two targets to track are connected by a line segment which visually links the targets, while in the other condition there is no connecting line. Our results indicate that all three experimental factors affect the degree of parallelism, which we quantify using a new metric of bimanual parallelism. However, differences in tracking error between the two hands are affected only by the visual integration factor.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {33–40},
numpages = {8},
keywords = {two-handed input, Guiard theory, symmetric interaction, input, interaction techniques},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332405,
author = {Myers, Brad A. and Lie, Kin Pou and Yang, Bo-Chieh},
title = {Two-Handed Input Using a PDA and a Mouse},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332405},
doi = {10.1145/332040.332405},
abstract = {We performed several experiments using a Personal Digital Assistant (PDA) as an input device in the non-dominant hand along with a mouse in the dominant hand. A PDA is a small hand-held palm-size computer like a 3Com Palm Pilot or a Windows CE device. These are becoming widely available and are easily connected to a PC. Results of our experiments indicate that people can accurately and quickly select among a small numbers of buttons on the PDA using the left hand without looking, and that, as predicted, performance does decrease as the number of buttons increases. Homing times to move both hands between the keyboard and devices are only about 10% to 15% slower than times to move a single hand to the mouse, suggesting that acquiring two devices does not cause a large penalty. In an application task, we found that scrolling web pages using buttons or a scroller on the PDA matched the speed of using a mouse with a conventional scroll bar, and beat the best two-handed times reported in an earlier experiment. These results will help make two-handed interactions with computers more widely available and more effective.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {41–48},
numpages = {8},
keywords = {two-handed input, Palm Pilot, personal digital assistant (PDAs), smart environments, Windows CE, ubiquitous computing, hand-held computers, pebbles},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332406,
author = {Rickenberg, Raoul and Reeves, Byron},
title = {The Effects of Animated Characters on Anxiety, Task Performance, and Evaluations of User Interfaces},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332406},
doi = {10.1145/332040.332406},
abstract = {Animated characters are common in user interfaces, but important questions remain about whether characters work in all situations and for all users. This experiment tested the effects of different character presentations on user anxiety, task performance, and subjective evaluations of two commerce websites. There were three character conditions (no character, a character that ignored the user, and a character that closely monitored work on the website). Users were separated into two groups that had different attitudes about accepting help from others: people with control orientations that were external (users thought that other people controlled their success) and those with internal orientations (users thought they were in control). Results showed that the effects of monitoring and individual differences in thoughts about control worked as they do in real life. Users felt more anxious when characters monitored their website work and this effect was strongest for users with an external control orientation. Monitoring characters also decreased task performance, but increased trust in website content. Results are discussed in terms of design considerations that maximize the positive influence of animated agents.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {49–56},
numpages = {8},
keywords = {animated characters, locus of control, social agents, social facilitation},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332407,
author = {Isbister, Katherine and Nakanishi, Hideyuki and Ishida, Toru and Nass, Cliff},
title = {Helper Agent: Designing an Assistant for Human-Human Interaction in  a Virtual Meeting Space},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332407},
doi = {10.1145/332040.332407},
abstract = {This paper introduces a new application area for agents in the computer interface: the support of human-human interaction. We discuss an interface agent prototype that is designed to support human-human communication in virtual environments. The prototype interacts with users strategically during conversation, spending most of its time listening. The prototype mimics a party host, trying to find a safe common topic for guests whose conversation has lagged. We performed an experimental evaluation of the prototype's ability to assist in cross-cultural conversations. We designed the prototype to introduce safe or unsafe topics to conversation pairs, through a series of questions and suggestions. The agent made positive contributions to participants' experience of the conversation, influenced their perception of each other and of each others' national group, and even seemed to effect their style of behavior. We discuss the implications of our research for the design of social agents to support human-human interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {57–64},
numpages = {8},
keywords = {social interface agents, cross-cultural communication, virtual meeting place, human-human interaction},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332408,
author = {Vivacqua, Adriana and Lieberman, Henry},
title = {Agents to Assist in Finding Help},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332408},
doi = {10.1145/332040.332408},
abstract = {When a novice needs help, often the best solution is to find a human expert who is capable of answering the novice's questions. But often, novices have difficulty characterizing their own questions and expertise and finding appropriate experts. Previous attempts to assist expertise location have provided matchmaking services, but leave the task of classifying knowledge and queries to be performed manually by the participants. We introduce Expert Finder, an agent that automatically classifies both novice and expert knowledge by autonomously analyzing documents created in the course of routine work. Expert Finder works in the domain of Java programming, where it relates a user's Java class usage to an independent domain model. User models are automatically generated that allow accurate matching of query to expert without either the novice or expert filling out skill questionnaires. Testing showed that automatically generated profiles matched well with experts' own evaluation of their skills, and we achieved a high rate of matching novice questions with appropriate experts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {65–72},
numpages = {8},
keywords = {expertise location, agents, matchmaking, help systems, Java},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332409,
author = {Nonnecke, Blair and Preece, Jenny},
title = {Lurker Demographics: Counting the Silent},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332409},
doi = {10.1145/332040.332409},
abstract = {As online groups grow in number and type, understanding lurking is becoming increasingly important. Recent reports indicate that lurkers make up over 90% of online groups, yet little is known about them.This paper presents a demographic study of lurking in email-based discussion lists (DLs) with an emphasis on health and software-support DLs. Four primary questions are examined. One, how prevalent is lurking, and do health and software-support DLs differ? Two, how do lurking levels vary as the definition is broadened from zero posts in 12 weeks to 3 or fewer posts in 12 weeks? Three, is there a relationship between lurking and the size of the DL, and four, is there a relationship between lurking and traffic level?When lurking is defined as no posts, the mean lurking level for all DLs is lower than the reported 90%. Health-support DLs have on average significantly fewer lurkers (46%) than software-support DLs (82%). Lurking varies widely ranging from 0 to 99%. The relationships between lurking, group size and traffic are also examined.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {73–80},
numpages = {8},
keywords = {lurker, BBS, newgroup, demographic, membership, health-support, discussion list, email, lurking, traffic},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332410,
author = {Rodenstein, Roy and Donath, Judith S.},
title = {Talking in Circles: Designing a Spatially-Grounded Audioconferencing Environment},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332410},
doi = {10.1145/332040.332410},
abstract = {This paper presents Talking in Circles, a multimodal audioconferencing environment whose novel design emphasizes spatial grounding with the aim of supporting naturalistic group interaction behaviors. Participants communicate primarily by speech and are represented as colored circles in a two-dimensional space. Behaviors such as subgroup conversations and social navigation are supported through circle mobility as mediated by the environment and the crowd and distance-based attenuation of the audio. The circles serve as platforms for the display of identity, presence and activity: graphics are synchronized to participants' speech to aid in speech-source identification and participants can sketch in their circle, allowing a pictorial and gestural channel to complement the audio. We note user experiences through informal studies as well as design challenges we have faced in the creation of a rich environment for computer-mediated communication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {81–88},
numpages = {8},
keywords = {interaction design, multicast, gesture, drawing, representation, media space, audio, speech, computer-mediated communication, multimodal interfaces, social navigation},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332411,
author = {Whittaker, Steve and Davis, Richard and Hirschberg, Julia and Muller, Urs},
title = {Jotmail: A Voicemail Interface That Enables You to See What Was Said},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332411},
doi = {10.1145/332040.332411},
abstract = {Voicemail is a pervasive, but under-researched tool for workplace communication. Despite potential advantages of voicemail over email, current phone-based voicemail UIs are highly problematic for users. We present a novel, Web-based, voicemail interface, Jotmail. The design was based on data from several studies of voicemail tasks and user strategies. The GUI has two main elements: (a) personal annotations that serve as a visual analogue to underlying speech; (b) automatically derived message header information. We evaluated Jotmail in an 8-week field trial, where people used it as their only means for accessing voicemail. Jotmail was successful in supporting most key voicemail tasks, although users' electronic annotation and archiving behaviors were different from our initial predictions. Our results argue for the utility of a combination of annotation based indexing and automatically derived information, as a general technique for accessing speech archives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {89–96},
numpages = {8},
keywords = {“speech as data”, note-taking, empirical evaluation, asynchronous communication, voicemail, annotation, speech access},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332412,
author = {Corbett, Albert and Trask, Holly},
title = {Instructional Interventions in Computer-Based Tutoring: Differential Impact on Learning Time and Accuracy},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332412},
doi = {10.1145/332040.332412},
abstract = {We can reliably build “second generation” intelligent computer tutors that are approximately half as effective as human tutors. This paper evaluates two interface enhancements designed to improve the effectiveness of one successful second generation tutor, the ACT Programming Tutor. One enhancement employs animated feedback to make key data structure relationships salient. The second enhancement employs subgoal scaffolding to support students in developing simple programming plans. Both interventions were successful, but had very different impacts on student effort required to achieve mastery in the tutor environment and on subsequent posttest accuracy. These results represent a step forward in closing the gap between computer tutors and human tutors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {97–104},
numpages = {8},
keywords = {student modeling, intelligent tutoring systems, animation, plan scaffolding, instructional interface design},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332413,
author = {B\"{a}lter, Olle},
title = {Keystroke Level Analysis of Email Message Organization},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332413},
doi = {10.1145/332040.332413},
abstract = {Organization of email messages takes an increasing amount of time for many email users. Research has demonstrated that users develop very different strategies to handle this organization. In this paper, the relationship between the different organization strategies and the time necessary to use a certain strategy is illustrated by a mathematical model based on keystroke-level analysis. The model estimates time usage for archiving and retrieving email messages for individual users. Besides explaining why users develop different strategies to organize email messages, the model can also be used to advise users individually when to start using folders, clean messages, learn the search functionality, and using filters to store messages. Similar models could assist evaluation of different interface designs where the number of items increase with time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {105–112},
numpages = {8},
keywords = {model, user, email, organisation of messages},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332414,
author = {Watson, Benjamin and Friedman, Alinda and McGaffey, Aaron},
title = {Using Naming Time to Evaluate Quality Predictors for Model Simplification},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332414},
doi = {10.1145/332040.332414},
abstract = {Model simplification researchers require quality heuristics to guide simplification, and quality predictors to allow comparison of different simplification algorithms. However, there has been little evaluation of these heuristics or predictors. We present an evaluation of quality predictors. Our standard of comparison is naming time, a well established measure of recognition from cognitive psychology. Thirty participants named models of familiar objects at three levels of simplification. Results confirm that naming time is sensitive to model simplification. Correlations indicate that view-dependent image quality predictors are most effective for drastic simplifications, while view-independent three-dimensional predictors are better for more moderate simplifications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {113–120},
numpages = {8},
keywords = {image quality, model simplification, naming time, human vision, simplification metrics},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332415,
author = {Koike, Hideki and Sato, Yoichi and Kobayashi, Yoshinori and Tobita, Hiroaki and Kobayashi, Motoki},
title = {Interactive Textbook and Interactive Venn Diagram: Natural and Intuitive Interfaces on Augmented Desk System},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332415},
doi = {10.1145/332040.332415},
abstract = {This paper describes two interface prototypes which we have developed on our augmented desk interface system, EnhancedDesk. The first application is Interactive Textbook, which is aimed at providing an effective learning environment. When a student opens a page which describes experiments or simulations, Interactive Textbook automatically retrieves digital contents from its database and projects them onto the desk. Interactive Textbook also allows the student hands-on ability to interact with the digital contents. The second application is the Interactive Venn Diagram, which is aimed at supporting effective information retrieval. Instead of keywords, the system uses real objects such as books or CDs as keys for retrieval. The system projects a circle around each book; data corresponding the book are then retrieved and projected inside the circle. By moving two or more circles so that the circles intersect each other, the user can compose a Venn diagram interactively on the desk. We also describe the new technologies introduced in EnhancedDesk which enable us to implement these applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {121–128},
numpages = {8},
keywords = {Venn diagram, computer supported learning, finger/hand recognition, information retrieval, augmented reality, computer vision, education},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332416,
author = {Frei, Phil and Su, Victor and Mikhak, Bakhtiar and Ishii, Hiroshi},
title = {<i>Curlybot</i>: Designing a New Class of Computational Toys},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332416},
doi = {10.1145/332040.332416},
abstract = {We introduce an educational toy, called curlybot, as the basis for a new class of toys aimed at children in their early stages of development — ages four and up. curlybot is an autonomous two-wheeled vehicle with embedded electronics that can record how it has been moved on any flat surface and then play back that motion accurately and repeatedly. Children can use curlybot to develop intuitions for advanced mathematical and computational concepts, like differential geometry, through play away from a traditional computer.In our preliminary studies, we found that children learn to use curlybot quickly. They readily establish an affective and body syntonic connection with curlybot, because of its ability to remember all of the intricacies of their original gesture; every pause, acceleration, and even the shaking in their hand is recorded. Programming by example in this context makes the educational ideas implicit in the design of curlybot accessible to young children.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {129–136},
numpages = {8},
keywords = {toy, education, children, learning, tangible interface},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332417,
author = {Lee, Jay and Su, Victor and Ren, Sandia and Ishii, Hiroshi},
title = {HandSCAPE: A Vectorizing Tape Measure for on-Site Measuring Applications},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332417},
doi = {10.1145/332040.332417},
abstract = {We introduce HandSCAPE, an orientation-aware digital tape measure, as an input device for digitizing field measurements, and visualizing the volume of the resulting vectors with computer graphics. Using embedded orientation-sensing hardware, HandSCAPE captures relevant vectors on each linear measurements and transmits this data wirelessly to a remote computer in real-time. To guide us in design, we have closely studied the intended users, their tasks, and the physical workplaces to extract the needs from real worlds. In this paper, we first describe the potential utility of HandSCAPE for three on-site application areas: archeological surveys, interior design, and storage space allocation. We then describe the overall system which includes orientation sensing, vector calculation, and primitive modeling. With exploratory usage results, we conclude our paper for interface design issues and future developments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {137–144},
numpages = {8},
keywords = {orientation-aware, input device, physical interaction, on-site applications, field measurement tool, tangible interface},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332418,
author = {Chen, Hao and Dumais, Susan},
title = {Bringing Order to the Web: Automatically Categorizing Search Results},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332418},
doi = {10.1145/332040.332418},
abstract = {We developed a user interface that organizes Web search results into hierarchical categories. Text classification algorithms were used to automatically classify arbitrary search results into an existing category structure on-the-fly. A user study compared our new category interface with the typical ranked list interface of search results. The study showed that the category interface is superior both in objective and subjective measures. Subjects liked the category interface much better than the list interface, and they were 50% faster at finding information that was organized into categories. Organizing search results allows users to focus on items in categories of interest rather than having to browse through all the results sequentially.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {145–152},
numpages = {8},
keywords = {user interface, classification, search, user study, text categrization, support vector machine, World Wide Web, text categorization},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332419,
author = {Woodruff, Allison and Gossweiler, Rich and Pitkow, James and Chi, Ed H. and Card, Stuart K.},
title = {Enhancing a Digital Book with a Reading Recommender},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332419},
doi = {10.1145/332040.332419},
abstract = {Digital books can significantly enhance the reading experience, providing many functions not available in printed books. In this paper we study a particular augmentation of digital books that provides readers with customized recommendations. We systematically explore the application of spreading activation over text and citation data to generate useful recommendations. Our findings reveal that for the tasks performed in our corpus, spreading activation over text is more useful than citation data. Further, fusing text and citation data via spreading activation results in the most useful recommendations. The fused spreading activation techniques outperform traditional text-based retrieval methods. Finally, we introduce a preliminary user interface for the display of recommendations from these algorithms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {153–160},
numpages = {8},
keywords = {bibliometrics, information visualization, degree of interest, 3D book, recommendations, spreading activation},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332423,
author = {Chi, Ed H. and Pirolli, Peter and Pitkow, James},
title = {The Scent of a Site: A System for Analyzing and Predicting Information Scent, Usage, and Usability of a Web Site},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332423},
doi = {10.1145/332040.332423},
abstract = {Designers and researchers of users' interactions with the World Wide Web need tools that permit the rapid exploration of hypotheses about complex interactions of user goals, user behaviors, and Web site designs. We present an architecture and system for the analysis and prediction of user behavior and Web site usability. The system integrates research on human information foraging theory, a reference model of information visualization and Web data-mining techniques. The system also incorporates new methods of Web site visualization (Dome Tree, Usage Based Layouts), a new predictive modeling technique for Web site use (Web User Flow by Information Scent, WUFIS), and new Web usability metrics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {161–168},
numpages = {8},
keywords = {data mining, dome tree, information foraging, information scent, information visualization, World Wide Web, longest repeated subsequences, usage-based layout, usability},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332425,
author = {Li, Francis C. and Gupta, Anoop and Sanocki, Elizabeth and He, Li-wei and Rui, Yong},
title = {Browsing Digital Video},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332425},
doi = {10.1145/332040.332425},
abstract = {Video in digital format played on programmable devices presents opportunities for significantly enhancing the user's viewing experience. For example, time compression and pause removal can shorten the viewing time for a video, textual and visual indices can allow personalized navigation through the content, and random-access digital storage allows instantaneous seeks into the content. To understand user behavior when such capabilities are available, we built a software video browsing application that combines many such features. We present results from a user study where users browsed video in six different categories: classroom lectures, conference presentations, entertainment shows, news, sports, and travel. Our results show that the most frequently used features were time compression, pause removal, and navigation using shot boundaries. Also, the behavior was different depending on the content type, and we present a classification. Finally, the users found the browser to be very useful. Two main reasons were: i) the ability to save time and ii) the feeling of control over what content they watched.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {169–176},
numpages = {8},
keywords = {pause removal, digital video, video indexing, time compression, next-generation video playback interfaces, video browsing},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332427,
author = {He, Liwei and Sanocki, Elizabeth and Gupta, Anoop and Grudin, Jonathan},
title = {Comparing Presentation Summaries: Slides vs. Reading vs. Listening},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332427},
doi = {10.1145/332040.332427},
abstract = {As more audio and video technical presentations go online, it becomes imperative to give users effective summarization and skimming tools so that they can find the presentation they want and browse through it quickly. In a previous study, we reported three automated methods for generating audio-video summaries and a user evaluation of those methods. An open question remained about how well various text/image only techniques will compare to the audio-video summarizations. This study attempts to fill that gap.This paper reports a user study that compares four possible ways of allowing a user to skim a presentation: 1) PowerPoint slides used by the speaker during the presentation, 2) the text transcript created by professional transcribers from the presentation, 3) the transcript with important points highlighted by the speaker, and 4) a audio-video summary created by the speaker. Results show that although some text-only conditions can match the audio-video summary, users have a marginal preference for audio-video (ANOVA f=3.067, p=0.087). Furthermore, different styles of slide-authoring (e.g., detailed vs. big-points only) can have a big impact on their effectiveness as summaries, raising a dilemma for some speakers in authoring for on-demand previewing versus that for live audiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {177–184},
numpages = {8},
keywords = {video summarization, digital video library, video browsing, multimedia, video skim, video abstraction},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332428,
author = {Boreczky, John and Girgensohn, Andreas and Golovchinsky, Gene and Uchihashi, Shingo},
title = {An Interactive Comic Book Presentation for Exploring Video},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332428},
doi = {10.1145/332040.332428},
abstract = {This paper presents a method for generating compact pictorial summarizations of video. We developed a novel approach for selecting still images from a video suitable for summarizing the video and for providing entry points into it. Images are laid out in a compact, visually pleasing display reminiscent of a comic book or Japanese manga. Users can explore the video by interacting with the presented summary. Links from each keyframe start video playback and/or present additional detail. Captions can be added to presentation frames to include commentary or descriptions such as the minutes of a recorded meeting. We conducted a study to compare variants of our summarization technique. The study participants judged the manga summary to be significantly better than the other two conditions with respect to their suitability for summaries and navigation, and their visual appeal.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {185–192},
numpages = {8},
keywords = {video browsing, keyframe extraction, video summarization},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332430,
author = {Schiano, Diane J. and Ehrlich, Sheryl M. and Rahardja, Krisnawan and Sheridan, Kyle},
title = {Face to Interface: Facial Affect in (Hu)Man and Machine},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332430},
doi = {10.1145/332040.332430},
abstract = {Facial expression of emotion (or “facial affect”) is rapidly becoming an area of intense interest in the computer science and interaction design communities. Ironically, this interest comes at a time when the classic findings on perception of human facial affect are being challenged in the psychological research literature, largely on methodological grounds. This paper presents two studies on perception of facial affect. Experiment 1 provides new data on the recognition of human facial expressions, using experimental methods and analyses designed to systematically address the criticisms and help resolve this controversy. Experiment 2 is a user study on affect in a prototype robot face; the results are compared to the human data of Experiment 1. Together they provide a demonstration of how basic and more applied research can mutually contribute to this rapidly developing field.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {193–200},
numpages = {8},
keywords = {facial affect, affect, nonverbal communications, face, emotion, facial expression of emotion, affective computing},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332432,
author = {Hassenzahl, Mare and Platz, Axel and Burmester, Michael and Lehner, Katrin},
title = {Hedonic and <i>Ergonomic Quality Aspects Determine a Software's Appeal</i>},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332432},
doi = {10.1145/332040.332432},
abstract = {The present study examines the role of subjectively perceived ergonomic quality (e.g. simplicity, controllability) and hedonic quality (e.g. novelty, originality) of a software system in forming a judgement of appeal. A hypothesised research model is presented. The two main research question are: (1) Are ergonomic and hedonic quality subjectively different quality aspects that can be independently perceived by the users? and (2) Is the judgement of appeal formed by combining and weighting ergonomic and hedonic quality and which weights are assigned?The results suggest that both quality aspects can be independently perceived by users. Moreover, they almost equally contributed to the appeal of the tested software prototypes. A simple averaging model implies that both quality aspects will compensate each other.Limitations and practical implication of the results are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {201–208},
numpages = {8},
keywords = {hedonic components, perceived software quality, emotional usability, joy of use},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332433,
author = {Gaver, Bill and Martin, Heather},
title = {Alternatives: Exploring Information Appliances through Conceptual Design Proposals},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332433},
doi = {10.1145/332040.332433},
abstract = {As a way of mapping a design space for a project on information appliances, we produced a workbook describing about twenty conceptual design proposals. On the one hand, they serve as suggestions that digital devices might embody values apart from those traditionally associated with functionality and usefulness. On the other, they are examples of research through design, balancing concreteness with openness to spur the imagination, and using multiplicity to allow the emergence of a new design space. Here we describe them both in terms of content and process, discussing first the values they address and then how they were crafted to encourage a broad discussion with our partners that could inform future stages of design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {209–216},
numpages = {8},
keywords = {home, conceptual design, information appliances, design research},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332434,
author = {Brereton, Margot and McGarry, Ben},
title = {An Observational Study of How Objects Support Engineering Design Thinking and Communication: Implications for the Design of Tangible Media},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332434},
doi = {10.1145/332040.332434},
abstract = {There has been an increasing interest in objects within the HCI field particularly with a view to designing tangible interfaces. However, little is known about how people make sense of objects and how objects support thinking. This paper presents a study of groups of engineers using physical objects to prototype designs, and articulates the roles that physical objects play in supporting their design thinking and communications. The study finds that design thinking is heavily dependent upon physical objects, that designers are active and opportunistic in seeking out physical props and that the interpretation and use of an object depends heavily on the activity. The paper discusses the trade-offs that designers make between speed and accuracy of models, and specificity and generality in choice of representations. Implications for design of tangible interfaces are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {217–224},
numpages = {8},
keywords = {tangible media, user models, augmented reality, design thinking, cognitive models, interaction design},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332435,
author = {MacLean, Karon E. and Snibbe, Scott S. and Levin, Golan},
title = {Tagged Handles: Merging Discrete and Continuous Manual Control},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332435},
doi = {10.1145/332040.332435},
abstract = {Discrete and continuous modes of manual control are fundamentally different: buttons select or change state, while handles persistently modulate an analog parameter. User interfaces for many electronically aided tasks afford only one of these modes when both are needed. We describe an integration of two kinds of physical interfaces (tagged objects and force feedback) that enables seamless execution of such multimodal tasks while applying the benefits of physicality; and demonstrate application scenarios with conceptual and engineering prototypes. Our emphasis is on sharing insights gained in a design case study, including expert user reactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {225–232},
numpages = {8},
keywords = {continuous, tool, force feedback, container, tagged object, token, discrete, design process, tangible, haptic},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332437,
author = {Koleva, Boriana and Schn\"{a}delbach, Holger and Benford, Steve and Greenhalgh, Chris},
title = {Traversable Interfaces between Real and Virtual Worlds},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332437},
doi = {10.1145/332040.332437},
abstract = {Traversable interfaces establish the illusion that virtual and physical worlds are joined together and that users can physically cross from one to the other. Our design for a traversable interface combines work on tele-embodiment, mixed reality boundaries and virtual environments. It also exploits non-solid projection surfaces, of which we describe four examples. Our design accommodates the perspectives of users who traverse the interface and also observers who are present in the connected physical and virtual worlds, an important consideration for performance and entertainment applications. A demonstrator supports encounters between members of our laboratory and remote visitors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {233–240},
numpages = {8},
keywords = {virtual environments, tele-embodiment, augmented reality, mixed reality, tele-presence},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332438,
author = {Maglio, Paul P. and Campbell, Christopher S.},
title = {Tradeoffs in Displaying Peripheral Information},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332438},
doi = {10.1145/332040.332438},
abstract = {Peripheral information is information that is not central to a person's current task, but provides the person the opportunity to learn more, to do a better job, or to keep track of less important tasks. Though peripheral information displays are ubiquitous, they have been rarely studied. For computer users, a common peripheral display is a scrolling text display that provides announcements, sports scores, stock prices, or other news. In this paper, we investigate how to design peripheral displays so that they provide the most information while having the least impact on the user's performance on the main task. We report a series of experiments on scrolling displays aimed at examining tradeoffs between distraction of scrolling motion and memorability of information displayed. Overall, we found that continuously scrolling displays are more distracting than displays that start and stop, but information in both is remembered equally well. These results are summarized in a set of design recommendations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {241–248},
numpages = {8},
keywords = {peripheral information, dual-task tradeoffs, user interface design},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332440,
author = {Zellweger, Polle T. and Regli, Susan Harkness and Mackinlay, Jock D. and Chang, Bay-Wei},
title = {The Impact of Fluid Documents on Reading and Browsing: An Observational Study},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332440},
doi = {10.1145/332040.332440},
abstract = {Fluid Documents incorporate additional information into a page by adjusting typography using interactive animation. One application is to support hypertext browsing by providing glosses for link anchors. This paper describes an observational study of the impact of Fluid Documents on reading and browsing. The study involved six conditions that differ along several dimensions, including the degree of typographic adjustment and the distance glosses are placed from anchors. Six subjects read and answered questions about two hypertext corpora while being monitored by an eyetracker. The eyetracking data revealed no substantial differenccs in eye behavior between conditions. Gloss placement was significant: subjects required less time to use nearby glosses. Finally, the reaction to the conditions was highly varied, with several conditions receiving both a best and worst rating on the subjective questionnaires. These results suggest implications for the design of dynamic reading environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {249–256},
numpages = {8},
keywords = {eye tracking, fluid user interfaces, on-line reading, fluid documents, focus+context, studies of dynamic user interfaces, hypertext navigation},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332442,
author = {Park, Joonah and Kim, Jinwoo},
title = {Effects of Contextual Navigation Aids on Browsing Diverse Web Systems},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332442},
doi = {10.1145/332040.332442},
abstract = {In spite of the radical enhancement of web technologies, many users still continue to experience severe difficulties in navigating web systems. One way to reduce the navigation difficulties is to provide context information that explains the current situation of users in the web systems. In this study, we empirically examined the effects of two types of context information, namely, structural and temporal context. In the experiment, we evaluated the effectiveness of the contextual navigation aids in two different types of web systems: an electronic commerce system and a content dissemination system. In our experiment, subjects performed several browsing tasks and answered a set of post-questionnaires. The results of the experiment reveal that the two types of contextual navigation aids significantly improved the performance of browsing tasks regardless of different web systems. Moreover, context information changed the users' navigation patterns, and increased their subjective ease of navigation. This study concludes with implications for understanding the users' browsing patterns and for developing effective navigation systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {257–264},
numpages = {8},
keywords = {hypertext, Web systems, structure, context information, navigation, browsing},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332443,
author = {Tanriverdi, Vildan and Jacob, Robert J. K.},
title = {Interacting with Eye Movements in Virtual Environments},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332443},
doi = {10.1145/332040.332443},
abstract = {Eye movement-based interaction offers the potential of easy, natural, and fast ways of interacting in virtual environments. However, there is little empirical evidence about the advantages or disadvantages of this approach. We developed a new interaction technique for eye movement interaction in a virtual environment and compared it to more conventional 3-D pointing. We conducted an experiment to compare performance of the two interaction types and to assess their impacts on spatial memory of subjects and to explore subjects' satisfaction with the two types of interactions. We found that the eye movement-based interaction was faster than pointing, especially for distant objects. However, subjects' ability to recall spatial information was weaker in the eye condition than the pointing one. Subjects reported equal satisfaction with both types of interactions, despite the technology limitations of current eye tracking equipment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {265–272},
numpages = {8},
keywords = {Polhemus tracker, virtual reality, virtual environments, interaction techniques, eye tracking, eye movements},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332444,
author = {Salvucci, Dario D. and Anderson, John R.},
title = {Intelligent Gaze-Added Interfaces},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332444},
doi = {10.1145/332040.332444},
abstract = {We discuss a novel type of interface, the intelligent gaze-added interface, and describe the design and evaluation of a sample gaze-added operating-system interface. Gaze-added interfaces, like current gaze-based systems, allow users to execute commands using their eyes. However, while most gaze-based systems replace the functionality of other inputs with that of gaze, gaze-added interfaces simply add gaze functionality that the user can employ if and when desired. Intelligent gaze-added interfaces utilize a probabilistic algorithm and user model to interpret gaze focus and alleviate typical problems with eye-taking data. We extended a standard WIMP operating-system interface into a new interface, IGO, that incorporates intelligent gaze-added input. In a user study, we found that users quickly adapted to the new interface and utilized gaze effectively both alone and with other inputs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {273–280},
numpages = {8},
keywords = {eye movements, gaze-added interfaces, gaze-based interfaces, intelligent interfaces, user models},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332445,
author = {Sibert, Linda E. and Jacob, Robert J. K.},
title = {Evaluation of Eye Gaze Interaction},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332445},
doi = {10.1145/332040.332445},
abstract = {Eye gaze interaction can provide a convenient and natural addition to user-computer dialogues. We have previously reported on our interaction techniques using eye gaze [10]. While our techniques seemed useful in demonstration, we now investigate their strengths and weaknesses in a controlled setting. In this paper, we present two experiments that compare an interaction technique we developed for object selection based on a where a person is looking with the most commonly used selection method using a mouse. We find that our eye gaze interaction technique is faster than selection with a mouse. The results show that our algorithm, which makes use of knowledge about how the eyes behave, preserves the natural quickness of the eye. Eye gaze interaction is a reasonable addition to computer interaction and is convenient in situations where it is important to use the hands for other tasks. It is particularly beneficial for the larger screen workspaces and virtual environments of the future, and it will become increasingly practical as eye tracker technology matures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {281–288},
numpages = {8},
keywords = {user interfaces, eye movements, interaction techniques, eye tracking},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332446,
author = {Pu, Pearl and Faltings, Boi},
title = {Enriching Buyers' Experiences: The SmartClient Approach},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332446},
doi = {10.1145/332040.332446},
abstract = {In electronic commerce, a satisfying buyer experience is a key competitive element. We show new techniques for better adapting interaction with an electronic catalog system to actual buying behavior. Our model replaces the sequential separation of needs identification and product brokering with a conversation in which both processes occur simultaneously. This conversation supports the buyer in formulating his or her needs, and in deciding which criteria to apply in selecting a product to buy. We have experimented with this approach in the area of travel planning and developed a system called SmartClient Travel which supports this process. It includes tools for need identification, visualization of alternatives, and choosing the most suitable one. We describe the system and its implementation, and report on user studies showing its advantages for electronic catalogs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {289–296},
numpages = {8},
keywords = {visual overview, eCommerce, on-line travel planning systems, constraint solver, client-server architecture},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332447,
author = {Bouch, Anna and Kuchinsky, Allan and Bhatti, Nina},
title = {Quality is in  the Eye of the Beholder: Meeting Users' Requirements for Internet Quality of Service},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332447},
doi = {10.1145/332040.332447},
abstract = {Growing usage and diversity of applications on the Internet makes Quality of Service (QoS) increasingly critical [15]. To date, the majority of research on QoS is systems oriented, focusing on traffic analysis, scheduling, and routing. Relatively minor attention has been paid to user-level QoS issues. It is not yet known how objective system quality relates to users' subjective perceptions of quality. This paper presents the results of quantitative experiments that establish a mapping between objective and perceived QoS in the context of Internet commerce. We also conducted focus groups to determine how contextual factors influence users' perceptions of QoS. We show that, while users' perceptions of World Wide Web QoS are influenced by a number of contextual factors, it is possible to correlate objective measures of QoS with subjective judgements made by users, and therefore influence system design. We argue that only by integrating users' requirements for QoS into system design can the utility of the future Internet be maximized.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {297–304},
numpages = {8},
keywords = {Internet, quality of service, user perception},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332448,
author = {Lee, Jungwon and Kim, Jinwoo and Moon, Jae Yun},
title = {What Makes Internet Users Visit Cyber Stores Again? Key Design Factors for Customer Loyalty},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332448},
doi = {10.1145/332040.332448},
abstract = {Retaining customer loyalty is crucial in electronic commerce because the value of an Internet store is largely determined by the number of its loyal customers. This paper proposes a multi-phased model of customer loyalty for Internet shopping, which fully takes the characteristics of the Internet and cyber shopping into consideration. In order to validate the model, we conducted a web-based survey of the customers of various Internet stores, and the data was processed using structural equation analysis. The results indicate that several factors can effectively increase customer loyalty towards an Internet store and that the relative importance of the identified factors varies according to the level of involvement with the product purchased through the store. We suggest several managerial implications in developing Internet stores for higher customer loyalty based on these results.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {305–312},
numpages = {8},
keywords = {electronic commerce, Internet shopping, involvement, customer interface, trust, transaction cost, customer loyalty},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332449,
author = {Christian, Andrew D. and Avery, Brian L.},
title = {Speak out and Annoy Someone: Experience with Intelligent Kiosks},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332449},
doi = {10.1145/332040.332449},
abstract = {An intelligent kiosk is a public information kiosk that senses the presence of humans and communicates in a natural way. To examine issues of human-kiosk interaction, we have built and deployed two versions of intelligent kiosks. The first kiosk design combines machine vision to locate and track people in the vicinity with an animated talking head that focuses on clients and talks to them. The second kiosk design uses infrared and sonar sensors to sense clients and multiple interacting agents to communicate with the client.The foremost lessons learned from public trials include (1) people are attracted to an animated face that watches them, (2) small mobile agents interact better with kiosk content than a single fixed face, (3) speaker-independent speech recognition is only useful in targeted applications, and (4) the quality of the content on the kiosk strongly influences the client's evaluation of the quality of the technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {313–320},
numpages = {8},
keywords = {public kiosk, user interface design, talking avatar, machine vision, information display, speech recognition},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332451,
author = {Lai, Jennifer and Wood, David and Considine, Michael},
title = {The Effect of Task Conditions on the Comprehensibility of Synthetic Speech},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332451},
doi = {10.1145/332040.332451},
abstract = {A study was conducted with 78 subjects to evaluate the comprehensibility of synthetic speech for various tasks ranging from short, simple e-mail messages to longer news articles on mostly obscure topics. Comprehension accuracy for each subject was measured for synthetic speech and for recorded human speech. Half the subjects were allowed to take notes while listening, the other half were not. Findings show that there was no significant difference in comprehension of synthetic speech among the five different text-to-speech engines used. Those subjects that did not take notes performed significantly worse for all synthetic voice tasks when compared to recorded speech tasks. Performance for synthetic speech in the non note-taking condition degraded as the task got longer and more complex. When taking notes, subjects also did significantly worse within the synthetic voice condition averaged across all six tasks. However, average performance scores for the last three tasks in this condition show comparable results for human and synthetic speech, reflective of a training effect.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {321–328},
numpages = {8},
keywords = {comprehension, text-to-speech, synthetic speech, user study},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332452,
author = {Nass, Clifford and Lee, Kwan Min},
title = {Does Computer-Generated  Speech Manifest Personality? An Experimental Test of Similarity-Attraction},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332452},
doi = {10.1145/332040.332452},
abstract = {This study examines whether people would interpret and respond to paralinguistic personality cues in computer-generated speech in the same way as they do human speech. Participants used a book-buying website and heard five book reviews in a 2 (synthesized voice personality: extrovert vs. introvert) by 2 (participant personality: extrovert vs. introvert) balanced, between-subjects experiment. Participants accurately recognized personality cues in TTS and showed strong similarity-attraction effects. Although the content was the same for all participants, when the personality of the computer voice matched their own personality: 1) participants regarded the computer voice as more attractive, credible, and informative; 2) the book review was evaluated more positively; 3) the reviewer was more attractive and credible; and 4) participants were more likely to buy the book. Match of user voice characteristics with TTS had no effect, confirming the social nature of the interaction. We discuss implications for HCI theory and design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {329–336},
numpages = {8},
keywords = {CASA (computers are social actors), personality, similarity-attraction effect, TTS (text-to-speech), user interfaces},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332454,
author = {Rosenbaum, Stephanie and Rohn, Janice Anne and Humburg, Judee},
title = {A Toolkit for Strategic Usability: Results from Workshops, Panels, and Surveys},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332454},
doi = {10.1145/332040.332454},
abstract = {This paper describes the organizational approaches and usability methodologies considered by HCI professionals to increase the strategic impact of usability research within companies. We collected the data from 134 HCI professionals at three conferences: CHI 98, CHI 99, and the Usability Professionals' Association 1999 conference. The results are the first steps towards a toolkit for the usability community that can help HCI practitioners learn from the experiences of others in similar situations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {337–344},
numpages = {8},
keywords = {strategic usability, usability, methodology, organizational change, HCI professionals, corporate planning},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332455,
author = {Fr\o{}kj\ae{}r, Erik and Hertzum, Morten and Hornb\ae{}k, Kasper},
title = {Measuring Usability: Are Effectiveness, Efficiency, and Satisfaction Really Correlated?},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332455},
doi = {10.1145/332040.332455},
abstract = {Usability comprises the aspects effectiveness, efficiency, and satisfaction. The correlations between these aspects are not well understood for complex tasks. We present data from an experiment where 87 subjects solved 20 information retrieval tasks concerning programming problems. The correlation between efficiency, as indicated by task completion time, and effectiveness, as indicated by quality of solution, was negligible. Generally, the correlations among the usability aspects depend in a complex way on the application domain, the user's experience, and the use context. Going through three years of CHI Proceedings, we find that 11 out of 19 experimental studies involving complex tasks account for only one or two aspects of usability. When these studies make claims concerning overall usability, they rely on risky assumptions about correlations between usability aspects. Unless domain specific studies suggest otherwise, effectiveness, efficiency, and satisfaction should be considered independent aspect of usability and all be included in usability testing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {345–352},
numpages = {8},
keywords = {user studies, usability testing, usability measures, information retrival, satisfaction, efficiency, effectiveness},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332456,
author = {Spencer, Rick},
title = {The Streamlined Cognitive Walkthrough Method, Working around Social Constraints Encountered in a Software Development Company},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332456},
doi = {10.1145/332040.332456},
abstract = {The cognitive walkthrough method described by Wharton et al. may be difficult to apply in a large software development company because of social constraints that exist in such companies. Managers, developers, and other team members are pressured for time, tend to lapse into lengthy design discussions, and are sometimes defensive about their user-interface designs. By enforcing four ground rules, explicitly defusing defensiveness, and streamlining the cognitive walkthrough method and data collection procedures, these social constraints can be overcome, and useful, valid data can be obtained. This paper describes a modified cognitive walkthrough process that accomplishes these goals, and has been applied in a large software development company.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {353–359},
numpages = {7},
keywords = {cognitive walkthrough, usability inspection},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332458,
author = {Long, A. Chris and Landay, James A. and Rowe, Lawrence A. and Michiels, Joseph},
title = {Visual Similarity of Pen Gestures},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332458},
doi = {10.1145/332040.332458},
abstract = {Pen-based user interfaces are becoming ever more popular. Gestures (i.e., marks made with a pen to invoke a command) are a valuable aspect of pen-based UIs, but they also have drawbacks. The challenge in designing good gestures is to make them easy for people to learn and remember. With the goal of better gesture design, we performed a pair of experiments to determine why users find gestures similar. From these experiments, we have derived a computational model for predicting perceived gesture similarity that correlates 0.56 with observation. We will incorporate the results of these experiments into a gesture design tool, which will aid the pen-based UI designer in creating gesture sets that are easier to learn and more memorable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {360–367},
numpages = {8},
keywords = {similarity, pen gestures, perception, pen-based user interfaces, multi-dimensional scaling},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332459,
author = {Mankoff, Jennifer and Hudson, Scott E. and Abowd, Gregory D.},
title = {Providing Integrated Toolkit-Level Support for Ambiguity in Recognition-Based Interfaces},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332459},
doi = {10.1145/332040.332459},
abstract = {Interfaces based on recognition technologies are used extensively in both the commercial and research worlds. But recognizers are still error-prone, and this results in human performance problems, brittle dialogues, and other barriers to acceptance and utility of recognition systems. Interface techniques specialized to recognition systems can help reduce the burden of recognition errors, but building these interfaces depends on knowledge about the ambiguity inherent in recognition. We have extended a user interface toolkit in order to model and to provide structured support for ambiguity at the input event level. This makes it possible to build re-usable interface components for resolving ambiguity and dealing with recognition errors. These interfaces can help to reduce the negative effects of recognition errors. By providing these components at a toolkit level, we make it easier for application writers to provide good support for error handling. Further, with this robust support, we are able to explore new types of interfaces for resolving a more varied range of ambiguity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {368–375},
numpages = {8},
keywords = {recognition-based interfaces, pen-based interfaces, ambiguous input, speech recognition, recognition errors, input models, interaction techniques, toolkits},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332460,
author = {Pauws, Steffen and Bouwhuis, Don and Eggen, Berry},
title = {Programming and Enjoying Music with Your Eyes Closed},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332460},
doi = {10.1145/332040.332460},
abstract = {Design and user evaluation of a multimodal interaction style for music programming is described. User requirements were instant usability and optional use of a visual display. The interaction style consists of a visual roller metaphor. User control of the rollers proceeds by manipulating a force feedback trackball. Tactual and auditory cues strengthen the roller impression and support use without a visual display. The evaluation investigated task performance and procedural learning when performing music programming tasks with and without a visual display. No procedural instructions were provided. Tasks could be completed successfully with and without a visual display, though programming without a display needed more time to complete. Prior experience with a visual display did not improve performance without a visual display. When working without a display, procedures have to be acquired and remembered explicitly, as more procedures were remembered after working without a visual display. It is demonstrated that multimodality provides new ways to interact with music.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {376–383},
numpages = {8},
keywords = {interactive music system, interface design, nonvisual interaction, user evaluation, multimodal interaction},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332461,
author = {Jancke, Gavin and Grudin, Jonathan and Gupta, Anoop},
title = {Presenting to Local and Remote Audiences: Design and Use of the TELEP System},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332461},
doi = {10.1145/332040.332461},
abstract = {The current generation of desktop computers and networks are bringing streaming audio and video into widespread use. A small investment allows presentations or lectures to be multicast, enabling passive viewing from offices or rooms. We surveyed experienced viewers of multicast presentations and designed a lightweight system that creates greater awareness in the presentation room of remote viewers and allows remote viewers to interact with each other and the speaker. We report on the design, use, and modification of the system, and discuss design tradeoffs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {384–391},
numpages = {8},
keywords = {tele-presentation, streaming media},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332463,
author = {Espinosa, Alberto and Cadiz, Jonathan and Rico-Gutierrez, Luis and Kraut, Robert and Scherlis, William and Lautenbacher, Glenn},
title = {Coming to the Wrong Decision Quickly: Why Awareness Tools Must Be Matched with Appropriate Tasks},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332463},
doi = {10.1145/332040.332463},
abstract = {This paper presents an awareness tool designed to help distributed, asynchronous groups solve problems quickly. Using a lab study, it was found that groups that used the awareness tool tended to converge and agree upon a solution more quickly. However, it was also found that individuals who did not use the awareness tool got closer to the correct solution. Implications for the design of awareness tools are discussed, with particular attention paid to the importance of matching the features of an awareness tool with a workgroup's tasks and goals.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {392–399},
numpages = {8},
keywords = {asynchronous work, computer-mediated communication, awareness devices, distributed work, workgroups, task awareness},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332464,
author = {Taylor, Michael J. and Rowe, Simon M.},
title = {Gaze Communication Using Semantically Consistent Spaces},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332464},
doi = {10.1145/332040.332464},
abstract = {This paper presents a design for a user interface that supports improved gaze communication in multi-point video conferencing. We set out to use traditional computer displays to mediate the gaze of remote participants in a realistic manner. Previous approaches typically assume immersive displays, and use live video to animate avatars in a shared 3D virtual world. This shared world is then rendered from the viewpoint of the appropriate avatar to yield the required views of the virtual meeting. We show why such views of a shared space do not convey gaze information realistically when using traditional computer displays. We describe a new approach that uses a different arrangement of the avatars for each participant in order to preserve the semantic significance of gaze. We present a design process for arranging these avatars. Finally, we demonstrate the effectiveness of the new interface with experimental results.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {400–407},
numpages = {8},
keywords = {gaze, animation, virtual meeting, avatar, videophones},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332466,
author = {Arsenault, Roland and Ware, Colin},
title = {Eye-Hand Co-Ordination with Force Feedback},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332466},
doi = {10.1145/332040.332466},
abstract = {The term Eye-hand co-ordination refers to hand movements controlled with visual feedback and reinforced by hand contact with objects. A correct perspective view of a virtual environment enables normal eye-hand co-ordination skills to be applied. But is it necessary for rapid interaction with 3D objects? A study of rapid hand movements is reported using an apparatus designed so that the user can touch a virtual object in the same place where he or she sees it. A Fitts tapping task is used to assess the effect of both contact with virtual objects and real-time update of the centre of perspective based on the user's actual eye position. A Polhemus tracker is used to measure the user's head position and from this estimate their eye position. In half of the conditions, head tracked perspective is employed so that visual feedback is accurate while in the other half a fixed eye-position is assumed. A Phantom force feedback device is used to make it possible to touch the targets in selected conditions. Subjects were required to change their viewing position periodically to assess the importance of correct perspective and of touching the targets in maintaining eye-hand co-ordination, The results show that accurate perspective improves performance by an average of 9% and contact improves it a further 12%. A more detailed analysis shows the advantages of head tracking to be greater for whole arm movements in comparison with movements from the elbow.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {408–414},
numpages = {7},
keywords = {virtual reality, interaction techniques, 3d interfaces, force feedback, haptics},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332467,
author = {Oakley, Ian and McGee, Marilyn Rose and Brewster, Stephen and Gray, Philip},
title = {Putting the Feel in ’Look and Feel‘},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332467},
doi = {10.1145/332040.332467},
abstract = {Haptic devices are now commercially available and thus touch has become a potentially realistic solution to a variety of interaction design challenges. We report on an investigation of the use of touch as a way of reducing visual overload in the conventional desktop. In a two-phase study, we investigated the use of the PHANToM haptic device as a means of interacting with a conventional graphical user interface. The first experiment compared the effects of four different haptic augmentations on usability in a simple targeting task. The second experiment involved a more ecologically-oriented searching and scrolling task. Results indicated that the haptic effects did not improve users performance in terms of task completion time. However, the number of errors made was significantly reduced. Subjective workload measures showed that participants perceived many aspects of workload as significantly less with haptics. The results are described and the implications for the use of haptics in user interface design are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {415–422},
numpages = {8},
keywords = {haptics, multimodal interaction, force feedback},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332469,
author = {Dennerlein, Jack Tigh and Martin, David B. and Hasser, Christopher},
title = {Force-Feedback Improves Performance for Steering and Combined Steering-Targeting Tasks},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332469},
doi = {10.1145/332040.332469},
abstract = {The introduction of a force-feedback mouse, which provides high fidelity tactile cues via force output, may represent a long-awaited technological breakthrough in pointing device designs. However, there have been few studies examining the benefits of force-feedback for the desktop computer human interface. Ten adults performed eighty steering tasks, where the participants moved the cursor through a small tunnel with varying indices of difficulty using a conventional and force-feedback mouse. For the force-feedback condition, the mouse displayed force that pulled the cursor to the center of the tunnel. The tasks required both horizontal and vertical screen movements of the cursor. Movement times were on average 52 percent faster during the force-feedback condition when compared to the conventional mouse. Furthermore, for the conventional mouse vertical movements required more time to complete than horizontal screen movements. Another ten adults completed a combined steering and targeting task, where the participants navigated through a tunnel and then clicked a small box at the end of the tunnel. Again, force-feedback improved times to complete the task. Although movement times were slower than the pure steering task, the steering index of difficulty dominated the steering-targeting relationship. These results further support that human computer interfaces benefit from the additional sensory input of tactile cues to the human user.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {423–429},
numpages = {7},
keywords = {haptic, steering task, index of difficulty, targeting task, Fitts' law, mouse, force-feedback, pointing devices},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332470,
author = {Buyukkokten, Orkut and Garcia-Molina, Hector and Paepcke, Andreas and Winograd, Terry},
title = {Power Browser: Efficient Web Browsing for PDAs},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332470},
doi = {10.1145/332040.332470},
abstract = {We have designed and implemented new Web browsing facilities to support effective navigation on Personal Digital Assistants (PDAs) with limited capabilities: low bandwidth, small display, and slow CPU. The implementation supports wireless browsing from 3Com's Palm Pilot. An HTTP proxy fetches web pages on the client's behalf and dynamically generates summary views to be transmitted to the client. These summaries represent both the link structure and contents of a set of web pages, using information about link importance. We discuss the architecture, user interface facilities, and the results of comparative performance evaluations. We measured a 45% gain in browsing speed, and a 42% reduction in required pen movements.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {430–437},
numpages = {8},
keywords = {Web, PDA (personal digital assistant), HTTP, PalmPilot, proxy, browser, wireless},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332472,
author = {Brown, Barry A. T. and Sellen, Abigail J. and O'Hara, Kenton P.},
title = {A Diary Study of Information Capture in Working Life},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332472},
doi = {10.1145/332040.332472},
abstract = {Despite the increasing number of new devices entering the market allowing the capture or recording of information (whether it be marks on paper, scene, sound or moving images), there has been little study of when and why people want to do these kinds of activities. In an effort to systematically explore design requirements for new kinds of information capture devices, we devised a diary study of 22 individuals in a range of different jobs. The data were used to construct a taxonomy as a framework for design and analysis. Design implications are drawn from the framework and applied to the design of digital cameras and hand held scanners.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {438–445},
numpages = {8},
keywords = {information capture, appliances, digital cameras, voice recorders, document use, PDAs, scanners, diary study},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332473,
author = {Beaudouin-Lafon, Michel},
title = {Instrumental Interaction: An Interaction Model for Designing Post-WIMP User Interfaces},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332473},
doi = {10.1145/332040.332473},
abstract = {This article introduces a new interaction model called Instrumental Interaction that extends and generalizes the principles of direct manipulation. It covers existing interaction styles, including traditional WIMP interfaces, as well as new interaction styles such as two-handed input and augmented reality. It defines a design space for new interaction techniques and a set of properties for comparing them. Instrumental Interaction describes graphical user interfaces in terms of domain objects and interaction instruments. Interaction between users and domain objects is mediated by interaction instruments, similar to the tools and instruments we use in the real world to interact with physical objects. The article presents the model, applies it to describe and compare a number of interaction techniques, and shows how it was used to create a new interface for searching and replacing text.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {446–453},
numpages = {8},
keywords = {instrumental interaction, post-WIMP interfaces, interaction model, direct manipulation, WIMP interfaces},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332475,
author = {Churchill, Elizabeth F. and Trevor, Jonathan and Bly, Sara and Nelson, Les and Cubranic, Davor},
title = {Anchored Conversations: Chatting in the Context of a Document},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332475},
doi = {10.1145/332040.332475},
abstract = {This paper describes an application-independent tool called Anchored Conversations that brings together text-based conversations and documents. The design of Anchored Conversations is based on our observations of the use of documents and text chats in collaborative settings. We observed that chat spaces support work conversations, but they do not allow the close integration of conversations with work documents that can be seen when people are working together face-to-face. Anchored Conversations directly addresses this problem by allowing text chats to be anchored into documents. Anchored Conversations also facilitates document sharing; accepting an invitation to an anchored conversation results in the document being automatically uploaded. In addition, Anchored Conversations provides support for review, catch-up and asynchronous communications through a database. In this paper we describe motivating fieldwork, the design of Anchored Conversations, a scenario of use, and some preliminary results from a user study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {454–461},
numpages = {8},
keywords = {text-based chat, synchronous communication, collaboration, CSCW, conversations, sticky chats, asynchronous communication, shared documents},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332477,
author = {Smith, Marc A. and Farnham, Shelly D. and Drucker, Steven M.},
title = {The Social Life of Small Graphical Chat Spaces},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332477},
doi = {10.1145/332040.332477},
abstract = {This paper provides a unique quantitative analysis of the social dynamics of three chat rooms in the Microsoft V-Chat graphical chat system. Survey and behavioral data were used to study user experience and activity. 150 V-Chat participants completed a web-based survey, and data logs were collected from three V-Chat rooms over the course of 119 days. This data illustrates the usage patterns of graphical chat systems, and highlights the ways physical proxemics are translated into social interactions in online environments. V-Chat participants actively used gestures, avatars, and movement as part of their social interactions. Analyses of clustering patterns and movement data show that avatars were used to provide nonverbal cues similar to those found in face-to-face interactions. However, use of some graphical features, in particular gestures, declined as users became more experienced with the system. These findings have implications for the design and study of online interactive environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {462–469},
numpages = {8},
keywords = {social interfaces, avatars, empirical analysis, proxemics, log file analysis, computer mediated communication, graphical chat, virtual community, social cyberspace, online community},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332478,
author = {Jensen, Carlos and Farnham, Shelly D. and Drucker, Steven M. and Kollock, Peter},
title = {The Effect of Communication Modality on Cooperation in Online Environments},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332478},
doi = {10.1145/332040.332478},
abstract = {One of the most robust findings in the sociological literature is the positive effect of communication on cooperation and trust. When individuals are able to communicate, cooperation increases significantly. How does the choice of communication modality influence this effect? We adapt the social dilemma research paradigm to quantitatively analyze different modes of communication. Using this method, we compare four forms of communication: no communication, text-chat, text-to-speech, and voice. We found statistically significant differences between different forms of communication, with the voice condition resulting in the highest levels of cooperation. Our results highlight the importance of striving towards the use of more immediate forms of communication in online environments, especially where trust and cooperation are essential. In addition, our research demonstrates the applicability of the social dilemma paradigm in testing the extent to which communication modalities promote the development of trust and cooperation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {470–477},
numpages = {8},
keywords = {social interfaces, online interaction, CSCW, computer mediated communication, social dilemna, collaboration},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332479,
author = {Patrick, Emilee and Cosgrove, Dennis and Slavkovic, Aleksandra and Rode, Jennifer A. and Verratti, Thom and Chiselko, Greg},
title = {Using a Large Projection Screen as an Alternative to Head-Mounted Displays for Virtual Environments},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332479},
doi = {10.1145/332040.332479},
abstract = {Head-mounted displays for virtual environments facilitate an immersive experience that seems more real than an experience provided by a desk-top monitor [18]; however, the cost of head-mounted displays can prohibit their use. An empirical study was conducted investigating differences in spatial knowledge learned for a virtual environment presented in three viewing conditions: head-mounted display, large projection screen, and desk-top monitor. Participants in each condition were asked to reproduce their cognitive map of a virtual environment, which had been developed during individual exploration of the environment along a predetermined course. Error scores were calculated, indicating the degree to which each participant's map differed from the actual layout of the virtual environment. No statistically significant difference was found between the head-mounted display and large projection screen conditions. An implication of this result is that a large projection screen may be an effective, inexpensive substitute for a head-mounted display.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {478–485},
numpages = {8},
keywords = {cognitive map, experiment, field of view, head-mounted display, monitor, virtual reality, projection screen, spatial knowledge},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332481,
author = {Conway, Matthew and Audia, Steve and Burnette, Tommy and Cosgrove, Dennis and Christiansen, Kevin},
title = {Alice: Lessons Learned from Building a 3D System for Novices},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332481},
doi = {10.1145/332040.332481},
abstract = {We present lessons learned from developing Alice, a 3D graphics programming environment designed for undergraduates with no 3D graphics or programming experience. Alice is a Windows 95/NT tool for describing the time-based and interactive behavior of 3D objects, not a CAD tool for creating object geometry. Our observations and conclusions come from formal and informal observations of hundreds of users. Primary results include the use of LOGO-style egocentric coordinate systems, the use of arbitrary objects as lightweight coordinate systems, the launching of implicit threads of execution, extensive function overloading for a small set of commands, the careful choice of command names, and the ubiquitous use of animation and undo.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {486–493},
numpages = {8},
keywords = {animation authoring tools, interactive 3D graphics},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332482,
author = {Robertson, George and van Dantzich, Maarten and Robbins, Daniel and Czerwinski, Mary and Hinckley, Ken and Risden, Kirsten and Thiel, David and Gorokhovsky, Vadim},
title = {The Task Gallery: A 3D Window Manager},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332482},
doi = {10.1145/332040.332482},
abstract = {The Task Gallery is a window manager that uses interactive 3D graphics to provide direct support for task management and document comparison, lacking from many systems implementing the desktop metaphor. User tasks appear as artwork hung on the walls of a virtual art gallery, with the selected task on a stage. Multiple documents can be selected and displayed side-by-side using 3D space to provide uniform and intuitive scaling. The Task Gallery hosts any Windows application, using a novel redirection mechanism that routes input and output between the 3D environment and unmodified 2D Windows applications. User studies suggest that the Task Gallery helps with task management, is enjoyable to use, and that the 3D metaphor evokes spatial memory and cognition.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {494–501},
numpages = {8},
keywords = {spatial cognition, 3D user interfaces, window managers, spatial memory},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332485,
author = {Baumeister, Lynn K. and John, Bonnie E. and Byrne, Michael D.},
title = {A Comparison of Tools for Building GOMS Models},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332485},
doi = {10.1145/332040.332485},
abstract = {We compare three tools for creating GOMS models, QGOMS [2), CATHCI (17) and GLEAN3 [12], along several dimensions. We examine the representation and available constructs in each tool, the qualitative and quantitative design information provided, the support for building cognitively plausible models, and pragmatics about using each tool (e.g., how easy it is to modify a model). While each tool has its strengths, they all leave something to be desired as a practical UI design tool.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {502–509},
numpages = {8},
keywords = {GOMS, tool support for evaluation},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332486,
author = {Lin, James and Newman, Mark W. and Hong, Jason I. and Landay, James A.},
title = {DENIM: Finding a Tighter Fit between Tools and Practice for Web Site Design},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332486},
doi = {10.1145/332040.332486},
abstract = {Through a study of web site design practice, we observed that web site designers design sites at different levels of refinement—site map, storyboard, and individual page—and that designers sketch at all levels during the early stages of design. However, existing web design tools do not support these tasks very well. Informed by these observations, we created DENIM, a system that helps web site designers in the early stages of design. DENIM supports sketching input, allows design at different refinement levels, and unifies the levels through zooming. We performed an informal evaluation with seven professional designers and found that they reacted positively to the concept and were interested in using such a system in their work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {510–517},
numpages = {8},
keywords = {pen-based computers, sketching, rapid prototyping, zooming user interface (ZUI), Web design, informal},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332488,
author = {Damm, Christian Heide and Hansen, Klaus Marius and Thomsen, Michael},
title = {Tool Support for Cooperative Object-Oriented Design: Gesture Based Modelling on an Electronic Whiteboard},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332488},
doi = {10.1145/332040.332488},
abstract = {Modeling is important in object-oriented software development. Although a number of Computer Aided Software Engineering (CASE) tools are available, and even though some are technically advanced, few developers use them. This paper describes our attempt to examine the requirements needed to provide tool support for the development process, and describes and evaluates a tool, Knight, which has been developed based on these requirements. The tool is based on a direct, whiteboard-like interaction achieved using gesture input on a large electronic whiteboard. So far the evaluations have been successful and the tool shows the potential of greatly enhancing current support for object-oriented modeling.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {518–525},
numpages = {8},
keywords = {electronic whiteboards, cooperative design, object-oriented modeling, user study, CASE tools, gesture input},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332491,
author = {Fr\"{o}hlich, Bernd and Plate, John},
title = {The Cubic Mouse: A New Device for Three-Dimensional Input},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332491},
doi = {10.1145/332040.332491},
abstract = {We have developed a new input device that allows users to intuitively specify three-dimensional coordinates in graphics applications. The device consists of a cube-shaped box with three perpendicular rods passing through the center and buttons on the top for additional control. The rods represent the X, Y, and Z axes of a given coordinate system. Pushing and pulling the rods specifies constrained motion along the corresponding axes. Embedded within the device is a six degree of freedom tracking sensor, which allows the rods to be continually aligned with a coordinate system located in a virtual world. We have integrated the device into two visualization prototypes for crash engineers and geologists from oil and gas companies. In these systems the Cubic Mouse controls the position and orientation of a virtual model and the rods move three orthogonal cutting or slicing planes through the model. We have evaluated the device with experts from these domains, who were enthusiastic about its ease of use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {526–531},
numpages = {6},
keywords = {user interface hardware, two-handed interaction, virtual reality},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332494,
author = {Wang, Yanqing and MacKenzie, Christine L.},
title = {The Role of Contextual Haptic and Visual Constraints on Object Manipulation in Virtual Environments},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332494},
doi = {10.1145/332040.332494},
abstract = {An experiment was conducted to investigate the role of surrounding haptic and visual information on object manipulation in a virtual environment. The contextual haptic constraints were implemented with a physical table and the contextual visual constraints included a checkerboard background (“virtual table”). It was found that the contextual haptic constraints (the physical table surface) dramatically increased object manipulation speed, but slightly reduced spatial accuracy, compared to free space. The contextual visual constraints (presence of the checkerboard) actually showed detrimental effects on both object manipulation speed and accuracy. Implications of these findings for human-computer interaction design are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {532–539},
numpages = {8},
keywords = {graphic interface, force feedback, visual information, docking, degrees of freedom, 3D, virtual reality, augmented environment, task context, controls and displays, human performance, haptic information},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332497,
author = {Poupyrev, Ivan and Weghorst, Suzanne and Fels, Sidney},
title = {Non-Isomorphic 3D Rotational Techniques},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332497},
doi = {10.1145/332040.332497},
abstract = {This paper demonstrates how non-isomorphic rotational mappings and interaction techniques can be designed and used to build effective spatial 3D user interfaces. In this paper, we develop a mathematical framework allowing us to design non-isomorphic 3D rotational mappings and techniques, investigate their usability properties, and evaluate their user performance characteristics. The results suggest that non-isomorphic rotational mappings can be an effective tool in building high-quality manipulation dialogs in 3D interfaces, allowing our subjects to accomplish experimental tasks 13% faster without a statistically detectable loss in accuracy. The current paper will help interface designers to use non-isomorphic rotational mappings effectively.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {540–547},
numpages = {8},
keywords = {motor control, 6DOF input devices, interaction techniques, interactive 3D rotations, 3D user interfaces},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332499,
author = {M\"{a}kel\"{a}, Ann and Giller, Verena and Tscheligi, Manfred and Sefelin, Reinhard},
title = {Joking, Storytelling, Artsharing, Expressing Affection: A Field Trial of How Children and Their Social Network Communicate with Digital Images in Leisure Time},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332499},
doi = {10.1145/332040.332499},
abstract = {Increasing use of mobile phones in leisure and communication with digital images are important and current issues in the field of telecommunications. However, little is known about how images would be used in leisure related communication. According to our experience field trials are the best way of studying it. In this paper, we describe a field-trial case study of leisure related communication with digital images. Moreover, we discuss the advantages of conducting field trials as part of product concept design process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {548–555},
numpages = {8},
keywords = {wireless communication, prototypes, product concept design, digital images, children, leisure, field trial, family},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332502,
author = {Benford, Steve and Bederson, Benjamin B. and \r{A}kesson, Karl-Petter and Bayon, Victor and Druin, Allison and Hansson, P\"{a}r and Hourcade, Juan Pablo and Ingram, Rob and Neale, Helen and O'Malley, Claire and Simsarian, Kristian T. and Stanton, Dana\"{e} and Sundblad, Yngve and Tax\'{e}n, Gustav},
title = {Designing Storytelling Technologies to Encouraging Collaboration between Young Children},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332502},
doi = {10.1145/332040.332502},
abstract = {We describe the iterative design of two collaborative storytelling technologies for young children, KidPad and the Klump. We focus on the idea of designing interfaces to subtly encourage collaboration so that children are invited to discover the added benefits of working together. This idea has been motivated by our experiences of using early versions of our technologies in schools in Sweden and the UK. We compare the approach of encouraging collaboration with other approaches to synchronizing shared interfaces. We describe how we have revised the technologies to encourage collaboration and to reflect design suggestions made by the children themselves.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {556–563},
numpages = {8},
keywords = {education, single display groupware (SDG), computer supported cooperative work (CSCW), computer supported collaborative learning (CSCL), children},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/332040.332505,
author = {Balabanovi\'{c}, Marko and Chu, Lonny L. and Wolff, Gregory J.},
title = {Storytelling with Digital Photographs},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332505},
doi = {10.1145/332040.332505},
abstract = {Photographs play a central role in many types of informal storytelling. This paper describes an easy-to-use device that enables digital photos to be used in a manner similar to print photos for sharing personal stories. A portable form factor combined with a novel interface supports local sharing like a conventional photo album as well as recording of stories that can be sent to distant friends and relatives. User tests validate the design and reveal that people alternate between “photo-driven” and “story-driven” strategies when telling stories about their photos.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {564–571},
numpages = {8},
keywords = {digital photography, digital storytelling, browsing, multimedia organization},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

