@inproceedings{10.1145/3313831.3376786,
author = {La Delfa, Joseph and Baytas, Mehmet Aydin and Patibanda, Rakesh and Ngari, Hazel and Khot, Rohit Ashok and Mueller, Florian 'Floyd'},
title = {Drone Chi: Somaesthetic Human-Drone Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376786},
doi = {10.1145/3313831.3376786},
abstract = {Somaesthetics - motivated by improving life quality via appreciation for bodily and sensory experiences - is increasingly influencing HCI designs. Investigating the potential of drones as a material for somaesthetic HCI, we designed Drone Chi: a Tai Chi-inspired close-range human-drone interaction experience. The design process for Drone Chi has been informed by the soma design approach and the Somaesthetic Appreciation concept from HCI literature. The artifact expands somaesthetic HCI by exemplifying dynamic and intimate somaesthetic interactions with a robotic design material, and body movements in expansive 3D space. To characterize the Drone Chi experience, we conducted an empirical study with 32 participants. Analysis of participant accounts revealed 4 themes that articulate different aspects of the experience: Looping Mental States, Environment, Agency vs. Control, and Physical Narratives. From these accounts and our craft knowledge, we derive 5 design implications to guide the development of movement-based close-range drone interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {somaesthetics, tai chi, soma design, somaesthetic appreciation, human-drone interaction, movement, drones},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@book{10.1145/3313831,
author = {Bernhaupt, Regina and Mueller, Florian 'Floyd' and Verweij, David and Andres, Josh and McGrenere, Joanna and Cockburn, Andy and Avellino, Ignacio and Goguey, Alix and Bj\o{}rn, Pernille and Zhao, Shengdong (Shen) and Samson, Briane Paul and Kocielnik, Rafal},
title = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Aloha!We are excited to welcome you to CHI 2020 in beautiful Honolulu, Hawai'i!Although CHI has strong origins in the USA, it has never been to Hawai'i. We see this rather "unusual" location for a conference as both an acknowledgement of the role underrepresented regions play in the field of Human-Computer Interaction as well as a symbol for more outreach to the rest of the world.The ACM CHI Conference on Human Factors in Computing Systems is the premier international conference of Human-Computer Interaction. CHI - pronounced "kai" - is a place where researchers and practitioners gather from across the world to discuss the latest in interactive technology. We are a multicultural community from highly diverse backgrounds who together investigate new and creative ways for people to interact.CHI has a rich history of bringing together people from different disciplines, cultures, sectors, communities and backgrounds. Through CHI, designers, researchers and practitioners come together with the common purpose of creating technology that works for people and society.We are increasingly realizing how our technology use is changing how we delineate work and pleasure, how it is advancing our productivity but at the same time threatening our wellbeing. In choosing a beautiful location like Hawai'i, we hope we highlight the importance of work-life balance and also elicit new discussions on such critical perspectives about the future of interactive technology.Thanks to our massive numbers of volunteers and help from ACM and its SIGCHI members, we are excited to present a vibrant technical and social programme for you to experience. Over six days, participants can join and continue to engage with the CHI community and explore technology and world-class research, and engage in discussions with designers, researchers, students, and practitioners!Ho'omalu-o means "to conserve; to use or manage wisely" in the Hawaiian language. One of our goals for CHI 2020 is to make more sustainable choices wherever we can, recognising, of course, that any travel, especially to locations like ours, has a significant impact on the environment. Working with the Sustainability Chairs, we have chosen recycled, biodegradable or eco-friendly products and engaged with local suppliers, wherever possible. We have implemented options to reduce travel related to the conference organisation by using videoconference meetings as much as possible. We have worked with the CHI Steering and Executive Committee to identify future opportunities to reduce travel and to reduce the number of meetings. We have removed the conference bag and gifts by default and encouraged the selection of more sustainable food choices (including the decision not to serve red meat). We have also chosen reusable or compostable crockery and cutlery where possible and are donating any remaining food to a homeless shelter to avoid food waste.Furthermore, we have chosen to locate all activities in or near the Convention Centre and negotiated deals with hotels nearby to reduce the need for transportation. The Convention Centre itself is the first and only public assembly convention centre to earn LEED v.4 O+M Gold Certification in the United States. In the spirit of Ho'omaluo- , we have also decided to set the default temperature in the venue higher to reduce air condition energy usage.A particular highlight is the Interactivity programme, which will be launched at the Reception on Monday evening, giving a live glimpse into the future with hands-on prototypes, design experiences as well as inspirational technologies.We are also excited to continue the commitment to making CHI, and CHI content, more widely accessible. We will be live-streaming even more paper sessions. We also provide a nursing room, all-gender bathrooms, badge pronouns, a desensitization room and a prayer room.}
}

@inproceedings{10.1145/3313831.3376448,
author = {Wacharamanotham, Chat and Eisenring, Lukas and Haroz, Steve and Echtler, Florian},
title = {Transparency of CHI Research Artifacts: Results of a Self-Reported Survey},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376448},
doi = {10.1145/3313831.3376448},
abstract = {Several fields of science are experiencing a "replication crisis" that has negatively impacted their credibility. Assessing the validity of a contribution via replicability of its experimental evidence and reproducibility of its analyses requires access to relevant study materials, data, and code. Failing to share them limits the ability to scrutinize or build-upon the research, ultimately hindering scientific progress.Understanding how the diverse research artifacts in HCI impact sharing can help produce informed recommendations for individual researchers and policy-makers in HCI. Therefore, we surveyed authors of CHI 2018-2019 papers, asking if they share their papers' research materials and data, how they share them, and why they do not. The results (34% response rate) show that sharing is uncommon, partly due to misunderstandings about the purpose of sharing and reliable hosting. We conclude with recommendations for fostering open research practices.This paper and all data and materials are freely available at https://osf.io/3bu6t.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {public data sharing, open science, data availability, open data},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376209,
author = {Li, Chi-Hsun and Yeh, Su-Fang and Chang, Tang-Jie and Tsai, Meng-Hsuan and Chen, Ken and Chang, Yung-Ju},
title = {A Conversation Analysis of Non-Progress and Coping Strategies with a Banking Task-Oriented Chatbot},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376209},
doi = {10.1145/3313831.3376209},
abstract = {Task-oriented chatbots are becoming popular alternatives for fulfilling users' needs, but few studies have investigated how users cope with conversational 'non-progress' (NP) in their daily lives. Accordingly, we analyzed a three-month conversation log between 1,685 users and a task-oriented banking chatbot. In this data, we observed 12 types of conversational NP; five types of content that was unexpected and challenging for the chatbot to recognize; and 10 types of coping strategies. Moreover, we identified specific relationships between NP types and strategies, as well as signs that users were about to abandon the chatbot, including 1) three consecutive incidences of NP, 2) consecutive use of message reformulation or switching subjects, and 3) using message reformulation as the final strategy. Based on these findings, we provide design recommendations for task-oriented chatbots, aimed at reducing NP, guiding users through such NP, and improving user experiences to reduce the cessation of chatbot use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {breakdowns, non-progress, coping strategies, conversation analysis, chatbot},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376865,
author = {Wang, Chi and Huang, Da-Yuan and Hsu, Shuo-Wen and Lin, Cheng-Lung and Chiu, Yeu-Luen and Hou, Chu-En and Chen, Bing-Yu},
title = {Gaiters: Exploring Skin Stretch Feedback on Legs for Enhancing Virtual Reality Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376865},
doi = {10.1145/3313831.3376865},
abstract = {We propose generating two-dimensional skin stretch feedback on the user's legs. Skin stretch is useful cutaneous feedback to induce the perception of virtual textures and illusory forces and to deliver directional cues. This feedback has been applied to the head, body, and upper limbs to simulate rich physical properties in virtual reality (VR). However, how to expand the benefit of skin stretch feedback and apply it to the lower limbs, remains to be explored. Our first two psychophysical studies examined the minimum changes in skin stretch distance and stretch angle that are perceivable by participants. We then designed and implemented Gaiters, a pair of ungrounded, leg-worn devices, each of which is able to generate multiple two-dimensional skin stretches on the skin of the user's leg. With Gaiters, we conducted an exploratory study to understand participants' experiences when coupling skin stretch patterns with various lower limb actions. The results indicate that rich haptic experiences can be created by our prototype. Finally, a user evaluation indicates that participants enjoyed the experiences when using Gaiters and considered skin stretch as compelling haptic feedback on the legs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {haptics, skin stretch feedback, sheartactors, virtual reality, leg-worn device},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376262,
author = {Liao, Yi-Chi and Kim, Sunjun and Lee, Byungjoo and Oulasvirta, Antti},
title = {Button Simulation and Design via FDVV Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376262},
doi = {10.1145/3313831.3376262},
abstract = {Designing a push-button with desired sensation and performance is challenging because the mechanical construction must have the right response characteristics. Physical simulation of a button's force-displacement (FD) response has been studied to facilitate prototyping; however, the simulations' scope and realism have been limited. In this paper, we extend FD modeling to include vibration (V) and velocity-dependence characteristics (V). The resulting FDVV models better capture tactility characteristics of buttons, including snap. They increase the range of simulated buttons and the perceived realism relative to FD models. The paper also demonstrates methods for obtaining these models, editing them, and simulating accordingly. This end-to-end approach enables the analysis, prototyping, and optimization of buttons, and supports exploring designs that would be hard to implement mechanically.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {fd model, simulation, button, force feedback, modeling, vibration, fdvv model, tactility, haptic rendering, haptic, input device},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376557,
author = {Tian, Yang and Bai, Yuming and Zhao, Shengdong and Fu, Chi-Wing and Yang, Tianpei and Heng, Pheng Ann},
title = {Virtually-Extended Proprioception: Providing Spatial Reference in VR through an Appended Virtual Limb},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376557},
doi = {10.1145/3313831.3376557},
abstract = {Selecting targets directly in the virtual world is difficult due to the lack of haptic feedback and inaccurate estimation of egocentric distances. Proprioception, the sense of self-movement and body position, can be utilized to improve virtual target selection by placing targets on or around one's body. However, its effective scope is limited closely around one's body. We explore the concept of virtually-extended proprioception by appending virtual body parts mimicking real body parts to users' avatars, to provide spatial reference to virtual targets. Our studies suggest that our approach facilitates more efficient target selection in VR as compared to no reference or using an everyday object as reference. Besides, by cultivating users' sense of ownership on the appended virtual body part, we can further enhance target selection performance. The effects of transparency and granularity of the virtual body part on target selection performance are also discussed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, proprioception, spatial reference, target selection, appended limb},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376131,
author = {Xiao, Ziang and Zhou, Michelle X. and Chen, Wenxi and Yang, Huahai and Chi, Changyan},
title = {If I Hear You Correctly: Building and Evaluating Interview Chatbots with Active Listening Skills},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376131},
doi = {10.1145/3313831.3376131},
abstract = {Interview chatbots engage users in a text-based conversation to draw out their views and opinions. It is, however, challenging to build effective interview chatbots that can handle user free-text responses to open-ended questions and deliver engaging user experience. As the first step, we are investigating the feasibility and effectiveness of using publicly available, practical AI technologies to build effective interview chatbots. To demonstrate feasibility, we built a prototype scoped to enable interview chatbots with a subset of active listening skills-the abilities to comprehend a user's input and respond properly. To evaluate the effectiveness of our prototype, we compared the performance of interview chatbots with or without active listening skills on four common interview topics in a live evaluation with 206 users. Our work presents practical design implications for building effective interview chatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {deep learning, conversational agents, chatbot platform, ai chatbot, interview chatbot, active listening},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376368,
author = {Meena, Yogesh Kumar and Seunarine, Krishna and Sahoo, Deepak Ranjan and Robinson, Simon and Pearson, Jennifer and Zhang, Chi and Carnie, Matt and Pockett, Adam and Prescott, Andrew and Thomas, Suzanne K. and Lee, Harrison Ka Hin and Jones, Matt},
title = {PV-Tiles: Towards Closely-Coupled Photovoltaic and Digital Materials for Useful, Beautiful and Sustainable Interactive Surfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376368},
doi = {10.1145/3313831.3376368},
abstract = {The interactive, digital future with its seductive vision of Internet-of-Things connected sensors, actuators and displays comes at a high cost in terms of both energy demands and the clutter it brings to the physical world. But what if such devices were made of materials that enabled them to self-power their interactive features? And, what if those materials were directly used to build aesthetically pleasing environments and objects that met practical physical needs as well as digital ones? In this paper we introduce PV-Tiles ? a novel material that closely couples photovoltaic energy harvesting and light sensing materials with digital interface components. We consider potential contexts, use-cases and light gestures surfaced through co-creation workshops; and, present initial technological designs and prototypes. The work opens a new set of opportunities and collaborations between HCI and material science, stimulating technical and design pointers to accommodate and exploit the material's properties.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {internet of things, interaction design, connected home, sustainability, self-powered devices},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376206,
author = {Lockton, Dan and Lallemand, Carine},
title = {Meeting Designers Where They Are: Using Industry Events as a Research Venue for HCI and Design Methods Development},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376206},
doi = {10.1145/3313831.3376206},
abstract = {There is much work in the CHI community about the 'industry-academia divide', and how to bridge it. One key crossover between HCI/UX scientists and practitioners is the development and use of tools and methods-boundary objects between academia and practice. Among other forms of collaboration, there is an underdeveloped opportunity for academics to make use of industry events (conferences, meetups, design jams) as a research venue in the context of tool and method development. This paper describes three cases from work in academia-industry engagement over the last decade, in which workshops or experiments have been run at industry events as a way of trialling and developing tools directly with practitioners. We discuss advantages of this approach and extract key insights and practical implications, highlighting how the CHI community might use this method more widely, gathering relevant research outcomes while contributing to knowledge exchange between academia and practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {practitioners, design tools, industry events, industry-academia engagement, method development},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376723,
author = {Tyack, April and Mekler, Elisa D.},
title = {Self-Determination Theory in HCI Games Research: Current Uses and Open Questions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376723},
doi = {10.1145/3313831.3376723},
abstract = {Self-Determination Theory (SDT), a major psychological theory of human motivation, has become increasingly popular in Human-Computer Interaction (HCI) research on games and play. However, it remains unclear how SDT has advanced HCI games research, or how HCI games scholars engage with the theory. We reviewed 110 CHI and CHI PLAY papers that cited SDT to gain a better understanding of the ways the theory has contributed to HCI games research. We find that SDT, and in particular, the concepts of need satisfaction and intrinsic motivation, have been widely applied to analyse the player experience and inform game design. Despite the popularity of SDT-based measures, however, prominent core concepts and mini-theories are rarely considered explicitly, and few papers engage with SDT beyond descriptive accounts. We highlight conceptual gaps at the intersection of SDT and HCI games research, and identify opportunities for SDT propositions, concepts, and measures to more productively inform future work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–22},
numpages = {22},
keywords = {gamification, games, theory, play, self-determination theory, motivation, player experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376201,
author = {Zhou, Rui and DiSalvo, Betsy},
title = {User's Role in Platform Infrastructuralization: WeChat as an Exemplar},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376201},
doi = {10.1145/3313831.3376201},
abstract = {Recent years have witnessed the rise of platforms such as Facebook and Google. Gigantic in scope and becoming omnipresent, these platforms are acquiring qualities of infrastructure, which is large-scale connected systems that support people's activities invisibly. Recent scholarship has identified WeChat, the most popular mobile social platform in China, as infrastructure. WeChat follows a platform logic to expand, and by conforming to the Chinese government's techno-nationalist focus, it has gradually become an infrastructure in China. We contribute to the understanding of platform infrastructuralization by taking WeChat as a case, highlighting the user's role in this process. We find user contributes to WeChat's infrastructuralization through a three-level interaction process: to practice, to appropriate, and to create. By calling out the user's role in platform infra-structuralization, we discuss how the CHI community can contribute to a better understanding of this phenomenon.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {infrastructure, social network, platform, china, user, wechat},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376791,
author = {Naiakshina, Alena and Danilova, Anastasia and Gerlitz, Eva and Smith, Matthew},
title = {On Conducting Security Developer Studies with CS Students: Examining a Password-Storage Study with CS Students, Freelancers, and Company Developers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376791},
doi = {10.1145/3313831.3376791},
abstract = {Ecological validity is a major concern in usable security studies with developers. Many studies are conducted with computer science (CS) students out of convenience, since recruiting professional software developers in sufficient numbers is very challenging. In a password-storage study, Naiakshina et al. (CHI'19) showed that CS students behave similarly to freelance developers recruited online. While this is a promising result for conducting developer studies with students, an open question remains: Do professional developers employed in companies behave similarly as well? To provide more insight into the ecological validity of recruiting students for security developer studies, we replicated the study of Naiakshina et al. with developers from diverse companies in Germany. We found that developers employed in companies performed better than students and freelancers in a direct comparison. However, treatment effects were found to be significant in all groups; the treatment effects on CS students also held for company developers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {developer password study, student developer, usable security and privacy, security developer study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376522,
author = {Murad, Christine and Munteanu, Cosmin},
title = {Designing Voice Interfaces: Back to the (Curriculum) Basics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376522},
doi = {10.1145/3313831.3376522},
abstract = {Voice user interfaces (VUIs) are rapidly increasing in popularity in the consumer space. This leads to a concurrent explosion of available applications for such devices, with many industries rushing to offer voice interactions for their products. This pressure is then transferred to interface designers; however, a large majority of designers have been only trained to handle the usability challenges specific to Graphical User Interfaces (GUIs). Since VUIs differ significantly in design and usability from GUIs, we investigate in this paper the extent to which current educational resources prepare designers to handle the specific challenges of VUI design. For this, we conducted a preliminary scoping scan and syllabi meta review of HCI curricula at more than twenty top international HCI departments, revealing that the current offering of VUI design training within HCI education is rather limited. Based on this, we advocate for the updating of HCI curricula to incorporate VUI design, and for the development of VUI-specific pedagogical artifacts to be included in new curricula.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {hci curriculum, conversational interface, speech, hci education, vui design, voice user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376596,
author = {Barathi, Soumya C. and Proulx, Michael and O'Neill, Eamonn and Lutteroth, Christof},
title = {Affect Recognition Using Psychophysiological Correlates in High Intensity VR Exergaming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376596},
doi = {10.1145/3313831.3376596},
abstract = {User experience estimation of VR exergame players by recognising their affective state could enable us to personalise and optimise their experience. Affect recognition based on psychophysiological measurements has been successful for moderate intensity activities. High intensity VR exergames pose challenges as the effects of exercise and VR headsets interfere with those measurements. We present two experiments that investigate the use of different sensors for affect recognition in a VR exergame. The first experiment compares the impact of physical exertion and gamification on psychophysiological measurements during rest, conventional exercise, VR exergaming, and sedentary VR gaming. The second experiment compares underwhelming, overwhelming and optimal VR exergaming scenarios. We identify gaze fixations, eye blinks, pupil diameter and skin conductivity as psychophysiological measures suitable for affect recognition in VR exergaming and analyse their utility in determining affective valence and arousal. Our findings provide guidelines for researchers of affective VR exergames.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {VR exergaming, psychophysiological correlates, affect recognition, high intensity exercise},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376811,
author = {Oh, Changhoon and Choi, Jinhan and Lee, Sungwoo and Park, SoHyun and Kim, Daeryong and Song, Jungwoo and Kim, Dongwhan and Lee, Joonhwan and Suh, Bongwon},
title = {Understanding User Perception of Automated News Generation System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376811},
doi = {10.1145/3313831.3376811},
abstract = {Automated journalism refers to the generation of news articles using computer programs. Although it is widely used in practice, its user experience and interface design remain largely unexplored. To understand the user perception of an automated news system, we designed NewsRobot, a research prototype that automatically generated news on major events of the PyeongChang 2018 Winter Olympic Games in real-time. It produces six types of news by combining two kinds of content (general/individualized) and three styles (text, text+image, text+image+sound). A total of 30 users participated in using NewsRobot, completing surveys and interviews on their experience. Our findings are as follows: (1) Users preferred individualized news yet considered it less credible, (2) more presentation elements were appreciated but only if their quality was assured, and (3) NewsRobot was considered factual and accurate yet shallow in depth. Based on our findings, we discuss implications for designing automated journalism user interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {automated journalism, robot journalism, multimedia modality, automated news generation system},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376453,
author = {Encinas, Enrique and Durrant, Abigail C. and Mitchell, Robb and Blythe, Mark},
title = {Metaprobes, Metaphysical Workshops and Sketchy Philosophy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376453},
doi = {10.1145/3313831.3376453},
abstract = {The intersection of philosophy and HCI is a longstanding site of interest for the field that has been attracting special attention in recent years. In this paper, we present metaphysical probes (Metaprobes) as a tool for design-led philosophical inquiry. A Metaprobe is a design artifact used to study a metaphysical idea without concealing the philosophical tools mobilized by the designers or the designerly knowledge attained after deployment. We introduce the concept of a Metaphysical Workshop. This is the set of sketchy philosophical notions that a designer mobilizes in order to research a philosophical idea through design. We then present a case study that comprises: the philosophical issue under examination, the Metaprobes designed to study it, the metaphysical workshop used and the designerly insight produced. We conclude with a discussion of the potentials and weaknesses of Metaprobes in relation to other critical and speculative research-through-design practices. We aim to provide one way to make philosophies already present in design more explicit and make other philosophical concepts relevant to HCI more accessible and workable for designers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cultural probes, ontology, philosophy, design fiction, metaphysics, research fiction, research through design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376658,
author = {Barbareschi, Giulia and Holloway, Catherine and Arnold, Katherine and Magomere, Grace and Wetende, Wycliffe Ambeyi and Ngare, Gabriel and Olenja, Joyce},
title = {The Social Network: How People with Visual Impairment Use Mobile Phones in Kibera, Kenya},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376658},
doi = {10.1145/3313831.3376658},
abstract = {Living in an informal settlement with a visual impairment can be very challenging resulting in social exclusion. Mobile phones have been shown to be hugely beneficial to people with sight loss in formal and high-income settings. However, little is known about whether these results hold true for people with visual impairment (VIPs) in informal settlements. We present the findings of a case study of mobile technology use by VIPs in Kibera, an informal settlement in Nairobi. We used contextual interviews, ethnographic observations and a co-design workshop to explore how VIPs use mobile phones in their daily lives, and how this use influences the social infrastructure of VIPs. Our findings suggest that mobile technology supports and shapes the creation of social infrastructure. However, this is only made possible through the existing support networks of the VIPs, which are mediated through four types of interaction: direct, supported, dependent and restricted.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {Kenya, informal settlements, HCI4D, Kibera, participatory design, ICT4D, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376676,
author = {Hoggenmueller, Marius and Hespanhol, Luke and Tomitsch, Martin},
title = {Stop and Smell the Chalk Flowers: A Robotic Probe for Investigating Urban Interaction with Physicalised Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376676},
doi = {10.1145/3313831.3376676},
abstract = {HCI researchers have begun to more systematically study non-digital transient approaches for displaying information in public space, for example, in the form of chalk infographics. These approaches provide several benefits compared to digital displays, such as: ad-hoc deployment, barrier-free interaction, and being more sustainable. However, one limitation is their hyperlocal scale and impact. Speculating on urban robots as agents for scaling up physicalised displays, we describe the exploratory design and deployment of Woodie, a slow-moving robot that draws on the ground using conventional chalk sticks. We deployed Woodie for three weeks in a quiet laneway situated within a highly urbanised area. Data collected from observations, video logs and interviews revealed that Woodie successfully attracted people's attention and acted as a facilitator for collaborative, creative placemaking. Furthermore, Woodie provoked emotional responses and was perceived as a living being. Findings are interpreted to describe opportunities urban robots provide for the design of future pervasive urban displays.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {urban probe, human-robot interaction, pervasive displays, design, urban robotic displays, physicalised displays, urban media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376681,
author = {Wu, Te-Yen and Qi, Shutong and Chen, Junchi and Shang, MuJie and Gong, Jun and Seyed, Teddy and Yang, Xing-Dong},
title = {Fabriccio: Touchless Gestural Input on Interactive Fabrics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376681},
doi = {10.1145/3313831.3376681},
abstract = {We present Fabriccio, a touchless gesture sensing technique developed for interactive fabrics using Doppler motion sensing. Our prototype was developed using a pair of loop antennas (one for transmitting and the other for receiving), made of conductive thread that was sewn onto a fabric substrate. The antenna type, configuration, transmission lines, and operating frequency were carefully chosen to balance the complexity of the fabrication process and the sensitivity of our system for touchless hand gestures, performed at a 10 cm distance. Through a ten-participant study, we evaluated the performance of our proposed sensing technique across 11 touchless gestures as well as 1 touch gesture. The study result yielded a 92.8% cross-validation accuracy and 85.2% leave-one-session-out accuracy. We conclude by presenting several applications to demonstrate the unique interactions enabled by our technique on soft objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {touchless gesture, interactive fabrics, doppler effect},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376153,
author = {Clegg, Tamara and Greene, Daniel M. and Beard, Nate and Brunson, Jasmine},
title = {Data Everyday: Data Literacy Practices in a Division I College Sports Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376153},
doi = {10.1145/3313831.3376153},
abstract = {Data analysis is central to sports training. Today, cutting-edge digital technologies are deployed to measure and improve athletes' performance. But too often researchers focus on the technology collecting performance data at the expense of understanding athletes' experiences with data. This is particularly the case in the understudied context of collegiate athletics, where competition is fierce, tools for data analysis abound, and the institution actively manages athletes' lives. By investigating how student-athletes analyze their performance data and are analyzed in turn, we can better understand the individual and institutional factors that make data literacy practices in athletics meaningful and productive-or not. Our pilot interview study of student-athletes at one Division I university reveals a set of opportunities for student-athletes to engage with and learn from data analytics practices. These opportunities come with a set of contextual tensions that should inform the design of new technologies for collegiate sports settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hci and sports, data literacy, personal informatics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376255,
author = {Tabassum, Madiha and Kropczynski, Jess and Wisniewski, Pamela and Lipford, Heather Richter},
title = {Smart Home Beyond the Home: A Case for Community-Based Access Control},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376255},
doi = {10.1145/3313831.3376255},
abstract = {As smart devices are becoming commonplace in homes, we need to explore the needs of not just the residents of the home, but also of secondary stakeholders who may be granted access to these devices from outside of the home. We conducted a mixed methods study, which included a survey of 163 smart home device owners and a follow-up interview with 13 individuals who currently share their smart home devices with others outside of their home. Nearly half (47.8%) of our survey participants shared at least one smart home device with someone that did not live with them. Individuals sought greater safety and security by providing remote access to trusted family members or friends. By understanding users' perspectives about privacy and trust in relation to sharing smart home devices beyond the home, we build a case for community-based access control of smart home devices in the Internet of Things.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {access control, community, smart home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376351,
author = {Tancred, Nicoletta and Turkay, Selen and Vickery, Nicole and Wyeth, Peta and McCoombe, Anna},
title = {Understanding Women Modders Using the Serious Leisure Perspective},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376351},
doi = {10.1145/3313831.3376351},
abstract = {Modding, the act of custom creation in videogames, is a large enterprise comprising millions of people. Despite the large number of individuals creating mods, our understanding of who modders are and their motivation for modding is limited. This is especially true for minority groups, including women. In prior research with modding communities, women modders were consistently underrepresented. Using a mixed-method survey (N = 68) that incorporates the Serious Leisure Framework, this study begins to unravel women's participation in modding activities. We begin to identify who women modders are, examine what motivates them to mod, and investigate their modding practices. Results show that women modders value the creation of multiple mod types, including cosmetic, environmental and gameplay modification. They are primarily motivated by self-gratification and enjoyment. These findings create new insights into how women interact with gaming environments, as well as identifying those aspects of the experience that motivate women's engagement in modding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {women modding, modding, modders, game modifications, video games, serious leisure, custom content},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376305,
author = {Aigner, Roland and Pointner, Andreas and Preindl, Thomas and Parzer, Patrick and Haller, Michael},
title = {Embroidered Resistive Pressure Sensors: A Novel Approach for Textile Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376305},
doi = {10.1145/3313831.3376305},
abstract = {We present a novel method for augmenting arbitrary fabrics with textile-based pressure sensors using an off-the-shelf embroidery machine. We apply resistive textiles and conductive yarns on top of a base fabric, to yield a flexible and versatile continuous sensing device, which is based on the widespread principle of force sensitive resistors. The patches can easily be attached to measurement and/or computing devices, e.g. for controlling accessories. In this paper, we investigate the impacts of related design and fabrication parameters, introduce five different pattern designs, and discuss their pros and cons. We present crucial insights and recommendations for design and manufacturing of embroidered pressure sensors. Our sensors show a very low activation threshold, as well as good dynamic range, signal-to-noise ratio, and part-to-part repeatability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {space-filling patterns, embroidered force sensitive resistance, embroidery, textile sensor, smart textiles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376174,
author = {Mitchell Finnigan, Samantha and Clear, Adrian K.},
title = {"No Powers, Man!": A Student Perspective on Designing University Smart Building Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376174},
doi = {10.1145/3313831.3376174},
abstract = {Smart buildings offer an opportunity for better performance and enhanced experience by contextualising services and interactions to the needs and practices of occupants. Yet, this vision is limited by established approaches to building management, delivered top-down through professional facilities management teams, opening up an interaction-gap between occupants and the spaces they inhabit. To address the challenge of how smart buildings might be more inclusively managed, we present the results of a qualitative study with student occupants of a smart building, with design workshops including building walks and speculative futuring. We develop new understandings of how student occupants conceptualise and evaluate spaces as they experience them, and of how building management practices might evolve with new sociotechnical systems that better leverage occupant agency. Our findings point to important directions for HCI research in this nascent area, including the need for HBI (Human-Building Interaction) design to challenge entrenched roles in building management.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {hbi, speculative design, walking, human-building interaction, sustainability, sustainable hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376590,
author = {Liao, Q. Vera and Gruen, Daniel and Miller, Sarah},
title = {Questioning the AI: Informing Design Practices for Explainable AI User Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376590},
doi = {10.1145/3313831.3376590},
abstract = {A surge of interest in explainable AI (XAI) has led to a vast collection of algorithmic work on the topic. While many recognize the necessity to incorporate explainability features in AI systems, how to address real-world user needs for understanding AI remains an open question. By interviewing 20 UX and design practitioners working on various AI products, we seek to identify gaps between the current XAI algorithmic work and practices to create explainable AI products. To do so, we develop an algorithm-informed XAI question bank in which user needs for explainability are represented as prototypical questions users might ask about the AI, and use it as a study probe. Our work contributes insights into the design space of XAI, informs efforts to support design practices in this space, and identifies opportunities for future XAI work. We also provide an extended XAI question bank and discuss how it can be used for creating user-centered XAI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {human-AI interaction, user experience, explainable AI},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376430,
author = {Svan\ae{}s, Dag and Barkhuus, Louise},
title = {The Designer's Body as Resource in Design: Exploring Combinations of Point-of-View and Tense},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376430},
doi = {10.1145/3313831.3376430},
abstract = {The design of wearable, tangible and embedded interactive products requires a focus on bodily/kinesthetic aspects of the user experience, that is, how the product "feels" in use. Although best practice in user-centered design (such as iterative design, prototyping, user testing) also applies for this new type of product, the designer's skill set needs to be supplemented with design methods and practices that utilize bodily intelligence and empathy with the user. We present a framework for categorizing such body-centered design practices based on two dimensions: point-of-view (1st, 2nd, 3rd person) and tense (past, present, future). Inspired by Merleau-Ponty's phenomenology of the body, Shusterman's work on somaesthetics, and Buber's theories on intersubjectivity, the framework provides a language for talking about different ways designers and co-designers can utilize their body as a design resource. The intention is not to be prescriptive on method, but to provide guidance during planning, execution and analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {designer training, design process, user experience, somaesthetics, phenomenology, body-centered design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376659,
author = {Fernando, Piyum and Kuznetsov, Stacey},
title = {OScH in the Wild: Dissemination of Open Science Hardware and Implications for HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376659},
doi = {10.1145/3313831.3376659},
abstract = {Open Science Hardware (OScH) refers to open-source alternatives for proprietary scientific equipment. While the OScH movement aims to reduce barriers for scientific experimentation both in and beyond professional labs, disseminating OScH for widespread adoption proves to be challenging in practice. To this end, we examined real-world practices related to the dissemination of OScH through a two-part study. First, we developed an open science hardware, a DIY incubator, and disseminated it through the Instructables website and maker workshops. In parallel, we interviewed eight open science hardware practitioners from different parts of the world. Insights from interviews together with our own self-reflections revealed how different OScH dissemination modalities serve unique purposes. Our findings also reveal several challenges for widespread adoption of OScH and the importance of collaborations between OScH developers. We conclude by discussing the opportunities for HCI to lower barriers for customization, support internationalization of OScH, and scaffold proactive distributed collaborations between developers and users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {open science hardware, maker movement, diy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376569,
author = {Choi, Dasom and Kwak, Daehyun and Cho, Minji and Lee, Sangsu},
title = {"Nobody Speaks That Fast!" An Empirical Study of Speech Rate in Conversational Agents for People with Vision Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376569},
doi = {10.1145/3313831.3376569},
abstract = {The number of people with vision impairments using Conversational Agents (CAs) has increased because of the potential of this technology to support them. As many visually impaired people are accustomed to understanding fast speech, most screen readers or voice assistant systems offer speech rate settings. However, current CAs are designed to interact at a human-like speech rate without considering their accessibility. In this study, we tried to understand how people with vision impairments use CA at a fast speech rate. We conducted a 20-day in-home study that examined the CA use of 10 visually impaired people at default and fast speech rates. We investigated the difference in visually impaired people's CA use with different speech rates and their perception toward CA at each rate. Based on these findings, we suggest considerations for the future design of CA speech rate for those with visual impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {speech rate, people with vision impairments, accessibility, conversational agents},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376492,
author = {Gen\c{c}, H\"{u}seyin Ugur and Coskun, Aykut},
title = {Designing for Social Interaction in the Age of Excessive Smartphone Use},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376492},
doi = {10.1145/3313831.3376492},
abstract = {Excessive smartphone use has negative effects on our social relations as well as on our mental and psychological health. Most of the previous work to avoid these negative effects is based on a top-down approach such as restricting or limiting users' use of smartphones. Diverging from previous work, we followed a bottom-up approach to understand the practice of smartphone use in public settings from the users' perspective. We conducted observations in four coffeehouses, six focus group sessions with 46 participants and three design workshops with 15 designers. We identified five themes that help better understand smartphone use behavior in public settings and four alternative design approaches to mediate this behavior, namely enlighteners, preventers, supporters, and compliers. We discuss the implications of these themes and approaches for designing future interactive technologies aimed at mediating excessive smartphone use behavior.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {focus group design workshop, design for behavioral change, smartphone},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376783,
author = {Smith, C. Estelle and Yu, Bowen and Srivastava, Anjali and Halfaker, Aaron and Terveen, Loren and Zhu, Haiyi},
title = {Keeping Community in the Loop: Understanding Wikipedia Stakeholder Values for Machine Learning-Based Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376783},
doi = {10.1145/3313831.3376783},
abstract = {On Wikipedia, sophisticated algorithmic tools are used to assess the quality of edits and take corrective actions. However, algorithms can fail to solve the problems they were designed for if they conflict with the values of communities who use them. In this study, we take a Value-Sensitive Algorithm Design approach to understanding a community-created and -maintained machine learning-based algorithm called the Objective Revision Evaluation System (ORES)---a quality prediction system used in numerous Wikipedia applications and contexts. Five major values converged across stakeholder groups that ORES (and its dependent applications) should: (1) reduce the effort of community maintenance, (2) maintain human judgement as the final authority, (3) support differing peoples' differing workflows, (4) encourage positive engagement with diverse editor groups, and (5) establish trustworthiness of people and algorithms within the community. We reveal tensions between these values and discuss implications for future research to improve algorithms like ORES.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {wikipedia, community values, ORES, value sensitive algorithm design, machine learning, peer production},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376157,
author = {Komatsu, Takanori and Yamada, Seiji},
title = {Exploring Auditory Information to Change Users' Perception of Time Passing as Shorter},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376157},
doi = {10.1145/3313831.3376157},
abstract = {Although the processing speed of computers has been drastically increasing year by year, users still have to wait for computers to complete tasks or to respond. To cope with this, several studies have proposed presenting certain visual information to users to change their perception of time passing as shorter, e.g., progress bars with animated ribbing or faster/slower virtual clocks. As speech interfaces such as smart speakers are becoming popular, a novel method is required to make users perceive the passing of time as shorter by presenting auditory stimuli. We thus prepared 20 pieces of auditory information as experimental stimuli; that is, 11 auditory stimuli that have the same 10.1-second duration but different numbers of 0.1-second sine-wave sounds and 9 other auditory stimuli that have the same 10.1-second duration and numbers of sounds but different interval patterns between the sounds. We conducted three experiments to figure out which kinds of auditory stimuli can change users' perception of time passing as shorter. We found that a 10.1-second auditory stimulus that has 0.1-second sine-wave sounds appearing 11 times with intervals between the sounds that narrow rapidly in a linear fashion was perceived as shortest at about 9.3 seconds, which was 7.6% shorter than the actual duration of the stimulus. We also found that different interval patterns of sounds in auditory information significantly affected users' perception of time passing as shorter, while different numbers of sounds did not.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {users' perception of time passing, eyes-free interaction, auditory information, filled-duration illusion, waiting time},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376528,
author = {Homewood, Sarah and Boer, Laurens and Vallg\r{a}rda, Anna},
title = {Designers in White Coats: Deploying Ovum, a Fertility Tracking Device},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376528},
doi = {10.1145/3313831.3376528},
abstract = {As self-tracking practices continue to proliferate, there has been a call for a consideration of how the design of these devices influence the users experience of themselves and their bodies beyond utility, efficacy and accuracy. The research product Ovum was designed to facilitate a DIY, shared, domestic experience, rather than an expert-led, individual, clinical experience of fertility tracking. Ovum uses the method of saliva sampling to determine ovulation. This paper unpacks the findings from a three-month long deployment of Ovum with seven couples trying to conceive. Besides an evaluation of the device in terms of the three experiential qualities aimed for in the design process, we report on the consequences of executing a design deployment that resembles a clinical trial. We contribute our experience in order to develop an understanding of how designing for the body places interaction designers in novel and complex situations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {fertility, research through design, ovulation, women's health, self-tracking, menstrual cycles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376456,
author = {Phadke, Shruti and Mitra, Tanushree},
title = {Many Faced Hate: A Cross Platform Study of Content Framing and Information Sharing by Online Hate Groups},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376456},
doi = {10.1145/3313831.3376456},
abstract = {Hate groups are increasingly using multiple social media platforms to promote extremist ideologies. Yet we know little about their communication practices across platforms. How do hate groups (or "in-groups"), frame their hateful agenda against the targeted group or the "out-group?" How do they share information? Utilizing "framing" theory from social movement research and analyzing domains in the shared links, we juxtapose the Facebook and Twitter communication of 72 Southern Poverty Law Center (SPLC) designated hate groups spanning five hate ideologies. Our findings show that hate groups use Twitter for educating the audience about problems with the out-group, maintaining positive self-image by emphasizing in-group's high social status, and for demanding policy changes to negatively affect the out-group. On Facebook, they use fear appeals, call for active participation in group events (membership requests), all while portraying themselves as being oppressed by the out-group and failed by the system. Our study unravels the ecosystem of cross-platform communication by hate groups, suggesting that they use Facebook for group radicalization and recruitment, while Twitter for reaching a diverse follower base.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cross-platform, framing, hate groups, information sharing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376535,
author = {Rumsey, Alyssa and Le Dantec, Christopher A.},
title = {Manufacturing Change: The Impact of Virtual Environments on Real Organizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376535},
doi = {10.1145/3313831.3376535},
abstract = {Manufacturing workplaces are becoming sites of intense change as technologies like IoT and AR/VR are beginning to make deep inroads into how complex products are engi-neered and assembled. These categories of technologies are becoming prominent in manufacturing because they offer potential solutions to the problems of unskilled labor and workforce shortages. Technology has the potential to shift manufacturing in both large and small ways, to better un-derstand how a manufacturing organization might appropri-ate VR, we ran a study with a global aviation manufacturer headquartered the United States. To document the changing nature of work via this class of technologies we conducted a VR study which facilitated access to participant observation and interviews (n=21). Our findings provide initial insights into the organizational impact of VR on human perfor-mance augmentation and skill acquisition revealing the larger infrastructural challenges facing the adoption of con-sumer grade smart technologies in industrial workplace settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {field studies, qualitative methods, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376871,
author = {McNaney, Roisin and Tsekleves, Emmanuel and Synnott, Jonathan},
title = {Future Opportunities for IoT to Support People with Parkinson's},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376871},
doi = {10.1145/3313831.3376871},
abstract = {Recent years have seen an explosion of internet of things (IoT) technologies being released to the market. There has also been an emerging interest in the potentials of IoT devices to support people with chronic health conditions. In this paper, we describe the results of engagements to scope the future potentials of IoT for supporting people with Parkinson's (PwP). We ran a 2-day multi-disciplinary event with professionals with expertise in Parkinson's and IoT, to explore the opportunities, challenges and benefits. We then ran 4 workshops, engaging 13 PwP and caregivers, to scope out the needs, values and desires that the community has for utilizing IoT to monitor their symptoms. This work contributes considerations for future IoT solutions that might support PwP in better understanding their condition, through the provision of objective measurements that correspond to their, currently unmeasured, subjective experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {design, self-monitoring, quantified self, parkinson's, iot},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376170,
author = {Evans, Hayley and Lakshmi, Udaya and Watson, Hue and Ismail, Azra and Sherrill, Andrew M. and Kumar, Neha and Arriaga, Rosa I.},
title = {Understanding the Care Ecologies of Veterans with PTSD},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376170},
doi = {10.1145/3313831.3376170},
abstract = {Post-traumatic stress disorder (PTSD) disproportionately affects United States veterans, yet they may be reluctant to seek or engage in care. We interview 21 participants, including veterans with PTSD, clinicians who treat veterans and friends and family that support veterans through mental health ordeals. We investigate the military identity these veterans share. We explore how this may add to their reluctance in care-seeking behaviors. We also explore the roles of human and non-human intermediaries in ecologies of care and the potential for enhancing patient empowerment in current clinical treatment contexts. We discuss how military culture can be utilized in clinical care, how multiple perspectives can be leveraged to create a more holistic view of the patient, and finally, how veterans can be empowered during treatment. We conclude with recommendations for the design of sociotechnical systems that prioritize the above in support of the mental well-being of veterans with PTSD.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {veteran care, treatment, therapy, ptsd, mental health, care ecologies},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376532,
author = {Parker, Callum and Tomitsch, Martin and Davies, Nigel and Valkanova, Nina and Kay, Judy},
title = {Foundations for Designing Public Interactive Displays That Provide Value to Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376532},
doi = {10.1145/3313831.3376532},
abstract = {Public interactive displays (PID) are a promising technology for providing information and collecting feedback in public spaces. Research on PIDs has shown that, like all public displays, their efficacy is reduced by display blindness. Rather than increase the visual attention-grabbing nature of PIDs, we propose that additional understanding is required around how and when these displays are able to offer value to users. We tackle this through a systematic analysis of PID studies published in the literature, which led to 9 aspects of value across 4 factors: people, location, community, and time. We discuss the identified aspects and their utility for the design of PIDs through a review of our own deployments carried out by 4 different labs across 5 countries. We conclude with a set of recommendations for identifying and optimising the intended value of future PIDs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {public interactive displays, value, literature review, public displays, deployments, design recommendations, in-the-wild},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376680,
author = {Andalibi, Nazanin and Buss, Justin},
title = {The Human in Emotion Recognition on Social Media: Attitudes, Outcomes, Risks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376680},
doi = {10.1145/3313831.3376680},
abstract = {Emotion recognition algorithms recognize, infer, and harvest emotions using data sources such as social media behavior, streaming service use, voice, facial expressions, and biometrics in ways often opaque to the people providing these data. People's attitudes towards emotion recognition and the harms and outcomes they associate with it are important yet unknown. Focusing on social media, we interviewed 13 adult U.S. social media users to fill this gap. We find that people view emotions as insights to behavior, prone to manipulation, intimate, vulnerable, and complex. Many find emotion recognition invasive and scary, associating it with autonomy and control loss. We identify two categories of emotion recognition's risks: individual and societal. We discuss findings' implications for algorithmic accountability and argue for considering emotion data as sensitive. Using a Science and Technology Studies lens, we advocate that technology users should be considered as a relevant social group in emotion recognition advancements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {emotion AI, social media, emotion recognition, privacy, AI ethics, ethics, fairness, algorithmic accountability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376839,
author = {Stemasov, Evgeny and Wagner, Tobias and Gugenheimer, Jan and Rukzio, Enrico},
title = {Mix&amp;Match: Towards Omitting Modelling Through In-Situ Remixing of Model Repository Artifacts in Mixed Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376839},
doi = {10.1145/3313831.3376839},
abstract = {The accessibility of tools to model artifacts is one of the core driving factors for the adoption of Personal Fabrication. Subsequently, model repositories like Thingiverse became important tools in (novice) makers' processes. They allow them to shorten or even omit the design process, offloading a majority of the effort to other parties. However, steps like measurement of surrounding constraints (e.g., clearance) which exist only inside the users' environment, can not be similarly outsourced. We propose Mix&amp;Match a mixed-reality-based system which allows users to browse model repositories, preview the models in-situ, and adapt them to their environment in a simple and immediate fashion. Mix&amp;Match aims to provide users with CSG operations which can be based on both virtual and real geometry. We present interaction patterns and scenarios for Mix&amp;Match, arguing for the combination of mixed reality and model repositories. This enables almost modelling-free personal fabrication for both novices and expert makers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {in-situ previews, personal fabrication, mixed reality, 3D printing, model repositories, in-situ modelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376707,
author = {Schneegass, Christina and Kosch, Thomas and Baumann, Andrea and Rusu, Marius and Hassib, Mariam and Hussmann, Heinrich},
title = {BrainCoDe: Electroencephalography-Based Comprehension Detection during Reading and Listening},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376707},
doi = {10.1145/3313831.3376707},
abstract = {The pervasive availability of media in foreign languages is a rich resource for language learning. However, learners are forced to interrupt media consumption whenever comprehension problems occur. We present BrainCoDe, a method to implicitly detect vocabulary gaps through the evaluation of event-related potentials (ERPs). In a user study (N=16), we evaluate BrainCoDe by investigating differences in ERP amplitudes during listening and reading of known words compared to unknown words. We found significant deviations in N400 amplitudes during reading and in N100 amplitudes during listening when encountering unknown words. To evaluate the feasibility of ERPs for real-time applications, we trained a classifier that detects vocabulary gaps with an accuracy of 87.13% for reading and 82.64% for listening, identifying eight out of ten words correctly as known or unknown. We show the potential of BrainCoDe to support media learning through instant translations or by generating personalized learning content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {language learning, EEG, implicit comprehension detection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376333,
author = {Zhu, Mengjia and Memar, Amirhossein H. and Gupta, Aakar and Samad, Majed and Agarwal, Priyanshu and Visell, Yon and Keller, Sean J. and Colonnese, Nicholas},
title = {PneuSleeve: In-Fabric Multimodal Actuation and Sensing in a Soft, Compact, and Expressive Haptic Sleeve},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376333},
doi = {10.1145/3313831.3376333},
abstract = {Integration of soft haptic devices into garments can improve their usability and wearability for daily computing interactions. In this paper, we introduce PneuSleeve, a fabric-based, compact, and highly expressive forearm sleeve which can render a broad range of haptic stimuli including compression, skin stretch, and vibration. The haptic stimuli are generated by controlling pneumatic pressure inside embroidered stretchable tubes. The actuation configuration includes two compression actuators on the proximal and distal forearm, and four uniformly distributed linear actuators around and tangent to the forearm. Further, to ensure a suitable grip force, two soft mutual capacitance sensors are fabricated and integrated into the compression actuators, and a closed-loop force controller is implemented. We physically characterize the static and dynamic behavior of the actuators, as well as the performance of closed-loop control. We quantitatively evaluate the psychophysical characteristics of the six actuators in a set of user studies. Finally, we show the expressiveness of PneuSleeve by evaluating combined haptic stimuli using subjective assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {closed-loop haptic rendering, skin stretch, wearables, compression, vibration, multimodal haptic display, pneumatic actuation, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376348,
author = {Romat, Hugo and Henry Riche, Nathalie and Hurter, Christophe and Drucker, Steven and Amini, Fereshteh and Hinckley, Ken},
title = {Dear Pictograph: Investigating the Role of Personalization and Immersion for Consuming and Enjoying Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376348},
doi = {10.1145/3313831.3376348},
abstract = {Much of the visualization literature focuses on assessment of visual representations with regard to their effectiveness for understanding data. In the present work, we instead focus on making data visualization experiences more enjoyable, to foster deeper engagement with data. We investigate two strategies to make visualization experiences more enjoyable and engaging: personalization, and immersion. We selected pictographs (composed of multiple data glyphs) as this representation affords creative freedom, allowing people to craft symbolic or whimsical shapes of personal significance to represent data. We present the results of a qualitative study with 12 participants crafting pictographs using a large pen-enabled device and while immersed within a VR environment. Our results indicate that personalization and immersion both have positive impact on making visualizations more enjoyable experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {immersion, personalization, qualitative study, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376234,
author = {Park, Keunwoo and Kim, Daehwa and Heo, Seongkook and Lee, Geehyuk},
title = {MagTouch: Robust Finger Identification for a Smartwatch Using a Magnet Ring and a Built-in Magnetometer},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376234},
doi = {10.1145/3313831.3376234},
abstract = {Completing tasks on smartwatches often requires multiple gestures due to the small size of the touchscreens and the lack of sufficient number of touch controls that are easily accessible with a finger. We propose to increase the number of functions that can be triggered with the touch gesture by enabling a smartwatch to identify which finger is being used. We developed MagTouch, a method that uses a magnetometer embedded in an off-the-shelf smartwatch. It measures the magnetic field of a magnet fixed to a ring worn on the middle finger. By combining the measured magnetic field and the touch location on the screen, MagTouch recognizes which finger is being used. The tests demonstrated that MagTouch can differentiate among the three fingers used to make contacts at a success rate of 95.03%.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {touch, magnetic, smartwatch, finger identification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376350,
author = {Pe\~{n}a-Araya, Vanessa and Bezerianos, Anastasia and Pietriga, Emmanuel},
title = {A Comparison of Geographical Propagation Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376350},
doi = {10.1145/3313831.3376350},
abstract = {Geographical propagation phenomena occur in multiple domains, such as in epidemiology and social media. Propagation dynamics are often complex, and visualizations play a key role in helping subject-matter experts understand and analyze them. However, there is little empirical data about the effectiveness of the various strategies used to visualize geographical propagation. To fill this gap, we conduct an experiment to evaluate the effectiveness of three strategies: an animated map, small-multiple maps, and a single map with glyphs. We compare them under five tasks that vary in one of the following dimensions: propagation scope, direction, speed, peaks, and spatial jumps. Our results show that small-multiple maps perform best overall, but that the effectiveness of each visualization varies depending on the task considered.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {geo-temporal data, propagation, animation, small-multiples},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376145,
author = {Reinders, Samuel and Butler, Matthew and Marriott, Kim},
title = {"Hey Model!" – Natural User Interactions and Agency in Accessible Interactive 3D Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376145},
doi = {10.1145/3313831.3376145},
abstract = {While developments in 3D printing have opened up opportunities for improved access to graphical information for people who are blind or have low vision (BLV), they can provide only limited detailed and contextual information. Interactive 3D printed models (I3Ms) that provide audio labels and/or a conversational agent interface potentially overcome this limitation. We conducted a Wizard-of-Oz exploratory study to uncover the multi-modal interaction techniques that BLV people would like to use when exploring I3Ms, and investigated their attitudes towards different levels of model agency. These findings informed the creation of an I3M prototype of the solar system. A second user study with this model revealed a hierarchy of interaction, with BLV users preferring tactile exploration, followed by touch gestures to trigger audio labels, and then natural language to fill in knowledge gaps and confirm understanding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {individuals with disabilities &amp; assistive technologies, accessibility, touch/haptic/pointing/gesture, input techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376564,
author = {Mudliar, Preeti},
title = {Whither Humane-Computer Interaction? Adult and Child Value Conflicts in the Biometric Fingerprinting for Food},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376564},
doi = {10.1145/3313831.3376564},
abstract = {This paper reports on the value conflicts that beneficiaries experience when engaging in the monthly ritual of the biometric authentication of their fingerprints to claim state-sponsored food entitlements in India. Drawing on value-based orientations to HCI inquiry, the study locates the interactions around the biometric process to illustrate the ways in which beneficiaries find their values of time, dignity, and privacy, consistently disregarded by the interactive demands of the biometric system. Additionally, to cope with these value conflicts, some beneficiaries pass on the responsibilities of completing the biometric process to the children in their families. While adult beneficiaries are vocal and articulate about the value tensions in their lives, children cope with the anxieties of interacting with the biometric process, silently; even as they experience conflicts in their education, play, and study time.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {aadhaar, biometrics, food security, social justice, values},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376474,
author = {Hudson, Lorraine and Amponsah, Clement and Bampoe, Josephine Ohenewa and Marshall, Julie and Owusu, Nana Akua Victoria and Hussein, Khalid and Linington, Jess and Banks Gross, Zoe and Stokes, Jane and McNaney, R\'{o}is\'{\i}n},
title = {Co-Designing Digital Tools to Enhance Speech and Language Therapy Training in Ghana},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376474},
doi = {10.1145/3313831.3376474},
abstract = {Ghana has a population of over 27 million people, of which 1 in 15 may have a communication disability. The number of speech and language therapists (SLTs) available to support these people remains remarkably small, presenting a major workforce challenge. As an emerging profession, there remain significant challenges around educating the first generation of SLTs. Ghana, however, has a healthy digital infrastructure which can be taken advantage of. We describe a comprehensive study which aimed to co-design a set of locally appropriate digital tools to enhance SLT training in Ghana. We contribute insights into how digital tools could support social learning and the transition from student to independent practitioner and future clinical supervisor. We offer a set of design recommendations for creating an online Community of Practice to enhance continuing professional development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {speech and language therapy, co-design, ghana, mobile learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376502,
author = {Salminen, Joni and Guan, Kathleen and Jung, Soon-Gyo and Chowdhury, Shammur A. and Jansen, Bernard J.},
title = {A Literature Review of Quantitative Persona Creation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376502},
doi = {10.1145/3313831.3376502},
abstract = {Quantitative persona creation (QPC) has tremendous potential, as HCI researchers and practitioners can leverage user data from online analytics and digital media platforms to better understand their users and customers. However, there is a lack of a systematic overview of the QPC methods and progress made, with no standard methodology or known best practices. To address this gap, we review 49 QPC research articles from 2005 to 2019. Results indicate three stages of QPC research: Emergence, Diversification, and Sophistication. Sharing resources, such as datasets, code, and algorithms, is crucial to achieving the next stage (Maturity). For practitioners, we provide guiding questions for assessing QPC readiness in organizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {literature review, personas, quantitative persona creation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376692,
author = {Mlakar, Sara and Haller, Michael},
title = {Design Investigation of Embroidered Interactive Elements on Non-Wearable Textile Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376692},
doi = {10.1145/3313831.3376692},
abstract = {As smart textiles are becoming more present in our lives, investigating and designing textile interfaces has started getting more and more attention. Still, very little research has been done on how to design interactive elements for non-wearable textile interfaces for the best recognition, perception, and interaction. In this paper, we present initial assumptions for designing such interfaces, which we derived from working intensively with our partners from the industry. These have been further explored with experts from the field during interviews, and finally tested in a user study. As a conclusion of the study, we define five design recommendations for textile interfaces and present several prototypes that demonstrate them in practice. Our recommendations cover tactile contrast between textures, heights, and shapes; minimal recognizable size of elements; perception of concave and convex shapes as interactive elements; indication of interaction through shape; and recognition of tactile symbols.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {user study, embroidery, expert interviews, smart textiles, non-wearables, design recommendations, textile interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376770,
author = {Salminen, Joni and Jung, Soon-Gyo and Chowdhury, Shammur and Seng\"{u}n, Sercan and Jansen, Bernard J.},
title = {Personas and Analytics: A Comparative User Study of Efficiency and Effectiveness for a User Identification Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376770},
doi = {10.1145/3313831.3376770},
abstract = {Personas are a well-known technique in human computer interaction. However, there is a lack of rigorous empirical research evaluating personas relative to other methods. In this 34-participant experiment, we compare a persona system and an analytics system, both using identical user data, for efficiency and effectiveness for a user identification task. Results show that personas afford faster task completion than the analytics system, as well as outperforming analytics with significantly higher user identification accuracy. Qualitative analysis of think-aloud transcripts shows that personas have other benefits regarding learnability and consistency. However, the analytics system affords insights and capabilities that personas cannot due to inherent design differences. Findings support the use of personas to learn about users, empirically confirming some of the stated benefits in the literature, while also highlighting the limitations of personas that may necessitate the use of accompanying methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mixed methods, personas, analytics systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376599,
author = {Semertzidis, Nathan and Scary, Michaela and Andres, Josh and Dwivedi, Brahmi and Kulwe, Yutika Chandrashekhar and Zambetta, Fabio and Mueller, Florian Floyd},
title = {Neo-Noumena: Augmenting Emotion Communication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376599},
doi = {10.1145/3313831.3376599},
abstract = {The subjective experience of emotion is notoriously difficult to interpersonally communicate. We believe that technology can challenge this notion through the design of neuroresponsive systems for interpersonal communication. We explore this through "Neo-Noumena", a communicative neuroresponsive system that uses brain-computer interfacing and artificial intelligence to read one's emotional states and dynamically represent them to others in mixed reality through two head-mounted displays. In our study five participant pairs were given Neo-Noumena for three days, using the system freely. Measures of emotional competence demonstrated a statistically significant increase in participants' ability to interpersonally regulate emotions. Furthermore, participant interviews revealed themes regarding Spatiotemporal Actualization, Objective Representation, and Preternatural Transmission. We also suggest design strategies for future augmented emotion communication systems. We intend that work gives guidance towards a future in which our ability to interpersonally communicate emotion is augmented beyond traditional experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {eeg, emotion recognition, emotion communication, mixed reality, machine learning, brain-computer interfacing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376181,
author = {Kong, Ha-Kyung and Karahalios, Karrie},
title = {Addressing Cognitive and Emotional Barriers in Parent-Clinician Communication through Behavioral Visualization Webtools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376181},
doi = {10.1145/3313831.3376181},
abstract = {Effective communication between clinicians and parents of young children with developmental delays can decrease parents' anxiety, help them handle bad news, and improve their adherence to proposed interventions. However, parents have reported dissatisfaction regarding their current communication with clinicians, and they face cognitive and emotional challenges when discussing their child's developmental delays. In this paper, we present visualization as a facilitator of parent-clinician communication and how it could address existing communication challenges. Parents and clinicians anticipated visualization webtools would aid their communication by helping parents gain a better understanding of their child, acting as objective evidence, and highlighting the strength of the child as well as important medical concepts. In addition, visualization can act as a longitudinal record, helping parents track, explore, and share their child's developmental progress. Finally, we propose visualization as a tool to guide parents in their transition from feeling emotional and disempowered to advocating with confidence.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {clinical communication, developmental delays, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376248,
author = {Hsu, Chen-Yuan and Wei, Li-Yi and You, Lihua and Zhang, Jian Jun},
title = {Autocomplete Element Fields},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376248},
doi = {10.1145/3313831.3376248},
abstract = {Aggregate elements are ubiquitous in natural and man-made objects. Interactively authoring these elements with varying anisotropy and deformability can require high artistic skills and manual labor. To reduce input workload and enhance output quality, we present an autocomplete system that can help users distribute and align such elements over different domains. Through a brushing interface, users can place and mix a few elements, and let our system automatically populate more elements for the remaining output. Furthermore, aggregate elements often require proper direction/scalar fields for proper arrangements, but fully specifying such fields across entire domains can be difficult or inconvenient for ordinary users. To address this usability challenge, we formulate element fields that can smoothly orient all the elements based on partial user specifications without requiring full input fields in any step. We validate our prototype system with a pilot user study and show applications in design, collage, and modeling.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {element, anisotropy, field, interface, synthesis, modeling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376549,
author = {Trieu, Penny and Baym, Nancy K.},
title = {Private Responses for Public Sharing: Understanding Self-Presentation and Relational Maintenance via Stories in Social Media},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376549},
doi = {10.1145/3313831.3376549},
abstract = {With nearly two billion users, social media Stories-an ephemeral format of sharing-are increasingly popular and projected to overtake sharing via public feeds. Sharing via Stories differs from Feeds sharing by removing the visible feedback (e.g. "likes" and "comments") which has come to characterize social media. Given the salience of responses visibility to self-presentation and relational maintenance in social media literature, we conducted semi-structured interviews (N = 22) to explore how people understand these processes when using Stories. We find that users have lower expectations for responses with Stories and experience lower pressure for self-presentation. This fosters more frequent sharing and a sense of daily connectedness, which strong ties can find valuable. Finally, the act of viewing takes on new significance of signaling attention when made known to the sharer. Our findings point to the importance of effort and attention in understanding responses on social media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {self-presentation, relational maintenance, stories, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376392,
author = {Ogbonnaya-Ogburu, Ihudiya Finda and Smith, Angela D.R. and To, Alexandra and Toyama, Kentaro},
title = {Critical Race Theory for HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376392},
doi = {10.1145/3313831.3376392},
abstract = {The human-computer interaction community has made some efforts toward racial diversity, but the outcomes remain meager. We introduce critical race theory and adapt it for HCI to lay a theoretical basis for race-conscious efforts, both in research and within our community. Building on the theory's original tenets, we argue that racism is pervasive in everyday socio-technical systems; that the HCI community is prone to "interest convergence", where concessions to inclusion require benefits to those in power; and that the neoliberal underpinnings of the technology industry itself propagate racism. Critical race theory uses storytelling as a means to upend deep-seated assumptions, and we relate several personal stories to highlight ongoing problems of race in HCI. The implications: all HCI research must be attuned to issues of race; participation of underrepresented minorities must be sought in all of our activities; and as a community, we cannot become comfortable while racial disparities exist.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {storytelling, critical race theory, theory, race, racism},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376435,
author = {Ernala, Sindhu Kiranmai and Burke, Moira and Leavitt, Alex and Ellison, Nicole B.},
title = {How Well Do People Report Time Spent on Facebook? An Evaluation of Established Survey Questions with Recommendations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376435},
doi = {10.1145/3313831.3376435},
abstract = {Many studies examining social media use rely on self-report survey questions about how much time participants spend on social media platforms. Because they are challenging to answer accurately and susceptible to various biases, these self-reported measures are known to contain error -- although the specific contours of this error are not well understood. This paper compares data from ten self-reported Facebook use survey measures deployed in 15 countries (N = 49,934) against data from Facebook's server logs to describe factors associated with error in commonly used survey items from the literature. Self-reports were moderately correlated with actual Facebook use (r = 0.42 for the best-performing question), though participants significantly overestimated how much time they spent on Facebook and underestimated the number of times they visited. People who spent a lot of time on the platform were more likely to misreport their time, as were teens and younger adults, which is notable because of the high reliance on college-aged samples in many fields. We conclude with recommendations on the most accurate ways to collect time-spent data via surveys.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {survey validation, time spent, self-reports, well-being},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376267,
author = {Tigwell, Garreth W. and Gorman, Benjamin M. and Menzies, Rachel},
title = {Emoji Accessibility for Visually Impaired People},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376267},
doi = {10.1145/3313831.3376267},
abstract = {Emoji are graphical symbols that appear in many aspects of our lives. Worldwide, around 36 million people are blind and 217 million have a moderate to severe visual impairment. This portion of the population may use and encounter emoji, yet it is unclear what accessibility challenges emoji introduce. We first conducted an online survey with 58 visually impaired participants to understand how they use and encounter emoji online, and the challenges they experience. We then conducted 11 interviews with screen reader users to understand more about the challenges reported in our survey findings. Our interview findings demonstrate that technology is both an enabler and a barrier, emoji descriptors can hinder communication, and therefore the use of emoji impacts social interaction. Using our findings from both studies, we propose best practice when using emoji and recommendations to improve the future accessibility of emoji for visually impaired people.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {emoji, cmc, visual impairments, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376870,
author = {Yuan, Arianna and Li, Yang},
title = {Modeling Human Visual Search Performance on Realistic Webpages Using Analytical and Deep Learning Methods},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376870},
doi = {10.1145/3313831.3376870},
abstract = {Modeling visual search not only offers an opportunity to predict the usability of an interface before actually testing it on real users but also advances scientific understanding about human behavior. In this work, we first conduct a set of analyses on a large-scale dataset of visual search tasks on realistic webpages. We then present a deep neural network that learns to predict the scannability of webpage content, i.e., how easy it is for a user to find a specific target. Our model leverages both heuristic-based features such as target size and unstructured features such as raw image pixels. This approach allows us to model complex interactions that might be involved in a realistic visual search task, which can not be achieved by traditional analytical models. We analyze the model behavior to offer our insights into how the salience map learned by the model aligns with human intuition.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {deep learning, visual attention, webpage, performance modeling, scannability, convolutional neural network},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376708,
author = {Seering, Joseph and Luria, Michal and Ye, Connie and Kaufman, Geoff and Hammer, Jessica},
title = {It Takes a Village: Integrating an Adaptive Chatbot into an Online Gaming Community},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376708},
doi = {10.1145/3313831.3376708},
abstract = {While the majority of research in chatbot design has focused on creating chatbots that engage with users one-on-one, less work has focused on the design of conversational agents for online communities. In this paper we present results from a three week test of a social chatbot in an established online community. During this study, the chatbot "grew up" from "birth" through its teenage years, engaging with community members and "learning" vocabulary from their conversations. We discuss the design of this chatbot, how users' interactions with it evolved over the course of the study, and how it impacted the community as a whole. We discuss how we addressed challenges in developing a chatbot whose vocabulary could be shaped by users, and conclude with implications for the role of machine learning in social interactions in online communities and potential future directions for design of community-based chatbots.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {long-term study, interaction design, chatbot, babybot, machine learning, twitch, AI, community interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376312,
author = {Sauv\'{e}, Kim and Potts, Dominic and Alexander, Jason and Houben, Steven},
title = {A Change of Perspective: How User Orientation Influences the Perception of Physicalizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376312},
doi = {10.1145/3313831.3376312},
abstract = {As physicalizations encode data in their physical 3D form, the orientation in which the user is viewing the physicalization may impact the way the information is perceived. However, this relation between user orientation and perception of physical properties is not well understood or studied. To investigate this relation, we conducted an experimental study with 20 participants who viewed 6 exemplars of physicalizations from 4 different perspectives. Our findings show that perception is directly influenced by user orientation as it affects (i) the number and type of clusters, (ii) anomalies and (iii) extreme values identified within a physicalization. Our results highlight the complexity and variability of the relation between user orientation and perception of physicalizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data physicalization, user orientation, physical visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376653,
author = {Tuli, Anupriya and Chopra, Shaan and Singh, Pushpendra and Kumar, Neha},
title = {Menstrual (Im)Mobilities and Safe Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376653},
doi = {10.1145/3313831.3376653},
abstract = {In cultural contexts where menstruation is a stigmatized health topic, daily management of menstrual hygiene comes with its set of challenges. Our research aims to identify and examine such challenges faced during menstruation in the urban environs of Delhi, India. Through participatory design activities and interviews conducted with 35 participants who identified as menstruating and female, and a survey with 139 responses, we investigate how participants deal with their periods on the go. We also examine participants' conceptualizations of safe spaces, where they are able to deal with their period on their own terms. Finally, we discuss how menstrual mobilities are being, and might be, supported through technology-based interventions for a third space, targeting the legibility, literacy, and legitimacy of surrounding environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {safe spaces, hci4d, menstrual health, india, mobilities, menstruation, menstrual hygiene},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376617,
author = {Zhu, Junyi and Blumberg, Lotta-Gili and Zhu, Yunyi and Nisser, Martin and Carlson, Ethan Levi and Wen, Xin and Shum, Kevin and Quaye, Jessica Ayeley and Mueller, Stefanie},
title = {CurveBoards: Integrating Breadboards into Physical Objects to Prototype Function in the Context of Form},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376617},
doi = {10.1145/3313831.3376617},
abstract = {CurveBoards are breadboards integrated into physical objects. In contrast to traditional breadboards, CurveBoards better preserve the object's look and feel while maintaining high circuit fluidity, which enables designers to exchange and reposition components during design iteration. Since CurveBoards are fully functional, i.e., the screens are displaying content and the buttons take user input, designers can test interactive scenarios and log interaction data on the physical prototype while still being able to make changes to the component layout and circuit design as needed. We present an interactive editor that enables users to convert 3D models into CurveBoards and discuss our fabrication technique for making CurveBoard prototypes. We also provide a technical evaluation of CurveBoard's conductivity and durability and summarize informal user feedback.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personal fabrication, breadboards, electronic prototyping},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376826,
author = {Hansen, Derek L. and Hughes, Amanda Lee and Cram, Sophie and Harker, Austin Bond and Ashton, Brinnley and Hirschi, Karli and Dorton, Ben and Bothwell, Nate and Stevens, Ashley},
title = {The DELAY Framework: Designing for Extended LAtencY},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376826},
doi = {10.1145/3313831.3376826},
abstract = {This paper introduces the Designing for Extended Latency (DELAY) Framework meant to inspire new systems that support social interaction in high-latency settings such as interplanetary communication, intermittent internet access, and time-zone incompatibilities. The framework includes six dimensions: Goal, Communication Genre, Sequencing, Cardinality, Mutability, and Responsiveness. We describe the iterative design process used to create the Framework, as well as three novel prototypes designed to increase social connectedness and social presence in high-latency situations: 1) the InSync app that allows partners to perform activities simultaneously even though they only see proof of their synchronicity later; 2) the After the Beep system that lets users leave IoT messages that are triggered by the recipients; and 3) the Surrogate platform where players play group battle games against "surrogate" artificial intelligence avatars that mimic unavailable individuals. Data from two design workshops validates the usefulness of the framework for generating new solutions to high-latency scenarios.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {high-latency, social connectedness, delay framework, interpersonal communication, interplanetary communication, social presence, delayed communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376364,
author = {Pschetz, Larissa and Dixon, Billy and Pothong, Kruakae and Bailey, Arlene and Glean, Allister and Soares, Luis Louren\c{c}o and Enright, Jessica A.},
title = {Designing Distributed Ledger Technologies for Social Change: The Case of CariCrop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376364},
doi = {10.1145/3313831.3376364},
abstract = {Distributed ledger technologies (DLTs) have been celebrated for promoting transparency, trust, and efficiency in several domains. However, recent research has also pointed out the potential of these technologies to increase power asymmetries and deepen social inequality. In this paper, we contribute to this discussion by reporting on a collective effort of academics, development partners, local authorities, businesses, and farming groups to look at the potential of DLTs, particularly Blockchains, to support socio-economic development in rural communities in the Caribbean. We present a series of design concepts resulting from this effort and reflect on a method to facilitate stakeholders' experience of possible implementations and enable them to voice concerns, preferences, and expectations. Results from workshops with different groups of stakeholders contribute insights into opportunities and limitations of these applications to enable social development and to level the playing field in agricultural exchanges in developing countries.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {agricultural development, distributed ledger technologies, blockchain, farming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376315,
author = {Strengers, Yolande and Qu, Lizhen and Xu, Qiongkai and Knibbe, Jarrod},
title = {Adhering, Steering, and Queering: Treatment of Gender in Natural Language Generation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376315},
doi = {10.1145/3313831.3376315},
abstract = {Natural Language Generation (NLG) supports the creation of personalized, contextualized, and targeted content. However, the algorithms underpinning NLG have come under scrutiny for reinforcing gender, racial, and other problematic biases. Recent research in NLG seeks to remove these biases through principles of fairness and privacy. Drawing on gender and queer theories from sociology and Science and Technology studies, we consider how NLG can contribute towards the advancement of gender equity in society. We propose a conceptual framework and technical parameters for aligning NLG with feminist HCI qualities. We present three approaches: (1) adhering to current approaches of removing sensitive gender attributes, (2) steering gender differences away from the norm, and (3) queering gender by troubling stereotypes. We discuss the advantages and limitations of these approaches across three hypothetical scenarios; newspaper headlines, job advertisements, and chatbots. We conclude by discussing considerations for implementing this framework and related ethical and equity agendas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {natural language generation, feminist hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376410,
author = {Tholander, Jakob and Normark, Maria},
title = {Crafting Personal Information - Resistance, Imperfection, and Self-Creation in Bullet Journaling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376410},
doi = {10.1145/3313831.3376410},
abstract = {Bullet journals are hand-written and self-created combinations of calendar, journal and planner. Central to this practice is how personal information is managed through a craft-based process. Based on a qualitative study, we discuss a set of themes that emerged in our analysis of this practice. We discuss how open-ended use of various materials for crafting of personal information engages in: 1) deliberate and strategic boundary work of what information to include and how combinations of data provide holistic and novel views of practitioner's life situations; 2) processes of self-creation and reflection on personal life trajectories; 3) appreciation of ourselves and the world around us as imperfect; and 4) ways of resisting the "business-like efficiency" that come with the large quantities of information that permeate contemporary life. We propose that this opens up new directions for thinking about how technologies of personal information may come into play in people's lives.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {making by hand, bullet journaling, personal informatics, crafts, self-creation, imperfection, analogue materials},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376278,
author = {Chapko, Dorota and Frumiento, Pino and Edwards, Nalini and Emeh, Lizzie and Kennedy, Donald and McNicholas, David and Overton, Michaela and Snead, Mark and Steward, Robyn and Sutton, Jenny M. and Jeffreys, Evie and Long, Catherine and Croll-Knight, Jess and Connors, Ben and Castell-Ward, Sam and Coke, David and McPeake, Bethany and Renel, William and McGinley, Chris and Remington, Anna and Whittuck, Dora and Kieffer, John and Ewans, Sarah and Williams, Mark and Grierson, Mick},
title = {"We Have Been Magnified for Years - Now You Are under the Microscope!": Co-Researchers with Learning Disabilities Created an Online Survey to Challenge Public Understanding of Learning Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376278},
doi = {10.1145/3313831.3376278},
abstract = {Public attitudes towards learning disabilities (LDs) are generally reported as positive, inclusive and empathetic. However, these findings do not reflect the lived experiences of people with LDs. To shed light on this disparity, a team of co-researchers with LDs created the first online survey to challenge public understanding of LDs, asking questions in ways that are important to them and represent how they see themselves. Here, we describe and evaluate the process of creating an accessible survey platform and an online survey in a research team consisting of academic and non-academic professionals with and without LDs or autism. Through this inclusive research process, the co-designed survey met the expectations of the co-researchers and was well-received by the initial survey respondents. We reflect on the co-researchers' perspectives following the study completion, and consider the difficulties and advantages we encountered deploying such approaches and their potential implications on future survey data analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {disability, design, attitudes, video, survey, participatory/inclusive research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376429,
author = {Biggs, Heidi R. and Desjardins, Audrey},
title = {High Water Pants: Designing Embodied Environmental Speculation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376429},
doi = {10.1145/3313831.3376429},
abstract = {In this paper, we present the High Water Pants: speculative wearable technology which makes climate change tangible for everyday cyclists. The pants work by mechanically shortening when a cyclist wearing the pants enters an area of Seattle, USA, which is projected to be impacted by sea-level rise in 30-80 years. This interaction 'bends time' by allowing cyclists to feel future climate change data in the present. First, we discuss the research through design process of creating the High Water Pants including foundational research, a description of the design concept and results of a preliminary study with the pants. Second, we discuss three implications of the pants for human-computer interaction (HCI): (1) they offer the concept of a 'present/future' paradigm for embodied speculation, (2) our research process demonstrates how to successfully involve more-than-human perspectives, and (3) we articulate how the High Water Pants respond to shifts in HCI's framing of sustainability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {speculative design, sustainability, wearables, research through design, cycling, embodied speculation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376587,
author = {Pei, Lucy and Crooks, Roderic},
title = {Attenuated Access: Accounting for Startup, Maintenance, and Affective Costs in Resource-Constrained Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376587},
doi = {10.1145/3313831.3376587},
abstract = {The term "digital divide" indexes a body of research at the intersection of digital technology and social equity, including research on inequality that criticizes and recapitulates the original concept. Based on a qualitative study at a community literacy center serving resettled refugees and immigrants, we show that the digital divide framework rests on a distributive logic, one that implies that distributing access to digital technology constitutes a form of social equity. Because this framework only considers valorized goods, skills, and uses, research has frequently ignored the startup, maintenance, and affective costs we found accompanied digital access for our participants. To account for these costs, we propose a theoretical adjustment to the digital divide framework, one where design is an act of configuring both costs and benefits together. We argue that considering such costs enables HCI researchers to engage more effectively with host communities in the non-innocent work of confronting inequity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {immigrants and resettled refugees, digital access, social justice, digital divide, equity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376674,
author = {Thakkar, Divy and Kumar, Neha and Sambasivan, Nithya},
title = {Towards an AI-Powered Future That Works for Vocational Workers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376674},
doi = {10.1145/3313831.3376674},
abstract = {The future of work is speculated to undergo profound change with increased automation. Predictable jobs are projected to face high susceptibility to technological developments. Many economies in Global South are built around outsourcing and manual labour, facing a risk of job insecurity. In this paper, we examine the perceptions and practices around automated futures of work among a population that is highly vulnerable to algorithms and robots entering rule-based and manual domains: vocational technicians. We present results from participatory action research with 38 vocational technician students of low socio-economic status in Bangalore, India. Our findings show that technicians were unfamiliar with the growth of automation, but upon learning about it, articulated an emic vision for a future of work in-line with their value systems. Participants felt excluded by current technological platforms for skilling and job-seeking. We present opportunities for technology industry and policy makers to build a future of work for vulnerable communities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {automation, ai, vocational technicians, algorithmic fairness, policy, skills, hci4d, india, future of work},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376411,
author = {Zuckerman, Oren and Walker, Dina and Grishko, Andrey and Moran, Tal and Levy, Chen and Lisak, Barak and Wald, Iddo Yehoshua and Erel, Hadas},
title = {Companionship Is Not a Function: The Effect of a Novel Robotic Object on Healthy Older Adults' Feelings of "Being-Seen"},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376411},
doi = {10.1145/3313831.3376411},
abstract = {One of the challenges faced by healthy older adults is experiencing feelings of not "being-seen". Companion robots, commonly designed with zoomorphic or humanoid appearance show success among clinical older adults, but healthy older adults find them degrading. We present the design and implementation of a novel non-humanoid robot. The robot's primary function is a cognitive word game. Social interaction is conveyed as a secondary function, using non-verbal gestures, inspired by dancers' movement. In a lab study, 39 healthy older adults interacted with the prototype in 3 conditions: Companion-Function; Game-Function; and No-Function. Results show the non-verbal gestures were associated with feelings of "being-seen", and willingness to accept the robot into their home was influenced by its function, with game significantly higher than companion. We conclude that robot designers should further explore the potential of non-humanoid robots as a new class of companion robots, with a primary function that is not companionship.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {tangible interaction, loneliness, social-interaction, successful aging, older adults, non-humanoid robot, acceptance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376320,
author = {Hettiachchi, Danula and Sarsenbayeva, Zhanna and Allison, Fraser and van Berkel, Niels and Dingler, Tilman and Marini, Gabriele and Kostakos, Vassilis and Goncalves, Jorge},
title = {"Hi! I Am the Crowd Tasker" Crowdsourcing through Digital Voice Assistants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376320},
doi = {10.1145/3313831.3376320},
abstract = {Inspired by the increasing prevalence of digital voice assistants, we demonstrate the feasibility of using voice interfaces to deploy and complete crowd tasks. We have developed Crowd Tasker, a novel system that delivers crowd tasks through a digital voice assistant. In a lab study, we validate our proof-of-concept and show that crowd task performance through a voice assistant is comparable to that of a web interface for voice-compatible and voice-based crowd tasks for native English speakers. We also report on a field study where participants used our system in their homes. We find that crowdsourcing through voice can provide greater flexibility to crowd workers by allowing them to work in brief sessions, enabling multi-tasking, and reducing the time and effort required to initiate tasks. We conclude by proposing a set of design guidelines for the creation of crowd tasks for voice and the development of future voice-based crowdsourcing systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {voice user interface, smart speakers, digital voice assistants, crowdsourcing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376132,
author = {Wang, Bryan and Grossman, Tovi},
title = {BlyncSync: Enabling Multimodal Smartwatch Gestures with Synchronous Touch and Blink},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376132},
doi = {10.1145/3313831.3376132},
abstract = {Input techniques have been drawing abiding attention along with the continual miniaturization of personal computers. In this paper, we present BlyncSync, a novel multi-modal gesture set that leverages the synchronicity of touch and blink events to augment the input vocabulary of smartwatches with a rapid gesture, while at the same time, offers a solution to the false activation problem of blink-based input. BlyncSync contributes the concept of a mutual delimiter, where two modalities are used to jointly delimit the intention of each other's input. A study shows that BlyncSync is 33% faster than using a baseline input delimiter (physical smartwatch button), with only 150ms in overhead cost compared to traditional touch events. Furthermore, our data indicates that the gesture can be tuned to elicit a true positive rate of 97% and a false positive rate of 1.68%.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mobile hci, smartwatch, mutual delimiter, blyncsync, gaze ui, wearables},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376741,
author = {Klefeker, Josephine and striegl, libi and Devendorf, Laura},
title = {What HCI Can Learn from ASMR: Becoming Enchanted with the Mundane},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376741},
doi = {10.1145/3313831.3376741},
abstract = {In this paper we explore how the qualities of Autonomous Sensory Meridian Response (ASMR) media - its pairing of sonic and visual design, ability to subvert fast-paced technology for slow experiences, production of somatic responses, and attention to the everyday-might reveal new design possibilities for interactions with wearable technology. We recount our year-long design inquiry into the subject which began with an interview with a "live" ASMR creator and design probes, a series of first-person design exercises, and resulted in the creation of two interactive garments for attending, noticing, and becoming enchanted with our our everyday surroundings. We conclude by suggesting that these ASMR inspired designs cultivate personal, intimate, embodied, and felt practices of attention within our everyday, mundane, environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {asmr media, enchantment, smart textiles, wearable technology, sonic interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376842,
author = {Goffin, Pascal and Blascheck, Tanja and Isenberg, Petra and Willett, Wesley},
title = {Interaction Techniques for Visual Exploration Using Embedded Word-Scale Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376842},
doi = {10.1145/3313831.3376842},
abstract = {We describe a design space of view manipulation interactions for small data-driven contextual visualizations (word-scale visualizations). These interaction techniques support an active reading experience and engage readers through exploration of embedded visualizations whose placement and content connect them to specific terms in a document. A reader could, for example, use our proposed interaction techniques to explore word-scale visualizations of stock market trends for companies listed in a market overview article. When readers wish to engage more deeply with the data, they can collect, arrange, compare, and navigate the document using the embedded word-scale visualizations, permitting more visualization-centric analyses. We support our design space with a concrete implementation, illustrate it with examples from three application domains, and report results from two experiments. The experiments show how view manipulation interactions helped readers examine embedded visualizations more quickly and with less scrolling and yielded qualitative feedback on usability and future opportunities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interaction techniques, text visualization, word-scale visualization, information visualization, glyphs},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376482,
author = {Burke, Moira and Cheng, Justin and de Gant, Bethany},
title = {Social Comparison and Facebook: Feedback, Positivity, and Opportunities for Comparison},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376482},
doi = {10.1145/3313831.3376482},
abstract = {People compare themselves to one another both offline and online. The specific online activities that worsen social comparison are partly understood, though much existing research relies on people recalling their own online activities post hoc and is situated in only a few countries. To better understand social comparison worldwide and the range of associated behaviors on social media, a survey of 38,000 people from 18 countries was paired with logged activity on Facebook for the prior month. People who reported more frequent social comparison spent more time on Facebook, had more friends, and saw proportionally more social content on the site. They also saw greater amounts of feedback on friends' posts and proportionally more positivity. There was no evidence that social comparison happened more with acquaintances than close friends. One in five respondents recalled recently seeing a post that made them feel worse about themselves but reported conflicting views: half wished they hadn't seen the post, while a third felt very happy for the poster. Design opportunities are discussed, including hiding feedback counts, filters for topics and people, and supporting meaningful interactions, so that when comparisons do occur, people are less affected by them.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {well-being, social comparison, envy, social media, facebook},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376479,
author = {Mayer, Sven and Laput, Gierad and Harrison, Chris},
title = {Enhancing Mobile Voice Assistants with WorldGaze},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376479},
doi = {10.1145/3313831.3376479},
abstract = {Contemporary voice assistants require that objects of inter-est be specified in spoken commands. Of course, users are often looking directly at the object or place of interest ? fine-grained, contextual information that is currently unused. We present WorldGaze, a software-only method for smartphones that provides the real-world gaze location of a user that voice agents can utilize for rapid, natural, and precise interactions. We achieve this by simultaneously opening the front and rear cameras of a smartphone. The front-facing camera is used to track the head in 3D, including estimating its direction vector. As the geometry of the front and back cameras are fixed and known, we can raycast the head vector into the 3D world scene as captured by the rear-facing camera. This allows the user to intuitively define an object or region of interest using their head gaze. We started our investigations with a qualitative exploration of competing methods, before developing a functional, real-time implementation. We conclude with an evaluation that shows WorldGaze can be quick and accurate, opening new multimodal gaze+voice interactions for mobile voice agents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {mobile interaction, worldgaze, interaction techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376477,
author = {Das, Maitraye and Borgos-Rodriguez, Katya and Piper, Anne Marie},
title = {Weaving by Touch: A Case Analysis of Accessible Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376477},
doi = {10.1145/3313831.3376477},
abstract = {The rise of maker communities and fabrication tools creates new opportunities for participation in design work. With this has come an interest in increasing the accessibility of making for people with disabilities, which has mainly emphasized independence and empowerment through the creation of more accessible fabrication tools. To understand and rethink the notion of accessible making, we analyze the context and practices of a particular site of making: the communal weaving studio within an assisted living facility for people with vision impairments. Our analysis helps reconsider the material and social processes that constitute accessible making, including the ways makers attend to interactive material properties, negotiate co-creative embodied work, and value the labor of making. We discuss future directions for design and research on accessible making while highlighting tensions around assistance, collaboration, and how disabled labor is valued.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {disability, design, vision impairments, materiality, making},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376238,
author = {Liang, Yuan and Fan, Hsuan Wei and Fang, Zhujun and Miao, Leiying and Li, Wen and Zhang, Xuan and Sun, Weibin and Wang, Kun and He, Lei and Chen, Xiang 'Anthony'},
title = {OralCam: Enabling Self-Examination and Awareness of Oral Health Using a Smartphone Camera},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376238},
doi = {10.1145/3313831.3376238},
abstract = {Due to a lack of medical resources or oral health awareness, oral diseases are often left unexamined and untreated, affecting a large population worldwide. With the advent of low-cost, sensor-equipped smartphones, mobile apps offer a promising possibility for promoting oral health. However, to the best of our knowledge, no mobile health (mHealth) solutions can directly support a user to self-examine their oral health condition. This paper presents OralCam, the first interactive app that enables end-users' self-examination of five common oral conditions (diseases or early disease signals) by taking smartphone photos of one's oral cavity. OralCam allows a user to annotate additional information (e.g. living habits, pain, and bleeding) to augment the input image, and presents the output hierarchically, probabilistically and with visual explanations to help a laymen user understand examination results. Developed on our in-house dataset that consists of 3,182 oral photos annotated by dental experts, our deep learning based framework achieved an average detection sensitivity of 0.787 over five conditions with high localization accuracy. In a week-long in-the-wild user study (N=18), most participants had no trouble using OralCam and interpreting the examination results. Two expert interviews further validate the feasibility of OralCam for promoting users' awareness of oral health.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {artificial intelligence, deep learning, mobile health, oral health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376756,
author = {Ku, Pin-Sung and Gong, Jun and Wu, Te-Yen and Wei, Yixin and Tang, Yiwen and Ens, Barrett and Yang, Xing-Dong},
title = {Zippro: The Design and Implementation of An Interactive Zipper},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376756},
doi = {10.1145/3313831.3376756},
abstract = {Zippers are common in a wide variety of objects that we use daily. This work investigates how we can take advantage of such common daily activities to support seamless interaction with technology. We look beyond simple zipper-sliding interactions explored previously to determine how to weave foreground and background interactions into a vocabulary of natural usage patterns. We begin by conducting two user studies to understand how people typically interact with zippers. The findings identify several opportunities for zipper input and sensing, which inform the design of Zippro, a self-contained prototype zipper slider, which we evaluate with a standard jacket zipper. We conclude by demonstrating several applications that make use of the identified foreground and background input methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wearable, zipper, smart things},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376779,
author = {Ku, Pin-Sung and Shao, Qijia and Wu, Te-Yen and Gong, Jun and Zhu, Ziyan and Zhou, Xia and Yang, Xing-Dong},
title = {ThreadSense: Locating Touch on an Extremely Thin Interactive Thread},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376779},
doi = {10.1145/3313831.3376779},
abstract = {We propose a new sensing technique for one-dimensional touch input workable on an interactive thread of less than 0.4 mm thick. Our technique locates up to two touches using impedance sensing with a spacing resolution unachievable by the existing methods. Our approach is also unique in that it locates a touch based on a mathematical model describing the change in thread impedance in relation to the touch locations. This allows the system to be easily calibrated by the user touching a known location(s) on the thread. The system can thus quickly adapt to various environmental settings and users. A system evaluation showed that our system could track the slide motion of a finger with an average error distance of 6.13 mm and 4.16 mm using one and five touches for calibration, respectively. The system could also distinguish between single touch and two concurrent touches with an accuracy of 99% and could track two concurrent touches with an average error distance of 8.55 mm. We demonstrate new interactions enabled by our sensing approach in several unique applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touch input, fabric, thread, impedance sensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376506,
author = {Schaekermann, Mike and Beaton, Graeme and Sanoubari, Elaheh and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Ambiguity-Aware AI Assistants for Medical Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376506},
doi = {10.1145/3313831.3376506},
abstract = {Artificial intelligence (AI) assistants for clinical decision making show increasing promise in medicine. However, medical assessments can be contentious, leading to expert disagreement. This raises the question of how AI assistants should be designed to handle the classification of ambiguous cases. Our study compared two AI assistants that provide classification labels for medical time series data along with quantitative uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware AI based on real-world expert discussions to highlight cases likely to lead to expert disagreement, and to present arguments for conflicting classification choices. Our results demonstrate that ambiguity-aware AI can alter expert workflows by significantly increasing the proportion of contentious cases reviewed. We also found that the relevance of AI-provided arguments (selected from guidelines either randomly or by experts) affected experts' accuracy at revising AI-suggested labels. Our work contributes a novel perspective on the design of AI for contentious clinical assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {medical data analysis, artificial intelligence, ambiguity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376856,
author = {Tigwell, Garreth W. and Crabb, Michael},
title = {Household Surface Interactions: Understanding User Input Preferences and Perceived Home Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376856},
doi = {10.1145/3313831.3376856},
abstract = {Households contain a variety of surfaces that are used in a number of activity contexts. As ambient technology becomes commonplace in our homes, it is only a matter of time before these surfaces become linked to computer systems for Household Surface Interaction (HSI). However, little is known about the user experience attached to HSI, and the potential acceptance of HSI within modern homes. To address this problem, we ran a mixed methods user study with 39 participants to examine HSI using nine household surfaces and five common gestures (tap, press, swipe, drag, and pinch). We found that under the right conditions, surfaces with some amount of texture can enhance HSI. Furthermore, perceived good and poor user experience varied among participants for surface type indicating individual preferences. We present findings and design considerations based on surface characteristics and the challenges that users perceive they may have with HSI within their homes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {materiality, surface texture, user experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376371,
author = {Yoo, Soojeong and Gough, Phillip and Kay, Judy},
title = {Embedding a VR Game Studio in a Sedentary Workplace: Use, Experience and Exercise Benefits},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376371},
doi = {10.1145/3313831.3376371},
abstract = {Many people, especially those in sedentary occupations, fail to achieve the recommended levels of physical activity. Virtual reality (VR) games have the potential to overcome this because they are fun and also can be physically demanding. This paper explores whether a VR game studio can help workers in sedentary jobs to get valuable levels of exercise. We studied how 11 participants used our VR game studio in a sedentary workplace over 8-weeks and their perceptions of the experience. We analysed the physical exertion in the VR game studio, comparing this to their step counts from a smartwatch. All participants achieved valuable levels of physical activity and mood benefits. Importantly, for 6 participants, only with the VR game studio did they meet recommended activity levels. Our key contributions are insights about the use of a workplace VR game studio and its health benefits.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {exercise, sedentary workplace, head-mounted display, virtual reality game},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376342,
author = {Desjardins, Audrey and Biggs, Heidi R. and Key, Cayla and Viny, Jeremy E.},
title = {IoT Data in the Home: Observing Entanglements and Drawing New Encounters},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376342},
doi = {10.1145/3313831.3376342},
abstract = {Internet of Things (IoT) technologies for the home are gaining in popularity, generating exponential data byproducts. Yet, everyday relationships between home dwellers and domestic IoT data often remain secondary interactions, preventing deeper understanding and awareness of data tracked in the home. Our paper offers a design ethnography and design inquiry which examine these human-data entanglements. Findings from working with 10 inhabitants who interact with their IoT data illustrate five characteristics of current data encounters: manifesting, inquiring, exposing, repositioning, and broadening. In response, we used speculative sketches to refine, refract and complicate these encounters. We argue that data do not have to be laborious, tidy or the byproduct of a service, but rather lively and affecting. We further suggest new modes of engagement with data which expand or step away from self-improvement and reflection: through diverse acts of noticing, by allowing data to remain invisible, and by embracing imaginative practices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {data, internet of things, home, speculative, design ethnography, research-through-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376293,
author = {Fan, Jenny and Zhang, Amy X.},
title = {Digital Juries: A Civics-Oriented Approach to Platform Governance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376293},
doi = {10.1145/3313831.3376293},
abstract = {As concerns have grown regarding harmful content spread on social media, platform mechanisms for content moderation have become increasingly significant. However, many existing platform governance structures lack formal processes for democratic participation by users of the platform. Drawing inspiration from constitutional jury trials in many legal systems, this paper proposes digital juries as a civics-oriented approach for adjudicating content moderation cases. Building on existing theoretical models of jury decision-making, we outline a 5-stage model characterizing the space of design considerations in a digital jury process. We implement two examples of jury designs involving blind-voting and deliberation. From users who participate in our jury implementations, we gather informed judgments of the democratic legitimacy of a jury process for content moderation. We find that digital juries are perceived as more procedurally just than existing common platform moderation practices, but also find disagreement over whether jury decisions should be enforced or used as recommendations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {institutional design, content moderation, civics, social media, platforms, governance, democracy, online speech, juries},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376294,
author = {Mustafa, Maryam and Batool, Amna and Fatima, Beenish and Nawaz, Fareeda and Toyama, Kentaro and Raza, Agha Ali},
title = {Patriarchy, Maternal Health and Spiritual Healing: Designing Maternal Health Interventions in Pakistan},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376294},
doi = {10.1145/3313831.3376294},
abstract = {We examine the opportunities and challenges in designing for maternal health in low-income, low-resource communities in patriarchal and religious contexts. Pakistan faces a crisis in maternal health with a maternal mortality ratio of 178 deaths per 100,000 live births, as compared to the developed-country average of just 12 deaths per 100,000. Through a 6-month long qualitative, empirical study we examine the prevalent beliefs and practices around maternal health in Pakistan, the access women have to health-care, the existing religious practices that influence them and the agency they exert in their own health-care decision making. We reveal the rampant misinformation among mothers and health workers, house-hold power dynamics that impact maternal health and the deep link between maternal health and religious beliefs. We also show how current maternal health care interventions fit poorly into this context and discuss alternate design recommendations for meeting the maternal health needs of these women.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hci4d, maternal health, patriarchy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376744,
author = {Smith, C. Estelle and Nevarez, Eduardo and Zhu, Haiyi},
title = {Disseminating Research News in HCI: Perceived Hazards, How-To's, and Opportunities for Innovation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376744},
doi = {10.1145/3313831.3376744},
abstract = {Mass media afford researchers critical opportunities to disseminate research findings and trends to the general public. Yet researchers also perceive that their work can be miscommunicated in mass media, thus generating unintended understandings of HCI research by the general public. We conduct a Grounded Theory analysis of interviews with 12 HCI researchers and find that miscommunication can occur at four origins along the socio-technical infrastructure known as the Media Production Pipeline (MPP) for science news. Results yield researchers' perceived hazards of disseminating their work through mass media, as well as strategies for fostering effective communication of research. We conclude with implications for augmenting or innovating new MPP technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {miscommunication, mass media, journalism, news production, media production pipeline, science communications, mass communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376619,
author = {Kim, Jinsoo and Oh, Seungjae and Park, Chaeyong and Choi, Seungmoon},
title = {Body-Penetrating Tactile Phantom Sensations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376619},
doi = {10.1145/3313831.3376619},
abstract = {In tactile interaction, a phantom sensation refers to an illusion felt on the skin between two distant points at which vibrations are applied. It can improve the perceptual spatial resolution of tactile stimulation with a few tactors. All phantom sensations reported in the literature act on the skin or out of the body, but no such reports exist for those eliciting sensations penetrating the body. This paper addresses tactile phantom sensations in which two vibration actuators on the dorsal and palmar sides of the hand present an illusion of vibration passing through the hand. We also demonstrate similar tactile illusions for the torso. For optimal design, we conducted user studies while varying vibration frequency, envelope function, stimulus duration, and penetrating direction. Based on the results, we present design guidelines on penetrating phantom sensations for its use in immersive virtual reality applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {phantom sensation, tactile illusion, penetrating tactile sensation, vibrotactile feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376733,
author = {Batch, Andrea and Patnaik, Biswaksen and Akazue, Moses and Elmqvist, Niklas},
title = {Scents and Sensibility: Evaluating Information Olfactation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376733},
doi = {10.1145/3313831.3376733},
abstract = {Olfaction---the sense of smell---is one of the least explored of the human senses for conveying abstract information. In this paper, we conduct a comprehensive perceptual experiment on information olfactation: the use of olfactory and cross-modal sensory marks and channels to convey data. More specifically, following the example from graphical perception studies, we design an experiment that studies the perceptual accuracy of four cross-modal sensory channels---scent type, scent intensity, airflow, and temperature---for conveying three different types of data---nominal, ordinal, and quantitative. We also present details of a 24-scent multi-sensory display and its software framework that we designed in order to run this experiment. Our results yield a ranking of olfactory and cross-modal sensory channels that follows similar principles as classic rankings for visual channels.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {scents, olfactory displays, smell, evaluation, olfactory perception, information olfactation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376376,
author = {Valencia, Stephanie and Pavel, Amy and Santa Maria, Jared and Yu, Seunga (Gloria) and Bigham, Jeffrey P. and Admoni, Henny},
title = {Conversational Agency in Augmentative and Alternative Communication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376376},
doi = {10.1145/3313831.3376376},
abstract = {Augmented communicators (ACs) use augmentative and alternative communication (AAC) technologies to speak. Prior work in AAC research has looked to improve efficiency and expressivity of AAC via device improvements and user training. However, ACs also face constraints in communication beyond their device and individual abilities such as when they can speak, what they can say, and who they can address. In this work, we recast and broaden this prior work using conversational agency as a new frame to study AC communication. We investigate AC conversational agency with a study examining different conversational tasks between four triads of expert ACs, their close conversation partners (paid aide or parent), and a third party (experimenter). We define metrics to analyze AAC conversational agency quantitatively and qualitatively. We conclude with implications for future research to enable ACs to easily exercise conversational agency.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {accessibility, cerebral palsy, conversation, aac, agency},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376413,
author = {Pusateri, Juliet and Leng, Judith and Wang, Qian and Chen, Xiangzhu and Hammer, Jessica},
title = {Designing Games for Healthy Sleep},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376413},
doi = {10.1145/3313831.3376413},
abstract = {A sleep deficit has far-reaching consequences, but for many people, healthy sleep is not a priority or a possibility. We explore the potential for "sleepy games" as a genre of transformational games. To explore this design space, we prototyped nine games through an iterative design process. Based on analysis of design decisions and the games as artifacts, we identify seven design challenges for sleepy games: agency and control; physiological and mental arousal; intervention timing; social embeddedness; multisensory experience; vulnerability; and identity and values. We expand on three games with playtesting to show how these design challenges unfold for players in practice, show the impact on players' lives, and discuss sleepy games as creative, social, and situated practices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {transformational games, games for health, game design, sleep},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376682,
author = {El Ali, Abdallah and Yang, Xingyu and Ananthanarayan, Swamy and R\"{o}ggla, Thomas and Jansen, Jack and Hartcher-O'Brien, Jess and Jansen, Kaspar and Cesar, Pablo},
title = {ThermalWear: Exploring Wearable On-Chest Thermal Displays to Augment Voice Messages with Affect},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376682},
doi = {10.1145/3313831.3376682},
abstract = {Voice is a rich modality for conveying emotions, however emotional prosody production can be situationally or medically impaired. Since thermal displays have been shown to evoke emotions, we explore how thermal stimulation can augment perception of neutrally-spoken voice messages with affect. We designed ThermalWear, a wearable on-chest thermal display, then tested in a controlled study (N=12) the effects of fabric, thermal intensity, and direction of change. Thereafter, we synthesized 12 neutrally-spoken voice messages, validated (N=7) them, then tested (N=12) if thermal stimuli can augment their perception with affect. We found warm and cool stimuli (a) can be perceived on the chest, and quickly without fabric (4.7-5s) (b) do not incur discomfort (c) generally increase arousal of voice messages and (d) increase / decrease message valence, respectively. We discuss how thermal displays can augment voice perception, which can enhance voice assistants and support individuals with emotional prosody impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {affect, wearable, thermal, voice, emotion, chest, prosody, display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376642,
author = {Wang, Cheng Yao and Sakashita, Mose and Ehsan, Upol and Li, Jingjin and Won, Andrea Stevenson},
title = {Again, Together: Socially Reliving Virtual Reality Experiences When Separated},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376642},
doi = {10.1145/3313831.3376642},
abstract = {To share a virtual reality (VR) experience remotely together, users usually record videos from an individual's point of view and then co-watch these videos. However, co-watching recorded videos limits users to reliving their memories from the perspective from which the video was captured. In this paper, we describe ReliveInVR, a new time-machine-like VR experience sharing method. ReliveInVR allows multiple users to immerse themselves in the relived experience together and independently view the experience from any perspective. We conducted a 1x3 within-subject study with 26 dyads to compare ReliveInVR with (1) co-watching 360-degree videos on desktop, and (2) co-watching 360-degree videos in VR. Our results suggest that participants reported higher levels of immersion and social presence in ReliveInVR. Participants in ReliveInVR also understood the shared experience better, discovered unnoticed things together and found the sharing experience more fulfilling. We discuss the design implications for sharing VR experiences over time and space.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social, virtual reality, shared experience, immersion, replay, presence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376523,
author = {Suzuki, Ryo and Hedayati, Hooman and Zheng, Clement and Bohn, James L. and Szafir, Daniel and Do, Ellen Yi-Luen and Gross, Mark D. and Leithinger, Daniel},
title = {RoomShift: Room-Scale Dynamic Haptics for VR with Furniture-Moving Swarm Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376523},
doi = {10.1145/3313831.3376523},
abstract = {RoomShift is a room-scale dynamic haptic environment for virtual reality, using a small swarm of robots that can move furniture. RoomShift consists of nine shape-changing robots: Roombas with mechanical scissor lifts. These robots drive beneath a piece of furniture to lift, move and place it. By augmenting virtual scenes with physical objects, users can sit on, lean against, place and otherwise interact with furniture with their whole body; just as in the real world. When the virtual scene changes or users navigate within it, the swarm of robots dynamically reconfigures the physical environment to match the virtual content. We describe the hardware and software implementation, applications in virtual tours and architectural design and interaction techniques.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {haptic interfaces, swarm robots, room-scale haptics, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376169,
author = {Iivari, Netta and Kinnula, Marianne and Kuure, Leena and Keisanen, Tiina},
title = {"Arseing around Was Fun!" – Humor as a Resource in Design and Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376169},
doi = {10.1145/3313831.3376169},
abstract = {Humor is an inevitable part of human life. Most of us are capable of experiencing and appreciating humor. From this perspective, surprisingly little HCI research can be found scrutinizing the existence, role, and potential of humor in our design practice. The gap remains also related to children and teenagers; there is a lack of studies appreciating the emergence and existence of humor in the design process without intentionally evoking it. Thus, this study examines humor as a naturally occurring phenomenon in the design process. The study was conducted in collaboration with a class of teenagers and their teachers. The study identifies various forms and functions of humor in the design process and reveals its situated, emergent nature as a resource in interaction within design. The study proposes a practical tool for designers for anticipating and potentially facilitating the emergence, forms and usages of humor as an interactional resource in design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design, children, humor, making in education, discourse, interaction, teenager, nexus analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376129,
author = {Mor, Hila and Yu, Tianyu and Nakagaki, Ken and Miller, Benjamin Harvey and Jia, Yichen and Ishii, Hiroshi},
title = {Venous Materials: Towards Interactive Fluidic Mechanisms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376129},
doi = {10.1145/3313831.3376129},
abstract = {Venous Materials is a novel concept and approach of an interactive material utilizing fluidic channels. We present a design method for fluidic mechanisms that respond to deformation by mechanical inputs from the user, such as pressure and bending. We designed a set of primitive venous structures that act as embedded analog fluidic sensors, displaying flow and color change. In this paper, we consider the fluid as the medium to drive tangible information triggered by deformation, and at the same time, to function as a responsive display of that information. To provide users with a simple way to create and validate designs of fluidic structures, we built a software platform and design tool UI. This design tool allows users to quickly design the geometry, and simulate the flow with intended mechanical force dynamically. We present a range of applications that demonstrate how Venous Materials can be utilized to augment interactivity of everyday physical objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {human material interactions, programmable materials, microfluidics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376678,
author = {Eriksson, Sara and H\"{o}\"{o}k, Kristina and Shusterman, Richard and Svanes, Dag and Unander-Scharin, Carl and Unander-Scharin, \r{A}sa},
title = {Ethics in Movement: Shaping and Being Shaped in Human-Drone Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376678},
doi = {10.1145/3313831.3376678},
abstract = {How is ethics shaped by the particularities of a design? Through a detailed video analysis, we explore how ethicality is shaped in interaction between a choreographer, a performer and a choir of five drones, performing together on the opera stage. We pinpoint how movements enabled by the human-drone assemblage may limit or liberate artistic expressions vis-\`{a}-vis the norms of operatic performance. From a somaesthetics perspective on ethics, we show how the process of crafting rich experiences together with drones can deepen sensory appreciation skills, leading to an increased understanding of underlying somatic drivers and imposed norms. Somatic awareness thereby enables a richer repertoire of movements, expanding the ability to freely choose how to act, and cultivating empathy towards others. This shifts our understanding of ethics in HCI as solely about abstract rules or policies 'out there' to also concern the specifics of how technology informs or dictates movement and experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ethics, somaesthetics, drones, soma design, movement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376773,
author = {Eschler, Jordan and Burgess, Eleanor R. and Reddy, Madhu and Mohr, David C.},
title = {Emergent Self-Regulation Practices in Technology and Social Media Use of Individuals Living with Depression},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376773},
doi = {10.1145/3313831.3376773},
abstract = {Much human-computer interaction work related to depression focuses on the population level (e.g., studying social media hashtags related to depression) or evaluates prototypes for digital interventions to manage depression. However, little is known about how people living with depression perceive and manage technology use, such as time spent on social media per day. For this study, we interviewed 30 individuals living with depression to explore their technology and social media use. We find that these individuals demonstrated emergent practices related to self-regulation, such as learning to monitor and adjust technology use to improve their emotional, cognitive, and behavioral health. Our findings add a human-centered viewpoint to the relationship between living with depression and technology and social media use. We present design implications of these findings for better empowering individuals with depression to encourage their natural inclinations to self-regulate technology and social media use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {qualitative, self-regulation, social media, depression},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376369,
author = {Avrahami, Daniel and Williams, Kristin and Lee, Matthew L. and Tokunaga, Nami and Tjahjadi, Yulius and Marlow, Jennifer},
title = {Celebrating Everyday Success: Improving Engagement and Motivation Using a System for Recording Daily Highlights},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376369},
doi = {10.1145/3313831.3376369},
abstract = {The demands of daily work offer few opportunities for workers to take stock of their own progress, big or small, which can lead to lower motivation, engagement, and higher risk of burnout. We present Highlight Matome, a personal online tool that encourages workers to quickly record and rank a single work highlight each day, helping them gain awareness of their own successes. We describe results from a field experiment investigating our tool's effectiveness for improving workers' engagement, perceptions, and affect. Thirty-three knowledge workers in Japan and the U.S. used Highlight Matome for six weeks. Our results show that using our tool for less than one minute each day significantly increased measures of work engagement, dedication, and positivity. A qualitative analysis of the highlights offers a window into participants' emotions and perceptions. We discuss implications for theories of inner work life and worker well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {knowledge workers, work engagement, well-being},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376246,
author = {Maddali, Hanuma Teja and Lazar, Amanda},
title = {Sociality and Skill Sharing in the Garden},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376246},
doi = {10.1145/3313831.3376246},
abstract = {Gardening is an activity that involves a number of dimensions of increasing interest to HCI and CSCW researchers, including recreation, sustainability, and engagement with nature. This paper considers the garden setting in order to understand the role that collaborative and social computing technologies might play for practitioners engaging in outdoor skilled activities. We conducted participant observations with nine experienced gardeners aged 22-71 years. Through this process, we find that gardeners continuously configure their environments to accommodate their preferences for sociality. They share embodied skills and help others attune to sensory information in person, but also influence learning through the features in their garden that are observed by others. This paper provides an understanding of sociality in the garden, highlights skill sharing as a key domain for design in this space, and contributes design considerations for collaborative technologies in outdoor settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {skill sharing, gardening, sociality, participant observation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376494,
author = {Lerner, Sorin},
title = {Projection Boxes: On-the-Fly Reconfigurable Visualization for Live Programming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376494},
doi = {10.1145/3313831.3376494},
abstract = {Live programming is a regime in which the programming environment provides continual feedback, most often in the form of runtime values. In this paper, we present Projection Boxes, a novel visualization technique for displaying runtime values of programs. The key idea behind projection boxes is to start with a full semantics of the program, and then use projections to pick a subset of the semantics to display. By varying the projection used, projection boxes can encode both previously known visualization techniques, and also new ones. As such, projection boxes provide an expressive and configurable framework for displaying runtime information. Through a user study we demonstrate that (1) users find projection boxes and their configurability useful (2) users are not distracted by the always-on visualization (3) a key driving force behind the need for a configurable visualization for live programming lies with the wide variation in programmer preferences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {program visualization, live programming, programming environment, debugging},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376166,
author = {Karusala, Naveena and Wang, Ding and O'Neill, Jacki},
title = {Making Chat at Home in the Hospital: Exploring Chat Use by Nurses},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376166},
doi = {10.1145/3313831.3376166},
abstract = {In this paper, we examine WhatsApp use by nurses in India. Globally, personal chat apps have taken the workplace by storm, and healthcare is no exception. In the hospital setting, this raises questions around how chat apps are integrated into hospital work and the consequences of using such personal tools for work. To address these questions, we conducted an ethnographic study of chat use in nurses' work in a large multi-specialty hospital. By examining how chat is embedded in the hospital, rather than focusing on individual use of personal tools, we throw new light on the adoption of personal tools at work — specifically what happens when such tools are adopted and used as though they were organisational tools. In doing so, we explicate their impact on invisible work [77] and the creep of work into personal time, as well as how hierarchy and power play out in technology use. Thus, we point to the importance of looking beyond individual adoption by knowledge workers when studying the impact of personal tools at work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {work-life balance, ethnography, hospital communication, chat apps, workplace studies, nursing, whatsapp},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376702,
author = {McGill, Mark and Brewster, Stephen and McGookin, David and Wilson, Graham},
title = {Acoustic Transparency and the Changing Soundscape of Auditory Mixed Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376702},
doi = {10.1145/3313831.3376702},
abstract = {Auditory headsets capable of actively or passively intermixing both real and virtual sounds are in-part acoustically transparent. This paper explores the consequences of acoustic transparency, both on the perception of virtual audio content, given the presence of a real-world auditory backdrop, and more broadly in facilitating a wearable, personal, private, always-available soundspace. We experimentally compare passive acoustically transparent, and active noise cancelling, orientation-tracked auditory headsets across a range of content types, both indoors and outdoors for validity. Our results show differences in terms of presence, realness and externalization for select content types. Via interviews and a survey, we discuss attitudes toward acoustic transparency (e.g. being perceived as safer), the potential shifts in audio usage that might be precipitated by adoption, and reflect on how such headsets and experiences fit within the area of Mixed Reality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {audio, acoustic transparency, mixed reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376404,
author = {Stangl, Abigale and Morris, Meredith Ringel and Gurari, Danna},
title = {"Person, Shoes, Tree. Is the Person Naked?" What People with Vision Impairments Want in Image Descriptions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376404},
doi = {10.1145/3313831.3376404},
abstract = {Access to digital images is important to people who are blind or have low vision (BLV). Many contemporary image description efforts do not take into account this population's nuanced image description preferences. In this paper, we present a qualitative study that provides insight into 28 BLV people's experiences with descriptions of digital images from news websites, social networking sites/platforms, eCommerce websites, employment websites, online dating websites/platforms, productivity applications, and e-publications. Our findings reveal how image description preferences vary based on the source where digital images are encountered and the surrounding context. We provide recommendations for the development of next-generation image description technologies inspired by our empirical analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visual impairment, alt text, image captions, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376863,
author = {Jung, Jingun and Lee, Sangyoon and Hong, Jiwoo and Youn, Eunhye and Lee, Geehyuk},
title = {Voice+Tactile: Augmenting In-Vehicle Voice User Interface with Tactile Touchpad Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376863},
doi = {10.1145/3313831.3376863},
abstract = {Promisingly, driving is adapting to a Voice User Interface (VUI) that lets drivers utilize diverse applications with little effort. However, the VUI has innate usability issues, such as a turn-taking problem, a short-term memory workload, inefficient controls, and difficulty correcting errors. To overcome these weaknesses, we explored supplementing the VUI with tactile interaction. As an early result, we present the Voice+Tactile interactions that augment the VUI via multi-touch inputs and high-resolution tactile outputs. We designed various Voice+Tactile interactions to support different VUI interaction stages and derived four Voice+Tactile interaction themes: Status Feedback, Input Adjustment, Output Control, and Finger Feedforward. A user study showed that the Voice+Tactile interactions improved the VUI efficiency and its user experiences without incurring significant additional distraction overhead on driving. We hope these early results open new research questions to improve in-vehicle VUI with a tactile channel.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {in-vehicle user interface, voice user interface, tactile feedback touchpad},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376844,
author = {Karyda, Maria and Ry\"{o}ppy, Merja and Buur, Jacob and Lucero, Andr\'{e}s},
title = {Imagining Data-Objects for Reflective Self-Tracking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376844},
doi = {10.1145/3313831.3376844},
abstract = {While self-tracking data is typically captured real-time in a lived experience, the data is often stored in a manner detached from the context where it belongs. Research has shown that there is a potential to enhance people's lived experiences with data-objects (artifacts representing contextually relevant data), for individual and collective reflections through a physical portrayal of data. This paper expands that research by studying how to design contextually relevant data-objects based on people's needs. We conducted a participatory research project with five households using object theater as a core method to encourage participants to speculate upon combinations of meaningful objects and personal data archives. In this paper, we detail three aspects that seem relevant for designing data-objects: social sharing, contextual ambiguity and interaction with the body. We show how an experience-centric view on data-objects can contribute with the contextual, social and bodily interplay between people, data and objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data-objects, personal objects, experience, object theater},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376710,
author = {Laschke, Matthias and Braun, Christoph and Neuhaus, Robin and Hassenzahl, Marc},
title = {Meaningful Technology at Work - A Reflective Design Case of Improving Radiologists' Wellbeing Through Medical Technology},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376710},
doi = {10.1145/3313831.3376710},
abstract = {In radiology, medical technology providers (MTP) focus mainly on technology-related issues, such as image quality or efficiency of reporting. Broader notions of radiology as "meaningful work" are largely seen as out of scope for an MTP. The present paper challenges this. In a real-world case with a large MTP, we showed that medical technology could be designed more holistically to explicitly improve radiologists' wellbeing. We first gathered work practices experienced as especially conducive to wellbeing. From there, we distilled ideal practices to increase wellbeing and turned them into two software applications. The MTP's initial skepticism dissolved, while radiologists unanimously emphasized wellbeing and demonstrated how they work towards improving it. Based on our insights, the applications resonated well among the radiologists involved, the healthcare provider, and other customers of the MTP. We close with a critical reflection of the challenges and opportunities of designing wellbeing-driven technology in the work domain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {practice-based, job design, wellbeing-driven design, technology at work},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376519,
author = {Leake, Mackenzie and Shin, Hijung Valentina and Kim, Joy O. and Agrawala, Maneesh},
title = {Generating Audio-Visual Slideshows from Text Articles Using Word Concreteness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376519},
doi = {10.1145/3313831.3376519},
abstract = {We present a system that automatically transforms text articles into audio-visual slideshows by leveraging the notion of word concreteness, which measures how strongly a word or phrase is related to some perceptible concept. In a formative study we learn that people not only prefer such audio-visual slideshows but find that the content is easier to understand compared to text articles or text articles augmented with images. We use word concreteness to select search terms and find images relevant to the text. Then, based on the distribution of concrete words and the grammatical structure of an article, we time-align selected images with audio narration obtained through text-to-speech to produce audio-visual slideshows. In a user evaluation we find that our concreteness-based algorithm selects images that are highly relevant to the text. The quality of our slideshows is comparable to slideshows produced manually using standard video editing tools, and people strongly prefer our slideshows to those generated using a simple keyword-search based approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {word concreteness, audio-visual slideshows, text-to-video},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376290,
author = {Schaekermann, Mike and Cai, Carrie J. and Huang, Abigail E. and Sayres, Rory},
title = {Expert Discussions Improve Comprehension of Difficult Cases in Medical Image Assessment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376290},
doi = {10.1145/3313831.3376290},
abstract = {Medical data labeling workflows critically depend on accurate assessments from human experts. Yet human assessments can vary markedly, even among medical experts. Prior research has demonstrated benefits of labeler training on performance. Here we utilized two types of labeler training feedback: highlighting incorrect labels for difficult cases ("individual performance" feedback), and expert discussions from adjudication of these cases. We presented ten generalist eye care professionals with either individual performance alone, or individual performance and expert discussions from specialists. Compared to performance feedback alone, seeing expert discussions significantly improved generalists' understanding of the rationale behind the correct diagnosis while motivating changes in their own labeling approach; and also significantly improved average accuracy on one of four pathologies in a held-out test set. This work suggests that image adjudication may provide benefits beyond developing trusted consensus labels, and that exposure to specialist discussions can be an effective training intervention for medical diagnosis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {medical images, labeler training, diagnosis, adjudication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376821,
author = {Rietzler, Michael and Deubzer, Martin and Dreja, Thomas and Rukzio, Enrico},
title = {Telewalk: Towards Free and Endless Walking in Room-Scale Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376821},
doi = {10.1145/3313831.3376821},
abstract = {Natural navigation in VR is challenging due to spatial limitations. While Teleportation enables navigation within very small physical spaces and without causing motion sickness symptoms, it may reduce the feeling of presence and spacial awareness. Redirected walking (RDW), in contrast, allows users to naturally walk while staying inside a finite, but still very large, physical space. We present Telewalk, a novel locomotion approach that combines curvature and translation gains known from RDW research in a perceivable way. This combination enables Telewalk to be applied even within a physical space of 3m x 3m. Utilizing the head rotation as input device enables directional changes without any physical turns to keep the user always on an optimal circular path inside the real world while freely walking inside the virtual one. In a user study we found that even though motion sickness susceptible participants reported respective symptoms, Telewalk did result in stronger feelings of presence and immersion and was seen as more natural then Teleportation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {redirected walking, Telewalk, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376612,
author = {Lu, Zhicong and Jiang, Yue and Lu, Cheng and Naaman, Mor and Wigdor, Daniel},
title = {The Government's Dividend: Complex Perceptions of Social Media Misinformation in China},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376612},
doi = {10.1145/3313831.3376612},
abstract = {The social media environment in China has become the dominant source of information and news over the past decade. This news environment has naturally suffered from challenges related to mis- and dis-information, encumbered by an increasingly complex landscape of factors and players including social media services, fact-checkers, censorship policies, and astroturfing. Interviews with 44 Chinese WeChat users were conducted to understand how individuals perceive misinformation and how it impacts their news consumption practices. Overall, this work exposes the diverse attitudes and coping strategies that Chinese users employ in complex social media environments. Due to the complex nature of censorship in China and participants' lack of understanding of censor-ship, they expressed varied opinions about its influence on the credibility of online information sources. Further, although most participants claimed that their opinions would not be easily swayed by astroturfers, many admitted that they could not effectively distinguish astroturfers from ordinary Internet users. Participants' inability to make sense of comments found online lead many participants to hold pro-censorship attitudes: the Government's Dividend.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social media, trust, astroturfing, misinformation, fake news},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376834,
author = {Gr\o{}nb\ae{}k, Jens Emil and Rasmussen, Majken Kirkegaard and Halskov, Kim and Petersen, Marianne Graves},
title = {KirigamiTable: Designing for Proxemic Transitions with a Shape-Changing Tabletop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376834},
doi = {10.1145/3313831.3376834},
abstract = {A core challenge in tabletop research is to support transitions between individual activities and team work. Shape-changing tabletops open up new opportunities for addressing this challenge. However, interaction design for shape-changing furniture is in its early stages - so far, research has mainly focused on triggering shape-changes, and less on the actual interface transitions. We present KirigamiTable - a novel actuated shape-changing tabletop for supporting transitions in collaborative work. Our work builds on the concept of Proxemic Transitions, considering the dynamic interplay between social interactions, interactive technologies and furniture. With KirigamiTable, we demonstrate the potential of interactions for proxemic transitions that combine transformation of shape and digital contents. We highlight challenges for shape-changing tabletops: initiating shape and content transformations, cooperative control, and anticipating shape-change. To address these challenges, we propose a set of novel interaction techniques, including shape-first and content-first interaction, cooperative gestures, and physical and digital preview of shape-changes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {collaboration, transitions, interactive tabletops, shape-changing interfaces, proxemics, interaction techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376758,
author = {Jain, Dhruv and Mack, Kelly and Amrous, Akli and Wright, Matt and Goodman, Steven and Findlater, Leah and Froehlich, Jon E.},
title = {HomeSound: An Iterative Field Deployment of an In-Home Sound Awareness System for Deaf or Hard of Hearing Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376758},
doi = {10.1145/3313831.3376758},
abstract = {We introduce HomeSound, an in-home sound awareness system for Deaf and hard of hearing (DHH) users. Similar to the Echo Show or Nest Hub, HomeSound consists of a microphone and display, and uses multiple devices installed in each home. We iteratively developed two prototypes, both of which sense and visualize sound information in real-time. Prototype 1 provided a floorplan view of sound occurrences with waveform histories depicting loudness and pitch. A three-week deployment in four DHH homes showed an increase in participants' home- and self-awareness but also uncovered challenges due to lack of line of sight and sound classification. For Prototype 2, we added automatic sound classification and smartwatch support for wearable alerts. A second field deployment in four homes showed further increases in awareness but misclassifications and constant watch vibrations were not well received. We discuss findings related to awareness, privacy, and display placement and implications for future home sound awareness technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {sound awareness, deaf and hard of hearing, smart home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376196,
author = {Creed, Chris and Frutos-Pascual, Maite and Williams, Ian},
title = {Multimodal Gaze Interaction for Creative Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376196},
doi = {10.1145/3313831.3376196},
abstract = {We present a new application ("Sakura") that enables people with physical impairments to produce creative visual design work using a multimodal gaze approach. The system integrates multiple features tailored for gaze interaction including the selection of design artefacts via a novel grid approach, control methods for manipulating canvas objects, creative typography, a new color selection approach, and a customizable guide technique facilitating the alignment of design elements. A user evaluation (N=24) found that non-disabled users were able to utilize the application to complete common design activities and that they rated the system positively in terms of usability. A follow-up study with physically impaired participants (N=6) demonstrated they were able to control the system when working towards a website design, rating the application as having a good level of usability. Our research highlights new directions in making creative activities more accessible for people with physical impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {eye gaze tracking, eye gaze design, gaze interaction, interface design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376393,
author = {Wong, Pui Chung and Zhu, Kening and Yang, Xing-Dong and Fu, Hongbo},
title = {Exploring Eyes-Free Bezel-Initiated Swipe on Round Smartwatches},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376393},
doi = {10.1145/3313831.3376393},
abstract = {Bezel-based gestures expand the interaction space of touch-screen devices (e.g., smartphones and smartwatches). Existing works have mainly focused on bezel-initiated swipe (BIS) on square screens. To investigate the usability of BIS on round smartwatches, we design six different circular bezel layouts, by dividing the bezel into 6, 8, 12, 16, 24, and 32 segments. We evaluate the user performance of BIS on these layouts in an eyes-free situation. The results show that the performance of BIS is highly orientation dependent, and varies significantly among users. Using the Support-Vector-Machine (SVM) model significantly increases the accuracy on 6-, 8-, 12-, and 16-segment layouts. We then compare the performance of personal and general SVM models, and find that personal models significantly improve the accuracy for 8-, 12-, 16-, and 24-segment layouts. Lastly, we discuss the potential smartwatch applications enabled by the BIS.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {bezel-initiated gestures, round smartwatches, bezel, eyes-free},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376631,
author = {Garg, Radhika and Sengupta, Subhasree},
title = {Conversational Technologies for In-Home Learning: Using Co-Design to Understand Children's and Parents' Perspectives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376631},
doi = {10.1145/3313831.3376631},
abstract = {Today, Conversational Agents (CA) are deeply integrated into the daily lives of millions of families, which has led children to extensively interact with such devices. Studies have suggested that the social nature of CA makes them a good learning companion for children. Therefore, to understand children's preferences for the use of CAs for the purpose of in-home learning, we conducted three participatory design sessions. In order to identify parents' requirements in this regard, we also included them in the third session. We found that children expect such devices to possess a personality and an advanced level of intelligence, and support multiple content domains and learning modes and human-like conversations. Parents desire such devices to include them in their children's learning activities, foster social engagement, and to allow them to monitor their children's use. This understanding will inform the design of future CAs for the purpose of in-home learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {participatory design, co-design, parents, learning technology, learning, children, conversational agents, cooperative inquiry, learning companion, home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376582,
author = {Bahng, Sojung and Kelly, Ryan M. and McCormack, Jon},
title = {Reflexive VR Storytelling Design Beyond Immersion: Facilitating Self-Reflection on Death and Loneliness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376582},
doi = {10.1145/3313831.3376582},
abstract = {This research examines the reflexive dimensions of cinematic virtual reality (CVR) storytelling. We created Anonymous, an interactive CVR piece that employs a reflexive storytelling method. This method is based on distancing effects and is used to elicit audience awareness and self-reflection about loneliness and death. To understand the audience's experiences, we conducted in-depth interviews to study which design factors and elements prompted reflexive thoughts and feelings. Our findings highlight how the audience experience was impacted by four reflexive dimensions: abstract and minimal aesthetics, everyday materials and textures, the restriction of control, and multiple, disembodied points of view. We use our findings to discuss how these dimensions can inform the design of VR storytelling experiences that provoke self and social reflection.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {estrangement, alienation, virtual reality, immersive storytelling, cinematic vr, distancing effect, reflexivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376830,
author = {Kim, Yoojung and Bhattacharya, Arpita and Kientz, Julie A. and Lee, Jin Ha},
title = {"It Should Be a Game for Fun, Not Exercise": Tensions in Designing Health-Related Features for Pok\'{e}Mon GO},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376830},
doi = {10.1145/3313831.3376830},
abstract = {Leveraging existing popular games such as Pok\'{e}mon GO to promote health can engage people in healthy activities without sacrificing gaming appeal. However, little is known about what potential tensions arise from incorporating new health-related features to already existing and popular games and how to resolve those tensions from players' perspectives. In this paper, we identify design tensions surrounding the appeals of Pok\'{e}mon GO, perspectives on different health needs, and mobile health technologies. By conducting surveys and design workshops with 20 avid Pok\'{e}mon GO players, we demonstrate four design tensions: (1) diverse goals and rewards vs. data accuracy, (2) strong bonds between players and characters vs. gaming obsession, (3) collaborative play vs. social anxiety, and (4) connection of in-real-life experiences with the game vs. different individual contexts. We provide design implications to resolve these tensions in Pok\'{e}mon GO and discuss how to extend our findings to the broader context of health promotion in location-based games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {augmented reality game, design tension, health-related game feature, game design, location-based game, pokemon go, health promotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376753,
author = {Hu, Donghan and Lee, Sang Won},
title = {ScreenTrack: Using a Visual History of a Computer Screen to Retrieve Documents and Web Pages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376753},
doi = {10.1145/3313831.3376753},
abstract = {Computers are used for various purposes and frequent context switch is inevitable. In this setting, retrieving the documents, files, and web pages that have been used for a task can be a challenge. While modern applications provide a history of recent documents for users to resume work, this is not sufficient to retrieve all the digital resources relevant to a given primary document. The histories currently available - file names, web page titles, or URLs - does not take into account the complex dependencies that exist among resources across applications. To address this problem, we tested the idea of using a visual history of a computer screen to retrieve digital resources within a few days through the development of ScreenTrack. ScreenTrack is software that captures screenshots of a computer at regular intervals. It then generates a time-lapse video from the captured screenshots and lets users retrieve a recently opened document or web page from a screenshot that they recognize from its visuals. Through a controlled user study, it was found that participants were able to retrieve requested information more quickly with ScreenTrack than under the control condition. A follow-up study showed that the participants used ScreenTrack to retrieve previously used resources, in order to resume interrupted tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {task resumption, self-tracking, productivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376581,
author = {Gupta, Maya and Abdolrahmani, Ali and Edwards, Emory and Cortez, Mayra and Tumang, Andrew and Majali, Yasmin and Lazaga, Marc and Tarra, Samhitha and Patil, Prasad and Kuber, Ravi and Branham, Stacy M.},
title = {Towards More Universal Wayfinding Technologies: Navigation Preferences Across Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376581},
doi = {10.1145/3313831.3376581},
abstract = {Accessibility researchers have been studying wayfinding technologies for people with disabilities for decades, typically focusing on solutions within disability populations - for example, technologies to support blind navigation. Yet, we know little about wayfinding needs across disabilities. In this paper, we describe a qualitative interview study examining the urban navigational experiences of 27 people who identified as older adults and/or who had cognitive, visual, hearing, and/or mobility disabilities. We found that many navigation route preferences were shared across disabilities (e.g., desire to avoid carpeted areas), while others diverged or were in tension (e.g., the need to avoid noisy areas while staying near main thoroughfares). To support design for multiple disability groups, we identify four dimensions of navigation preferences - technology, route, assistance, experience - and describe how these might usefully inform design of more universally usable wayfinding technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {navigation, cognitive impairment, mobility impairment, accessibility, visual impairment, deaf, older adults},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376489,
author = {Henrikson, Rorik and Grossman, Tovi and Trowbridge, Sean and Wigdor, Daniel and Benko, Hrvoje},
title = {Head-Coupled Kinematic Template Matching: A Prediction Model for Ray Pointing in VR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376489},
doi = {10.1145/3313831.3376489},
abstract = {This paper presents a new technique to predict the ray pointer landing position for selection movements in virtual reality (VR) environments. The technique adapts and extends a prior 2D kinematic template matching method to VR environments where ray pointers are used for selection. It builds on the insight that the kinematics of a controller and Head-Mounted Display (HMD) can be used to predict the ray's final landing position and angle. An initial study provides evidence that the motion of the head is a key input channel for improving prediction models. A second study validates this technique across a continuous range of distances, angles, and target sizes. On average, the technique's predictions were within 7.3° of the true landing position when 50% of the way through the movement and within 3.4° when 90%. Furthermore, compared to a direct extension of Kinematic Template Matching, which only uses controller movement, this head-coupled approach increases prediction accuracy by a factor of 1.8x when 40% of the way through the movement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {target prediction, template matching, kinematics, virtual reality, ray pointing, endpoint prediction, vr},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376390,
author = {Yang, Saelyne and Lee, Changyoon and Shin, Hijung Valentina and Kim, Juho},
title = {Snapstream: Snapshot-Based Interaction in Live Streaming for Visual Art},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376390},
doi = {10.1145/3313831.3376390},
abstract = {Live streaming visual art such as drawing or using design software is gaining popularity. An important aspect of live streams is the direct and real-time communication between streamers and viewers. However, currently available text-based interaction limits the expressiveness of viewers as well as streamers, especially when they refer to specific moments or objects in the stream. To investigate the feasibility of using snapshots of streamed content as a way to enhance streamer-viewer interaction, we introduce Snapstream, a system that allows users to take snapshots of the live stream, annotate them, and share the annotated snapshots in the chat. Streamers can also verbally reference a specific snapshot during streaming to respond to viewers' questions or comments. Results from live deployments show that participants communicate more expressively and clearly with increased engagement using Snapstream. Participants used snapshots to reference part of the artwork, give suggestions on it, make fun images or memes, and log intermediate milestones. Our findings suggest that visual interaction enables richer experiences in live streaming.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {context sharing, live streaming, online interaction, chat interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376615,
author = {Abdul, Ashraf and von der Weth, Christian and Kankanhalli, Mohan and Lim, Brian Y.},
title = {COGAM: Measuring and Moderating Cognitive Load in Machine Learning Model Explanations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376615},
doi = {10.1145/3313831.3376615},
abstract = {Interpretable machine learning models trade -off accuracy for simplicity to make explanations more readable and easier to comprehend. Drawing from cognitive psychology theories in graph comprehension, we formalize readability as visual cognitive chunks to measure and moderate the cognitive load in explanation visualizations. We present Cognitive-GAM (COGAM) to generate explanations with desired cognitive load and accuracy by combining the expressive nonlinear generalized additive models (GAM) with simpler sparse linear models. We calibrated visual cognitive chunks with reading time in a user study, characterized the trade-off between cognitive load and accuracy for four datasets in simulation studies, and evaluated COGAM against baselines with users. We found that COGAM can decrease cognitive load without decreasing accuracy and/or increase accuracy without increasing cognitive load. Our framework and empirical measurement instruments for cognitive load will enable more rigorous assessment of the human interpretability of explainable AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {generalized additive models, explanations, visual explanations, explainable artificial intelligence, cognitive load},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376343,
author = {Garzotto, Franca and Beccaluva, Eleonora and Gianotti, Mattia and Riccardi, Fabiano},
title = {Interactive Multisensory Environments for Primary School Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376343},
doi = {10.1145/3313831.3376343},
abstract = {Interactive Multi-Sensory Environments (iMSEs) are room-sized interactive installations equipped with digitally enriched physical materials and ambient embedded devices. These items can sense users' presence, gestures, movements, and manipulation, and react by providing gentle stimulation (e.g., light, sound, projections, blowing bubbles, tactile feel, aromas) to different senses. Most of prior research on iMSEs investigates their use for persons with disabilities (e.g., autism). Our work focuses on the use of iMSEs in primary education contexts and for mixed groups of young students, i.e., children with and without disability. The paper describes the latest version of an iMSE called Magic Room that has been installed in two local schools. We report two empirical studies devoted to understand how the Magic Room could be used in inclusive educational settings, and to explore its potential benefits.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {primary school, interactive multisensory environment, children, smart object, smart space, children with special needs, embodied interaction, well-being},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376177,
author = {Hohman, Fred and Wongsuphasawat, Kanit and Kery, Mary Beth and Patel, Kayur},
title = {Understanding and Visualizing Data Iteration in Machine Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376177},
doi = {10.1145/3313831.3376177},
abstract = {Successful machine learning (ML) applications require iterations on both modeling and the underlying data. While prior visualization tools for ML primarily focus on modeling, our interviews with 23 ML practitioners reveal that they improve model performance frequently by iterating on their data (e.g., collecting new data, adding labels) rather than their models. We also identify common types of data iterations and associated analysis tasks and challenges. To help attribute data iterations to model performance, we design a collection of interactive visualizations and integrate them into a prototype, Chameleon, that lets users compare data features, training/testing splits, and performance across data versions. We present two case studies where developers apply system to their own evolving datasets on production ML projects. Our interface helps them verify data collection efforts, find failure cases stretching across data versions, capture data processing changes that impacted performance, and identify opportunities for future data iterations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive interfaces, data iteration, evolving datasets, machine learning iteration, visual analytics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376243,
author = {Wolf, Dennis and Rogers, Katja and Kunder, Christoph and Rukzio, Enrico},
title = {JumpVR: Jump-Based Locomotion Augmentation for Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376243},
doi = {10.1145/3313831.3376243},
abstract = {One of the great benefits of virtual reality (VR) is the implementation of features that go beyond realism. Common "unrealistic" locomotion techniques (like teleportation) can avoid spatial limitation of tracking, but minimize potential benefits of more realistic techniques (e.g. walking). As an alternative that combines realistic physical movement with hyper-realistic virtual outcome, we present JumpVR, a jump-based locomotion augmentation technique that virtually scales users' physical jumps. In a user study (N=28), we show that jumping in VR (regardless of scaling) can significantly increase presence, motivation and immersion compared to teleportation, while largely not increasing simulator sickness. Further, participants reported higher immersion and motivation for most scaled jumping variants than forward-jumping. Our work shows the feasibility and benefits of jumping in VR and explores suitable parameters for its hyper-realistic scaling. We discuss design implications for VR experiences and research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {super human, immersion, jumping, vr, hyper realism, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376762,
author = {Gupta, Saumya and Tanenbaum, Theresa Jean and Muralikumar, Meena Devii and Marathe, Aparajita S.},
title = {Investigating Roleplaying and Identity Transformation in a Virtual Reality Narrative Experience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376762},
doi = {10.1145/3313831.3376762},
abstract = {In this paper we describe the design and evaluation of The Next Fairy Tale (TNFT) VR, a theatrical interactive storytelling system created in virtual reality and informed by performing arts theories. TNFT was designed to produce opportunities for interactors to experience role-taking and character identification using design principles drawn from actor training and theatrical performance. We report the results of a pilot qualitative study of interactors using TNFT to explore the elements of the design that supported or hindered roleplaying behavior. We identify four design patterns that supported roleplaying in the system: (1) using explicit roles to set player expectations, (2) embracing the "mask and the mirror" effect, (3) attending to visual and interactional details, and (4) easing the player gently into the roleplaying experience. These patterns speak to a broader need to support roleplay through explicit scaffolding of desired player behaviors in digital narrative experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {roleplaying, interactive performance, virtual reality, drama, narrative, interactive digital storytelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376620,
author = {Waern, Annika and Rajkowska, Paulina and Johansson, Karin B. and Bac, Jon and Spence, Jocelyn and L\o{}vlie, Anders Sundnes},
title = {Sensitizing Scenarios: Sensitizing Designer Teams to Theory},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376620},
doi = {10.1145/3313831.3376620},
abstract = {Concepts and theories that emerge within the social sciences tend to be nuanced, dealing with complex social phenomena. While their relevance to design could be high, it is difficult to make sense of them in design projects, especially when participants have a variety of backgrounds. We report on our experiences using role-play scenarios as a way to sensitize heterogeneous designer teams to complex theoretical concepts related to museology as social and cultural phenomena. We discuss design requirements on such scenarios, and the importance of connecting their execution closely to the context of the design and the current stage of the design process.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social science theory, role-play, sensitizing designers, sensitizing concepts},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376447,
author = {Yan, Jing Nathan and Gu, Ziwei and Lin, Hubert and Rzeszotarski, Jeffrey M.},
title = {Silva: Interactively Assessing Machine Learning Fairness Using Causality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376447},
doi = {10.1145/3313831.3376447},
abstract = {Machine learning models risk encoding unfairness on the part of their developers or data sources. However, assessing fairness is challenging as analysts might misidentify sources of bias, fail to notice them, or misapply metrics. In this paper we introduce Silva, a system for exploring potential sources of unfairness in datasets or machine learning models interactively. Silva directs user attention to relationships between attributes through a global causal view, provides interactive recommendations, presents intermediate results, and visualizes metrics. We describe the implementation of Silva, identify salient design and technical challenges, and provide an evaluation of the tool in comparison to an existing fairness optimization tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {bias, machine learning fairness, interactive system},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376660,
author = {Cila, Nazli and Ferri, Gabriele and de Waal, Martijn and Gloerich, Inte and Karpinski, Tara},
title = {The Blockchain and the Commons: Dilemmas in the Design of Local Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376660},
doi = {10.1145/3313831.3376660},
abstract = {This paper addresses the design dilemmas that arise when distributed ledger technologies (DLT) are to be applied in the governance of artificial material commons. DLTs, such as blockchain, are often presented as enabling technologies for self-governing communities, provided by their consensus mechanisms, transparent administration, and incentives for collaboration and cooperation. Yet, these affordances may also undermine public values such as privacy and displace human agency in governance procedures. In this paper, the conflicts regarding the governance of communities which collectively manage and produce a commons are discussed through the case of a fictional energy community. Three mechanisms are identified in this process: tracking use of and contributions to the commons; managing resources, and negotiating the underlying rule sets and user rights. Our effort is aimed at contributing to the HCI community by introducing a framework of three mechanisms and six design dilemmas that can aid in balancing conflicting values in the design of local platforms for commons-based resource management.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {platformization, energy community, governance, design dilemmas, blockchain, commons},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376805,
author = {Dahl, Yngve and Svan\ae{}s, Dag},
title = {Facilitating Democracy: Concerns from Participatory Design with Asymmetric Stakeholder Relations in Health Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376805},
doi = {10.1145/3313831.3376805},
abstract = {This paper addresses how facilitation can implicate what, whose and how perspectives and values become embedded in the results from participatory design activities. Inspired by Donald Sch\"{o}n's reflection-on-action theory, an analysis of our facilitator performances in three design activities involving health care stakeholder groups with asymmetric relations has been performed. The analysis highlights the often subtle and unforeseen ways by which facilitator actions influence who "has a say". The results emphasize how continuous introspective analyses and reflections may improve the facilitator's attentiveness to actions that may inadvertently impede the disfavored party. In the long-term, neglect may threaten the integrity of participatory design as a democratic and empowering design approach. The shift towards a practice-perspective on facilitation goes beyond the efforts of the individual practitioner. The cultivation of the reflective facilitator, a concern of relevance for the Human?Computer Interaction and Participatory Design community as a whole, is considered.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {participation, facilitation, asymmetries, reflection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376335,
author = {Kaul, Oliver Beren and Rohs, Michael and Simon, Benjamin and Demir, Kerem Can and Ferry, Kamillo},
title = {Vibrotactile Funneling Illusion and Localization Performance on the Head},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376335},
doi = {10.1145/3313831.3376335},
abstract = {The vibrotactile funneling illusion is the sensation of a single (non-existing) stimulus somewhere in-between the actual stimulus locations. Its occurrence depends upon body location, distance between the actuators, signal synchronization, and intensity. Related work has shown that the funneling illusion may occur on the forehead. We were able to reproduce these findings and explored five further regions to get a more complete picture of the occurrence of the funneling illusion on the head. The results of our study (24 participants) show that the actuator distance, for which the funneling illusion occurs, strongly depends upon the head region. Moreover, we evaluated the centralizing bias (smaller perceived than actual actuator distances) for different head regions, which also showed widely varying characteristics. We computed a detailed heat map of vibrotactile localization accuracies on the head. The results inform the design of future tactile head-mounted displays that aim to support the funneling illusion.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {funneling illusion, tactile feedback, phantom sensation, centralizing bias},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376521,
author = {Kim, Sunyoung and Li, Muyang},
title = {Awareness, Understanding, and Action: A Conceptual Framework of User Experiences and Expectations about Indoor Air Quality Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376521},
doi = {10.1145/3313831.3376521},
abstract = {With the advent of new sensors and technologies, smart devices that monitor the level of indoor air quality (IAQ) are increasingly available to create a healthy home environment. However, little has been studied regarding design principles for effective IAQ visualizations to help better understand and improve IAQ. We analyzed Amazon reviews of IAQ monitors and their design components for IAQ visualizations. Based on our findings, we created a conceptual framework to explain the process of facilitating an effective IAQ visualization with a proposed set of design considerations in each stage. The process includes helping users easily understand what is happing to IAQ (awareness), what it means to them (understanding), and what to do with the information (action), which results in two outcomes, knowledge gain and emotional relief. We hope our framework can help practitioners and researchers in designing eco-feedback system and beyond to advance both research and practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {indoor air quality, design principles, peripheral display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376344,
author = {Beneteau, Erin and Boone, Ashley and Wu, Yuxing and Kientz, Julie A. and Yip, Jason and Hiniker, Alexis},
title = {Parenting with Alexa: Exploring the Introduction of Smart Speakers on Family Dynamics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376344},
doi = {10.1145/3313831.3376344},
abstract = {Smart speakers have become pervasive in family homes, creating the potential for these devices to influence parent-child dynamics and parenting behaviors. We investigate the impact of introducing a smart speaker to 10 families with children, over four weeks. We use pre- and post- deployment interviews with the whole family and in-home audio capture of parent-child interactions with the smart speaker for our analysis. Despite the smart speaker causing occasional conflict in the home, we observed that parents lever-aged the smart speaker to further parenting goals. We found three forms of influence the smart speaker has on family dynamics: 1) fostering communication, 2) disrupting access, and 3) augmenting parenting. All of these influences arise from a communally accessible, stand-alone voice interface which democratizes family access to technology. We discuss design implications in furthering parenting practices and behaviors as the capabilities of the technology continue to improve.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart speakers, child development, voice interfaces, parental mediation, families, parenting},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376765,
author = {Li, Jingyi and Brandt, Joel and Mech, Radom\'{\i}r and Agrawala, Maneesh and Jacobs, Jennifer},
title = {Supporting Visual Artists in Programming through Direct Inspection and Control of Program Execution},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376765},
doi = {10.1145/3313831.3376765},
abstract = {Programming offers new opportunities for visual art creation, but understanding and manipulating the abstract representations that make programming powerful can pose challenges for artists who are accustomed to manual tools and concrete visual interaction. We hypothesize that we can reduce these barriers through programming environments that link state to visual artwork output. We created Demystified Dynamic Brushes (DDB), a tool that bidirectionally links code, numerical data, and artwork across the programming interface and the execution environment - i.e., the artist's in-progress artwork. DDB automatically records stylus input as artists draw, and stores a history of brush state and output in relation to the input. This structure enables artists to inspect current and past numerical input, state, and output and control program execution through the direct selection of visual geometric elements in the drawing canvas. An observational study suggests that artists engage in program inspection when they can visually access geometric state information on the drawing canvas in the process of manual drawing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual art, creativity support tools, programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376365,
author = {Karduni, Alireza and Wesslen, Ryan and Cho, Isaac and Dou, Wenwen},
title = {Du Bois Wrapped Bar Chart: Visualizing Categorical Data with Disproportionate Values},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376365},
doi = {10.1145/3313831.3376365},
abstract = {We propose a visualization technique, Du Bois wrapped bar chart, inspired by work of W.E.B Du Bois. Du Bois wrapped bar charts enable better large-to-small bar comparison by wrapping large bars over a certain threshold. We first present two crowdsourcing experiments comparing wrapped and standard bar charts to evaluate (1) the benefit of wrapped bars in helping participants identify and compare values; (2) the characteristics of data most suitable for wrapped bars. In the first study (n=98) using real-world datasets, we find that wrapped bar charts lead to higher accuracy in identifying and estimating ratios between bars. In a follow-up study (n=190) with 13 simulated datasets, we find participants were consistently more accurate with wrapped bar charts when certain category values are disproportionate as measured by entropy and H-spread. Finally, in an in-lab study, we investigate participants' experience and strategies, leading to guidelines for when and how to use wrapped bar charts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {graphical perception, evaluation, user study, crowdsourcing, mechanical turk, information visualization, bar chart},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376212,
author = {Lee, Sangyoon and Lim, Youn-kyung and Lee, Geehyuk},
title = {MirrorPad: Mirror on Touchpad for Direct Pen Interaction in the Laptop Environment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376212},
doi = {10.1145/3313831.3376212},
abstract = {There are needs for pen interaction on a laptop, and the market sees many pen-enabled laptop products. Many of these laptops can be transformed into tablets, when pen interaction is needed. In a real situation, however, a workflow often requires both keyboard and pen interactions, and such a convertible feature may not be effective. In this study, we introduce MirrorPad, a novel interface device contained in a laptop for direct pen interaction. It is both a normal touchpad and a viewport for pen interaction with a mirrored region on the screen. We report findings and decisions obtained from the design iterations that we conducted with users to refine MirrorPad toward the final design. In the user study, MirrorPad showed the same performance as that of the laptop configuration during keyboard interaction and a performance similar to that of the tablet configuration during pen interaction. The user study results confirmed that MirrorPad effectively supports a workflow, which requires interspersed keyboard and pen interactions, thereby achieving its initial goal.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {touchpad with display, laptop environment, direct pen interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376281,
author = {Li, Quan and Lin, Huanbin and Wei, Xiguang and Huang, Yangkun and Fan, Lixin and Du, Jian and Ma, Xiaojuan and Chen, Tianjian},
title = {MaraVis: Representation and Coordinated Intervention of Medical Encounters in Urban Marathon},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376281},
doi = {10.1145/3313831.3376281},
abstract = {There is an increased use of Internet-of-Things and wearable sensing devices in the urban marathon to ensure effective response to unforeseen medical needs. However, the massive amount of real-time, heterogeneous movement and psychological data of runners impose great challenges on prompt medical incident analysis and intervention. Conventional approaches compile such data into one dashboard visualization to facilitate rapid data absorption but fail to support joint decision-making and operations in medical encounters. In this paper, we present MaraVis, a real-time urban marathon visualization and coordinated intervention system. It first visually summarizes real-time marathon data to facilitate the detection and exploration of possible anomalous events. Then, it calculates an optimal camera route with an arrangement of shots to guide offline effort to catch these events in time with a smooth view transition. We conduct a within-subjects study with two baseline systems to assess the efficacy of MaraVis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {anomaly detection, shot chaining, marathon visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376832,
author = {Monaco, John V.},
title = {Bug or Feature? Covert Impairments to Human Computer Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376832},
doi = {10.1145/3313831.3376832},
abstract = {Computer users commonly experience interaction anomalies, such as the text cursor jumping to another location in a document, perturbed mouse pointer motion, or a disagreement between tactile input and touch screen location. These anomalies impair interaction and require the user to take corrective measures, such as resetting the text cursor or correcting the trajectory of the pointer to reach a desired target. Impairments can result from software bugs, physical hardware defects, and extraneous input. However, some designs alter the course of interaction through covert impairments, anomalies introduced intentionally and without the user's knowledge. There are various motivations for doing so rooted in disparate fields including biometrics, electronic voting, and entertainment. We examine this kind of deception by systematizing four different ways computer interaction may become impaired and three different goals of the designer, providing insight to the design of systems that implement covert impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {cybersecurity, influence, interaction, deception, behavior change},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376648,
author = {Unbehaun, David and Aal, Konstantin and Vaziri, Daryoush Daniel and Tolmie, Peter David and Wieching, Rainer and Randall, David and Wulf, Volker},
title = {Social Technology Appropriation in Dementia: Investigating the Role of Caregivers in Engaging People with Dementia with a Videogame-Based Training System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376648},
doi = {10.1145/3313831.3376648},
abstract = {There has been increasing interest in designing for dementia in recent years. Empirical investigation is now needed of the long-term role of caregivers in appropriating ICTs into the complex daily life of people with dementia (PwD). We present here the outcomes of a 4-month evaluation of the individual, social and institutional impact of a videogame-based training system. The everyday behavior and interactions of 52 PwD and 25 caregivers was studied qualitatively, focusing on the role played by caregivers in integrating the system into daily routines. Our results indicate that the successful appropriation of ICT for PwD depends partly on the physical, cognitive and social benefits for PwD, but especially on the added value perceived by their social care-network. We discuss the need for design in dementia to develop more socially embedded innovations that can address the social actors involved and thus contribute to practical solutions for professional and private care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {care, exergame, dementia, appropriation, caregiver, ICT},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376183,
author = {Prpa, Mirjana and Stepanova, Ekaterina R. and Schiphorst, Thecla and Riecke, Bernhard E. and Pasquier, Philippe},
title = {Inhaling and Exhaling: How Technologies Can Perceptually Extend Our Breath Awareness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376183},
doi = {10.1145/3313831.3376183},
abstract = {Attending to breath is a self-awareness practice that exists within many contemplative and reflective traditions and is recognized for its benefits to well-being. Our current technological landscape embraces a large body of systems that utilize breath data in order to foster self-awareness. This paper seeks to deepen our understanding of the design space of systems that perceptually extend breath awareness. Our contribution is twofold: (1) our analysis reveals how the underlying theoretical frameworks shape the system design and its evaluation, and (2) how system design features support perceptual extension of breath awareness. We review and critically analyze 31 breath-based interactive systems. We identify 4 theoretical frameworks and 3 design strategies for interactive systems that perceptually extend breath awareness. We reflect upon this design space from both a theoretical and system design perspective, and propose future design directions for developing systems that "listen to" breath and perceptually extend it.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {breath, perceptually extending, breathing regulation, soma design, breathing synchronization, mindfulness-based design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376737,
author = {Wang, Yanan and Amores, Judith and Maes, Pattie},
title = {On-Face Olfactory Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376737},
doi = {10.1145/3313831.3376737},
abstract = {On-face wearables are currently limited to piercings, tattoos, or interactive makeup that aesthetically enhances the user, and have been minimally used for scent-delivery methods. However, on-face scent interfaces could provide an advantage for personal scent delivery in comparison with other modalities or body locations since they are closer to the nose. In this paper, we present the mechanical and industrial design details of a series of form factors for on-face olfactory wearables that are lightweight and can be adhered to the skin or attached to glasses or piercings. We assessed the usability of three prototypes by testing with 12 participants in a within-subject study design while they were interacting in pairs at a close personal distance. We compare two of these designs with an "off-face" olfactory necklace and evaluate their social acceptance, comfort as well as perceived odor intensity for both the wearer and observer.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {on-face wearables, olfactory interfaces, scent display, on-face interfaces, wearability, wearable device, jewelry, olfaction, fashion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376437,
author = {Fraser, C. Ailie and Kim, Joy O. and Shin, Hijung Valentina and Brandt, Joel and Dontcheva, Mira},
title = {Temporal Segmentation of Creative Live Streams},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376437},
doi = {10.1145/3313831.3376437},
abstract = {Many artists broadcast their creative process through live streaming platforms like Twitch and YouTube, and people often watch archives of these broadcasts later for learning and inspiration. Unfortunately, because live stream videos are often multiple hours long and hard to skim and browse, few can leverage the wealth of knowledge hidden in these archives. We present an approach for automatic temporal segmentation of creative live stream videos. Using an audio transcript and a log of software usage, the system segments the video into sections that the artist can optionally label with meaningful titles. We evaluate this approach by gathering feedback from expert streamers and comparing automatic segmentations to those made by viewers. We find that, while there is no one "correct" way to segment a live stream, our automatic method performs similarly to viewers, and streamers find it useful for navigating their streams after making slight adjustments and adding section titles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {creativity, live streaming, video segmentation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376887,
author = {Heyer, Jeremy and Raveendranath, Nirmal Kumar and Reda, Khairi},
title = {Pushing the (Visual) Narrative: The Effects of Prior Knowledge Elicitation in Provocative Topics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376887},
doi = {10.1145/3313831.3376887},
abstract = {Narrative visualization is a popular style of data-driven storytelling. Authors use this medium to engage viewers with complex and sometimes controversial issues. A challenge for authors is to not only deliver new information, but to also overcome people's biases and misconceptions. We study how people adjust their attitudes toward (or away from) a message experienced through a narrative visualization. In a mixed-methods analysis, we investigate whether eliciting participants' prior beliefs, and visualizing those beliefs alongside actual data, can increase narrative persuasiveness. We find that incorporating priors does not significantly affect attitudinal change. However, participants who externalized their beliefs expressed greater surprise at the data. Their comments also indicated a greater likelihood of acquiring new information, despite the minimal change in attitude. Our results also extend prior findings, showing that visualizations are more persuasive than equivalent textual data representations for exposing contentious issues. We discuss the implications and outline future research directions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {belief elicitation, narrative visualization, persuasion, debiasing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376420,
author = {McNutt, Andrew and Kindlmann, Gordon and Correll, Michael},
title = {Surfacing Visualization Mirages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376420},
doi = {10.1145/3313831.3376420},
abstract = {Dirty data and deceptive design practices can undermine, invert, or invalidate the purported messages of charts and graphs. These failures can arise silently: a conclusion derived from a particular visualization may look plausible unless the analyst looks closer and discovers an issue with the backing data, visual specification, or their own assumptions. We term such silent but significant failures . We describe a conceptual model of mirages and show how they can be generated at every stage of the visual analytics process. We adapt a methodology from software testing, , as a way of automatically surfacing potential mirages at the visual encoding stage of analysis through modifications to the underlying data and chart specification. We show that metamorphic testing can reliably identify mirages across a variety of chart types with relatively little prior knowledge of the data or the domain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {visualization testing, information visualization, deceptive visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376306,
author = {Xu, Zheer and Chen, Weihao and Zhao, Dongyang and Luo, Jiehui and Wu, Te-Yen and Gong, Jun and Yin, Sicheng and Zhai, Jialun and Yang, Xing-Dong},
title = {BiTipText: Bimanual Eyes-Free Text Entry on a Fingertip Keyboard},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376306},
doi = {10.1145/3313831.3376306},
abstract = {We present a bimanual text input method on a miniature fingertip keyboard, that invisibly resides on the first segment of a user's index finger on both hands. Text entry can be carried out using the thumb-tip to tap the tip of the index finger. The design of our keyboard layout followed an iterative process, where we first conducted a study to understand the natural expectation of the handedness of the keys in a QWERTY layout for users. Among a choice of 67,108,864 design variations, we identified 1295 candidates offering a good satisfaction for user expectations. Based on these results, we computed an optimized bimanual keyboard layout, while considering the joint optimization problems of word ambiguity and movement time. Our user evaluation revealed that participants achieved an average text entry speed of 23.4 WPM.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {bimanual input, text entry, wearable, micro finger gesture},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376807,
author = {Xie, Yao and Chen, Melody and Kao, David and Gao, Ge and Chen, Xiang 'Anthony'},
title = {CheXplain: Enabling Physicians to Explore and Understand Data-Driven, AI-Enabled Medical Imaging Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376807},
doi = {10.1145/3313831.3376807},
abstract = {The recent development of data-driven AI promises to automate medical diagnosis; however, most AI functions as 'black boxes' to physicians with limited computational knowledge. Using medical imaging as a point of departure, we conducted three iterations of design activities to formulate CheXplain — a system that enables physicians to explore and understand AI-enabled chest X-ray analysis: (i) a paired survey between referring physicians and radiologists reveals whether, when, and what kinds of explanations are needed; (ii) a low-fidelity prototype co-designed with three physicians formulates eight key features; and (iii) a high-fidelity prototype evaluated by another six physicians provides detailed summative insights on how each feature enables the exploration and understanding of AI. We summarize by discussing recommendations for future work to design and implement explainable medical AI systems that encompass four recurring themes: motivation, constraint, explanation, and justification.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {system design, physician-centered design, explainable artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376867,
author = {Zhu, Haining and Moffa, Zachary J. and Carroll, John M.},
title = {Relational Aspects in Patient-Provider Interactions: A Facial Paralysis Case Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376867},
doi = {10.1145/3313831.3376867},
abstract = {Facial appearance is significant for everyday interactions, but hundreds of thousands of people have interactions negatively affected by facial paralysis (FP) annually. FP treatment utilizes multiple components and requires significant collaboration amongst multidisciplinary specialists and patients. Complex interactions in these contexts offer ample challenges for designers to technologically support healthcare providers in their processes. We conduct a formative case study, employing 20 clinic observations and 11 interviews, to investigate FP treatment workflow. We use cognitive authority theory (CAT) to understand relational factors in patient-provider collaboration. We then pinpoint structural and relational components of workflow challenges and discuss the utility of these distinctions; notably, we identify that patient adherence lapses caused by perceived plateaus may be primarily relational and caused by unmet expectations. Our work adds to patient-provider interaction literature and sheds light upon technology design for healthcare team contexts with significant patient obligations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {therapy, cognitive authority theory, workflow, patient-provider interaction, facial paralysis, multidisciplinary team},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376481,
author = {Wilberz, Alexander and Leschtschow, Dominik and Trepkowski, Christina and Maiero, Jens and Kruijff, Ernst and Riecke, Bernhard},
title = {FaceHaptics: Robot Arm Based Versatile Facial Haptics for Immersive Environments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376481},
doi = {10.1145/3313831.3376481},
abstract = {This paper introduces FaceHaptics, a novel haptic display based on a robot arm attached to a head-mounted virtual reality display. It provides localized, multi-directional and movable haptic cues in the form of wind, warmth, moving and single-point touch events and water spray to dedicated parts of the face not covered by the head-mounted display.The easily extensible system, however, can principally mount any type of compact haptic actuator or object. User study 1 showed that users appreciate the directional resolution of cues, and can judge wind direction well, especially when they move their head and wind direction is adjusted dynamically to compensate for head rotations. Study 2 showed that adding FaceHaptics cues to a VR walkthrough can significantly improve user experience, presence, and emotional responses.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {presence, haptics, immersive environments, user study, perception, virtual reality, emotion, robot arm},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376471,
author = {Campo Woytuk, Nadia and S\o{}ndergaard, Marie Louise Juul and Ciolfi Felice, Marianela and Balaam, Madeline},
title = {Touching and Being in Touch with the Menstruating Body},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376471},
doi = {10.1145/3313831.3376471},
abstract = {We describe a Research through Design project-Curious Cycles-a collection of objects and interactions which encourage people to be in close contact with their menstruating body. Throughout a full menstrual cycle, five participants used Curious Cycles to look at their bodies in unfamiliar ways and to touch their bodily fluids, specifically, menstrual blood, saliva, and cervical mucus. The act of touching and looking led to the construction of new knowledge about the self and to a nurturing appreciation for the changing body. Yet, participants encountered and reflected upon frictions within themselves, their home, and their social surroundings, which stem from societal stigma and preconceptions about menstruation and bodily fluids. We call for and show how interaction design can engage with technologies that mediate self-touch as a first step towards reconfiguring the way menstruating bodies are treated in society.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {menstruation, touching, research through design, women's health, menstrual cycles, feminist hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376180,
author = {Chen, Kun-Ting and Dwyer, Tim and Marriott, Kim and Bach, Benjamin},
title = {DoughNets: Visualising Networks Using Torus Wrapping},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376180},
doi = {10.1145/3313831.3376180},
abstract = {We investigate visualisations of networks on a 2-dimensional torus topology, like an opened-up and flattened doughnut. That is, the network is drawn on a rectangular area while "wrapping" specific links around the border. Previous work on torus drawings of networks has been mostly theoretical, limited to certain classes of networks, and not evaluated by human readability studies. We offer a simple interactive layout approach applicable to general graphs. We use this to find layouts affording better aesthetics in terms of conventional measures like more equal edge length and fewer crossings. In two controlled user studies we find that torus layout with either additional context or interactive panning provided significant performance improvement (in terms of error and time) over torus layout without either of these improvements, to the point that it is comparable to standard non-torus layout.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {graph visualization, user study, network visualization, torus topology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376645,
author = {Rubin, Jennifer D. and Blackwell, Lindsay and Conley, Terri D.},
title = {Fragile Masculinity: Men, Gender, and Online Harassment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376645},
doi = {10.1145/3313831.3376645},
abstract = {Harassment is a persistent problem in contemporary online environments, with women disproportionately experiencing its most severe forms. While critical scholars posit that online gender harassment may be linked to men's anxieties about fulfilling normative masculine gender roles, this relationship has not been examined by empirical research. We survey 264 young men between the ages of 18-24 about their masculinity anxieties and their perceptions of harassment directed at a woman on Twitter. We find that men who perceive themselves as less masculine than average men report higher endorsement of harassment. Further, we find that the relationship between masculinity anxieties and harassment endorsement is mediated by men's adherence to masculine norms and toxic disinhibition. We interpret these results through the lens of social media's specific affordances, and we discuss their implications for technology designers and other practitioners who wish to better detect, prevent, and remediate online harassment by accounting for the role of gender.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {women, masculinity, social media, online harassment, misogyny, gender},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376438,
author = {Sidenmark, Ludwig and Clarke, Christopher and Zhang, Xuesong and Phu, Jenny and Gellersen, Hans},
title = {Outline Pursuits: Gaze-Assisted Selection of Occluded Objects in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376438},
doi = {10.1145/3313831.3376438},
abstract = {In 3D environments, objects can be difficult to select when they overlap, as this affects available target area and increases selection ambiguity. We introduce Outline Pursuits which extends a primary pointing modality for gaze-assisted selection of occluded objects. Candidate targets within a pointing cone are presented with an outline that is traversed by a moving stimulus. This affords completion of the selection by gaze attention to the intended target's outline motion, detected by matching the user's smooth pursuit eye movement. We demonstrate two techniques implemented based on the concept, one with a controller as the primary pointer, and one in which Outline Pursuits are combined with head pointing for hands-free selection. Compared with conventional raycasting, the techniques require less movement for selection as users do not need to reposition themselves for a better line of sight, and selection time and accuracy are less affected when targets become highly occluded.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {occlusion, eye tracking, virtual reality, smooth pursuits},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376349,
author = {Pandey, Maulishree and Subramonyam, Hariharan and Sasia, Brooke and Oney, Steve and O'Modhrain, Sile},
title = {Explore, Create, Annotate: Designing Digital Drawing Tools with Visually Impaired People},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376349},
doi = {10.1145/3313831.3376349},
abstract = {People often use text in their drawings to communicate their ideas. For visually impaired people, adding textual information to tactile graphics is challenging. Labeling in braille is a laborious process and clutters the drawings. Audio labels provide an alternative way to add text. However, digital drawing tools for visually impaired people have not examined the use of audio for creating labels. We conducted a study comprising three tasks with 11 visually impaired adults. Our goal was to understand how participants explored and created labeled tactile graphics (both braille and audio), and their interaction preferences. We find that audio labels were quicker to use and easier to create. However, braille labels enabled flexible exploration strategies. We also find that participants preferred multimodal interaction commands, and report hand postures and movements observed during the drawing process for designing recognizable interactions. Based on our findings, we derive design implications for digital drawing tools.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {tactile graphics, accessibility, drawing applications, blind},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376178,
author = {Swart, Michael and Lopez, Ylana and Mathur, Arunesh and Chetty, Marshini},
title = {Is This An Ad?: Automatically Disclosing Online Endorsements On YouTube With AdIntuition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376178},
doi = {10.1145/3313831.3376178},
abstract = {Undisclosed online endorsements on social media can be misleading to users who may not know when viewed content contains advertisements. Despite federal regulations requiring content creators to disclose online endorsements, studies suggest that less than 10% do so in practice. To overcome this issue, we need knowledge of how to best detect online endorsements, knowledge about how prevalent online endorsements are in the wild, and ways to design systems to automatically disclose advertising content to viewers. To that end, we designed, implemented, and evaluated a tool called AdIntuition which automatically discloses when YouTube videos contain affiliate marketing, a type of social media endorsement. We evaluated AdIntuition with 783 users using a survey, field deployment, and diary study. We discuss our findings and recommendations for future measurements of and tools to detect and alert users about affiliate marketing content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social media, influencer, advertisements, browser extension},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376504,
author = {Wampfler, Rafael and Klingler, Severin and Solenthaler, Barbara and Schinazi, Victor R. and Gross, Markus},
title = {Affective State Prediction Based on Semi-Supervised Learning from Smartphone Touch Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376504},
doi = {10.1145/3313831.3376504},
abstract = {Gaining awareness of the user's affective states enables smartphones to support enriched interactions that are sensitive to the user's context. To accomplish this on smartphones, we propose a system that analyzes the user's text typing behavior using a semi-supervised deep learning pipeline for predicting affective states measured by valence, arousal, and dominance. Using a data collection study with 70 participants on text conversations designed to trigger different affective responses, we developed a variational auto-encoder to learn efficient feature embeddings of two-dimensional heat maps generated from touch data while participants engaged in these conversations. Using the learned embedding in a cross-validated analysis, our system predicted three levels (low, medium, high) of valence (AUC up to 0.84), arousal (AUC up to 0.82), and dominance (AUC up to 0.82). These results demonstrate the feasibility of our approach to accurately predict affective states based only on touch data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smartphone, affective computing, deep learning, classification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376264,
author = {Seymour, William and Kraemer, Martin J. and Binns, Reuben and Van Kleek, Max},
title = {Informing the Design of Privacy-Empowering Tools for the Connected Home},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376264},
doi = {10.1145/3313831.3376264},
abstract = {Connected devices in the home represent a potentially grave new privacy threat due to their unfettered access to the most personal spaces in people's lives. Prior work has shown that despite concerns about such devices, people often lack sufficient awareness, understanding, or means of taking effective action. To explore the potential for new tools that support such needs directly we developed Aretha, a privacy assistant technology probe that combines a network disaggregator, personal tutor, and firewall, to empower end-users with both the knowledge and mechanisms to control disclosures from their homes. We deployed Aretha in three households over six weeks, with the aim of understanding how this combination of capabilities might enable users to gain awareness of data disclosures by their devices, form educated privacy preferences, and to block unwanted data flows. The probe, with its novel affordances-and its limitations-prompted users to co-adapt, finding new control mechanisms and suggesting new approaches to address the challenge of regaining privacy in the connected home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {technology probe, privacy-empowering technology, network disaggregator},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376879,
author = {Rohani, Darius A. and Quemada Lopategui, Andrea and Tuxen, Nanna and Faurholt-Jepsen, Maria and Kessing, Lars V. and Bardram, Jakob E.},
title = {MUBS: A Personalized Recommender System for Behavioral Activation in Mental Health},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376879},
doi = {10.1145/3313831.3376879},
abstract = {Depression is a leading cause of disability worldwide, which has inspired the design of mobile health (mHealth) applications for disease monitoring, prediction, and diagnosis. Less mHealth research has, however, focused on the treatment of depressive disorders. Clinical evidence shows that depressive symptoms can be reduced through a behavior change method known as Behavioral Activation (BA). This paper presents MUBS; a smartphone-based system for BA, which specifically contributes a personalized content-based activity recommendation model using a unique list of validated activities. An 8-week feasibility study with 17 depressive patients provided detailed insight into how MUBS provided inspiration and motivation for planning and engaging in more pleasant activities, thereby facilitating the core components of BA. Based on this study, the paper discusses how recommender technology can be used in the design of mHealth technology for BA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smartphone, well-being, depression, activities, recommendation, mental health, planning, behavioral activation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376665,
author = {Kuzminykh, Anastasia and Sun, Jenny and Govindaraju, Nivetha and Avery, Jeff and Lank, Edward},
title = {Genie in the Bottle: Anthropomorphized Perceptions of Conversational Agents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376665},
doi = {10.1145/3313831.3376665},
abstract = {This paper presents a qualitative multi-phase study seeking to identify patterns in users' anthropomorphized perceptions of conversational agents. Through a comparative analysis of behavioral perceptions and visual conceptions of three agents - Alexa, Google Assistant, and Siri - we first show that the perceptions of an agent's character are structured according to five categories: approachability, sentiment toward a user, professionalism, intelligence, and individuality. We then explore visualizations of the agents' appearance and discuss the specifics assigned to each agent. Finally, we analyze associative explanations for these perceptions. We demonstrate that the anthropomorphized behavioral and visual perceptions of agents yield structural consistency and discuss how these perceptions are linked with each other and system features.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {behavioral, conversational agents, visual, interaction, anthropomorphism, user perception, personification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376509,
author = {Kj\ae{}rup, Maria and Skov, Mikael B. and Agerholm, Niels},
title = {Digital-Enabled Last Mile: A Study of Passenger Trips in Rural, Low-Density Populated Areas},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376509},
doi = {10.1145/3313831.3376509},
abstract = {Public transportation in rural areas is difficult due to low numbers of passengers and diverse needs, also reflected in the last mile problem that points to the distance to access transportation hubs in order to connect with core networks of transportation. In this paper, we study public transportation in rural areas using a digital-enabled, demand-responsive service called Plustur. This service was recently introduced as an effort to increase mobility in underserved rural areas by creating routes ad-hoc to answer to the last mile(s). We study how passengers and drivers understand Plustur, as well as experience the role of passenger. Our findings show that Plustur is viewed as a benefit for autonomy of mobility in rural areas, however is lacking in addressing integration of modes of mobilities, flexibility and spontaneous trips. We contribute with design implications for digital multimodal mobility services.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mobility as a service, demand-responsive transit, digital-enabled passenger trips, mobility on demand},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376277,
author = {An, Pengcheng and Holstein, Kenneth and d'Anjou, Bernice and Eggen, Berry and Bakker, Saskia},
title = {The TA Framework: Designing Real-Time Teaching Augmentation for K-12 Classrooms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376277},
doi = {10.1145/3313831.3376277},
abstract = {Recently, the HCI community has seen increased interest in the design of teaching augmentation (TA): tools that extend and complement teachers' pedagogical abilities during ongoing classroom activities. Examples of TA systems are emerging across multiple disciplines, taking various forms: e.g., ambient displays, wearables, or learning analytics dashboards. However, these diverse examples have not been analyzed together to derive more fundamental insights into the design of teaching augmentation. Addressing this opportunity, we broadly synthesize existing cases to propose the TA framework. Our framework specifies a rich design space in five dimensions, to support the design and analysis of teaching augmentation. We contextualize the framework using existing designs cases, to surface underlying design trade-offs: for example, balancing actionability of presented information with teachers' needs for professional autonomy, or balancing unobtrusiveness with informativeness in the design of TA systems. Applying the TA framework, we identify opportunities for future research and design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {k-12, dashboards, augmented intelligence, teacher, classroom, ambient intelligence, orchestration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376852,
author = {M\"{u}ller, Florian and Schmitz, Martin and Schmitt, Daniel and G\"{u}nther, Sebastian and Funk, Markus and M\"{u}hlh\"{a}user, Max},
title = {Walk The Line: Leveraging Lateral Shifts of the Walking Path as an Input Modality for Head-Mounted Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376852},
doi = {10.1145/3313831.3376852},
abstract = {Recent technological advances have made head-mounted displays (HMDs) smaller and untethered, fostering the vision of ubiquitous interaction in a digitally augmented physical world. Consequently, a major part of the interaction with such devices will happen on the go, calling for interaction techniques that allow users to interact while walking. In this paper, we explore lateral shifts of the walking path as a hands-free input modality. The available input options are visualized as lanes on the ground parallel to the user's walking path. Users can select options by shifting the walking path sideways to the respective lane. We contribute the results of a controlled experiment with 18 participants, confirming the viability of our approach for fast, accurate, and joyful interactions. Further, based on the findings of the controlled experiment, we present three example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {walking, input, head-mounted display, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376771,
author = {Zhu, Suwen and Kim, Yoonsang and Zheng, Jingjie and Luo, Jennifer Yi and Qin, Ryan and Wang, Liuping and Fan, Xiangmin and Tian, Feng and Bi, Xiaojun},
title = {Using Bayes' Theorem for Command Input: Principle, Models, and Applications},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376771},
doi = {10.1145/3313831.3376771},
abstract = {Entering commands on touchscreens can be noisy, but existing interfaces commonly adopt deterministic principles for deciding targets and often result in errors. Building on prior research of using Bayes' theorem to handle uncertainty in input, this paper formalized Bayes' theorem as a generic guiding principle for deciding targets in command input (referred to as "BayesianCommand"), developed three models for estimating prior and likelihood probabilities, and carried out experiments to demonstrate the effectiveness of this formalization. More specifically, we applied BayesianCommand to improve the input accuracy of (1) point-and-click and (2) word-gesture command input. Our evaluation showed that applying BayesianCommand reduced errors compared to using deterministic principles (by over 26.9% for point-and-click and by 39.9% for word-gesture command input) or applying the principle partially (by over 28.0% and 24.5%).},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {command input, point-and-click, touchscreen, bayes' theorem, word-gesture shortcuts},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376515,
author = {Wong, Richmond Y. and Khovanskaya, Vera and Fox, Sarah E. and Merrill, Nick and Sengers, Phoebe},
title = {Infrastructural Speculations: Tactics for Designing and Interrogating Lifeworlds},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376515},
doi = {10.1145/3313831.3376515},
abstract = {This paper introduces "infrastructural speculations," an orientation toward speculative design that considers the complex and long-lived relationships of technologies with broader systems, beyond moments of immediate invention and design. As modes of speculation are increasingly used to interrogate questions of broad societal concern, it is pertinent to develop an orientation that foregrounds the "lifeworld" of artifacts-the social, perceptual, and political environment in which they exist. While speculative designs often imply a lifeworld, infrastructural speculations place lifeworlds at the center of design concern, calling attention to the cultural, regulatory, environmental, and repair conditions that enable and surround particular future visions. By articulating connections and affinities between speculative design and infrastructure studies research, we contribute a set of design tactics for producing infrastructural speculations. These tactics help design researchers interrogate the complex and ongoing entanglements among technologies, institutions, practices, and systems of power when gauging the stakes of alternate lifeworlds.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {speculative design, design research, futures, infrastructure studies, infrastructure, lifeworld},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376835,
author = {Chen, Yan and Pandey, Maulishree and Song, Jean Y. and Lasecki, Walter S. and Oney, Steve},
title = {Improving Crowd-Supported GUI Testing with Structural Guidance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376835},
doi = {10.1145/3313831.3376835},
abstract = {Crowd testing is an emerging practice in Graphical User Interface (GUI) testing, where developers recruit a large number of crowd testers to test GUI features. It is often easier and faster than a dedicated quality assurance team, and its output is more realistic than that of automated testing. However, crowds of testers working in parallel tend to focus on a small set of commonly-used User Interface (UI) navigation paths, which can lead to low test coverage and redundant effort. In this paper, we introduce two techniques to increase crowd testers' coverage: interactive event-flow graphs and GUI-level guidance. The interactive event-flow graphs track and aggregate every tester's interactions into a single directed graph that visualizes the cases that have already been explored. Crowd testers can interact with the graphs to find new navigation paths and increase the coverage of the created tests. We also use the graphs to augment the GUI (GUI-level guidance) to help testers avoid only exploring common paths. Our evaluation with 30 crowd testers on 11 different test pages shows that the techniques can help testers avoid redundant effort while also increasing untrained testers' coverage by 55%. These techniques can help us develop more robust software that works in more mission-critical settings not only by performing more thorough testing with the same effort that has been put in before but also by integrating them into different parts of the development pipeline to make more reliable software in the early development stage.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {GUI testing, crowdsourcing, software testing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376363,
author = {Hui, Julie and Barber, Nefer Ra and Casey, Wendy and Cleage, Suzanne and Dolley, Danny C. and Worthy, Frances and Toyama, Kentaro and Dillahunt, Tawanna R.},
title = {Community Collectives: Low-Tech Social Support for Digitally-Engaged Entrepreneurship},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376363},
doi = {10.1145/3313831.3376363},
abstract = {With the rise of social media, entrepreneurs are feeling the pressure to adopt digital tools for their work. However, the upfront effort and resources needed to participate on these platforms is ever more complex, particularly in underresourced contexts. Through participatory action research over two years in Detroit's Eastside, we found that local entrepreneurs preferred to become engaged digitally through a community collective, which involved (a) resource-connecting organizations, (b) regular in-person meetings, (c) paper planning tools, and (d) practice and validation. Together, these elements combined to provide (1) awareness and willingness to use digital tools, (2) regular opportunities to build internet self-efficacy, and (3) ways to collectively overcome digital obstacles. We discuss our findings in the context of digital engagement and entrepreneurship, and outline recommendations for digital platforms seeking to better support economic mobility more broadly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {qualitative methods, participatory action research, digital divide, entrepreneurship, community informatics, digital literacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376470,
author = {Fang, Cathy and Zhang, Yang and Dworman, Matthew and Harrison, Chris},
title = {Wireality: Enabling Complex Tangible Geometries in Virtual Reality with Worn Multi-String Haptics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376470},
doi = {10.1145/3313831.3376470},
abstract = {Today's virtual reality (VR) systems allow users to explore immersive new worlds and experiences through sight. Unfortunately, most VR systems lack haptic feedback, and even high-end consumer systems use only basic vibration motors. This clearly precludes realistic physical interactions with virtual objects. Larger obstacles, such as walls, railings, and furniture are not simulated at all. In response, we developed Wireality, a self-contained worn system that allows for individual joints on the hands to be accurately arrested in 3D space through the use of retractable wires that can be programmatically locked. This allows for convincing tangible interactions with complex geometries, such as wrapping fingers around a railing. Our approach is lightweight, low-cost, and low-power, criteria important for future, worn consumer uses. In our studies, we further show that our system is fast-acting, spatially-accurate, high-strength, comfortable, and immersive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {haptics, touch, force feedback, virtual reality, grasp, string-driven},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376452,
author = {Son, Kihoon and Chun, Hwiwon and Park, Sojin and Hyun, Kyung Hoon},
title = {C-Space: An Interactive Prototyping Platform for Collaborative Spatial Design Exploration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376452},
doi = {10.1145/3313831.3376452},
abstract = {C-Space is an interactive prototyping platform for collaborative spatial design exploration. Spatial design projects often begin with conceptualization that includes abstract diagramming, zoning, and massing to provide a foundation for making design decisions. Specifically, abstract diagrams guide designers to explore alternative designs without thinking prematurely about the details. However, complications arise when communicating ambiguous and incomplete designs to collaborators. To overcome this drawback, designers devote considerable amounts of time and resources into searching for design references and creating rough prototypes to explicate their design concepts better. Therefore, this study proposes C-Space, a novel design support system that integrates the abstract diagram with design reference retrieval and prototyping through a tangible user interface and augmented reality. Through a user study with 12 spatial designers, we verify that C-Space promotes rapid and robust spatial design exploration, inducing collaborative discussions and motivating users to interact with designs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-computer interaction, design support system, prototyping, design collaboration, tangible user interface, augmented reality, spatial design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376148,
author = {Martinez-Maldonado, Roberto and Echeverria, Vanessa and Fernandez Nieto, Gloria and Buckingham Shum, Simon},
title = {From Data to Insights: A Layered Storytelling Approach for Multimodal Learning Analytics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376148},
doi = {10.1145/3313831.3376148},
abstract = {Significant progress to integrate and analyse multimodal data has been carried out in the last years. Yet, little research has tackled the challenge of visualising and supporting the sensemaking of multimodal data to inform teaching and learning. It is na\"{\i}ve to expect that simply by rendering multiple data streams visually, a teacher or learner will be able to make sense of them. This paper introduces an approach to unravel the complexity of multimodal data by organising it into meaningful layers that explain critical insights to teachers and students. The approach is illustrated through the design of two data storytelling prototypes in the context of nursing simulation. Two authentic studies with educators and students identified the potential of the approach to create learning analytics interfaces that communicate insights on team performance, as well as concerns in terms of accountability and automated insights discovery.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {data storytelling, teamwork, CSCW, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376795,
author = {Avellino, Ignacio and Bailly, Gilles and Arico, Mario and Morel, Guillaume and Canlorbe, Geoffroy},
title = {Multimodal and Mixed Control of Robotic Endoscopes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376795},
doi = {10.1145/3313831.3376795},
abstract = {Bedside robotic endoscopes render surgeons autonomous from assistants, potentially improving surgical outcome and decreasing costs. Why then have they not been widely adopted? We take a step back and first characterize classic (non-robotic) endoscope use through observations, literature and a domain expert interview. We review the literature on bedside robotic endoscopes and find that existing controls, individually, do not have the power to support both intended and appropriated endoscope uses. We thus explore combining controls to support this diversity of uses. Through an iterative cycle, we design and implement a multimodal and mixed-initiative technique that combines two user controls and one system control. Our evaluations confirm that individual controls do not satisfy the diversity of endoscope uses, and also that our technique indeed does so. Our work highlights the relevance of HCI research in the medical domain through robotic systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {minimally invasive surgery, mixed-initiative interfaces, robotic endoscope manipulator},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376292,
author = {Wang, Bo-Xiang and Wang, Yu-Wei and Chen, Yen-Kai and Tseng, Chun-Miao and Hsu, Min-Chien and Hsieh, Cheng An and Lee, Hsin-Ying and Chen, Mike Y.},
title = {Miniature Haptics: Experiencing Haptic Feedback through Hand-Based and Embodied Avatars},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376292},
doi = {10.1145/3313831.3376292},
abstract = {We present Miniature Haptics, a new approach to providing realistic haptic experiences by applying miniaturized haptic feedback to hand-based, embodied avatars. By shrinking haptics to a much smaller scale, Miniature Haptics enables the exploration of new haptic experiences that are not practical to create at the full, human-body scale. Using Finger Walking in Place (FWIP) as an example avatar embodiment and control method, we first explored the feasibility of Miniature Haptics then conducted a human factors study to understand how people map their full-body skeletal model to their hands. To understand the user experience of Miniature Haptic, we developed a miniature football haptic display, and results from our user study show that Miniature Haptics significantly improved the realism and enjoyment of the experience and is preferred by users (p &lt; 0.05). In addition, we present two miniature motion platforms supporting the haptic experiences of: 1) rapidly changing ground height for platform jumping games such as Super Mario Bros and 2) changing terrain slope. Overall, Miniature Haptics makes it possible to explore novel haptic experiences that have not been practical before.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {embodied avatar, haptics, embodiment illusion, finger walking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376610,
author = {Jiang, Yue and Stuerzlinger, Wolfgang and Zwicker, Matthias and Lutteroth, Christof},
title = {ORCSolver: An Efficient Solver for Adaptive GUI Layout with OR-Constraints},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376610},
doi = {10.1145/3313831.3376610},
abstract = {OR-constrained (ORC) graphical user interface layouts unify conventional constraint-based layouts with flow layouts, which enables the definition of flexible layouts that adapt to screens with different sizes, orientations, or aspect ratios with only a single layout specification. Unfortunately, solving ORC layouts with current solvers is time-consuming and the needed time increases exponentially with the number of widgets and constraints. To address this challenge, we propose ORCSolver, a novel solving technique for adaptive ORC layouts, based on a branch-and-bound approach with heuristic preprocessing. We demonstrate that ORCSolver simplifies ORC specifications at runtime and our approach can solve ORC layout specifications efficiently at near-interactive rates.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {gui builder, optimization, layout manager, visual interface design, visual programming, constraint-based layout},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376491,
author = {Muthukumarana, Sachith and Elvitigala, Don Samitha and Forero Cortes, Juan Pablo and Matthies, Denys J.C. and Nanayakkara, Suranga},
title = {Touch Me Gently: Recreating the Perception of Touch Using a Shape-Memory Alloy Matrix},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376491},
doi = {10.1145/3313831.3376491},
abstract = {We present a wearable forearm augmentation that enables the recreation of natural touch sensation by applying shear-forces onto the skin. In contrast to previous approaches, we arrange light-weight and stretchable 3x3cm plasters in a matrix onto the skin. Individual plasters were embedded with lines of shape-memory alloy (SMA) wires to generate shear-forces. Our design is informed by a series of studies investigating the perceptibility of different sizes, spacings, and attachments of plasters on the forearm. Our matrix arrangement enables the perception of touches, for instance, feeling ones wrist being grabbed or the arm being stroked. Users rated the recreated touch sensations as being fairly similar to a real touch (4.1/5). Even without a visual representation, users were able to correctly distinguish them with an overall accuracy of 94.75%. Finally, we explored two use cases showing how AR and VR could be empowered with experiencing recreated touch sensations on the forearm.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touch perception, pinching, shape memory alloys, wearable, haptics, recreation of touch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376432,
author = {Dixon, Emma and Lazar, Amanda},
title = {Approach Matters: Linking Practitioner Approaches to Technology Design for People with Dementia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376432},
doi = {10.1145/3313831.3376432},
abstract = {Technology design for dementia is an active and growing area. Though work to date has largely addressed functional needs, there is a growing recognition of the importance of supporting meaningful activities. However, technology for active, rather than passive, engagement is relatively novel beyond specific applications (e.g., music or reminiscence therapy). To better understand how to support active engagement of people with dementia in activities, we interviewed nineteen practitioners. Our findings reveal differing approaches to making sense of the actions of people with dementia, as well as to engaging them in activities. We discuss the importance of tracing epistemological understandings of dementia to different configurations of technology for people living with dementia and provide a practical guide to support designers to do so. Finally, we discuss considerations for the design of dementia technologies around facilitating self-actualization and managing emotional exposure for care-providers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {design, practitioners, dementia, meaningful activities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376561,
author = {Wang, Jinping and Yang, Hyun and Shao, Ruosi and Abdullah, Saeed and Sundar, S. Shyam},
title = {Alexa as Coach: Leveraging Smart Speakers to Build Social Agents That Reduce Public Speaking Anxiety},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376561},
doi = {10.1145/3313831.3376561},
abstract = {Public speaking anxiety is one of the most common social phobias. We explore the feasibility of using a conversational agent to reduce this anxiety. We developed a public-speaking tutor on the Amazon Alexa platform that enables users to engage in cognitive reconstruction exercises. We also investigated how the sociability of the agent might affect its performance as a tutor. A user study of 53 college students with fear of public speaking showed that the interaction with the agent served to assuage pre-speech state anxiety. Agent sociability improved the sense of interpersonal closeness, which was associated with lower pre-speech anxiety. Moreover, sociability of the agent increased participants' satisfaction and their willingness to continue engagement. Our findings, thus, have implications not only for addressing public speaking anxiety in a scalable way but also for the design of future conversational agents using smart speaker platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sociability, conversational agent, public speaking anxiety, experiment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376187,
author = {Parviainen, Emmi and S\o{}ndergaard, Marie Louise Juul},
title = {Experiential Qualities of Whispering with Voice Assistants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376187},
doi = {10.1145/3313831.3376187},
abstract = {We present a Research through Design project that explores how whispering influences the ways people experience and interact with voice assistants. The research project includes a co-speculation workshop and the use of a design probe, which culminated in the production of a design fiction short film. Our design-led inquiry contributes with experiential qualities of whispering with voice assistants: creepiness, trust, and intimacy. Furthermore, we present how whispering opens up new dimensions of how and when voice interaction could be used. We propose that designers of whispering voice assistants should reflect on how they facilitate the experiential qualities of creepiness, trust, and intimacy, and reflect on the potential challenges whispering brings to the relation between a user and a voice assistant.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {voice assistants, voice interaction, experiential qualities, research through design, design fiction, whispering},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376597,
author = {Yoo, Daisy and Tabard, Aur\'{e}lien and Ducros, Alix and Dalsgaard, Peter and Klokmose, Clemens Nylandsted and Eriksson, Eva and Serholt, Sofia},
title = {Computational Alternatives Vignettes for Place- and Activity-Centered Digital Services in Public Libraries},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376597},
doi = {10.1145/3313831.3376597},
abstract = {We investigate how to design community technologies for public events. We do so with a focus on technologies that give rise to new forms of participation and knowledge co-production in public libraries. Specifically, we deployed a digital service at a major public library during its four-week creative workshop series. The system offered an alternative way for people to work together as a community, to go beyond achieving individual goals, and to contribute to the achievement of public goals (e.g., building community bookshelves). We report on how the system has reconfigured physical spaces and afforded new social practices in the library. We propose Computational Alternatives as a fruitful approach for gaining situated, nuanced insights into a technology's possible adoption. We offer key insights in the form of computational alternatives vignettes -- grounded stories that encapsulate sociotechnical implications of technology, pointing to plausible alternative futures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {library events, place-centric, third places, public libraries, knowledge sharing, computational alternatives},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376846,
author = {Williams, Francis and Bock, Alexander and Doraiswamy, Harish and Donatelli, Cassandra and Hall, Kayla and Summers, Adam and Panozzo, Daniele and Silva, Cl\'{a}udio T.},
title = {Unwind: Interactive Fish Straightening},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376846},
doi = {10.1145/3313831.3376846},
abstract = {The ScanAllFish project is a large-scale effort to scan all the world's 33,100 known species of fishes. It has already generated thousands of volumetric CT scans of fish species which are available on open access platforms such as the Open Science Framework. To achieve a scanning rate required for a project of this magnitude, many specimens are grouped together into a single tube and scanned all at once. The resulting data contain many fish which are often bent and twisted to fit into the scanner. Our system, Unwind, is a novel interactive visualization and processing tool which extracts, unbends, and untwists volumetric images of fish with minimal user interaction. Our approach enables scientists to interactively unwarp these volumes to remove the undesired torque and bending using a piecewise-linear skeleton extracted by averaging isosurfaces of a harmonic function connecting the head and tail of each fish. The result is a volumetric dataset of a individual, straight fish in a canonical pose defined by the marine biologist expert user. We have developed Unwind in collaboration with a team of marine biologists: Our system has been deployed in their labs, and is presently being used for dataset construction, biomechanical analysis, and the generation of figures for scientific publication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive system, ct scan data, visualization, volumetric deformation, visual analytics, visualization toolkits},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376551,
author = {Cho, Eugene and Sundar, S. Shyam and Abdullah, Saeed and Motalebi, Nasim},
title = {Will Deleting History Make Alexa More Trustworthy? Effects of Privacy and Content Customization on User Experience of Smart Speakers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376551},
doi = {10.1145/3313831.3376551},
abstract = {"Always-on" smart speakers have raised privacy and security concerns, to address which vendors have introduced customizable privacy settings. But, does the act of customizing one's privacy preferences have any effects on user experience and trust? To address this question, we developed an app for Amazon Alexa and conducted a user study (N = 90). Our data show that the affordance to customize privacy settings enhances trust and usability for regular users, while it has adverse effects on power users. In addition, only enabling privacy-setting customization without allowing content customization negatively affects trust among users with higher privacy concerns. When they can customize both content and privacy settings, user trust is highest. That is, while privacy customization may cause reactance among power users, allowing privacy-concerned individuals to simultaneously customize content can help to alleviate the resultant negative effect on trust. These findings have implications for designing more privacy-sensitive and trustworthy smart speakers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {customization, security, voice assistant(s), power usage, smart speaker(s), privacy concern},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376538,
author = {Raissi, Reyhaneh and Dimara, Evanthia and Berry, Jacquelyn H. and Gray, Wayne D. and Bailly, Gilles},
title = {Retroactive Transfer Phenomena in Alternating User Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376538},
doi = {10.1145/3313831.3376538},
abstract = {We investigated retroactive transfer when users alternate between different interfaces. Retroactive transfer is the influence of a newly learned interface on users' performance with a previously learned interface. In an interview study, participants described their experiences when alternating between different interfaces, e.g. different operating systems, devices or techniques. Negative retroactive transfer related to text entry was the most frequently reported incident. We then reported a laboratory experiment that investigated the impact of similarity between two abstract keyboard layouts, and the number of alternations between them, on retroactive interference. Results indicated that even small changes in the interference interface produced a significant performance drop for the entire previously learned interface. The amplitude of this performance drop decreases with the number of alternations. We suggest that retroactive transfer should receive more attention in HCI, as the ubiquitous nature of interactions across applications and systems requires users to increasingly alternate between similar interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {skill transfer, keyboard layout, retroactive interference},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376217,
author = {Li, Yang and Sarcar, Sayan and Kim, Sunjun and Ren, Xiangshi},
title = {Swap: A Replacement-Based Text Revision Technique for Mobile Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376217},
doi = {10.1145/3313831.3376217},
abstract = {Text revision is an important task to ensure the accuracy of text content. Revising text on mobile devices is cumbersome and time-consuming due to the imprecise caret control and the repetitive use of the backspace. We present Swap, a novel replacement-based technique to facilitate text revision on mobile devices. We conducted two user studies to validate the feasibility and the effectiveness of Swap compared to traditional text revision techniques. Results showed that Swap reduced efforts in caret control and repetitive backspace pressing during the text revision process. Most participants preferred to use the replacement-based technique rather than backspace and caret. They also commented that the new technique is easy to learn, and it makes text revision rapid and intuitive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mobile device, text revision, backspace, caret control, virtual keyboard},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376859,
author = {Altarriba Bertran, Ferran and M\'{a}rquez Segura, Elena and Isbister, Katherine},
title = {Technology for Situated and Emergent Play: A Bridging Concept and Design Agenda},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376859},
doi = {10.1145/3313831.3376859},
abstract = {Despite the capacity of play to spontaneously emerge in our daily life, the scope of application of play design in HCI is generally narrower, specifically targeting areas of pure leisure, or wholly utilitarian and productive play. Here we focus on the value of play design to respond to and support our natural gravitation towards emergent play that helps to meet our social and emotional needs. We present a bridging concept: Technology for Situated and Emergent Play, i.e. technology design that supports playful engagement that emerges interwoven with our everyday activities outside leisure, and that enriches these activities with socio-emotional value. Our intermediate-level contribution has value as a synthesis piece: it weaves together theories of play and play design and bridges them with concrete design examples. As a bridging concept, it contributes: i) theoretical grounding; ii) inspiring design exemplars that illustrate the theory and foreground its value; and iii) design articulations in the form of valuable experiential qualities and design features. Our work can help to focus design agendas for playful technology and inspire future designs in this space.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {playfulness, hci, interaction design, play},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376147,
author = {Matulic, Fabrice and Arakawa, Riku and Vogel, Brian and Vogel, Daniel},
title = {PenSight: Enhanced Interaction with a Pen-Top Camera},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376147},
doi = {10.1145/3313831.3376147},
abstract = {We propose mounting a downward-facing camera above the top end of a digital tablet pen. This creates a unique and practical viewing angle for capturing the pen-holding hand and the immediate surroundings which can include the other hand. The fabrication of a prototype device is described and the enabled interaction design space is explored, including dominant and non-dominant hand pose recognition, tablet grip detection, hand gestures, capturing physical content in the environment, and detecting users and pens. A deep learning computer vision pipeline is developed for classification, regression, and keypoint detection to enable these interactions. Example applications demonstrate usage scenarios and a qualitative user evaluation confirms the potential of the approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {tablet input, hand pose estimation, pen input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376743,
author = {Kim, Taewan and Ruensuk, Mintra and Hong, Hwajung},
title = {In Helping a Vulnerable Bot, You Help Yourself: Designing a Social Bot as a Care-Receiver to Promote Mental Health and Reduce Stigma},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376743},
doi = {10.1145/3313831.3376743},
abstract = {Helping others can have a positive effect on both the giver and the receiver. However, supporting someone with depression can be complicated and overwhelming. To address this, we proposed a Facebook-based social bot displaying depressive symptoms and disclosing vulnerable experiences that allows users to practice providing reactions online. We investigated how 55 college students interacted with the social bot for three weeks and how these support-giving experiences affected their mental health and stigma. By responding to the bot, the participants reframed their own negative experiences, reported reduced feelings of danger regarding an individual with depression and increased willingness to help the person, and presented favorable attitudes toward seeking treatment for depression. We discuss design opportunities for accessible social bots that could help users to keep practicing peer support interventions without fear of negative consequences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mental health, college student, stigma, health, depression, social bot},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376356,
author = {Markum, Robert B. and Toyama, Kentaro},
title = {Digital Technology, Meditative and Contemplative Practices, and Transcendent Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376356},
doi = {10.1145/3313831.3376356},
abstract = {Meditative and contemplative practices are common among U.S. adults, but the impact of digital technology use on these practices and on associated transcendent experiences is poorly understood. Through semi-structured interviews with sixteen experienced practitioners from a variety of traditions, we find that practitioners consider digital technology to be a mixed blessing. While they see its practical value, they are wary of its stimulation-based effects and find minimal usefulness in commercial meditation apps. They also feel that digital technology use may interfere with possible transcendent experiences. The practitioners, however, applied insights from their respective practices to strategically mitigate digital technology's negative effects in three ways: limiting its use to instrumental purposes, using technology interactions as grist for self-reflection, and integrating technology itself into a site for practice. Specific design recommendations are discussed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {digital technology, meditative and contemplative practices, techno-spirituality, transcendent experiences},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376704,
author = {Gan, Yumei and Greiffenhagen, Christian and Reeves, Stuart},
title = {Connecting Distributed Families: Camera Work for Three-Party Mobile Video Calls},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376704},
doi = {10.1145/3313831.3376704},
abstract = {Mobile video calling technologies have become a critical link to connect distributed families. However, these technologies have been principally designed for video calling between two parties, whereas family video calls involve young children often comprise three parties, namely a co-present adult (a parent or grandparent) helping with the interaction between the child and another remote adult. We examine how manipulation of phone cameras and management of co-present children is used to stage parent-child interactions. We present results from a video-ethnographic study based on 40 video recordings of video calls between 'left-behind' children and their migrant parents in China. Our analysis reveals a key practice of 'facilitation work', performed by grandparents, as a crucial feature of three-party calls. Facilitation work offers a new concept for HCI's broader conceptualisation of mobile video calling, suggesting revisions that design might take into consideration for triadic interactions in general.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mobile video calls, camera work, distributed families, conversation analysis, facilitation work},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376850,
author = {Olgado, Benedict Salazar and Pei, Lucy and Crooks, Roderic},
title = {Determining the Extractive Casting Mold of Intimate Platforms through Document Theory},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376850},
doi = {10.1145/3313831.3376850},
abstract = {This paper introduces document theory as a mechanism to analyze intimate platforms as sociotechnical systems. The theory, developed in documentation studies and applied to HCI, focuses on the casting mold or how agents, through particular means and modes, produce documents that govern social relations. We studied the process of creating a profile by identifying and mapping out the fields asked among the ten most popular online dating apps in the US. By looking at dating profiles as documents and their creation as a process of documentation, we argue that the current casting mold of these intimate platforms is designed to extract profit via invisibilization of labor in digital networks leading to the emergence of a constrained rational market agent. Our study illustrates how document theory makes visible the assumptions of technological systems, calling on us to imagine alternatives beyond incremental design changes given broader structural realities of market and power.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {political economy, intimate platforms, document theory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376767,
author = {Reyes-Cruz, Gisela and Fischer, Joel E. and Reeves, Stuart},
title = {Reframing Disability as Competency: Unpacking Everyday Technology Practices of People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376767},
doi = {10.1145/3313831.3376767},
abstract = {More than a billion people in the world live with some form of visual impairment, and a wide variety of technologies are now routinely used by them in the course of 'getting on' in everyday life. However, little is known about the ways in which assistive and non-assistive technologies are brought to bear on material practices. We present findings from a four-month ethnographic study facilitated by a local branch of a UK charity that supports people with visual impairments. Our study explores mainstream and assistive technology use within their everyday lives. We identify three main sites for technology use: social relations and communication practices, textual reading practices, and mobility practices. Via an ethnographic approach we contribute to understanding how people accomplish such practices, and in doing so, uncover the practical competencies that enable people with visual impairments to conduct their everyday activities. Thus we investigate how disability can be thought of in terms of competencies, arguing that understanding of competencies can enrich the design of technologies that fit the needs of people with visual impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {assistive technology, ethnography, visual impairments, disability, ethnomethodology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376848,
author = {Wacker, Philipp and Wagner, Adrian and Voelker, Simon and Borchers, Jan},
title = {Heatmaps, Shadows, Bubbles, Rays: Comparing Mid-Air Pen Position Visualizations in Handheld AR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376848},
doi = {10.1145/3313831.3376848},
abstract = {In Handheld Augmented Reality, users look at AR scenes through the smartphone held in their hand. In this setting, having a mid-air pointing device like a pen in the other hand greatly expands the interaction possibilities. For example, it lets users create 3D sketches and models while on the go. However, perceptual issues in Handheld AR make it difficult to judge the distance of a virtual object, making it hard to align a pen to it. To address this, we designed and compared different visualizations of the pen's position in its virtual environment, measuring pointing precision, task time, activation patterns, and subjective ratings of helpfulness, confidence, and comprehensibility of each visualization. While all visualizations resulted in only minor differences in precision and task time, subjective ratings of perceived helpfulness and confidence favor a 'heatmap' technique that colors the objects in the scene based on their distance to the pen.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {3D pen, depth perception, mid-air, smartphone, depth cues, interaction, modeling, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376360,
author = {Schubhan, Marc and Altmeyer, Maximilian and Buchheit, Dominic and Lessel, Pascal},
title = {Investigating User-Created Gamification in an Image Tagging Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376360},
doi = {10.1145/3313831.3376360},
abstract = {Commonly, gamification is designed by developers and not by end-users. In this paper we investigate an approach where users take control of this process. Firstly, users were asked to describe their own gamification concepts which would motivate them to put more effort into an image tagging task. We selected this task as gamification has already been shown to be effective here in previous work. Based on these descriptions, an implementation was made for each concept and given to the creator. In a between-subjects study (n=71), our approach was compared to a no-gamification condition and two conditions with fixed gamification settings. We found that providing participants with an implementation of their own concept significantly increased the amount of generated tags compared to the other conditions. Although the quality of tags was lower, the number of usable tags remained significantly higher in comparison, suggesting the usefulness of this approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {customization, user-driven game design, replication, bottom-up, motivation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376472,
author = {Colley, Mark and Walch, Marcel and Gugenheimer, Jan and Askari, Ali and Rukzio, Enrico},
title = {Towards Inclusive External Communication of Autonomous Vehicles for Pedestrians with Vision Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376472},
doi = {10.1145/3313831.3376472},
abstract = {People with vision impairments (VIP) are among the most vulnerable road users in traffic. Autonomous vehicles are believed to reduce accidents but still demand some form of external communication signaling relevant information to pedestrians. Recent research on the design of vehicle-pedestrian communication (VPC) focuses strongly on concepts for a non-disabled population. Our work presents an inclusive user-centered design for VPC, beneficial for both vision impaired and seeing pedestrians. We conducted a workshop with VIP (N=6), discussing current issues in road traffic and comparing communication concepts proposed by literature. A thematic analysis unveiled two important themes: number of communicating vehicles and content (affecting duration). Subsequently, we investigated these in a second user study in virtual reality (N=33, 8 VIP) comparing the VPC between groups of abilities. We found that trust and understanding is enhanced and cognitive load reduced when all relevant vehicles communicate; high content messages also reduce cognitive load.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {vulnerable road users, autonomous vehicles, accessibility, inclusive design research, external communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376718,
author = {Beede, Emma and Baylor, Elizabeth and Hersch, Fred and Iurchenko, Anna and Wilcox, Lauren and Ruamviboonsuk, Paisan and Vardoulakis, Laura M.},
title = {A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376718},
doi = {10.1145/3313831.3376718},
abstract = {Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human-centered ai, diabetes, health, deep learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376503,
author = {Iravantchi, Yasha and Goel, Mayank and Harrison, Chris},
title = {Digital Ventriloquism: Giving Voice to Everyday Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376503},
doi = {10.1145/3313831.3376503},
abstract = {Smart speakers with voice agents are becoming increasingly common. However, the agent's voice always emanates from the device, even when that information is contextually and spatially relevant elsewhere. Digital Ventriloquism allows smart speakers to render sound onto everyday objects, such that it appears they are speaking and are interactive. This can be achieved without any modification of objects or the environment. For this, we used a highly directional pan-tilt ultrasonic array. By modulating a 40 kHz ultrasonic signal, we can emit sound that is inaudible "in flight" and demodulates to audible frequencies when impacting a surface through acoustic parametric interaction. This makes it appear as though the sound originates from an object and not the speaker. We ran a study in which we projected speech onto five objects in three environments, and found that participants were able to correctly identify the source object 92% of the time and correctly repeat the spoken message 100% of the time, demonstrating our digital ventriloquy is both directional and intelligible.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {interaction, ultrasound, smart speakers, vr/ar, iot},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376699,
author = {Ding, Xianghua and Gui, Xinning and Ma, Xiaojuan and Ding, Zhaofei and Chen, Yunan},
title = {Getting the Healthcare We Want: The Use of Online "Ask the Doctor" Platforms in Practice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376699},
doi = {10.1145/3313831.3376699},
abstract = {Online Ask the Doctor (AtD) services allow access to health professionals anytime anywhere beyond existing patient-provider relationships. Recently, many free-market AtD platforms have emerged and been adopted by a large scale of users. However, it is still unclear how people make use of these AtD platforms in practice. In this paper, we present an interview study with 12 patients/caregivers who had experience using AtD in China, highlighting patient agency in seeking more reliable and cost-effective healthcare beyond clinic settings. Specifically, we illustrate how they make strategic choices online on AtD platforms, and how they strategically integrate online and offline services together for healthcare. This paper contributes an empirical study of the use of large-scale AtD platforms in practice, demonstrates patient agency for healthcare beyond clinic settings, and recommends design implications for online healthcare services.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {healthcare engagement, AtD, online healthcare services, patient agency, healthcare navigation, ask the doctor services},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376689,
author = {Claisse, Caroline and Petrelli, Daniela and Ciolfi, Luigina and Dulake, Nick and Marshall, Mark T. and Durrant, Abigail C.},
title = {Crafting Critical Heritage Discourses into Interactive Exhibition Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376689},
doi = {10.1145/3313831.3376689},
abstract = {This paper argues how a more reflective design practice that embraces critical discourses can transform interactive exhibition design and therefore the museum visiting experience. Four framing arguments underpin our exhibition design making: the value of materiality, visiting as an aesthetic experience, challenging the authorized voice, and heritage as a process. These arguments were embodied through design, art and craft practice into one interactive exhibition at a house museum. We draw from our design process discussing the implications that adopting an approach informed by critical heritage debates has on exhibition design and suggest three sensitizing concepts (polyvocal narratives, dialogical interaction, interweaving time and space) bridging the practice of interactive exhibition design and critical heritage theory.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {critical heritage, tangible interaction, reflective practice, craft practice, exhibition design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376192,
author = {Fern\'{a}ndez Camporro, Marina and Marquardt, Nicolai},
title = {Live Sketchnoting Across Platforms: Exploring the Potential and Limitations of Analogue and Digital Tools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376192},
doi = {10.1145/3313831.3376192},
abstract = {Sketchnoting is the process of creating a visual record with combined text and imagery of an event or presentation. Although analogue tools are still the most common method for sketchnoting, the use of digital tools is increasing. We conducted a study to better understand the current practices, techniques, compromises and opportunities of creating both pen&amp;paper and digital sketchnotes. Our research combines insights from semi-structured interviews with the findings from a within-subjects observational study where ten participants created real time sketchnotes of two video presentations on both paper and digital tablet. We report our key findings, categorised into six themes: insights into sense of space; trade-offs with flexibility; choice paradox and cognitive load; matters of perception, accuracy and texture; issues around confidence; and practicalities. We discuss those findings, the potential and limitations of different methods, and implications for the design of future digital sketchnoting tools.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pen interaction, digital ink, sketchnoting, visual note taking, sketching, tablet},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376493,
author = {Wirfs-Brock, Jordan and Mennicken, Sarah and Thom, Jennifer},
title = {Giving Voice to Silent Data: Designing with Personal Music Listening History},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376493},
doi = {10.1145/3313831.3376493},
abstract = {Music streaming services collect listener data to support personalization and discovery of their extensive catalogs. Yet this data is typically used in ways that are not immediately apparent to listeners. We conducted design workshops with ten Spotify listeners to imagine future voice assistant (VA) interactions leveraging logged music data. We provided participants with detailed personal music listening data, such as play-counts and temporal patterns, which grounded their design ideas in their current behaviors. In the interactions participants designed, VAs did not simply speak their data out loud; instead, participants envisioned how data could implicitly support introspection, behavior change, and exploration. We present reflections on how VAs could evolve from voice-activated remote controls to intelligent music coaches and how personal data can be leveraged as a design resource.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {personal informatics, voice assistants, speculative design, co-design, participatory design, music},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376782,
author = {Srinivasan, Arjun and Lee, Bongshin and Henry Riche, Nathalie and Drucker, Steven M. and Hinckley, Ken},
title = {InChorus: Designing Consistent Multimodal Interactions for Data Visualization on Tablet Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376782},
doi = {10.1145/3313831.3376782},
abstract = {While tablet devices are a promising platform for data visualization, supporting consistent interactions across different types of visualizations on tablets remains an open challenge. In this paper, we present multimodal interactions that function consistently across different visualizations, supporting common operations during visual data analysis. By considering standard interface elements (e.g., axes, marks) and grounding our design in a set of core concepts including operations, parameters, targets, and instruments, we systematically develop interactions applicable to different visualization types. To exemplify how the proposed interactions collectively facilitate data exploration, we employ them in a tablet-based system, InChorus that supports pen, touch, and speech input. Based on a study with 12 participants performing replication and factchecking tasks with InChorus, we discuss how participants adapted to using multimodal input and highlight considerations for future multimodal visualization systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {pen, tablet devices, touch, multimodal interaction, speech, data visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376171,
author = {Wilson, Cara and Sitbon, Laurianne and Ploderer, Bernd and Opie, Jeremy and Brereton, Margot},
title = {Self-Expression by Design: Co-Designing the ExpressiBall with Minimally-Verbal Children on the Autism Spectrum},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376171},
doi = {10.1145/3313831.3376171},
abstract = {Expressing one's thoughts and feelings is a fundamental human need - the basis for communication and social interaction. We ask, how do minimally-verbal children on the autism spectrum express themselves? How can we better recognise instances of self-expression? And how might technologies support and encourage self-expression? To address these questions, we undertook co-design research at an autism-specific primary school with 20 children over one school year. This paper contributes six Modalities of Self-Expression, through which children self-express and convey their design insights. Each modality of self-expression can occur across two different dimensions (socio-expressive and auto-expressive) and can be of a fundamental or an integrative nature. Further, we contribute the design trajectory of a tangible ball prototype, the ExpressiBall, which - through voice, sounds, lights, and motion sensors - explores how tangible technologies can support this range of expressive modalities. Finally, we discuss the concept of Self-Expression by Design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multimodal, autism, children, self-expression, tangible, non-verbal, play, minimally-verbal, modalities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376424,
author = {Xiao, Sijia and Metaxa, Dana\"{e} and Park, Joon Sung and Karahalios, Karrie and Salehi, Niloufar},
title = {Random, Messy, Funny, Raw: Finstas as Intimate Reconfigurations of Social Media},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376424},
doi = {10.1145/3313831.3376424},
abstract = {Among many young people, the creation of a finsta-a portmanteau of "fake" and "Instagram" which describes secondary Instagram accounts-provides an outlet to share emotional, low-quality, or indecorous content with their close friends. To study why people create and maintain finstas, we conducted a qualitative study through interviews with finsta users and content analysis of video bloggers exposing their finsta on YouTube. We found that one way that young people deal with mounting social pressures is by reconfiguring online platforms and changing their purposes, norms, expectations, and currencies. Carving out smaller spaces accessible only to close friends allows users the opportunity for a more unguarded, vulnerable, and unserious performance. Drawing on feminist theory, we term this process intimate reconfiguration. Through this reconfiguration finsta users repurpose an existing and widely-used social platform to create opportunities for more meaningful and reciprocal forms of social support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {reconfiguration, finsta, performance, feminist hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376265,
author = {Gerling, Kathrin and Dickinson, Patrick and Hicks, Kieran and Mason, Liam and Simeone, Adalberto L. and Spiel, Katta},
title = {Virtual Reality Games for People Using Wheelchairs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376265},
doi = {10.1145/3313831.3376265},
abstract = {Virtual Reality (VR) holds the promise of providing engaging embodied experiences, but little is known about how people with disabilities engage with it. We explore challenges and opportunities of VR gaming for wheelchair users. First, we present findings from a survey that received 25 responses and gives insights into wheelchair users' motives to (non-) engage with VR and their experiences. Drawing from this survey, we derive design implications which we tested through implementation and qualitative evaluation of three full-body VR game prototypes with 18 participants. Our results show that VR gaming engages wheelchair users, though nuanced consideration is required for the design of embodied immersive experiences for minority bodies, and we illustrate how designers can create meaningful, positive experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {virtual reality, games, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376747,
author = {Ghosh, Arup Kumar and Hughes, Charles E. and Wisniewski, Pamela J.},
title = {Circle of Trust: A New Approach to Mobile Online Safety for Families},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376747},
doi = {10.1145/3313831.3376747},
abstract = {Traditional parental control applications designed to protect children and teens from online risks do so through parental restrictions and privacy-invasive monitoring. We propose a new approach to adolescent online safety that aims to strike a balance between a teen's privacy and their online safety through active communication and fostering trust between parents and children. We designed and developed an Android "app" called Circle of Trust and conducted a mixed methods user study of 17 parent-child pairs to understand their perceptions about the app. Using a within-subjects experimental design, we found that parents and children significantly preferred our new app design over existing parental control apps in terms of perceived usefulness, ease of use, and behavioral intent to use. By applying a lens of Value Sensitive Design to our interview data, we uncovered that parents and children who valued privacy, trust, freedom, and balance of power preferred our app over traditional apps. However, those who valued transparency and control preferred the status quo. Overall, we found that our app was better suited for teens than for younger children.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mobile smart phones, adolescent online safety, technical monitoring, parental mediation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376577,
author = {Houben, Maarten and Brankaert, Rens and Bakker, Saskia and Kenning, Gail and Bongers, Inge and Eggen, Berry},
title = {The Role of Everyday Sounds in Advanced Dementia Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376577},
doi = {10.1145/3313831.3376577},
abstract = {The representation of sounds derived from everyday life can be beneficial for people with dementia by evoking memories and emotional responses. Despite this potential, integrating sound and sound-based interventions in care facilities has not received much research attention. In this paper, we present the findings from a field study that explored the responses of 19 people with advanced dementia to a selection of everyday sounds presented to them in a care home and the role of these responses in the care environment. To study this, we deployed Vita, a 'pillow-like' sound player, in two dementia care facilities for four weeks, during which observations were recorded. Afterwards, we conducted interviews with caregivers who used Vita in everyday care practice. Our findings reveal how everyday sounds provided by Vita stimulated meaningful conversation, playfulness, and connection between residents and caregivers. Furthermore, we propose design implications for integrating everyday sounds in dementia care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {dementia, care home, everyday sounds, design, soundscapes},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376210,
author = {V\"{o}lkel, Sarah Theres and Sch\"{o}del, Ramona and Buschek, Daniel and Stachl, Clemens and Winterhalter, Verena and B\"{u}hner, Markus and Hussmann, Heinrich},
title = {Developing a Personality Model for Speech-Based Conversational Agents Using the Psycholexical Approach},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376210},
doi = {10.1145/3313831.3376210},
abstract = {We present the first systematic analysis of personality dimensions developed specifically to describe the personality of speech-based conversational agents. Following the psycholexical approach from psychology, we first report on a new multi-method approach to collect potentially descriptive adjectives from 1) a free description task in an online survey (228 unique descriptors), 2) an interaction task in the lab (176 unique descriptors), and 3) a text analysis of 30,000 online reviews of conversational agents (Alexa, Google Assistant, Cortana) (383 unique descriptors). We aggregate the results into a set of 349 adjectives, which are then rated by 744 people in an online survey. A factor analysis reveals that the commonly used Big Five model for human personality does not adequately describe agent personality. As an initial step to developing a personality model, we propose alternative dimensions and discuss implications for the design of agent personalities, personality-aware personalisation, and future research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {big 5, conversational agents, personality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376531,
author = {Wallace, Jayne and Montague, Kyle and Duncan, Trevor and Carvalho, Lu\'{\i}s P. and Koulidou, Nantia and Mahoney, Jamie and Morrissey, Kellie and Craig, Claire and Groot, Linnea Iris and Lawson, Shaun and Olivier, Patrick and Trueman, Julie and Fisher, Helen},
title = {ReFind: Design, Lived Experience and Ongoingness in Bereavement},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376531},
doi = {10.1145/3313831.3376531},
abstract = {We describe the design and use of ReFind, a handheld artefact made for people who are bereaved and are ready to re-explore their relationship to the deceased person. ReFind was made within a project seeking to develop new ways to curate and create digital media to support ongoingness - an active, dynamic component of continuing bonds. We draw on bereavement theory and care championing practices that enable a continued sense of connection between someone bereaved and a person who has died. We present the design development of ReFind and the lived experience of the piece by the first author. We discuss our wider methodology which includes autobiographical design and reflections on if and how the piece supported ongoing connections, the challenges faced, and insights gained.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {continuing bonds, grief, bereavement, photographs, death, ongoingness, digital images, design, physical/digital, autoethnography, relational selves, autobiographical, lived experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376802,
author = {Monastero, Beatrice and McGookin, David and Takala, Tapio},
title = {"I Just Leaned on It!" Exploring Opportunistic Social Discovery of a Technologically Augmented Cushion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376802},
doi = {10.1145/3313831.3376802},
abstract = {While personal devices are often used to connect online with others far away, public media rarely offers opportunities to connect with collocated individuals. We explore novel interaction strategies to enhance opportunistic collocated sociality through technologically augmented daily objects. ThinkCushion is an augmented cushion allowing users to record and playback audio messages either explicitly or implicitly by leaning on it. We deployed ThinkCushion in an open coworking space and gathered quantitative and qualitative data over one month to unveil how individuals discovered it and interacted. We individuate three modes of discovery (serendipitous, spectated and facilitated) and their relations with situated socio-spatial aspects. We discuss the interplay of active and passive interaction modalities for locally accessing and creating content, and how verbal content can be used in either performative or informative ways. We suggest future research on how to design public technologies supporting collocated sociality already from the phase of technological discovery.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sociality, opportunistic interaction, embedded systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376273,
author = {Kurze, Albrecht and Bischof, Andreas and Totzauer, S\"{o}ren and Storz, Michael and Eibl, Maximilian and Brereton, Margot and Berger, Arne},
title = {Guess the Data: Data Work to Understand How People Make Sense of and Use Simple Sensor Data from Homes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376273},
doi = {10.1145/3313831.3376273},
abstract = {Simple smart home sensors, e.g. for temperature or light, increasingly collect seemingly inconspicuous data. Prior work has shown that human sensemaking of such sensor data can reveal domestic activities. Such sensemaking presents an opportunity to empower people to understand the implications of simple smart home sensors. To investigate, we developed and field-tested the Guess the Data method, which enabled people to use and make sense of live data from their homes and to collectively interpret and reflect on anonymized data from the homes in our study. Our findings show how participants reconstruct behavior, both individually and collectively, expose the sensitive personal data of others, and use sensor data as evidence and for lateral surveillance within the household. We discuss the potential of our method as a participatory HCI method for investigating design of the IoT and implications created by doing data work on home sensors.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {personal data, privacy, sensor data, smart home, iot, internet of things, data work, networked sensing systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376303,
author = {Strandholt, Patrick L. and Dogaru, Oana A. and Nilsson, Niels C. and Nordahl, Rolf and Serafin, Stefania},
title = {Knock on Wood: Combining Redirected Touching and Physical Props for Tool-Based Interaction in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376303},
doi = {10.1145/3313831.3376303},
abstract = {When physical props serve as proxies for virtual tools used to manipulate the virtual environment, it is challenging to provide appropriate haptic feedback. Redirected tool-mediated manipulation addresses this challenge by distorting the mapping between physical and virtual tools to provide a sensation of manipulating the virtual environment, when the physical tool comes into contact with another physical prop. For example, a virtual hammer's position can be offset to ensure that physical impacts accompany each strike of a virtual nail. We demonstrate the idea by showing that it can be used to create sensations of impact and resistance when driving a virtual nail into a surface, when tightening a virtual screw, and when sawing through a virtual plank. The results of a user study indicate that the proposed approach is perceived as more realistic than interaction with a single physical prop or controller and no notable detriments to precision were observed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {redirected touching, passive haptics, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376271,
author = {Wang, Zezhong and Sundin, Lovisa and Murray-Rust, Dave and Bach, Benjamin},
title = {Cheat Sheets for Data Visualization Techniques},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376271},
doi = {10.1145/3313831.3376271},
abstract = {This paper introduces the concept of 'cheat sheets' for data visualization techniques, a set of concise graphical explanations and textual annotations inspired by infographics, data comics, and cheat sheets in other domains. Cheat sheets aim to address the increasing need for accessible material that supports a wide audience in understanding data visualization techniques, their use, their fallacies and so forth. We have carried out an iterative design process with practitioners, teachers and students of data science and visualization, resulting six types of cheat sheet (anatomy, construction, visual patterns, pitfalls, false-friends and well-known relatives) for six types of visualization, and formats for presentation. We assess these with a qualitative user study using 11 participants that demonstrates the readability and usefulness of our cheat sheets.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cheat sheet, visualization literacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376578,
author = {Voelker, Simon and Hueber, Sebastian and Holz, Christian and Remy, Christian and Marquardt, Nicolai},
title = {GazeConduits: Calibration-Free Cross-Device Collaboration through Gaze and Touch},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376578},
doi = {10.1145/3313831.3376578},
abstract = {We present GazeConduits, a calibration-free ad-hoc mobile interaction concept that enables users to collaboratively interact with tablets, other users, and content in a cross-device setting using gaze and touch input. GazeConduits leverages recently introduced smartphone capabilities to detect facial features and estimate users' gaze directions. To join a collaborative setting, users place one or more tablets onto a shared table and position their phone in the center, which then tracks users present as well as their gaze direction to determine the tablets they look at. We present a series of techniques using GazeConduits for collaborative interaction across mobile devices for content selection and manipulation. Our evaluation with 20 simultaneous tablets on a table shows that GazeConduits can reliably identify which tablet or collaborator a user is looking at.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {touch input, cross-device interaction, gaze input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376345,
author = {Devendorf, Laura and Andersen, Kristina and Kelliher, Aisling},
title = {Making Design Memoirs: Understanding and Honoring Difficult Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376345},
doi = {10.1145/3313831.3376345},
abstract = {Design is commonly understood as a storytelling practice, yet we have few narratives with which to describe the felt experiences of struggle, pain, and difficulty, beyond treating them as subjects to resolve. This work uses the praxis of embodied design as a way to bring more complex narratives to the community for contemplation---to engage and entangle personal and difficult stories within a public context. We propose the term Design Memoirs for these first-person practices and reflections. Design Memoirs are subjective and corporeal in nature, and provide a direct and observable way to reckon with felt experiences through, and for, design. We demonstrate Design Memoirs by drawing on our own experiences as mothers, caregivers, and corporeal subjects. Following Barad, we propose a practice of diffractive reading to locate resonances between Design Memoirs which render difficult autobiographical material addressable, shareable, and open for new interpretations. We present this strategy as a method for arriving at deeper understandings of difficult experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {design memoirs, methodology, design research, motherhood, autobiographical design, design fiction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376195,
author = {G\"{u}nther, Sebastian and M\"{u}ller, Florian and Sch\"{o}n, Dominik and Elmoghazy, Omar and M\"{u}hlh\"{a}user, Max and Schmitz, Martin},
title = {Therminator: Understanding the Interdependency of Visual and On-Body Thermal Feedback in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376195},
doi = {10.1145/3313831.3376195},
abstract = {Recent advances have made Virtual Reality (VR) more realistic than ever before. This improved realism is attributed to today's ability to increasingly appeal to human sensations, such as visual, auditory or tactile. While research also examines temperature sensation as an important aspect, the interdependency of visual and thermal perception in VR is still underexplored. In this paper, we propose Therminator, a thermal display concept that provides warm and cold on-body feedback in VR through heat conduction of flowing liquids with different temperatures. Further, we systematically evaluate the interdependency of different visual and thermal stimuli on the temperature perception of arm and abdomen with 25 participants. As part of the results, we found varying temperature perception depending on the stimuli, as well as increasing involvement of users during conditions with matching stimuli.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {haptics, temperature, thermal feedback, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376146,
author = {Villanueva, Ana and Zhu, Zhengzhe and Liu, Ziyi and Peppler, Kylie and Redick, Thomas and Ramani, Karthik},
title = {Meta-AR-App: An Authoring Platform for Collaborative Augmented Reality in STEM Classrooms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376146},
doi = {10.1145/3313831.3376146},
abstract = {Augmented Reality (AR) has become a valuable tool for education and training processes. Meanwhile, cloud-based technologies can foster collaboration and other interaction modalities to enhance learning. We combine the cloud capabilities with AR technologies to present Meta-AR-App, an authoring platform for collaborative AR, which enables authoring between instructors and students. Additionally, we introduce a new application of an established collaboration process, the pull-based development model, to enable sharing and retrieving of AR learning content. We customize this model and create two modalities of interaction for the classroom: local (student to student) and global (instructor to class) pull. Based on observations from our user studies, we organize a four-category classroom model which implements our system: Work, Design, Collaboration, and Technology. Further, our system enables an iterative improvement workflow of the class content and enables synergistic collaboration that empowers students to be active agents in the learning process.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {git, collaboration, version control, pull-based model, augmented reality, electrical circuitry, classroom, authoring, stem},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376874,
author = {Leung, Weiwen and Zhang, Zheng and Jibuti, Daviti and Zhao, Jinhao and Klein, Maximilian and Pierce, Casey and Robert, Lionel and Zhu, Haiyi},
title = {Race, Gender and Beauty: The Effect of Information Provision on Online Hiring Biases},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376874},
doi = {10.1145/3313831.3376874},
abstract = {We conduct a study of hiring bias on a simulation platform where we ask Amazon MTurk participants to make hiring decisions for a mathematically intensive task. Our findings suggest hiring biases against Black workers and less attractive workers, and preferences towards Asian workers, female workers and more attractive workers. We also show that certain UI designs, including provision of candidates' information at the individual level and reducing the number of choices, can significantly reduce discrimination. However, provision of candidate's information at the subgroup level can increase discrimination. The results have practical implications for designing better online freelance marketplaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {gig economy, discrimination, hiring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376745,
author = {Fiesler, Casey},
title = {Lawful Users: Copyright Circumvention and Legal Constraints on Technology Use},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376745},
doi = {10.1145/3313831.3376745},
abstract = {The study of human-computer interaction requires consideration of aspects of interactions with technology that may be outside of the control of both user and designer. One example of when a user's question of "can I do this?" may have an answer beyond technological affordances is that of legal constraints. This paper considers an example of this phenomenon: section 1201 of the Digital Millennium Copyright Act (DMCA) in the United States, which criminalizes circumventing copyright protection such as digital rights management (DRM). The DMCA also includes a triennial policymaking process that considers exemptions to the law to protect "lawful users" from adverse effects. Through an analysis of public comments of support for exemptions, this paper explores the ways in which users see the law as a hindrance to desired uses of technology. This analysis sheds light on users' expectations for rights of use, how these expectations clash with policy, and what this might mean for technology designers. Drawing lessons from the infrastructure problem in HCI, this paper concludes with laying out solutions that can both work within policy constraints, and more importantly, work to change them.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {infrastructure, accessibility, dmca, drm, copyright, policy, ownership, law},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376450,
author = {Park, Sunjeong and Lim, Youn-kyung},
title = {Investigating User Expectations on the Roles of Family-Shared AI Speakers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376450},
doi = {10.1145/3313831.3376450},
abstract = {AI assistants that use a voice user interface (VUI), such as AI speakers, have become popular in family homes. However, it is still unclear what roles the AI speaker can support within the family unit. We investigated the roles of an AI speaker as a family-shared technology. By conducting a one-week participatory user study, we discovered that family members' co-ownership toward the AI speaker was the key in the development of its family-oriented roles. Our findings showed seven domains of user expectations on these roles, and we realized that all the expectations can be represented as family cohesion. In addition, privacy awareness was emphasized regarding personal supports. Finally, we discuss a new perspective for AI speaker design and offer two suggestions: 1) leveraging human-likeness to develop its potential roles of supporting the unit of a family and 2) interpreting the home context to seamlessly connect family and personal supporting roles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {family, participatory design study, AI speaker},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376685,
author = {Slegers, Karin and Kouwenberg, Kristel and Lou\v{c}ova, Tereza and Daniels, Ramon},
title = {Makers in Healthcare: The Role of Occupational Therapists in the Design of DIY Assistive Technology},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376685},
doi = {10.1145/3313831.3376685},
abstract = {Advancements in personal fabrication technologies (e.g. 3D printing) resulted in a rising interest in 'do-it-yourself assistive technology' (DIY AT). Clinical knowledge is considered fundamental for DIY AT design, but research into making DIY AT by clinicians is limited. In this paper, we explore occupational therapists' attitudes towards 3D printing both before and after gaining hands-on experience with 3D modelling software. In addition, as clinicians indicate to prefer collaborations with experienced designers, we organized a codesign study with occupational therapists and professional designers to conceptualize a feasible collaborative DIY-AT design process. The results of our studies show an overall enthusiasm of occupational therapists towards 3D printing, but the perceived impact of 3D printing on their job performance decreased after gaining hands-on experience. Collaborating with designers seems a viable way forward. We propose a model for a collaborative design process, highlighting different phases and the roles that occupational therapists and designers play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {occupational therapy, DIY assistive technology, digital fabrication, 3D printing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376889,
author = {Sanches, Pedro and Tsaknaki, Vasiliki and Rostami, Asreen and Brown, Barry},
title = {Under Surveillance: Technology Practices of Those Monitored by the State},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376889},
doi = {10.1145/3313831.3376889},
abstract = {This paper documents the experiences of those living under state surveillance. We interviewed our participants about how they lived under threat, and how it changed their technology practices. Our participants spanned three groups - journalists who reported from countries where their activities were illegal; activists who took part in civil disobedience, and individuals who worked in illegal activities that would have likely led to prosecution. In our analysis we cover four themes: first, 'the imagined surveillant'. Second, the danger and dependencies of technology use, third, their coping strategies, and lastly how belonging to a group can protect but also expose. In our discussion we cover how we can design for dissidents, and how to deal with the difficult questions this raises. We conclude by advocating for research that takes into account a critical view of the state in HCI and more broadly for an anti-surveillance stance in the design of technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {state, surveillance, dissidents},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376308,
author = {Morreale, Fabio and Eriksson, Maria},
title = {"My Library Has Just Been Obliterated": Producing New Norms of Use Via Software Update},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376308},
doi = {10.1145/3313831.3376308},
abstract = {Software updates are commonly perceived as tools for fixing flaws and improving functionality. In this paper, we problematise this view by showing how software updates may also be used by vendors to create new norms of use that control user behaviour and reduce their agency. We explore the nature and aftermath of a controversial software update that was released by Spotify in June 2019. By analysing almost 3,500 reactions to this update, we show how it removed and modified several features in ways that severely affected users' capability to organise, navigate, and maintain their music libraries, while it pushed modes of listening that delegate song selection to Spotify. Elaborating upon our results, we discuss how updates may be used as political tools that privilege certain forms of behaviour while restricting others. We also portray updates as sites where ongoing struggles and negotiations regarding user agency and digital ownership take place.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {protocological power, spotify, normative affordances, psychological ownership, critical computing, music streaming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376426,
author = {Hong, Matthew K. and Lakshmi, Udaya and Do, Kimberly and Prahalad, Sampath and Olson, Thomas and Arriaga, Rosa I. and Wilcox, Lauren},
title = {Using Diaries to Probe the Illness Experiences of Adolescent Patients and Parental Caregivers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376426},
doi = {10.1145/3313831.3376426},
abstract = {Adolescents with chronic conditions must work with family caregivers to manage their illness experiences. To explore how technology can support collaborative documentation of these experiences, we designed and distributed a paper diary probe kit in a two-week field deployment with 12 adolescent-parent dyads (24 participants). Three insights emerged from the study that highlight how technology can support shared illness management: 1) provide scaffolds to recognize physical and emotional experiences in the context of daily activities; 2) help families reconstruct patient experiences; and 3) adapt to individual preferences for capturing, representing and sharing experiences. We discuss opportunities for HCI research that follow from these findings and conclude by reflecting on the benefits and limitations of using diary probes with adolescent patients and their parental caregivers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {adolescents, family-centered design, co-design, diary studies, chronic illness, health, probes, family informatics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376341,
author = {Chikersal, Prerna and Belgrave, Danielle and Doherty, Gavin and Enrique, Angel and Palacios, Jorge E. and Richards, Derek and Thieme, Anja},
title = {Understanding Client Support Strategies to Improve Clinical Outcomes in an Online Mental Health Intervention},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376341},
doi = {10.1145/3313831.3376341},
abstract = {Online mental health interventions are increasingly important in providing access to, and supporting the effectiveness of, mental health treatment. While these technologies are effective, user attrition and early disengagement are key challenges. Evidence suggests that integrating a human supporter into such services mitigates these challenges, however, it remains under-studied how supporter involvement benefits client outcomes, and how to maximize such effects. We present our analysis of 234,735 supporter messages to discover how different support strategies correlate with clinical outcomes. We describe our machine learning methods for: (i) clustering supporters based on client outcomes; (ii) extracting and analyzing linguistic features from supporter messages; and (iii) identifying context-specific patterns of support. Our findings indicate that concrete, positive and supportive feedback from supporters that reference social behaviors are strongly associated with better outcomes; and show how their importance varies dependent on different client situations. We discuss design implications for personalized support and supporter interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {digital behavioral intervention, support, unsupervised learning, cbt, data mining, mental health, ai, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376498,
author = {Li, Yifang and Vishwamitra, Nishant and Hu, Hongxin and Caine, Kelly},
title = {Towards A Taxonomy of Content Sensitivity and Sharing Preferences for Photos},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376498},
doi = {10.1145/3313831.3376498},
abstract = {Determining which photos are sensitive is difficult. Although emerging computer vision systems can label content items, previous attempts to distinguish private or sensitive content fall short. There is no human-centered taxonomy that describes what content is sensitive or how sharing preferences for content differs across recipients. To fill this gap, we introduce a new sensitive content elicitation method which surmounts limitations of previous approaches, and, using this new method, collected sensitive content from 116 participants. We also recorded participants' sharing preferences with 20 recipient groups. Next, we conducted a card sort to surface user-defined categories of sensitive content. Using data from these studies, we generated a taxonomy that identifies 28 categories of sensitive content. We also establish how sharing preferences for content differs across groups of recipients. This taxonomy can serve as a framework for understanding photo privacy, which can, in turn, inform new photo privacy protection mechanisms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {security, sensitive content, privacy, photo privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376562,
author = {Ogawa, Nami and Narumi, Takuji and Kuzuoka, Hideaki and Hirose, Michitaka},
title = {Do You Feel Like Passing Through Walls?: Effect of Self-Avatar Appearance on Facilitating Realistic Behavior in Virtual Environments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376562},
doi = {10.1145/3313831.3376562},
abstract = {Preventing users from walking through virtual boundaries (e.g., walls) is an important issue to be addressed in room-scale virtual environments (VEs), considering the safety and design limitations. Sensory feedback from wall collisions has been shown to be effective; however, it can disrupt the immersion. We assumed that a greater sense of presence would discourage users from walking through walls and conducted a two-factor between-subjects experiment (N = 92) that controls the anthropomorphism (realistic or abstract) and visibility (full-body or hand-only) of self-avatars. We analyzed the participants' behaviors and the moment they first penetrated the wall in game-like VEs that gradually instigated participants to penetrate the walls. The results showed that the realistic full-body self-avatar was the most effective for discouraging the participants from penetrating the walls. Furthermore, the participants with lower presence tended to walk through the walls sooner. This study can contribute to applications that require realistic user responses in VEs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {self-avatar, body ownership, presence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376598,
author = {Troiano, Giovanni Maria and Wood, Matthew and Harteveld, Casper},
title = {"And This, Kids, Is How I Met Your Mother": Consumerist, Mundane, and Uncanny Futures with Sex Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376598},
doi = {10.1145/3313831.3376598},
abstract = {Sex Robots are no longer science fiction and may soon be-come widespread. While much discussion has developed in academia on their moral and social impact, sex robots have yet to be examined from a critical design perspective and are under-explored in HCI. We use the Story Completion Method(SCM) to explore commonplace assumptions around futures with sex robots and discuss those from a critical design perspective. Thirty five participants completed a story stem of a human encountering a sex robot or vice-versa. Through thematic analysis, we show narratives of consumerist relation-ships between humans and sex robots, stories that describe sex robots as highly-efficient sex workers that (out)perform humans in routinal sex activities, and narratives that explore sex robots as empathetic and sentient beings. Our participant-created stories both reinforce and challenge established norms of sex robots and raise questions that concern responsible design and ethics in HCI. Finally, we show opportunities and limitations of using multiple-perspective story stems in SCM},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {human-robot interaction, sexual HCI, story completion method, ethics, research fiction, sex robots, speculative design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376530,
author = {Roldan, Wendy and Gao, Xin and Hishikawa, Allison Marie and Ku, Tiffany and Li, Ziyue and Zhang, Echo and Froehlich, Jon E. and Yip, Jason},
title = {Opportunities and Challenges in Involving Users in Project-Based HCI Education},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376530},
doi = {10.1145/3313831.3376530},
abstract = {Users are fundamental to HCI. However, little is known about how HCI education introduces students to working with users, particularly those different from themselves. To better understand design students' engagement, reactions, and reflections with users, we investigate a case study of a graduate-level 10-week prototyping studio course that partnered with a children's co-design team. HCI students participated in two co-design sessions with children to design a STEM learning experience for youth. We conducted participant observations, interviews with 14 students, and analyzed final artifacts. Our findings demonstrate the communication challenges and strategies students experienced, how students observed issues of power dynamics, and students' perceived value in engaging with users. We contribute empirical evidence of how HCI students directly interact with target users, principles for reflective HCI pedagogy, and highlight the need for more intentional investigation into HCI educational practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {hci education, user-centered design, reflection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376233,
author = {Zhu, Fengyuan and Grossman, Tovi},
title = {BISHARE: Exploring Bidirectional Interactions Between Smartphones and Head-Mounted Augmented Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376233},
doi = {10.1145/3313831.3376233},
abstract = {In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {cross-device computing, augmented reality, smartphones, mixed-reality computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376518,
author = {Bassen, Jonathan and Balaji, Bharathan and Schaarschmidt, Michael and Thille, Candace and Painter, Jay and Zimmaro, Dawn and Games, Alex and Fast, Ethan and Mitchell, John C.},
title = {Reinforcement Learning for the Adaptive Scheduling of Educational Activities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376518},
doi = {10.1145/3313831.3376518},
abstract = {Adaptive instruction for online education can increase learning gains and decrease the work required of learners, instructors, and course designers. Reinforcement Learning (RL) is a promising tool for developing instructional policies, as RL models can learn complex relationships between course activities, learner actions, and educational outcomes. This paper demonstrates the first RL model to schedule educational activities in real time for a large online course through active learning. Our model learns to assign a sequence of course activities while maximizing learning gains and minimizing the number of items assigned. Using a controlled experiment with over 1,000 learners, we investigate how this scheduling policy affects learning gains, dropout rates, and qualitative learner feedback. We show that our model produces better learning gains using fewer educational activities than a linear assignment condition, and produces similar learning gains to a self-directed condition using fewer educational activities and with lower dropout rates.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online education, adaptive learning, reinforcement learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376866,
author = {Sun, Dong and Feng, Zezheng and Chen, Yuanzhe and Wang, Yong and Zeng, Jia and Yuan, Mingxuan and Pong, Ting-Chuen and Qu, Huamin},
title = {DFSeer: A Visual Analytics Approach to Facilitate Model Selection for Demand Forecasting},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376866},
doi = {10.1145/3313831.3376866},
abstract = {Selecting an appropriate model to forecast product demand is critical to the manufacturing industry. However, due to the data complexity, market uncertainty and users' demanding requirements for the model, it is challenging for demand analysts to select a proper model. Although existing model selection methods can reduce the manual burden to some extent, they often fail to present model performance details on individual products and reveal the potential risk of the selected model. This paper presents DFSeer, an interactive visualization system to conduct reliable model selection for demand forecasting based on the products with similar historical demand. It supports model comparison and selection with different levels of details. Besides, it shows the difference in model performance on similar products to reveal the risk of model selection and increase users' confidence in choosing a forecasting model. Two case studies and interviews with domain experts demonstrate the effectiveness and usability of DFSeer.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive visualization, model selection, product demand forecasting, time series},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376673,
author = {Fu, Xinyi and Zhu, Yaxin and Xiao, Zhijing and Xu, Yingqing and Ma, Xiaojuan},
title = {RestoreVR: Generating Embodied Knowledge and Situated Experience of Dunhuang Mural Conservation via Interactive Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376673},
doi = {10.1145/3313831.3376673},
abstract = {In Dunhuang Mogao Grottoes, unique Buddhist murals of ancient China are preserved. Unfortunately, the exquisite murals are suffering from degradation. Experts have been trying to enhance public's awareness of mural protection, but there's no efficacious means to attract interest and popularize knowledge yet. In this paper, we propose RestoreVR, an interactive virtual reality (VR) system engaging users to experience Dunhuang mural restoration in a digital tour in the cave. Based on an online survey with the public and in-depth interviews with five Dunhuang experts, we derive a set of design requirements for generating embodied knowledge and situated experience in VR to bridge the gap between highly specialized experts and general audiences. Accordingly, we design RestoreVR and conduct a between-subjects user study to compare our system with traditional methods. The results suggest that RestoreVR significantly improves user experience and awareness of CH protection over existing methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {dunhuang, mural conservation, cultural heritage, interactive virtual reality, implementation, survey},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376337,
author = {Logler, Nick and Pitt, Caroline and Gao, Xin and Hishikawa, Allison Marie and Yip, Jason and Friedman, Batya},
title = {"I Feel Like This is a Bad Thing": Investigating Disassembly in Action for Novices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376337},
doi = {10.1145/3313831.3376337},
abstract = {Materials are dynamic-they can be shaped and changed. Often however, our tools and technologies appear to fix materials in place. Disassembly is one practice that provides openings to explore and understand the dynamic nature of material. In this research, we investigate possibilities that emerge from disassembly. Specifically, we studied how novices disassembled a common digital artifact-desktop printers. We worked with 21 young people and family members across two evening workshops at a middle school. We report on the workshop interactions, categories of actions of disassembly, and four in-depth vignettes showcasing disassembly in action. In the discussion, we reflect on disassembly and permission, sustainability, the joy of disassembling, and design considerations in support of disassembly. Our contributions include: (1) extending existing theoretical framings about artifacts and materials; (2) an empirical study documenting the process by which novices disassemble; and (3) preliminary design and policy considerations that enable disassembly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {materials, unmaking, disassembly, design theory, making, empowerment, play, novices, design principles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376268,
author = {Turmo Vidal, Laia and Zhu, Hui and Riego-Delgado, Abraham},
title = {BodyLights: Open-Ended Augmented Feedback to Support Training Towards a Correct Exercise Execution},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376268},
doi = {10.1145/3313831.3376268},
abstract = {Technologies targeting a correct execution of physical training exercises typically use pre-determined models for what they consider correct, automatizing instruction and feedback. This falls short on catering to diverse trainees and exercises. We explore an alternative design approach, in which technology provides open-ended feedback for trainers and trainees to use during training. With a personal trainer we designed the augmentation of 18 strength training exercises with BodyLights: 3D printed wearable projecting lights that augment body movement and orientation. To study them, 15 trainees at different skill levels trained three times with our personal trainer and BodyLights. Our findings show that BodyLights catered to a wide range of trainees and exercises, and supported understanding, executing and correcting diverse technique parameters. We discuss design features and methodological aspects that allowed this; and what open-ended feedback offered in comparison to current technology approaches to support training towards a correct exercise execution.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {activity design, physical training, correct performance, rtd, augmented feedback, wearables, strength training},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376486,
author = {Heshmat, Yasamin and Neustaedter, Carman and McCaffrey, Kyle and Odom, William and Wakkary, Ron and Yang, Zikun},
title = {FamilyStories: Asynchronous Audio Storytelling for Family Members Across Time Zones},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376486},
doi = {10.1145/3313831.3376486},
abstract = {Family members who are separated across time zones can easily miss out on feeling connected. We designed and studied the usage of an asynchronous storytelling system, called FamilyStories, to explore the use of audio-based sharing. FamilyStories allows family members to share activities and experiences over distance in different time zones using three different devices that contain different contextual features. To evaluate the design, we conducted a five-week long field study with two family member pairs. Our results show the value of slow, flexible, and non-suggestive interfaces for asynchronous audio communication. We also found ephemerality helped in the sharing of 'instant' feelings, while large time zone differences could be 'synchronized' with time delayed messages. We raise these as design opportunities for asynchronous audio storytelling systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {domestic, family communication, slow technology, asynchronous communication, audio},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376283,
author = {Morales-Martinez, Gabriela and Latreille, Paul and Denny, Paul},
title = {Nationality and Gender Biases in Multicultural Online Learning Environments: The Effects of Anonymity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376283},
doi = {10.1145/3313831.3376283},
abstract = {Online learning environments eliminate geographical barriers and enable new forms of collaboration between students at large scale. Self-presentation within such environments affects how students interact with learning content and with each other. We explore how anonymity/identifiability in user profile design impacts student interactions in a large multicultural classroom across two geographical locations. After triangulating 150,000 online interactions with questionnaires and focus groups, we provide three major findings. First, being identifiable had a significant impact on how students accessed and rated content created by their peers. Second, when identifiable, cultural differences became more prominent, leading some students to avoid content created by classmates of certain nationalities. Finally, when students interacted with their real identities, there were significant and negative gender effects which were absent when students were anonymous. These findings contribute to our understanding of social dynamics within multicultural learning environments, and raise practical implications for tool design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {nationality bias, anonymity, online learning environments, peer ratings, computer-mediated communication, gender bias, vles, oles, online education, identity, peerwise},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376225,
author = {Storer, Kevin M. and Judge, Tejinder K. and Branham, Stacy M.},
title = {"All in the Same Boat": Tradeoffs of Voice Assistant Ownership for Mixed-Visual-Ability Families},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376225},
doi = {10.1145/3313831.3376225},
abstract = {A growing body of evidence suggests Voice Assistants (VAs) are highly valued by people with vision impairments (PWVI) and much less so by sighted users. Yet, many are deployed in homes where both PWVI and sighted family members reside. Researchers have yet to study whether VA use and perceived benefits are affected in settings where one person has a visual impairment and others do not. We conducted six in-depth interviews with partners to understand patterns of domestic VA use in mixed-visual-ability families. Although PWVI were more motivated to acquire VAs, used them more frequently, and learned more proactively about their features, partners with vision identified similar benefits and disadvantages of having VAs in their home. We found that the universal usability of VAs both equalizes experience across abilities and presents complex tradeoffs for families-regarding interpersonal relationships, domestic labor, and physical safety-which are weighed against accessibility benefits for PWVI and complicate the decision to fully integrate VAs in the home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {home, voice assistant, universal usability, vision impairment, mixed-visual-ability settings},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376151,
author = {Seering, Joseph and Hammer, Jessica and Kaufman, Geoff and Yang, Diyi},
title = {Proximate Social Factors in First-Time Contribution to Online Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376151},
doi = {10.1145/3313831.3376151},
abstract = {In the course of every member's integration into an online community, a decision must be made to participate for the first time. The challenges of effective recruitment, management, and retention of new users have been extensively explored in social computing research. However, little work has looked at in-the-moment factors that lead users to decide to participate instead of "lurk", conditions which can be shaped to draw new users in at crucial moments. In this work we analyze 183 million messages scraped from chatrooms on the livestreaming platform Twitch in order to understand differences between first-time participants' and regulars' behaviors and to identify conditions that encourage first-time participation. We find that presence of diverse types of users increases likelihood of new participation, with effects depending on the size of the community. We also find that information-seeking behaviors in first-time participation are negatively associated with retention in the short and medium term.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {online communities, retention, participation, newcomers, twitch, social roles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376634,
author = {Kow, Yong Ming and Nardi, Bonnie and Cheng, Wai Kuen},
title = {Be Water: Technologies in the Leaderless Anti-ELAB Movement in Hong Kong},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376634},
doi = {10.1145/3313831.3376634},
abstract = {We examine a leaderless social movement characterized by participants' autonomy and the absence of leaders and organizations. We conducted a participant observation study of the Anti-ELAB movement in Hong Kong. Focusing on the organization of a protest march, we collected thousands of lines of discourse in the LIHKG Forum and the Telegram instant messaging system. Our grounded theory analysis revealed hundreds of groups acting within a symbiotic network. Participants promoted an ethos of empowering individual participants and groups to act autonomously. At the same time, participants' extensive use of hyperlinks and polls orchestrated a coherent social movement. We discuss how this novel formation can mediate successful leaderless movements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {leaderless social movement, anti-elab, hong kong, ethnography},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376391,
author = {Kotut, Lindah and Horning, Michael and Stelter, Timothy L. and McCrickard, D. Scott},
title = {Preparing for the Unexpected: Community Framework for Social Media Use and Social Support by Trail Thru-Hikers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376391},
doi = {10.1145/3313831.3376391},
abstract = {A months-long hike of the Appalachian Trail often involve long-term preparation and life-altering decisions. Would-be hikers leverage institutional knowledge from literature and online forums to physically and mentally prepare for such an arduous hike. Their use of social platforms provide useful insights on motivations for undertaking the thru-hike, how they deal with unexpected conditions on the trail and understand choices made in conditions of scarcity. By analyzing over 100,000 Reddit posts and comments in r/AppalachianTrail and applying a Sense of Community theory, we sought to understand hikers' identity as community members, how their emotional and practical needs are met, and how they evolve. We found that the role and language of thru-hikers change as they progress from pre-hike, on-hike, and post-hike stages, from a questioner early on, to an expert post-hike. We conclude with design recommendations to support offline communities online.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {rural computing, trail community, appalachian trail, information seeking, long-distance hiking, thru-hike},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376221,
author = {Peng, Xiaolan and Huang, Jin and Denisova, Alena and Chen, Hui and Tian, Feng and Wang, Hongan},
title = {A Palette of Deepened Emotions: Exploring Emotional Challenge in Virtual Reality Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376221},
doi = {10.1145/3313831.3376221},
abstract = {Recent work introduced the notion of 'emotional challenge' promising for understanding more unique and diverse player experiences (PX). Although emotional challenge has immediately attracted HCI researchers' attention, the concept has not been experimentally explored, especially in virtual reality (VR), one of the latest gaming environments. We conducted two experiments to investigate how emotional challenge affects PX when separately from or jointly with conventional challenge in VR and PC conditions. We found that relatively exclusive emotional challenge induced a wider range of different emotions in both conditions, while the adding of emotional challenge broadened emotional responses only in VR. In both experiments, VR significantly enhanced the measured PX of emotional responses, appreciation, immersion and presence. Our findings indicate that VR may be an ideal medium to present emotional challenge and also extend the understanding of emotional (and conventional) challenge in video games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {player experience, games, emotional challenge, virtual reality, emotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376633,
author = {Tseng, Emily and Okeke, Fabian and Sterling, Madeline and Dell, Nicola},
title = {"We Can Learn. Why Not?": Designing Technologies to Engender Equity for Home Health Aides},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376633},
doi = {10.1145/3313831.3376633},
abstract = {HCI researchers have increasingly studied how technology might improve the lives of marginalized workers. We explored this question through a qualitative study with home health aides in New York City, a vulnerable group of frontline caregivers whose work with patients is poorly paid and highly stressful, often involving life-or-death situations. To elicit the perspectives of aides and their supervisors on how technology interventions might contribute to moving aides towards a better future, we created a design provocation that centers aides' needs and suggests more equitable roles for them within the home care ecosystem. Findings from design sessions with 16 aides, nurses, and aide coordinators illuminate the ethical and pragmatic dilemmas inherent in this complex ecosystem, and show that designing technology for equity requires attention to structural problems in addition to workers' stated needs. We analyze our findings through the lens of social justice-oriented interaction design, and discuss how our work extends key strategies within this framework.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design provocation, design for social justice, home health aides, home care},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376868,
author = {Voelker, Simon and Hueber, Sebastian and Corsten, Christian and Remy, Christian},
title = {HeadReach: Using Head Tracking to Increase Reachability on Mobile Touch Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376868},
doi = {10.1145/3313831.3376868},
abstract = {People often operate their smartphones with only one hand, using just their thumb for touch input. With today's larger smartphones, this leads to a reachability issue: Users can no longer comfortably touch everywhere on the screen without changing their grip. We investigate using the head tracking in modern smartphones to address this reachability issue. We developed three interaction techniques, pure head (PH), head + touch (HT), and head area + touch (HA), to select targets beyond the reach of one's thumb. In two user studies, we found that selecting targets using HT and HA had higher success rates than the default direct touch (DT) while standing (by about 9%) and walking (by about 12%), while being moderately slower. HT and HA were also faster than one of the best techniques, BezelCursor (BC) (by about 20% while standing and 6% while walking), while having the same success rate.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {gaze selection, touch input, force input, walking, reachability, user study, head tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376746,
author = {Bae, Suyun Sandra and Kwon, Oh-Hyun and Chandrasegaran, Senthil and Ma, Kwan-Liu},
title = {Spinneret: Aiding Creative Ideation through Non-Obvious Concept Associations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376746},
doi = {10.1145/3313831.3376746},
abstract = {Mind mapping is a popular way to explore a design space in creative thinking exercises, allowing users to form associations between concepts. Yet, most existing digital tools for mind mapping focus on authoring and organization, with little support for addressing the challenges of mind mapping such as stagnation and design fixation. We present Spinneret, a functional approach to aid mind mapping by providing suggestions based on a knowledge graph. Spinneret uses biased random walks to explore the knowledge graph in the neighborhood of an existing concept node in the mind map, and provides "suggestions" for the user to add to the mind map. A comparative study with a baseline mind-mapping tool reveals that participants created more diverse and distinct concepts with Spinneret, and reported that the suggestions inspired them to think of ideas they would otherwise not have explored.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {knowledge graph, mind mapping, creativity, suggestion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376526,
author = {Kozubaev, Sandjar and Elsden, Chris and Howell, Noura and S\o{}ndergaard, Marie Louise Juul and Merrill, Nick and Schulte, Britta and Wong, Richmond Y.},
title = {Expanding Modes of Reflection in Design Futuring},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376526},
doi = {10.1145/3313831.3376526},
abstract = {Design futuring approaches, such as speculative design, design fiction and others, seek to (re)envision futures and explore alternatives. As design futuring becomes established in HCI design research, there is an opportunity to expand and develop these approaches. To that end, by reflecting on our own research and examining related work, we contribute five modes of reflection. These modes concern formgiving, temporality, researcher positionality, real-world engagement, and knowledge production. We illustrate the value of each mode through careful analysis of selected design exemplars and provide questions to interrogate the practice of design futuring. Each reflective mode offers productive resources for design practitioners and researchers to articulate their work, generate new directions for their work, and analyze their own and others' work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {research through design, speculative design, design futuring, design methods, futures, futures-oriented design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376721,
author = {Zhong, Ce and Wakkary, Ron and Zhang, Xiao and Chen, Amy Yo Sue},
title = {TransTexture Lamp: Understanding Lived Experiences with Deformation Through a Materiality Lens},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376721},
doi = {10.1145/3313831.3376721},
abstract = {This paper provides a materiality perspective to understanding lived experiences with a deformable domestic artefact, named transTexture lamp. The lamp is an interactive light with a deformable lampshade surface. We deployed transTexture lamps in the homes of three professional designers for two months with the aim of exploring possible interactions and engagements with the deformable lamp. Our findings show how participants experienced transTexture through pleasurable interactions and how they experienced deformation over time from reflections on these interactions. Analyzing the data through a materiality lens unpacked a creative process of drawing on the deformable lampshade surface, which results in the accumulation of substrates and transformations of deformations. These findings suggest opportunities for future material-centered interaction design research and practices in HCI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {deformation, research-through-design, computational design, materiality, material-centered interaction design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376845,
author = {Lee, Bridjet and Muldner, Kasia},
title = {Instructional Video Design: Investigating the Impact of Monologue- and Dialogue-Style Presentations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376845},
doi = {10.1145/3313831.3376845},
abstract = {Instructional videos are frequently used in online courses and websites. Such videos may include an instructor delivering a monologue-style presentation, or alternatively, engaging in a dialogue with a student who appears in the video alongside of the instructor. We compared three instructional video designs (N = 77), including monologue and dialogue style presentations. To obtain a comprehensive view of the impact of video design, we used a variety of measures, including eye tracking data, learning gains, self-efficacy, cognitive load, social presence, and interest. Despite eye tracking data showing that participants in speaker-visible conditions spent significantly less time on the domain content, learning and related variables were similar in all three conditions, a result we confirmed with Bayesian statistics that provided substantial evidence for the null model. Altogether, we provide evidence that learning and interest are not enhanced by a dialogue-style presentation or visual presence of the instructor. However, further work is needed to investigate the effect of other domains, speaker persona and saliency, and configuration of the speakers in the instructional video.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual presence, instructional video design, monologue presentation, eye tracking, interest, dialogue presentation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376728,
author = {Gleason, Cole and Pavel, Amy and McCamey, Emma and Low, Christina and Carrington, Patrick and Kitani, Kris M. and Bigham, Jeffrey P.},
title = {Twitter A11y: A Browser Extension to Make Twitter Images Accessible},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376728},
doi = {10.1145/3313831.3376728},
abstract = {Social media platforms are integral to public and private discourse, but are becoming less accessible to people with vision impairments due to an increase in user-posted images. Some platforms (i.e. Twitter) let users add image descriptions (alternative text), but only 0.1% of images include these. To address this accessibility barrier, we created Twitter A11y, a browser extension to add alternative text on Twitter using six methods. For example, screenshots of text are common, so we detect textual images, and create alternative text using optical character recognition. Twitter A11y also leverages services to automatically generate alternative text or reuse them from across the web. We compare the coverage and quality of Twitter A11y's six alt-text strategies by evaluating the timelines of 50 self-identified blind Twitter users. We find that Twitter A11y increases alt-text coverage from 7.6% to 78.5%, before crowdsourcing descriptions for the remaining images. We estimate that 57.5% of returned descriptions are high-quality. We then report on the experiences of 10 participants with visual impairments using the tool during a week-long deployment. Twitter A11y increases access to social media platforms for people with visual impairments by providing high-quality automatic descriptions for user-posted images.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {twitter, screen reader, social media, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376313,
author = {Zhou, Qian and Sykes, Sarah and Fels, Sidney and Kin, Kenrick},
title = {Gripmarks: Using Hand Grips to Transform In-Hand Objects into Mixed Reality Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376313},
doi = {10.1145/3313831.3376313},
abstract = {We introduce Gripmarks, a system that enables users to opportunistically use objects they are already holding as input surfaces for mixed reality head-mounted displays (HMD). Leveraging handheld objects reduces the need for users to free up their hands or acquire a controller to interact with their HMD. Gripmarks associate a particular hand grip with the shape primitive of the physical object without the need of object recognition or instrumenting the object. From the grip pose and shape primitive we can infer the surface of the object. With an activation gesture, we can enable the object for use as input to the HMD. With five gripmarks we demonstrate a recognition rate of 94.2%; we show that our grip detection benefits from the physical constraints of holding an object. We explore two categories of input objects 1) tangible surfaces and 2) tangible tools and present two representative applications. We discuss the design and technical challenges for expanding the concept.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {mixed reality, grip recognition, gripmarks, tangible objects},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376706,
author = {Kelliher, Aisling and Zilevu, Setor and Rikakis, Thanassis and Ahmed, Tamim and Truong, Yen and Wolf, Steven L.},
title = {Towards Standardized Processes for Physical Therapists to Quantify Patient Rehabilitation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376706},
doi = {10.1145/3313831.3376706},
abstract = {Physical rehabilitation typically requires therapists to make judgements about patient movement and functional improvement using subjective observation. This process makes it challenging to quantitatively track, compute and predict long-term patient improvement. We therefore propose a novel methodical approach to the standardized and interpretable quantification of patient movement during rehabilitation. We describe the expert-led development of a movement assessment rubric and an accompanying quantitative rating system. We present our movement capture and annotation computational tools designed to implement the rubric and assist therapists in the quantitative documentation and assessment of rehabilitation. We describe results from a movement capture study of the tool with nine stroke survivors and a movement rating study with four therapists. Findings from these studies highlight potential optimal methodical process paths for individuals engaged in capturing, understanding and predicting human movement performance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human movement capture, stroke rehabilitation, home based rehabilitation therapy, human movement assessment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376222,
author = {Correll, Michael and Bertini, Enrico and Franconeri, Steven},
title = {Truncating the Y-Axis: Threat or Menace?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376222},
doi = {10.1145/3313831.3376222},
abstract = {Bar charts with y-axes that don't begin at zero can visually exaggerate effect sizes. However, advice for whether or not to truncate the y-axis can be equivocal for other visualization types. In this paper we present examples of visualizations where this y-axis truncation can be beneficial as well as harmful, depending on the communicative and analytic intent. We also present the results of a series of crowd-sourced experiments in which we examine how y-axis truncation impacts subjective effect size across visualization types, and we explore alternative designs that more directly alert viewers to this truncation. We find that the subjective impact of axis truncation is persistent across visualizations designs, even for designs with explicit visual cues that indicate truncation has taken place. We suggest that designers consider the scale of the meaningful effect sizes and variation they intend to communicate, regardless of the visual encoding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {information visualization, deceptive visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376664,
author = {Prpa, Mirjana and Fdili-Alaoui, Sarah and Schiphorst, Thecla and Pasquier, Philippe},
title = {Articulating Experience: Reflections from Experts Applying Micro-Phenomenology to Design Research in HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376664},
doi = {10.1145/3313831.3376664},
abstract = {Third wave HCI initiated a slow transformation in the methods of UX research: from widely used quantitative approaches to more recently employed qualitative techniques. Articulating the nuances, complexity, and diversity of a user's experience beyond surface descriptions remains a challenge within design. One qualitative method — micro-phenomenology — has been used in HCI/Design research since 2001. Yet, no systematic understanding of micro-phenomenology has been presented, particularly from the perspective of HCI/Design researchers who actively use it in design contexts. We interviewed 5 HCI/Design experts who utilize micro-phenomenology and present their experiences with the method. We illustrate how this method has been applied by the selected experts through developing a practice, and present conditions under which the descriptions of the experience unfold, and the values that this method can provide to HCI/Design field. Our contribution highlights the value of micro-phenomenology in articulating the experience of designers and participants, developing vocabulary for multi-sensory experiences, and unfolding embodied tacit knowledge.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {micro-phenomenology, user experience, empirical methods},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376632,
author = {Obada-Obieh, Borke and Huang, Yue and Beznosov, Konstantin},
title = {The Burden of Ending Online Account Sharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376632},
doi = {10.1145/3313831.3376632},
abstract = {Many people share online accounts, even in situations where high privacy and security are expected. Naturally, the sharing of these accounts does not endure forever. This paper reports the privacy and security challenges that people experience when they stop online account sharing. We conducted semi-structured interviews with 25 participants who stopped sharing at least one online account in the 12 months preceding the study. Our results suggest that users experience cognitive and psychosocial burdens when ending account sharing. We offer suggestions for how to improve the design of online accounts to support users better when they end account sharing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {usable security and privacy, online shared accounts},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376657,
author = {Wang, Xiyao and Besan\c{c}on, Lonni and Rousseau, David and Sereno, Mickael and Ammi, Mehdi and Isenberg, Tobias},
title = {Towards an Understanding of Augmented Reality Extensions for Existing 3D Data Analysis Tools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376657},
doi = {10.1145/3313831.3376657},
abstract = {We present an observational study with domain experts to understand how augmented reality (AR) extensions to traditional PC-based data analysis tools can help particle physicists to explore and understand 3D data. Our goal is to allow researchers to integrate stereoscopic AR-based visual representations and interaction techniques into their tools, and thus ultimately to increase the adoption of modern immersive analytics techniques in existing data analysis workflows. We use Microsoft's HoloLens as a lightweight and easily maintainable AR headset and replicate existing visualization and interaction capabilities on both the PC and the AR view. We treat the AR headset as a second yet stereoscopic screen, allowing researchers to study their data in a connected multi-view manner. Our results indicate that our collaborating physicists appreciate a hybrid data exploration setup with an interactive AR extension to improve their understanding of particle collision events.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {3D visualization, immersive analytics, hybrid visualization system, user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376322,
author = {Zhang, Xinlei and Miyaki, Takashi and Rekimoto, Jun},
title = {WithYou: Automated Adaptive Speech Tutoring With Context-Dependent Speech Recognition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376322},
doi = {10.1145/3313831.3376322},
abstract = {Learning to speak in foreign languages is hard. Speech shadowing has been rising as a proven way to practice speaking, which asks a learner to listen and repeat a native speech template as simultaneously as possible. However, shadowing can be hard to do because learners can frequently fail to follow the speech and unintentionally interrupt a practice session. Worse, as a technical way to evaluate shadowing performance in real-time has not been established, no automated solutions are available to help. In this paper, we propose a technical framework with context-dependent speech recognition to evaluate shadowing in real-time. We propose a shadowing tutor system called WithYou, which can automatically adjust the playback and the difficulty of a speech template when learners fail, so shadowing becomes smooth and tailored. Results from a user study show that WithYou provides greater speech improvements (14%) than the conventional method (2.7%) with a lower cognitive load.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {intelligent tutoring system, language learning, shadowing, speech recognition, speaking, computer assisted language learning (call)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376877,
author = {V\"{o}lkel, Sarah Theres and Haeuslschmid, Renate and Werner, Anna and Hussmann, Heinrich and Butz, Andreas},
title = {How to Trick AI: Users' Strategies for Protecting Themselves from Automatic Personality Assessment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376877},
doi = {10.1145/3313831.3376877},
abstract = {Psychological targeting tries to influence and manipulate users' behaviour. We investigated whether users can protect themselves from being profiled by a chatbot, which automatically assesses users' personality. Participants interacted twice with the chatbot: (1) They chatted for 45 minutes in customer service scenarios and received their actual profile (baseline). (2) They then were asked to repeat the interaction and to disguise their personality by strategically tricking the chatbot into calculating a falsified profile. In interviews, participants mentioned 41 different strategies but could only apply a subset of them in the interaction. They were able to manipulate all Big Five personality dimensions by nearly 10%. Participants regarded personality as very sensitive data. As they found tricking the AI too exhaustive for everyday use, we reflect on opportunities for privacy protective designs in the context of personality-aware systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {personality, automatic personality assessment, chatbot},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376752,
author = {Kizilcec, Rene F. and Saltarelli, Andrew and Bonfert-Taylor, Petra and Goudzwaard, Michael and Hamonic, Ella and Sharrock, R\'{e}mi},
title = {Welcome to the Course: Early Social Cues Influence Women's Persistence in Computer Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376752},
doi = {10.1145/3313831.3376752},
abstract = {First impressions influence subsequent behavior, especially when deciding how much effort to invest in an activity such as taking an online course. In computer programming courses, a context where social group stereotypes are salient, social cues early in the course can be used strategically to affirm members of historically underrepresented groups in their sense of belonging. We tested this idea in two randomized field experiments (N=53,922) by varying the social identity and status of the presenter of a welcome video and assessing online learners' persistence and achievement. Counter to our hypotheses, we found lower persistence among women in certain age groups if the welcome video was presented by a female instructor or by lower-status peers. Men remained unaffected. The results suggest that women are more responsive to social cues in online STEM courses, an environment where their social identity has been negatively stereotyped. Presenting a male and female instructor together was an effective strategy for retaining women in the course.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {inclusion, computer science, gender, psychology, education},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376822,
author = {Khurana, Rushil and Goel, Mayank},
title = {Eyes on the Road: Detecting Phone Usage by Drivers Using On-Device Cameras},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376822},
doi = {10.1145/3313831.3376822},
abstract = {Using a phone while driving is distracting and dangerous. It increases the accident chances by 400%. Several techniques have been proposed in the past to detect driver distraction due to phone usage. However, such techniques usually require instrumenting the user or the car with custom hardware. While detecting phone usage in the car can be done by using the phone's GPS, it is harder to identify whether the phone is used by the driver or one of the passengers. In this paper, we present a lightweight, software-only solution that uses the phone's camera to observe the car's interior geometry to distinguish phone position and orientation. We then use this information to distinguish between driver and passenger phone use. We collected data in 16 different cars with 33 different users and achieved an overall accuracy of 94% when the phone is held in hand and 92.2% when the phone is docked (1 sec. delay). With just a software upgrade, this work can enable smartphones to proactively adapt to the user's context in the car and and substantially reduce distracted driving incidents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {position sensing, in-car behavior, situational impairments, driver detection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376334,
author = {Ces\'{a}rio, Vanessa and Petrelli, Daniela and Nisi, Valentina},
title = {Teenage Visitor Experience: Classification of Behavioral Dynamics in Museums},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376334},
doi = {10.1145/3313831.3376334},
abstract = {Teenagers' engagement in museums is much talked about but little research has been done to understand their behavior and inform design. Findings from co-design sessions with teenagers suggested they value games and stories when thinking about enjoyable museum tours. Informed by these findings and working with a natural history museum, we designed: a story-based tour (Turning Point) and a game-based tour (Haunted Encounters), informed by similar content. The two strategies were evaluated with 78 teenagers (15-19 years old) visiting the museum as part of an educational school trip. We assessed teenagers' personality in class; qualitative and quantitative data on their engagement, experience, and usability of the apps were collected at the museum. The triangulation of quantitative and qualitative data show personality traits mapping into different behaviors. We offer implications for the design of museum apps targeted to teenagers, a group known as difficult to reach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visitor experience, game, teenagers, storytelling, co-design, museums, mobile experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376184,
author = {Richardson, Mike L. and Lloyd-Esenkaya, Tayfun and Petrini, Karin and Proulx, Michael J.},
title = {Reading with the Tongue: Individual Differences Affect the Perception of Ambiguous Stimuli with the BrainPort},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376184},
doi = {10.1145/3313831.3376184},
abstract = {There is an increasing interest in non-visual interfaces for HCI to take advantage of the information processing capability of the other sensory modalities. The BrainPort is a vision-to-tactile sensory substitution device that conveys information through electro-stimulation on the tongue. As the tongue is a horizontal surface, it makes for an interesting platform to study the brain's representation of space. But which way is up on the tongue? We provided participants with perceptually ambiguous stimuli and measured how often different perspectives were adopted; furthermore, whether camera orientation and gender had an effect. Additionally, we examined whether personality (trait extraversion and openness) could predict the perspective taken. We found that self-centered perspectives were predominantly adopted, and that trait openness may predict perspective. This research demonstrates how individual differences can affect the usability of sensory substitution devices, and highlights the need for flexible and customisable interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {sensory substitution, tactile interfaces, individual differences in computing, user preferences},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376138,
author = {Han, Teng and Wang, Sirui and Wang, Sijia and Fan, Xiangmin and Liu, Jie and Tian, Feng and Fan, Mingming},
title = {Mouill\'{e}: Exploring Wetness Illusion on Fingertips to Enhance Immersive Experience in VR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376138},
doi = {10.1145/3313831.3376138},
abstract = {Providing users with rich sensations is beneficial to enhance their immersion in Virtual Reality (VR) environments. Wetness is one such imperative sensation that affects users' sense of comfort and helps users adjust grip force when interacting with objects. Researchers have recently begun to explore ways to create wetness illusions, primarily on a user's face or body skin. In this work, we extended this line of research by creating wetness illusion on users' fingertips. We first conducted a user study to understand the effect of thermal and tactile feedback on users' perceived wetness sensation. Informed by the findings, we designed and evaluated a prototype---Mouill\'{e}---that provides various levels of wetness illusions on fingertips for both hard and soft items when users squeeze, lift, or scratch it. Study results indicated that users were able to feel wetness with different levels of temperature changes and they were able to distinguish three levels of wetness for simulated VR objects. We further presented applications that simulated an ice cube, an iced cola bottle, and a wet sponge, etc, to demonstrate its use in VR.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {virtual reality, prototype, wetness illusion, user study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376203,
author = {Meschtscherjakov, Alexander and D\"{o}ttlinger, Christine and Kaiser, Tim and Tscheligi, Manfred},
title = {Chase Lights in the Peripheral View: How the Design of Moving Patterns on an LED Strip Influences the Perception of Speed in an Automotive Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376203},
doi = {10.1145/3313831.3376203},
abstract = {LEDs on a strip, when turned on and off in a specific order, result in the perception of apparent motion (i.e. beta movement). In the automotive domain such chase lights have been used to alter drivers' perception of driving speed by manipulating the pixel speed of LEDs. We argue that the perceived velocity of beta movement in the peripheral view is not only based on the actual pixel speed but can be influenced by other factors such as frequency, width and brightness of lit LED segments. We conducted a velocity matching experiment (N=25) by systematically varying these three properties, in order to determine their influence on a participant's perceived velocity in a vehicle mock-up. Results show that a higher frequency and stronger brightness increased perceived velocity, whereas segment width had no influence. We discuss how findings may be applied when designing systems that use beta movement to influence the perception of ambient light velocity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {chase lights, velocity perception, moving patterns, peripheral vision},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376527,
author = {Carstensdottir, Elin and Partlan, Nathan and Sutherland, Steven and Duke, Tyler and Ferris, Erika and Richter, Robin M. and Valladares, Maria and Seif El-Nasr, Magy},
title = {Progression Maps: Conceptualizing Narrative Structure for Interaction Design Support},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376527},
doi = {10.1145/3313831.3376527},
abstract = {Interactive narratives are frequently designed for learning and training applications, such as social training. In these contexts, designers may be inexperienced in storytelling and interaction design, and it may be difficult to quickly build an effective experience, even for experienced designers. Designers often approach this problem through iterative design. To augment and reduce iteration, we argue for the utility of employing models to reason about, evaluate, and improve designs. While there has been much previous work on interactive narrative models, none of them capture aspects of the interaction design necessary for testing and evaluation. In this paper we propose a new computational model called Progression Maps, which abstracts interaction design elements of the narrative's structure and visualizes its interaction properties. We report on the model, its implementation, and two studies evaluating its use. Our results demonstrate Progression Maps' effectiveness in communicating the underlying design through an easily understandable visualization.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visualization, interaction design, design assistance tools, interactive narrative, game design, interactive narrative model, graph-based models},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376496,
author = {Cockburn, Andy and Lewis, Blaine and Quinn, Philip and Gutwin, Carl},
title = {Framing Effects Influence Interface Feature Decisions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376496},
doi = {10.1145/3313831.3376496},
abstract = {Studies in psychology have shown that framing effects, where the positive or negative attributes of logically equivalent choices are emphasised, influence people's decisions. When outcomes are uncertain, framing effects also induce patterns of choice reversal, where decisions tend to be risk averse when gains are emphasised and risk seeking when losses are emphasised. Studies of these effects typically use potent framing stimuli, such as the mortality of people suffering from diseases or personal financial standing. We examine whether these effects arise in users' decisions about interface features, which typically have less visceral consequences, using a crowd-sourced study based on snap-to-grid drag-and-drop tasks (n = 842). The study examined several framing conditions: those similar to prior psychological research, and those similar to typical interaction choices (enabling/disabling features). Results indicate that attribute framing strongly influences users' decisions, that these decisions conform to patterns of risk seeking for losses, and that patterns of choice reversal occur.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {attribute framing, risky choice framing, framing effects, interface decisions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376883,
author = {Beneteau, Erin},
title = {Who Are You Asking?: Qualitative Methods for Involving AAC Users as Primary Research Participants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376883},
doi = {10.1145/3313831.3376883},
abstract = {When trying to understand people's perspectives, qualitative researchers in HCI often use methods which assume participants can easily communicate verbally. There are few dedicated resources in HCI which provide an overview of qualitative methods to effectively gather the perspectives of people who cannot easily communicate verbally; specifically, people who use Augmentative and Alternative Communication (AAC). As a result, AAC users might be excluded from studies using methods such as interviews or focus groups, even if they fit the researcher's target population. To address this problem, I review literature from both HCI and therapeutic AAC research fields to discuss methods used with AAC users. In addition, I present relevant case examples from my own qualitative research and propose a framework to guide HCI researchers on choosing appropriate methods when involving AAC users as central research participants. I also identify design opportunities for HCI researchers to innovate on the tools and methods used for qualitative research with AAC users. This paper provides an easily accessible overview of qualitative methods HCI researchers can use with AAC users as participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {disabilities, methods, qualitative research, aac, augmentative and alternative communication, hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376468,
author = {Soni, Nikita and Gleaves, Schuyler and Neff, Hannah and Morrison-Smith, Sarah and Esmaeili, Shaghayegh and Mayne, Ian and Bapat, Sayli and Schuman, Carrie and Stofer, Kathryn A. and Anthony, Lisa},
title = {Adults' and Children's Mental Models for Gestural Interactions with Interactive Spherical Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376468},
doi = {10.1145/3313831.3376468},
abstract = {Interactive spherical displays offer numerous opportunities for engagement and education in public settings. Prior work established that users' touch-gesture patterns on spherical displays differ from those on flatscreen tabletops, and speculated that these differences stem from dissimilarity in how users conceptualize interactions with these two form factors. We analyzed think-aloud data collected during a gesture elicitation study to understand adults' and children's (ages 7 to 11) conceptual models of interaction with spherical displays and compared them to conceptual models of interaction with tabletop displays from prior work. Our findings confirm that the form factor strongly influenced users' mental models of interaction with the sphere. For example, participants conceptualized that the spherical display would respond to gestures in a similar way as real-world spherical objects like physical globes. Our work contributes new understanding of how users draw upon the perceived affordances of the sphere as well as prior touchscreen experience during their interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touchscreen displays, mental models, touchscreen gestures, adults, children, interactive spherical displays},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376454,
author = {Hofman, Jake M. and Goldstein, Daniel G. and Hullman, Jessica},
title = {How Visualizing Inferential Uncertainty Can Mislead Readers About Treatment Effects in Scientific Results},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376454},
doi = {10.1145/3313831.3376454},
abstract = {When presenting visualizations of experimental results, scientists often choose to display either inferential uncertainty (e.g., uncertainty in the estimate of a population mean) or outcome uncertainty (e.g., variation of outcomes around that mean) about their estimates. How does this choice impact readers' beliefs about the size of treatment effects? We investigate this question in two experiments comparing 95% confidence intervals (means and standard errors) to 95% prediction intervals (means and standard deviations). The first experiment finds that participants are willing to pay more for and overestimate the effect of a treatment when shown confidence intervals relative to prediction intervals. The second experiment evaluates how alternative visualizations compare to standard visualizations for different effect sizes. We find that axis rescaling reduces error, but not as well as prediction intervals or animated hypothetical outcome plots (HOPs), and that depicting inferential uncertainty causes participants to underestimate variability in individual outcomes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {judgment and decision making, confidence intervals, uncertainty visualization, prediction intervals, effect sizes},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376156,
author = {Petro, Gwen and Gonzales, Amy and Calarco, Jessica},
title = {"Out of Luck": Socio-Economic Differences in Student Coping Responses to Technology Problems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376156},
doi = {10.1145/3313831.3376156},
abstract = {Despite high levels of digital technology access among college students, technology disruption remains an issue. This study was conducted to understand how technology disruption might contribute to socio-economic disparities in academic performance. Data were analyzed from a non-representative sample of 748 undergraduate students. We examined socio-economic differences in types of technology problems students experience; the consequences of those problems; and beliefs about how to handle future problems. Socio-economic status was not associated with types of technology problems, but it was associated with greater negative consequences and less-efficacious beliefs about handling future situations. These findings are consistent with sociological work on socio-economic differences in student help-seeking. They also elaborate mechanistic understanding of the technology maintenance construct. Finally, for those interested in designing to reduce socio-economic inequalities, they suggest the need for interfaces that go beyond information accessibility to facilitate student empowerment and student-teacher communication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {education/learning, accessibility, schools/educational setting, empirical study that tells us about people},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376301,
author = {Yang, Qian and Steinfeld, Aaron and Ros\'{e}, Carolyn and Zimmerman, John},
title = {Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376301},
doi = {10.1145/3313831.3376301},
abstract = {Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user experience, artificial intelligence, sketching, prototyping},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376875,
author = {Wu, Jason and Harrison, Chris and Bigham, Jeffrey P. and Laput, Gierad},
title = {Automated Class Discovery and One-Shot Interactions for Acoustic Activity Recognition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376875},
doi = {10.1145/3313831.3376875},
abstract = {Acoustic activity recognition has emerged as a foundational element for imbuing devices with context-driven capabilities, enabling richer, more assistive, and more accommodating computational experiences. Traditional approaches rely either on custom models trained in situ, or general models pre-trained on preexisting data, with each approach having accuracy and user burden implications. We present Listen Learner, a technique for activity recognition that gradually learns events specific to a deployed environment while minimizing user burden. Specifically, we built an end-to-end system for self-supervised learning of events labelled through one-shot interaction. We describe and quantify system performance 1) on preexisting audio datasets, 2) on real-world datasets we collected, and 3) through user studies which uncovered system behaviors suitable for this new type of interaction. Our results show that our system can accurately and automatically learn acoustic events across environments (e.g., 97% precision, 87% recall), while adhering to users' preferences for non-intrusive interactive behavior.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {automatic class discovery, acoustic activity recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376792,
author = {Lindley, Joseph and Akmal, Haider Ali and Pilling, Franziska and Coulton, Paul},
title = {Researching AI Legibility through Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376792},
doi = {10.1145/3313831.3376792},
abstract = {Everyday interactions with computers are increasingly likely to involve elements of Artificial Intelligence (AI). Encompassing a broad spectrum of technologies and applications, AI poses many challenges for HCI and design. One such challenge is the need to make AI's role in a given system legible to the user in a meaningful way. In this paper we employ a Research through Design (RtD) approach to explore how this might be achieved. Building on contemporary concerns and a thorough exploration of related research, our RtD process reflects on designing imagery intended to help increase AI legibility for users. The paper makes three contributions. First, we thoroughly explore prior research in order to critically unpack the AI legibility problem space. Second, we respond with design proposals whose aim is to enhance the legibility, to users, of systems using AI. Third, we explore the role of design-led enquiry as a tool for critically exploring the intersection between HCI and AI research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {research through design, legibility, machine learning, human-data interaction, artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376675,
author = {Kraus, Matthias and Angerbauer, Katrin and Buchm\"{u}ller, Juri and Schweitzer, Daniel and Keim, Daniel A. and Sedlmair, Michael and Fuchs, Johannes},
title = {Assessing 2D and 3D Heatmaps for Comparative Analysis: An Empirical Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376675},
doi = {10.1145/3313831.3376675},
abstract = {Heatmaps are a popular visualization technique that encode 2D density distributions using color or brightness. Experimental studies have shown though that both of these visual variables are inaccurate when reading and comparing numeric data values. A potential remedy might be to use 3D heatmaps by introducing height as a third dimension to encode the data. Encoding abstract data in 3D, however, poses many problems, too. To better understand this tradeoff, we conducted an empirical study (N=48) to evaluate the user performance of 2D and 3D heatmaps for comparative analysis tasks. We test our conditions on a conventional 2D screen, but also in a virtual reality environment to allow for real stereoscopic vision. Our main results show that 3D heatmaps are superior in terms of error rate when reading and comparing single data items. However, for overview tasks, the well-established 2D heatmap performs better.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visual analytics, virtual reality, heatmaps},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376194,
author = {Bachynskyi, Myroslav and M\"{u}ller, J\"{o}rg},
title = {Dynamics of Aimed Mid-Air Movements},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376194},
doi = {10.1145/3313831.3376194},
abstract = {Mid-air arm movements are ubiquitous in VR, AR, and gestural interfaces. While mouse movements have received some attention, the dynamics of mid-air movements are understudied in HCI. In this paper we present an exploratory analysis of the dynamics of aimed mid-air movements. We explore the 3rd order lag (3OL) and existing 2nd order lag (2OL) models for modeling these dynamics. For a majority of movements the 3OL model captures mid-air dynamics better, in particular acceleration. The models can effectively predict the complete time series of position, velocity and acceleration of aimed movements given an initial state and a target using three (2OL) or four (3OL) free parameters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {aimed movements, mid-air movements, control theory, movement dynamics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376425,
author = {Vasquez, Joshua and Twigg-Smith, Hannah and Tran O'Leary, Jasper and Peek, Nadya},
title = {Jubilee: An Extensible Machine for Multi-Tool Fabrication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376425},
doi = {10.1145/3313831.3376425},
abstract = {We present Jubilee, an open-source hardware machine with automatic tool-changing and interchangeable bed plates. As digital fabrication tools have become more broadly accessible, tailoring those machines to new users and novel workflows has become central to HCI research. However, the lack of hardware infrastructure makes custom application development cumbersome. We identify a need for an extensible platform to allow HCI researchers to develop workflows for fabrication, material exploration, and other applications. Jubilee addresses this need. It can automatically and repeatably change tools in the same operation. It can be built with a combination of simple 3D-printed and readily available parts. It has several standard head designs for a variety of applications including 3D printing, syringe-based liquid handling, imaging, and plotting. We present Jubilee with a comprehensive set of assembly instructions and kinematic mount templates for user-designed tools and bed plates. Finally we demonstrate Jubilee's multi-tool workflow functionality with a series of example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {digital fabrication, multi-tool workflows, toolchanging},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376712,
author = {Arimatsu, Kazuyuki and Mori, Hideki},
title = {Evaluation of Machine Learning Techniques for Hand Pose Estimation on Handheld Device with Proximity Sensor},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376712},
doi = {10.1145/3313831.3376712},
abstract = {Tracking finger movement for natural interaction using hand is commonly studied. For vision-based implementations of finger tracking in virtual reality (VR) application, finger movement is occluded by a handheld device which is necessary for auxiliary input, thus tracking finger movement using cameras is still challenging. Finger tracking controllers using capacitive proximity sensors on the surface are starting to appear. However, research on estimating articulated hand pose from curved capacitance sensing electrodes is still immature. Therefore, we built a prototype with 62 electrodes and recorded training datasets using an optical tracking system. We have introduced 2.5D representation to apply convolutional neural network methods on a capacitive image of the curved surface, and two types of network architectures based on recent achievements in the computer vision field were evaluated with our dataset. We also implemented real-time interactive applications using the prototype and demonstrated the possibility of intuitive interaction using fingers in VR applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human computer interactiton, virtual reality, capacitive image, finger tracking controller, hand pose estimation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376230,
author = {Joshi, Nikhita and Matejka, Justin and Anderson, Fraser and Grossman, Tovi and Fitzmaurice, George},
title = {MicroMentor: Peer-to-Peer Software Help Sessions in Three Minutes or Less},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376230},
doi = {10.1145/3313831.3376230},
abstract = {While synchronous one-on-one help for software learning is rich and valuable, it can be difficult to find and connect with someone who can provide assistance. Through a formative user study, we explore the idea of fixed-duration, one-on-one help sessions and find that 3 minutes is often enough time for novice users to explain their problem and receive meaningful help from an expert. To facilitate this type of interaction, we developed MicroMentor, an on-demand help system that connects users via video chat for 3-minute help sessions. MicroMentor automatically attaches relevant supplementary materials and uses contextual information, such as command history and expertise, to encourage the most qualified users to accept incoming requests. These help sessions are recorded and archived, building a bank of knowledge that can further help a broader audience. Through a user study, we find MicroMentor to be useful and successful in connecting users for short teaching moments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {software learning, quick help, mentoring, one-on-one help},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376602,
author = {Miniukovich, Aliaksei and Marchese, Maurizio},
title = {Relationship Between Visual Complexity and Aesthetics of Webpages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376602},
doi = {10.1145/3313831.3376602},
abstract = {Substantial HCI research investigated the relationship between webpage complexity and aesthetics, but without a definitive conclusion. Some research showed an inverse linear correlation, some other showed an inverted u-shaped curve, while the rest showed no relationship at all. Such a lack of clarity complicates hypothesis formulation and result interpretation for future research, and lowers the reliability and generalizability of potential advice for Web design practice. We re-collected complexity and aesthetics ratings for five datasets previously used in webpage aesthetics and complexity research. The results were mixed, but suggested an inverse linear relationship with a weaker u-shaped sub-component. A subsequent visual inspection of revealed several confounding factors that may have led to the mixed results, including some webpages looking broken or archaic. The second data collection showed that accounting for these factors generally eliminates the u-shaped tendency of the complexity-aesthetics relationship, at least, for a relatively homogeneous sample of English-speaking participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visual aesthetics, graphical user interfaces, user study, quantitative analyses, web design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376329,
author = {Wong-Villacres, Marisol and DiSalvo, Carl and Kumar, Neha and DiSalvo, Betsy},
title = {Culture in Action: Unpacking Capacities to Inform Assets-Based Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376329},
doi = {10.1145/3313831.3376329},
abstract = {The field of Human-Computer Interaction (HCI) aims at securing a lasting impact for technology-based interventions in the context of social inequities. Increasingly, HCI scholars are proposing assets-based design as an effective approach towards this issue. Rather than starting from people's needs and deficits, this approach posits that design should start from a deep understanding of people's assets. A pending issue, however, is how to account for the situated nature of assets; that is, how to decide which asset to leverage and for what design purpose. Drawing from cultural sociology and shifting the emphasis from assets to capacities, we propose Swidler's theory of culture-in-action as an analytical lens for unpacking the complex relationship between capacities, goals, and structural limitations. Leveraging findings from a Participatory Design engagement with 35 Latino immigrant parents for envisioning parent-education technologies, we demonstrate the applicability of this lens. We contribute to HCI scholarship by further discussing 1) how to analyze capacities' design potential, and 2) the methodological particularities for collecting them.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {capacities, assets-based, immigrant parents, participatory design, culture},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376463,
author = {Spagnolli, Anna and Mora, Diletta and Fanchin, Matteo and Orso, Valeria and Gamberini, Luciano},
title = {Automation and Creativity: A Case Study of DJs' and VJs' Ambivalent Positions on Automated Visual Software},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376463},
doi = {10.1145/3313831.3376463},
abstract = {Computerized solutions in the domain of creativity and expressive performance increasingly provide art and artists with exciting new opportunities. However, the combination of automation and creativity also raises controversies and resistance in some user groups. This paper considers the case of software-generated visuals in live music performance and tries to make sense of the ambivalent response given by its intended users (i.e., DJs and VJs). We carried out seven face-to-face interviews, an online survey (N = 102) and 25 interviews at a distance to unravel DJs' and VJs' positions on automated visual software. Four core controversies were eventually identified, gravitating around the implications of using such software on DJs' and VJs' identities as artists and on their competitive advantage in their activity sector. The conclusions reconnect these findings with the larger issue of understanding the users' responses to automation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {automation, acceptance, live music performance, ambivalence, creativity, visual software, argumentation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376781,
author = {Winkler, Rainer and Hobert, Sebastian and Salovaara, Antti and S\"{o}llner, Matthias and Leimeister, Jan Marco},
title = {Sara, the Lecturer: Improving Learning in Online Education with a Scaffolding-Based Conversational Agent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376781},
doi = {10.1145/3313831.3376781},
abstract = {Enrollment in online courses has sharply increased in higher education. Although online education can be scaled to large audiences, the lack of interaction between educators and learners is difficult to replace and remains a primary challenge in the field. Conversational agents may alleviate this problem by engaging in natural interaction and by scaffolding learners' understanding similarly to educators. However, whether this approach can also be used to enrich online video lectures has largely remained unknown. We developed Sara, a conversational agent that appears during an online video lecture. She provides scaffolds by voice and text when needed and includes a voice-based input mode. An evaluation with 182 learners in a 2 x 2 lab experiment demonstrated that Sara, compared to more traditional conversational agents, significantly improved learning in a programming task. This study highlights the importance of including scaffolding and voice-based conversational agents in online videos to improve meaningful learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {conversational agent, online education, voice interaction, interactivity, scaffolding, experiment, online videos},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376317,
author = {Kumar, Chandan and Hedeshy, Ramin and MacKenzie, I. Scott and Staab, Steffen},
title = {TAGSwipe: Touch Assisted Gaze Swipe for Text Entry},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376317},
doi = {10.1145/3313831.3376317},
abstract = {The conventional dwell-based methods for text entry by gaze are typically slow and uncomfortable. A swipe-based method that maps gaze path into words offers an alternative. However, it requires the user to explicitly indicate the beginning and ending of a word, which is typically achieved by tedious gaze-only selection. This paper introduces TAGSwipe, a bi-modal method that combines the simplicity of touch with the speed of gaze for swiping through a word. The result is an efficient and comfortable dwell-free text entry method. In the lab study TAGSwipe achieved an average text entry rate of 15.46 wpm and significantly outperformed conventional swipe-based and dwell-based methods in efficacy and user satisfaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touch input, eye tracking, dwell-free typing, word-level text entry, eye typing, multimodal interaction, swipe},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376726,
author = {Wang, Xingbo and Zeng, Haipeng and Wang, Yong and Wu, Aoyu and Sun, Zhida and Ma, Xiaojuan and Qu, Huamin},
title = {VoiceCoach: Interactive Evidence-Based Training for Voice Modulation Skills in Public Speaking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376726},
doi = {10.1145/3313831.3376726},
abstract = {The modulation of voice properties, such as pitch, volume, and speed, is crucial for delivering a successful public speech. However, it is challenging to master different voice modulation skills. Though many guidelines are available, they are often not practical enough to be applied in different public speaking situations, especially for novice speakers. We present VoiceCoach, an interactive evidence-based approach to facilitate the effective training of voice modulation skills. Specifically, we have analyzed the voice modulation skills from 2623 high-quality speeches (i.e., TED Talks) and use them as the benchmark dataset. Given a voice input, VoiceCoach automatically recommends good voice modulation examples from the dataset based on the similarity of both sentence structures and voice modulation skills. Immediate and quantitative visual feedback is provided to guide further improvement. The expert interviews and the user study provide support for the effectiveness and usability of VoiceCoach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {evidence-based training, voice modulation, data visualization, public speaking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376395,
author = {Seifi, Hasti and Oppermann, Michael and Bullard, Julia and MacLean, Karon E. and Kuchenbecker, Katherine J.},
title = {Capturing Experts' Mental Models to Organize a Collection of Haptic Devices: Affordances Outweigh Attributes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376395},
doi = {10.1145/3313831.3376395},
abstract = {Humans rely on categories to mentally organize and understand sets of complex objects. One such set, haptic devices, has myriad technical attributes that affect user experience in complex ways. Seeking an effective navigation structure for a large online collection, we elicited expert mental categories for grounded force-feedback haptic devices: 18 experts (9 device creators, 9 interaction designers) reviewed, grouped, and described 75 devices according to their similarity in a custom card-sorting study. From the resulting quantitative and qualitative data, we identify prominent patterns of tagging versus binning, and we report 6 uber-attributes that the experts used to group the devices, favoring affordances over device specifications. Finally, we derive 7 device categories and 9 subcategories that reflect the imperfect yet semantic nature of the expert mental models. We visualize these device categories and similarities in the online haptic collection, and we offer insights for studying expert understanding of other human-centered technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {information visualization, haptic hardware collection, expert-sourced categorization, mental model, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376311,
author = {Luria, Michal and Zheng, Rebecca and Huffman, Bennett and Huang, Shuangni and Zimmerman, John and Forlizzi, Jodi},
title = {Social Boundaries for Personal Agents in the Interpersonal Space of the Home},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376311},
doi = {10.1145/3313831.3376311},
abstract = {The presence of voice activated personal assistants (VAPAs) in people's homes rises each year [31]. Industry efforts are invested in making interactions with VAPAs more personal by leveraging information from messages and calendars, and by accessing user accounts for 3rd party services. However, the use of personal data becomes more complicated in interpersonal spaces, such as people's homes. Should a shared agent access the information of many users? If it does, how should it navigate issues of privacy and control? Designers currently lack guidelines to help them design appropriate agent behaviors. We used Speed Dating to explore inchoate social mores around agent actions within a home, including issues of proactivity, interpersonal conflict, and agent prevarication. Findings offer new insights on how more socially sophisticated agents might sense, make judgements about, and navigate social roles and individuals. We discuss how our findings might impact future research and future agent behaviors.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social robots, conversational agents, speed dating, interaction design, embodied agents, voice activated personal assistants},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376666,
author = {Masaki, Hiroaki and Shibata, Kengo and Hoshino, Shui and Ishihama, Takahiro and Saito, Nagayuki and Yatani, Koji},
title = {Exploring Nudge Designs to Help Adolescent SNS Users Avoid Privacy and Safety Threats},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376666},
doi = {10.1145/3313831.3376666},
abstract = {A nudge is a method to influence individual choices without taking away freedom of choice. We are interested in whether nudges can help adolescents avoid privacy and safety threats on social network services (SNS). We conducted an online survey to compare how 11 different nudge designs influence decisions on 9 scenarios featuring various privacy and safety threats. We collected 29,608 responses from adolescent SNS users (self-claimed high school and university students), and found that nudges can help to educe potentially risk choices. Participants were more likely to avoid potentially risky choices when presented with negative frames (e.g., "90% of users would not share a photo without permission'') than affirmative ones (e.g., "10% of users would''). Social nudges displaying statistics on how likely other people would make potentially risky decisions can have a negative effect in comparison to a nudge with only general privacy and safety suggestions. We conclude by providing design considerations for privacy/safety nudges targeting adolescent SNS users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {adolescent sns users, online privacy and safety, large-scale survey, social nudges},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376484,
author = {Faas, Stefanie M. and Kao, Andrea C. and Baumann, Martin},
title = {A Longitudinal Video Study on Communicating Status and Intent for Self-Driving Vehicle – Pedestrian Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376484},
doi = {10.1145/3313831.3376484},
abstract = {With self-driving vehicles (SDVs), pedestrians cannot rely on communication with the driver anymore. Industry experts and policymakers are proposing an external Human-Machine Interface (eHMI) communicating the automated status. We investigated whether additionally communicating SDVs' intent to give right of way further improves pedestrians' street crossing. To evaluate the stability of these eHMI effects, we conducted a three-session video study with N=34 pedestrians where we assessed subjective evaluations and crossing onset times. This is the first work capturing long-term effects of eHMIs. Our findings add credibility to prior studies by showing that eHMI effects last (acceptance, user experience) or even increase (crossing onset, perceived safety, trust, learnability, reliance) with time. We found that pedestrians benefit from an eHMI communicating SDVs' status, and that additionally communicating SDVs' intent adds further value. We conclude that SDVs should be equipped with an eHMI communicating both status and intent.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {intent, information need, external human-machine interface, status, self-driving vehicles, pedestrians},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376739,
author = {Louie, Ryan and Coenen, Andy and Huang, Cheng Zhi and Terry, Michael and Cai, Carrie J.},
title = {Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376739},
doi = {10.1145/3313831.3376739},
abstract = {While generative deep neural networks (DNNs) have demonstrated their capacity for creating novel musical compositions, less attention has been paid to the challenges and potential of co-creating with these musical AIs, especially for novices. In a needfinding study with a widely used, interactive musical AI, we found that the AI can overwhelm users with the amount of musical content it generates, and frustrate them with its non-deterministic output. To better match co-creation needs, we developed AI-steering tools, consisting of Voice Lanes that restrict content generation to particular voices; Example-Based Sliders to control the similarity of generated content to an existing example; Semantic Sliders to nudge music generation in high-level directions (happy/sad, conventional/surprising); and Multiple Alternatives of generated content to audition and choose from. In a summative study (N=21), we discovered the tools not only increased users' trust, control, comprehension, and sense of collaboration with the AI, but also contributed to a greater sense of self-efficacy and ownership of the composition relative to the AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {generative deep neural networks, co-creation, human-ai interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376415,
author = {Hanson, Julia and Wei, Miranda and Veys, Sophie and Kugler, Matthew and Strahilevitz, Lior and Ur, Blase},
title = {Taking Data Out of Context to Hyper-Personalize Ads: Crowdworkers' Privacy Perceptions and Decisions to Disclose Private Information},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376415},
doi = {10.1145/3313831.3376415},
abstract = {Data brokers and advertisers increasingly collect data in one context and use it in another. When users encounter a misuse of their data, do they subsequently disclose less information? We report on human-subjects experiments with 25 in-person and 280 online participants. First, participants provided personal information amidst distractor questions. A week later, while participants completed another survey, they received either a robotext or online banner ad seemingly unrelated to the study. Half of the participants received an ad containing their name, partner's name, preferred cuisine, and location; others received a generic ad. We measured how many of 43 potentially invasive questions participants subsequently chose to answer. Participants reacted negatively to the personalized ad, yet answered nearly all invasive questions accurately. We unpack our results relative to the privacy paradox, contextual integrity, and power dynamics in crowdworker platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {creepy, hyper-personalization, user study, targeted advertising},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376815,
author = {Putze, Felix and Ihrig, Tilman and Schultz, Tanja and Stuerzlinger, Wolfgang},
title = {Platform for Studying Self-Repairing Auto-Corrections in Mobile Text Entry Based on Brain Activity, Gaze, and Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376815},
doi = {10.1145/3313831.3376815},
abstract = {Auto-correction is a standard feature of mobile text entry. While the performance of state-of-the-art auto-correct methods is usually relatively high, any errors that occur are cumbersome to repair, interrupt the flow of text entry, and challenge the user's agency over the process. In this paper, we describe a system that aims to automatically identify and repair auto-correction errors. This system comprises a multi-modal classifier for detecting auto-correction errors from brain activity, eye gaze, and context information, as well as a strategy to repair such errors by replacing the erroneous correction or suggesting alternatives. We integrated both parts in a generic Android component and thus present a research platform for studying self-repairing end-to-end systems. To demonstrate its feasibility, we performed a user study to evaluate the classification performance and usability of our approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {EEG, self-repair, text entry, eye gaze, auto-correction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376614,
author = {Lin, Chuan-en and Cheng, Ta Ying and Ma, Xiaojuan},
title = {ARchitect: Building Interactive Virtual Experiences from Physical Affordances by Bringing Human-in-the-Loop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376614},
doi = {10.1145/3313831.3376614},
abstract = {Automatic generation of Virtual Reality (VR) worlds which adapt to physical environments have been proposed to enable safe walking in VR. However, such techniques mainly focus on the avoidance of physical objects as obstacles and overlook their interaction affordances as passive haptics. Current VR experiences involving interaction with physical objects in surroundings still require verbal instruction from an assisting partner. We present ARchitect, a proof-of-concept prototype that allows flexible customization of a VR experience with human-in-the-loop. ARchitect brings in an assistant to map physical objects to virtual proxies of matching affordances using Augmented Reality (AR). In a within-subjects study (9 user pairs) comparing ARchitect to a baseline condition, assistants and players experienced decreased workload and players showed increased VR presence and trust in the assistant. Finally, we defined design guidelines of ARchitect for future designers and implemented three demonstrative experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {passive haptics, asymmetric, architect, affordance, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376542,
author = {Rho, Eugenia Ha Rim and Mazmanian, Melissa},
title = {Political Hashtags &amp; the Lost Art of Democratic Discourse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376542},
doi = {10.1145/3313831.3376542},
abstract = {In this work, we investigate whether and how the presence of political hashtags in social media news articles influences the way people discuss news content. Specifically, we examine how political hashtags in news posts act as a design characteristic that affects the quality of online discourse. We use a randomized control experiment to assess how the presence versus absence of political hashtags (particularly the most prevalently used #MeToo and #BlackLivesMatter) in social media news posts shapes discourse across a general audience (n=3205). Key findings show differences in topical focus, emotional tone of discourse, and rhetorical styles between commenters who were shown news posts with political hashtags versus those shown news posts without the hashtags. Compared to the control group, those shown hashtagged news posts heavily focus on the politics of the hashtag, use more words associated with fear, anger, and disgust in their comments, and exhibit black-and-white rhetoric and less emotionally temperate expressions in their arguments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social media news, political hashtags, digital journalism, control experiment, online social movements, civil discourse},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376252,
author = {Kang, Seokbin and Shokeen, Ekta and Byrne, Virginia L. and Norooz, Leyla and Bonsignore, Elizabeth and Williams-Pierce, Caro and Froehlich, Jon E.},
title = {ARMath: Augmenting Everyday Life with Math Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376252},
doi = {10.1145/3313831.3376252},
abstract = {We introduce ARMath, a mobile Augmented Reality (AR) system that allows ch ildren to discover mathematical concepts in familiar, ord inary objects and engage with math problems in meaningful contexts. Leveraging advanced computer vision, ARMath recognizes everyday objects, visualizes their mathematical attributes, and turns them into tangible or virtual manipulatives. Using the manipulatives, children can solve problems that situate math operations or concepts in specific everyday contexts. Informed by four participatory design sessions with teachers and children, we developed five ARMath modules to support basic arithmetic and 2D geometry. We also conducted an exploratory evaluation of ARMath with 27 children (ages 5-8) at a local children's museum. Our findings demonstrate how ARMath engages children in math learning, how failures in AI can be used as learning opportunities, and challenges that children face when using ARMath.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {human-ai interaction, learning, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376500,
author = {Chidziwisano, George Hope and Wyche, Susan and Oduor, Erick},
title = {GridAlert: Using a Sensor-Based Technology to Monitor Power Blackouts in Kenyan Homes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376500},
doi = {10.1145/3313831.3376500},
abstract = {Power blackouts (outages) are a common occurrence in Kenyan households. They affect people's livelihoods, and damage their property (household electrical items). We explore the role of GridAlert-a sensor-based technology we designed-in monitoring power blackouts. We worked with local technicians to design GridAlert's housing and integrate GridAlert with Kenya's electricity infrastructure. Then, we used interview, observation, diary, and data logging methods to understand 18 households' experiences using the system. Our findings provide insights for using sensor-based technology to monitor power usage and blackouts in Kenyan households. We also present participants' thoughts about GridAlert's housing, and about how it influenced their actions when using the system. We use these findings to discuss design insights for power monitoring systems, and to offer new perspectives on the role of technology in monitoring blackouts in Kenyan households.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {domestic technology, electricity, blackouts, monitoring, sensors, hardware, kenya},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376231,
author = {Jung, Heekyoung},
title = {In Search of Forms for Evocative and Generative Reflection: Exploratory Studies and a Design Proposal},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376231},
doi = {10.1145/3313831.3376231},
abstract = {Today an increasing number of personal informatics tools and platforms support intended behavior change and goal achievement through data-based self-reflection. The scope of self-reflection expands with emerging sources, goals, and challenges of human well-being, demanding for reframing recent computer-mediated reflective practice. This study investigates a broader range of contexts and forms of self-reflection that support navigating one's mind and goals beyond achieving preset goals. This paper describes contemporary issues on human well-being and two exploratory studies-one conducted in a traveling artists' residency and the other in a design studio class-which surveyed various triggers, contexts, and forms of self-reflection. By connecting the insights from the two studies, I propose evocative and generative reflection as an alternative perspective to tracking-based, goal-oriented reflection and discuss implications for the design for reflection with a focus on the creative dimension of human well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {well-being, reflection, reflective forms, creativity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376534,
author = {Schr\"{o}der, Christoph and Al Zaidawi, Sahar Mahdie Klim and Prinzler, Martin H.U. and Maneth, Sebastian and Zachmann, Gabriel},
title = {Robustness of Eye Movement Biometrics Against Varying Stimuli and Varying Trajectory Length},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376534},
doi = {10.1145/3313831.3376534},
abstract = {Recent results suggest that biometric identification based on human's eye movement characteristics can be used for authentication. In this paper, we present three new methods and benchmark them against the state-of-the-art. The best of our new methods improves the state-of-the-art performance by 5.2 percentage points. Furthermore, we investigate some of the factors that affect the robustness of the recognition rate of different classifiers on gaze trajectories, such as the type of stimulus and the tracking trajectory length. We find that the state-of-the-art method only works well when using the same stimulus for testing that was used for training. By contrast, our novel method more than doubles the identification accuracy for these transfer cases. Furthermore, we find that with only 90 seconds of eye tracking data, 86.7% accuracy can be achieved.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {eye movement biometrics, gaze detection, eye tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376808,
author = {Zhang, Tianyi and El Ali, Abdallah and Wang, Chen and Hanjalic, Alan and Cesar, Pablo},
title = {RCEA: Real-Time, Continuous Emotion Annotation for Collecting Precise Mobile Video Ground Truth Labels},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376808},
doi = {10.1145/3313831.3376808},
abstract = {Collecting accurate and precise emotion ground truth labels for mobile video watching is essential for ensuring meaningful predictions. However, video-based emotion annotation techniques either rely on post-stimulus discrete self-reports, or allow real-time, continuous emotion annotations (RCEA) only for desktop settings. Following a user-centric approach, we designed an RCEA technique for mobile video watching, and validated its usability and reliability in a controlled, indoor (N=12) and later outdoor (N=20) study. Drawing on physiological measures, interaction logs, and subjective workload reports, we show that (1) RCEA is perceived to be usable for annotating emotions while mobile video watching, without increasing users' mental workload (2) the resulting time-variant annotations are comparable with intended emotion attributes of the video stimuli (classification error for valence: 8.3%; arousal: 25%). We contribute a validated annotation technique and associated annotation fusion method, that is suitable for collecting fine-grained emotion annotations while users watch mobile videos.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {labels, video, emotion, continuous, annotation, real-time, mobile},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376695,
author = {Peng, Zhenhui and Guo, Qingyu and Tsang, Ka Wing and Ma, Xiaojuan},
title = {Exploring the Effects of Technological Writing Assistance for Support Providers in Online Mental Health Community},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376695},
doi = {10.1145/3313831.3376695},
abstract = {Textual comments from peers with informational and emotional support are beneficial to members of online mental health communities (OMHCs). However, many comments are not of high quality in reality. Writing support technologies that assess (AS) the text or recommend (RE) writing examples on the fly could potentially help support providers to improve the quality of their comments. However, how providers perceive and work with such technologies are under-investigated. In this paper, we present a technological prototype MepsBot which offers providers in-situ writing assistance in either AS or RE mode. Results of a mixed-design study with 30 participants show that both types of MepsBots improve users' confidence in and satisfaction with their comments. The AS-mode MepsBot encourages users to refine expressions and is deemed easier to use, while the RE-mode one stimulates more support-related content re-editions. We report concerns on MepsBot and propose design considerations for writing support technologies in OMHCs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mental health, emotional support, online community, informational support, writing support tools},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376443,
author = {Lai, Chufan and Lin, Zhixian and Jiang, Ruike and Han, Yun and Liu, Can and Yuan, Xiaoru},
title = {Automatic Annotation Synchronizing with Textual Description for Visualization},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376443},
doi = {10.1145/3313831.3376443},
abstract = {In this paper, we propose a technique for automatically annotating visualizations according to the textual description. In our approach, visual elements in the target visualization, along with their visual properties, are identified and extracted with a Mask R-CNN model. Meanwhile, the description is parsed to generate visual search requests. Based on the identification results and search requests, each descriptive sentence is displayed beside the described focal areas as annotations. Different sentences are presented in various scenes of the generated animation to promote a vivid step-by-step presentation. With a user-customized style, the animation can guide the audience's attention via proper highlighting such as emphasizing specific features or isolating part of the data. We demonstrate the utility and usability of our method through a user study with use cases.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {machine learning, natural language interface, annotation, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376440,
author = {Abu-Salma, Ruba and Livshits, Benjamin},
title = {Evaluating the End-User Experience of Private Browsing Mode},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376440},
doi = {10.1145/3313831.3376440},
abstract = {In this paper, we investigate why users of private browsing mode misunderstand the benefits and limitations of private browsing. We design and conduct a three-part study: (1) an analytic evaluation of the user interface of private mode in different browsers; (2) a qualitative user study to explore user mental models of private browsing; (3) a participatory design study to investigate why existing browser disclosures, the in-browser explanations of private mode, do not communicate the actual protection of private mode. We find the user interface of private mode in different browsers violated well-established design guidelines and heuristics. Further, most participants had incorrect mental models of private browsing, influencing their understanding and usage of private mode. We also find existing browser disclosures did not explain the primary security goal of private mode. Drawing from the results of our study, we extract a set of recommendations to improve the design of disclosures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human-computer interaction, usable security and privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376880,
author = {Lin, Halden and Moritz, Dominik and Heer, Jeffrey},
title = {Dziban: Balancing Agency &amp; Automation in Visualization Design via Anchored Recommendations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376880},
doi = {10.1145/3313831.3376880},
abstract = {Visualization recommender systems attempt to automate design decisions spanning choices of selected data, transformations, and visual encodings. However, across invocations such recommenders may lack the context of prior results, producing unstable outputs that override earlier design choices. To better balance automated suggestions with user intent, we contribute Dziban, a visualization API that supports both ambiguous specification and a novel anchoring mechanism for conveying desired context. Dziban uses the Draco knowledge base to automatically complete partial specifications and suggest appropriate visualizations. In addition, it extends Draco with chart similarity logic, enabling recommendations that also remain perceptually similar to a provided "anchor" chart. Existing APIs for exploratory visualization, such as ggplot2 and Vega-Lite, require fully specified chart definitions. In contrast, Dziban provides a more concise and flexible authoring experience through automated design, while preserving predictability and control through anchored recommendations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visualization, anchoring, recommendation, language},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376353,
author = {Siu, Alexa F. and Sinclair, Mike and Kovacs, Robert and Ofek, Eyal and Holz, Christian and Cutrell, Edward},
title = {Virtual Reality Without Vision: A Haptic and Auditory White Cane to Navigate Complex Virtual Worlds},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376353},
doi = {10.1145/3313831.3376353},
abstract = {Current Virtual Reality (VR) technologies focus on rendering visuospatial effects, and thus are inaccessible for blind or low vision users. We examine the use of a novel white cane controller that enables navigation without vision of large virtual environments with complex architecture, such as winding paths and occluding walls and doors. The cane controller employs a lightweight three-axis brake mechanism to provide large-scale shape of virtual objects. The multiple degrees-of-freedom enables users to adapt the controller to their preferred techniques and grip. In addition, surface textures are rendered with a voice coil actuator based on contact vibrations; and spatialized audio is determined based on the progression of sound through the geometry around the user. We design a scavenger hunt game that demonstrates how our device enables blind users to navigate a complex virtual environment. Seven out of eight users were able to successfully navigate the virtual room (6x6m) to locate targets while avoiding collisions. We conclude with design consideration on creating immersive non-visual VR experiences based on user preferences for cane techniques, and cane material properties.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, white cane, haptic feedback, auditory feedback, blindness, mobility, 3d audio, visual impairments},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376359,
author = {Jo, Eunkyung and Toombs, Austin L. and Gray, Colin M. and Hong, Hwajung},
title = {Understanding Parenting Stress through Co-Designed Self-Trackers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376359},
doi = {10.1145/3313831.3376359},
abstract = {New parents often experience significant stress as they take on new roles and responsibilities. Stress management and mental wellbeing are two areas in which personal informatics (PI) research has gained attention, and there is an opportunity to investigate how parenting stress can be mitigated through PI practices. In this paper, we present the results of a co-designed technology probe study through which we deployed individualized self-trackers with new parents. We investigate the stress management topics new parents are interested in tracking and how — and with what goals---they engage in self-directed PI practices. Our findings indicate that PI practices can potentially enable parents to: re-discover positive aspects of their everyday lives; identify better-suited stress management strategies; and facilitate spousal communication about shared responsibilities. We discuss how self-tracking experiences for the mental wellness of parents can be better designed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personal informatics, co-design, stress management, parenting, self-tracking, new parents},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376460,
author = {Smith, Taliesin L. and Moore, Emily B.},
title = {Storytelling to Sensemaking: A Systematic Framework for Designing Auditory Description Display for Interactives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376460},
doi = {10.1145/3313831.3376460},
abstract = {Auditory description display is verbalized text typically used to describe live, recorded, or graphical displays to support access for people who are blind or visually impaired. Significant prior research has resulted in guidelines for auditory description for non-interactive or minimally interactive contexts. A lack of auditory description for complex interactive environments remains a tremendous barrier to access for people with visual impairments. In this work, we present a systematic design framework for designing auditory description within complex interactive environments. We illustrate how modular descriptions aligned with this framework can result in an interactive storytelling experience constructed through user interactions. This framework has been used in a set of published and widely used interactive science simulations, and in its generalized form could be applied to a variety of contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {non-visual access, auditory description display, description design, interactive information spaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376250,
author = {Kim, Seoyoung and Thakur, Arti and Kim, Juho},
title = {Understanding Users' Perception Towards Automated Personality Detection with Group-Specific Behavioral Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376250},
doi = {10.1145/3313831.3376250},
abstract = {Thanks to advanced sensing and logging technology, automatic personality assessment (APA) with users' behavioral data in the workplace is on the rise. While previous work has focused on building APA systems with high accuracy, little research has attempted to understand users' perception towards APA systems. To fill this gap, we take a mixed-methods approach: we (1) designed a survey (n=89) to understand users'social workplace behavior both online and offline and their privacy concerns; (2) built a research probe that detects personality from online and offline data streams with up to 81.3% accuracy, and deployed it for three weeks in Korea (n=32); and (3) conducted post-interviews (n=9). We identify privacy issues in sharing data and system-induced change in natural behavior as important design factors for APA systems. Our findings suggest that designers should consider the complex relationship between users' perception and system accuracy for a more user-centered APA design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {co-located group, privacy, automatic personality assessment (apa), tracking, behavior change, user perception},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376475,
author = {Lee, Kwangyoung and Cho, Hyewon and Toshnazarov, Kobiljon and Narziev, Nematjon and Rhim, So Young and Han, Kyungsik and Noh, YoungTae and Hong, Hwajung},
title = {Toward Future-Centric Personal Informatics: Expecting Stressful Events and Preparing Personalized Interventions in Stress Management},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376475},
doi = {10.1145/3313831.3376475},
abstract = {Stress is caused by a variety of events in our daily lives. By anticipating stressful situations, we can prepare and better cope with stressors when they actually occur. However, many past-centric personal informatics (PI) tools focus on capturing events that already happened and analyzing the data. In this work, we examine how anticipation — a future-centric self-tracking practice — could be used to manage daily stress levels. To address this, we built MindForecaster, a calendar- mediated stress anticipation application that allows users to expect stressful events in advance, generates activities to mitigate stress, and evaluates actual stress levels compared to previously estimated stress levels. In a 30-day deployment with 47 users, the users who explicitly planned and executed coping interventions reported reduced stress more than those who only expected stressful events. We suggest design implications for stress management by incorporating the properties of anticipation into current PI models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {stress, anticipation, coping planning, future-centric personal informatics, intervention, self-experimentation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376881,
author = {Stobert, Elizabeth and Barrera, David and Homier, Val\'{e}rie and Kollek, Daniel},
title = {Understanding Cybersecurity Practices in Emergency Departments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376881},
doi = {10.1145/3313831.3376881},
abstract = {Emergency departments (EDs) have unique operational requirements within hospitals. They have strong availability demands, are staffed by rotating personnel, and must provide services as quickly as possible. Modern EDs are also heavily computerized, and as such cybersecurity practices play a key role in meeting the expected operational standards. To better understand the cybersecurity challenges in EDs, we conducted a survey asking 347 ED personnel across Canada about their cybersecurity practices. The survey collected information relating to authentication and password management, use of personal devices for handling patient data, Internet connectivity on personal and hospital systems, and institutional security policies. Our results show that across multiple hospitals, deployed computer security systems fail to integrate with the requirements of staff and patients, leading to interruptions and inefficiencies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {hospitals, medicine, security, usability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376794,
author = {Shin, Joon Gi and Kim, Doheon and So, Chaehan and Saakes, Daniel},
title = {Body Follows Eye: Unobtrusive Posture Manipulation Through a Dynamic Content Position in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376794},
doi = {10.1145/3313831.3376794},
abstract = {While virtual objects are likely to be a part of future interfaces, we lack knowledge of how the dynamic position of virtual objects influences users' posture. In this study, we investigated users' posture change following the unobtrusive and swift motions of a content window in virtual reality (VR). In two perception studies, we estimated the perception threshold on undetectable slow motions and displacement during an eye blink. In a formative study, we compared users' performance, posture change as well as subjective responses on unobtrusive, swift, and no motions. Based on the result, we designed concept applications and explored potential design space of moving virtual content for unobtrusive posture change. With our study, we discuss the interfaces that control users and the initial design guidelines of unobtrusive posture manipulation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {posture change, unobtrusive interaction, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376626,
author = {von Willich, Julius and Schmitz, Martin and M\"{u}ller, Florian and Schmitt, Daniel and M\"{u}hlh\"{a}user, Max},
title = {Podoportation: Foot-Based Locomotion in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376626},
doi = {10.1145/3313831.3376626},
abstract = {Virtual Reality (VR) allows for infinitely large environments. However, the physical traversable space is always limited by real-world boundaries. This discrepancy between physical and virtual dimensions renders traditional locomotion methods used in real world unfeasible. To alleviate these limitations, research proposed various artificial locomotion concepts such as teleportation, treadmills, and redirected walking. However, these concepts occupy the user's hands, require complex hardware or large physical spaces. In this paper, we contribute nine VR locomotion concepts for foot-based locomotion, relying on the 3D position of the user's feet and the pressure applied to the sole as input modalities. We evaluate our concepts and compare them to state-of-the-art point &amp; teleport technique in a controlled experiment with 20 participants. The results confirm the viability of our approaches for foot-based and engaging locomotion. Further, based on the findings, we contribute a wireless hardware prototype implementation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {foot-based input, locomotion, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376394,
author = {Duchowski, Andrew T. and Krejtz, Krzysztof and Gehrer, Nina A. and Bafna, Tanya and B\ae{}kgaard, Per},
title = {The Low/High Index of Pupillary Activity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376394},
doi = {10.1145/3313831.3376394},
abstract = {A novel eye-tracked measure of pupil diameter oscillation is derived as an indicator of cognitive load. The new metric, termed the Low/High Index of Pupillary Activity (LHIPA), is able to discriminate cognitive load (vis-a-vis task difficulty) in several experiments where the Index of Pupillary Activity fails to do so. Rationale for the LHIPA is tied to the functioning of the human autonomic nervous system yielding a hybrid measure based on the ratio of Low/High frequencies of pupil oscillation. The paper's contribution is twofold. First, full documentation is provided for the calculation of the LHIPA. As with the IPA, it is possible for researchers to apply this metric to their own experiments where a measure of cognitive load is of interest. Second, robustness of the LHIPA is shown in analysis of three experiments, a restrictive fixed-gaze number counting task, a less restrictive fixed-gaze n-back task, and an applied eye-typing task.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {eye tracking, task difficulty, pupillometry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376750,
author = {Hirsch, Tad},
title = {Practicing Without a License: Design Research as Psychotherapy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376750},
doi = {10.1145/3313831.3376750},
abstract = {This paper considers the potential for participants to experience psychotherapeutic effects through their involvement in design research. Drawing on literature in human-computer interaction, psychotherapy, and feminist sociology, I argue that vulnerable participants may experience qualitative interviews therapeutically when they engage in reflexive activity about sensitive topics with researchers who employ psychotherapeutic techniques that encourage disclosure and reflection. I discuss ethical concerns and suggest the need for trauma-informed research practices, updated consent procedures, and revised pedagogy that better support researchers and participants engaged in emotionally charged encounters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {trauma-informed research, qualitative research, semi-structured interviewing, psychotherapy, design research, emotion work},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376405,
author = {Burova, Alisa and M\"{a}kel\"{a}, John and Hakulinen, Jaakko and Keskinen, Tuuli and Heinonen, Hanna and Siltanen, Sanni and Turunen, Markku},
title = {Utilizing VR and Gaze Tracking to Develop AR Solutions for Industrial Maintenance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376405},
doi = {10.1145/3313831.3376405},
abstract = {Augmented reality (AR) presents a variety of possibilities for industrial maintenance. However, the development of real-world AR solutions has been limited due to the technological capabilities and uncertainty with respect to safety at deployment. We introduce the approach of using AR simulation in virtual reality (VR) coupled with gaze tracking to enable resource-efficient AR development. We tested in-field AR guidance and safety awareness features in an iterative development-evaluation process with experts from the elevator maintenance industry. We further conducted a survey, utilizing actual gaze data from the evaluation to elicit comments from industry experts on the usefulness of AR simulation and gaze tracking. Our results show the potential of AR within VR approach combined with gaze tracking. With this framework, AR solutions can be iteratively and safely tested without actual implementation, while gaze data provide advanced objective means to evaluate the designed AR content, documentation usage, and safety awareness.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, industrial maintenance, gaze tracking, safety, virtual prototyping, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376228,
author = {Hsieh, Ching-Yu and Chiang, Yi-Shyuan and Chiu, Hung-Yu and Chang, Yung-Ju},
title = {Bridging the Virtual and Real Worlds: A Preliminary Study of Messaging Notifications in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376228},
doi = {10.1145/3313831.3376228},
abstract = {Virtual reality (VR) platforms provide their users with immersive virtual environments, but disconnect them from real-world events. The increasing length of VR sessions can therefore be expected to boost users' needs to obtain information about external occurrences such as message arrival. Yet, how and when to present these real-world notifications to users engaged in VR activities remains underexplored. We conducted an experiment to investigate individuals' receptivity during four VR activities (Loading, 360 Video, Treasure Hunt, Rhythm Game) to message notifications delivered using three types of displays (head-mounted, controller, and movable panel). While higher engagement generally led to higher perceptions that notifications were ill-timed and/or disruptive, the suitability of notification displays to VR activities was influenced by the time-sensitiveness of VR content, overlapping use of modalities for delivering alerts, the display locations, and a requirement that the display be moved for notifications to be seen. Specific design suggestions are also provided.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interruptibility, eye-tracking, virtual reality, notification systems, receptivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376480,
author = {Schneider, Adrian L. Jessup and Keiver, Kathy and Pritchard Orr, Alison and Reynolds, James N. and Golubovich, Neven and Graham, T.C. Nicholas},
title = {Toward the Design of Enjoyable Games for Children with Fetal Alcohol Spectrum Disorder},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376480},
doi = {10.1145/3313831.3376480},
abstract = {Fetal Alcohol Spectrum Disorder (FASD) is a heterogeneous and complex set of disorders caused by prenatal alcohol exposure, estimated to affect 2-5% of the North American population. Deficits associated with FASD affect social skill development and executive function, including emotional regulation and impulse control. These deficits can increase the difficulty of playing digital games. While considerable research has been performed in understanding how to design games for people with neurodevelopmental disorders in general, there is little data on how to design engaging games for children with FASD. We conducted a ten-week in-school gaming trial with eleven elementary-aged children with diagnosed or suspected FASD. Participants enjoyed playing together and responded well to the in-game reward system, while some game elements caused unexpected frustration. Based on our observations, we advise that games for FASD be designed to have low cost of failure, avoid retracting options, account for taking breaks when needed, show progression in rewards, and enable cooperative play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social play, game design, FASD, executive function, fetal alcohol spectrum disorder},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376128,
author = {Andres, Josh and schraefel, m.c. and Semertzidis, Nathan and Dwivedi, Brahmi and Kulwe, Yutika C. and von Kaenel, Juerg and Mueller, Florian Floyd},
title = {Introducing Peripheral Awareness as a Neurological State for Human-Computer Integration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376128},
doi = {10.1145/3313831.3376128},
abstract = {In this work we introduce peripheral awareness as a neurological state for real-time human-computer integration, where the human is assisted by a computer to interact with the world. Changes to the field of view in peripheral awareness have been linked with quality of human performance. This instinctive narrowing of vision that occurs as a threat is perceived has implications in activities that benefit from the user having a wide field of view, such as cycling to navigate the environment. We present "Ena", a novel EEG-eBike system that draws from the user's neural activity to determine when the user is in a state of peripheral awareness to regulate engine support. A study with 20 participants revealed various themes and tactics suggesting that peripheral awareness as a neurological state is viable to align human-machine integration with internal bodily processes. Ena suggests that our work facilitates a safe and enjoyable human-computer integration experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-system partnership, peripheral awareness, human-computer-integration, inbodied interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376600,
author = {Di Geronimo, Linda and Braz, Larissa and Fregnan, Enrico and Palomba, Fabio and Bacchelli, Alberto},
title = {UI Dark Patterns and Where to Find Them: A Study on Mobile Applications and User Perception},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376600},
doi = {10.1145/3313831.3376600},
abstract = {A Dark Pattern (DP) is an interface maliciously crafted to deceive users into performing actions they did not mean to do. In this work, we analyze Dark Patterns in 240 popular mobile apps and conduct an online experiment with 589 users on how they perceive Dark Patterns in such apps. The results of the analysis show that 95% of the analyzed apps contain one or more forms of Dark Patterns and, on average, popular applications include at least seven different types of deceiving interfaces. The online experiment shows that most users do not recognize Dark Patterns, but can perform better in recognizing malicious designs if informed on the issue. We discuss the impact of our work and what measures could be applied to alleviate the issue.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ethical design, user experiments, dark patterns},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376254,
author = {Jardine, Jacinta and Earley, Caroline and Richards, Derek and Timulak, Ladislav and Palacios, Jorge E. and Duffy, Daniel and Tierney, Karen and Doherty, Gavin},
title = {The Experience of Guided Online Therapy: A Longitudinal, Qualitative Analysis of Client Feedback in a Naturalistic RCT},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376254},
doi = {10.1145/3313831.3376254},
abstract = {Internet-delivered Cognitive Behavioural Therapy (iCBT) is an effective treatment for depression and anxiety disorders. However longitudinal qualitative research into the client's subjective experience of this form of treatment ?in the wild' is relatively scarce. We present an analysis of secondary outcomes in a naturalistic RCT conducted within the UK's Improving Access to Psychological Therapies programme. We evaluated clients' expectations, experience, and context of usage of iCBT, across three timepoints. Results are discussed in terms of the creation of a therapeutic space online, the impact of hope, expectations and personal factors on the therapeutic experience, iCBT as "therapy on the go" and developing skills for life. While iCBT on the whole provides a positive, supportive and therapeutic experience for clients, the study identified managing expectations, polarized preferences, momentary help-seeking and long-term support as important aspects of the experience to consider in future design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mental health, longitudinal study, icbt, user experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376816,
author = {Funk, Markus and Tobisch, Vanessa and Emfield, Adam},
title = {Non-Verbal Auditory Input for Controlling Binary, Discrete, and Continuous Input in Automotive User Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376816},
doi = {10.1145/3313831.3376816},
abstract = {Using auditory input while driving is becoming increasingly popular for making distraction-free inputs while driving. However, we argue that auditory input is more than just using speech. Thus, in this work, we explore using Non-Verbal Auditory Input (NVAI) for interacting with smart assistants while driving. Through an online study with 100 participants, we initially investigated users' input preferences for binary, discrete, and continuous data types. After identifying the top three modalities for NVAI, we subsequently conducted an in-person study with 16 participants. In our study, the participants tested these input modalities for three different input data types regarding their accuracy, driver-distraction, and social acceptability, while operating a driving simulator. The results reveal that, although clapping hands for making input was initially preferred in our online survey, it is snapping fingers for binary input and discrete input and humming for making continuous input that is the preferred NVAI modality while driving.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {voice-user interface, automotive user interfaces, speech input, non-verbal auditory interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376888,
author = {Wu, Qin and Yu, Chenmei and Chen, Yanjun and Yao, Jiayu and Wu, Xi and Peng, Xiaolan and Han, Teng},
title = {Squeeze the Ball: Designing an Interactive Playground towards Aiding Social Activities of Children with Low-Function Autism},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376888},
doi = {10.1145/3313831.3376888},
abstract = {Most intervention methods used for social skills training in children with autism are dedicated to high-functioning autism (HFA). However, extensive neurological and developmental disorders of low-functioning autism (LFA) have hampered their adoption. In this study, we observed and interviewed children with LFA, and their teachers, from a local educational institution, to better understand the children's social needs and barriers. Then, with the aim of aiding the children with their social activities, we illustrate the design process of SqueeBall, an interactive playground equipment. We evaluated the design with 18 children (16 with LFA and 2 with HFA) between 2.5 and 7 years of age. Results showed that these children had a pleasant game experience when the group bonded, and the equipment had a positive effect on aiding them in various ways. Finally, we discuss the challenges and opportunities of multimedia interaction techniques in aiding children with LFA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {low-function autism, social communication intervention, autism, disability, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376396,
author = {Kruzan, Kaylee Payne and Whitlock, Janis and Bazarova, Natalya N. and Miller, Katherine D. and Chapman, Julia and Won, Andrea Stevenson},
title = {Supporting Self-Injury Recovery: The Potential for Virtual Reality Intervention},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376396},
doi = {10.1145/3313831.3376396},
abstract = {In this paper, we explore the use of virtual reality (VR) in assisting individuals who self-injure. Past work on self-injury in HCI has focused almost exclusively on mobile applications and message boards. As VR systems become more common, it is worth exploring what unique affordances of the technology can be leveraged to support self-injury reduction and cessation. Research on VR intervention and self-injury treatment informed the design of three novel virtual reality experiences. Nineteen interviews were conducted with individuals with current, or a past history of, self-injury with the goals of uncovering overall impressions of the perceived efficacy of VR with this population, as well as better understanding key mechanisms which impact their experience. Our analysis reveals four key elements common across all experiences: transportation, embodiment, immersion/distraction, and sense of control, and additional themes within each unique experience. We discuss the implications of these findings for future intervention design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {self-injury, intervention, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376778,
author = {Lee, DoYoung and Lee, SooHwan and Oakley, Ian},
title = {Nailz: Sensing Hand Input with Touch Sensitive Nails},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376778},
doi = {10.1145/3313831.3376778},
abstract = {Touches between the fingers of an unencumbered hand represent a ready-to-use, eyes-free and expressive input space suitable for interacting with wearable devices such as smart glasses or watches. While prior work has focused on touches to the inner surface of the hand, touches to the nails, a practical site for mounting sensing hardware, have been comparatively overlooked. We extend prior implementations of single touch sensing nails to a full set of five and explore their potential for wearable input. We present design ideas and an input space of 144 touches (taps, flicks and swipes) derived from an ideation workshop. We complement this with data from two studies characterizing the subjective comfort and objective characteristics (task time, accuracy) of each touch. We conclude by synthesizing this material into a set of 29 viable nail touches, assessing their performance in a final study and illustrating how they could be used by presenting, and qualitatively evaluating, two example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wearable, eyes-free, touch sensing fingernail, finger input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376540,
author = {Zagermann, Johannes and Pfeil, Ulrike and von Bauer, Philipp and Fink, Daniel and Reiterer, Harald},
title = {"It's in My Other Hand!" – Studying the Interplay of Interaction Techniques and Multi-Tablet Activities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376540},
doi = {10.1145/3313831.3376540},
abstract = {Cross-device interaction with tablets is a popular topic in HCI research. Recent work has shown the benefits of including multiple devices into users' workflows while various interaction techniques allow transferring content across devices. However, users are only reluctantly using multiple devices in combination. At the same time, research on cross-device interaction struggles to find a frame of reference to compare techniques or systems. In this paper, we try to address these challenges by studying the interplay of interaction techniques, device utilization, and task-specific activities in a user study with 24 participants from different but complementary angles of evaluation using an abstract task, a sensemaking task, and three interaction techniques. We found that different interaction techniques have a lower influence than expected, that work behaviors and device utilization depend on the task at hand, and that participants value specific aspects of cross-device interaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interaction techniques, evaluation, cross-device interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376199,
author = {Klamka, Konstantin and Horak, Tom and Dachselt, Raimund},
title = {Watch+Strap: Extending Smartwatches with Interactive StrapDisplays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376199},
doi = {10.1145/3313831.3376199},
abstract = {While smartwatches are widely adopted these days, their input and output space remains fairly limited by their screen size. We present StrapDisplays-interactive watchbands with embedded display and touch technologies-that enhance commodity watches and extend their input and output capabilities. After introducing the physical design space of these StrapDisplays, we explore how to combine a smartwatch and straps in a synergistic Watch+Strap system. Specifically, we propose multiple interface concepts that consider promising content distributions, interaction techniques, usage types, and display roles. For example, the straps can enrich watch apps, display visualizations, provide glanceable feedback, or help avoiding occlusion issues. Further, we provide a modular research platform incorporating three StrapDisplay prototypes and a flexible web-based software architecture, demonstrating the feasibility of our approach. Early brainstorming sessions with 15 participants informed our design process, while later interviews with six experts supported our concepts and provided valuable feedback for future developments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mobile visualization, wearable device, mde, flexible displays, smartwatch, mobile interaction, interactive watchband},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376358,
author = {Yoshida, Shigeo and Sun, Yuqian and Kuzuoka, Hideaki},
title = {PoCoPo: Handheld Pin-Based Shape Display for Haptic Rendering in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376358},
doi = {10.1145/3313831.3376358},
abstract = {We introduce PoCoPo, the first handheld pin-based shape display that can render various 2.5D shapes in hand in realtime. We designed the display small enough for a user to hold it in hand and carry it around, thereby enhancing the haptic experiences in a virtual environment. PoCoPo has 18 motor-driven pins on both sides of a cuboid, providing the sensation of skin contact on the user's palm and fingers. We conducted two user studies to understand the capability of PoCoPo. The first study showed that the participants were generally successful in distinguishing the shapes rendered by PoCoPo with an average success rate of 88.5%. In the second study, we investigated the acceptable visual size of a virtual object when PoCoPo rendered a physical object of a certain size. The result led to a better understanding of the acceptable differences between the perceptions of visual size and haptic size.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {shape display, virtual reality, handheld device, haptic device},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376330,
author = {Nebeling, Michael and Speicher, Maximilian and Wang, Xizi and Rajaram, Shwetha and Hall, Brian D. and Xie, Zijian and Raistrick, Alexander R. E. and Aebersold, Michelle and Happ, Edward G. and Wang, Jiayin and Sun, Yanan and Zhang, Lotus and Ramsier, Leah E. and Kulkarni, Rhea},
title = {MRAT: The Mixed Reality Analytics Toolkit},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376330},
doi = {10.1145/3313831.3376330},
abstract = {Significant tool support exists for the development of mixed reality (MR) applications; however, there is a lack of tools for analyzing MR experiences. We elicit requirements for future tools through interviews with 8 university research, instructional, and media teams using AR/VR in a variety of domains. While we find a common need for capturing how users perform tasks in MR, the primary differences were in terms of heuristics and metrics relevant to each project. Particularly in the early project stages, teams were uncertain about what data should, and even could, be collected with MR technologies. We designed the Mixed Reality Analytics Toolkit (MRAT) to instrument MR apps via visual editors without programming and enable rapid data collection and filtering for visualizations of MR user sessions. With MRAT, we contribute flexible interaction tracking and task definition concepts, an extensible set of heuristic techniques and metrics to measure task success, and visual inspection tools with in-situ visualizations in MR. Focusing on a multi-user, cross-device MR crisis simulation and triage training app as a case study, we then show the benefits of using MRAT, not only for user testing of MR apps, but also performance tuning throughout the design process.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user testing, augmented/virtual reality, interaction tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376259,
author = {Dogar, Fahad R. and Qazi, Ihsan Ayyub and Tariq, Ali Raza and Murtaza, Ghulam and Ahmad, Abeer and Stocking, Nathan},
title = {MissIt: Using Missed Calls for Free, Extremely Low Bit-Rate Communication in Developing Regions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376259},
doi = {10.1145/3313831.3376259},
abstract = {Mobile devices have become the primary mode for Internet access in developing countries. Yet typical data plans and SMS costs can be overwhelming for low income users in these countries. In this paper, we explore the design and usability of a free but extremely low bit rate communication channel to address this challenge. We propose, a data communication channel that uses to transmit messages between phones, thereby sacrificing performance in exchange for low cost. While the data rate of is extremely low (&lt;1 bps), our prototype implementation and small scale user studies explore the feasibility of this idea for different types of messaging scenarios. Our results show that could be a viable option for messaging scenarios that require short, pre-determined responses (e.g., survey questions) while for traditional SMS-style messaging, a suitable user interface and other customizations are likely required to make it a viable option for users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {networks, missed-calls, ictd},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376541,
author = {Wells, Thomas and Houben, Steven},
title = {CollabAR – Investigating the Mediating Role of Mobile AR Interfaces on Co-Located Group Collaboration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376541},
doi = {10.1145/3313831.3376541},
abstract = {Mobile Augmented Reality (AR) technology is enabling new applications for different domains including architecture, education or medical work. As AR interfaces project digital data, information and models into the real world, it allows for new forms of collaborative work. However, despite the wide availability of AR applications, very little is known about how AR interfaces mediate and shape collaborative practices. This paper presents a study which examines how a mobile AR (M-AR) interface for inspecting and discovering AR models of varying complexity impacts co-located group practices. We contribute new insights into how current mobile AR interfaces impact co-located collaboration. Our results show that M-AR interfaces induce high mental load and frustration, cause a high number of context switches between devices and group discussion, and overall leads to a reduction in group interaction. We present design recommendations for future work focusing on collaborative AR interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {co-located collaboration, mobile augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376446,
author = {Frommel, Julian and Sagl, Valentin and Depping, Ansgar E. and Johanson, Colby and Miller, Matthew K. and Mandryk, Regan L.},
title = {Recognizing Affiliation: Using Behavioural Traces to Predict the Quality of Social Interactions in Online Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376446},
doi = {10.1145/3313831.3376446},
abstract = {Online social interactions in multiplayer games can be supportive and positive or toxic and harmful; however, few methods can easily assess interpersonal interaction quality in games. We use behavioural traces to predict affiliation between dyadic strangers, facilitated through their social interactions in an online gaming setting. We collected audio, video, in-game, and self-report data from 23 dyads, extracted 75 features, trained Random Forest and Support Vector Machine models, and evaluated their performance predicting binary (high/low) as well as continuous affiliation toward a partner. The models can predict both binary and continuous affiliation with up to 79.1% accuracy (F1) and 20.1% explained variance (R2) on unseen data, with features based on verbal communication demonstrating the highest potential. Our findings can inform the design of multiplayer games and game communities, and guide the development of systems for matchmaking and mitigating toxic behaviour in online games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {affiliation, bonding, cooperative games, evaluation, social interaction, prediction, machine learning, recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376836,
author = {Xu, Xuhai and Shi, Haitian and Yi, Xin and Liu, WenJia and Yan, Yukang and Shi, Yuanchun and Mariakakis, Alex and Mankoff, Jennifer and Dey, Anind K.},
title = {EarBuddy: Enabling On-Face Interaction via Wireless Earbuds},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376836},
doi = {10.1145/3313831.3376836},
abstract = {Past research regarding on-body interaction typically requires custom sensors, limiting their scalability and generalizability. We propose EarBuddy, a real-time system that leverages the microphone in commercial wireless earbuds to detect tapping and sliding gestures near the face and ears. We develop a design space to generate 27 valid gestures and conducted a user study (N=16) to select the eight gestures that were optimal for both human preference and microphone detectability. We collected a dataset on those eight gestures (N=20) and trained deep learning models for gesture detection and classification. Our optimized classifier achieved an accuracy of 95.3%. Finally, we conducted a user study (N=12) to evaluate EarBuddy's usability. Our results show that EarBuddy can facilitate novel interaction and that users feel very positively about the system. EarBuddy provides a new eyes-free, socially acceptable input method that is compatible with commercial wireless earbuds and has the potential for scalability and generalizability},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {gesture recognition, wireless earbuds, face and ear interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376458,
author = {Tachtler, Franziska and Michel, Toni and Slov\'{a}k, Petr and Fitzpatrick, Geraldine},
title = {Supporting the Supporters of Unaccompanied Migrant Youth: Designing for Social-Ecological Resilience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376458},
doi = {10.1145/3313831.3376458},
abstract = {Unaccompanied migrant youth, fleeing to a new country without their parents, are exposed to mental health risks. Resilience interventions mitigate such risks, but access can be hindered by systemic and personal barriers. While much work has recently addressed designing technology to promote mental health, none has focused on the needs of these populations. This paper presents the results of interviews with 18 professional/ volunteer support workers and 5 unaccompanied migrant youths, followed by three design workshops. The results point to the diverse systems that can facilitate youths' resilience development. The relationship between the youth and volunteers acting as mentors is particularly important for increasing resilience but comes with challenges. This suggests the relevance of a social-ecological model of resilience with a focus on designing technology to support the mentors in order to help them better support the youth. We conclude by mapping out the design space for mentor support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mental health technology, care, refugees, resilience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376709,
author = {Saint-Lot, Julie and Imbert, Jean-Paul and Dehais, Fr\'{e}d\'{e}ric},
title = {Red Alert: A Cognitive Countermeasure to Mitigate Attentional Tunneling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376709},
doi = {10.1145/3313831.3376709},
abstract = {Attentional tunneling, that is the inability to detect unexpected changes in the environment, has been shown to have critical consequences in air traffic control. The motivation of this study was to assess the design of a cognitive countermeasure dedicated to mitigate such failure of attention. The Red Alert cognitive countermeasure relies on a brief orange-red flash (300 ms) that masks the entire screen with a 15% opacity. Twenty-two air traffic controllers faced two demanding scenarios, with or without the cognitive countermeasure. The volunteers were not told about the Red Alert so as to assess the intuitiveness of the design without prior knowledge. Behavioral results indicated that the cognitive countermeasure reduced reaction time and improved the detection of the notification when compared to the classical operational design. Further analyses showed this effect was even stronger for half of our participants (91.7% detection rate) who intuitively understood the purpose of this design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {countermeasure, interruption, air traffic controller (atco), air traffic control, attentional tunneling, notification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376591,
author = {Lee, Sooyeon and Reddie, Madison and Tsai, Chun-Hua and Beck, Jordan and Rosson, Mary Beth and Carroll, John M.},
title = {The Emerging Professional Practice of Remote Sighted Assistance for People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376591},
doi = {10.1145/3313831.3376591},
abstract = {People with visual impairments (PVI) must interact with a world they cannot see. Remote sighted assistance (RSA) has emerged as a conversational assistive technology. We interviewed RSA assistants ("agents") who provide assistance to PVI via a conversational prosthetic called Aira (https://aira.io/) to understand their professional practice. We identified four types of support provided: scene description, navigation, task performance, and social engagement. We discovered that RSA provides an opportunity for PVI to appropriate the system as a richer conversational/social support tool. We studied and identified patterns in how agents provide assistance and how they interact with PVI as well as the challenges and strategies associated with each context. We found that conversational interaction is highly context-dependent. We also discuss implications for design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {remote sighted assistance, visual impairment, human powered accessibility, assistive technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376677,
author = {Oppenlaender, Jonas and Milland, Kristy and Visuri, Aku and Ipeirotis, Panos and Hosio, Simo},
title = {Creativity on Paid Crowdsourcing Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376677},
doi = {10.1145/3313831.3376677},
abstract = {Crowdsourcing platforms are increasingly being harnessed for creative work. The platforms' potential for creative work is clearly identified, but the workers' perspectives on such work have not been extensively documented. In this paper, we uncover what the workers have to say about creative work on paid crowdsourcing platforms. Through a quantitative and qualitative analysis of a questionnaire launched on two different crowdsourcing platforms, our results revealed clear differences between the workers on the platforms in both preferences and prior experience with creative work. We identify common pitfalls with creative work on crowdsourcing platforms, provide recommendations for requesters of creative work, and discuss the meaning of our findings within the broader scope of creativity-oriented research. To the best of our knowledge, we contribute the first extensive worker-oriented study of creative work on paid crowdsourcing platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {creativity, creativity support tools, creative tasks, creativity tests, creative work, crowdsourcing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376876,
author = {Wolf, Dennis and Gugenheimer, Jan and Combosch, Marco and Rukzio, Enrico},
title = {Understanding the Heisenberg Effect of Spatial Interaction: A Selection Induced Error for Spatially Tracked Input Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376876},
doi = {10.1145/3313831.3376876},
abstract = {Virtual and augmented reality head-mounted displays (HMDs) are currently heavily relying on spatially tracked input devices (STID) for interaction. These STIDs are all prone to the phenomenon that a discrete input (e.g. button press) will disturb the position of the tracker, resulting in a different selection point during ray-cast interaction (Heisenberg Effect of Spatial Interaction). Besides the knowledge of its existence, there is currently a lack of a deeper understanding of its severity, structure and impact on throughput and angular error during a selection task. In this work, we present a formal evaluation of the Heisenberg effect and the impact of body posture, arm position and STID degrees of freedom on its severity. In a Fitt's Law inspired user study (N=16), we found that the Heisenberg effect is responsible for 30.45% of the overall errors occurring during a pointing task, but can be reduced by 25.4% using a correction function.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {offset, vr, heisenberg effect, pointing, stid, correction, selection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376198,
author = {Yeo, Hui-Shyong and Feng, Wenxin and Huang, Michael Xuelin},
title = {WATouCH: Enabling Direct Input on Non-Touchscreen Using Smartwatch's Photoplethysmogram and IMU Sensor Fusion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376198},
doi = {10.1145/3313831.3376198},
abstract = {Interacting with non-touchscreens such as TV or public displays can be difficult and inefficient. We propose WATouCH, a novel method that localizes a smartwatch on a display and allows direct input by turning the smartwatch into a tangible controller. This low-cost solution leverages sensor fusion of the built-in inertial measurement unit (IMU) and photoplethysmogram (PPG) sensor on a smartwatch that is used for heart rate monitoring. Specifically, WATouCH tracks the smartwatch movement using IMU data and corrects its location error caused by drift using the PPG responses to a dynamic visual pattern on the display. We conducted a user study on two tasks -- a point and click and line tracing task -- to evaluate the system usability and user performance. Evaluation results suggested that our sensor fusion mechanism effectively confined IMU-based localization error, achieved encouraging targeting and tracing precision, was well received by the participants, and thus opens up new opportunities for interaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {direct input, tangible input, smartwatch, public display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376563,
author = {Alonzo, Oliver and Seita, Matthew and Glasser, Abraham and Huenerfauth, Matt},
title = {Automatic Text Simplification Tools for Deaf and Hard of Hearing Adults: Benefits of Lexical Simplification and Providing Users with Autonomy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376563},
doi = {10.1145/3313831.3376563},
abstract = {Automatic Text Simplification (ATS), which replaces text with simpler equivalents, is rapidly improving. While some research has examined ATS reading-assistance tools, little has examined preferences of adults who are deaf or hard-of-hearing (DHH), and none empirically evaluated lexical simplification technology (replacement of individual words) with these users. Prior research has revealed that U.S. DHH adults have lower reading literacy on average than their hearing peers, with unique characteristics to their literacy profile. We investigate whether DHH adults perceive a benefit from lexical simplification applied automatically or when users are provided with greater autonomy, with on-demand control and visibility as to which words are replaced. Formative interviews guided the design of an experimental study, in which DHH participants read English texts in their original form and with lexical simplification applied automatically or on-demand. Participants indicated that they perceived a benefit form lexical simplification, and they preferred a system with on-demand simplification.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {lexical simplification, reading assistance, autonomy, people who are deaf or hard of hearing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376810,
author = {Yan, Yukang and Yu, Chun and Zheng, Wengrui and Tang, Ruining and Xu, Xuhai and Shi, Yuanchun},
title = {FrownOnError: Interrupting Responses from Smart Speakers by Facial Expressions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376810},
doi = {10.1145/3313831.3376810},
abstract = {In the conversations with smart speakers, misunderstandings of users' requests lead to erroneous responses. We propose FrownOnError, a novel interaction technique that enables users to interrupt the responses by intentional but natural facial expressions. This method leverages the human nature that the facial expression changes when we receive unexpected responses. We conducted a first user study (N=12) to understand users' intuitive reactions to the correct and incorrect responses. Our results reveal the significant difference in the frequency of occurrence and intensity of users' facial expressions between two conditions, and frowning and raising eyebrows are intuitive to perform and easy to control. Our second user study (N=16) evaluated the user experience and interruption efficiency of FrownOnError and the third user study (N=12) explored suitable conversation recovery strategies after the interruptions. Our results show that FrownOnError can be accurately detected (precision: 97.4%, recall: 97.6%), provides the most timely interruption compared to the baseline methods of wake-up word and button press, and is rated as most intuitive and easiest to be performed by users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {facial expression, voice user interface, conversation interruption},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376713,
author = {Dema, Tshering and Brereton, Margot and Esteban, Michael and Soro, Alessandro and Sherub, Sherub and Roe, Paul},
title = {Designing in the Network of Relations for Species Conservation: The Playful Tingtibi Community Birdhouse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376713},
doi = {10.1145/3313831.3376713},
abstract = {This paper investigates connecting people in remote communities through nature in order to foster stewardship and conservation of endangered species. Global citizen science technologies have found success in urban, developed countries, but they typically rely on large distributed populations to gather or analyze data and do not suit sparsely populated and remote contexts. We undertook a long-term field study to iteratively co-design a tangible and playful nature engagement prototype in a remote World Heritage Area community. The prototype design fosters learning through ambient sounds as well as exploration and discovery of species through nature soundscape recordings. We found that the prototypes amplified locals' interest, became embedded in community relations and gradually led to placemaking of new engagement 'spaces' and of newer forms. We contribute lessons learned on how design can foster nature engagement and stewardship of endangered species by heeding Suchman's call for design to "enter networks of relations that make technology possible". We contribute design implications and new design foci HCI/Citizen science engagement for species conservation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {endangered species stewardship, wilderness soundscapes, citizen science interfaces, nature engagement, social and playful, network of relations, tingtibi birdhouse},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376505,
author = {Huang, Kai-Chieh and Sun, Chen-Kuo and Huang, Da-Yuan and Chen, Yu-Chun and Chang, Ruei-Che and Hsu, Shuo-wen and Yang, Chih-Yun and Chen, Bing-Yu},
title = {Glissade: Generating Balance Shifting Feedback to Facilitate Auxiliary Digital Pen Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376505},
doi = {10.1145/3313831.3376505},
abstract = {This paper introduces Glissade, a digital pen that generates balance shifting feedback by changing the weight distribution of the pen. A pulley system shifts a brass mass inside the pen to change the pen's center of mass and moment of inertia. When the mass is stationary, the pen delivers a constant yet natural sensation of weight, which can be used to convey a status. The pen can also generate a variety of haptic clues by actuating the mass according to the tilt or rotation of the pen, two commonly-used auxiliary pen input channels. Glissade demonstrates new possibilities that balance shifting feedback can bring to digital pen interactions. We validated the usability of this feedback by determining the recognizability of six balance patterns – a mix of static and dynamic patterns chosen based on our design considerations – in two controlled experiments. The results show that, on average, the participants could distinguish between the patterns with a 94.25% accuracy. At the end, we demonstrate a set of novel interactions enabled by Glissade and discuss the directions for future research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {balance shifting feedback, haptics, sensation of weight, digital pen},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376546,
author = {Kuzminykh, Anastasia and Rintel, Sean},
title = {Classification of Functional Attention in Video Meetings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376546},
doi = {10.1145/3313831.3376546},
abstract = {Participants in video meetings have long struggled with asymmetrical attention levels, especially when participants are distributed unevenly. While technological advances offer exciting opportunities to augment remote users' attention, the phenomenological complexity of attention means that to design attention-fostering features we must first understand what aspects of it are functionally meaningful to support. In this paper, we present a functional classification of observable attention for video meetings. The classification was informed by two studies on sense-making and selectiveness of attention in work meetings. It includes categories of attention accessible for technological support, their functions in a meeting process, and meeting-related activities that correspond to these functions. This classification serves as a multi-level representation of attention and informs the design of features aiming to support remote participants' attention in video meetings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {features, meetings, video-mediated communication, attention, engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376327,
author = {Lee, Chunggi and Kim, Sanghoon and Han, Dongyun and Yang, Hongjun and Park, Young-Woo and Kwon, Bum Chul and Ko, Sungahn},
title = {GUIComp: A GUI Design Assistant with Real-Time, Multi-Faceted Feedback},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376327},
doi = {10.1145/3313831.3376327},
abstract = {Users may face challenges while designing graphical user interfaces, due to a lack of relevant experience and guidance. This paper aims to investigate the issues users face during the design process, and how to resolve them. To this end, we conducted semi-structured interviews, based on which we built a GUI prototyping assistance tool called GUIComp. This tool can be connected to GUI design software as an extension, and it provides real-time, multi-faceted feedback on a user's current design. Additionally, we conducted two user studies, in which we asked participants to create mobile GUIs with or without GUIComp, and requested online workers to assess the created GUIs. The experimental results show that GUIComp facilitated iterative designs and the participants with GUIComp had better a user experience and produced more acceptable designs than those who did not use it.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design feedback, gui design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376738,
author = {Agarwal, Mohit and Sivakumar, Raghupathy},
title = {Charge for a Whole Day: Extending Battery Life for BCI Wearables Using a Lightweight Wake-Up Command},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376738},
doi = {10.1145/3313831.3376738},
abstract = {Commercially available EEG-based Brain-Computer Interface (BCI) wearable headsets are always-on and are thus power hungry, requiring users to charge the headsets multiple times a day. In this paper, we tackle the problem of wake-up command design and detection for BCI headsets, and explore how battery life can be made to last for approximately a whole day. The key challenge that we address is enabling the headset to operate in a near-sleep mode but still reliably detect and interpret an EEG-based wake-up command from the user. Towards addressing the challenge, we present a solution that is built upon eye-blinks. Our core contribution is Trance, a user-friendly and robust wake-up command for BCI headsets that is computationally lightweight. We show using experimental results coupled with multiple data sets collected through user-studies that Trance can extend battery life by approximately 2.7x or to approximately 10 hours for a typical wearable battery, while remaining user-friendly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {eye tracking, wearable systems, interaction design, input techniques, brain-computer interfaces (bcis)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376284,
author = {Abdulgalimov, Dinislam and Kirkham, Reuben and Nicholson, James and Vlachokyriakos, Vasilis and Briggs, Pam and Olivier, Patrick},
title = {Designing for Employee Voice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376284},
doi = {10.1145/3313831.3376284},
abstract = {Employee voice and workplace democracy have a positive impact on employee wellbeing and the performance of organizations. In this paper, we conducted interviews with employees to identify facilitators and inhibitors for voice within the workplace and a corresponding set of appropriate qualities: Civility, Validity, Safety and Egalitarianism. We then operationalised these qualities as a set of design goals - Assured Anonymity, Constructive Moderation, Adequate Slowness and Controlled Access - in the design and development of a secure anonymous employee voice system. Our novel take on the Enterprise Social Network aims to foster good citizenship whilst also promoting frank yet constructive discussion. We reflect on a two-week deployment of our system, the diverse range of candid discussions that emerged around important workplace issues and the potential for change within the host organization. We conclude by reflecting on the ways in which our approach shaped discourse and supported the creation of a trusted environment for employee voice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {employee voice, workplace, cscw, enterprise social networks, anonymous online communities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376637,
author = {Nebeling, Michael and Lewis, Katy and Chang, Yu-Cheng and Zhu, Lihan and Chung, Michelle and Wang, Piaoyang and Nebeling, Janet},
title = {XRDirector: A Role-Based Collaborative Immersive Authoring System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376637},
doi = {10.1145/3313831.3376637},
abstract = {Immersive authoring is an increasingly popular technique to design AR/VR scenes because design and testing can be done concurrently. Most existing systems, however, are single-user and limited to either AR or VR, thus constrained in the interaction techniques. We present XRDirector, a role-based collaborative immersive authoring system that enables designers to freely express interactions using AR and VR devices as puppets to manipulate virtual objects in 3D physical space. In XRDirector, we adapt roles known from filmmaking to structure the authoring process and help coordinate multiple designers in immersive authoring tasks. We study how novice AR/VR creators can take advantage of the roles and modes in XRDirector to prototype complex scenes with animated 3D characters, light effects, and camera movements, and also simulate interactive system behavior in a Wizard of Oz style. XRDirector's design was informed by case studies around complex 3D movie scenes and AR/VR games, as well as workshops with novice AR/VR creators. We show that XRDirector makes it easier and faster to create AR/VR scenes without the need for coding, characterize the issues in coordinating designers between AR and VR, and identify the strengths and weaknesses of each role and mode to mitigate the issues.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ar/vr, mixed-reality collaboration, immersive authoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376507,
author = {D\"{o}rrenb\"{a}cher, Judith and L\"{o}ffler, Diana and Hassenzahl, Marc},
title = {Becoming a Robot - Overcoming Anthropomorphism with Techno-Mimesis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376507},
doi = {10.1145/3313831.3376507},
abstract = {Employing anthropomorphism in physical appearance and behavior is the most widespread strategy for designing social robots. In the present paper, we argue that imitating humans impedes the full exploration of robots' social abilities. In fact, their very 'thingness' (e.g., sensors, rationality) is able to create 'superpowers' that go beyond human abilities, such as endless patience. To better identify these special abilities, we develop a performative method called 'Techno-Mimesis' and explore it in a series of workshops with robot designers. Specifically, we create 'prostheses' to allow designers to transform themselves into their future robot to experience use cases from the robot's perspective, e.g., 'seeing' with a distance sensor rather than with eyes. This imperfect imitation helps designers to experience being human and being robot at the same time, making differences apparent and facilitating the discovery of a number of potential physical, cognitive, and communicational robotic superpowers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {anthropomorphism, service robots, social robots, new animism, performative design method},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376774,
author = {Feltwell, Tom and Wood, Gavin and Brooker, Phillip and Rowland, Scarlett and Baumer, Eric P. S. and Long, Kiel and Vines, John and Barnett, Julie and Lawson, Shaun},
title = {Broadening Exposure to Socio-Political Opinions via a Pushy Smart Home Device},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376774},
doi = {10.1145/3313831.3376774},
abstract = {Motivated by the effects of the filter bubble and echo chamber phenomena on social media, we developed a smart home device, Spkr, that unpredictably "pushes" socio-political discussion topics into the home. The device utilised trending Twitter discussions, categorised by their socio-political alignment, to present people with a purposefully assorted range of viewpoints. We deployed Spkr in 10 homes for 28 days with a diverse range of participants and interviewed them about their experiences. Our results show that Spkr presents a novel means of combating selective exposure to socio-political issues, providing participants with identifiably diverse viewpoints. Moreover, Spkr acted as a conversational prompt for discussion within the home, initiating collective processes and engaging those who would not often be involved in political discussions. We demonstrate how smart home assistants can be used as a catalyst for provocation by altering and pluralising political discussions within households.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {filter bubble, pushy device, viewpoint diversity, smart home technology, echo chamber, Nolan chart, selective exposure, socio-political discussion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376777,
author = {Hoffswell, Jane and Li, Wilmot and Liu, Zhicheng},
title = {Techniques for Flexible Responsive Visualization Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376777},
doi = {10.1145/3313831.3376777},
abstract = {Responsive visualizations adapt to effectively present information based on the device context. Such adaptations are essential for news content that is increasingly consumed on mobile devices. However, existing tools provide little support for responsive visualization design. We analyze a corpus of 231 responsive news visualizations and discuss formative interviews with five journalists about responsive visualization design. These interviews motivate four central design guidelines: enable simultaneous cross-device edits, facilitate device-specific customization, show cross-device previews, and support propagation of edits. Based on these guidelines, we present a prototype system that allows users to preview and edit multiple visualization versions simultaneously. We demonstrate the utility of the system features by recreating four real-world responsive visualizations from our corpus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {responsive design, visualization, news, mobile devices},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376595,
author = {Huang, Xiaoyun and Vitak, Jessica and Tausczik, Yla},
title = {"You Don't Have To Know My Past": How WeChat Moments Users Manage Their Evolving Self-Presentation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376595},
doi = {10.1145/3313831.3376595},
abstract = {Most social media platforms record, display, and archive users' personal histories. This persistence of posts over time can be problematic, as users' self-presentation goals and network composition change, but old content remains. In this paper, we explore an alternative feature that provides control over content persistence. We present findings from interviews with 16 users of the popular Chinese social media platform WeChat Moments. We focused on Moments' Time Limit setting, which makes social media data ephemeral to audiences, but persistent to posters. Interviewees described changes in their self-presentation goals and social network composition over time and reported the Time Limit feature helped them effortlessly manage their desired self-presentation as they matured. Drawing on these findings, we discuss design implications for social media to facilitate greater control over content visibility and persistence, which may have significant benefits for social media users with large and diverse networks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {self-presentation, wechat moments, ephemerality, persistence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376860,
author = {Jahanbakhsh, Farnaz and Cranshaw, Justin and Counts, Scott and Lasecki, Walter S. and Inkpen, Kori},
title = {An Experimental Study of Bias in Platform Worker Ratings: The Role of Performance Quality and Gender},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376860},
doi = {10.1145/3313831.3376860},
abstract = {We study how the ratings people receive on online labor platforms are influenced by their performance, gender, their rater's gender, and displayed ratings from other raters. We conducted a deception study in which participants collaborated on a task with a pair of simulated workers, who varied in gender and performance level, and then rated their performance. When the performance of paired workers was similar, low-performing females were rated lower than their male counterparts. Where there was a clear performance difference between paired workers, low-performing females were preferred over a similarly-performing male peer. Furthermore, displaying an average rating from other raters made ratings more extreme, resulting in high performing workers receiving significantly higher ratings and low performers lower ratings compared to when average ratings were absent. This work contributes an empirical understanding of when biases in ratings manifest, and offers recommendations for how online work platforms can counter these biases.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {bias in ratings, social mimicry, digital ratings, bias in gig platforms, gender discrimination},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376473,
author = {Wang, Yihong and Papangelis, Konstantinos and Saker, Michael and Lykourentzou, Ioanna and Chamberlain, Alan and Khan, Vassilis-Javed},
title = {Crowdsourcing in China: Exploring the Work Experiences of Solo Crowdworkers and Crowdfarm Workers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376473},
doi = {10.1145/3313831.3376473},
abstract = {Recent research highlights the potential of crowdsourcing in China. Yet very few studies explore the workplace context and experiences of Chinese crowdworkers. Those that do, focus mainly on the work experiences of solo crowdworkers but do not deal with issues pertaining to the substantial amount of people working in 'crowdfarms'. This article addresses this gap as one of its primary concerns. Drawing on a study that involves 48 participants, our research explores, compares and contrasts the work experiences of solo crowdworkers to those of crowdfarm workers. Our findings illustrate that the work experiences and context of the solo workers and crowdfarm workers are substantially different, with regards to their motivations, the ways they engage with crowdsourcing, the tasks they work on, and the crowdsourcing platforms they utilize. Overall, our study contributes to furthering the understandings on the work experiences of crowdworkers in China.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {platform satisfaction, reputation management, tasks, crowdfarms, crowdsourcing, crowdworkers, work experience, work life balance, motivations and attitudes},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376858,
author = {Kleinberger, R\'{e}becca and Harrington, Anne H. K. and Yu, Lydia and van Troyer, Akito and Su, David and Baker, Janet M. and Miller, Gabriel},
title = {Interspecies Interactions Mediated by Technology: An Avian Case Study at the Zoo},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376858},
doi = {10.1145/3313831.3376858},
abstract = {Enrichment is a methodology for caregivers to offer zoo animals improved psychological and physiological well-being. Although many species rely on auditory senses, sonic enrichment is rarely implemented. Zoo soundscapes are dominated by human-generated noises and do not respond meaningfully to animals' behavior. Designing interactive sonic enrichment systems for animals presents unique ergonomic, ethical, and agency-related challenges. We present a case study of such design. We deployed two novel interventions at the San Diego Zoo to allow Sampson, a music-savvy hyacinth macaw, to gain control over his sonic environment. Our results suggest that (1) the bird uses, understands, and benefits from the system, and (2) visitors play a major role in Sampson's engagement with this technology. With his new agency, the bird seemingly gains more control over his interactions with the public, creating an interspecies experience mediated by technology. The resulting animal-human-computer interaction may inform mediated interspecies experiences in the future.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {animal music, enrichment, animal computer interaction, animal agency, sonic enrichment, interspecies interactions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376152,
author = {Liu, Zipeng and Liu, Zhicheng and Munzner, Tamara},
title = {Data-Driven Multi-Level Segmentation of Image Editing Logs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376152},
doi = {10.1145/3313831.3376152},
abstract = {Automatic segmentation of logs for creativity tools such as image editing systems could improve their usability and learnability by supporting such interaction use cases as smart history navigation or recommending alternative design choices. We propose a multi-level segmentation model that works for many image editing tasks including poster creation, portrait retouching, and special effect creation. The lowest-level chunks of logged events are computed using a support vector machine model and higher-level chunks are built on top of these, at a level of granularity that can be customized for specific use cases. Our model takes into account features derived from four event attributes collected in realistically complex Photoshop sessions with expert users: command, timestamp, image content, and artwork layer. We present a detailed analysis of the relevance of each feature and evaluate the model using both quantitative performance metrics and qualitative analysis of sample sessions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interaction history, image editing logs, log segmentation, multi-level hierarchy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376324,
author = {Wu, Ziming and Jiang, Yulun and Liu, Yiding and Ma, Xiaojuan},
title = {Predicting and Diagnosing User Engagement with Mobile UI Animation via a Data-Driven Approach},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376324},
doi = {10.1145/3313831.3376324},
abstract = {Animation, a common design element in user interfaces (UI), can impact user engagement (UE) with mobile applications. To avoid impairing UE due to improper design of animation, designers rely on resource-intensive evaluation methods like user studies or expert reviews. To alleviate this burden, we propose a data-driven approach to assisting designers in examining UE issues with their animation designs. We first crowdsource UE assessments of mobile UI animations. Based on the collected data, we then build a novel deep learning model that captures both spatial and temporal features of animations to predict their UE levels. Evaluations show that our model achieves a reasonable accuracy. We further leverage the animation feature encoded by our model and a sample set of expert reviews to derive potential UE issues of a particular animation. Finally, we develop a proof-of-concept tool and evaluate its potential usage in actual design practices with experts},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile ui animation, data-driven approach, user engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376840,
author = {Katsini, Christina and Abdrabou, Yasmeen and Raptis, George E. and Khamis, Mohamed and Alt, Florian},
title = {The Role of Eye Gaze in Security and Privacy Applications: Survey and Future HCI Research Directions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376840},
doi = {10.1145/3313831.3376840},
abstract = {For the past 20 years, researchers have investigated the use of eye tracking in security applications. We present a holistic view on gaze-based security applications. In particular, we canvassed the literature and classify the utility of gaze in security applications into a) authentication, b) privacy protection, and c) gaze monitoring during security critical tasks. This allows us to chart several research directions, most importantly 1) conducting field studies of implicit and explicit gaze-based authentication due to recent advances in eye tracking, 2) research on gaze-based privacy protection and gaze monitoring in security critical tasks which are under-investigated yet very promising areas, and 3) understanding the privacy implications of pervasive eye tracking. We discuss the most promising opportunities and most pressing challenges of eye tracking for security that will shape research in gaze-based security applications for the next decade.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–21},
numpages = {21},
keywords = {survey, literature survey, privacy, security, gaze interaction, human-centered security, eye tracking, usable security},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376158,
author = {Manuel, Jennifer and Crivellaro, Clara},
title = {Place-Based Policymaking and HCI: Opportunities and Challenges for Technology Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376158},
doi = {10.1145/3313831.3376158},
abstract = {There has been a growing interest in HCI in designing and developing technology to support democratic participation, particularly in the domain of urban planning or place-based research. In addition, the HCI field has increasingly considered the intersection of HCI and policymaking to understand how our research can have a broader impact. In this paper, we report on a series of workshops with citizens and city planners to explore place-based policymaking through the case study of neighbourhood planning in the UK. Our analysis highlights the tensions, opportunities and challenges faced by citizens in creating policy. Drawing from our findings, we stress the need for HCI to be actively involved in supporting, innovating and (re)designing civic policymaking processes while emphasising design considerations for the development of technological tools.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {digital civics, citizen participation, policymaking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376299,
author = {Pradhan, Alisha and Jelen, Ben and Siek, Katie A. and Chan, Joel and Lazar, Amanda},
title = {Understanding Older Adults' Participation in Design Workshops},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376299},
doi = {10.1145/3313831.3376299},
abstract = {Design workshops are a popular means of including older adults in technology development. However, there are open questions around how to best scaffold this participation, particularly in supporting older adults to associate their designs with themselves, rather than designing for an "other older adult." By conducting workshops focusing on envisioning the future of internet of things (IoT) technologies at home, we provide an understanding of how older individuals participate in group activities to conceptualize technology for themselves. We find that at different stages of the design process, individuals shift in who they envision the end user of the technology: at first, they think about common older adult needs, then turn to designing for themselves. Individuals' attitudes towards technology also impact group dynamics along with final design ideas. Our discussion contributes to an understanding of how to support older adults in designing for themselves, new perspectives on aging-in-place technologies, and recommendations for configuring design workshops with older individuals.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {design workshops, participatory design, co-design, iot, older adults},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376372,
author = {Kontogiorgos, Dimosthenis and van Waveren, Sanne and Wallberg, Olle and Pereira, Andre and Leite, Iolanda and Gustafson, Joakim},
title = {Embodiment Effects in Interactions with Failing Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376372},
doi = {10.1145/3313831.3376372},
abstract = {The increasing use of robots in real-world applications will inevitably cause users to encounter more failures in interactions. While there is a longstanding effort in bringing human-likeness to robots, how robot embodiment affects users' perception of failures remains largely unexplored. In this paper, we extend prior work on robot failures by assessing the impact that embodiment and failure severity have on people's behaviours and their perception of robots. Our findings show that when using a smart-speaker embodiment, failures negatively affect users' intention to frequently interact with the device, however not when using a human-like robot embodiment. Additionally, users significantly rate the human-like robot higher in terms of perceived intelligence and social presence. Our results further suggest that in higher severity situations, human-likeness is distracting and detrimental to the interaction. Drawing on quantitative findings, we discuss benefits and drawbacks of embodiment in robot failures that occur in guided tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {conversational failures, social robots, common ground, time pressure, guided tasks, smart-speakers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376514,
author = {Frid, Emma and Gomes, Celso and Jin, Zeyu},
title = {Music Creation by Example},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376514},
doi = {10.1145/3313831.3376514},
abstract = {Short online videos have become the dominating media on social platforms. However, finding suitable music to accompany videos can be a challenging task to some video creators, due to copyright constraints, limitations in search engines, and required audio-editing expertise. One possible solution to these problems is to use AI music generation. In this paper we present a user interface (UI) paradigm that allows users to input a song to an AI engine and then interactively regenerate and mix AI-generated music. To arrive at this design, we conducted user studies with a total of 104 video creators at several stages of our design and development process. User studies supported the effectiveness of our approach and provided valuable insights about human-AI interaction as well as the design and evaluation of mixed-initiative interfaces in creative practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mixed-initiative interaction, music generation, artificial intelligence, algorithmic composition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376793,
author = {Das Swain, Vedant and Saha, Koustuv and Reddy, Manikanta D. and Rajvanshy, Hemang and Abowd, Gregory D. and De Choudhury, Munmun},
title = {Modeling Organizational Culture with Workplace Experiences Shared on Glassdoor},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376793},
doi = {10.1145/3313831.3376793},
abstract = {Organizational culture (OC) encompasses the underlying beliefs, values, and practices that are unique to an organization. However, OC is inherently subjective and a coarse construct, and therefore challenging to quantify. Alternatively, self-initiated workplace reviews on online platforms like Glassdoor provide the opportunity to leverage the richness of language to understand OC. In as much, first, we use multiple job descriptors to operationalize OC as a word vector representation. We validate this construct with language used in 650k different Glassdoor reviews. Next, we propose a methodology to apply our construct on Glassdoor reviews to quantify the OC of employees by sector. We validate our measure of OC on a dataset of 341 employees by providing empirical evidence that it helps explain job performance. We discuss the implications of our work in guiding tailored interventions and designing tools for improving employee functioning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {organizational culture, glassdoor, social media, wordvector},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376570,
author = {Zou, Yixin and Roundy, Kevin and Tamersoy, Acar and Shintre, Saurabh and Roturier, Johann and Schaub, Florian},
title = {Examining the Adoption and Abandonment of Security, Privacy, and Identity Theft Protection Practices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376570},
doi = {10.1145/3313831.3376570},
abstract = {Users struggle to adhere to expert-recommended security and privacy practices. While prior work has studied initial adoption of such practices, little is known about the subsequent implementation and abandonment. We conducted an online survey (n=902) examining the adoption and abandonment of 30 commonly recommended practices. Security practices were more widely adopted than privacy and identity theft protection practices. Manual and fully automatic practices were more widely adopted than practices requiring recurring user interaction. Participants' gender, education, technical background, and prior negative experience are correlated with their levels of adoption. Furthermore, practices were abandoned when they were perceived as low-value, inconvenient, or when users overrode them with subjective judgment. We discuss how security, privacy, and identity theft protection recommendations and tools can be better aligned with user needs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {adoption, abandonment, security and privacy decision-making, technology non-use, usable security and privacy, user behavior, risk perception},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376433,
author = {Robinson, Raquel Breejon and Reid, Elizabeth and Fey, James Collin and Depping, Ansgar E. and Isbister, Katherine and Mandryk, Regan L.},
title = {Designing and Evaluating 'In the Same Boat', A Game of Embodied Synchronization for Enhancing Social Play},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376433},
doi = {10.1145/3313831.3376433},
abstract = {Social closeness is important for health and well-being, but is difficult to maintain over a distance. Games can help connect people by strengthening existing relationships or creating new ones through shared playful experiences. We present the design and evaluation of 'In the Same Boat' (ITSB), a two-player infinite runner designed to foster social closeness in distributed dyads. ITSB leverages the synchronization of both players' input to steer a canoe down a river and avoid obstacles. We created two versions: embodied controls, which use players' physiological signals (breath rate, facial expressions), and standard keyboard controls. Results from a study with 35 dyads indicate that ITSB fostered affiliation, and while embodied controls were less intuitive, people enjoyed them more. Further, photos of the dyads were rated as happier and closer in the embodied condition, indicating the potential of embodied controls to foster social closeness in synchronized play over a distance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {body games, emotion, physiological data, social games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376755,
author = {Troiano, Giovanni Maria and Chen, Qinyu and Alba, \'{A}ngela Vargas and Robles, Gregorio and Smith, Gillian and Cassidy, Michael and Tucker-Raymond, Eli and Puttick, Gillian and Harteveld, Casper},
title = {Exploring How Game Genre in Student-Designed Games Influences Computational Thinking Development},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376755},
doi = {10.1145/3313831.3376755},
abstract = {Game design is increasingly used in modern education to foster Computational Thinking (CT). Yet, it is unclear how and if the game genre of student-designed games impact CT and programming. We explore how game genre impacts CT development and programming routines in Scratch games designed by 8th-grade students using a metrics-based approach (i.e., Dr. Scratch). Our findings show that designing particular games (e.g., action, storytelling) impact CT and programming development. We observe, for instance, that CT skills develop and consolidate fast, after which students can focus on aspects more specific to game design. Based on the results, we suggest that researchers and educators in constructionist learning consider the impact of game genre when designing game-based curricula for the learning of programming and CT.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {computational thinking, constructionist learning, game design, video games, game-based learning, Dr. Scratch, scratch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376130,
author = {Yu, Junnan and Bai, Chenke and Roque, Ricarose},
title = {Considering Parents in Coding Kit Design: Understanding Parents' Perspectives and Roles},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376130},
doi = {10.1145/3313831.3376130},
abstract = {As education researchers, policymakers, and industry leaders recognize the importance of computing, many coding kits (toys and apps) have emerged to help young children learn to code at home. However, how parents perceive and support their children's use of the kits at home are less understood. In this study, we performed semi-structured interviews with eighteen parents who obtained coding kits for their young children for home use. The results show parents expected their kids to have fun and meaningful interactions with the kits. In supporting the play, parents took on various roles, mostly acting as spectator, scaffolder, and teacher. While parents perceived benefits of coding kits like a changed perspective on coding, they also reported concerns, such as their limited programming knowledge to provide help. Finally, we reflect on design and research implications to develop coding kits that consider parents' perspectives and important roles in supporting young children's exploration with computational thinking.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {informal learning, parent roles, parents' perspectives, young children, coding toys and kits, educational technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376556,
author = {Schroeder, Kay and Ajdadilish, Batoul and Henkel, Alexander P. and Calero Valdez, Andr\'{e}},
title = {Evaluation of a Financial Portfolio Visualization Using Computer Displays and Mixed Reality Devices with Domain Experts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376556},
doi = {10.1145/3313831.3376556},
abstract = {With the advent of mixed reality devices such as the Microsoft HoloLens, developers have been faced with the challenge to utilize the third dimension in information visualization effectively. Research on stereoscopic devices has shown that three-dimensional representation can improve accuracy in specific tasks (e.g., network visualization). Yet, so far the field has remained mute on the underlying mechanism. Our study systematically investigates the differences in user perception between a regular monitor and a mixed reality device. In a real-life within-subject experiment in the field with twenty-eight investment bankers, we assessed subjective and objective task performance with two- and three-dimensional systems, respectively. We tested accuracy with regard to position, size, and color using single and combined tasks. Our results do not show a significant difference in accuracy between mixed-reality and standard 2D monitor visualizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {UX study, mixed reality displays, hololens, user study, information visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376439,
author = {Gao, Ge and Sun, Yuling and Zhang, Yongle},
title = {Engaging the Commons in Participatory Sensing: Practice, Problems, and Promise in the Context of Dockless Bikesharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376439},
doi = {10.1145/3313831.3376439},
abstract = {Participatory sensing refers to the sensing paradigm where human participants use personal mobile devices to generate and share data from their surroundings. It holds the promise of providing information that is otherwise challenging to access, which sets the stage for understanding and resolving various social issues. However, difficulties in engaging participants often hinder the fulfillment of this promise. The current paper presents a qualitative study in the context of dockless bikesharing, where participatory sensing constitutes a backbone of the bike status monitoring system. We conducted in-depth interviews with 30 participants. These participants came from different emergent groups who took part in filing status reports for shared bikes. Our analysis indicated close associations among participants' models of engagement, their perceived (dis)connections with the sensing data, and their situated interpretation of the incentives. Based on these findings, we propose ways to engage the commons in participatory sensing for dockless bikesharing and beyond.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {urban transportation, dockless bikesharing, smart city, engagement, participatory sensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376186,
author = {Trajkova, Milka and Alhakamy, A'aeshah and Cafaro, Francesco and Mallappa, Rashmi and Kankara, Sreekanth R.},
title = {Move Your Body: Engaging Museum Visitors with Human-Data Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376186},
doi = {10.1145/3313831.3376186},
abstract = {Museums have embraced embodied interaction: its novelty generates buzz and excitement among their patrons, and it has enormous educational potential. Human-Data Interaction (HDI) is a class of embodied interactions that enables people to explore large sets of data using interactive visualizations that users control with gestures and body movements. In museums, however, HDI installations have no utility if visitors do not engage with them. In this paper, we present a quasi-experimental study that investigates how different ways of representing the user ("mode type") next-to a data visualization alters the way in which people engage with a HDI system. We consider four mode types: avatar, skeleton, camera overlay, and control. Our findings indicate that the mode type impacts the number of visitors that interact with the installation, the gestures that people do, and the amount of time that visitors spend observing the data on display and interacting with the system.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {embodied interaction, human-data interaction, informal learning, museums, public displays},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376613,
author = {Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim},
title = {Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376613},
doi = {10.1145/3313831.3376613},
abstract = {We present Embodied Axes, a controller which supports selection operations for 3D imagery and data visualisations in Augmented Reality. The device is an embodied representation of a 3D data space -- each of its three orthogonal arms corresponds to a data axis or domain specific frame of reference. Each axis is composed of a pair of tangible, actuated range sliders for precise data selection, and rotary encoding knobs for additional parameter tuning or menu navigation. The motor actuated sliders support alignment to positions of significant values within the data, or coordination with other input: e.g., mid-air gestures in the data space, touch gestures on the surface below the data, or another Embodied Axes device supporting multi-user scenarios. We conducted expert enquiries in medical imaging which provided formative feedback on domain tasks and refinements to the design. Additionally, a controlled user study was performed and found that the Embodied Axes was overall more accurate than conventional tracked controllers for selection tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3d visualisation, tangible interaction, augmented reality, actuation, device},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376403,
author = {Qiu, Sihang and Gadiraju, Ujwal and Bozzon, Alessandro},
title = {Improving Worker Engagement Through Conversational Microtask Crowdsourcing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376403},
doi = {10.1145/3313831.3376403},
abstract = {The rise in popularity of conversational agents has enabled humans to interact with machines more naturally. Recent work has shown that crowd workers in microtask marketplaces can complete a variety of human intelligence tasks (HITs) using conversational interfaces with similar output quality compared to the traditional Web interfaces. In this paper, we investigate the effectiveness of using conversational interfaces to improve worker engagement in microtask crowdsourcing. We designed a text-based conversational agent that assists workers in task execution, and tested the performance of workers when interacting with agents having different conversational styles. We conducted a rigorous experimental study on Amazon Mechanical Turk with 800 unique workers, to explore whether the output quality, worker engagement and the perceived cognitive load of workers can be affected by the conversational agent and its conversational styles. Our results show that conversational interfaces can be effective in engaging workers, and a suitable conversational style has potential to improve worker engagement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user engagement, conversational interface, microtask crowdsourcing, cognitive task load, conversational style},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376219,
author = {Kaur, Harmanpreet and Nori, Harsha and Jenkins, Samuel and Caruana, Rich and Wallach, Hanna and Wortman Vaughan, Jennifer},
title = {Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376219},
doi = {10.1145/3313831.3376219},
abstract = {Machine learning (ML) models are now routinely deployed in domains ranging from criminal justice to healthcare. With this newfound ubiquity, ML has moved beyond academia and grown into an engineering discipline. To that end, interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study data scientists' use of two existing interpretability tools, the InterpretML implementation of GAMs and the SHAP Python package. We conduct a contextual inquiry (N=11) and a survey (N=197) of data scientists to observe how they use interpretability tools to uncover common issues that arise when building and evaluating ML models. Our results indicate that data scientists over-trust and misuse interpretability tools. Furthermore, few of our participants were able to accurately describe the visualizations output by these tools. We highlight qualitative themes for data scientists' mental models of interpretability tools. We conclude with implications for researchers and tool designers, and contextualize our findings in the social science literature.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interpretability, machine learning, user-centric evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376809,
author = {Ayobi, Amid and Marshall, Paul and Cox, Anna L.},
title = {Trackly: A Customisable and Pictorial Self-Tracking App to Support Agency in Multiple Sclerosis Self-Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376809},
doi = {10.1145/3313831.3376809},
abstract = {Self-tracking is an important part of self-care. However, predefined self-tracking approaches can impede people's agency in managing their health. We investigated a customisable and pictorial self-tracking approach in multiple sclerosis self-management by implementing and conducting a field study of Trackly: a prototype app that supports people in defining and colouring pictorial trackers, such as body shapes. We found that participants utilised the elements of Trackly designed to support agentive behaviour: they defined personally meaningful tracking parameters in their own words, and particularly valued being able to flexibly colour in and make sense of their pictorial trackers. Having been able to support their individual self-care intentions with Trackly, participants reported a spectrum of interrelated experiences of agency, including a sense of ownership, identity, self-awareness, mindfulness, and control. Our findings demonstrate the importance of supporting people's individual needs and creative capacities to foster mindful and personally meaningful engagement with health and wellbeing data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {bullet journaling, self-tracking, customization, self-reflection, mood tracking, agency, self-awareness, customisation, mindfulness, perceived control, symptom monitoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376787,
author = {Yeo, Dohyeon and Kim, Gwangbin and Kim, Seungjun},
title = {Toward Immersive Self-Driving Simulations: Reports from a User Study across Six Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376787},
doi = {10.1145/3313831.3376787},
abstract = {As self-driving car technology matures, autonomous vehicle research is moving toward building more human-centric interfaces and accountable experiences. Driving simulators avoid many ethical and regulatory concerns about self-driving cars and play a key role in testing new interfaces or autonomous driving scenarios. However, apart from validity studies for manual driving simulation, the capabilities of driving simulators in replicating the experience of self-driving cars have not been widely investigated. In this paper, we build six self-driving simulation platforms with varying levels of visual and motion fidelities ranging from a screen-based in-lab simulator to the mixed-reality on-road simulator we propose. We compare the sense of presence and simulator sickness for each simulator composition, as well as its visual and motion fidelities with a user study. Our novel mixed-reality automotive driving simulator, named MAXIM, showed highest fidelity and presence. Our findings suggest how visual and motion configurations affect experience in autonomous driving simulators.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {autonomous driving, user studies, mixed reality, on-road simulation, driving simulator, immersive technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376575,
author = {Ebert, Nico and Ackermann, Kurt Alexander and Heinrich, Peter},
title = {Does Context in Privacy Communication Really Matter? — A Survey on Consumer Concerns and Preferences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376575},
doi = {10.1145/3313831.3376575},
abstract = {Privacy policies as a means of communicating with customers still prove ineffective. Researchers have recently suggested that a specific usage context should be considered to make privacy notices more relevant to users. To explore this approach further, we conducted an explorative online survey of privacy concerns and privacy information preferences with 642 participants for two different contexts (loyalty cards and fitness tracking). Our data shows some support for the suggestion that context may be a significant moderator of concerns and preferences. However, the corresponding effects are rather small and limited to specific concerns and information categories. In line with other research, the data supports the known hierarchy of concerns regarding unauthorized secondary use and improper data access, which seem to exceed concerns about erroneous data processing or excessive data collection in both contexts. Furthermore, participants considered information on personal rights and processing purposes more relevant than information on contact persons.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {privacy concerns, privacy, policy, user preferences},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376639,
author = {Zindulka, Tim and Bachynskyi, Myroslav and M\"{u}ller, J\"{o}rg},
title = {Performance and Experience of Throwing in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376639},
doi = {10.1145/3313831.3376639},
abstract = {Throwing is a fundamental movement in many sports and games. Given this, accurate throwing in VR applications today is surprisingly difficult. In this paper we explore the nature of the difficulties of throwing in VR in more detail. We present the results of a user study comparing throwing in VR and in the physical world. In a short pre-study with 3 participants we determine an optimal number of throwing repetitions for the main study by exploring the learning curve and subjective fatigue of throwing in VR. In the main study, with 12 participants, we find that throwing precision and accuracy in VR are lower particularly in the distance and height dimensions. It also requires more effort and exhibits different kinematic patterns.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {user study, virtual reality, throwing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376316,
author = {Gero, Katy Ilonka and Ashktorab, Zahra and Dugan, Casey and Pan, Qian and Johnson, James and Geyer, Werner and Ruiz, Maria and Miller, Sarah and Millen, David R. and Campbell, Murray and Kumaravel, Sadhana and Zhang, Wei},
title = {Mental Models of AI Agents in a Cooperative Game Setting},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376316},
doi = {10.1145/3313831.3376316},
abstract = {As more and more forms of AI become prevalent, it becomes increasingly important to understand how people develop mental models of these systems. In this work we study people's mental models of AI in a cooperative word guessing game. We run think-aloud studies in which people play the game with an AI agent; through thematic analysis we identify features of the mental models developed by participants. In a large-scale study we have participants play the game with the AI agent online and use a post-game survey to probe their mental model. We find that those who win more often have better estimates of the AI agent's abilities. We present three components for modeling AI systems, propose that understanding the underlying technology is insufficient for developing appropriate conceptual models (analysis of behavior is also necessary), and suggest future work for studying the revision of mental models over time.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {word games, mental models, games, conceptual models, artificial intelligence, think-aloud, ai agents},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376829,
author = {Syeda, Uzma Haque and Murali, Prasanth and Roe, Lisa and Berkey, Becca and Borkin, Michelle A.},
title = {Design Study "Lite" Methodology: Expediting Design Studies and Enabling the Synergy of Visualization Pedagogy and Social Good},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376829},
doi = {10.1145/3313831.3376829},
abstract = {Design studies are frequently used to conduct problem-driven visualization research by working with real-world domain experts. In visualization pedagogy, design studies are often introduced but rarely practiced due to their large time requirements. This limits students to a classroom curriculum, often involving projects that may not have implications beyond the classroom. Thus we present the Design Study "Lite" Methodology, a novel framework for implementing design studies with novice students in 14 weeks. We utilized the Design Study "Lite" Methodology in conjunction with Service-Learning to teach five Data Visualization courses and demonstrate that it benefits not only the students but also the community through service to non-profit partners. In this paper, we provide a detailed breakdown of the methodology and how Service-Learning can be incorporated with it. We also include an extensive reflection on the methodology and provide recommendations for future applications of the framework for teaching visualization courses and research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {service-learning, theory and methods, visualization, pedagogy, design studies},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376467,
author = {Kim, Dae Hyun and Hoque, Enamul and Agrawala, Maneesh},
title = {Answering Questions about Charts and Generating Visual Explanations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376467},
doi = {10.1145/3313831.3376467},
abstract = {People often use charts to analyze data, answer questions and explain their answers to others. In a formative study, we find that such human-generated questions and explanations commonly refer to visual features of charts. Based on this study, we developed an automatic chart question answering pipeline that generates visual explanations describing how the answer was obtained. Our pipeline first extracts the data and visual encodings from an input Vega-Lite chart. Then, given a natural language question about the chart, it transforms references to visual attributes into references to the data. It next applies a state-of-the-art machine learning algorithm to answer the transformed question. Finally, it uses a template-based approach to explain in natural language how the answer is determined from the chart's visual features. A user study finds that our pipeline-generated visual explanations significantly outperform in transparency and are comparable in usefulness and trust to human-generated explanations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {question answering, visualization, explainable ai},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376164,
author = {Arshad, Muhammad Bilal and Sarwar, Muhammad Farhan and Zaidi, Meher Fatima and Shahid, Suleman},
title = {EAST: Early Autism Screening Tool for Preschoolers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376164},
doi = {10.1145/3313831.3376164},
abstract = {We describe the iterative co-design process and evaluation of an early autism screening tool (EAST). EAST is an intermediary interactive tablet based app that assists in the early-detection of Autism Spectrum Disorder (ASD) by screening preschoolers in Pakistan through play-based activities in a home, school or clinical setting. Medical professionals, parents of autistic children and teachers were surveyed through focus groups to understand the reasons that contribute to the increasing number of missed early detections, and late- or misdiagnoses. We also evaluate the acceptability, usability and validity of our tool. We tested EAST with both typically developed and autistic children on how they relate to people, imitation, motor skills, visual and intellectual response. They were scored via time taken, the number of wrong attempts, or incorrect answers and audiovisual feedback. This paper contributes towards a digital autism screening tool that delivers insights into the child's behaviour and enables collaboration among parents, teachers and medical professionals.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {digital tool, preschool children, autism screening},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376140,
author = {Sun, Jiao and Li, Yin and Chen, Charley and Lee, Jihae and Liu, Xin and Zhang, Zhongping and Huang, Ling and Shi, Lei and Xu, Wei},
title = {FDHelper: Assist Unsupervised Fraud Detection Experts with Interactive Feature Selection and Evaluation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376140},
doi = {10.1145/3313831.3376140},
abstract = {Online fraud is the well-known dark side of the modern Internet. Unsupervised fraud detection algorithms are widely used to address this problem. However, selecting features, adjusting hyperparameters, evaluating the algorithms, and eliminating false positives all require human expert involvement. In this work, we design and implement an end-to-end interactive visualization system, FDHelper, based on the deep understanding of the mechanism of the black market and fraud detection algorithms. We identify a workflow based on experience from both fraud detection algorithm experts and domain experts. Using a multi-granularity three-layer visualization map embedding an entropy-based distance metric ColDis, analysts can interactively select different feature sets, refine fraud detection algorithms, tune parameters and evaluate the detection result in near real-time. We demonstrate the effectiveness and significance of FDHelper through two case studies with state-of-the-art fraud detection algorithms, interviews with domain experts and algorithm experts, and a user study with eight first-time end users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visualization, fraud detection, human computer interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376670,
author = {Huang, Gaoping and Rao, Pawan S. and Wu, Meng-Han and Qian, Xun and Nof, Shimon Y. and Ramani, Karthik and Quinn, Alexander J.},
title = {Vipo: Spatial-Visual Programming with Functions for Robot-IoT Workflows},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376670},
doi = {10.1145/3313831.3376670},
abstract = {Mobile robots and IoT (Internet of Things) devices can increase productivity, but only if they can be programmed by workers who understand the domain. This is especially true in manufacturing. Visual programming in the spatial context of the operating environment can enable mental models at a familiar level of abstraction. However, spatial-visual programming is still in its infancy; existing systems lack IoT integration and fundamental constructs, such as functions, that are essential for code reuse, encapsulation, or recursive algorithms. We present Vipo, a spatial-visual programming system for robot-IoT workflows. Vipo was designed with input from managers at six factories using mobile robots. Our user study (n=22) evaluated efficiency, correctness, comprehensibility of spatial-visual programming with functions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {spatial visual programming, internet of things, robots},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376377,
author = {Sarma, Abhraneel and Kay, Matthew},
title = {Prior Setting in Practice: Strategies and Rationales Used in Choosing Prior Distributions for Bayesian Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376377},
doi = {10.1145/3313831.3376377},
abstract = {Bayesian statistical analysis is steadily growing in popularity and use. Choosing priors is an integral part of Bayesian inference. While there exist extensive normative recommendations for prior setting, little is known about how priors are chosen in practice. We conducted a survey (N = 50) and interviews (N = 9) where we used interactive visualizations to elicit prior distributions from researchers experienced withBayesian statistics and asked them for rationales for those priors. We found that participants' experience and philosophy influence how much and what information they are willing to incorporate into their priors, manifesting as different levels of informativeness and skepticism. We also identified three broad strategies participants use to set their priors: centrality matching, interval matching, and visual mass allocation. We discovered that participants' understanding of the notion of 'weakly informative priors"-a commonly-recommended normative approach to prior setting-manifests very differently across participants. Our results have implications both for how to develop prior setting recommendations and how to design tools to elicit priors in Bayesian analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {prior distributions, bayesian inference, descriptive analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376149,
author = {Oleson, Alannah and Solomon, Meron and Ko, Amy J.},
title = {Computing Students' Learning Difficulties in HCI Education},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376149},
doi = {10.1145/3313831.3376149},
abstract = {Software developers often make interface design decisions and work with designers. Therefore, computing students who seek to become developers need some education about interface design. While prior work has studied difficulties that educators face when teaching design to computing students, there is comparatively little work on the difficulties computing students face when learning HCI design skills. To uncover these difficulties, we conducted two qualitative studies consisting of surveys and interviews with (1) computing students and (2) educators who teach interface design to computing students. Qualitative analysis of their responses revealed 18 types of learning difficulties students might experience in HCI design education, including difficulties around the mechanics of design work, project management skills, the wicked nature of design problems, and distorted perspectives on design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {hci education, learning difficulties, interface design education, pedagogical content knowledge},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376608,
author = {Alshehri, Taghreed and Kirkham, Reuben and Olivier, Patrick},
title = {Scenario Co-Creation Cards: A Culturally Sensitive Tool for Eliciting Values},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376608},
doi = {10.1145/3313831.3376608},
abstract = {Values are an integral part of human identity and have a pervasive impact upon human behavior. This makes understanding them a central concern in the design of technology, as exemplified by approaches such as Value Sensitive Design ("VSD"). Identifying and concreting the values held by a given population can be a difficult endeavor, especially where there is a cultural barrier limiting an effective discussion of them, for example in societies where freedom of expression is discouraged. Addressing this concern requires an in-depth consideration of appropriate value elicitation methods, which responds to the fact that it is not possible to understand values detached from their cultural context. We introduce a novel implicit method, Scenario Co-Creation Cards, and show how it can be used to incorporate existing models of culture in the value elicitation process. We demonstrate this in a case study of Saudi women's visibility in the digital media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {values, user research, method, cards, scenarios, vsd, value elicitation, saudi arabia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376302,
author = {Dylan, Thomas and Wood, Gavin and Durrant, Abigail C. and Vines, John and Torres, Pablo E. and Ulrich, Philip I. N. and Cukurova, Mutlu and Carr, Amanda and \c{C}er\c{c}i, Sena and Lawson, Shaun},
title = {Designing IoT Resources to Support Outdoor Play for Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376302},
doi = {10.1145/3313831.3376302},
abstract = {We describe a Research-through-Design (RtD) project that explores the Internet of Things (IoT) as a resource for children's free play outdoors. Based on initial insights from a design ethnography, we developed four RtD prototypes for social play in different scenarios of use outdoors, including congregating on a street or in a park to play physical games with IoT. We observed these prototypes in use by children in their free play in two community settings, and report on the qualitative analysis of our fieldwork. Our findings highlight the designs' material qualities that encouraged social and physical play under certain conditions, suggesting social affordances that are central to the success of IoT designs for free play outdoors. We provide directions for future research that addresses the challenges faced when deploying IoT with children, contributing new considerations for interaction design with children in outdoor settings and free play contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {outdoor play, internet of things, free play, pervasive play, digital playing out, children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376436,
author = {Chen, Zhutian and Tong, Wai and Wang, Qianwen and Bach, Benjamin and Qu, Huamin},
title = {Augmenting Static Visualizations with PapARVis Designer},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376436},
doi = {10.1145/3313831.3376436},
abstract = {This paper presents an authoring environment for augmenting static visualizations with virtual content in augmented reality.Augmenting static visualizations can leverage the best of both physical and digital worlds, but its creation currently involves different tools and devices, without any means to explicitly design and debug both static and virtual content simultaneously. To address these issues, we design an environment that seamlessly integrates all steps of a design and deployment workflow through its main features: i) an extension to Vega, ii) a preview, and iii) debug hints that facilitate valid combinations of static and augmented content. We inform our design through a design space with four ways to augment static visualizations. We demonstrate the expressiveness of our tool through examples, including books, posters, projections, wall-sized visualizations. A user study shows high user satisfaction of our environment and confirms that participants can create augmented visualizations in an average of 4.63 minutes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visualization in augmented reality, augmented static visualization, data visualization authoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376266,
author = {Kurzhals, Kuno and G\"{o}bel, Fabian and Angerbauer, Katrin and Sedlmair, Michael and Raubal, Martin},
title = {A View on the Viewer: Gaze-Adaptive Captions for Videos},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376266},
doi = {10.1145/3313831.3376266},
abstract = {Subtitles play a crucial role in cross-lingual distribution of multimedia content and help communicate information where auditory content is not feasible (loud environments, hearing impairments, unknown languages). Established methods utilize text at the bottom of the screen, which may distract from the video. Alternative techniques place captions closer to related content (e.g., faces) but are not applicable to arbitrary videos such as documentations. Hence, we propose to leverage live gaze as indirect input method to adapt captions to individual viewing behavior. We implemented two gaze-adaptive methods and compared them in a user study (n=54) to traditional captions and audio-only videos. The results show that viewers with less experience with captions prefer our gaze-adaptive methods as they assist them in reading. Furthermore, gaze distributions resulting from our methods are closer to natural viewing behavior compared to the traditional approach. Based on these results, we provide design implications for gaze-adaptive captions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {video captions, gaze input, eye tracking, subtitles, multimedia, gaze-responsive display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376769,
author = {Marky, Karola and Zimmermann, Verena and Funk, Markus and Daubert, J\"{o}rg and Bleck, Kira and M\"{u}hlh\"{a}user, Max},
title = {Improving the Usability and UX of the Swiss Internet Voting Interface},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376769},
doi = {10.1145/3313831.3376769},
abstract = {Up to 20% of residential votes and up to 70% of absentee votes in Switzerland are cast online. The Swiss system aims to provide individual verifiability by different verification codes. The voters have to carry out verification on their own, making the usability and UX of the interface of great importance. To improve the usability, we first performed an evaluation with 12 human-computer interaction experts to uncover usability weaknesses of the Swiss Internet voting interface. Based on the experts' findings, related work, and an exploratory user study with 36 participants, we propose a redesign that we evaluated in a user study with 49 participants. Our study confirmed that the redesign indeed improves the detection of incorrect votes by 33% and increases the trust and understanding of the voters. Our studies furthermore contribute important lessons for designing verifiable e-voting systems in general.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {individual verifiability, e-voting, usability evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376861,
author = {Foley, Margaret and Casiez, G\'{e}ry and Vogel, Daniel},
title = {Comparing Smartphone Speech Recognition and Touchscreen Typing for Composition and Transcription},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376861},
doi = {10.1145/3313831.3376861},
abstract = {Ruan et al. found transcribing short phrases with speech recognition nearly 200% faster than typing on a smartphone. We extend this comparison to a novel composition task, using a protocol that enables a controlled comparison with transcription. Results show that both composing and transcribing with speech is faster than typing. But, the magnitude of this difference is lower with composition, and speech has a lower error rate than keyboard during composition, but not during transcription. When transcribing, speech outperformed typing in most NASA-TLX measures, but when composing, there were no significant differences between typing and speech for any measure except physical demand.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {mobile phones, text entry, speech recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376229,
author = {Saxena, Devansh and Badillo-Urquiola, Karla and Wisniewski, Pamela J. and Guha, Shion},
title = {A Human-Centered Review of Algorithms Used within the U.S. Child Welfare System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376229},
doi = {10.1145/3313831.3376229},
abstract = {The U.S. Child Welfare System (CWS) is charged with improving outcomes for foster youth; yet, they are overburdened and underfunded. To overcome this limitation, several states have turned towards algorithmic decision-making systems to reduce costs and determine better processes for improving CWS outcomes. Using a human-centered algorithmic design approach, we synthesize 50 peer-reviewed publications on computational systems used in CWS to assess how they were being developed, common characteristics of predictors used, as well as the target outcomes. We found that most of the literature has focused on risk assessment models but does not consider theoretical approaches (e.g., child-foster parent matching) nor the perspectives of caseworkers (e.g., case notes). Therefore, future algorithms should strive to be context-aware and theoretically robust by incorporating salient factors identified by past research. We provide the HCI community with research avenues for developing human-centered algorithms that redirect attention towards more equitable outcomes for CWS.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {human-centered algorithm design, algorithmic decision-making, child welfare system},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376381,
author = {Nobre, Carolina and Wootton, Dylan and Harrison, Lane and Lex, Alexander},
title = {Evaluating Multivariate Network Visualization Techniques Using a Validated Design and Crowdsourcing Approach},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376381},
doi = {10.1145/3313831.3376381},
abstract = {Visualizing multivariate networks is challenging because of the trade-offs necessary for effectively encoding network topology and encoding the attributes associated with nodes and edges. A large number of multivariate network visualization techniques exist, yet there is little empirical guidance on their respective strengths and weaknesses. In this paper, we describe a crowdsourced experiment, comparing node-link diagrams with on-node encoding and adjacency matrices with juxtaposed tables. We find that node-link diagrams are best suited for tasks that require close integration between the network topology and a few attributes. Adjacency matrices perform well for tasks related to clusters and when many attributes need to be considered. We also reflect on our method of using validated designs for empirically evaluating complex, interactive visualizations in a crowdsourced setting. We highlight the importance of training, compensation, and provenance tracking.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {multivariate networks visualization, crowdsourced evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376727,
author = {Long, Duri and Magerko, Brian},
title = {What is AI Literacy? Competencies and Design Considerations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376727},
doi = {10.1145/3313831.3376727},
abstract = {Artificial intelligence (AI) is becoming increasingly integrated in user-facing technology, but public understanding of these technologies is often limited. There is a need for additional HCI research investigating a) what competencies users need in order to effectively interact with and critically evaluate AI and b) how to design learner-centered AI technologies that foster increased user understanding of AI. This paper takes a step towards realizing both of these goals by providing a concrete definition of AI literacy based on existing research. We synthesize a variety of interdisciplinary literature into a set of core competencies of AI literacy and suggest several design considerations to support AI developers and educators in creating learner-centered AI. These competencies and design considerations are organized in a conceptual framework thematically derived from the literature. This paper's contributions can be used to start a conversation about and guide future research on AI literacy within the HCI community.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {AI for K-12, AI education, machine learning, computing education, artificial intelligence, AI literacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376388,
author = {Spillane, Brendan and Hoe, Isla and Brady, Mike and Wade, Vincent and Lawless, S\'{e}amus},
title = {Tabloidization versus Credibility: Short Term Gain for Long Term Pain},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376388},
doi = {10.1145/3313831.3376388},
abstract = {Print news agencies have been under pressure from falling sales and advertising revenue and increased competition. As the Internet became the dominant medium, news agencies invested heavily in their websites and apps, providing their news for free, rather than selling a print edition. Reducing the cost of production and removing access barriers such as geographic location had the potential to increase readership and advertising, covering costs and maintaining profits. Unfortunately, this business model has for the most part failed. Many higher quality news agencies are now implementing paywalls on their news websites to once again monetize their product. Others have begun to emulate the look and feel of tabloid news websites to increase readership and stickiness and advertising revenue. This study shows the negative impact of such visual tabloidization on initial impressions of credibility, which may have long term detrimental effects on the news agency.The authors would like to dedicate this paper to the memory of Professor S\'{e}amus "Shay" Lawless, the supervisor of this work who died on May 16th 2019 after fulfilling his dream of summiting Mount Everest.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {first impressions, news website design, news website aesthetics, credibility, tabloidization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376838,
author = {Han, Changyo and Takahashi, Ryo and Yahagi, Yuchi and Naemura, Takeshi},
title = {PneuModule: Using Inflatable Pin Arrays for Reconfigurable Physical Controls on Pressure-Sensitive Touch Surfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376838},
doi = {10.1145/3313831.3376838},
abstract = {We present PneuModule, a tangible interface platform that enables users to reconfigure physical controls on pressure-sensitive touch surfaces using pneumatically-actuated inflatable pin arrays. PneuModule consists of a main module and extension modules. The main module is tracked on the touch surface and forwards continuous inputs from attached multiple extension modules to the touch surface. Extension modules have distinct mechanisms for user input, which pneumatically actuates the inflatable pins at the bottom of the main module through internal air pipes. The main module accepts multi-dimensional inputs since each pin is individually inflated by the corresponding air chamber. Also, since the extension modules are swappable and identifiable owing to the marker design, users can quickly customize the interface layout. We contribute to design details of inflatable pins and diverse pneumatic input control design examples for PneuModule. We also showcase the feasibility of PneuModule through a series of evaluations and interactive prototypes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {pneumatic actuation, tangible user interfaces, pressure-sensitive touch surfaces, reconfigurable physical controls},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376162,
author = {Koelle, Marion and Ananthanarayan, Swamy and Boll, Susanne},
title = {Social Acceptability in HCI: A Survey of Methods, Measures, and Design Strategies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376162},
doi = {10.1145/3313831.3376162},
abstract = {With the increasing ubiquity of personal devices, social acceptability of human-machine interactions has gained relevance and growing interest from the HCI community. Yet, there are no best practices or established methods for evaluating social acceptability. Design strategies for increasing social acceptability have been described and employed, but so far not been holistically appraised and evaluated. We offer a systematic literature analysis (N=69) of social acceptability in HCI and contribute a better understanding of current research practices, namely, methods employed, measures and design strategies. Our review identified an unbalanced distribution of study approaches, shortcomings in employed measures, and a lack of interweaving between empirical and artifact-creating approaches. The latter causes a discrepancy between design recommendations based on user research, and design strategies employed in artifact creation. Our survey lays the groundwork for a more nuanced evaluation of social acceptability, the development of best practices, and a future research agenda.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–19},
numpages = {19},
keywords = {social acceptability, literature analysis, research methods},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376291,
author = {Baykal, G\"{o}k\c{c}e Elif and Van Mechelen, Maarten and Eriksson, Eva},
title = {Collaborative Technologies for Children with Special Needs: A Systematic Literature Review},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376291},
doi = {10.1145/3313831.3376291},
abstract = {This paper presents a systematic literature review on collaborative technologies for children with special needs in ACM Digital Library. The aim of the review is to (1) reveal the current state of the art, (2) identify the types of technologies and contexts of use, the demographics and special needs of the target group, and the methodological approaches and theoretical groundings, and (3) define a future research agenda. The results of the systematic literature review show that collaborative technologies for children with special needs are increasingly gaining attention, mostly involve tangible and/or embodied interaction, and are often developed for use in the classroom. The target group that is most represented are boys between 6 to 12 years with Autism Spectrum Disorder. The results further show a wide range of evaluation criteria for measuring collaboration, an interchanging use of theoretical concepts and a lack of definitions for the concept collaboration, and a need for more demographically diverse studies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {collaborative learning, collaboration, special need, collaborative technologies, cci, systematic literature review},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376705,
author = {Maekawa, Azumi and Matsubara, Seito and Wakisaka, Sohei and Uriu, Daisuke and Hiyama, Atsushi and Inami, Masahiko},
title = {Dynamic Motor Skill Synthesis with Human-Machine Mutual Actuation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376705},
doi = {10.1145/3313831.3376705},
abstract = {This paper presents an approach for coupling robotic capability with human ability in dynamic motor skills, called "Human-Machine Mutual Actuation (HMMA)." We focus specifically on throwing motions and propose a method to control the release timing computationally. A system we developed achieves our concept, HMMA, by a robotic handheld device that acts as a release controller. We conducted user studies to validate the feasibility of the concept and clarify related technical issues to be tackled. We recognized that the system successfully performs on throwing according to the target while it exploits human ability. These empirical experiments suggest that robotic capability can be embedded into the users' motions without losing their senses of control. Throughout the user study, we also revealed several issues to be tackled in further research contributing to HMMA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human augmentation, robotic device, motor skill, human-machine mutual actuation, motion sensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376167,
author = {McDonald, Nora and Forte, Andrea},
title = {The Politics of Privacy Theories: Moving from Norms to Vulnerabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376167},
doi = {10.1145/3313831.3376167},
abstract = {Privacy and surveillance are central features of public discourse around use of computing systems. As the systems we design and study are increasingly used and regulated as potential instruments of surveillance, HCI researchers-even those whose focus is not privacy-find themselves needing to understand privacy in their work. Concepts like contextual integrity and boundary regulation have become touchstones for thinking about privacy in HCI. In this paper, we draw on HCI and privacy literature to understand the limitations of commonly used theories and examine their assumptions, politics, strengths, and weaknesses. We use a case study from the HCI literature to illustrate conceptual gaps in existing frameworks where privacy requirements can fall through. Finally, we advocate vulnerability as a core concept for privacy theorizing and examine how feminist, queer-Marxist, and intersectional thinking may augment our existing repertoire of privacy theories to create a more inclusive scholarship and design practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {feminist intersectional theory, privacy theory, queer theory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376445,
author = {Madaio, Michael A. and Stark, Luke and Wortman Vaughan, Jennifer and Wallach, Hanna},
title = {Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376445},
doi = {10.1145/3313831.3376445},
abstract = {Many organizations have published principles intended to guide the ethical development and deployment of AI systems; however, their abstract nature makes them difficult to operationalize. Some organizations have therefore produced AI ethics checklists, as well as checklists for more specific concepts, such as fairness, as applied to AI systems. But unless checklists are grounded in practitioners' needs, they may be misused. To understand the role of checklists in AI ethics, we conducted an iterative co-design process with 48 practitioners, focusing on fairness. We co-designed an AI fairness checklist and identified desiderata and concerns for AI fairness checklists in general. We found that AI fairness checklists could provide organizational infrastructure for formalizing ad-hoc processes and empowering individual advocates. We highlight aspects of organizational culture that may impact the efficacy of AI fairness checklists, and suggest future design directions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ethics, checklists, fairness, co-design, ML, AI},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376566,
author = {Babaei, Ebrahim and Srivastava, Namrata and Newn, Joshua and Zhou, Qiushi and Dingler, Tilman and Velloso, Eduardo},
title = {Faces of Focus: A Study on the Facial Cues of Attentional States},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376566},
doi = {10.1145/3313831.3376566},
abstract = {Automatically detecting attentional states is a prerequisite for designing interventions to manage attention - knowledge workers' most critical resource. As a first step towards this goal, it is necessary to understand how different attentional states are made discernible through visible cues in knowledge workers. In this paper, we demonstrate the important facial cues to detect attentional states by evaluating a data set of 15 participants that we tracked over a whole workday, which included their challenge and engagement levels. Our evaluation shows that gaze, pitch, and lips part action units are indicators of engaged work; while pitch, gaze movements, gaze angle, and upper-lid raiser action units are indicators of challenging work. These findings reveal a significant relationship between facial cues and both engagement and challenge levels experienced by our tracked participants. Our work contributes to the design of future studies to detect attentional states based on facial cues.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {attentional state, challenge, facial expression, focus, engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376323,
author = {Zhang, Tengxiang and Zeng, Xin and Zhang, Yinshuai and Sun, Ke and Wang, Yuntao and Chen, Yiqiang},
title = {ThermalRing: Gesture and Tag Inputs Enabled by a Thermal Imaging Smart Ring},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376323},
doi = {10.1145/3313831.3376323},
abstract = {The heterogeneous and ubiquitous input demands in smart spaces call for an input device that can enable rich and spontaneous interactions. We propose ThermalRing, a thermal imaging smart ring using low-resolution thermal camera for identity-anonymous, illumination-invariant, and power-efficient sensing of both dynamic and static gestures. We also design ThermalTag, thin and passive thermal imageable tags that reflect the heat from the human hand. ThermalTag can be easily made and applied onto everyday objects by users. We develop sensing techniques for three typical input demands: drawing gestures for device pairing, click and slide gestures for device control, and tag scan gestures for quick access. The study results show that ThermalRing can recognize nine drawing gestures with an overall accuracy of 90.9%, detect click gestures with an accuracy of 94.9%, and identify among six ThermalTags with an overall accuracy of 95.0%. Finally, we show the versatility and potential of ThermalRing through various applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gesture recognition, interactive tags, thermal imaging, smart ring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376872,
author = {Baceviciute, Sarune and Mottelson, Aske and Terkildsen, Thomas and Makransky, Guido},
title = {Investigating Representation of Text and Audio in Educational VR Using Learning Outcomes and EEG},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376872},
doi = {10.1145/3313831.3376872},
abstract = {This paper reports findings from a between-subjects experiment that investigates how different learning content representations in virtual environments (VE) affect the process and outcomes of learning. Seventy-eight participants were subjected to an immersive virtual reality (VR) application, where they received identical instructional information, rendered in three different formats: as text in an overlay interface, as text embedded semantically in a virtual book, or as audio. Learning outcome measures, self-reports, and an electroencephalogram (EEG) were used to compare conditions. Results show that reading was superior to listening for the learning outcomes of retention, self-efficacy, and extraneous attention. Reading text from a virtual book was reported to be less cognitively demanding, compared to reading from an overlay interface. EEG analyses show significantly lower theta and higher alpha activation in the audio condition. The findings provide important considerations for the design of educational VR environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {eeg, educational technology, cognitive load, virtual reality, learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376476,
author = {Huang, Hsin-Yu and Ning, Chih-Wei and Wang, Po-Yao and Cheng, Jen-Hao and Cheng, Lung-Pan},
title = {Haptic-Go-Round: A Surrounding Platform for Encounter-Type Haptics in Virtual Reality Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376476},
doi = {10.1145/3313831.3376476},
abstract = {We present Haptic-go-round, a surrounding platform that allows deploying props and devices to provide haptic feedbacks in any direction in virtual reality experiences. The key component of Haptic-go-round is a motorized turntable that rotates the correct haptic device to the right direction at the right time to match what users are about to touch. We implemented a working platform including plug-and-play prop cartridges and a software interface that allow experience designers to agilely add their haptic components and use the platform for their applications. We conducted technical experiments and two user studies on Haptic-go-round to evaluate its performance. We report the results and discuss our insights and limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {virtual reality, encounter-type haptic feedback, props},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376354,
author = {Kotut, Lindah and Bhatti, Neelma and Saaty, Morva and Haqq, Derek and Stelter, Timothy L. and McCrickard, D. Scott},
title = {Clash of Times: Respectful Technology Space for Integrating Community Stories in Intangible Exhibits},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376354},
doi = {10.1145/3313831.3376354},
abstract = {Emerging research in Human Computer Interaction (HCI) has considered the use of technology to preserve Intangible Cultural Heritage (ICH) while wrestling with the dilemma of local participation in the face of post-colonialism. There remains a need to understand how ICH is portrayed by museums and texts, how communities regard these representations, and how technology would affect preservation. We conducted a study in the North Rift region of Kenya to understand how ICH is preserved and disseminated by the museum in comparison with the community. The findings describe a respectful technology space where community needs and museum needs can co-exist. We also articulate social challenges that should be considered by designers when recommending or designing technological solutions. This paper concludes by recommending ways for researchers to smoothly integrate technology with ICH through community participation and an awareness of the respectful space.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {post-colonial computing, indigenous knowledge, intangible cultural heritage, respectful technology, hci4d},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376235,
author = {Zhang, Xiong and Engel, Jonathan and Evensen, Sara and Li, Yuliang and Demiralp, \c{C}a\u{g}atay and Tan, Wang-Chiew},
title = {Teddy: A System for Interactive Review Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376235},
doi = {10.1145/3313831.3376235},
abstract = {Reviews are integral to e-commerce services and products. They contain a wealth of information about the opinions and experiences of users, which can help better understand consumer decisions and improve user experience with products and services. Today, data scientists analyze reviews by developing rules and models to extract, aggregate, and understand information embedded in the review text. However, working with thousands of reviews, which are typically noisy incomplete text, can be daunting without proper tools. Here we first contribute results from an interview study that we conducted with fifteen data scientists who work with review text, providing insights into their practices and challenges. Results suggest data scientists need interactive systems for many review analysis tasks. Towards a solution, we then introduce Teddy, an interactive system that enables data scientists to quickly obtain insights from reviews and improve their extraction and modeling pipelines.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sentiment analysis, schema generation, review analysis, interactive systems, data science, contextual interviews, visualization, text mining},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376592,
author = {Chen, Yuan and Katsuragawa, Keiko and Lank, Edward},
title = {Understanding Viewport- and World-Based Pointing with Everyday Smart Devices in Immersive Augmented Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376592},
doi = {10.1145/3313831.3376592},
abstract = {Personal smart devices have demonstrated a variety of efficient techniques for pointing and selecting on physical displays. However, when migrating these input techniques to augmented reality, it is both unclear what the relative performance of different techniques will be given the immersive nature of the environment, and it is unclear how viewport-based versus world-based pointing methods will impact performance. To better understand the impact of device and viewing perspectives on pointing in augmented reality, we present the results of two controlled experiments comparing pointing conditions that leverage various smartphone- and smartwatch-based external display pointing techniques and examine viewport-based versus world-based target acquisition paradigms. Our results demonstrate that viewport-based techniques offer faster selection and that both smartwatch- and smartphone-based pointing techniques represent high-performance options for performing distant target acquisition tasks in augmented reality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {augmented reality, mobile devices, 3D pointing, input devices, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376499,
author = {Tuncer, Sylvaine and Brown, Barry},
title = {E-Scooters on the Ground: Lessons for Redesigning Urban Micro-Mobility},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376499},
doi = {10.1145/3313831.3376499},
abstract = {The worldwide deployment of rental electric scooters has generated new opportunities for urban mobility, but also intensified conflict over public space. This article reports on an ethnographic study of both rental and privately-owned e-scooters, mapping out the main problems and potentials around this new form of 'micro-mobility'. While it suffers from problems of reliability and conflict, user experience is an important part of e-scooters' appeal, an enjoyable way of 'hacking the city'. E-scooters have a hybrid character: weaving through the city, riders can switch between riding as a pedestrian, a car or a bicycle. Building on these results, we discuss how e-scooters, ridesharing services, and their apps could develop further, alongside the role for HCI in re-thinking urban transport and vehicle design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {user experience, micro-mobility, co-ordination in mobile interactions, intermodal mobility, electric scooters, vehicle design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376497,
author = {Walker, Ashley Marie and DeVito, Michael A.},
title = {"'More Gay' Fits in Better": Intracommunity Power Dynamics and Harms in Online LGBTQ+ Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376497},
doi = {10.1145/3313831.3376497},
abstract = {Online spaces play crucial roles in the lives of most LGBTQ+ people, but can also replicate and exacerbate existing intracommunity tensions and power dynamics, potentially harming subgroups within this marginalized community. Using qualitative probes and interviews, we engaged a diverse group of 25 bi+ (attracted to more than one gender) people to explore these dynamics. We identify two types of intracommunity conflict that bi+ users face (validity and normative conflicts), and a resulting set of what we call latent harms, or coping strategies for dealing with conflict that have delayed negative psychological effects for bi+ users. Using intersectionality as a sensitizing concept to understand shifting power dynamics embedded in sociotechnical contexts, we discuss challenges for future design work including the need to account for intracommunity dynamics within marginalized groups and the utility of disentangling conflict from harm.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {pansexuality, social media, online communities, power dynamics, intersectionality, harm, conflict, bisexuality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376188,
author = {Robinson, Charlotte and Brul\'{e}, Emeline and Jackson, James and Torjussen, Alice and Kybett, Joshua and Appshaw, Tom},
title = {Tricks and Treats: Designing Technology to Support Mobility Assistance Dogs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376188},
doi = {10.1145/3313831.3376188},
abstract = {Assistance dogs are a key intervention to support the autonomy of people with tetraplegia. Previous research on assistive technologies have investigated ways to, ultimately, replace their labour using technology, for instance through the design of smart home environments. However, both the disability studies literature and our interviews suggest there is an immediate need to support these relationships, both in terms of training and bonding. Through a case study of an accessible dog treats dispenser, we investigate a technological intervention responding to these needs, detailing an appropriate design methodology and contributing insights into user requirements and preferences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {assistance dog, assistive technology, service dog, tetraplegia, disability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376340,
author = {Mayer, Sven and Reinhardt, Jens and Schweigert, Robin and Jelke, Brighten and Schwind, Valentin and Wolf, Katrin and Henze, Niels},
title = {Improving Humans' Ability to Interpret Deictic Gestures in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376340},
doi = {10.1145/3313831.3376340},
abstract = {Collaborative Virtual Environments (CVEs) offer unique opportunities for human communication. Humans can interact with each other over a distance in any environment and visual embodiment they want. Although deictic gestures are especially important as they can guide other humans' attention, humans make systematic errors when using and interpreting them. Recent work suggests that the interpretation of vertical deictic gestures can be significantly improved by warping the pointing arm. In this paper, we extend previous work by showing that models enable to also improve the interpretation of deictic gestures at targets all around the user. Through a study with 28 participants in a CVE, we analyzed the errors users make when interpreting deictic gestures. We derived a model that rotates the arm of a pointing user's avatar to improve the observing users' accuracy. A second study with 24 participants shows that we can improve observers' accuracy by 22.9%. As our approach is not noticeable for users, it improves their accuracy without requiring them to learn a new interaction technique or distracting from the experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, correction model, deictic, ray tracing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376211,
author = {Andrade, Ronny and Rogerson, Melissa J. and Waycott, Jenny and Baker, Steven and Vetere, Frank},
title = {Introducing the Gamer Information-Control Framework: Enabling Access to Digital Games for People with Visual Impairment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376211},
doi = {10.1145/3313831.3376211},
abstract = {In this paper, we present a foundation for understanding the elements that enable people with visual impairment to engage with digital games. This is defined by the gamer's relation- ships with information and with elements of control provided by the game, and is mediated through in-game metaphors and affordances when gamers interact as users or creators. This work complements previous research exploring the points of view of gamers with visual impairment by focusing on the games they play and prioritising the relationships between the key enablers of access to digital games. Using the framework to examine existing and missing components will enable de- signers to consider broader aspects of accessibility in game design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {information, digital games, control, audiogames, visual impairment, framework},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376182,
author = {Taber, Lee and Whittaker, Steve},
title = {"On Finsta, I Can Say 'Hail Satan'": Being Authentic but Disagreeable on Instagram},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376182},
doi = {10.1145/3313831.3376182},
abstract = {We use personality theory to compare self-presentation between multiple Instagram accounts, investigating authenticity and consistency. Many studies claim social media promote inauthentic self-presentation focused on socially desirable traits. At the same time, affordances suggest that self-presentation should be relatively consistent within one social medium. For 88 participants, we examine personality traits for 'real Instagram' ('Rinsta') versus 'fake Instagram' ('Finsta') accounts, comparing these with people's offline traits using mixed-methods. Counterintuitively, we find Finsta accounts often present socially undesirable traits. Furthermore, different accounts on the same social medium reveal quite different styles of self-presentation. Overall Finstas are more Extraverted, less Conscientious, and less Agreeable than Rinstas, although equally Neurotic as offline. Interviews indicate trait differences arise from differing audience perceptions. A large anonymous Rinsta audience promotes a carefully curated self. In contrast, a small but trusted Finsta audience can engender more authentic, but negative self-presentation. We discuss design and theory implications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {rinsta, self-presentation, traits, finsta, personality, affordances, self-perception, instagram, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376282,
author = {Blank, Christopher and Zaman, Shaila and Wesley, Amanveer and Tsiamyrtzis, Panagiotis and Da Cunha Silva, Dennis R. and Gutierrez-Osuna, Ricardo and Mark, Gloria and Pavlidis, Ioannis},
title = {Emotional Footprints of Email Interruptions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376282},
doi = {10.1145/3313831.3376282},
abstract = {Working in an environment with constant interruptions is known to affect stress, but how do interruptions affect emotional expression? Emotional expression can have significant impact on interactions among coworkers. We analyzed the video of 26 participants who performed an essay task in a laboratory while receiving either continual email interruptions or receiving a single batch of email. Facial videos of the participants were run through a convolutional neural network to determine the emotional mix via decoding of facial expressions. Using a novel co-occurrence matrix analysis, we showed that with batched email, a neutral emotional state is dominant with sadness being a distant second, and with continual interruptions, this pattern is reversed, and sadness is mixed with fear. We discuss the implications of these results for how interruptions can impact employees' well-being and organizational climate.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {convolutional neural network, emotions, email interruptions, co-occurence matrix, facial expressions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376623,
author = {Marcu, Gabriela and Spiller, Allison N.},
title = {Collaborative Aspects of Collecting and Reflecting on Behavioral Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376623},
doi = {10.1145/3313831.3376623},
abstract = {Direct observation of behavior provides a unique type of data for reflecting on during a process of behavioral intervention. This study focuses on practitioners who specialize in operationalizing, recording, and monitoring behavior using data collection through paper-and-pencil or, increasingly, mobile computing. Applying an action research approach, we conducted fieldwork to understand observational data collection among practitioners providing children with special education support for behavioral needs. We present a model of collaborative data collection, which describes how practices are situated in the process of collecting data that are useful for reflection by teams of practitioners. We discuss how computer-assisted data collection could promote more systematic and rigorous practices, and design considerations for the collaborative aspects of collecting and reflecting on behavioral data. This study builds on research describing the practices of individuals who track their own behavioral data, and improves our understanding of informal documentation practices in organizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {behavioral intervention, action research, computer-assisted data collection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376558,
author = {Tsenova, Violeta and Wood, Gavin and Dolfini, Andrea and Tindley, Annie and Kirk, David},
title = {Un-Authorised View: Leveraging Volunteer Expertise in Heritage},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376558},
doi = {10.1145/3313831.3376558},
abstract = {Volunteers are an underused but important resource in presenting plural heritages within large heritage organizations. We report on a qualitative study at a heritage site in the UK which combined explorations of volunteers' practice and digital design. The study comprised of observational fieldwork with co-creative activities across eight linked workshops, where we explored the site with volunteers, and how we might leverage existing working structures to make new design prototypes. Our collective account contributes new insights on working with volunteers and the opportunities that arise from acknowledging them as genius loci - recognising them as experts of their own experience and capturing and supporting their skills as storytellers. Working with the volunteering staff in a co-design process we created innovative designs including our Un-authorised View, which draws out the unique perspectives and the personal stories at heritage destinations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {critical heritage, cultural probes, plural heritages, vr design, digital storytelling, genius loci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376155,
author = {Subramonyam, Hariharan and Seifert, Colleen and Shah, Priti and Adar, Eytan},
title = {TexSketch: Active Diagramming through Pen-and-Ink Annotations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376155},
doi = {10.1145/3313831.3376155},
abstract = {Learning from text is a constructive activity in which sentence-level information is combined by the reader to build coherent mental models. With increasingly complex texts, forming a mental model becomes challenging due to a lack of background knowledge, and limits in working memory and attention. To address this, we are taught knowledge externalization strategies such as active reading and diagramming. Unfortunately, paper-and-pencil approaches may not always be appropriate, and software solutions create friction through difficult input modalities, limited workflow support, and barriers between reading and diagramming. For all but the simplest text, building coherent diagrams can be tedious and difficult. We propose Active Diagramming, an approach extending familiar active reading strategies to the task of diagram construction. Our prototype, texSketch, combines pen-and-ink interactions with natural language processing to reduce the cost of producing diagrams while maintaining the cognitive effort necessary for comprehension. Our user study finds that readers can effectively create diagrams without disrupting reading.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {active reading, pen-and-ink gestures, diagramming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376696,
author = {Vezzoli, Yvonne and Kalantari, Sara and Kucirkova, Natalia and Vasalou, Asimina},
title = {Exploring the Design Space for Parent-Child Reading},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376696},
doi = {10.1145/3313831.3376696},
abstract = {Given the significant potential of shared book reading to promote children's learning, the design of e-books has focused on maximising this learning experience. However, recent studies have begun to show that shared reading is a broader opportunity for the family to spend quality time together. Our study aims to explore this perspective further, focusing on the types of parent-child interactions during shared reading and the ways in which shared reading may foster intimacy when parents and children read digital books. We used cultural probes and contextual interviews to capture the shared reading experiences of 7 parents and 6 children in their homes. We discuss the different nuances of the shared reading practices identified. We use these findings to suggest new design opportunities that support the complex practices of shared reading with technologies at home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {families, parent-child reading, shared reading, cultural probes, digital books},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376813,
author = {Wang, Ruotong and Harper, F. Maxwell and Zhu, Haiyi},
title = {Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376813},
doi = {10.1145/3313831.3376813},
abstract = {Algorithmic decision-making systems are increasingly used throughout the public and private sectors to make important decisions or assist humans in making these decisions with real social consequences. While there has been substantial research in recent years to build fair decision-making algorithms, there has been less research seeking to understand the factors that affect people's perceptions of fairness in these systems, which we argue is also important for their broader acceptance. In this research, we conduct an online experiment to better understand perceptions of fairness, focusing on three sets of factors: algorithm outcomes, algorithm development and deployment procedures, and individual differences. We find that people rate the algorithm as more fair when the algorithm predicts in their favor, even surpassing the negative effects of describing algorithms that are very biased against particular demographic groups. We find that this effect is moderated by several variables, including participants' education level, gender, and several aspects of the development procedure. Our findings suggest that systems that evaluate algorithmic fairness through users' feedback must consider the possibility of "outcome favorability" bias.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {algorithmic decision-making, perceived fairness, algorithm development, algorithmoutcome},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376516,
author = {Zhao, Yuhang and Kupferstein, Elizabeth and Rojnirun, Hathaitorn and Findlater, Leah and Azenkot, Shiri},
title = {The Effectiveness of Visual and Audio Wayfinding Guidance on Smartglasses for People with Low Vision},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376516},
doi = {10.1145/3313831.3376516},
abstract = {Wayfinding is a critical but challenging task for people who have low vision, a visual impairment that falls short of blindness. Prior wayfinding systems for people with visual impairments focused on blind people, providing only audio and tactile feedback. Since people with low vision use their remaining vision, we sought to determine how audio feedback compares to visual feedback in a wayfinding task. We developed visual and audio wayfinding guidance on smartglasses based on de facto standard approaches for blind and sighted people and conducted a study with 16 low vision participants. We found that participants made fewer mistakes and experienced lower cognitive load with visual feedback. Moreover, participants with a full field of view completed the wayfinding tasks faster when using visual feedback. However, many participants preferred audio feedback because of its shorter learning curve. We propose design guidelines for wayfinding systems for low vision.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {audio feedback, visual feedback, wayfinding, augmented reality, low vision, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376512,
author = {Preechayasomboon, Pornthep and Israr, Ali and Samad, Majed},
title = {Chasm: A Screw Based Expressive Compact Haptic Actuator},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376512},
doi = {10.1145/3313831.3376512},
abstract = {We present a compact broadband linear actuator, Chasm, that renders expressive haptic feedback on wearable and handheld devices. Unlike typical motor-based haptic devices with integrated gearheads, Chasm utilizes a miniature leadscrew coupled to a motor shaft, thereby directly translating the high-speed rotation of the motor to the linear motion of a nut carriage without an additional transmission. Due to this simplicity, Chasm can render low-frequency skin-stretch and high-frequency vibrations, simultaneously and independently. We present the design of the actuator assembly and validate its electromechanical and perceptual performance. We then explore use cases and show design solutions for embedding Chasm in device prototypes. Finally, we report investigations with Chasm in two VR embodiments, i.e., in a headgear band to induce locomotion cues and in a handheld pointer to enhance dynamic manual interactions. Our explorations show wide use for Chasm in enhancing user interactions and experience in virtual and augmented settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {haptic devices, skin stretch, handheld haptics, wearable haptics, multidimensional haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376466,
author = {Pu, Xiaoying and Kay, Matthew},
title = {A Probabilistic Grammar of Graphics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376466},
doi = {10.1145/3313831.3376466},
abstract = {Visualizations depicting probabilities and uncertainty are used everywhere from medical risk communication to machine learning, yet these probabilistic visualizations are difficult to specify, prone to error, and their designs are cumbersome to explore. We propose a Probabilistic Grammar of Graphics (PGoG), an extension to Wilkinson's original framework. Inspired by the success of probabilistic programming languages, PGoG makes probability expressions, such as P(A|B), a first-class citizen in the language. PGoG abstractions also reflect the distinction between probability and frequency framing, a concept from the uncertainty communication literature. It is expressive, encompassing product plots, density plots, icon arrays, and dotplots, among other visualizations. Its coherent syntax ensures correctness (that the proportions of visual elements and their spatial placement reflect the underlying probability distribution) and reduces edit distance between probabilistic visualization specifications, potentially supporting more design exploration. We provide a proof-of-concept implementation of PGoG in R.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {uncertainty visualization, grammar of graphics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376352,
author = {Mironcika, Svetlana and Hupfeld, Annika and Frens, Joep and Wensveen, Stephan},
title = {I Am Not an Object: Reframing 3D Body Scanning for Co-Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376352},
doi = {10.1145/3313831.3376352},
abstract = {3D scanning technologies provide designers with tools to generate a digital representation of the human body that can be used in the design of ultra-personalized apparel and wearables. However, prior work shows that the body scanning process can be an uncomfortable experience for users. In this work, we take a first-person perspective to identify frictions in the experience of being body scanned compared to having one's body measurements taken by a professional tailor. Based on our findings, we offer a reframing of body scanning as a collaborative process, and discuss implications for the design of tools and processes that shift agency in the generation of body data towards users. Our paper is relevant to design researchers and practitioners interested in taking a co-design approach to ultra-personalization.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {autoethnography, 3d body data visualization, wearables, co-design, personal data., 3d body scanning, personalization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376574,
author = {Freiwald, Jann Philipp and Ariza, Oscar and Janeh, Omar and Steinicke, Frank},
title = {Walking by Cycling: A Novel In-Place Locomotion User Interface for Seated Virtual Reality Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376574},
doi = {10.1145/3313831.3376574},
abstract = {We introduce VR Strider, a novel locomotion user interface (LUI) for seated virtual reality (VR) experiences, which maps cycling biomechanics of the user's legs to virtual walking movements. The core idea is to translate the motion of pedaling on a mini exercise bike to a corresponding walking animation of a virtual avatar while providing audio-based tactile feedback on virtual ground contacts. We conducted an experiment to evaluate the LUI and our novel anchor-turning rotation control method regarding task performance, spatial cognition, VR sickness, sense of presence, usability and comfort in a path-integration task. The results show that VR Strider has a significant positive effect on the participants' angular and distance estimation, sense of presence and feeling of comfort compared to other established locomotion techniques, such as teleportation and joystick-based navigation. A confirmatory study further indicates the necessity of synchronized avatar animations for virtual vehicles that rely on pedalling.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {locomotion, input techniques, virtual reality, embodied interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376833,
author = {Stowell, Elizabeth and O'Leary, Teresa K. and Kimani, Everlyne and Paasche-Orlow, Michael K. and Bickmore, Timothy and Parker, Andrea G.},
title = {Investigating Opportunities for Crowdsourcing in Church-Based Health Interventions: A Participatory Design Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376833},
doi = {10.1145/3313831.3376833},
abstract = {Churches play a major role in providing social support to address health inequities within Black communities, in part by connecting members to key organizations and services. While public health has a history of disseminating interventions in faith communities, little work has explored the use of crowdsourcing to tailor interventions to the unique culture of each church community. Following Community Based Participatory Research principles, we partnered with two predominantly Black churches, and report on a series of three participatory design sessions with nine participants. We developed a novel storyboarding method to explore how crowdsourcing could promote health in these faith-based communities. Our findings characterize existing supports within the church community, and how church social structures impact member access to these supports. We further identify motivations to engage with a church-situated health application, and how these motivations translate to crowdsourcing tasks. Finally, we discuss considerations for public health crowdsourcing tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {african-american, crowdsourcing, faith-based communities, participatory design, health promotion, mhealth},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376141,
author = {Damen, Ida and Lallemand, Carine and Brankaert, Rens and Brombacher, Aarnout and van Wesemael, Pieter and Vos, Steven},
title = {Understanding Walking Meetings: Drivers and Barriers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376141},
doi = {10.1145/3313831.3376141},
abstract = {There is increased interest in reducing sedentary behavior of office workers to combat the negative health effects of prolonged sitting. Walking meetings offer a promising solution to this problem as they facilitate a physically active way of working. To inform future development of technologies supporting these type of meetings, in-depth qualitative insights into people's experiences of walking meetings are needed. We conducted semi-structured walking interviews (N=16) to identify key drivers and barriers for walking meetings in a living lab setting by using the 'WorkWalk'. The 'WorkWalk' is a 1.8 km walking route indicated by a dotted blue line with outdoor meeting points, integrated into the room booking system. Our findings provide insights into how walking meetings are experienced and affect the set-up and social dynamics of meetings. We offer design recommendations for the development of future technologies and service design elements to support walking meetings and active ways of working.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design research, field study, sedentary behavior, walking meetings, office workers, physical activity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376485,
author = {Gathani, Sneha and Lim, Peter and Battle, Leilani},
title = {Debugging Database Queries: A Survey of Tools, Techniques, and Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376485},
doi = {10.1145/3313831.3376485},
abstract = {Database management systems (or DBMSs) have been around for decades, and yet are still difficult to use, particularly when trying to identify and fix errors in user programs (or queries). We seek to understand what methods have been proposed to help people debug database queries, and whether these techniques have ultimately been adopted by DBMSs (and users). We conducted an interdisciplinary review of 112 papers and tools from the database, visualisation and HCI communities. To better understand whether academic and industry approaches are meeting the needs of users, we interviewed 20 database users (and some designers), and found surprising results. In particular, there seems to be a wide gulf between users' debugging strategies and the functionality implemented in existing DBMSs, as well as proposed in the literature. In response, we propose new design guidelines to help system designers to build features that more closely match users debugging strategies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {survey, debugging databases, literature review, visualization, empirical study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376568,
author = {Bennett, Cynthia L. and Rosner, Daniela K. and Taylor, Alex S.},
title = {The Care Work of Access},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376568},
doi = {10.1145/3313831.3376568},
abstract = {Current approaches to AI and Assistive Technology (AT) often foreground task completion over other encounters such as expressions of care. Our paper challenges and complements such task-completion approaches by attending to the care work of access-the continual affective and emotional adjustments that people make by noticing and attending to one another. We explore how this work impacts encounters among people with and without vision impairments who complete tasks together. We find that bound up in attempts to get things done are concerns for one another and how well people are doing together. Reading this work through emerging disability studies and feminist STS scholarship, we account for two important forms of work that give rise to access: (1) mundane attunements and (2) non-innocent authorizations. Together these processes work as sensitizing concepts to help HCI scholars account for the ways that intelligent ATs both produce access while sometimes subverting people with disabilities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {blind, vision impaired, assistance, interdependence, disability, care, artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376272,
author = {Sheshadri, Smitha and Zhao, Shengdong and Chen, Yang and Fjeld, Morten},
title = {Learn with Haptics: Improving Vocabulary Recall with Free-Form Digital Annotation on Touchscreen Mobiles},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376272},
doi = {10.1145/3313831.3376272},
abstract = {Mobile vocabulary learning interfaces typically present material only in auditory and visual channels, underutilizing the haptic modality. We explored haptic-integrated learning by adding free-form digital annotation to mobile vocabulary learning interfaces. Through a series of pilot studies, we identified three design factors: annotation mode, presentation sequence, and vibrotactile feedback, that influence recall in haptic-integrated vocabulary interfaces. These factors were then evaluated in a within-subject comparative study using a digital flashcard interface as baseline. Results using a 84-item vocabulary showed that the 'whole word' annotation mode is highly effective, yielding a 24.21% increase in immediate recall scores and a 30.36% increase in the 7-day delayed scores. Effects of presentation sequence and vibrotactile feedback were more transient; they affected the results of immediate tests, but not the delayed tests. We discuss the implications of these factors for designing future mobile learning applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile vocabulary learning, intersensory reinforced learning, motoric engagement, multimodal learning, haptics for learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376150,
author = {Warner, Mark and Kitkowska, Agnieszka and Gibbs, Jo and Maestre, Juan F. and Blandford, Ann},
title = {Evaluating 'Prefer Not to Say' Around Sensitive Disclosures},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376150},
doi = {10.1145/3313831.3376150},
abstract = {As people's offline and online lives become increasingly entwined, the sensitivity of personal information disclosed online is increasing. Disclosures often occur through structured disclosure fields (e.g., drop-down lists). Prior research suggests these fields may limit privacy, with non-disclosing users being presumed to be hiding undesirable information. We investigated this around HIV status disclosure in online dating apps used by men who have sex with men. Our online study asked participants (N=183) to rate profiles where HIV status was either disclosed or undisclosed. We tested three designs for displaying undisclosed fields. Visibility of undisclosed fields had a significant effect on the way profiles were rated, and other profile information (e.g., ethnicity) could affect inferences that develop around undisclosed information. Our research highlights complexities around designing for non-disclosure and questions the voluntary nature of these fields. Further work is outlined to ensure disclosure control is appropriately implemented around online sensitive information disclosures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {privacy unraveling, online dating, disclosure, online privacy, structured disclosure fields, privacy, non-disclosure, prefer not to say},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376825,
author = {Agrawal, Ankit and Abraham, Sophia J. and Burger, Benjamin and Christine, Chichi and Fraser, Luke and Hoeksema, John M. and Hwang, Sarah and Travnik, Elizabeth and Kumar, Shreya and Scheirer, Walter and Cleland-Huang, Jane and Vierhauser, Michael and Bauer, Ryan and Cox, Steve},
title = {The Next Generation of Human-Drone Partnerships: Co-Designing an Emergency Response System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376825},
doi = {10.1145/3313831.3376825},
abstract = {The use of semi-autonomous Unmanned Aerial Vehicles (UAV) to support emergency response scenarios, such as fire surveillance and search and rescue, offers the potential for huge societal benefits. However, designing an effective solution in this complex domain represents a "wicked design" problem, requiring a careful balance between trade-offs associated with drone autonomy versus human control, mission functionality versus safety, and the diverse needs of different stakeholders. This paper focuses on designing for situational awareness (SA) using a scenario-driven, participatory design process. We developed SA cards describing six common design-problems, known as SA demons, and three new demons of importance to our domain. We then used these SA cards to equip domain experts with SA knowledge so that they could more fully engage in the design process. We designed a potentially reusable solution for achieving SA in multi-stakeholder, multi-UAV, emergency response applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {participatory design, emergency response, situational awareness, human-CPS interactions, unmanned aerial vehicles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376571,
author = {Mohaddesi, Omid and Sun, Yifan and Azghandi, Rana and Doroudi, Rozhin and Snodgrass, Sam and Ergun, Ozlem and Griffin, Jacqueline and Kaeli, David and Marsella, Stacy and Harteveld, Casper},
title = {Introducing Gamettes: A Playful Approach for Capturing Decision-Making for Informing Behavioral Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376571},
doi = {10.1145/3313831.3376571},
abstract = {Agent-based simulations are widely used for modeling human behavior in various contexts. However, such simulations may oversimplify human decision-making. We propose the use of Gamettes to extract rich data on human decision-making and help in improving the human behavioral aspects of models underlying agent-based simulations. We show how Gamettes are designed and provide empirical validation for using Gamettes in an experimental supply chain setting to study human decision-making. Our results show that Gamettes are successful in capturing the expected behaviors and patterns in supply chain decisions, and, thus, we find evidence for the capability of Gamettes to inform behavioral models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gamette, simulation, beer game, decision-making, supply chain, agent-based model, human behavior},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376241,
author = {Heyer, Jeremy and Schmitt, Zachary and Dombrowski, Lynn and Yarosh, Svetlana},
title = {Opportunities for Enhancing Access and Efficacy of Peer Sponsorship in Substance Use Disorder Recovery},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376241},
doi = {10.1145/3313831.3376241},
abstract = {Substance use disorders (SUDs) are characterized by an inability to decrease a substance use (e.g., alcohol or opioids) despite negative repercussions. SUDs are clinically diagnosable, hazardous, and considered a public health issue. Sponsorship, a specialized type of peer mentorship, is vital in the recovery process and originates from 12-step fellowship programs such as Alcoholics Anonymous (AA) and Narcotics Anonymous (NA). To investigate sponsorship relationship practices and to identify design opportunities for digitally-mediated peer support, we conducted 27 in-depth interviews with members of AA and NA. We identified five key sponsorship relationship practices relevant for designing social computing tools to support sponsorship and recovery: 1) assessing dyadic compatibility, 2) managing sponsorship with or without technology, 3) establishing boundaries, 4) building a peer support network, and 5) managing anonymity. We identify social computing and digitally-mediated design opportunities and implications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {technology for substance use, substance use disorders, recovery, peer health support, 12-step fellowships, addiction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376662,
author = {Shipman, Frank M. and Marshall, Catherine C.},
title = {Ownership, Privacy, and Control in the Wake of Cambridge Analytica: The Relationship between Attitudes and Awareness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376662},
doi = {10.1145/3313831.3376662},
abstract = {Has widespread news of abuse changed the public's perceptions of how user-contributed content from social networking sites like Facebook and LinkedIn can be used? We collected two datasets that reflect participants' attitudes about content ownership, privacy, and control, one in April 2018, while Cambridge Analytica was still in the news, and another in February 2019, after the event had faded from the headlines, and aggregated the data according to participants' awareness of the story, contrasting the attitudes of those who reported the greatest awareness with those who reported the least. Participants with the greatest awareness of the news story's details have more polarized attitudes about reuse, especially the reuse of content as data. They express a heightened desire for data mobility, greater concern about networked privacy rights, increased skepticism of algorithmically targeted advertising and news, and more willingness for social media platforms to demand corrections of inaccurate or deceptive content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data use, linkedin, social media attitudes, ownership, data monetization, privacy, facebook, cambridge analytica},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376215,
author = {Watson, Colin and Kirkham, Reuben and Kharrufa, Ahmed},
title = {PIP Kit: An Exploratory Investigation into Using Lifelogging to Support Disability Benefit Claimants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376215},
doi = {10.1145/3313831.3376215},
abstract = {Disability assessment processes are complex and stressful, with claimants finding it challenging to prepare an effective account of their disabilities to support their claim. This project focuses on a disability benefit called Personal Independence Payment (PIP), which is received by millions of people with disabilities in the UK. We present a multi-stage exploratory investigation into how lifelogging could help address the challenges claimants have in accessing disability benefits. In the first study, benefit advisors participated in interviews and workshops to inform the design of PIP Kit, a highly customisable prototype elicitation diary to help disability claimants articulate their experiences. In the second study, PIP Kit was trialled by benefit claimants whilst making their actual PIP claims. We found that PIP Kit helped empower claimants in understanding the claim process and assisted in building arguments for their claims. We also have identified clear principles for supporting disability benefit claimants with technological interventions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {accessibility, social security, disability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376370,
author = {Honary, Mahsa and Bell, Beth and Clinch, Sarah and Vega, Julio and Kroll, Leo and Sefi, Aaron and McNaney, Roisin},
title = {Shaping the Design of Smartphone-Based Interventions for Self-Harm},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376370},
doi = {10.1145/3313831.3376370},
abstract = {Self-harm is a prevalent issue amongst young people, yet it is thought around 40% will never seek professional help due to stigma surrounding it. It is generally a way of coping with emotional distress and can have a range of triggers which are highly heterogeneous to the individual. In a move towards enhancing the accessibility of personalized interventions for self-harm, we undertook a three-stage study. We first conducted interviews with 4 counsellors in self-harm to understand how they clinically respond to self-harm triggers. We then ran a survey with 37 young people, to explore perceptions of mobile sensing, and current and future uses for smartphone-based interventions. Finally, we ran a workshop with 11 young people to further explore how a context-aware self-management application might be used to support them. We contribute an in-depth understanding of how triggers for self-harm might be identified and subsequently predicted and prevented using mobile-sensing technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {situation-aware app, mobile sensing, trust, non-suicidal self-injury, mental health, intervention, co-design, self-harm},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376295,
author = {Gadiraju, Vinitha and Muehlbradt, Annika and Kane, Shaun K.},
title = {BrailleBlocks: Computational Braille Toys for Collaborative Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376295},
doi = {10.1145/3313831.3376295},
abstract = {Braille literacy has fallen in recent years, and many blind children now grow up without learning Braille. However, learning Braille can increase employment chances and improve literacy skills. We introduce BrailleBlocks, a system to help visually impaired children learn and practice Braille alongside a sighted parent. BrailleBlocks comprises a set of tangible blocks and pegs, each block representing a Braille cell, and an associated application with games. The system automatically tracks and recognizes the blocks so that parents can follow along even if they cannot read Braille. We conducted a user study to test BrailleBlocks with five families, with five parents and six visually impaired children. The contributions of this work are a novel approach to Braille education toys, observations of how visually impaired children and sighted parents used this system together, their insights on current issues with Braille educational tools, and actionable feedback for future Braille-based learning tools.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {accessibility, visually impaired, education, children, collaboration, braille, blind},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376331,
author = {Zarei, Niloofar and Chu, Sharon Lynn and Quek, Francis and Rao, Nanjie 'Jimmy' and Brown, Sarah Anne},
title = {Investigating the Effects of Self-Avatars and Story-Relevant Avatars on Children's Creative Storytelling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376331},
doi = {10.1145/3313831.3376331},
abstract = {Storytelling is a critical step in the cognitive development of children. Particularly, this requires children to mentally project into the story context and to identify with the thoughts of the characters in their stories. We propose to support free imagination in creative storytelling through an enactment-based approach that allows children to embody an avatar and perform as the story character. We designed our story creation interface with two modes of avatar: the story-relevant avatar and the self-avatar, to investigate the effects of avatar design on the quality of children's creative products. In our study with 20 child participants, the results indicate that self-avatars can create a stronger sense of identification and embodied presence, while story-relevant avatars can provide a scaffold for mental projection.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {virtual reality, storytelling, expressive writing, creativity, embodied interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376444,
author = {Chatterjee, Soujanya and Rahman, Md Mahbubur and Ahmed, Tousif and Saleheen, Nazir and Nemati, Ebrahim and Nathan, Viswam and Vatanparvar, Korosh and Kuang, Jilong},
title = {Assessing Severity of Pulmonary Obstruction from Respiration Phase-Based Wheeze-Sensing Using Mobile Sensors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376444},
doi = {10.1145/3313831.3376444},
abstract = {Obstructive pulmonary diseases cause limited airflow from the lung and severely affect patients' quality of life. Wheeze is one of the most prominent symptoms for them. High requirements imposed by traditional diagnosis methods make regular monitoring of pulmonary obstruction challenging, which hinders the opportunity of early intervention and prevention of significant exacerbation. In this work, we explore the feasibility of developing a mobile sensor-based system as a convenient means of assessing the severity of pulmonary obstruction via respiration phase-based symptomatic wheeze sensing. We conduct a 131 subjects' (91 patients and 40 healthy) study for the detection (F1: 87.96%) and characterization (F1: 79.47%) of wheeze. Subsequently, we develop novel wheeze metrics, which show a significant correlation (Pearson's correlation: -0.22, p-value: 0.024) with standard spirometry measure of pulmonary obstruction severity. This work takes a principal step towards the unobtrusive assessment of pulmonary condition from mobile sensor interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile application, pulmonary monitoring, mobile health (mhealth), wheezing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376442,
author = {Drosos, Ian and Barik, Titus and Guo, Philip J. and DeLine, Robert and Gulwani, Sumit},
title = {Wrex: A Unified Programming-by-Example Interaction for Synthesizing Readable Code for Data Scientists},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376442},
doi = {10.1145/3313831.3376442},
abstract = {Data wrangling is a difficult and time-consuming activity in computational notebooks, and existing wrangling tools do not fit the exploratory workflow for data scientists in these environments. We propose a unified interaction model based on programming-by-example that generates readable code for a variety of useful data transformations, implemented as a Jupyter notebook extension called Wrex. User study results demonstrate that data scientists are significantly more effective and efficient at data wrangling with Wrex over manual programming. Qualitative participant feedback indicates that Wrex was useful and reduced barriers in having to recall or look up the usage of various data transform functions. The synthesized code allowed data scientists to verify the intended data transformation, increased their trust and confidence in Wrex, and fit seamlessly within their cell-based notebook workflows. This work suggests that presenting readable code to professional data scientists is an indispensable component of offering data wrangling tools in notebooks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data science, computational notebooks, program synthesis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376417,
author = {Taranta, Eugene M. and Pittman, Corey R. and Oakley, Jack P. and Maslych, Mykola and Maghoumi, Mehran and LaViola, Joseph J.},
title = {Moving Toward an Ecologically Valid Data Collection Protocol for 2D Gestures In Video Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376417},
doi = {10.1145/3313831.3376417},
abstract = {Those who design gesture recognizers and user interfaces often use data collection applications that enable users to comfortably produce gesture training samples. In contrast, games present unique contexts that impact cognitive load and have the potential to elicit rapid gesticulations as players react to dynamic conditions, which can result in high gesture form variability. However, the extent to which these gestures differ is presently unknown. To this end, we developed two games with unique mechanics, Follow the Leader (FTL) and Sleepy Town, as well as a standard data collection application. We collected gesture samples from 18 participants across all conditions for gestures of varying complexity, and through an analysis using relative, global, and distribution coverage measures, we confirm significant differences between conditions. We discuss the implications of our findings, and show that our FTL design is closer to being an ecologically valid data collection protocol with low implementation complexity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {gestures, follow the leader, games, ecologically validity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376585,
author = {Song, Yunpeng and Huang, Yun and Cai, Zhongmin and Hong, Jason I.},
title = {I'm All Eyes and Ears: Exploring Effective Locators for Privacy Awareness in IoT Scenarios},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376585},
doi = {10.1145/3313831.3376585},
abstract = {With the proliferation of IoT devices, there are growing concerns about being sensed or monitored by these devices unawares, especially in places perceived as private. We explore the design space of IoT locators to help people physically find nearby IoT devices. We first conducted a survey to understand people's willingness, current practices, and challenges in finding IoT devices. Our survey findings motivated us to design and implement low-cost locators (visual, auditory, and contextualized pictures) to help people find nearby devices. Through an iterative design process and two rounds of experiments, we found that these locators greatly reduced people's search time over a baseline of no locators. Many participants found the visual and auditory locators enjoyable. Some participants also appropriated the use of our system for other purposes, e.g., to learn about new IoT devices, instead of for privacy awareness.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {privacy awareness, internet of things, locator},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376416,
author = {Xu, Ying and Warschauer, Mark},
title = {What Are You Talking To?: Understanding Children's Perceptions of Conversational Agents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376416},
doi = {10.1145/3313831.3376416},
abstract = {Conversational agents (CAs) available in smart phones or smart speakers play an increasingly important role in young children's technological landscapes and life worlds. While a handful of studies have documented children's natural interactions with CAs, little is known about children's perceptions of CAs. To fill this gap, we examined three- to six-year-olds' perceptions of CAs' animate/artifact domain membership and properties, as well as their justifications for these perceptions. We found that children sometimes take a more nuanced position and spontaneously attribute both artifact and animate properties to CAs or view them as neither artifacts nor animate objects. This study extends current research on children's perceptions of intelligent artifacts by adding CAs as a new genre of study and provides some underlying knowledge that may guide the development of CAs to support young children's cognitive and social development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {perceptions, conversational agents, child-agent interactions, children, animacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376257,
author = {Mallari, Keri and Inkpen, Kori and Johns, Paul and Tan, Sarah and Ramesh, Divya and Kamar, Ece},
title = {Do I Look Like a Criminal? Examining How Race Presentation Impacts Human Judgement of Recidivism},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376257},
doi = {10.1145/3313831.3376257},
abstract = {Understanding how racial information impacts human decision making in online systems is critical in today's world. Prior work revealed that race information of criminal defendants, when presented as a text field, had no significant impact on users' judgements of recidivism. We replicated and extended this work to explore how and when race information influences users' judgements, with respect to the saliency of presentation. Our results showed that adding photos to the race labels had a significant impact on recidivism predictions for users who identified as female, but not for those who identified as male. The race of the defendant also impacted these results, with black defendants being less likely to be predicted to recidivate compared to white defendants. These results have strong implications for how system-designers choose to display race information, and cautions researchers to be aware of gender and race effects when using Amazon Mechanical Turk workers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-ai collaboration, race, bias, recidivism, legal, crowd work, mechanical turk, gender},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376548,
author = {Hua, Yiqing and Naaman, Mor and Ristenpart, Thomas},
title = {Characterizing Twitter Users Who Engage in Adversarial Interactions against Political Candidates},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376548},
doi = {10.1145/3313831.3376548},
abstract = {Social media provides a critical communication platform for political figures, but also makes them easy targets for harassment. In this paper, we characterize users who adversarially interact with political figures on Twitter using mixed-method techniques. The analysis is based on a dataset of 400 thousand users' 1.2 million replies to 756 candidates for the U.S. House of Representatives in the two months leading up to the 2018 midterm elections. We show that among moderately active users, adversarial activity is associated with decreased centrality in the social graph and increased attention to candidates from the opposing party. When compared to users who are similarly active, highly adversarial users tend to engage in fewer supportive interactions with their own party's candidates and express negativity in their user profiles. Our results can inform the design of platform moderation mechanisms to support political figures countering online harassment.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {political candidates, twitter, online harassment, user behavior},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376249,
author = {Wessely, Michael and Sethapakdi, Ticha and Castillo, Carlos and Snowden, Jackson C. and Hanton, Ollie and Qamar, Isabel P. S. and Fraser, Mike and Roudaut, Anne and Mueller, Stefanie},
title = {Sprayable User Interfaces: Prototyping Large-Scale Interactive Surfaces with Sensors and Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376249},
doi = {10.1145/3313831.3376249},
abstract = {We present Sprayable User Interfaces: room-sized interactive surfaces that contain sensor and display elements created by airbrushing functional inks. Since airbrushing is inherently mobile, designers can create large-scale user interfaces on complex 3D geometries where existing stationary fabrication methods fail. To enable Sprayable User Interfaces, we developed a novel design and fabrication pipeline that takes a desired user interface layout as input and automatically generates stencils for airbrushing the layout onto a physical surface. After fabricating stencils from cardboard or projecting stencils digitally, designers spray each layer with an airbrush, attach a microcontroller to the user interface, and the interface is ready to be used. Our technical evaluation shows that Sprayable User Interfaces work on various geometries and surface materials, such as porous stone and rough wood. We demonstrate our system with several application examples including interactive smart home applications on a wall and a soft leather sofa, an interactive smart city application, and interactive architecture in public office spaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {printed electronics, ubiquitous computing, spraying, airbrush, fabrication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376601,
author = {Zhou, Qian and Wu, Fan and Fels, Sidney and Stavness, Ian},
title = {Closer Object Looks Smaller: Investigating the Duality of Size Perception in a Spherical Fish Tank VR Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376601},
doi = {10.1145/3313831.3376601},
abstract = {Fish Tank Virtual Reality (FTVR) displays provide compelling 3D experiences by rendering view-dependent imagery on a 2D screen. While users perceive a 3D object in space, they are actually looking at pixels on a 2D screen, thus, a perceptual duality exists between the object's pixels and the 3D percept potentially interfering with the experience. To investigate, we conducted an experiment to see whether the on-screen size of the 2D imagery affects the perceived object size in 3D space with different viewing conditions, including stereopsis. We found that the size of on-screen imagery significantly influenced object size perception, causing 83.3% under/overestimation of perceived size when viewing without stereopsis and reducing to 64.7% with stereopsis. Contrary to reality, objects look smaller when the viewer gets closer. Understanding the perceptual duality helps us to provide accurate perception of real-world objects depicted in the virtual environment and pave the way for 3D applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {spherical display, fish tank virtual reality, 3d perception},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376715,
author = {Huang, Chieh-Yang and Huang, Shih-Hong and Huang, Ting-Hao Kenneth},
title = {Heteroglossia: In-Situ Story Ideation with the Crowd},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376715},
doi = {10.1145/3313831.3376715},
abstract = {Ideation is essential for creative writing. Many authors struggle to come up with ideas throughout the writing process, yet modern writing tools fail to provide on-the-spot assistance for writers when they get stuck. This paper introduces Heteroglossia, an add-on for Google Docs that allows writers to elicit story ideas from the online crowd using their text editors. Writers can share snippets of their working drafts and ask the crowd to provide follow-up story ideas based on it. Heteroglossia employs a strategy called "role play", where each worker is assigned a fictional character in a story and asked to brainstorm plot ideas from that character's perspective. Our deployment with two experienced story writers shows that Heteroglossia is easy to use and can generate interesting ideas. Heteroglossia allows us to gain insight into how future technologies can be developed to support ideation in creative writing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ideation, role play, story, creative writing, crowdsourcing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376161,
author = {Foley, Sarah and Pantidi, Nadia and McCarthy, John},
title = {Student Engagement in Sensitive Design Contexts: A Case Study in Dementia Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376161},
doi = {10.1145/3313831.3376161},
abstract = {There is a growing body of HCI work that seeks to understand and enhance the lived experience of people with dementia. The majority of this work involves researchers working alongside people with dementia and their carers, focused on the design project outcomes. In order to enrich the social context of this work, we explore broadening participation to include student volunteers. To encourage mutually engaging experiences in this design context, careful consideration of how to support both students and people with dementia is needed. In this paper, we present two case- studies of co-design projects between students and people with dementia. Our findings detail the use of design methods to reconfigure the role of the residents in care contexts and the students learning process. We discuss the project learning outcomes as well as practical and ethical considerations to support the use of design methods to support mutual engagement in sensitive contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {experience-centered design, inter-generational engagement, co-design, dementia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376869,
author = {Bedri, Abdelkareem and Li, Diana and Khurana, Rushil and Bhuwalka, Kunal and Goel, Mayank},
title = {FitByte: Automatic Diet Monitoring in Unconstrained Situations Using Multimodal Sensing on Eyeglasses},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376869},
doi = {10.1145/3313831.3376869},
abstract = {In an attempt to help users reach their health goals and practitioners understand the relationship between diet and disease, researchers have proposed many wearable systems to automatically monitor food consumption. When a person consumes food, he/she brings the food close to their mouth, take a sip or bite and chew, and then swallow. Most diet monitoring approaches focus on one of these aspects of food intake, but this narrow reliance requires high precision and often fails in noisy and unconstrained situations common in a person's daily life. In this paper, we introduce FitByte, a multi-modal sensing approach on a pair of eyeglasses that tracks all phases of food intake. FitByte contains a set of inertial and optical sensors that allow it to reliably detect food intake events in noisy environments. It also has an on-board camera that opportunistically captures visuals of the food as the user consumes it. We evaluated the system in two studies with decreasing environmental constraints with 23 participants. On average, FitByte achieved 89% F1-score in detecting eating and drinking episodes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {drinking detection, activity recognition, eating detection, earables, ubiquitous computing, diet monitoring, health sensing, wearable computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376851,
author = {D\"{u}rr, Maximilian and Gr\"{o}schel, Carla and Pfeil, Ulrike and Reiterer, Harald},
title = {NurseCare: Design and 'In-The-Wild' Evaluation of a Mobile System to Promote the Ergonomic Transfer of Patients},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376851},
doi = {10.1145/3313831.3376851},
abstract = {Nurses are frequently required to transfer patients as part of their daily duties. However, the manual transfer of patients is a major risk factor for injuries to the back. Although the Kinaesthetics Care Conception can help to address this issue, existing support for the integration of the concept into nursing-care practice is low. We present NurseCare, a mobile system that aims to promote the practical application of ergonomic patient transfers based on the Kinaesthetics Care Conception. NurseCare consists of a wearable and a smartphone app. Key features of NurseCare include mobile accessible instructions for ergonomic patient transfers, in-situ feedback for the risky bending of the back, and long-term feedback. We evaluated NurseCare in a nine participant 'in-the-wild' evaluation. Results indicate that NurseCare can facilitate ergonomic work while providing a high user experience adequate to the nurses' work domain, and reveal how NurseCare can be incorporated in given practices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile system, nursing care, `in-the-wild' evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376339,
author = {Lerner, Ada and He, Helen Yuxun and Kawakami, Anna and Zeamer, Silvia Catherine and Hoyle, Roberto},
title = {Privacy and Activism in the Transgender Community},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376339},
doi = {10.1145/3313831.3376339},
abstract = {Transgender people are marginalized, facing specific privacy concerns and high risk of online and offline harassment, discrimination, and violence. They also benefit tremendously from technology. We conducted semi-structured interviews with 18 transgender people from 3 U.S. cities about their computer security and privacy experiences broadly construed. Participants frequently returned to themes of activism and prosocial behavior, such as protest organization, political speech, and role-modeling transgender identities, so we focus our analysis on these themes. We identify several prominent risk models related to visibility, luck, and identity that participants used to analyze their own risk profiles, often as distinct or extreme. These risk perceptions may heavily influence transgender people's defensive behaviors and self-efficacy, jeopardizing their ability to defend themselves or gain technology's benefits. We articulate design lessons emerging from these ideas, contrasting and relating them to lessons about other marginalized groups whenever possible.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {transgender, social networks, user-centered design, gender identity, privacy, presentation management, security},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376759,
author = {Tuncer, Sylvaine and Brown, Barry and Lindwall, Oskar},
title = {On Pause: How Online Instructional Videos Are Used to Achieve Practical Tasks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376759},
doi = {10.1145/3313831.3376759},
abstract = {Instructional videos have become an important site of everyday learning. This paper explores how these videos are used to complete practical tasks, analyzing video-recorded interactions between pairs of users. Users need to repeatedly pause their videos to be able to follow the instructions, and we document how pausing is used to coordinate and interweave watching and doing. We describe four purposes and types of pausing: finding task objects, turning to action, keeping up, and fixing problems. Building on these results, we discuss how video players could better support following instructions, and the role of basic user interface functions in complex tasks involving different forms of engagement with the physical world and with screen-based activity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {video interface, ethnomethodology, pause button, video players, instructional videos},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376261,
author = {Liebling, Daniel J. and Lahav, Michal and Evans, Abigail and Donsbach, Aaron and Holbrook, Jess and Smus, Boris and Boran, Lindsey},
title = {Unmet Needs and Opportunities for Mobile Translation AI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376261},
doi = {10.1145/3313831.3376261},
abstract = {Translation apps and devices are often presented in the context of providing assistance while traveling abroad. However, the spectrum of needs for cross-language communication is much wider. To investigate these needs, we conducted three studies with populations spanning socioeconomic status and geographic regions: (1) United States-based travelers, (2) migrant workers in India, and (3) immigrant populations in the United States. We compare frequent travelers' perception and actual translation needs with those of the two migrant communities. The latter two, with low language proficiency, have the greatest translation needs to navigate their daily lives. However, current mobile translation apps do not meet these needs. Our findings provide new insights on the usage practices and limitations of mobile translation tools. Finally, we propose design implications to help apps better serve these unmet needs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {speech, migrants, emerging markets, mobile, immigrants, machine translation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376580,
author = {Maye, Laura and Robinson, Sarah and Pantidi, Nadia and Ganea, Liana and Ganea, Oana and Linehan, Conor and McCarthy, John},
title = {Considerations for Implementing Technology to Support Community Radio in Rural Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376580},
doi = {10.1145/3313831.3376580},
abstract = {Rural communities often lack platforms to support civic engagement and local deliberation. Community radio is intended to facilitate such functions, yet, radio technologies can be expensive and complex to use. To tackle this challenge, low-barrier radio technologies are becoming available. We argue that technology to support civic engagement and local deliberation are important, and design of such platforms must take into consideration specific community needs. We contribute by exploring the needs of three rural European communities. Findings indicate that communities are now distributed beyond place. Platforms for deliberation must include both hyper-local and geographically dispersed populations. Rural values of accountability, reliability and maintaining social harmony are important design considerations. Community radio platforms should support geographically distributed community connections, sharing of health and emergency information, preservation of heritage and as a space for advocacy and civic action.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {community media, rural, community radio},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376652,
author = {Jetter, Hans-Christian and R\"{a}dle, Roman and Feuchtner, Tiare and Anthes, Christoph and Friedl, Judith and Klokmose, Clemens Nylandsted},
title = {"In VR, Everything is Possible!": Sketching and Simulating Spatially-Aware Interactive Spaces in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376652},
doi = {10.1145/3313831.3376652},
abstract = {We propose using virtual reality (VR) as a design tool for sketching and simulating spatially-aware interactive spaces. Using VR, designers can quickly experience their envisioned spaces and interactions by simulating technologies such as motion tracking, multiple networked devices, or unusual form factors such as spherical touchscreens or bezel-less display tiles. Design ideas can be rapidly iterated without restrictions by the number, size, or shape and availability of devices or sensors in the lab. To understand the potentials and challenges of designing in VR, we conducted a user study with 12 interaction designers. As their tool, they used a custom-built virtual design environment with finger tracking and physics simulations for natural interactions with virtual devices and objects. Our study identified the designers' experience of space in relation to their own bodies and playful design explorations as key opportunities. Key challenges were the complexities of building a usable yet versatile VR-based "World Editor".},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {interactive spaces, virtual reality, interaction design, spatial awareness, design tools, sketching, simulation, prototyping},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376820,
author = {Devendorf, Laura and Arquilla, Katya and Wirtanen, Sandra and Anderson, Allison and Frost, Steven},
title = {Craftspeople as Technical Collaborators: Lessons Learned through an Experimental Weaving Residency},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376820},
doi = {10.1145/3313831.3376820},
abstract = {While craft has had increasing influence on HCI research, HCI researchers tend to engage craft in limited capacities, often focusing on the juxtapositions of "traditional" craft and "innovative" computing. In this paper, we describe the structure and results of a six-week "experimental weaving residency" to show how HCI practitioners, engineers, and craftspeople perform similar work and can productively collaborate to envision new technological interfaces at early stages of development. We address both social and technical challenges of residencies and critically reflect on biases about technical and craft labor that we held prior to the residency. We share our experiences and lessons learned in the hopes of supporting future collaborations with craftspeople and broadening the techniques we use to address design challenges.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart textiles, collaboration models, feminist HCI, artist residencies, electrodes, weaving},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376135,
author = {Wilkins, Denise J. and Chitchyan, Ruzanna and Levine, Mark},
title = {Peer-to-Peer Energy Markets: Understanding the Values of Collective and Community Trading},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376135},
doi = {10.1145/3313831.3376135},
abstract = {Peer-to-peer energy-trading platforms (P2P) have the potential to transform the current energy system. However, research is presently scarce on how people would like to participate in, and what would they expect to gain from, such platforms. We address this gap by exploring these questions in the context of the UK energy market. Using a qualitative interview study, we examine how 45 people with an interest in renewable energy understand P2P. We find that the prospective users value the collective benefits of P2P, and understand participation as a mechanism to support social, ecological and economic benefits for communities and larger groups. Drawing on the findings from the interview analysis, we explore broad design characteristics that a prospective P2P energy trading platform should provide to meet the expectations and concerns voiced by our study participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {semi-structured interview, thematic analysis, peer to peer energy trading platforms, sustainability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376697,
author = {Wiley, Katelyn and Vedress, Sarah and Mandryk, Regan L.},
title = {How Points and Theme Affect Performance and Experience in a Gamified Cognitive Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376697},
doi = {10.1145/3313831.3376697},
abstract = {Cognitive tasks are increasingly being gamified in an attempt to leverage the motivational power of games; however, they are sensitive to manipulation and literature is divided on how adding game elements affects participant performance and experience. We applied two popular gamification approaches (points/feedback and theme/narrative) to a typical cognitive task (the dot probe) and measured performance and experience in two studies (N1=287, N2=321). Similar to prior work, we confirm in Study1 that points increase reaction time and error rate, and positive affect. We replicated these results in Study2, and expanded our analysis to investigate participant experience. Our findings suggest that theme creates expectations of an interesting game, which gamified tasks fail to deliver, whereas points maintain enjoyment better throughout the task itself. Important for the development of gamified cognitive tasks, our findings suggest that novel approaches to gameful assessment may be better than the status quo.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {assessment, cognitive tasks, dot probe, gamification, games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376431,
author = {Shi, Lei and Zhao, Yuhang and Gonzalez Penuela, Ricardo and Kupferstein, Elizabeth and Azenkot, Shiri},
title = {Molder: An Accessible Design Tool for Tactile Maps},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376431},
doi = {10.1145/3313831.3376431},
abstract = {Tactile materials are powerful teaching aids for students with visual impairments (VIs). To design these materials, designers must use modeling applications, which have high learning curves and rely on visual feedback. Today, Orientation and Mobility (O&amp;M) specialists and teachers are often responsible for designing these materials. However, most of them do not have professional modeling skills, and many are visually impaired themselves. To address this issue, we designed Molder, an accessible design tool for interactive tactile maps, an important type of tactile materials that can help students learn O&amp;M skills. A designer uses Molder to design a map using tangible input techniques, and Molder provides auditory feedback and high-contrast visual feedback. We evaluated Molder with 12 participants (8 with VIs, 4 sighted). After a 30-minute training session, the participants were all able to use Molder to design maps with customized tactile and interactive information.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {tactile maps, visual impairments, design tool},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376418,
author = {Jensen, Emily and Dale, Meghan and Donnelly, Patrick J. and Stone, Cathlyn and Kelly, Sean and Godley, Amanda and D'Mello, Sidney K.},
title = {Toward Automated Feedback on Teacher Discourse to Enhance Teacher Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376418},
doi = {10.1145/3313831.3376418},
abstract = {Like anyone, teachers need feedback to improve. Due to the high cost of human classroom observation, teachers receive infrequent feedback which is often more focused on evaluating performance than on improving practice. To address this critical barrier to teacher learning, we aim to provide teachers with detailed and actionable automated feedback. Towards this end, we developed an approach that enables teachers to easily record high-quality audio from their classes. Using this approach, teachers recorded 142 classroom sessions, of which 127 (89%) were usable. Next, we used speech recognition and machine learning to develop teacher-generalizable computer-scored estimates of key dimensions of teacher discourse. We found that automated models were moderately accurate when compared to human coders and that speech recognition errors did not influence performance. We conclude that authentic teacher discourse can be recorded and analyzed for automatic feedback. Our next step is to incorporate the automatic models into an interactive visualization tool that will provide teachers with objective feedback on the quality of their discourse.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {classroom discourse, automatic speech recognition, natural language processing, dialogic instruction, audio recording},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376817,
author = {Kaur, Harmanpreet and Williams, Alex C. and McDuff, Daniel and Czerwinski, Mary and Teevan, Jaime and Iqbal, Shamsi T.},
title = {Optimizing for Happiness and Productivity: Modeling Opportune Moments for Transitions and Breaks at Work},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376817},
doi = {10.1145/3313831.3376817},
abstract = {Information workers perform jobs that demand constant multitasking, leading to context switches, productivity loss, stress, and unhappiness. Systems that can mediate task transitions and breaks have the potential to keep people both productive and happy. We explore a crucial initial step for this goal: finding opportune moments to recommend transitions and breaks without disrupting people during focused states. Using affect, workstation activity, and task data from a three-week field study (N=25), we build models to predict whether a person should continue their task, transition to a new task, or take a break.&nbsp;The R-squared values of our models are as high as 0.7, with only 15% error cases. We ask users to evaluate the timing of recommendations provided by a recommender that relies on these models. Our study shows that users find our transition and break recommendations to be well-timed, rating them as 86% and 77% accurate, respectively. We conclude with a discussion of the implications for intelligent systems that seek to guide task transitions and manage interruptions at work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {workplace, productivity, recommendations, affect},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376644,
author = {Park, So Yeon and Moore, Dylan James and Sirkin, David},
title = {What a Driver Wants: User Preferences in Semi-Autonomous Vehicle Decision-Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376644},
doi = {10.1145/3313831.3376644},
abstract = {Autonomous vehicle (AV) systems are developing at a rapid pace, not only in technological capabilities, but also in human-centered directions. Despite this development, we lack a nuanced understanding of driver preference in decision scenarios that semi-AVs will face, and of possible misalignment between semi-AV decisions and user preference. Using an online survey, we explore how participants would like semi-AVs to act and alert them of the vehicles' decisions in various scenarios. Participants reported varying levels of comfort with autonomy, desire to takeover control, and desire for AV informing. Individual differences, including level of experience with autonomy and situation awareness, affected perceptions of the vehicle. Our results highlight the importance of considering driver preference in AV decision-making, and we present an influence diagram that situates this factor among others. We also derive five design principles, including that a previous positive AV experience can lead to more harmful consequences for AVs when not aligned with driver preference.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online study, notifications, transition of control, driver preferences, autonomous vehicles, decision-making},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376594,
author = {Zhu, Haining and Moffa, Zachary J. and Gui, Xinning and Carroll, John M.},
title = {Prehabilitation: Care Challenges and Technological Opportunities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376594},
doi = {10.1145/3313831.3376594},
abstract = {Millions of surgeries are performed in the US annually, and numbers are trending upwards. Traditional rehabilitative interventions are struggling to meet current demands, and researchers have turned to pre-operative interventions, or prehabilitation, to improve patient functions. However, existing literature primarily discusses efficacy or the use of commercial sensing devices, and lacks a clear comprehension of healthcare professionals' (HPs') needs and perspectives. User-centered stakeholder understandings are crucial for a technology's adoption, but prehabilitation literature lacks such understandings. Therefore we conduct semi-structured interviews with 12 prehabilitation healthcare professionals (HPs) to offer descriptions of care challenges, tool usage, and perspectives regarding suitable and effective technologies. These data can assist designers in fostering prehabilitation processes via tailored prehabilitation tools which meet HPs' needs and expectations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {nutritional health, physical health, psychological health, surgical care, user-centered design, prehabilitation, rehabilitation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376513,
author = {Davis, Josh Urban and Wu, Te-Yen and Shi, Bo and Lu, Hanyi and Panotopoulou, Athina and Whiting, Emily and Yang, Xing-Dong},
title = {TangibleCircuits: An Interactive 3D Printed Circuit Education Tool for People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376513},
doi = {10.1145/3313831.3376513},
abstract = {We present a novel haptic and audio feedback device that allows blind and visually impaired (BVI) users to understand circuit diagrams. TangibleCircuits allows users to interact with a 3D printed tangible model of a circuit which provides audio tutorial directions while being touched. Our system comprises an automated parsing algorithm which extracts 3D printable models as well as an audio interfaces from a Fritzing diagram. To better understand the requirements of designing technology to assist BVI users in learning hardware computing, we conducted a series of formative inquiries into the accessibility limitations of current circuit tutorial technologies. In addition, we derived insights and design considerations gleaned from conducting a formal comparative user study to understand the effectiveness of TangibleCircuits as a tutorial system. We found that BVI users were better able to understand the geometric, spatial and structural circuit information using TangibleCircuits, as well as enjoyed learning with our tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {accessibility, universal design, education tools, circuit prototyping, tangible user interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376288,
author = {Davis, Keith M. and Kangassalo, Lauri and Spap\'{e}, Michiel and Ruotsalo, Tuukka},
title = {Brainsourcing: Crowdsourcing Recognition Tasks via Collaborative Brain-Computer Interfacing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376288},
doi = {10.1145/3313831.3376288},
abstract = {This paper introduces brainsourcing: utilizing brain responses of a group of human contributors each performing a recognition task to determine classes of stimuli. We investigate to what extent it is possible to infer reliable class labels using data collected utilizing electroencephalography (EEG) from participants given a set of common stimuli. An experiment (N=30) measuring EEG responses to visual features of faces (gender, hair color, age, smile) revealed an improved F1 score of 0.94 for a crowd of twelve participants compared to an F1 score of 0.67 derived from individual participants and a random chance of 0.50. Our results demonstrate the methodological and pragmatic feasibility of brainsourcing in labeling tasks and opens avenues for more general applications using brain-computer interfacing in a crowdsourced setting.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {crowdsourcing, brain-computer interfaces, brainsourcing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376536,
author = {Lehmann, Florian and Buschek, Daniel},
title = {Heartbeats in the Wild: A Field Study Exploring ECG Biometrics in Everyday Life},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376536},
doi = {10.1145/3313831.3376536},
abstract = {This paper reports on an in-depth study of electrocardiogram (ECG) biometrics in everyday life. We collected ECG data from 20 people over a week, using a non-medical chest tracker. We evaluated user identification accuracy in several scenarios and observed equal error rates of 9.15% to 21.91%, heavily depending on 1) the number of days used for training, and 2) the number of heartbeats used per identification decision. We conclude that ECG biometrics can work in the wild but are less robust than expected based on the literature, highlighting that previous lab studies obtained highly optimistic results with regard to real life deployments. We explain this with noise due to changing body postures and states as well as interrupted measures. We conclude with implications for future research and the design of ECG biometrics systems for real world deployments, including critical reflections on privacy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {electrocardiogram, field study, ecg, biometrics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376236,
author = {Olwal, Alex and Starner, Thad and Mainini, Gowa},
title = {E-Textile Microinteractions: Augmenting Twist with Flick, Slide and Grasp Gestures for Soft Electronics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376236},
doi = {10.1145/3313831.3376236},
abstract = {E-textile microinteractions advance cord-based interfaces by enabling the simultaneous use of precise continuous control and casual discrete gestures. We leverage the recently introduced I/O Braid sensing architecture to enable a series of user studies and experiments which help design suitable interactions and a real-time gesture recognition pipeline. Informed by a gesture elicitation study with 36 participants, we developed a user-dependent classifier for eight discrete gestures with 94% accuracy for 12 participants. In a formal evaluation we show that we can enable precise manipulation with the same architecture. Our quantitative targeting experiment suggests that twisting is faster than existing headphone button controls and is comparable in speed to a capacitive touch surface. Qualitative interview feedback indicates a preference for I/O Braid's interaction over that of in-line headphone controls. Our applications demonstrate how continuous and discrete gestures can be combined to form new, integrated e-textile microinteraction techniques for real-time continuous control, discrete actions and mode switching.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wearables, smart textile, gestures, e-textile, interactive fabric, soft electronics, electronic textile, microinteractions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376136,
author = {Tejada, Carlos E. and Ramakers, Raf and Boring, Sebastian and Ashbrook, Daniel},
title = {AirTouch: 3D-Printed Touch-Sensitive Objects Using Pneumatic Sensing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376136},
doi = {10.1145/3313831.3376136},
abstract = {3D printing technology can be used to rapidly prototype the look and feel of 3D objects. However, the objects produced are passive. There has been increasing interest in making these objects interactive, yet they often require assembling components or complex calibration. In this paper, we contribute AirTouch, a technique that enables designers to fabricate touch-sensitive objects with minimal assembly and calibration using pneumatic sensing. AirTouch-enabled objects are 3D printed as a single structure using a consumer-level 3D printer. AirTouch uses pre-trained machine learning models to identify interactions with fabricated objects, meaning that there is no calibration required once the object has completed printing. We evaluate our technique using fabricated objects with various geometries and touch sensitive locations, obtaining accuracies of at least 90% with 12 interactive locations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {touch interactio, pneumatic sensing, 3d printing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376455,
author = {Asai, Kentaro and Fukusato, Tsukasa and Igarashi, Takeo},
title = {Integrated Development Environment with Interactive Scatter Plot for Examining Statistical Modeling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376455},
doi = {10.1145/3313831.3376455},
abstract = {The development of a statistical modeling program requires example data to observe and verify the behavior of the program. Such example data are either taken from an existing dataset or synthesized using commands. Programmers may want to directly design an arbitrary dataset or modify it interactively, but it is difficult to do so in current development environments. We therefore propose combining a code editor with an interactive scatter plot editor to efficiently understand the behavior of statistical modeling algorithms. The user interactively creates and modifies the dataset on the scatter plot editor, while the system continuously executes the code in the editor, taking the data as input, and shows the result in the editor. This paper presents the design rationale behind the system and introduces several usage scenarios.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {statistical modeling, interactive data design and editing, live programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376357,
author = {Ryding, Karin},
title = {The Silent Conversation: Designing for Introspection and Social Play in Art Museums},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376357},
doi = {10.1145/3313831.3376357},
abstract = {This paper presents an attempt to design for a combination of social play and introspection using a ludic approach within an art museum setting. The field trial is described of a mobile web app called 'Never let me go', a two-player system enabling visitors to an art museum to create impromptu experiences in-situ for a companion. The study reveals that players used the app for communicating with each other during the visit, often without speaking. This led to deeply personal and introspective moments, as well as, lots of teasing and playing. The implications of allowing for social, personal and playful experiences in an art museum are discussed, as well as, the advantages and challenges of designing for improvisation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {personalisation, impromptu experience design, introspective, play, art, affective, social, experience, mobile, museums},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376716,
author = {Ahmadi, Michael and Eilert, Rebecca and Weibert, Anne and Wulf, Volker and Marsden, Nicola},
title = {Feminist Living Labs as Research Infrastructures for HCI: The Case of a Video Game Company},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376716},
doi = {10.1145/3313831.3376716},
abstract = {The number of women in IT is still low and companies struggle to integrate female professionals. The aim of our research is to provide methodological support for understanding and sharing experiences of gendered practices in the IT industry and encouraging sustained reflection about these matters over time. We established a Living Lab with that end in view, aiming to enhance female participation in the IT workforce and committing ourselves to a participatory approach to the sharing of women's experiences. Here, using the case of a German video game company which participated in our Lab, we detail our lessons learned. We show that this kind of long-term participation involves challenges over the lifetime of the project but can lead to substantial benefits for organizations. Our findings demonstrate that Living Labs are suitable for giving voice to marginalized groups, addressing their concerns and evoking change possibilities. Nevertheless, uncertainties about long-term sustainability remain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {methodology, feminist research, feminist HCI, living lab, ethnography, participatory action research, gender},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376332,
author = {Tyack, April and Wyeth, Peta and Johnson, Daniel},
title = {Restorative Play: Videogames Improve Player Wellbeing After a Need-Frustrating Event},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376332},
doi = {10.1145/3313831.3376332},
abstract = {People often use videogames to restore wellbeing after negative experiences in day-to-day life. Although some research suggests that play can restore wellbeing, few studies have investigated the means by which restoration occurs. We employed self-determination theory (SDT) to understand how and to what degree play improves wellbeing after a need-frustrating event, and how players understand experiences of competence in play. Sixty-five participants worked at a competence manipulation task prior to playing a competence-satisfying videogame. Competence, affect, and vitality improved during play, and in-game experiences of need frustration were observed to effectively predict post-play negative affect. Post-experiment interviews indicate that videogames are seen to support competence relative to perceived skill, extending our knowledge of how design can support competence and restoration. We demonstrate that play can restore wellbeing, present need frustration as a means to explain negative experiences with interactive systems, and discuss effects of design on competence.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {self-determination theory, player experience, video games, wellbeing, restoration, need frustration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376543,
author = {Hanton, Ollie and Wessely, Michael and Mueller, Stefanie and Fraser, Mike and Roudaut, Anne},
title = {ProtoSpray: Combining 3D Printing and Spraying to Create Interactive Displays with Arbitrary Shapes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376543},
doi = {10.1145/3313831.3376543},
abstract = {ProtoSpray is a fabrication method that combines 3D printing and spray coating, to create interactive displays of arbitrary shapes. Our approach makes novel use of 3D printed conductive channels to create base electrodes on 3D shapes. This is then combined with spraying active materials to produce illumination. We demonstrate the feasibility and benefits of this combined approach in 6 evaluations exploring different shaped topologies. We analyze factors such as spray orientations, surface topologies and printer resolutions, to discuss how spray nozzles can be integrated into traditional 3D printers. We present a series of ProtoSprayed objects demonstrating how our technique goes beyond existing fabrication techniques by allowing creation of displays on objects with curvatures as complex as a Mobius strip. Our work provides a platform to empower makers to use displays as a fabrication material.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {rapid prototyping, spraying, electroluminescence, 3d printing, fabrication, display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376142,
author = {Gorski, Peter Leo and Acar, Yasemin and Lo Iacono, Luigi and Fahl, Sascha},
title = {Listen to Developers! A Participatory Design Study on Security Warnings for Cryptographic APIs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376142},
doi = {10.1145/3313831.3376142},
abstract = {The positive effect of security information communicated to developers through API warnings has been established. However, current prototypical designs are based on security warnings for end-users. To improve security feedback for developers, we conducted a participatory design study with 25 professional software developers in focus groups. We identify which security information is considered helpful in avoiding insecure cryptographic API use during development. Concerning console messages, participants suggested five core elements, namely message classification, title message, code location, link to detailed external resources, and color. Design guidelines for end-user warnings are only partially suitable in this context. Participants emphasized the importance of tailoring the detail and content of security information to the context. Console warnings call for concise communication; further information needs to be linked externally. Therefore, security feedback should transcend tools and should be adjustable by software developers across development tools, considering the work context and developer needs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {participatory design, security warning design, developer console, software development, focus groups, cryptographic apis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376407,
author = {Superti Pantoja, Luiza and Diederich, Kyle and Crawford, Liam and Corbett, Megan and Klemm, Samantha and Peterman, Kerry and Currin, Flannery and Hourcade, Juan Pablo},
title = {Play-Based Design: Giving 3- to 4-Year-Old Children a Voice in the Design Process},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376407},
doi = {10.1145/3313831.3376407},
abstract = {There has been a dramatic growth in interactive technology use by children under the age of 5 during the past decade. Despite this growth, children under the age of 5 typically participate only as users or testers in the design process in the overwhelming majority of projects targeting this population presented in key child-computer interaction venues. In this paper we introduce play-based design, an age-appropriate design method to give 3-4-year-old children a voice in the design process. More specifically, we contribute a thorough analysis of the use of existing methods to design technologies for children under the age of 5, a summary of the process that resulted in the development of play-based design, a detailed description of play-based design, a qualitative analysis of our experience implementing play-based design with two groups of children, and a discussion of play-based design's place among other methods, its advantages, and limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {children, design methods, play, preschool},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376300,
author = {Fu, Ernestine and Johns, Mishel and Hyde, David A. B. and Sibi, Srinath and Fischer, Martin and Sirkin, David},
title = {Is Too Much System Caution Counterproductive? Effects of Varying Sensitivity and Automation Levels in Vehicle Collision Avoidance Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376300},
doi = {10.1145/3313831.3376300},
abstract = {Autonomous vehicle system performance is limited by uncertainties inherent in the driving environment and challenges in processing sensor data. Engineers thus face the design decision of biasing systems toward lower sensitivity to potential threats (more misses) or higher sensitivity (more false alarms). We explored this problem for Automatic Emergency Braking systems in Level 3 autonomous vehicles, where the driver is required to monitor the system for failures. Participants (N=48) drove through a simulated suburban environment and experienced detection misses, perfect performance, or false alarms. We found that driver vigilance was greater for less-sensitive braking systems, resulting in improved performance during a potentially fatal failure. In addition, regardless of system bias, greater levels of autonomy resulted in significantly worse driver performance. Our results demonstrate that accounting for the effects of system bias on driver vigilance and performance will be critical design considerations as vehicle autonomy levels increase.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {autonomous vehicles, controlled experiment, human machine interaction, simulation, automated emergency braking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376462,
author = {Concannon, Shauna and Rajan, Natasha and Shah, Parthiv and Smith, Davy and Ursu, Marian and Hook, Jonathan},
title = {Brooke Leave Home: Designing a Personalized Film to Support Public Engagement with Open Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376462},
doi = {10.1145/3313831.3376462},
abstract = {Brooke Leave Home is a personalized film designed to engage a non-expert audience with open data about the support young adults receive when leaving the care system in England. The film draws upon a range of video-based data storytelling techniques to present each viewer with a personalized perspective on the topic based on data from their own local area. We present the film's design and describe how its storytelling techniques were developed to support viewers in understanding, and fostering empathic connections with, the data sources featured and the implications they have for care leavers. We also present a study with 47 viewers, which explores how these techniques were experienced and how effective they were in aiding engagement with the data included and its meaning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {film, data, storytelling, personalization, video, narrative},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376197,
author = {Ackermans, Sander and Dey, Debargha and Ruijten, Peter and Cuijpers, Raymond H. and Pfleging, Bastian},
title = {The Effects of Explicit Intention Communication, Conspicuous Sensors, and Pedestrian Attitude in Interactions with Automated Vehicles},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376197},
doi = {10.1145/3313831.3376197},
abstract = {In this paper, we investigate the effect of an external human-machine interface (eHMI) and a conspicuous external vehicle appearance due to visible sensors on pedestrian interactions with automated vehicles (AVs). Recent research shows that AVs may need to explicitly communicate with the environment due to the absence of a driver. Furthermore, in interaction situations, an AV that looks different and conspicuous owing to an extensive sensor system may potentially lead to hesitation stemming from mistrust in automation. Thus, we evaluated in a virtual reality study how pedestrian attitude, the presence/absence of an eHMI, and a conspicuous sensor system affect their willingness to cross the road. Results recommend the use of an eHMI. A conspicuous appearance of automated-driving capability had no effect for the sample as a whole, although it led to more efficient crossing decisions for those with a more negative attitude towards AVs. Our findings contribute towards the effective design of future AV interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {external appearance, automated vehicles, vehicle-pedestrian interaction, vulnerable road users, pedestrians, automated driving, visible sensors, ehmi},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376618,
author = {Zhao, Nanxuan and Kim, Nam Wook and Herman, Laura Mariah and Pfister, Hanspeter and Lau, Rynson W.H. and Echevarria, Jose and Bylinskii, Zoya},
title = {ICONATE: Automatic Compound Icon Generation and Ideation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376618},
doi = {10.1145/3313831.3376618},
abstract = {Compound icons are prevalent on signs, webpages, and infographics, effectively conveying complex and abstract concepts, such as "no smoking" and "health insurance", with simple graphical representations. However, designing such icons requires experience and creativity, in order to efficiently navigate the semantics, space, and style features of icons. In this paper, we aim to automate the process of generating icons given compound concepts, to facilitate rapid compound icon creation and ideation. Informed by ethnographic interviews with professional icon designers, we have developed ICONATE, a novel system that automatically generates compound icons based on textual queries and allows users to explore and customize the generated icons. At the core of ICONATE is a computational pipeline that automatically finds commonly used icons for sub-concepts and arranges them according to inferred conventions. To enable the pipeline, we collected a new dataset, Compicon1k, consisting of 1000 compound icons annotated with semantic labels (i.e., concepts). Through user studies, we have demonstrated that our tool is able to automate or accelerate the compound icon design process for both novices and professionals.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {graphic design, design tools, compound icon, icon design, pictogram, ideogram},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376641,
author = {Khan, Taslim Arefin and Yoon, Dongwook and McGrenere, Joanna},
title = {Designing an Eyes-Reduced Document Skimming App for Situational Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376641},
doi = {10.1145/3313831.3376641},
abstract = {Listening to text using read-aloud applications is a popular way for people to consume content when their visual attention is situationally impaired (e.g., commuting, walking, tired eyes). However, due to the linear nature of audio, such apps do not support skimming---a non-linear, rapid form of reading---essential for quickly grasping the gist and organization of difficult texts, like academic or professional documents. To support auditory skimming for situational impairments, we (1) identified the user needs and challenges in auditory skimming through a formative study (N=20), (2) derived the concept of "eyes-reduced" skimming that blends auditory and visual modes of reading, inspired by how participants mixed visual and non-visual interactions, (3) generated a set of design guidelines for eyes-reduced skimming, and (4) designed and evaluated a novel audio skimming app that embodies the guidelines. Our in-situ preliminary observation study (N=6) suggested that participants were positive about our design and were able to auditorily skim documents. We discuss design implications for eyes-reduced reading, read-aloud apps, and text-to-speech engines.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {skim reading, eyes-free, mobile device, accessibility, text-to-speech, eyes-reduced, design guidelines, situational impairments, interactive prototype},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376419,
author = {Peck, Tabitha C. and Good, Jessica J. and Bourne, Kimberly A.},
title = {Inducing and Mitigating Stereotype Threat Through Gendered Virtual Body-Swap Illusions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376419},
doi = {10.1145/3313831.3376419},
abstract = {A psychological phenomenon termed "stereotype threat" has been shown to contribute to women's underperformance and underrepresentation in math and science fields. Within the virtual reality literature, a recent study utilized gendered body-swap illusions (i.e., women in male virtual bodies) to mitigate the effects of stereotype threat among a sample of female participants. The present research provides a much needed replication of this intervention, as well as a critical extension of virtual reality research on the Proteus Effect to test whether stereotype threat can be induced among male participants immersed in a female virtual body. Results supported both the replication and extension hypotheses; female participants embodied in male avatars were buffered from stereotype threat whereas male participants embodied in female avatars suffered from stereotype threat. Avatar gender also influenced participants' math confidence and awareness of the negative societal stereotype regarding women's math ability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, embodiment, proteus effect, gender, self-avatars, stereotype threat, body-swap illusions, gender identity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376650,
author = {Richardson, Dan and Kharrufa, Ahmed},
title = {We Are the Greatest Showmen: Configuring a Framework for Project-Based Mobile Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376650},
doi = {10.1145/3313831.3376650},
abstract = {Little research has explored how mobile-learning technologies could be used by students to produce interactive artefacts during project-based learning processes. Following a design-based approach, we report on engagements spanning classroom and outdoor learning with students (ages 6-13) and teachers from three different UK schools and a summer school of Travelling Showchildren. Working within the time constraints of each context, we deployed a variety of configurations of a project-based mobile learning (PBML) framework intended to support the production of student-designed mobile-learning activities. We contribute insights gained from these engagements, including how mobile technologies can harness students' existing desire for independence and how they can be configured to leverage the physical and social attributes of place and community as learning resources. We argue for further exploration of the potential roles for mobile technologies within project-based learning, and contribute our PBML framework with recommendations for its re-configuration in response to contextual constraints.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {digital civics, mobile-learning, project-based learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376367,
author = {Yang, Yalong and Marriott, Kim and Butler, Matthew and Goncu, Cagatay and Holloway, Leona},
title = {Tactile Presentation of Network Data: Text, Matrix or Diagram?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376367},
doi = {10.1145/3313831.3376367},
abstract = {Visualisations are commonly used to understand social, biological and other kinds of networks. Currently we do not know how to effectively present network data to people who are blind or have low-vision (BLV). We ran a controlled study with 8 BLV participants comparing four tactile representations: organic node-link diagram, grid node-link diagram, adjacency matrix and braille list. We found that the node-link representations were preferred and more effective for path following and cluster identification while the matrix and list were better for adjacency tasks. This is broadly in line with findings for the corresponding visual representations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {graphvisualization, accessibility, vision impairment, adjacency matrix, blindness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376525,
author = {Kristensson, Per Ola and Lilley, James and Black, Rolf and Waller, Annalu},
title = {A Design Engineering Approach for Quantitatively Exploring Context-Aware Sentence Retrieval for Nonspeaking Individuals with Motor Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376525},
doi = {10.1145/3313831.3376525},
abstract = {Nonspeaking individuals with motor disabilities typically have very low communication rates. This paper proposes a design engineering approach for quantitatively exploring context-aware sentence retrieval as a promising complementary input interface, working in tandem with a word-prediction keyboard. We motivate the need for complementary design engineering methodology in the design of augmentative and alternative communication and explain how such methods can be used to gain additional design insights. We then study the theoretical performance envelopes of a context-aware sentence retrieval system, identifying potential keystroke savings as a function of the parameters of the subsystems, such as the accuracy of the underlying auto-complete word prediction algorithm and the accuracy of sensed context information under varying assumptions. We find that context-aware sentence retrieval has the potential to provide users with considerable improvements in keystroke savings under reasonable parameter assumptions of the underlying subsystems. This highlights how complementary design engineering methods can reveal additional insights into design for augmentative and alternative communication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {augmentative and alternative communication, sentence prediction, context-aware text entry, text entry, information retrieval, design engineering},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376790,
author = {Glenn, Terrell and Ipsita, Ananya and Carithers, Caleb and Peppler, Kylie and Ramani, Karthik},
title = {StoryMakAR: Bringing Stories to Life With An Augmented Reality &amp; Physical Prototyping Toolkit for Youth},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376790},
doi = {10.1145/3313831.3376790},
abstract = {Makerspaces can support educational experiences in prototyping for children. Storytelling platforms enable high levels of creativity and expression, but have high barriers of entry. We introduce StoryMakAR, which combines making and storytelling. StoryMakAR is a new AR-IoT system for children that uses block programming, physical prototyping, and event-based storytelling to bring stories to life. We reduce the barriers to entry for youth (Age=14-18) by designing an accessible, plug-and-play system through merging both electro-mechanical devices and virtual characters to create stories. We describe our initial design process, the evolution and workflow of StoryMakAR, and results from multiple single-session workshops with 33 high school students. Our preliminary studies led us to understand what students want to make. We provide evidence of how students both engage and have difficulties with maker-based storytelling. We also discuss the potential for StoryMakAR to be used as a learning environment for classrooms and younger students.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {maker culture, storytelling, augmented reality, children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376671,
author = {Bentley, Frank and O'Neill, Kathleen and Quehl, Katie and Lottridge, Danielle},
title = {Exploring the Quality, Efficiency, and Representative Nature of Responses Across Multiple Survey Panels},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376671},
doi = {10.1145/3313831.3376671},
abstract = {A common practice in HCI research is to conduct a survey to understand the generalizability of findings from smaller-scale qualitative research. These surveys are typically deployed to convenience samples, on low-cost platforms such as Amazon's Mechanical Turk or Survey Monkey, or to more expensive market research panels offered by a variety of premium firms. Costs can vary widely, from hundreds of dollars to tens of thousands of dollars depending on the platform used. We set out to understand the accuracy of ten different survey platforms/panels compared to ground truth data for a total of 6,007 respondents on 80 different aspects of demographic and behavioral questions. We found several panels that performed significantly better than others on certain topics, while different panels provided longer and more relevant open-ended responses. Based on this data, we highlight the benefits and pitfalls of using a variety of survey distribution options in terms of the quality, efficiency, and representative nature of the respondents and the types of responses that can be obtained.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {surveymonkey, representative, survey, mturk},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376191,
author = {T\"{u}rkay, Selen and Formosa, Jessica and Adinolf, Sonam and Cuthbert, Robert and Altizer, Roger},
title = {See No Evil, Hear No Evil, Speak No Evil: How Collegiate Players Define, Experience and Cope with Toxicity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376191},
doi = {10.1145/3313831.3376191},
abstract = {Toxicity in online environments is a complex and a systemic issue. Collegiate esports communities seem to be particularly vulnerable to toxic behaviors. In esports games, negative behavior, such as harassment, can create barriers to players achieving high performance and can reduce enjoyment which may cause them to leave the game. The aim of this study is to investigate how players define, experience and deal with toxicity in esports games that they play. Our findings from an interview study and five monthly follow ups with 19 participants from a university esports club show that players define toxicity as behaviors disrupt their morale and team dynamics, and are inclined to normalize negative behaviors, rationalize it as part of the competitive game culture akin to traditional sports, and participate a form of gamer classism, believing that toxicity is more common in lower level play than in professional and collegiate esports. There are many coping mechanisms employed by collegiate esports players, including ignoring offenders, deescalating tense encounters, and using tools to mute offenders. Understanding the motivations behind collegiate esports players' engagement with toxicity may help the growing sport plot a positive trajectory towards healthy play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {esports, player perceptions, competitive games, interview study, toxicity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376862,
author = {Zhang, Yixuan and Suhaimi, Nurul and Azghandi, Rana and Joseph, Mary Amulya and Kim, Miso and Griffin, Jacqueline and Parker, Andrea G.},
title = {Understanding the Use of Crisis Informatics Technology among Older Adults},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376862},
doi = {10.1145/3313831.3376862},
abstract = {Mass emergencies increasingly pose significant threats to human life, with a disproportionate burden being incurred by older adults. Research has explored how mobile technology can mitigate the effects of mass emergencies. However, less work has examined how mobile technologies support older adults during emergencies, considering their unique needs. To address this research gap, we interviewed 16 older adults who had recent experience with an emergency evacuation to understand the perceived value of using mobile technology during emergencies. We found that there was a lack of awareness and engagement with existing crisis apps. Our findings characterize the ways in which our participants did and did not feel crisis informatics tools address human values, including basic needs and esteem needs. We contribute an understanding of how older adults used mobile technology during emergencies and their perspectives on how well such tools address human values.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {older adults, human values, emergencies, crisis informatics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376628,
author = {Drey, Tobias and Gugenheimer, Jan and Karlbauer, Julian and Milo, Maximilian and Rukzio, Enrico},
title = {VRSketchIn: Exploring the Design Space of Pen and Tablet Interaction for 3D Sketching in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376628},
doi = {10.1145/3313831.3376628},
abstract = {Sketching in virtual reality (VR) enhances perception and understanding of 3D volumes, but is currently a challenging task, as spatial input devices (e.g., tracked controllers) do not provide any scaffolding or constraints for mid-air interaction. We present VRSketchIn, a VR sketching application using a 6DoF-tracked pen and a 6DoF-tracked tablet as input devices, combining unconstrained 3D mid-air with constrained 2D surface-based sketching. To explore what possibilities arise from this combination of 2D (pen on tablet) and 3D input (6DoF pen), we present a set of design dimensions and define the design space for 2D and 3D sketching interaction metaphors in VR. We categorize prior art inside our design space and implemented a subset of metaphors for pen and tablet sketching in our prototype. To gain a deeper understanding which specific sketching operations users perform with 2D and which with 3D metaphors, we present findings of usability walkthroughs with six participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mid-air painting, pen and tablet, interaction metaphors, sketching, design space, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376627,
author = {Hodge, James and Foley, Sarah and Brankaert, Rens and Kenning, Gail and Lazar, Amanda and Boger, Jennifer and Morrissey, Kellie},
title = {Relational, Flexible, Everyday: Learning from Ethics in Dementia Research},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376627},
doi = {10.1145/3313831.3376627},
abstract = {Engaging in participatory research in HCI raises numerous ethical complexities such as consent, researcher relationships, and participant compensation. Doing HCI work in the area of dementia amplifies these issues, and researchers in this area are modelling ethical stances to ensure researcher-participant relationships focus on meaningful engagement and care. This paper presents an insight into the kinds of ethical foci required when doing design research with people living with dementia and their carers. We interviewed 22 HCI researchers with experience working in dementia care contexts. Our qualitative analysis outlines subsequent lessons-learned, such as recognition of the participants, self-care, research impact, and subjectivity in ethical review boards. Furthermore, we found the complexity of navigating both "everyday" and more formal, institutional ethics in dementia research has implications beyond the context of working with people with dementia and outline key considerations for ethical practices in socially orientated HCI research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {ethics, care, emotion, relational, lived experience, dementia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376237,
author = {Di Bartolomeo, Sara and Pandey, Aditeya and Leventidis, Aristotelis and Saffo, David and Syeda, Uzma Haque and Carstensdottir, Elin and Seif El-Nasr, Magy and Borkin, Michelle A. and Dunne, Cody},
title = {Evaluating the Effect of Timeline Shape on Visualization Task Performance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376237},
doi = {10.1145/3313831.3376237},
abstract = {Timelines are commonly represented on a horizontal line, which is not necessarily the most effective way to visualize temporal event sequences. However, few experiments have evaluated how timeline shape influences task performance. We present the design and results of a controlled experiment run on Amazon Mechanical Turk (n=192) in which we evaluate how timeline shape affects task completion time, correctness, and user preference. We tested 12 combinations of 4 shapes --- horizontal line, vertical line, circle, and spiral — and 3 data types — recurrent, non-recurrent, and mixed event sequences. We found good evidence that timeline shape meaningfully affects user task completion time but not correctness and that users have a strong shape preference. Building on our results, we present design guidelines for creating effective timeline visualizations based on user task and data types. A free copy of this paper, the evaluation stimuli and data, and code are available https://osf.io/qr5yu/},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {information visualization, temporal event sequences, controlled experiments, timelines},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376378,
author = {Lam, Amy T. and Griffin, Jonathan and Loeun, Matthew Austin and Cira, Nate J. and Lee, Seung Ah and Riedel-Kruse, Ingmar H.},
title = {Pac-Euglena: A Living Cellular Pac-Man Meets Virtual Ghosts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376378},
doi = {10.1145/3313831.3376378},
abstract = {The advancement of biotechnology enabled the development of "biotic video games", where human players manipulate real biological samples for fun and educational human-biology interactions. However, new design principles are needed to both leverage and mitigate biological properties (e.g., variability and stochasticity), and create unique play experiences that transcend traditional video games. This paper describes the implementation of Pac-Euglena, a biotic Pac-Man analog, where players guide live microscopic Euglena cells with light stimuli through a physical microfluidic maze. Through use of multi-modal stimuli, a mixed biology-digital-human reality is achieved, enabling cell interactions with virtual ghosts and collectibles. Through an iterative design process, we illustrate challenges and strategies for designing games with living organisms. A user study (n=18, conducted at a university event) showed that Pac-Euglena was fun, stimulated curiosity, and taught users about Euglena. We conclude with five general guidelines for the design and development of biotic games and HBI interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {augmented reality, euglena gracilis, biological user interfaces, human-biology interaction (hbi), biotic games, mixed reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376244,
author = {Lee, Byungjoo and Nancel, Mathieu and Kim, Sunjun and Oulasvirta, Antti},
title = {AutoGain: Gain Function Adaptation with Submovement Efficiency Optimization},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376244},
doi = {10.1145/3313831.3376244},
abstract = {A well-designed control-to-display gain function can improve pointing performance with indirect pointing devices like trackpads. However, the design of gain functions is challenging and mostly based on trial and error. AutoGain is a novel method to individualize a gain function for indirect pointing devices in contexts where cursor trajectories can be tracked. It gradually improves pointing efficiency by using a novel submovement-level tracking+optimization technique that minimizes aiming error (undershooting/overshooting) for each submovement. We first show that AutoGain can produce, from scratch, gain functions with performance comparable to commercial designs, in less than a half-hour of active use. Second, we demonstrate AutoGain's applicability to emerging input devices (here, a Leap Motion controller) with no reference gain functions. Third, a one-month longitudinal study of normal computer use with AutoGain showed performance improvements from participants' default functions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pointing, human performance, pointing facilitation, pointer acceleration, submovement, cd gain functions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376207,
author = {Rao, Hrishikesh V. and O'Modhrain, Sile},
title = {2Across: A Comparison of Audio-Tactile and Screen-Reader Based Representations of a Crossword Puzzle},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376207},
doi = {10.1145/3313831.3376207},
abstract = {Crosswords are a popular recreational game that relies on the spatial relationship between words. As a player answers clues, they begin to organize words to form an intersecting grid. A good non-visual representation should convey the interrelation of words and support the user in building a practical spatial image of the crossword grid. This paper looks at two approaches to representing a crossword puzzle for visually impaired users: a screen reader based crossword, and an audio-tactile crossword puzzle. We evaluate the designs in a study with 10 visually impaired participants. The audio-tactile representation was found to support the practical use of the crossword's spatial structure while the screen reader based puzzle leveraged participant's prior experience in navigating websites. The paper discusses critical aspects of our study and presents a perspective on the use of multimodal interfaces for such spatial applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {audio-tactile, refreshable braille display, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376143,
author = {Ahmetovic, Dragan and Sato, Daisuke and Oh, Uran and Ishihara, Tatsuya and Kitani, Kris and Asakawa, Chieko},
title = {ReCog: Supporting Blind People in Recognizing Personal Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376143},
doi = {10.1145/3313831.3376143},
abstract = {We present ReCog, a mobile app that enables blind users to recognize objects by training a deep network with their own photos of such objects. This functionality is useful to differentiate personal objects, which cannot be recognized with pre-trained recognizers and may lack distinguishing tactile features. To ensure that the objects are well-framed in the captured photos, ReCog integrates a camera-aiming guidance that tracks target objects and instructs the user through verbal and sonification feedback to appropriately frame them.We report a two-session study with 10 blind participants using ReCog for object training and recognition, with and without guidance. We show that ReCog enables blind users to train and recognize their personal objects, and that camera-aiming guidance helps novice users to increase their confidence, achieve better accuracy, and learn strategies to capture better photos.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {object recognition, photography guidance, visual impairment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376216,
author = {Marathe, Megh and Chandra, Priyank},
title = {Officers Never Type: Examining the Persistence of Paper in e-Governance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376216},
doi = {10.1145/3313831.3376216},
abstract = {The Global South has seen a proliferation of e-governance initiatives aimed at digitizing governmental service delivery. However, paper continues to remain the primary medium of bureaucracy. During ethnographic fieldwork at the CM Helpline, a state-wide e-governance initiative in central India, we observed that even tech-savvy bureaucrats who fully supported both the initiative and its paper-to-electronic transition ensured that paper continues to persist in abundance. Drawing upon scholarship from HCI, anthropology, and science &amp; technology studies, we theorize this contradiction to uncover the circulations of power between people, paper, and electronic systems. We suggest that designers should recognize that new systems often disempower existing actors. The process of transition should integrate new systems into the existing ecosystem and plan for the graceful retirement of older technologies. In addition to machine errors, systems should be resilient to human errors. Finally, new systems should attend to sociocultural and historical specificities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {e-governance, structural violence, paper, bureaucracy, persistence, design, power},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376524,
author = {August, Tal and Card, Dallas and Hsieh, Gary and Smith, Noah A. and Reinecke, Katharina},
title = {Explain like I Am a Scientist: The Linguistic Barriers of Entry to r/Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376524},
doi = {10.1145/3313831.3376524},
abstract = {As an online community for discussing research findings, r/science has the potential to contribute to science outreach and communication with a broad audience. Yet previous work suggests that most of the active contributors on r/science are science-educated people rather than a lay general public. One potential reason is that r/science contributors might use a different, more specialized language than used in other subreddits. To investigate this possibility, we analyzed the language used in more than 68 million posts and comments from 12 subreddits from 2018. We show that r/science uses a specialized language that is distinct from other subreddits. Transient (newer) authors of posts and comments on r/science use less specialized language than more frequent authors, and those that leave the community use less specialized language than those that stay, even when comparing their first comments. These findings suggest that the specialized language used in r/science has a gatekeeping effect, preventing participation by people whose language does not align with that used in r/science. By characterizing r/science's specialized language, we contribute guidelines and tools for increasing the number of contributors in r/science.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {reddit, social computing, science communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376605,
author = {Watson, Hue and Moju-Igbene, Eyitemi and Kumari, Akanksha and Das, Sauvik},
title = {"We Hold Each Other Accountable": Unpacking How Social Groups Approach Cybersecurity and Privacy Together},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376605},
doi = {10.1145/3313831.3376605},
abstract = {Digital resources are often collectively owned and shared by small social groups (e.g., friends sharing Netflix accounts, roommates sharing game consoles, families sharing WhatsApp groups). Yet, little is known about (i) how these groups jointly navigate cybersecurity and privacy (S&amp;P) decisions for shared resources, (ii) how shared experiences influence individual S&amp;P attitudes and behaviors, and (iii) how well existing S&amp;P controls map onto group needs. We conducted group interviews and a supplemental diary study with nine social groups (n=34) of varying relationship types. We identified why, how and what resources groups shared, their jointly construed threat models, and how these factors influenced group strategies for securing shared resources. We also identified missed opportunities for cooperation and stewardship among group members that could have led to improved S&amp;P behaviors, and found that existing S&amp;P controls often fail to meet the needs of these small social groups.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social cybersecurity, privacy, groups, interviews, security, qualitative methods},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376165,
author = {Dev, Jayati and Rader, Emilee and Patil, Sameer},
title = {Why Johnny Can't Unsubscribe: Barriers to Stopping Unwanted Email},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376165},
doi = {10.1145/3313831.3376165},
abstract = {A large proportion of email messages in an average Internet user's inbox are unwanted commercial messages from mailing lists, bots, and so on. Although such messages often include instructions to unsubscribe, people still struggle with stopping unwanted email. We investigated the user experience of unsubscribing from unwanted email messages by recruiting 18 individuals for via a lab study followed by semi-structured interviews. Based on unsubscribing practices of the study participants, we synthesized eight common unsubscription mechanisms and identified the corresponding user experience challenges. We further uncovered alternative practices aimed at circumventing the need to unsubscribe. Our findings reveal frustration with the prevailing options for limiting access to the self by managing email boundaries. We apply our insight to offer design suggestions that could help commercial providers improve the user experience of unsubscribing and provide users more control over the email they receive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {unwanted email, boundary management, mailing lists, opt-out, newsletters, marketing email, privacy, unsubscribing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376751,
author = {Gerber, Michael A. and Schroeter, Ronald and Xiaomeng, Li and Elhenawy, Mohammed},
title = {Self-Interruptions of Non-Driving Related Tasks in Automated Vehicles: Mobile vs Head-Up Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376751},
doi = {10.1145/3313831.3376751},
abstract = {Automated driving raises new human factors challenges. There is a paradox that allows drivers to perform non-driving related tasks (NDRTs), while benefiting from a driver who regularly attends to the driving task. Systems that aim to better manage a driver's attention, encouraging task switching and interleaving, may help address this paradox. However, a better understanding of how drivers self-interrupt while engaging in NDRTs is required to inform such systems. This paper presents a counterbalanced within-subject simulator study with N=42 participants experiencing automated driving in a familiar driving environment. Participants chose a TV show to watch on a HUD and mobile display during two 15min drives on the same route. Eye and head tracking data revealed more self-interruptions in the HUD condition, suggesting a higher likelihood of a higher situation awareness. Our results may benefit the design of future attention management systems by informing the visual and temporal integration of the driving and non-driving related task.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {self-interruption, non-driving related task, attention management, human-automation interaction, conditionally automated vehicles, task engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376379,
author = {Gr\o{}nb\ae{}k, Jens Emil and Knudsen, Mille Skovhus and O'Hara, Kenton and Krogh, Peter Gall and Vermeulen, Jo and Petersen, Marianne Graves},
title = {Proxemics Beyond Proximity: Designing for Flexible Social Interaction Through Cross-Device Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376379},
doi = {10.1145/3313831.3376379},
abstract = {Cross-device interactions enable ad hoc sharing of content and control in co-located collaboration. Cross-device research often draws from proxemics theory for designing interactions based on detection of spatial relations such as distance and orientation between people and devices. However, detection of human-human or human-device proximity also constrains flexibility in co-located social interaction. We suggest a proxemics-based approach to designing flexible cross-device interactions. From observations in a field study, we articulate how co-located sharing practices are shaped by the interplay between everyday mobile devices and the physical environment. Based on these insights, we present three cross-device prototypes as proofs-of-concept, demonstrating three design sensitivities for considering proxemics beyond proximity; incorporating features in the environment, enabling flexibility in interpersonal distance and orientation, and providing multiple alternative action possibilities. Drawing from characteristics of our prototypes, we discuss concrete proposals for designing cross-device interactions to enable flexible social interaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {proximity sensing, ad hoc collaboration, sensing systems, cross-device interaction, interaction proxemics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376227,
author = {Wu, Shanel and Devendorf, Laura},
title = {Unfabricate: Designing Smart Textiles for Disassembly},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376227},
doi = {10.1145/3313831.3376227},
abstract = {Smart textiles development is combining computing and textile technologies to create tactile, functional objects such as smart garments, soft medical devices, and space suits. However, the field also combines the massive waste streams of both the digital electronics and textiles industries. The following work explores how HCI researchers might be poised to address sustainability and waste in future smart textiles development through interventions at design time. Specifically, we perform a design inquiry into techniques and practices for reclaiming and reusing smart textiles materials and explore how such techniques can be integrated into smart textiles design tools. Beginning with a practice in sustainable or "slow" fashion, unravelling a garment into yarn, the suite of explorations titled "Unfabricate" probes values of time and labor in crafting a garment; speculates how a smart textile garment may be designed with reuse in mind; and imagines how electronic and textile components may be given new life in novel uses.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sustainability, unraveling, knitting, smart textiles, computer-aided design, weaving, disassembly},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376554,
author = {Blaga, Andreea Dalia and Frutos-Pascual, Maite and Creed, Chris and Williams, Ian},
title = {Too Hot to Handle: An Evaluation of the Effect of Thermal Visual Representation on User Grasping Interaction in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376554},
doi = {10.1145/3313831.3376554},
abstract = {Influence of interaction fidelity and rendering quality on perceived user experience have been largely explored in Virtual Reality (VR). However, differences in interaction choices triggered by these rendering cues have not yet been explored. We present a study analysing the effect of thermal visual cues and contextual information on 50 participants' approach to grasp and move a virtual mug. This study comprises 3 different temperature cues (baseline empty, hot and cold) and 4 contextual representations; all embedded in a VR scenario. We evaluate 2 different hand representations (abstract and human) to assess grasp metrics. Results show temperature cues influenced grasp location, with the mug handle being predominantly grasped with a smaller grasp aperture for the hot condition, while the body and top were preferred for baseline and cold conditions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {hand tracking, hand interaction, grasping metrics, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376441,
author = {Yi, Xin and Wang, Chen and Bi, Xiaojun and Shi, Yuanchun},
title = {PalmBoard: Leveraging Implicit Touch Pressure in Statistical Decoding for Indirect Text Entry},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376441},
doi = {10.1145/3313831.3376441},
abstract = {We investigated how to incorporate implicit touch pressure, finger pressure applied to a touch surface during typing, to improve text entry performance via statistical decoding. We focused on one-handed touch-typing on indirect interface as an example scenario. We first collected typing data on a pressure-sensitive touchpad, and analyzed users' typing behavior such as touch point distribution, key-to-finger mappings, and pressure images. Our investigation revealed distinct pressure patterns for different keys. Based on the findings, we performed a series of simulations to iteratively optimize the statistical decoding algorithm. Our investigation led to a Markov-Bayesian decoder incorporating pressure image data into decoding. It improved the top-1 accuracy from 53% to 74% over a naive Bayesian decoder. We then implemented PalmBoard, a text entry method that implemented the Markov-Bayesian decoder and effectively supported one-handed touch-typing on indirect interfaces. A user study showed participants achieved an average speed of 32.8 WPM with 0.6% error rate. Expert typists could achieve 40.2 WPM with 30 minutes of practice. Overall, our investigation showed that incorporating implicit touch pressure is effective in improving text entry decoding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {input prediction, text entry, touch-typing, touch pressure},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

