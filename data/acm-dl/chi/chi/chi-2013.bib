@inproceedings{10.1145/3250108,
author = {Barkhuus, Louise},
title = {Session Details: Papers: Managing Social Media},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250108},
doi = {10.1145/3250108},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470656,
author = {Zhao, Xuan and Salehi, Niloufar and Naranjit, Sasha and Alwaalan, Sara and Voida, Stephen and Cosley, Dan},
title = {The Many Faces of Facebook: Experiencing Social Media as Performance, Exhibition, and Personal Archive},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470656},
doi = {10.1145/2470654.2470656},
abstract = {The growing use of social media means that an increasing amount of people's lives are visible online. We draw from Goffman's theatrical metaphor and Hogan's exhibition approach to explore how people manage their personal collection of social media data over time. We conducted a qualitative study of 13 participants to reveal their day-to-day decision-making about producing and curating digital traces on Facebook. Their goals and strategies showed that people experience the Facebook platform as consisting of three different functional regions: a performance region for managing recent data and impression management, an exhibition region for longer term presentation of self-image, and a personal region for archiving meaningful facets of life. Further, users' need for presenting and archiving data in these three regions is mediated by temporality. These findings trigger a discussion of how to design social media that support these dynamic and sometimes conflicting needs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {exhibition, curation, personal archives, identity, reminiscing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470657,
author = {Jung, Yumi and Gray, Rebecca and Lampe, Cliff and Ellison, Nicole},
title = {Favors from Facebook Friends: Unpacking Dimensions of Social Capital},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470657},
doi = {10.1145/2470654.2470657},
abstract = {Past research has demonstrated a link between perceptions of social capital and use of the popular social network site, Facebook. Williams' Internet Social Capital Scales, based on Putnam's formulation, tap into sub-dimensions of social capital that have not been broadly used yet may enlighten our understanding of the different ways in which connecting with others online can facilitate access to resources embedded within our social relationships. In this study, we segment Williams' Internet Social Capital Scales into various sub-dimensions using factor analysis and explicate the distinct facets of social capital through a lab experiment in which Facebook users (N=98) request a small favor from their Facebook network. We find that some sub-dimensions play a significant role in getting favors from Facebook friends while bonding and bridging social capital do not significantly predict responses to favor requests.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {facebook network, social capital, favor asking},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470658,
author = {Bernstein, Michael S. and Bakshy, Eytan and Burke, Moira and Karrer, Brian},
title = {Quantifying the Invisible Audience in Social Networks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470658},
doi = {10.1145/2470654.2470658},
abstract = {When you share content in an online social network, who is listening? Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate. However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online. In this paper, we combine survey and large-scale log data to examine how well users' perceptions of their audience match their actual audience on Facebook. We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27% of its true size. Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate. We analyze audience logs for 222,000 Facebook users' posts over the course of one month and find that publicly visible signals --- friend count, likes, and comments --- vary widely and do not strongly indicate the audience of a single post. Despite the variation, users typically reach 61% of their friends each month. Together, our results begin to reveal the invisible undercurrents of audience attention and behavior in online social networks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {21–30},
numpages = {10},
keywords = {social networks, audience, information distribution},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470659,
author = {Wang, Yi-Chia and Burke, Moira and Kraut, Robert E.},
title = {Gender, Topic, and Audience Response: An Analysis of User-Generated Content on Facebook},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470659},
doi = {10.1145/2470654.2470659},
abstract = {Although both men and women communicate frequently on Facebook, we know little about what they talk about, whether their topics differ and how their network responds. Using Latent Dirichlet Allocation (LDA), we identify topics from more than half a million Facebook status updates and determine which topics are more likely to receive feedback, such as likes and comments. Women tend to share more personal topics (e.g., family matters), while men discuss more public ones (e.g., politics and sports). Generally, women receive more feedback than men, but "male" topics (those more often posted by men) receive more feedback, especially when posted by women.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {31–34},
numpages = {4},
keywords = {topics, natural language analysis, gender, social networking sites, computer-mediated communication, facebook},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470660,
author = {Shi, Pan and Xu, Heng and Chen, Yunan},
title = {Using Contextual Integrity to Examine Interpersonal Information Boundary on Social Network Sites},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470660},
doi = {10.1145/2470654.2470660},
abstract = {Although privacy problems in Social Network Sites (SNS) have become more salient than ever in recent years, interpersonal privacy issues in SNS remain understudied. This study aims to generate insights in understanding users' interpersonal privacy concerns by expounding interpersonal privacy boundaries in SNS. Through a case analysis of Friendship Pages on Facebook, this paper identifies users' interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity, as well as the tensions that occur within and cross these informational norms. This paper concludes with a discussion of design implications and future research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {35–38},
numpages = {4},
keywords = {interpersonal privacy concerns, facebook, social network sites (sns), friendship pages, privacy boundary},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250109,
author = {Fitzpatrick, Geraldine},
title = {Session Details: Papers: Enhancing Access},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250109},
doi = {10.1145/3250109},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470662,
author = {Waycott, Jenny and Vetere, Frank and Pedell, Sonja and Kulik, Lars and Ozanne, Elizabeth and Gruner, Alan and Downs, John},
title = {Older Adults as Digital Content Producers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470662},
doi = {10.1145/2470654.2470662},
abstract = {Older adults are normally characterized as consumers, rather than producers, of digital content. Current research concerning the design of technologies for older adults typically focuses on providing access to digital resources. Access is important, but is often insufficient, especially when establishing new social relationships. This paper investigates the nature and role of digital content that has been created by older adults, for the purpose of forging new relationships. We present a unique field study in which seven older adults (aged 71-92 years), who did not know each other, used a prototype iPad application (Enmesh) to create and share photographs and messages. The findings demonstrate that older adults, even those in the '1c"oldest old'1d" age group, embraced opportunities to express themselves creatively through digital content production. We show that self-expression and social engagement with peers can be realized when socio-technical systems are suitably designed to allow older adults to create and share their own digital content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {39–48},
numpages = {10},
keywords = {social connection, user-generated content, older adults},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470663,
author = {Liu, Leslie S. and Huh, Jina and Neogi, Tina and Inkpen, Kori and Pratt, Wanda},
title = {Health Vlogger-Viewer Interaction in Chronic Illness Management},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470663},
doi = {10.1145/2470654.2470663},
abstract = {Health video blogs (vlogs) allow individuals with chronic illnesses to share their stories, experiences, and knowledge with the general public. Furthermore, health vlogs help in creating a connection between the vlogger and the viewers. In this work, we present a qualitative study examining the various methods that health vloggers use to establish a connection with their viewers. We found that vloggers used genres to express specific messages to their viewers while using the uniqueness of video to establish a deeper connection with their viewers. Health vloggers also explicitly sought interaction with their viewers. Based on these results, we present design implications to help facilitate and build sustainable communities for vloggers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {49–58},
numpages = {10},
keywords = {youtube, video blogging, health vlogs, communication, chronic illness management, patient-centered},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470664,
author = {Kuksenok, Katie and Brooks, Michael and Mankoff, Jennifer},
title = {Accessible Online Content Creation by End Users},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470664},
doi = {10.1145/2470654.2470664},
abstract = {Like most online content, user-generated content (UGC) poses accessibility barriers to users with disabilities. However, the accessibility difficulties pervasive in UGC warrant discussion and analysis distinct from other kinds of online content. Content authors, community culture, and the authoring tool itself all affect UGC accessibility. The choices, resources available, and strategies in use to ensure accessibility are different than for other types of online content. We contribute case studies of two UGC communities with accessible content: Wikipedia, where authors focus on access to visual materials and navigation, and an online health support forum where users moderate the cognitive accessibility of posts. Our data demonstrate real world moderation strategies and illuminate factors affecting success, such as community culture. We conclude with recommended strategies for creating a culture of accessibility around UGC.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {59–68},
numpages = {10},
keywords = {user-generated content, accessibility},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470665,
author = {Ban, Yuki and Narumi, Takuji and Fujii, Tatsuya and Sakurai, Sho and Imura, Jun and Tanikawa, Tomohiro and Hirose, Michitaka},
title = {Augmented Endurance: Controlling Fatigue While Handling Objects by Affecting Weight Perception Using Augmented Reality},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470665},
doi = {10.1145/2470654.2470665},
abstract = {The main contribution of this paper is to develop a method for alleviating fatigue during handling medium-weight objects and augmenting our endurance by affecting our weight perception with augmented reality technology. To assist people to lift medium-weight objects without a complex structure or various costs, we focus on the phenomenon that our weight perception during handling objects is affected by visual properties. Our hypothesis is that this illusionary effect in weight perception can be applied to reduce fatigue while handling medium-weight objects without mechatronics-based physical assistance. In this paper, we propose an augmented reality system that changes the brightness value of an object in order to reduce fatigue while handling the object. We conducted two fundamental experiments to investigate the effectiveness of the proposed system. Our results suggested that the system eliminates the need to use excess energy for handling objects and reduces fatigue during the handling task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {69–78},
numpages = {10},
keywords = {weight perception, assistance for physical work, augmented reality, cross-modal interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250110,
author = {Kerne, Andruid},
title = {Session Details: Papers: Learning},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250110},
doi = {10.1145/3250110},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470667,
author = {Harpstead, Erik and Myers, Brad A. and Aleven, Vincent},
title = {In Search of Learning: Facilitating Data Analysis in Educational Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470667},
doi = {10.1145/2470654.2470667},
abstract = {The field of Educational Games has seen many calls for added rigor. One avenue for improving the rigor of the field is developing more generalizable methods for measuring student learning within games. Throughout the process of development, what is relevant to measure and assess may change as a game evolves into a finished product. The field needs an approach for game developers and researchers to be able to prototype and experiment with different measures that can stand up to rigorous scrutiny, as well as provide insight into possible new directions for development. We demonstrate a toolkit and analysis tools that capture and analyze students' performance within open educational games. The system records relevant events during play, which can be used for analysis of player learning by designers. The tools support replaying student sessions within the original game's environment, which allows researchers and developers to explore possible explanations for student behavior. Using this system, we were able to facilitate a number of analyses of student learning in an open educational game developed by a team of our collaborators as well as gain greater insight into student learning with the game and where to focus as we iterate.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {79–88},
numpages = {10},
keywords = {toolkits, educational games, logging, analysis of learning},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470668,
author = {Lomas, Derek and Patel, Kishan and Forlizzi, Jodi L. and Koedinger, Kenneth R.},
title = {Optimizing Challenge in an Educational Game Using Large-Scale Design Experiments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470668},
doi = {10.1145/2470654.2470668},
abstract = {Online games can serve as research instruments to explore the effects of game design elements on motivation and learning. In our research, we manipulated the design of an online math game to investigate the effect of challenge on player motivation and learning. To test the '1cInverted-U Hypothesis'1d, which predicts that maximum game engagement will occur with moderate challenge, we produced two large-scale (10K and 70K subjects), multi-factor (2x3 and 2x9x8x4x25) online experiments. We found that, in almost all cases, subjects were more engaged and played longer when the game was easier, which seems to contradict the generality of the Inverted-U Hypothesis. Troublingly, we also found that the most engaging design conditions produced the slowest rates of learning. Based on our findings, we describe several design implications that may increase challenge-seeking in games, such as providing feedforward about the anticipated degree of challenge.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {89–98},
numpages = {10},
keywords = {games, design, education, crowdsourcing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470669,
author = {Foster, Stephen R. and Esper, Sarah and Griswold, William G.},
title = {From Competition to Metacognition: Designing Diverse, Sustainable Educational Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470669},
doi = {10.1145/2470654.2470669},
abstract = {We investigate the unique educational benefits of 1-on-1 competitive games, arguing that such games can be just as easy to design as single-player educational games, while yielding a more diverse and sustainable learning experience. We present a study of chess and StarCraft II in order to inform the design of similar educational games and their communities. We discuss a competitive game we designed to teach Java programming. We evaluate the game by discussing its user study. Our main contributions are 1) an argument that the use of 1-on-1 competition can solve two existing problems inherent to single-player games, 2) an analysis of the features that make competitive games effective learning environments, and 3) an early but encouraging description of the emergent learning environment one can expect from designing an educational game with these features.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {99–108},
numpages = {10},
keywords = {games, education},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470670,
author = {Rau, Martina A. and Aleven, Vincent and Rummel, Nikol and Rohrbach, Stacie},
title = {Why Interactive Learning Environments Can Have It All: Resolving Design Conflicts between Competing Goals},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470670},
doi = {10.1145/2470654.2470670},
abstract = {Designing interactive learning environments (ILEs; e.g., intelligent tutoring systems, educational games, etc.) is a challenging interdisciplinary process that needs to satisfy multiple stakeholders. ILEs need to function in real educational settings (e.g., schools) in which a number of goals interact. Several instructional design methodologies exist to help developers address these goals. However, they often lead to conflicting recommendations. Due to the lack of an established methodology to resolve such conflicts, developers of ILEs have to rely on ad-hoc solutions. We present a principled methodology to resolve such conflicts. We build on a well-established design process for creating Cognitive Tutors, a highly effective type of ILE. We extend this process by integrating methods from multiple disciplines to resolve design conflicts. We illustrate our methodology's effectiveness by describing the iterative development of the Fractions Tutor, which has proven to be effective in classroom studies with 3,000 4th-6th graders.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {109–118},
numpages = {10},
keywords = {cognitive tutors, interactive learning environments, instructional design, design conflicts},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2470670_R48799,
author = {Godwin, Stewart Mark},
title = {Review ID:R48799 for DOI: 10.1145/2470654.2470670},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2470670_R48799}
}

@dataset{10.1145/review-2470654.2470670_R48845,
author = {Hazeltine, Barrett},
title = {Review ID:R48845 for DOI: 10.1145/2470654.2470670},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2470670_R48845}
}

@inproceedings{10.1145/3250111,
author = {Jirotka, Marina},
title = {Session Details: Papers: Interaction in the Wild},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250111},
doi = {10.1145/3250111},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470672,
author = {Pierce, James and Paulos, Eric},
title = {Electric Materialities and Interactive Technology},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470672},
doi = {10.1145/2470654.2470672},
abstract = {This paper offers new theoretical and design insights into nteractive technology. By initially considering electric technology broadly, our work informs how HCI approaches a range of specific interactive or digital things and materials. Theoretically, we contribute a rigorous analysis of electric technology using the experiential lens of phenomenology. A major result is to characterize electric technology by three forms of materiality: the electric object, its electric materiality, and electric power. In terms of design, we present and analyze novel interactive form prototypes. Our theoretical contributions offer new insight into design artifacts, just as our novel design artifacts help reveal new theoretical insight.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {119–128},
numpages = {10},
keywords = {electricity, interaction design, design theory},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470673,
author = {Jacobs, Rachel and Benford, Steve and Selby, Mark and Golembewski, Michael and Price, Dominic and Giannachi, Gabriella},
title = {A Conversation between Trees: What Data Feels like in the Forest},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470673},
doi = {10.1145/2470654.2470673},
abstract = {A study of an interactive artwork shows how artists engaged the public with scientific climate change data. The artwork visualised live environmental data collected from remote trees, alongside both historical and forecast global CO2 data. Visitors also took part in a mobile sensing experience in a nearby forest. Our study draws on the perspectives of the artists, visitors and a climate scientist to reveal how the work was designed and experienced. We show that the artists adopted a distinct approach that fostered an emotional engagement with data rather than an informative or persuasive one. We chart the performative strategies they used to achieve this including sensory engagement with data, a temporal structure that balanced liveness with slowness, and the juxtaposition of different treatments of the data to enable interpretation and dialogue.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {129–138},
numpages = {10},
keywords = {embodied, liveness, environmentally engaged art, performance, sensory, slowness, sustainability, climate},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470674,
author = {Blythe, Mark and Briggs, Jo and Hook, Jonathan and Wright, Peter and Olivier, Patrick},
title = {Unlimited Editions: Three Approaches to the Dissemination and Display of Digital Art},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470674},
doi = {10.1145/2470654.2470674},
abstract = {The paper reflects on three approaches to the dissemination and display of digital art. '1c"s[edition]'1d" is a novel, web-based service that offers limited editions of "'1cdigital prints"'1d. Analysis of user comments suggests that the metaphor of a '1c"limited digital edition"'1d raises issues and to some extent is resisted. The second approach is the Flickr Brushes Gallery, where digital painters post images and comment on one another's work. Analysis of comment boards indicates that the shared art and comments are a form of gift exchange. Finally, the paper discusses a field study in which artists exhibited their work as it develops over time in digital frames and also in an immersive digital projection room. Analysis of field notes and interviews indicate that the digital frame approach was unsuccessful because of aesthetic and environmental concerns. The immersive projection suggested that more experiential approaches may be more interesting. It is argued that there is an inherent resistance in digital media to previous models of art commoditization. None of the approaches discussed here resolve the dilemma but rather indicate the scope and complexity of the issues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {139–148},
numpages = {10},
keywords = {digital culture, ethnography, art, interaction design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470675,
author = {Fosh, Lesley and Benford, Steve and Reeves, Stuart and Koleva, Boriana and Brundell, Patrick},
title = {See Me, Feel Me, Touch Me, Hear Me: Trajectories and Interpretation in a Sculpture Garden},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470675},
doi = {10.1145/2470654.2470675},
abstract = {We apply the HCI concept of trajectories to the design of a sculpture trail. We crafted a trajectory through each sculpture, combining textual and audio instructions to drive directed viewing, movement and touching while listening to accompanying music. We designed key transitions along the way to oscillate between moments of social interaction and isolated personal engagement, and to deliver official interpretation only after visitors had been given the opportunity to make their own. We describe how visitors generally followed our trajectory, engaging with sculptures and making interpretations that sometimes challenged the received interpretation. We relate our findings to discussions of sense-making and design for multiple interpretations, concluding that curators and designers may benefit from considering '18trajectories of interpretation'.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {149–158},
numpages = {10},
keywords = {trajectories, audio, art, collaboration, instructions., galleries, interpretation, sculpture, museums},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250112,
author = {Cubaud, Pierre},
title = {Session Details: Papers: 3D User Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250112},
doi = {10.1145/3250112},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470677,
author = {Teather, Robert J. and Stuerzlinger, Wolfgang},
title = {Pointing at 3d Target Projections with One-Eyed and Stereo Cursors},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470677},
doi = {10.1145/2470654.2470677},
abstract = {We present a study of cursors for selecting 2D-projected 3D targets. We compared a stereo- and mono-rendered (one-eyed) cursor using two mouse-based and two remote pointing techniques in a 3D Fitts' law pointing experiment. The first experiment used targets at fixed depths. Results indicate that one-eyed cursors only improve screen-plane pointing techniques, and that constant target depth does not influence pointing throughput. A second experiment included pointing between targets at varying depths and used only "screen-plane" pointing techniques. Our results suggest that in the absence of stereo cue conflicts, screen-space projections of Fitts' law parameters (target size and distance) yield constant throughput despite target depth differences and produce better models of performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {159–168},
numpages = {10},
keywords = {cursors, fitts'19 law, 3d pointing, selection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470678,
author = {Schild, Jonas and B\"{o}licke, Liane and LaViola Jr., Joseph J. and Masuch, Maic},
title = {Creating and Analyzing Stereoscopic 3D Graphical User Interfaces in Digital Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470678},
doi = {10.1145/2470654.2470678},
abstract = {Creating graphical user interfaces (GUI) for stereoscopic 3D (S3D) games is a difficult choice between visual comfort and effect. We present a S3D Game GUI Design Space and a list of S3D-specific attributes that emphasizes integrating visually comfortable interfaces into the game world, story and S3D view. To showcase our approach, we created two GUI concepts and evaluated them with 32 users. Our results show quality improvements for a combination of bottom position and visual attachment for a menu. In a referencing interface, placing the reference near to the target depth significantly improved perceived quality, game integration, and increased presence. These results confirm the need to create S3D GUIs with perceptual constraints in mind, demonstrating the potential to extend the user experience. Additionally, our design space offers a formal and flexible way to create new effects in S3D GUIs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {169–178},
numpages = {10},
keywords = {visual 3d quality, presence, stereoscopic 3d, depth, user experience, game, design space, graphical user interface},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470679,
author = {Sodhi, Rajinder S. and Jones, Brett R. and Forsyth, David and Bailey, Brian P. and Maciocci, Giuliano},
title = {BeThere: 3D Mobile Collaboration with Spatial Input},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470679},
doi = {10.1145/2470654.2470679},
abstract = {We present BeThere, a proof-of-concept system designed to explore 3D input for mobile collaborative interactions. With BeThere, we explore 3D gestures and spatial input which allow remote users to perform a variety of virtual interactions in a local user's physical environment. Our system is completely self-contained and uses depth sensors to track the location of a user's fingers as well as to capture the 3D shape of objects in front of the sensor. We illustrate the unique capabilities of our system through a series of interactions that allow users to control and manipulate 3D virtual content. We also provide qualitative feedback from a preliminary user study which confirmed that users can complete a shared collaborative task using our system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {179–188},
numpages = {10},
keywords = {depth sensors, collaboration, augmented reality, around device interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470680,
author = {Lee, Jinha and Olwal, Alex and Ishii, Hiroshi and Boulanger, Cati},
title = {SpaceTop: Integrating 2D and Spatial 3D Interactions in a See-through Desktop Environment},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470680},
doi = {10.1145/2470654.2470680},
abstract = {SpaceTop is a concept that fuses spatial 2D and 3D interactions in a single workspace. It extends the traditional desktop interface with interaction technology and visualization techniques that enable seamless transitions between 2D and 3D manipulations. SpaceTop allows users to type, click, draw in 2D, and directly manipulate interface elements that float in the 3D space above the keyboard. It makes it possible to easily switch from one modality to another, or to simultaneously use two modalities with different hands. We introduce hardware and software configurations for co-locating these various interaction modalities in a unified workspace using depth cameras and a transparent display. We describe new interaction and visualization techniques that allow users to interact with 2D elements floating in 3D space. We present the results from a preliminary user study that indicates the benefit of such hybrid workspaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {189–192},
numpages = {4},
keywords = {augmented reality, desktop management, 3d ui},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470681,
author = {Ortega, Michael},
title = {3D Object Position Using Automatic Viewpoint Transitions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470681},
doi = {10.1145/2470654.2470681},
abstract = {This paper presents IUCA (Interaction Using Camera Animations), a new interaction technique for 3D objects manipulation. IUCA allows efficient interaction in a full-resolution perspective view by integrating transients animated transitions to orthographic views into the manipulation task. This provides an interaction in context, with precise object positioning and alignment. An evaluation of the technique shows that, compared to the classical configurations, IUCA allows to reduce pointing time by 14% on average. Testing with professional 3D designers and novice users indicate that IUCA is easy to use and to learn; and that users feel comfortable with it.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {193–196},
numpages = {4},
keywords = {3d pointing, four-views configuration, 3d interaction, 3d modeling, fitts' law},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250113,
author = {Parikh, Tapan},
title = {Session Details: Papers: Crowdsourcing: People Power},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250113},
doi = {10.1145/3250113},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470683,
author = {O'Neill, Jacki and Roy, Shourya and Grasso, Antonietta and Martin, David},
title = {Form Digitization in BPO: From Outsourcing to Crowdsourcing?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470683},
doi = {10.1145/2470654.2470683},
abstract = {This paper describes an ethnographic study of an outsourced business process - the digitization of healthcare forms. The aim of the study was to understand how the work is currently organized, with an eye to uncovering the research challenges which need to be addressed if that work is to be crowdsourced. The findings are organised under four emergent themes: Workplace Ecology, Data Entry Skills and Knowledge, Achieving Targets and Collaborative Working. For each theme a description of how the work is undertaken in the outsourcer's Indian office locations is given, followed by the implications for crowdsourcing that work. This research is a first step in understanding how crowdsourcing might be applied to BPO activities. The paper examines features specific to form digitization - extreme distribution and form decomposition - and lightly touches on the crowdsourcing of BPO work more generally.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {197–206},
numpages = {10},
keywords = {business process, outsourcing, crowdsourcing, ethnography},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470684,
author = {Komarov, Steven and Reinecke, Katharina and Gajos, Krzysztof Z.},
title = {Crowdsourcing Performance Evaluations of User Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470684},
doi = {10.1145/2470654.2470684},
abstract = {Online labor markets, such as Amazon's Mechanical Turk (MTurk), provide an attractive platform for conducting human subjects experiments because the relative ease of recruitment, low cost, and a diverse pool of potential participants enable larger-scale experimentation and faster experimental revision cycle compared to lab-based settings. However, because the experimenter gives up the direct control over the participants' environments and behavior, concerns about the quality of the data collected in online settings are pervasive. In this paper, we investigate the feasibility of conducting online performance evaluations of user interfaces with anonymous, unsupervised, paid participants recruited via MTurk. We implemented three performance experiments to re-evaluate three previously well-studied user interface designs. We conducted each experiment both in lab and online with participants recruited via MTurk. The analysis of our results did not yield any evidence of significant or substantial differences in the data collected in the two settings: All statistically significant differences detected in lab were also present on MTurk and the effect sizes were similar. In addition, there were no significant differences between the two settings in the raw task completion times, error rates, consistency, or the rates of utilization of the novel interaction mechanisms introduced in the experiments. These results suggest that MTurk may be a productive setting for conducting performance evaluations of user interfaces providing a complementary approach to existing methodologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {207–216},
numpages = {10},
keywords = {mechanical turk, user interface evaluation, crowdsourcing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470685,
author = {Chilana, Parmit K. and Ko, Andrew J. and Wobbrock, Jacob O. and Grossman, Tovi},
title = {A Multi-Site Field Study of Crowdsourced Contextual Help: Usage and Perspectives of End Users and Software Teams},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470685},
doi = {10.1145/2470654.2470685},
abstract = {We present a multi-site field study to evaluate LemonAid, a crowdsourced contextual help approach that allows users to retrieve relevant questions and answers by making selections within the interface. We deployed LemonAid on 4 different web sites used by thousands of users and collected data over several weeks, gathering over 1,200 usage logs, 168 exit surveys, and 36 one-on-one interviews. Our results indicate that over 70% of users found LemonAid to be helpful, intuitive, and desirable for reuse. Software teams found LemonAid easy to integrate with their sites and found the analytics data aggregated by LemonAid a novel way of learning about users' popular questions. Our work provides the first holistic picture of the adoption and use of a crowdsourced contextual help system and offers several insights into the social and organizational dimensions of implementing such help systems for real-world applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {217–226},
numpages = {10},
keywords = {contextual help, crowdsourced help, software support=., field studies, field deployments, help systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470686,
author = {Dow, Steven and Gerber, Elizabeth and Wong, Audris},
title = {A Pilot Study of Using Crowds in the Classroom},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470686},
doi = {10.1145/2470654.2470686},
abstract = {Industry relies on higher education to prepare students for careers in innovation. Fulfilling this obligation is especially difficult in classroom settings, which often lack authentic interaction with the outside world. Online crowdsourcing has the potential to change this. Our research explores if and how online crowds can support student learning in the classroom. We explore how scalable, diverse, immediate (and often ambiguous and conflicting) input from online crowds affects student learning and motivation for project-based innovation work. In a pilot study with three classrooms, we explore interactions with the crowd at four key stages of the innovation process: needfinding, ideating, testing, and pitching. Students reported that online crowds helped them quickly and inexpensively identify needs and uncover issues with early-stage prototypes, although they favored face-to-face interactions for more contextual feed-back. We share early evidence and discuss implications for creating a socio-technical infrastructure to more effectively use crowdsourcing in education.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {227–236},
numpages = {10},
keywords = {education, feedback, innovation, crowdsourcing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250114,
author = {Fogarty, James},
title = {Session Details: Papers: Multitouch and Gesture},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250114},
doi = {10.1145/3250114},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470688,
author = {Steimle, J\"{u}rgen and Jordt, Andreas and Maes, Pattie},
title = {Flexpad: Highly Flexible Bending Interactions for Projected Handheld Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470688},
doi = {10.1145/2470654.2470688},
abstract = {Flexpad is an interactive system that combines a depth camera and a projector to transform sheets of plain paper or foam into flexible, highly deformable, and spatially aware handheld displays. We present a novel approach for tracking deformed surfaces from depth images in real time. It captures deformations in high detail, is very robust to occlusions created by the user's hands and fingers, and does not require any kind of markers or visible texture. As a result, the display is considerably more deformable than in previous work on flexible handheld displays, enabling novel applications that leverage the high expressiveness of detailed deformation. We illustrate these unique capabilities through three application examples: curved cross-cuts in volumetric images, deforming virtual paper characters, and slicing through time in videos. Results from two user studies show that our system is capable of detecting complex deformations and that users are able to perform them quickly and precisely.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {237–246},
numpages = {10},
keywords = {tracking, flexible display, bending, depth camera, handheld display, projection, volumetric data, deformation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470689,
author = {Sun, Qian and Lin, Juncong and Fu, Chi-Wing and Kaijima, Sawako and He, Ying},
title = {A Multi-Touch Interface for Fast Architectural Sketching and Massing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470689},
doi = {10.1145/2470654.2470689},
abstract = {Architectural sketching and massing are used by designers to analyze and explore the design space of buildings. This paper describes a novel multi-touch interface for fast architectural sketching and massing of tall buildings. It incorporates a family of multi-touch gestures, enabling one to quickly sketch the 2D contour of a base floor plan and extrude it to model a building with multi-floor structures. Further, it provides a set of gestures to users: select and edit a range of floors; scale contours of a building; copy, paste, and rotate a building, i.e., create a twisted structure; edit profile curves of a building's profile; and collapse and remove a selected range of floors. The multi-touch system also allows users to apply textures or geometric facades to the building, and to compare different designs side-by-side. To guide the design process, we describe interactions with a domain expert, a practicing architect. The final interface is evaluated by architects and students in an architecture Dept., which demonstrates that the system allows rapid conceptual design and massing of novel multi-story building structures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {247–256},
numpages = {10},
keywords = {sketching, massing, multi-touch, building design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470690,
author = {L\"{u}, Hao and Li, Yang},
title = {Gesture Studio: Authoring Multi-Touch Interactions through Demonstration and Declaration},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470690},
doi = {10.1145/2470654.2470690},
abstract = {The prevalence of multi-touch devices opens the space for rich interactions. However, the complexity for creating multi-touch interactions hinders this potential. In this paper, we present Gesture Studio, a tool for creating multi-touch interaction behaviors by combining the strength of two distinct but complementary approaches: programming by demonstration and declaration. We employ an intuitive video-authoring metaphor for developers to demonstrate touch gestures, compose complicated behaviors, test these behaviors in the tool and export them as source code that can be integrated into the developers' project.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {257–266},
numpages = {10},
keywords = {declaration, multi-touch gestures, probabilistic reasoning, state machines, programming by demonstration},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470691,
author = {Kim, Ju-Whan and Nam, Tek-Jin},
title = {EventHurdle: Supporting Designers' Exploratory Interaction Prototyping with Gesture-Based Sensors},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470691},
doi = {10.1145/2470654.2470691},
abstract = {Prototyping of gestural interactions in the early phase of design is one of the most challenging tasks for designers without advanced programming skills. Relating users' input from gesture-based sensor values requires a great deal of effort on the designer's part and disturbs their reflective and creative thinking. To deal with this problem, we present EventHurdle, a visual gesture-authoring tool to support designers' explorative prototyping. It supports remote gestures from a camera, handheld gestures with physical sensors, and touch gestures by utilizing touch screens. EventHurdle allows designers to visually define and modify gestures through interaction workspace and graphical markup language with hurdles. Because the created gestures can be integrated into a prototype as programming code and automatically recognized, designers do not need to pay attention in sensor-related implementation. Two user studies and a recognition test are reported to discuss the acceptance and implications of explorative prototyping tools for designers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {267–276},
numpages = {10},
keywords = {visual programming, gesture-based interaction, exploratory prototyping},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470692,
author = {Vatavu, Radu-Daniel and Casiez, G\'{e}ry and Grisoni, Laurent},
title = {Small, Medium, or Large? Estimating the User-Perceived Scale of Stroke Gestures},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470692},
doi = {10.1145/2470654.2470692},
abstract = {We show that large consensus exists among users in the way they articulate stroke gestures at various scales (i.e., small, medium, and large), and formulate a simple rule that estimates the user-intended scale of input gestures with 87% accuracy. Our estimator can enhance current gestural interfaces by leveraging scale as a natural parameter for gesture input, reflective of user perception (i.e., no training required). Gesture scale can simplify gesture set design, improve gesture-to-function mappings, and reduce the need for users to learn and for recognizers to discriminate unnecessary symbols.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {277–280},
numpages = {4},
keywords = {pen gestures, bayes' rule, gesture recognition, gesture articulation, gesture size, gesture scale, human factors},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470693,
author = {Heo, Seongkook and Lee, Geehyuk},
title = {Indirect Shear Force Estimation for Multi-Point Shear Force Operations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470693},
doi = {10.1145/2470654.2470693},
abstract = {The possibility of using shear forces is being explored recently as a method to enrich touch screen interaction. However, most of the related studies are restricted to the case of single-point shear forces, possibly owing to the difficulty of independently sensing shear forces at multiple touch points. In this paper, we propose indirect methods to estimate shear forces using the movement of contact areas. These methods enable multi-point shear force estimation, where the estimation is done for each finger independently. We show the feasibility of these methods through an informal user study with a demo application utilizing these methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {281–284},
numpages = {4},
keywords = {shear force, touch screen, force sensing, multi-touch},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250115,
author = {Bartram, Lyn},
title = {Session Details: Papers: Gaze},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250115},
doi = {10.1145/3250115},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470695,
author = {Stellmach, Sophie and Dachselt, Raimund},
title = {Still Looking: Investigating Seamless Gaze-Supported Selection, Positioning, and Manipulation of Distant Targets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470695},
doi = {10.1145/2470654.2470695},
abstract = {We investigate how to seamlessly bridge the gap between users and distant displays for basic interaction tasks, such as object selection and manipulation. For this, we take advantage of very fast and implicit, yet imprecise gaze- and head-directed input in combination with ubiquitous smartphones for additional manual touch control. We have carefully elaborated two novel and consistent sets of gaze-supported interaction techniques based on touch-enhanced gaze pointers and local magnification lenses. These conflict-free sets allow for fluently selecting and positioning distant targets. Both sets were evaluated in a user study with 16 participants. Overall, users were fastest with a touch-enhanced gaze pointer for selecting and positioning an object after some training. While the positive user feedback for both sets suggests that our proposed gaze- and head-directed interaction techniques are suitable for a convenient and fluent selection and manipulation of distant targets, further improvements are necessary for more precise cursor control.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {285–294},
numpages = {10},
keywords = {mobile touch input, eye tracking, visual attention, distant displays, positioning, gaze interaction, selection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470696,
author = {Toker, Dereck and Conati, Cristina and Steichen, Ben and Carenini, Giuseppe},
title = {Individual User Characteristics and Information Visualization: Connecting the Dots through Eye Tracking},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470696},
doi = {10.1145/2470654.2470696},
abstract = {There is increasing evidence that users' characteristics such as cognitive abilities and personality have an impact on the effectiveness of information visualization techniques. This paper investigates the relationship between such characteristics and fine-grained user attention patterns. In particular, we present results from an eye tracking user study involving bar graphs and radar graphs, showing that a user's cognitive abilities such as perceptual speed and verbal working memory have a significant impact on gaze behavior, both in general and in relation to task difficulty and visualization type. These results are discussed in view of our long-term goal of designing information visualisation systems that can dynamically adapt to individual user characteristics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {295–304},
numpages = {10},
keywords = {adaptive information visualization, information visualization, eye tracking, user characteristics},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470697,
author = {Bulling, Andreas and Weichel, Christian and Gellersen, Hans},
title = {EyeContext: Recognition of High-Level Contextual Cues from Human Visual Behaviour},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470697},
doi = {10.1145/2470654.2470697},
abstract = {In this work we present EyeContext, a system to infer high-level contextual cues from human visual behaviour. We conducted a user study to record eye movements of four participants over a full day of their daily life, totalling 42.5 hours of eye movement data. Participants were asked to self-annotate four non-mutually exclusive cues: social (interacting with somebody vs. no interaction), cognitive (concentrated work vs. leisure), physical (physically active vs. not active), and spatial (inside vs. outside a building). We evaluate a proof-of-concept EyeContext system that combines encoding of eye movements into strings and a spectrum string kernel support vector machine (SVM) classifier. Our results demonstrate the large information content available in long-term human visual behaviour and opens up new venues for research on eye-based behavioural monitoring and life logging.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {305–308},
numpages = {4},
keywords = {eye movement analysis, visual behaviour, context recognition, electrooculography (eog)},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470698,
author = {Lee, Joong Ho and Kim, Sei-young and Yoon, Hae Cheol and Huh, Bo Kyung and Park, Ji-Hyung},
title = {A Preliminary Investigation of Human Adaptations for Various Virtual Eyes in Video See-through HMDS},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470698},
doi = {10.1145/2470654.2470698},
abstract = {A video see-through head mounted display (HMD) has a different viewing point than does the real eye, resulting in visual displacement (VD). VD deteriorates visuomotor performance due to sensory conflict. Previous work has investigated this deterioration and human adaptation by comparing fixed VD and real eye conditions. In this study we go a step further to investigate whether any differences in visuomotor and adaptation trends exist across 16 distinct VD conditions. The performance tasks studied were of two types: foot placement and finger touch. In contrast to our initial prediction, the results showed equal task performance levels and adaptation within about 5 minutes regardless of VD conditions. We found that human adaptation covered a variety of VDs --- up to 55 mm in the X, Y direction; up to 125mm in the Z direction; and up to 140mm of interocular distance (IOD). In addition, we found that partial adaptation gave participants the interesting experience of a sense of body structure distortion for a few minutes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {309–312},
numpages = {4},
keywords = {immersive reality, adaptation, visual displacement, visuomotor, task performance., hmd, video see-through},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250116,
author = {Bigham, Jeffrey},
title = {Session Details: Papers: Technologies for Life 1},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250116},
doi = {10.1145/3250116},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470700,
author = {Gibson, Lorna and Hanson, Vicki L.},
title = {Digital Motherhood: How Does Technology Help New Mothers?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470700},
doi = {10.1145/2470654.2470700},
abstract = {New mothers can experience social exclusion, particularly during the early weeks when infants are solely dependent on their mothers. We used ethnographic methods to investigate whether technology plays a role in supporting new mothers. Our research identified two core themes: (1) the need to improve confidence as a mother; and (2) the need to be more than '18just' a mother. We reflect on these findings both in terms of those interested in designing applications and services for motherhood and also the wider CHI community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {313–322},
numpages = {10},
keywords = {social support, motherhood, new mothers, ethnography},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470701,
author = {Nicholson, James and Coventry, Lynne and Briggs, Pam},
title = {Age-Related Performance Issues for PIN and Face-Based Authentication Systems},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470701},
doi = {10.1145/2470654.2470701},
abstract = {Graphical authentication systems typically claim to be more usable than PIN or password-based systems, but these claims often follow limited, single-stage paradigm testing on a young, student population. We present a more demanding test paradigm in which multiple codes are learned and tested over a three-week period. We use this paradigm with two user populations, comparing the performance of younger and older adults. We first establish baseline performance in a study in which populations of younger and older adults learn PIN codes and we follow this with a second study in which younger and older adults use two face-based graphical authentication systems employing young faces vs. old faces as code components. As expected, older adults show relatively poor performance when compared to younger adults, irrespective of the authentication material, but this age-related deficit can be markedly reduced by the introduction of age-appropriate faces. We conclude firstly that this paradigm provides a good basis for the future evaluation of memory-based authentication systems and secondly that age-appropriate face-based authentication is viable in the security marketplace.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {323–332},
numpages = {10},
keywords = {older adults, authentication, usable security, graphical codes},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470702,
author = {Lauckner, Carolyn and Hsieh, Gary},
title = {The Presentation of Health-Related Search Results and Its Impact on Negative Emotional Outcomes},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470702},
doi = {10.1145/2470654.2470702},
abstract = {Searching for health information online has become increasingly common, yet few studies have examined potential negative emotional effects of online health information search. We present results from an experiment manipulating the presentation of search results for common symptoms, which shows that the frequency and placement of serious illness mentions within results can influence perceptions of symptom severity and susceptibility of having the serious illness, respectively. The increase in severity and susceptibility can then lead to higher levels of negative emotional outcomes experienced--including feeling overwhelmed and frightened. Interestingly, health literacy can help reduce perceived symptom severity, and high online health experience actually increases the likelihood that individuals use a frequency-based heuristic. Technological implications and directions for future research are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {333–342},
numpages = {10},
keywords = {health literacy, negative effects, online health information},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470703,
author = {Findlater, Leah and Froehlich, Jon E. and Fattal, Kays and Wobbrock, Jacob O. and Dastyar, Tanya},
title = {Age-Related Differences in Performance with Touchscreens Compared to Traditional Mouse Input},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470703},
doi = {10.1145/2470654.2470703},
abstract = {Despite the apparent popularity of touchscreens for older adults, little is known about the psychomotor performance of these devices. We compared performance between older adults and younger adults on four desktop and touchscreen tasks: pointing, dragging, crossing and steering. On the touchscreen, we also examined pinch-to-zoom. Our results show that while older adults were significantly slower than younger adults in general, the touchscreen reduced this performance gap relative to the desktop and mouse. Indeed, the touchscreen resulted in a significant movement time reduction of 35% over the mouse for older adults, compared to only 16% for younger adults. Error rates also decreased.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {343–346},
numpages = {4},
keywords = {older adults, input, accessibility, touchscreens},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470704,
author = {Kane, Shaun K. and Frey, Brian and Wobbrock, Jacob O.},
title = {Access Lens: A Gesture-Based Screen Reader for Real-World Documents},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470704},
doi = {10.1145/2470654.2470704},
abstract = {Gesture-based touch screen user interfaces, when designed to be accessible to blind users, can be an effective mode of interaction for those users. However, current accessible touch screen interaction techniques suffer from one serious limitation: they are only usable on devices that have been explicitly designed to support them. Access Lens is a new interaction method that uses computer vision-based gesture tracking to enable blind people to use accessible gestures on paper documents and other physical objects, such as product packages, device screens, and home appliances. This paper describes the development of Access Lens hardware and software, the iterative design of Access Lens in collaboration with blind computer users, and opportunities for future development.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {347–350},
numpages = {4},
keywords = {computer vision, gestures, augmented reality, accessibility, blindness},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250117,
author = {Jameson, Anthony},
title = {Session Details: Papers: Evaluation Methods 1},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250117},
doi = {10.1145/3250117},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470706,
author = {Huisman, Gijs and van Hout, Marco and van Dijk, Elisabeth and van der Geest, Thea and Heylen, Dirk},
title = {LEMtool: Measuring Emotions in Visual Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470706},
doi = {10.1145/2470654.2470706},
abstract = {In this paper the development process and validation of the LEMtool (Layered Emotion Measurement tool) are described. The LEMtool consists of eight images that display a cartoon figure expressing four positive and four negative emotions using facial expressions and body postures. The instrument can be used during interaction with a visual interface, such as a website, and allows participants to select elements of the interface that elicit a certain emotion. The images of the cartoon figure were submitted to a validation study, in which participants rated the recognizability of the images as specific emotions. All images were found to be recognizable above chance level. In another study, the LEMtool was used to assess visual appeal judgements of a number of web pages. The LEMtool ratings were supported by visual appeal ratings of web pages both for very brief (50 milliseconds) and for long (free-viewing) stimulus exposures. Furthermore, the instrument provided insight into the elements of the web pages that elicited the emotional responses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {351–360},
numpages = {10},
keywords = {web pages., lemtool, visual appeal, emotion, user experience},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470707,
author = {Nov, Oded and Arazy, Ofer and L\'{o}pez, Claudia and Brusilovsky, Peter},
title = {Exploring Personality-Targeted UI Design in Online Social Participation Systems},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470707},
doi = {10.1145/2470654.2470707},
abstract = {We present a theoretical foundation and empirical findings demonstrating the effectiveness of personality-targeted design. Much like a medical treatment applied to a person based on his specific genetic profile, we argue that theory-driven, personality-targeted UI design can be more effective than design applied to the entire population. The empirical exploration focused on two settings, two populations and two personality traits: Study 1 shows that users' extraversion level moderates the relationship between the UI cue of audience size and users' contribution. Study 2 demonstrates that the effectiveness of social anchors in encouraging online contributions depends on users' level of emotional stability. Taken together, the findings demonstrate the potential and robustness of the interactionist approach to UI design. The findings contribute to the HCI community, and in particular to designers of social systems, by providing guidelines to targeted design that can increase online participation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {361–370},
numpages = {10},
keywords = {personality, audience size, theory-driven design, emotional stability, extraversion, anchoring., user interface},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470708,
author = {Massung, Elaine and Coyle, David and Cater, Kirsten F. and Jay, Marc and Preist, Chris},
title = {Using Crowdsourcing to Support Pro-Environmental Community Activism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470708},
doi = {10.1145/2470654.2470708},
abstract = {Community activist groups typically rely on core groups of highly motivated members. In this paper we consider how crowdsourcing strategies can be used to supplement the activities of pro-environmental community activists, thus increasing the scalability of their campaigns. We focus on mobile data collection applications and strategies that can be used to engage casual participants in pro-environmental data collection. We report the results of a study that used both quantitative and qualitative methods to investigate the impact of different motivational factors and strategies, including both intrinsic and extrinsic motivators. The study compared and provides empirical evidence for the effectiveness of two extrinsic motivation strategies, pointification - a subset of gamification - and financial incentives. Prior environmental interest is also assessed as an intrinsic motivation factor. In contrast to previous HCI research on pro-environmental technology, much of which has focused on individual behavior change, this paper offers new insights and recommendations on the design of systems that target groups and communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {371–380},
numpages = {10},
keywords = {gamification, sustainability, motivation, participatory urbanism, community activism, crowdsourcing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470709,
author = {Reitmaier, Thomas and Benz, Pierre and Marsden, Gary},
title = {Designing and Theorizing Co-Located Interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470709},
doi = {10.1145/2470654.2470709},
abstract = {This paper gives an interwoven account of the theoretical and practical work we undertook in pursuit of designing co-located interactions. We show how we sensitized ourselves to theory from diverse intellectual disciplines, to develop an analytical lens to better think about co-located interactions. By critiquing current systems and their conceptual foundations, and further interrelating theories particularly in regard to performative aspects of identity and communication, we develop a more nuanced way of thinking about co-located interactions. Drawing on our sensitivities, we show how we generated and are exploring, through the process of design, a set of co-located interactions that are situated within our social ecologies, and contend that our upfront theoretical work enabled us to identify and explore this space in the first place. This highlights the importance of problem framing, especially for projects adopting design methodologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {381–390},
numpages = {10},
keywords = {co-located interaction, design research, co-presence, theory},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470710,
author = {Kusano, Koki and Nakatani, Momoko and Ohno, Takehiko},
title = {Scenario-Based Interactive UI Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470710},
doi = {10.1145/2470654.2470710},
abstract = {Clearly picturing user behavior is one of the key requirements when designing successful interactive software. However, covering all possible user behaviors with one UI is a complex challenge. The Scenario-based Interactive UI Design tool is designed to support the characterization of user behavior based on scenarios and then using the information in UI design. Scenarios make it easy to understand and share user behavior even if we have little design knowledge. However, they have two big weaknesses; 1) integrating several scenarios in one UI is difficult, even if we can create appropriate scenarios, 2) maintaining the links between scenarios and the UI is a heavy task in iterative design. Our tool solves the above problems through its hierarchical scenario structure and visualized overview of scenarios. It enhances the designer's skill in writing scenarios and designing UIs smoothly and easily.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {391–394},
numpages = {4},
keywords = {traceability, design tool, scenario, user interface design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470711,
author = {Qu, Yan and Zhang, Jun},
title = {Regularly Visited Patches in Human Mobility},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470711},
doi = {10.1145/2470654.2470711},
abstract = {In this paper, we propose a new analytic unit for human mobility analysis -- the patch. We developed a process to identify Regularly Visited Patches (RVP) and a set of metrics to characterize and measure their spatial patterns. Using a large dataset of Foursquare check-ins as a test bed, we show that RVP analysis reveals fundamental patterns of human mobility and will lead to promising research with strong implications for businesses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {395–398},
numpages = {4},
keywords = {regularly visited patches, human mobility, optics},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250118,
author = {Parker, Andrea},
title = {Session Details: Papers: Co-Design with Users},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250118},
doi = {10.1145/3250118},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470713,
author = {Dalsgaard, Peter and Eriksson, Eva},
title = {Large-Scale Participation: A Case Study of a Participatory Approach to Developing a New Public Library},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470713},
doi = {10.1145/2470654.2470713},
abstract = {In this paper, we present a case study of a participatory project that focuses on interaction in large-scale design, namely, the development of the new Urban Mediaspace Aarhus. This project, which has been under way for ten years, embodies a series of issues that arise when participatory design approaches are applied to large-scale, IT-oriented projects. At the same time, it highlights the issues public knowledge institutions face, when interactive technologies challenge their fundamental roles and practices; by extension, this case offers examples of how these challenges may be explored and addressed through IT-based participatory initiatives. We present a range of such activities carried out during the past ten years, and present the main lessons from the project, based on interviews with three key stakeholders. These lessons focus on how to make participation work in practice, how to align different paradigms of inquiry and practice in a project of this scale, and how to capture and anchor the insights from participatory events to inform the ongoing design process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {399–408},
numpages = {10},
keywords = {participatory design, interaction design, citizen involvement, design methods, large-scale projects},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470714,
author = {Yoo, Daisy and Zimmerman, John and Hirsch, Tad},
title = {Probing Bus Stop for Insights on Transit Co-Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470714},
doi = {10.1145/2470654.2470714},
abstract = {Social computing provides a new way for citizens to engage with their public service. Our research investigates how social computing might support citizens co-design their transit service. We conducted a field study with public transit riders, exploring the issues and controversies that reveal conflicting communities. Our analyses revealed three insights. First, encourage citizens to share what they see as the rationale for current service offerings. Second, encourage citizens to share the consequences of current services and of proposed changes and new designs. Third, focus on producing a shared citizen and service provider understanding of what the goals and mission of the public service should be.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {409–418},
numpages = {10},
keywords = {service design, transit, social computing, political design, public service, contestational design, co-design, egovernment},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470715,
author = {Yoo, Daisy and Huldtgren, Alina and Woelfer, Jill Palzkill and Hendry, David G. and Friedman, Batya},
title = {A Value Sensitive Action-Reflection Model: Evolving a Co-Design Space with Stakeholder and Designer Prompts},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470715},
doi = {10.1145/2470654.2470715},
abstract = {We introduce a design method for evolving a co-design space to support stakeholders untrained in design. Specifically, the purpose of the method is to expand and shape a co-design space so that stakeholders, acting as designers, focus not only on the form and function of a tool being envisioned but also on the social context of its use and values that lie with individuals, groups, and societies. The method introduces value sensitive stakeholder prompts and designer prompts into a co-design process, creating a particular kind of reflection-on-action cycle. The prompts provide a means for bringing empirical data on values and theoretical perspective into the co-design process. We present the method in terms of a general model, the Value Sensitive Action-Reflection Model; place the model within discourse on co-design spaces; and illustrate the model with a discussion of its application in a lo-fi prototyping activity around safety for homeless young people. We conclude with reflections on the model and method.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {419–428},
numpages = {10},
keywords = {homeless young people, security, value scenarios, co-design, creativity, mobile technologies, value sensitive action-reflection model, prototyping, value sensitive design, design method, envisioning cards, reflection-on-action, safety},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470716,
author = {Vines, John and Clarke, Rachel and Wright, Peter and McCarthy, John and Olivier, Patrick},
title = {Configuring Participation: On How We Involve People in Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470716},
doi = {10.1145/2470654.2470716},
abstract = {The term 'participation' is traditionally used in HCI to describe the involvement of users and stakeholders in design processes, with a pretext of distributing control to participants to shape their technological future. In this paper we ask whether these values can hold up in practice, particularly as participation takes on new meanings and incorporates new perspectives. We argue that much HCI research leans towards configuring participation. In exploring this claim we explore three questions that we consider important for understanding how HCI configures participation; Who initiates, directs and benefits from user participation in design? In what forms does user participation occur? How is control shared with users in design? In answering these questions we consider the conceptual, ethical and pragmatic problems this raises for current participatory HCI research. Finally, we offer directions for future work explicitly dealing with the configuration of participation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {429–438},
numpages = {10},
keywords = {participation, performance art, participatory media, participatory design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250119,
author = {Gweon, Gahgene},
title = {Session Details: Papers: Language and Translation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250119},
doi = {10.1145/3250119},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470718,
author = {Green, Spence and Heer, Jeffrey and Manning, Christopher D.},
title = {The Efficacy of Human Post-Editing for Language Translation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470718},
doi = {10.1145/2470654.2470718},
abstract = {Language translation is slow and expensive, so various forms of machine assistance have been devised. Automatic machine translation systems process text quickly and cheaply, but with quality far below that of skilled human translators. To bridge this quality gap, the translation industry has investigated post-editing, or the manual correction of machine output. We present the first rigorous, controlled analysis of post-editing and find that post-editing leads to reduced time and, surprisingly, improved quality for three diverse language pairs (English to Arabic, French, and German). Our statistical models and visualizations of experimental data indicate that some simple predictors (like source text part of speech counts) predict translation time, and that post-editing results in very different interaction patterns. From these results we distill implications for the design of new language translation interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {439–448},
numpages = {10},
keywords = {modeling, post-editing, language translation, experiment},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470719,
author = {Gao, Ge and Wang, Hao-Chuan and Cosley, Dan and Fussell, Susan R.},
title = {Same Translation but Different Experience: The Effects of Highlighting on Machine-Translated Conversations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470719},
doi = {10.1145/2470654.2470719},
abstract = {Machine translation (MT) has the potential to allow members of multilingual organizations to interact via their own native languages, but issues with the quality of MT output have made it difficult to realize this potential. We hypothesized that highlighting keywords in MT output might make it easier for people to overlook translation errors and focus on what was intended by the message. To test this hypothesis, we conducted a laboratory experiment in which native English speakers interacted with a Mandarin-speaking confederate using machine translation. Participants performed three brainstorming tasks, under each of three conditions: no highlighting, keyword highlighting, and random highlighting. Our results indicated that people consider the identical messages clearer and less distracting when the keywords in the message are highlighted. Keyword highlighting also improved subjective impressions of the partner and the quality of the collaboration. These findings inform the design of future communication tools to support multilingual communications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {449–458},
numpages = {10},
keywords = {machine translation, multilingual communication, brainstorming, highlighting},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470720,
author = {Tausczik, Yla R. and Pennebaker, James W.},
title = {Improving Teamwork Using Real-Time Language Feedback},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470720},
doi = {10.1145/2470654.2470720},
abstract = {We develop and evaluate a real-time language feedback system that monitors the communication patterns among students in a discussion group and provides real-time instructions to shape the way the group works together. As an initial step, we determine which group processes are related to better outcomes. We then experimentally test the efficacy of providing real-time instructions which target two of these group processes. The feedback system was successfully able to shape the way groups worked together. However, only appropriate feedback given to groups that were not working well together from the start was able to improve group performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {459–468},
numpages = {10},
keywords = {feedback, linguistic analysis, cscw, teamwork, cmc},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470721,
author = {Edge, Darren and Cheng, Kai-Yin and Whitney, Michael},
title = {SpatialEase: Learning Language through Body Motion},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470721},
doi = {10.1145/2470654.2470721},
abstract = {Games that engage both mind and body by targeting users' kinesthetic intelligence have the potential to transform the activity of learning across a wide variety of domains. To investigate this potential in the context of second language learning, we have developed SpatialEase: a Kinect game for the body-based learning of language that is grounded in space and motion. In this game, learners respond to audio commands in the second language by moving their bodies in space, while a game mechanic based on distributed cued-recall supports learning over time. Our comparison of SpatialEase with the popular Rosetta Stone software for learner of Mandarin Chinese showed similar learning gains over a single session and generated several key implications for the future design of mixed-modality learning systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {469–472},
numpages = {4},
keywords = {embodied gaming, language learning, kinesthetic learning},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250120,
author = {Isenberg, Petra},
title = {Session Details: Papers: Brain Sensing and Analysis},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250120},
doi = {10.1145/3250120},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470723,
author = {Peck, Evan M M. and Yuksel, Beste F. and Ottley, Alvitta and Jacob, Robert J.K. and Chang, Remco},
title = {Using FNIRS Brain Sensing to Evaluate Information Visualization Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470723},
doi = {10.1145/2470654.2470723},
abstract = {We show how brain sensing can lend insight to the evaluation of visual interfaces and establish a role for fNIRS in visualization. Research suggests that the evaluation of visual design benefits by going beyond performance measures or questionnaires to measurements of the user's cognitive state. Unfortunately, objectively and unobtrusively monitoring the brain is difficult. While functional near-infrared spectroscopy (fNIRS) has emerged as a practical brain sensing technology in HCI, visual tasks often rely on the brain's quick, massively parallel visual system, which may be inaccessible to this measurement. It is unknown whether fNIRS can distinguish differences in cognitive state that derive from visual design alone. In this paper, we use the classic comparison of bar graphs and pie charts to test the viability of fNIRS for measuring the impact of a visual design on the brain. Our results demonstrate that we can indeed measure this impact, and furthermore measurements indicate that there are not universal differences in bar graphs and pie charts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {473–482},
numpages = {10},
keywords = {bci, brain sensing, visualization, evaluation, fnirs},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470724,
author = {Alper, Basak and Bach, Benjamin and Henry Riche, Nathalie and Isenberg, Tobias and Fekete, Jean-Daniel},
title = {Weighted Graph Comparison Techniques for Brain Connectivity Analysis},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470724},
doi = {10.1145/2470654.2470724},
abstract = {The analysis of brain connectivity is a vast field in neuroscience with a frequent use of visual representations and an increasing need for visual analysis tools. Based on an in-depth literature review and interviews with neuroscientists, we explore high-level brain connectivity analysis tasks that need to be supported by dedicated visual analysis tools. A significant example of such a task is the comparison of different connectivity data in the form of weighted graphs. Several approaches have been suggested for graph comparison within information visualization, but the comparison of weighted graphs has not been addressed. We explored the design space of applicable visual representations and present augmented adjacency matrix and node-link visualizations. To assess which representation best support weighted graph comparison tasks, we performed a controlled experiment. Our findings suggest that matrices support these tasks well, outperforming node-link diagrams. These results have significant implications for the design of brain connectivity analysis tools that require weighted graph comparisons. They can also inform the design of visual analysis tools in other domains, e.g. comparison of weighted social networks or biological pathways.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {483–492},
numpages = {10},
keywords = {brain connectivity analysis, brain connectivity visualization, graph comparison},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2470724_R49782,
author = {Rosa, Joao Luis Garcia},
title = {Review ID:R49782 for DOI: 10.1145/2470654.2470724},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2470724_R49782}
}

@inproceedings{10.1145/2470654.2470725,
author = {Taylor, Alex S. and Piterman, Nir and Ishtiaq, Samin and Fisher, Jasmin and Cook, Byron and Cockerton, Caitlin and Bourton, Sam and Benque, David},
title = {At the Interface of Biology and Computation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470725},
doi = {10.1145/2470654.2470725},
abstract = {Representing a new class of tool for biological modeling, Bio Model Analyzer (BMA) uses sophisticated computational techniques to determine stabilization in cellular networks. This paper presents designs aimed at easing the problems that can arise when such techniques - '14using distinct approaches to conceptualizing networks'14 - are applied in biology. The work also engages with more fundamental issues being discussed in the philosophy of science and science studies. It shows how scientific ways of knowing are constituted in routine interactions with tools like BMA, where the emphasis is on the practical business at hand, even when seemingly deep conceptual problems exist. For design, this perspective refigures the frictions raised when computation is used to model biology. Rather than obstacles, they can be seen as opportunities for opening up different ways of knowing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {493–502},
numpages = {10},
keywords = {materiality, science studies, computational biology, ethnography, epistemology, philosophy of science},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2470725_R48994,
author = {Kalvala, Sara},
title = {Review ID:R48994 for DOI: 10.1145/2470654.2470725},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2470725_R48994}
}

@inproceedings{10.1145/3250121,
author = {Gajos, Krzysztof},
title = {Session Details: Papers: Crowdwork and Online Communities},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250121},
doi = {10.1145/3250121},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470727,
author = {Muller, Michael and Geyer, Werner and Soule, Todd and Daniels, Steven and Cheng, Li-Te},
title = {Crowdfunding inside the Enterprise: Employee-Initiatives for Innovation and Collaboration},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470727},
doi = {10.1145/2470654.2470727},
abstract = {We describe a first experiment in enterprise crowdfunding - i.e., employees allocating money for employee-initiated proposals at an Intranet site, including a trial of this system with 511 employees in IBM Research. Major outcomes include: employee proposals that addressed diverse individual and organizational needs; high participation rates; extensive inter-departmental collaboration, including the discovery of large numbers of previously unknown collaborators; and the development of goals and motivations based on collective concerns at multiple levels of project groups, communities of practice, and the organization as a whole. We recommend further, comparative research into crowd-funding and other forms of employee-initiated innovations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {503–512},
numpages = {10},
keywords = {employee, enterprise, social, crowdfunding, innovation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470728,
author = {Matthews, Tara and Whittaker, Steve and Badenes, Hernan and Smith, Barton A. and Muller, Michael and Ehrlich, Kate and Zhou, Michelle X. and Lau, Tessa},
title = {Community Insights: Helping Community Leaders Enhance the Value of Enterprise Online Communities},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470728},
doi = {10.1145/2470654.2470728},
abstract = {Online communities are increasingly being deployed in enterprises to increase productivity and share expertise. Community leaders are critical for fostering successful communities, but existing technologies rarely support leaders directly, both because of a lack of clear data about leader needs, and because existing tools are member- rather than leader-centric. We present the evidence-based design and evaluation of a novel tool for community leaders, Community Insights (CI). CI provides actionable analytics that help community leaders foster healthy communities, providing value to both members and the organization. We describe empirical and system contributions derived from a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical contributions include new data showing: (a) which metrics are most useful for leaders to assess community health, (b) the need for and how to design actionable metrics, (c) the need for and how to design contextualized analytics to support sensemaking about community data. These findings motivate a novel community system that provides leaders with useful, actionable and contextualized analytics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {513–522},
numpages = {10},
keywords = {online communities, iterative design, community leaders, enterprise, system evaluation, workplace},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470729,
author = {Xu, Anbang and Chen, Jilin and Matthews, Tara and Muller, Michael and Badenes, Hernan},
title = {CommunityCompare: Visually Comparing Communities for Online Community Leaders in the Enterprise},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470729},
doi = {10.1145/2470654.2470729},
abstract = {Online communities are important in enterprises, helping workers to build skills and collaborate. Despite their unique and critical role fostering successful communities, community leaders have little direct support in existing technologies. We introduce CommunityCompare, an interactive visual analytic system to enable leaders to make sense of their community's activity with comparisons. Composed of a parallel coordinates plot, various control widgets, and a preview of example posts from communities, the system supports comparisons with hundreds of related communities on multiple metrics and the ability to learn by example. We motivate and inform the system design with formative interviews of community leaders. From additional interviews, a field deployment, and surveys of leaders, we show how the system enabled leaders to assess community performance in the context of other comparable communities, learn about community dynamics through data exploration, and identify examples of top performing communities from which to learn. We conclude by discussing how our system and design lessons generalize.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {523–532},
numpages = {10},
keywords = {system evaluation, online communities, iterative design, enterprise, workplace, community leaders, visualization},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470730,
author = {Lee, Uichin and Kim, Jihyoung and Yi, Eunhee and Sung, Juyup and Gerla, Mario},
title = {Analyzing Crowd Workers in Mobile Pay-for-Answer Q&amp;a},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470730},
doi = {10.1145/2470654.2470730},
abstract = {Despite the popularity of mobile pay-for-answer Q&amp;A services, little is known about the people who answer questions on these services. In this paper we examine 18.8 million question and answer pairs from Jisiklog, the largest mobile pay-foranswer Q&amp;A service in Korea, and the results of a complementary survey study of 245 Jisiklog workers. The data are used to investigate key motivators of participation, working strategies of experienced users, and longitudinal interaction dynamics. We find that answerers are rarely motivated by social factors but are motivated by financial incentives and intrinsic motives. Additionally, although answers are provided quickly, an answerer's topic selection tends to be broad, with experienced workers employing unique strategies to answer questions and judge relevance. Finally, analysis of longitudinal working patterns and community dynamics demonstrate the robustness of mobile pay-for-answer Q&amp;A. These findings have significant implications on the design of mobile pay-for-answer Q&amp;A.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {533–542},
numpages = {10},
keywords = {user behavior, mobile pay-for-answer q&amp;a},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250122,
author = {Dunlop, Mark},
title = {Session Details: Papers: Keyboards and Hotkeys},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250122},
doi = {10.1145/3250122},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470732,
author = {Bi, Xiaojun and Azenkot, Shiri and Partridge, Kurt and Zhai, Shumin},
title = {Octopus: Evaluating Touchscreen Keyboard Correction and Recognition Algorithms Via},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470732},
doi = {10.1145/2470654.2470732},
abstract = {The time and labor demanded by a typical laboratory-based keyboard evaluation are limiting resources for algorithmic adjustment and optimization. We propose Remulation, a complementary method for evaluating touchscreen keyboard correction and recognition algorithms. It replicates prior user study data through real-time, on-device simulation. We have developed Octopus, a Remulation-based evaluation tool that enables keyboard developers to efficiently measure and inspect the impact of algorithmic changes without conducting resource-intensive user studies. It can also be used to evaluate third-party keyboards in a "black box" fashion, without access to their algorithms or source code. Octopus can evaluate both touch keyboards and word-gesture keyboards. Two empirical examples show that Remulation can efficiently and effectively measure many aspects of touch screen keyboards at both macro and micro levels. Additionally, we contribute two new metrics to measure keyboard accuracy at the word level: the Ratio of Error Reduction (RER) and the Word Score.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {543–552},
numpages = {10},
keywords = {simulation, touch screen interaction, text entry},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470733,
author = {Kim, Sunjun and Son, Jeongmin and Lee, Geehyuk and Kim, Hwan and Lee, Woohun},
title = {TapBoard: Making a Touch Screen Keyboard More Touchable},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470733},
doi = {10.1145/2470654.2470733},
abstract = {A physical keyboard key has three states, whereas a touch screen usually has only two. Due to this difference, the state corresponding to the touched state of a physical key is missing in a touch screen keyboard. This touched state is an important factor in the usability of a keyboard. In order to recover the role of a touched state in a touch screen, we propose the TapBoard, a touch screen software keyboard that regards tapping actions as keystrokes and other touches as the touched state. In a series of user studies, we validate the effectiveness of the TapBoard concept. First, we show that tapping to type is in fact compatible with the existing typing skill of most touch screen keyboard users. Second, users quickly adapt to the TapBoard and learn to rest their fingers in the touched state. Finally, we confirm by a controlled experiment that there is no difference in text-entry performance between the TapBoard and a traditional touch screen software keyboard. In addition to these experimental results, we demonstrate a few new interaction techniques that will be made possible by the TapBoard.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {553–562},
numpages = {10},
keywords = {text-entry method, touch screen keyboard, tapboard},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470734,
author = {Bailly, Gilles and Pietrzak, Thomas and Deber, Jonathan and Wigdor, Daniel J.},
title = {M\'{e}Tamorphe: Augmenting Hotkey Usage with Actuated Keys},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470734},
doi = {10.1145/2470654.2470734},
abstract = {Hotkeys are an efficient method of selecting commands on a keyboard. However, these shortcuts are often underused by users. We present M\'{e}tamorphe, a novel keyboard with keys that can be individually raised and lowered to promote hotkeys usage. M\'{e}tamorphe augments the output of traditional keyboards with haptic and visual feedback, and offers a novel design space for user input on raised keys (e.g., gestures such as squeezing or pushing the sides of a key). We detail the implementation of M\'{e}tamorphe and discuss design factors. We also report two user studies. The first is a user-defined interface study that shows that the new input vocabulary is usable and useful, and provides insights into the mental models that users associate with raised keys. The second user study shows improved eyes-free selection performance for raised keys as well as the surrounding unraised keys.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {563–572},
numpages = {10},
keywords = {shape-changing interfaces, user-defined gestures, augmented keyboard, height-changing keys, hotkeys},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470735,
author = {Malacria, Sylvain and Bailly, Gilles and Harrison, Joel and Cockburn, Andy and Gutwin, Carl},
title = {Promoting Hotkey Use through Rehearsal with ExposeHK},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470735},
doi = {10.1145/2470654.2470735},
abstract = {Keyboard shortcuts allow fast interaction, but they are known to be infrequently used, with most users relying heavily on traditional pointer-based selection for most commands. We describe the goals, design, and evaluation of ExposeHK, a new interface mechanism that aims to increase hotkey use. ExposeHK's four key design goals are: 1) enable users to browse hotkeys; 2) allow non-expert users to issue hotkey commands as a physical rehearsal of expert performance; 3) exploit spatial memory to assist non-expert users in identifying hotkeys; and 4) maximise expert performance by using consistent shortcuts in a flat command hierarchy. ExposeHK supports these objectives by displaying hotkeys overlaid on their associated commands when a modifier key is pressed. We evaluated ExposeHK in three empirical studies using toolbars, menus, and a tabbed '18ribbon' toolbar. Results show that participants used more hotkeys, and used them more often, with ExposeHK than with other techniques; they were faster with ExposeHK than with either pointing or other hotkey methods; and they strongly preferred ExposeHK. Our research shows that ExposeHK can substantially improve the user's transition from a '18beginner mode' of interaction to a higher level of expertise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {573–582},
numpages = {10},
keywords = {menus, novice mode, keyboard shortcuts, expert mode, hotkeys, rehearsal, command selection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250123,
author = {Lank, Edward},
title = {Session Details: Papers: Flexible Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250123},
doi = {10.1145/3250123},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470737,
author = {Gomes, Antonio and Nesbitt, Andrea and Vertegaal, Roel},
title = {MorePhone: A Study of Actuated Shape Deformations for Flexible Thin-Film Smartphone Notifications},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470737},
doi = {10.1145/2470654.2470737},
abstract = {We present MorePhone, an actuated flexible smartphone with a thin-film E Ink display. MorePhone uses shape memory alloys to actuate the entire surface of the display as well as individual corners. We conducted a participatory study to determine how users associate urgency and notification type with full screen, 1 corner, 2 corner and 3 corner actuations of the smartphone. Results suggest that with the current prototype, actuated shape notifications are useful for visual feedback. Urgent notifications such as alarms and voice calls were best matched with actuation of the entire display surface, while less urgent notifications, such as software notifications were best matched to individual corner bends. While different corner actuations resulted in significantly different matches between notification types, medium urgency notification types were treated as similar, and best matched to a single corner bend. A follow-up study suggested that users prefer to dedicate each corner to a specific type of notification. Users would like to personalize the assignment of corners to notification type. Animation of shape actuation significantly increased the perceived urgency of any of the presented shapes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {583–592},
numpages = {10},
keywords = {flexible displays, notification, organic user interfaces, shape changing interfaces, actuation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470738,
author = {Roudaut, Anne and Karnik, Abhijit and L\"{o}chtefeld, Markus and Subramanian, Sriram},
title = {Morphees: Toward High "Shape Resolution" in Self-Actuated Flexible Mobile Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470738},
doi = {10.1145/2470654.2470738},
abstract = {We introduce the term shape resolution, which adds to the existing definitions of screen and touch resolution. We propose a framework, based on a geometric model (Non-Uniform Rational B-splines), which defines a metric for shape resolution in ten features. We illustrate it by comparing the current related work of shape changing devices. We then propose the concept of Morphees that are self-actuated flexible mobile devices adapting their shapes on their own to the context of use in order to offer better affordances. For instance, when a game is launched, the mobile device morphs into a console-like shape by curling two opposite edges to be better grasped with two hands. We then create preliminary prototypes of Morphees in order to explore six different building strategies using advanced shape changing materials (dielectric electro active polymers and shape memory alloys). By comparing the shape resolution of our prototypes, we generate insights to help designers toward creating high shape resolution Morphees.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {593–602},
numpages = {10},
keywords = {organic user interface, shape changing, flexible touchscreen, shape resolution, haptic feedback},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470739,
author = {Hashimoto, Sunao and Suzuki, Ryohei and Kamiyama, Youichi and Inami, Masahiko and Igarashi, Takeo},
title = {LightCloth: Senseable Illuminating Optical Fiber Cloth for Creating Interactive Surfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470739},
doi = {10.1145/2470654.2470739},
abstract = {This paper introduces an input and output device that enables illumination, bi-directional data communication, and position sensing on a soft cloth. This "LightCloth" is woven from diffusive optical fibers. Since the fibers are arranged in parallel, the cloth has one-dimensional position information. Sensor-emitter pairs attached to bundles of contiguous fibers enable bundle-specific light input and output. We developed a prototype system that allows full-color illumination and 8-bit data input by infrared signals. We present as an application a chair with a LightCloth cover whose illumination pattern is specified using an infrared light pen. Here we describe the implementation details of the device and discuss possible interactions using the device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {603–606},
numpages = {4},
keywords = {light communication, illumination, position sensing, soft deformable user interface, diffusive optical fiber},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470740,
author = {Warren, Kristen and Lo, Jessica and Vadgama, Vaibhav and Girouard, Audrey},
title = {Bending the Rules: Bend Gesture Classification for Flexible Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470740},
doi = {10.1145/2470654.2470740},
abstract = {Bend gestures have a large number of degrees of freedom and therefore offer a rich interaction language. We propose a classification scheme for bend gestures, and explore how users perform these bend gestures along four classification criterion: location, direction, size, and angle. We collected 36 unique bend gestures performed three times by each participant. The results suggest a strong agreement among participants for preferences of location and direction. Size and angle were difficult for users to differentiate. Finally, users performed and perceived two distinct levels of magnitude. We propose recommendations for designing bend gestures with flexible displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {607–610},
numpages = {4},
keywords = {deformable user interface, affordance, flexible display, organic user interface, bend gesture},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250124,
author = {Dow, Steven},
title = {Session Details: Papers: Smart Tools, Smart Work},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250124},
doi = {10.1145/3250124},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470742,
author = {Irani, Lilly C. and Silberman, M. Six},
title = {Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470742},
doi = {10.1145/2470654.2470742},
abstract = {As HCI researchers have explored the possibilities of human computation, they have paid less attention to ethics and values of crowdwork. This paper offers an analysis of Amazon Mechanical Turk, a popular human computation system, as a site of technically mediated worker-employer relations. We argue that human computation currently relies on worker invisibility. We then present Turkopticon, an activist system that allows workers to publicize and evaluate their relationships with employers. As a common infrastructure, Turkopticon also enables workers to engage one another in mutual aid. We conclude by discussing the potentials and challenges of sustaining activist technologies that intervene in large, existing socio-technical systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {611–620},
numpages = {10},
keywords = {human computation, design, amazon mechanical turk, ethics, infrastructure, activism},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470743,
author = {Huang, Shih-Wen and Fu, Wai-Tat},
title = {Don't Hide in the Crowd! Increasing Social Transparency between Peer Workers Improves Crowdsourcing Outcomes},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470743},
doi = {10.1145/2470654.2470743},
abstract = {This paper studied how social transparency and different peer-dependent reward schemes (i.e., individual, teamwork, and competition) affect the outcomes of crowdsourcing. The results showed that when social transparency was increased by asking otherwise anonymous workers to share their demographic information (e.g., name, nationality) to the paired worker, they performed significantly better. A more detailed analysis showed that in a teamwork reward scheme, in which the reward of the paired workers depended only on the collective outcomes, increasing social transparency could offset effects of social loafing by making them more accountable to their teammates. In a competition reward scheme, in which workers competed against each other and the reward depended on how much they outperformed their opponent, increasing social transparency could augment effects of social facilitation by providing more incentives for them to outperform their opponent. The results suggested that a careful combination of methods that increase social transparency and different reward schemes can significantly improve crowdsourcing outcomes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {621–630},
numpages = {10},
keywords = {social facilitation, social transparency, human computation, social loafing, crowdsourcing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470744,
author = {Hara, Kotaro and Le, Vicki and Froehlich, Jon},
title = {Combining Crowdsourcing and Google Street View to Identify Street-Level Accessibility Problems},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470744},
doi = {10.1145/2470654.2470744},
abstract = {Poorly maintained sidewalks, missing curb ramps, and other obstacles pose considerable accessibility challenges; however, there are currently few, if any, mechanisms to determine accessible areas of a city a priori. In this paper, we investigate the feasibility of using untrained crowd workers from Amazon Mechanical Turk (turkers) to find, label, and assess sidewalk accessibility problems in Google Street View imagery. We report on two studies: Study 1 examines the feasibility of this labeling task with six dedicated labelers including three wheelchair users; Study 2 investigates the comparative performance of turkers. In all, we collected 13,379 labels and 19,189 verification labels from a total of 402 turkers. We show that turkers are capable of determining the presence of an accessibility problem with 81% accuracy. With simple quality control methods, this number increases to 93%. Our work demonstrates a promising new, highly scalable method for acquiring knowledge about sidewalk accessibility.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {631–640},
numpages = {10},
keywords = {google street view, accessible urban navigation, mechanical turk, image labeling, crowdsourcing accessibility},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470745,
author = {Musthag, Mohamed and Ganesan, Deepak},
title = {Labor Dynamics in a Mobile Micro-Task Market},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470745},
doi = {10.1145/2470654.2470745},
abstract = {The ubiquity of smartphones has led to the emergence of mobile crowdsourcing markets, where smartphone users participate to perform tasks in the physical world. Mobile crowdsourcing markets are uniquely different from their online counterparts in that they require spatial mobility, and are therefore impacted by geographic factors and constraints that are not present in the online case. Despite the emergence and importance of such mobile marketplaces, little to none is known about the labor dynamics and mobility patterns of agents. This paper provides an in-depth exploration of labor dynamics in mobile task markets based on a year-long dataset from a leading mobile crowdsourcing platform. We find that a small core group of workers (&lt; 10%) account for a disproportionately large proportion of activity (&gt; 80%) generated in the market. We find that these super agents are more efficient than other agents across several dimensions: a) they are willing to move longer distances to perform tasks, yet they amortize travel across more tasks, b) they work and search for tasks more efficiently, c) they have higher data quality in terms of accepted submissions, and d) they improve in almost all of these efficiency measures over time. We find that super agent efficiency stems from two simple optimizations --- they are 3x more likely than other agents to chain tasks and they pick fewer lower priced tasks than other agents. We compare mobile and online micro-task markets, and discuss differences in demographics, data quality, and time of use, as well as similarities in super agent behavior. We conclude with a discussion of how a mobile micro-task market might leverage some of our results to improve performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {641–650},
numpages = {10},
keywords = {mobile crowdsourcing, crowdsourcing, labor mobility, micro task markets},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250125,
author = {Ko, Andrew},
title = {Session Details: Papers: Creating and Authoring},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250125},
doi = {10.1145/3250125},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470747,
author = {Davis, Nicholas and Zook, Alexander and O'Neill, Brian and Headrick, Brandon and Riedl, Mark and Grosz, Ashton and Nitsche, Michael},
title = {Creativity Support for Novice Digital Filmmaking},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470747},
doi = {10.1145/2470654.2470747},
abstract = {Machinima is a new form of creative digital filmmaking that leverages the real time graphics rendering of computer game engines. Because of the low barrier to entry, machinima has become a popular creative medium for hobbyists and novices while still retaining borrowed conventions from professional filmmaking. Can novice machinima creators benefit from creativity support tools? A preliminary study shows novices generally have difficulty adhering to cinematographic conventions. We identify and document four cinematic conventions novices typically violate. We report on a Wizard-of-Oz study showing a rule-based intelligent system that can reduce the frequency of errors that novices make by providing information about rule violations without prescribing solutions. We discuss the role of error reduction in creativity support tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {651–660},
numpages = {10},
keywords = {creativity support tools, digital filmmaking},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470748,
author = {Zhu, Kening and Zhao, Shengdong},
title = {AutoGami: A Low-Cost Rapid Prototyping Toolkit for Automated Movable Paper Craft},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470748},
doi = {10.1145/2470654.2470748},
abstract = {AutoGami is a toolkit for designing automated movable paper craft using the technology of selective inductive power transmission. AutoGami has hardware and software components that allow users to design and implement automated movable paper craft without any prerequisite knowledge of electronics; it also supports rapid prototyping. Apart from developing the toolkit, we have analyzed the design space of movable paper craft and developed a taxonomy to facilitate the design of automated paper craft. AutoGami made consistently strong showings in design workshops, confirming its viability in supporting engagement and creativity as well as its usability in storytelling through paper craft. Additional highlights include rapid prototyping of product design as well as interaction design such as human-robot interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {661–670},
numpages = {10},
keywords = {selective inductive power transmission, toolkit, automated paper craft, paper computing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470749,
author = {Edge, Darren and Savage, Joan and Yatani, Koji},
title = {HyperSlides: Dynamic Presentation Prototyping},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470749},
doi = {10.1145/2470654.2470749},
abstract = {Presentations are a crucial form of modern communication, yet there is a dissonance between everyday practices with presentation tools and best practices from the presentation literature. We conducted a grounded theory study to gain a better understanding of the activity of presenting, discovering the potential for a more dynamic, automated, and story-centered approach to prototyping slide presentations that are themselves dynamic in their ability to help presenters rehearse and deliver their story. Our prototype tool for dynamic presentation prototyping, which we call HyperSlides, uses a simple markup language for the creation of hierarchically structured scenes, which are algorithmically transformed into hyperlinked slides of a consistent and minimalist style. Our evaluation suggests that HyperSlides helps idea organization, saves authoring time, creates aesthetic layouts, and supports more flexible rehearsal and delivery than linear slides, at the expense of reduced layout control and increased navigation demands.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {671–680},
numpages = {10},
keywords = {slideware, grounded theory, presentations, powerpoint},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470750,
author = {Liu, Yefeng and Edge, Darren and Yatani, Koji},
title = {SidePoint: A Peripheral Knowledge Panel for Presentation Slide Authoring},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470750},
doi = {10.1145/2470654.2470750},
abstract = {Presentation authoring is an important activity, but often requires the secondary task of collecting the information and media necessary for both slides and speech. Integration of implicit search and peripheral displays into presentation authoring tools may reduce the effort to satisfy not just active needs the author is aware of, but also latent needs that she is not aware of until she encounters content of perceived value. We develop SidePoint, a peripheral panel that supports presentation authoring by showing concise knowledge items relevant to the slide content. We study SidePoint as a technology probe to examine the benefits and issues associated with peripheral knowledge panels for presentation authoring. Our results show that peripheral knowledge panels have the potential to satisfy both types of needs in ways that transform presentation authoring for the better.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {681–684},
numpages = {4},
keywords = {natural language processing, presentation authoring, peripheral displays},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250126,
author = {Nacke, Lennart},
title = {Session Details: Papers: Exploring Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250126},
doi = {10.1145/3250126},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470752,
author = {Birk, Max and Mandryk, Regan L.},
title = {Control Your Game-Self: Effects of Controller Type on Enjoyment, Motivation, and Personality in Game},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470752},
doi = {10.1145/2470654.2470752},
abstract = {Whether they are made to entertain you, or to educate you, good video games engage you. Significant research has tried to understand engagement in games by measuring player experience (PX). Traditionally, PX evaluation has focused on the enjoyment of game, or the motivation of players; these factors no doubt contribute to engagement, but do decisions regarding play environment (e.g., the choice of game controller) affect the player more deeply than that? We apply self-determination theory (specifically satisfaction of needs and self-discrepancy represented using the five factors model of personality) to explain PX in an experiment with controller type as the manipulation. Our study shows that there are a number of effects of controller on PX and in-game player personality. These findings provide both a lens with which to view controller effects in games and a guide for controller choice in the design of new games. Our research demonstrates that including self-characteristics assessment in the PX evaluation toolbox is valuable and useful for understanding player experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {685–694},
numpages = {10},
keywords = {games, self-discrepancy theory, motivation, controller, personality, self-determination theory},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470753,
author = {Huang, Jeff and Zimmermann, Thomas and Nagapan, Nachiappan and Harrison, Charles and Phillips, Bruce C.},
title = {Mastering the Art of War: How Patterns of Gameplay Influence Skill in Halo},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470753},
doi = {10.1145/2470654.2470753},
abstract = {How do video game skills develop, and what sets the top players apart? We study this question of skill through a rating generated from repeated multiplayer matches called TrueSkill. Using these ratings from 7 months of games from over 3 million players, we look at how play intensity, breaks in play, skill change over time, and other games affect skill. These analyzed factors are then combined to model future skill and games played; the results show that skill change in early matches is a useful metric for modeling future skill, while play intensity explains eventual games played. The best players in the 7-month period, who we call "Master Blasters", have varied skill patterns that often run counter to the trends we see for typical players. The data analysis is supplemented with a 70 person survey to explore how players' self-perceptions compare to the gameplay data; most survey responses align well with the data and provide insight into player beliefs and motivation. Finally, we wrap up with a discussion about hiding skill information from players, and implications for game designers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {695–704},
numpages = {10},
keywords = {online multiplayer, video games, gaming skill, learning},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470754,
author = {Graham, T.C. Nicholas and Schumann, Irina and Patel, Mrunal and Bellay, Quentin and Dachselt, Raimund},
title = {Villains, Architects and Micro-Managers: What Tabula Rasa Teaches Us about Game Orchestration},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470754},
doi = {10.1145/2470654.2470754},
abstract = {Players of digital games are limited by the constraints of the game's implementation. Players cannot fly a kite, plant a tree or make friends with a dragon if these activities were not coded within the game. Game orchestration relaxes these restrictions by allowing players to create game narratives and settings as the game is being played. This enables players to express their creativity beyond the strictures of the game's implementation. We present Tabula Rasa, a novel game orchestration tool based on an efficient tabletop interface. Based on a study of 20 game orchestration sessions using Tabula Rasa, we identify five behavioural patterns adopted by orchestrators, and four styles of collaborative interaction between orchestrators and players. Finally, we present recommendations for designers of game orchestration systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {705–714},
numpages = {10},
keywords = {tabletop gaming, game orchestration, game design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470755,
author = {Peyton, Tamara and Young, Alyson L. and Lutters, Wayne},
title = {Playing with Leadership and Expertise: Military Tropes and Teamwork in an Arg},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470755},
doi = {10.1145/2470654.2470755},
abstract = {Ad-hoc virtual teams often lack tools to formalize leadership and structure collaboration, yet they are often successful. How does this happen? We argue that the emergence of leadership and the development of expertise occurs in the process of taking action and in direct response to a lack of structure. Using a twinned set of eight modality sliders, we examine the interactions of fourteen players in an alternate reality game. We find that players adopted military language and culture to structure and arrange their play. We determine that it is critical to account for the context of play across these modalities in order to design appropriately for effective in-game virtual organizing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {715–724},
numpages = {10},
keywords = {alternate reality games, expertise, qualitative research, computer-supported cooperative work, leadership, team work},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250127,
author = {Subramanian, Sriram},
title = {Session Details: Papers: Tables and Floors},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250127},
doi = {10.1145/3250127},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470757,
author = {Br\"{a}nzel, Alan and Holz, Christian and Hoffmann, Daniel and Schmidt, Dominik and Knaust, Marius and L\"{u}hne, Patrick and Meusel, Ren\'{e} and Richter, Stephan and Baudisch, Patrick},
title = {GravitySpace: Tracking Users and Their Poses in a Smart Room Using a Pressure-Sensing Floor},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470757},
doi = {10.1145/2470654.2470757},
abstract = {We explore how to track people and furniture based on a high-resolution pressure-sensitive floor. Gravity pushes people and objects against the floor, causing them to leave imprints of pressure distributions across the surface. While the sensor is limited to sensing direct contact with the surface, we can sometimes conclude what takes place above the surface, such as users' poses or collisions with virtual objects. We demonstrate how to extend the range of this approach by sensing through passive furniture that propagates pressure to the floor. To explore our approach, we have created an 8 m2 back-projected floor prototype, termed GravitySpace, a set of passive touch-sensitive furniture, as well as algorithms for identifying users, furniture, and poses. Pressure-based sensing on the floor offers four potential benefits over camera-based solutions: (1) it provides consistent coverage of rooms wall-to-wall, (2) is less susceptible to occlusion between users, (3) allows for the use of simpler recognition algorithms, and (4) intrudes less on users' privacy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {725–734},
numpages = {10},
keywords = {vision, smart rooms, ubicomp, iinteractive floor, multitouch, multitoe, tabletop, ftir},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470758,
author = {Sutcliffe, Steven W.T. and Ivkovic, Zenja and Flatla, David R. and Pavlovych, Andriy and Stavness, Ian and Gutwin, Carl},
title = {Improving Digital Handoff Using the Space above the Table},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470758},
doi = {10.1145/2470654.2470758},
abstract = {Object handoff - that is, passing an object or tool to another person - is an extremely common activity in collaborative tabletop work. On digital tables, object handoff is typically accomplished by sliding them on the table surface - but surface-only interactions can be slow and error-prone, particularly when there are multiple people carrying out multiple handoffs. An alternative approach is to use the space above the table for object handoff; this provides more room to move, but requires above-surface tracking. We have developed two above-the-surface handoff techniques that use simple and inexpensive tracking: a force-field technique that uses a depth camera to determine hand proximity, and an electromagnetic-field technique called ElectroTouch that provides positive indication when people touch hands over the table. We compared the new techniques to three kinds of surface-only handoff (sliding, flicking, and surface-only Force-Fields). The study showed that the above-surface techniques significantly improved both speed and accuracy, and that ElectroTouch was the best technique overall. This work provides designers with practical new techniques for substantially increasing performance and interaction richness on digital tables.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {735–744},
numpages = {10},
keywords = {coordination, digital tables, digital object handoff},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470759,
author = {Voelker, Simon and Wacharamanotham, Chat and Borchers, Jan},
title = {An Evaluation of State Switching Methods for Indirect Touch Systems},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470759},
doi = {10.1145/2470654.2470759},
abstract = {Indirect touch systems combine a horizontal touch input surface with a vertical display for output. While this division is ergonomically superior to simple direct-touch displays for many tasks, users are no longer looking at their hands when touching. This requires the system to support an intermediate '1ctracking'1d state that lets users aim at objects without triggering a selection, similar to the hover state in mouse-based UIs. We present an empirical analysis of several interaction techniques for indirect touch systems to switch to this intermediate state, and derive design recommendations for incorporating it into such systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {745–754},
numpages = {10},
keywords = {indirect-touch, three-state model},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470760,
author = {M\"{o}llers, Max and Dumont, Norbert and Ladwig, Stefan and Borchers, Jan},
title = {Improving Touch Accuracy on Large Tabletops Using Predecessor and Successor},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470760},
doi = {10.1145/2470654.2470760},
abstract = {Touch interfaces provide great flexibility in designing an UI. However, the actual experience is often frustrating due to bad touch recognition. On small systems, we can analyze yaw, roll, and pitch of the finger to increase touch accuracy for a single touch. On larger systems, we need to take additional factors into account as users have more flexibility for their limb posture and need to aim over larger distances. Thus, we investigated how people perform touch sequences on those large touch surfaces. We show that the relative location of the predecessor of a touch has a significant impact on the orientation and position of the touch ellipsis.We exploited this effect on an off-the-shelf touch display and showed that with only minimal preparation the touch accuracy of standard hardware can be improved by at least 7%, allowing better recognition rates or more UI components on the same screen.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {755–758},
numpages = {4},
keywords = {tabletops, offset, sequence, touch, accuracy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470761,
author = {Nowacka, Diana and Ladha, Karim and Hammerla, Nils Y. and Jackson, Daniel and Ladha, Cassim and Rukzio, Enrico and Olivier, Patrick},
title = {Touchbugs: Actuated Tangibles on Multi-Touch Tables},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470761},
doi = {10.1145/2470654.2470761},
abstract = {We present a novel approach to graspable interfaces using Touchbugs, actuated physical objects for interacting with interactive surface computing applications. Touchbugs are active tangibles that are able to move across surfaces by employing vibrating motors and can communicate with camera based multi-touch surfaces using infrared LEDs. Touchbug's embedded inertial sensors and computational capabilities open a new interaction space by providing autonomous capabilities for tangibles that allow goal directed behavior.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {759–762},
numpages = {4},
keywords = {user interface device, interactive tabletops, actuated tangibles},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250128,
author = {Tatar, Deborah},
title = {Session Details: Papers: Design for Classrooms 1},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250128},
doi = {10.1145/3250128},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470763,
author = {Denny, Paul},
title = {The Effect of Virtual Achievements on Student Engagement},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470763},
doi = {10.1145/2470654.2470763},
abstract = {Badge-based achievement systems are being used increasingly to drive user participation and engagement across a variety of platforms and contexts. Despite positive anecdotal reports, there is currently little empirical evidence to support their efficacy in particular domains. With the recent rapid growth of tools for online learning, an interesting open question for educators is the extent to which badges can positively impact student participation.In this paper, we report on a large-scale (n &gt; 1000) randomized, controlled experiment measuring the impact of incorporating a badge-based achievement system within an online learning tool. We discover a highly significant positive effect on the quantity of students' contributions, without a corresponding reduction in their quality, as well as on the period of time over which students engaged with the tool. Students enjoyed being able to earn badges, and indicated a strong preference for having them available in the user interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {763–772},
numpages = {10},
keywords = {education, badges, achievements, online learning, gamification, peerwise},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470764,
author = {Andersen, Erik and Gulwani, Sumit and Popovic, Zoran},
title = {A Trace-Based Framework for Analyzing and Synthesizing Educational Progressions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470764},
doi = {10.1145/2470654.2470764},
abstract = {A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning game. We present the results of a user study with this game confirming that our partial ordering can predict user evaluation of procedural difficulty better than baseline methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {773–782},
numpages = {10},
keywords = {problem generation, games, execution traces, education},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470765,
author = {Farzan, Rosta and Kraut, Robert E.},
title = {Wikipedia Classroom Experiment: Bidirectional Benefits of Students' Engagement in Online Production Communities},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470765},
doi = {10.1145/2470654.2470765},
abstract = {Over the last decade, a citizen science movement has tried to engage students, laymen and other non-scientists in the production of science. However, there has been less attention in citizen science projects to use the public to disseminate scientific knowledge. Wikipedia provides a platform to study engagement of citizen scientists in knowledge dissemination. College and university students are especially appropriate members of the public to write science articles, because of the course-work and mentorship they receive from faculty. This paper describes a project to support students' writing of scientific articles in Wikipedia. In collaboration with a scientific association, we involved 640 students from 36 courses in editing scientific articles on Wikipedia. This paper provides details in the design of the program and our quantitative and qualitative approaches to evaluating it. Our results show that the Wikipedia classroom experiment benefits both the Wikipedia community and students. Undergraduate and graduate students substantially improved the scientific content of over 800 articles, at a level of quality indistinguishable from content written by PhD experts. Both students and faculty endorsed the motivational benefits of an authentic writing experience that would be read by thousands of people.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {783–792},
numpages = {10},
keywords = {socialization, experiment, online volunteer community},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470766,
author = {Cross, Andrew and Bayyapunedi, Mydhili and Cutrell, Edward and Agarwal, Anant and Thies, William},
title = {TypeRighting: Combining the Benefits of Handwriting and Typeface in Online Educational Videos},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470766},
doi = {10.1145/2470654.2470766},
abstract = {Recent years have seen enormous growth of online educational videos, spanning K-12 tutorials to university lectures. As this content has grown, so too has grown the number of presentation styles. Some educators have strong allegiance to handwritten recordings (using pen and tablet), while others use only typed (PowerPoint) presentations. In this paper, we present the first systematic comparison of these two presentation styles and how they are perceived by viewers. Surveys on edX and Mechanical Turk suggest that users enjoy handwriting because it is personal and engaging, yet they also enjoy typeface because it is clear and legible. Based on these observations, we propose a new presentation style, TypeRighting, that combines the benefits of handwriting and typeface. Each phrase is written by hand, but fades into typeface soon after it appears. Our surveys suggest that about 80% of respondents prefer TypeRighting over handwriting. The same fraction of respondents prefer TypeRighting over typeface, for videos in which the handwriting is sufficiently legible.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {793–796},
numpages = {4},
keywords = {online education, massive open online course, handwriting},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470767,
author = {Birnholtz, Jeremy and Hancock, Jeff and Retelny, Daniela},
title = {Tweeting for Class: Co-Construction as a Means for Engaging Students in Lectures},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470767},
doi = {10.1145/2470654.2470767},
abstract = {Motivating students to be active learners is a perennial problem in education, and is particularly challenging in lectures where instructors typically prepare content in ad-vance with little direct student participation. We describe our experience using Twitter as a tool for student "co-construction" of lecture materials. Students were required to post a tweet prior to each lecture related to that day's topic, and these tweets -- consisting of questions, examples and reflections -- were incorporated into the lecture slides and notes. Students reported that they found lectures including their tweets in the class slides to be engaging, interactive and relevant, and nearly 90% of them recommended we use our co-construction approach again.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {797–800},
numpages = {4},
keywords = {lecture, engagement, co-construction., education, twitter},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250129,
author = {Teevan, Jaime},
title = {Session Details: Papers: Crowds and Activism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250129},
doi = {10.1145/3250129},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470769,
author = {Starbird, Kate},
title = {Delivering Patients to Sacr\'{e} Coeur: Collective Intelligence in Digital Volunteer Communities},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470769},
doi = {10.1145/2470654.2470769},
abstract = {This study examines the information-processing activities of digital volunteers and other connected ICT users in the wake of crisis events. Synthesizing findings from several previous research studies of digital volunteerism, this paper offers a new approach for conceptualizing the activities of digital volunteers, shifting from a focus on organizing to a focus on information movement. Using the lens of distributed cognition, this research describes collective intelligence as transformations of information within a system where cognition is distributed socially across individuals as well as through their tools and resources. This paper demonstrates how digital volunteers, through activities such as relaying, amplifying, verifying, and structuring information, function as a collectively intelligent cognitive system in the wake of disaster events.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {801–810},
numpages = {10},
keywords = {crowdsourcing, crisis informatics, collective intelligence, distributed cognition},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470770,
author = {Lee, Yu-Hao and Hsieh, Gary},
title = {Does Slacktivism Hurt Activism? The Effects of Moral Balancing and Consistency in Online Activism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470770},
doi = {10.1145/2470654.2470770},
abstract = {In this paper we explore how the decision of partaking in low-cost, low-risk online activism - slacktivism - '14may affect subsequent civic action. Based on moral balancing and consistency effects, we designed an online experiment to test if signing or not signing an online petition increased or decreased subsequent contribution to a charity. We found that participants who signed the online petition were significantly more likely to donate money to a related charity, demonstrating a consistency effect. We also found that participants who did not sign the petition donated significantly more money to an unrelated charity, demonstrating a moral balancing effect. The results suggest that exposure to an online activism influences individual decision on subsequent civic actions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {811–820},
numpages = {10},
keywords = {moral balancing, slacktivism, consistency, online petitions},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470771,
author = {Hutto, C.J. and Yardi, Sarita and Gilbert, Eric},
title = {A Longitudinal Study of Follow Predictors on Twitter},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470771},
doi = {10.1145/2470654.2470771},
abstract = {Follower count is important to Twitter users: it can indicate popularity and prestige. Yet, holistically, little is understood about what factors -- like social behavior, message content, and network structure - lead to more followers. Such information could help technologists design and build tools that help users grow their audiences. In this paper, we study 507 Twitter users and a half-million of their tweets over 15 months. Marrying a longitudinal approach with a negative binomial auto-regression model, we find that variables for message content, social behavior, and network structure should be given equal consideration when predicting link formations on Twitter. To our knowledge, this is the first longitudinal study of follow predictors, and the first to show that the relative contributions of social behavior and mes-sage content are just as impactful as factors related to social network structure for predicting growth of online social networks. We conclude with practical and theoretical implications for designing social media technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {821–830},
numpages = {10},
keywords = {computer-mediated communication, social media, social networks},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250130,
author = {Cao, Xiang},
title = {Session Details: Papers: Large and Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250130},
doi = {10.1145/3250130},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470773,
author = {Nancel, Mathieu and Chapuis, Olivier and Pietriga, Emmanuel and Yang, Xing-Dong and Irani, Pourang P. and Beaudouin-Lafon, Michel},
title = {High-Precision Pointing on Large Wall Displays Using Small Handheld Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470773},
doi = {10.1145/2470654.2470773},
abstract = {Rich interaction with high-resolution wall displays is not limited to remotely pointing at targets. Other relevant types of interaction include virtual navigation, text entry, and direct manipulation of control widgets. However, most techniques for remotely acquiring targets with high precision have studied remote pointing in isolation, focusing on pointing efficiency and ignoring the need to support these other types of interaction. We investigate high-precision pointing techniques capable of acquiring targets as small as 4 millimeters on a 5.5 meters wide display while leaving up to 93 % of a typical tablet device's screen space available for task-specific widgets. We compare these techniques to state-of-the-art distant pointing techniques and show that two of our techniques, a purely relative one and one that uses head orientation, perform as well or better than the best pointing-only input techniques while using a fraction of the interaction resources.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {831–840},
numpages = {10},
keywords = {pointing, wall displays, handheld devices},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470774,
author = {Walter, Robert and Bailly, Gilles and M\"{u}ller, J\"{o}rg},
title = {StrikeAPose: Revealing Mid-Air Gestures on Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470774},
doi = {10.1145/2470654.2470774},
abstract = {We investigate how to reveal an initial mid-air gesture on interactive public displays. This initial gesture can serve as gesture registration for advanced operations. We propose three strategies to reveal the initial gesture: spatial division, temporal division and integration. Spatial division permanently shows the gesture on a dedicated screen area. Temporal division interrupts the application to reveal the gesture. Integration embeds gesture hints directly in the application. We also propose a novel initial gesture called Teapot to illustrate our strategies. We report on a laboratory and field study. Our main findings are: A large percentage of all users execute the gesture, especially with spatial division (56%). Users intuitively discover a gesture vocabulary by exploring variations of the Teapot gesture by themselves, as well as by imitating and extending other users' variations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {841–850},
numpages = {10},
keywords = {public displays, revelation, field study, initial gesture},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2470775,
author = {Zhang, Yanxia and Bulling, Andreas and Gellersen, Hans},
title = {SideWays: A Gaze Interface for Spontaneous Interaction with Situated Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2470775},
doi = {10.1145/2470654.2470775},
abstract = {Eye gaze is compelling for interaction with situated displays as we naturally use our eyes to engage with them. In this work we present SideWays, a novel person-independent eye gaze interface that supports spontaneous interaction with displays: users can just walk up to a display and immediately interact using their eyes, without any prior user calibration or training. Requiring only a single off-the-shelf camera and lightweight image processing, SideWays robustly detects whether users attend to the centre of the display or cast glances to the left or right. The system supports an interaction model in which attention to the central display is the default state, while "sidelong glances" trigger input or actions. The robustness of the system and usability of the interaction model are validated in a study with 14 participants. Analysis of the participants' strategies in performing different tasks provides insights on gaze control strategies for design of SideWays applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {851–860},
numpages = {10},
keywords = {situated display, eye-based interaction, calibration-free, spontaneous interaction, eye tracking},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250064,
author = {Casiez, G\'{e}ry},
title = {Session Details: Papers: Interacting around Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250064},
doi = {10.1145/3250064},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466112,
author = {Jones, Brett R. and Benko, Hrvoje and Ofek, Eyal and Wilson, Andrew D.},
title = {IllumiRoom: Peripheral Projected Illusions for Interactive Experiences},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466112},
doi = {10.1145/2470654.2466112},
abstract = {IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. We investigate how projected visualizations in the periphery can negate, include, or augment the existing physical environment and complement the content displayed on the television screen. Peripheral projected illusions can change the appearance of the room, induce apparent motion, extend the field of view, and enable entirely new physical gaming experiences. Our system is entirely self-calibrating and is designed to work in any room. We present a detailed exploration of the design space of peripheral projected illusions and we demonstrate ways to trigger and drive such illusions from gaming content. We also contribute specific feedback from two groups of target users (10 gamers and 15 game designers); providing insights for enhancing game experiences through peripheral projected illusions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {869–878},
numpages = {10},
keywords = {immersion, gaming, projection mapping, spatial augmented reality, augmented reality, apparent motion},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466113,
author = {Xiao, Robert and Harrison, Chris and Hudson, Scott E.},
title = {WorldKit: Rapid and Easy Creation of Ad-Hoc Interactive Applications on Everyday Surfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466113},
doi = {10.1145/2470654.2466113},
abstract = {Instant access to computing, when and where we need it, has long been one of the aims of research areas such as ubiquitous computing. In this paper, we describe the WorldKit system, which makes use of a paired depth camera and projector to make ordinary surfaces instantly interactive. Using this system, touch-based interactivity can, without prior calibration, be placed on nearly any unmodified surface literally with a wave of the hand, as can other new forms of sensed interaction. From a user perspective, such interfaces are easy enough to instantiate that they could, if desired, be recreated or modified "each time we sat down" by "painting" them next to us. From the programmer's perspective, our system encapsulates these capabilities in a simple set of abstractions that make the creation of interfaces quick and easy. Further, it is extensible to new, custom interactors in a way that closely mimics conventional 2D graphical user interfaces, hiding much of the complexity of working in this new domain. We detail the hardware and software implementation of our system, and several example applications built using the library.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {879–888},
numpages = {10},
keywords = {sensors, augmented reality, surface computing, interactive spaces, ubiquitous computing, smart rooms, touch screens, depth sensing cameras},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466114,
author = {Gustafson, Sean G. and Rabe, Bernhard and Baudisch, Patrick M.},
title = {Understanding Palm-Based Imaginary Interfaces: The Role of Visual and Tactile Cues When Browsing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466114},
doi = {10.1145/2470654.2466114},
abstract = {Imaginary Interfaces are screen-less ultra-mobile interfaces. Previously we showed that even though they offer no visual feedback they allow users to interact spatially, e.g., by pointing at a location on their non-dominant hand.The primary goal of this paper is to provide a deeper understanding of palm-based imaginary interfaces, i.e., why they work. We perform our exploration using an interaction style inspired by interfaces for visually impaired users. We implemented a system that audibly announces target names as users scrub across their palm. Based on this interface, we conducted three studies. We found that (1) even though imaginary interfaces cannot display visual contents, users' visual sense remains the main mechanism that allows users to control the interface, as they watch their hands interact. (2) When we remove the visual sense by blindfolding, the tactile cues of both hands feeling each other in part replace the lacking visual cues, keeping imaginary interfaces usable. (3) While we initially expected the cues sensed by the pointing finger to be most important, we found instead that it is the tactile cues sensed by the palm that allow users to orient themselves most effectively.While these findings are primarily intended to deepen our understanding of Imaginary Interfaces, they also show that eyes-free interfaces located on skin outperform interfaces on physical devices. In particular, this suggests that palm-based imaginary interfaces may have benefits for visually impaired users, potentially outperforming the touchscreen-based devices they use today.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {889–898},
numpages = {10},
keywords = {imaginary interfaces, tactile feedback, non-visual, wearable, visual feedback, mobile},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466115,
author = {Hasan, Khalad and Ahlstr\"{o}m, David and Irani, Pourang},
title = {Ad-Binning: Leveraging around Device Space for Storing, Browsing and Retrieving Mobile Device Content},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466115},
doi = {10.1145/2470654.2466115},
abstract = {Exploring information content on mobile devices can be tedious and time consuming. We present Around-Device Binning, or AD-Binning, a novel mobile user interface that allows users to off-load mobile content in the space around the device. We informed our implementation of AD-Binning by exploring various design factors, such as the minimum around-device target size, suitable item selection methods, and techniques for placing content in off-screen space. In a task requiring exploration, we find that AD-Binning improves browsing efficiency by avoiding the minute selection and flicking mechanisms needed for on-screen interaction. We conclude with design guidelines for off screen content storage and browsing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {899–908},
numpages = {10},
keywords = {around-device interaction, visual analytics, off-screen discretization, data analytics},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250065,
author = {Weibel, Nadir},
title = {Session Details: Papers: Design for the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250065},
doi = {10.1145/3250065},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466117,
author = {Ylirisku, Salu and Lindley, Si\^{a}n and Jacucci, Giulio and Banks, Richard and Stewart, Craig and Sellen, Abigail and Harper, Richard and Regan, Tim},
title = {Designing Web-Connected Physical Artefacts for the 'aesthetic' of the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466117},
doi = {10.1145/2470654.2466117},
abstract = {Web-based technologies are often built to capitalize on the flexibility and fluidity that is supported by the internet, with the value of 'access anywhere' underpinning a blurring of boundaries across home and work. Yet the home is well known in HCI to have a unique set of qualities that can use-fully be drawn upon when designing to support domestic life. In this paper we ask what it means to design domestic web-connected technologies, placing the aesthetic and material properties intrinsic to the home and home life at the centre of our design exploration. We present three concepts that were selected and prototyped from a broader process of research-through-design: Tokens of Search provides tangible handles to web resources; Hole in Space connects the home intimately to a remote place; and Manhattan enables the tangible exploration of events in the community, putting the home at the centre. Discussions in the paper consider not only how aesthetics is articulated in the material and digital properties of the artefacts, but also how a consideration of the properties of the home can create a potentially new design space to explore.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {909–918},
numpages = {10},
keywords = {search, domestic, tangible, research through design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466118,
author = {Juhlin, Oskar and \"{O}nnevall, Elin},
title = {On the Relation of Ordinary Gestures to TV Screens: General Lessons for the Design of Collaborative Interactive Techniques},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466118},
doi = {10.1145/2470654.2466118},
abstract = {We present an interaction analysis based on ethnographic fieldwork of how physical movements, including gestures, are produced by viewers in front of television screens in a sports bar. Understanding ordinary life and specifically television watching in social situations will benefit the discussion of the potential of gesture techniques for controlling interactive televisions in various locations. Challenges for system design include body movement recognition, since movements can have many different purposes and are directed simultaneously at the screen and co-viewers. Moreover, gestures as elements of conversation are sometimes negotiated and overlapping. Since these ordinary movements are hard to automatically track and analyse, suggested systems might lead to demands on viewers to restrain their accustomed movements and adapt them in ways that might be considered awkward. We also reveal new design opportunities that draw upon the ways viewers' gestures are influenced by ongoing broadcast.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {919–930},
numpages = {12},
keywords = {everyday practice, tv viewing, gesture tracking adaptation, interaction analysis, group watching, interactive television, gestures, ethnomethodology, overlaps},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466119,
author = {Meese, Rupert and Ali, Shakir and Thorne, Emily-Clare and Benford, Steve D. and Quinn, Anthony and Mortier, Richard and Koleva, Boriana N. and Pridmore, Tony and Baurley, Sharon L.},
title = {From Codes to Patterns: Designing Interactive Decoration for Tableware},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466119},
doi = {10.1145/2470654.2466119},
abstract = {We explore the idea of making aesthetic decorative patterns that contain multiple visual codes. We chart an iterative collaboration with ceramic designers and a restaurant to refine a recognition technology to work reliably on ceramics, produce a pattern book of designs, and prototype sets of tableware and a mobile app to enhance a dining experience. We document how the designers learned to work with and creatively exploit the technology, enriching their patterns with embellishments and backgrounds and developing strategies for embedding codes into complex designs. We discuss the potential and challenges of interacting with such patterns. We argue for a transition from designing 'codes to patterns' that reflects the skills of designers alongside the development of new technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {931–940},
numpages = {10},
keywords = {recognition, patterns, qr codes, mobile applications, food, ceramics, barcodes, vision},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466120,
author = {Yuill, Nicola and Rogers, Yvonne and Rick, Jochen},
title = {Pass the IPad: Collaborative Creating and Sharing in Family Groups},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466120},
doi = {10.1145/2470654.2466120},
abstract = {The increasingly cross-generational use of personal technology portrays families each absorbed in individual devices. Tablets potentially support multi-user working but are currently used as personal devices primarily for consumption, or individual or web-based games. Could tablets support creative co-located groupwork in families and how does such creative work differ from the same task on paper? We designed and evaluated an app requiring individual and group co-creation in families. 262 family groups visiting a science fair played the collaborative drawing game on paper and iPads. Group creations were rated significantly more original and cohesive on iPads than paper. Detailed video analysis of seven family groups showed how tablets support embodiment and use of digital traces, and how the different media sustain individual and shared actions at different stages in the creative process. We sketch out implications for ownership and 'scrap computers': going beyond personally-owned devices and developing collaborative apps to support groupwork with tablets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {941–950},
numpages = {10},
keywords = {families, creation, shareable interfaces, scrap computers, group working, tablets, collaboration},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250066,
author = {Hsieh, Gary},
title = {Session Details: Papers: Social Creativity},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250066},
doi = {10.1145/3250066},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466122,
author = {Leong, Tuck W. and Wright, Peter C.},
title = {Revisiting Social Practices Surrounding Music},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466122},
doi = {10.1145/2470654.2466122},
abstract = {Music shapes our social lives. While previous research has provided a foundational understanding of the social affordances surrounding people's interactions with music, there is a need to update this understanding in light of recent key developments in our digital technological landscape. This paper describes a qualitative study of people's social activities and practices around music in households. It extends previous research by revealing the impact key technologies have on how, where, when, and with who people's interactions surrounding music occur. It also reveals people's creative attempts to design their musical experiences with others through reconfiguring and connecting to various digital technologies and digital platforms in order to pursue more opportunities for communicating, sharing, bonding, and celebrating lives with others.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {951–960},
numpages = {10},
keywords = {sociality, digital music, household, design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466123,
author = {Birnholtz, Jeremy and Steinhardt, Stephanie and Pavese, Antonella},
title = {Write Here, Write Now! An Experimental Study of Group Maintenance in Collaborative Writing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466123},
doi = {10.1145/2470654.2466123},
abstract = {Writing documents together using collaborative editing tools has become extremely common with the widespread availability of tools such as Google Docs. The design of such tools, rooted in early CSCW research, has historically been focused on providing awareness of the presence and activities of one's collaborators. Evidence from a recent qualitative study, however, suggests that people are also concerned about how their behaviors -- and they themselves -- will be perceived by others; and take steps to mitigate possible negative perceptions. We present an experimental study of dyads composing documents together, focusing in particular on group maintenance, impression management and relationship-focused behavior. Results suggest that communication is positively related to social relations, but only for synchronous writing in a shared space; the reverse can be true in asynchronous commenting and editing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {961–970},
numpages = {10},
keywords = {awareness, group maintenance., collaborative writing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466124,
author = {Gross, Shad and Pace, Tyler and Bardzell, Jeffrey and Bardzell, Shaowen},
title = {Machinima Production Tools: A Vernacular History of a Creative Medium},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466124},
doi = {10.1145/2470654.2466124},
abstract = {In recent years, HCI has shown a rising interest in the creative practices associated with massive online communities, including crafters, hackers, DIY, and other expert amateurs. One strategy for researching creativity at this scale is through an analysis of a community's outputs, including its creative works, custom created tools, and emergent practices. In this paper, we offer one such case study, a historical account of World of Warcraft (WoW) machinima (i.e., videos produced inside of video games), which shows how the aesthetic needs and requirements of video making community coevolved with the community-made creativity support tools in use at the time. We view this process as inhabiting different layers and practices of appropriation, and through an analysis of them, we trace the ways that support for emerging stylistic conventions become built into creativity support tools over time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {971–980},
numpages = {10},
keywords = {machinima, medium, hci, creativity},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466125,
author = {Cui, Yanqing and Kangas, Jari and Holm, Jukka and Grassel, Guido},
title = {Front-Camera Video Recordings as Emotion Responses to Mobile Photos Shared within Close-Knit Groups},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466125},
doi = {10.1145/2470654.2466125},
abstract = {People use social-photography services to tell stories about themselves and to solicit responses from viewers. State of the-art services concentrate on textual comments, "Like" buttons, or similar means for viewers to give explicit feedback, but they overlook other, non-textual means. This paper investigates how emotion responses--as video clips captured by the front camera of a cell phone and used as tags for the individual photo viewed--can enhance photo-sharing experiences for close-knit groups. Our exploration was carried out with a mobile social-photography service called Social Camera. Four user groups (N=19) used the application for two to four weeks. The study's results support the value of using front-camera video recordings to glean emotion response. It supports lightweight phatic social interactions not possible with comments and "Like" buttons. Most users kept sharing emotion responses throughout the study. They typically shared the responses right after they saw a just taken photo received from a remote partner. They used the responses to share their current contexts with others just as much as to convey nuanced feelings about a photo. We discuss the implications for future design and research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {981–990},
numpages = {10},
keywords = {mobile, social photography, feedback, close-knit group, social camera, emotion response, co-presence},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250067,
author = {Kay, Judy},
title = {Session Details: Papers: Design for Classrooms 2},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250067},
doi = {10.1145/3250067},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466127,
author = {Coughlan, Tim and Pitt, Rebecca and McAndrew, Patrick},
title = {Building Open Bridges: Collaborative Remixing and Reuse of Open Educational Resources across Organisations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466127},
doi = {10.1145/2470654.2466127},
abstract = {In this paper we analyse the remixing and reuse of online learning materials offered as Open Educational Resources (OER). We explore the practices that developed as a set of course materials were released as OER from the UK, remixed for a US context by a cross-organisational, cross-cultural team, and then reused in a broad range of educational settings. We analyse the approaches taken during these remixing and reuse activities as novel forms of creative collaboration. As a basis for comparison, we explore similarities and differences with openness in other domains. We identify how openness provoked novel inter-organisational collaboration and forms of ownership; define forms of open practice that need support, and present issues that should be considered in devising and supporting open projects in education and beyond.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {991–1000},
numpages = {10},
keywords = {collaboration, education, oer, open},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466128,
author = {Szafir, Daniel and Mutlu, Bilge},
title = {ARTFul: Adaptive Review Technology for Flipped Learning},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466128},
doi = {10.1145/2470654.2466128},
abstract = {Internet technology is revolutionizing education. Teachers are developing massive open online courses (MOOCs) and using innovative practices such as flipped learning in which students watch lectures at home and engage in hands-on, problem solving activities in class. This work seeks to explore the design space afforded by these novel educational paradigms and to develop technology for improving student learning. Our design, based on the technique of adaptive content review, monitors student attention during educational presentations and determines which lecture topic students might benefit the most from reviewing. An evaluation of our technology within the context of an online art history lesson demonstrated that adaptively reviewing lesson content improved student recall abilities 29% over a baseline system and was able to match recall gains achieved by a full lesson review in less time. Our findings offer guidelines for a novel design space in dynamic educational technology that might support both teachers and online tutoring systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1001–1010},
numpages = {10},
keywords = {learning, flipped learning, adaptive content review, electroencephalography (eeg), massive open online course (mooc), adaptive user interfaces (aui), information recall, brain-computer interfaces (bci)},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466129,
author = {Kuksenok, Katie and Brooks, Michael and Wang, Qian and Lee, Charlotte P.},
title = {Challenges and Opportunities for Technology in Foreign Language Classrooms},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466129},
doi = {10.1145/2470654.2466129},
abstract = {We present the results of a two-month ethnographic study of three introductory Russian classrooms. Through observation and interviews, we identify several distinct roles played by physical artifacts in the classrooms, such as providing a reference to necessary foreign-language material and serving as props in creative role-play. The range of roles taken on by artifacts and the attitudes students have toward them provide a basis for our discussion about how technology might be more effectively introduced into the socially negotiated environment of the introductory foreign-language classroom. We identify the need to balance between collaborative and personal technology in a stressful, but social, context. Our findings inform a range of roles that technology can undertake in replacing or augmenting existing classroom artifacts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1011–1020},
numpages = {10},
keywords = {classroom, students, foreign, language-learning, russian, artifact, communication, textbook, language},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466130,
author = {Kharrufa, Ahmed and Balaam, Madeline and Heslop, Phil and Leat, David and Dolan, Paul and Olivier, Patrick},
title = {Tables in the Wild: Lessons Learned from a Large-Scale Multi-Tabletop Deployment},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466130},
doi = {10.1145/2470654.2466130},
abstract = {This paper presents the results and experiences of a six-week deployment of multiple digital tabletops in a school. Dillenbourg's orchestration framework was used both to guide the design and analysis of the study. Four themes, which directly relate to the design of the technology for the classroom, out of the 15 orchestration factors are considered. For each theme, we present our design choices, the relevant observations, feedback from teachers and students, and we conclude with a number of lessons learned in the form of design recommendations. The distinguishing factors of our study are its scale (in terms of duration, number of classes, subjects, and teachers), and its 'in-the-wild' character, with the entire study being conducted in a school, led by the teachers, and using teacher-prepared, curriculum-based tasks. Our primary contributions are the analysis of our observations and design recommendations for future multi-tabletop applications designed for and deployed within the classroom. Our analyses and recommendations meaningfully extend HCI's current design understandings of such settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1021–1030},
numpages = {10},
keywords = {classroom orchestration, collaborative learning, tabletops},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250068,
author = {Lee, Joonhwan},
title = {Session Details: Papers: Reflecting on Phones},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250068},
doi = {10.1145/3250068},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466132,
author = {Brown, Barry and McGregor, Moira and Laurier, Eric},
title = {IPhone in Vivo: Video Analysis of Mobile Device Use},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466132},
doi = {10.1145/2470654.2466132},
abstract = {Despite the widespread use of mobile devices, details of mobile technology use 'in the wild' have proven difficult to collect. This paper uses video data to gain new insight into the use of mobile computing devices. Our new method combines screen-capture of iPhone use with video recordings from wearable cameras. We use this data to analyse how mobile device use is threaded into other co-present activities, focusing on the use of maps and internet searches. Close analysis reveals novel aspects of gestures on touch screens, how they serve 'double duty' - both as interface gestures but as as resources for ongoing joint action. We go on to describe how users 'walk the blue dot' to orientate themselves, and how searches are occasioned by the local environment. In conclusion, we argue that mobile devices - rather than pushing us away from the world around us - are instead just another thread in the complex tapestry of everyday interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1031–1040},
numpages = {10},
keywords = {video methods, ethnography, smartphone use, mobility},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466133,
author = {Devendorf, Laura and Ryokai, Kimiko},
title = {AnyType: Provoking Reflection and Exploration with Aesthetic Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466133},
doi = {10.1145/2470654.2466133},
abstract = {AnyType is a mobile application that generates unique typefaces from photographs of shapes that people find in their environment. In keeping with the principles of aesthetic interaction, the design of AnyType supports opportunities for surprise, storytelling, and expression. This paper presents data collected from two observational studies of AnyType. In both studies, we found that people appropriated the application to create highly personalized messages. They found inspiration in unexpected locations, created memories from nuanced details in their lives, and creatively explored the design space provided by the system. Drawing from our observations, we discuss possible roles mobile devices could play in people's personal meaning making, creative process, and discovery, in interaction with elements of their physical environment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1041–1050},
numpages = {10},
keywords = {self-expression, aesthetic interaction, typography, user experience design, mobile technology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466134,
author = {Harmon, Ellie and Mazmanian, Melissa},
title = {Stories of the Smartphone in Everyday Discourse: Conflict, Tension &amp; Instability},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466134},
doi = {10.1145/2470654.2466134},
abstract = {As the smartphone proliferates in American society, so too do stories about its value and impact. In this paper we draw on advertisements and news articles to analyze cultural discourse about the smartphone. We highlight two common tropes: one calling for increased technological integration, the other urging individuals to dis-integrate the smartphone from daily life. We examine the idealized subject positions of these two stories and show how both simplistic tropes call on the same overarching values to compel individuals to take opposing actions. We then reflect on the conflicts individuals experience in trying to align and account for their actions in relation to multiple contradictory narratives. Finally, we call for CHI researchers to tell and provoke more complicated stories of technologies and their relationships with values in conversations, publications, and future designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1051–1060},
numpages = {10},
keywords = {cultural discourse, smartphones, values and design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466135,
author = {Kujala, Sari and Miron-Shatz, Talya},
title = {Emotions, Experiences and Usability in Real-Life Mobile Phone Use},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466135},
doi = {10.1145/2470654.2466135},
abstract = {Positive emotional experiences with an interactive product are assumed to lead to good user experience and, ultimately, to product success. However, the path from emotional experiences to product evaluation may not be direct, as emotions fluctuate over time, and some experiences are easier to recall than others. In this study, we examined emotions and experience episodes during real-life mobile phone use over a five-month period. The goal is to understand how emotions and memories are related to overall evaluation of a product: usability, user experience and behavioral intentions. The results show that both emotions and how people remember them had strong unique roles in the overall evaluation of the product. Positive emotions were mostly related to good user experience and negative emotions to low usability. In the early stages of use, users overestimated their positive emotions and seemed to focus on user experience, the importance of usability increased over time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1061–1070},
numpages = {10},
keywords = {day reconstruction method, memories, word of mouth, mobile phone, emotions, user experience, usability, user satisfaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250069,
author = {Klasnja, Predrag},
title = {Session Details: Papers: Technologies for Life 2},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250069},
doi = {10.1145/3250069},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466137,
author = {Isaacs, Ellen and Konrad, Artie and Walendowski, Alan and Lennig, Thomas and Hollis, Victoria and Whittaker, Steve},
title = {Echoes from the Past: How Technology Mediated Reflection Improves Well-Being},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466137},
doi = {10.1145/2470654.2466137},
abstract = {As people document more of their lives online, some recent systems are encouraging people to later revisit those recordings, a practice we're calling technology-mediated reflection (TMR). Since we know that unmediated reflection benefits psychological well-being, we explored whether and how TMR affects well-being. We built Echo, a smartphone application for recording everyday experiences and reflecting on them later. We conducted three system deployments with 44 users who generated over 12,000 recordings and reflections. We found that TMR improves well-being as assessed by four psychological metrics. By analyzing the content of these entries we discovered two mechanisms that explain this improvement. We also report benefits of very long-term TMR.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1071–1080},
numpages = {10},
keywords = {memory, reflection, recording, well-being, technology mediated reflection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466138,
author = {Rice, Mark and Tan, Wah Pheow and Ong, Jeremy and Yau, Lih Jie and Wan, Marcus and Ng, Jamie},
title = {The Dynamics of Younger and Older Adult's Paired Behavior When Playing an Interactive Silhouette Game},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466138},
doi = {10.1145/2470654.2466138},
abstract = {In this paper, we report on the findings of an acute trial in which we evaluate the design of a novel gesture-based game. 60 younger and older players, divided into three separate group-types: (i) Young-Young, (ii) Old-Old, and (iii) Young-Old, took part in the study. The primary aim of this work was to evaluate the communicative and cooperative behavior of same-age and mixed-age pairs, with secondary interests in their perceived ease-of-use of the game. A mixed-method approach was used, comprising of direct observations, a post-game questionnaire and paired interviews. Our results identified noticeable differences between the group-types, with the Young-Old showing more physical cooperation, as compared to the same-age groups. The work elaborates on how the young and old differ in expectations and perceived interaction, and concludes with some recommendations for future research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1081–1090},
numpages = {10},
keywords = {digital games, silhouette interaction, intergenerational relations, older adults, cooperation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466139,
author = {Warnock, David and McGee-Lennon, Marilyn and Brewster, Stephen},
title = {Multiple Notification Modalities and Older Users},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466139},
doi = {10.1145/2470654.2466139},
abstract = {Multimodal interaction can make home care reminder systems more accessible to their users, most of whom are older and/or have sensory impairments. Existing research into the properties of different notification modalities have used younger participants rather than members of the older population at which they are aimed. This paper presents the results of a user study with older adults that examined how different notification modalities affected (a) performance in a card matching game and (b) how effective the different modalities were at delivering information. Participants were all aged over 50 and notifications were delivered using textual, pictographic, abstract visual, speech, Earcon, Auditory Icon, tactile and olfactory modalities while playing the game. The results showed that older users were influenced by the same factors as younger users, yet there were subjective differences. The implications for the design of multimodal reminder systems for home care are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1091–1094},
numpages = {4},
keywords = {multimodal, notifications, older users, reminders},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466140,
author = {Bentley, Frank and Tollmar, Konrad},
title = {The Power of Mobile Notifications to Increase Wellbeing Logging Behavior},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466140},
doi = {10.1145/2470654.2466140},
abstract = {Self-logging is a critical component to many wellbeing systems. However, self-logging often is difficult to sustain at regular intervals over many weeks. We demonstrate the power of passive mobile notifications to increase logging of wellbeing data, particularly food intake, in a mobile health service. Adding notifications increased the frequency of logging from 12% in a one-month, ten-user pilot study without reminders to 63% in the full 60-user study with reminders included. We will discuss the benefits of passive notifications over existing interruptive methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1095–1098},
numpages = {4},
keywords = {wellbeing, personal informatics, mobile, behavior change, notifications, logging},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250070,
author = {Li, Yang},
title = {Session Details: Papers: Gesture Studies},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250070},
doi = {10.1145/3250070},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466142,
author = {Nacenta, Miguel A. and Kamber, Yemliha and Qiang, Yizhou and Kristensson, Per Ola},
title = {Memorability of Pre-Designed and User-Defined Gesture Sets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466142},
doi = {10.1145/2470654.2466142},
abstract = {We studied the memorability of free-form gesture sets for invoking actions. We compared three types of gesture sets: user-defined gesture sets, gesture sets designed by the authors, and random gesture sets in three studies with 33 participants in total. We found that user-defined gestures are easier to remember, both immediately after creation and on the next day (up to a 24% difference in recall rate compared to pre-designed gestures). We also discovered that the differences between gesture sets are mostly due to association errors (rather than gesture form errors), that participants prefer user-defined sets, and that they think user-defined gestures take less time to learn. Finally, we contribute a qualitative analysis of the tradeoffs involved in gesture type selection and share our data and a video corpus of 66 gestures for replicability and further analysis.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1099–1108},
numpages = {10},
keywords = {user-defined gestures, gesture memorability, gesture sets},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466143,
author = {Anderson, Fraser and Bischof, Walter F.},
title = {Learning and Performance with Gesture Guides},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466143},
doi = {10.1145/2470654.2466143},
abstract = {Gesture-based interfaces are becoming more prevalent and complex, requiring non-trivial learning of gesture sets. Many methods for learning gestures have been proposed, but they are often evaluated with short-term recall tests that measure user performance, rather than learning. We evaluated four types of gesture guides using a retention and transfer paradigm common in motor learning experiments and found results different from those typically reported with recall tests. The results indicate that many guide systems with higher levels of guidance exhibit high performance benefits while the guide is being used, but are ultimately detrimental to user learning. We propose an adaptive guide that does not suffer from these drawbacks, and that enables a smooth transition from novice to expert. The results contrasting learning and performance can be explained by the guidance hypothesis. They have important implications for the design and evaluation of future gesture learning systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1109–1118},
numpages = {10},
keywords = {guides, learning, evaluation, gestures},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466144,
author = {Annett, Michelle and Bischof, Walter F.},
title = {Your Left Hand Can Do It Too! Investigating Intermanual, Symmetric Gesture Transfer on Touchscreens},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466144},
doi = {10.1145/2470654.2466144},
abstract = {This work examines intermanual gesture transfer, i.e., learning a gesture with one hand and performing it with the other. Using a traditional retention and transfer paradigm from the motor learning literature, participants learned four gestures on a touchscreen. The study found that touchscreen gestures transfer, and do so symmetrically. Regardless of the hand used during training, gestures were performed with a comparable level of error and speed by the untrained hand, even after 24 hours. In addition, the form of a gesture, i.e., its length or curvature, was found to have no influence on transferability. These results have important implications for the design of stroke-based gestural interfaces: acquisition could occur with either hand and it is possible to interchange the hand used to perform gestures. The work concludes with a discussion of these implications and highlights how they can be applied to gesture learning and current gestural systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1119–1128},
numpages = {10},
keywords = {skill acquisition, symmetric transfer, touchscreen, gesture transfer, gestures, intermanual transfer, motor learning},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466145,
author = {Oh, Uran and Findlater, Leah},
title = {The Challenges and Potential of End-User Gesture Customization},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466145},
doi = {10.1145/2470654.2466145},
abstract = {The vast majority of work on understanding and supporting the gesture creation process has focused on professional designers. In contrast, gesture customization by end users' - which may offer better memorability, efficiency and accessibility than pre-defined gestures - has received little attention. To understand the end-user gesture creation process, we conducted a study where 20 participants were asked to: (1) exhaustively create new gestures for an open-ended use case; (2) exhaustively create new gestures for 12 specific use cases; (3) judge the saliency of different touchscreen gesture features. Our findings showed that even when asked to create novel gestures, participants tended to focus on the familiar. Misconceptions about the gesture recognizer's abilities were also evident, and in some cases constrained the range of gestures that participants created. Finally, as a calibration point for future research, we used a simple gesture recognizer ($N) to analyze recognition accuracy of the participants' custom gesture sets: accuracy was 68-88% on average, depending on the amount of training and the customization scenario. We conclude with implications for the design of a mixed-initiative approach to support custom gesture creation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1129–1138},
numpages = {10},
keywords = {gestures, customization, touchscreen, personalization},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250071,
author = {Feiner, Steven},
title = {Session Details: Papers: Manipulating Video},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250071},
doi = {10.1145/3250071},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466147,
author = {Monserrat, Toni-Jan Keith Palma and Zhao, Shengdong and McGee, Kevin and Pandey, Anshul Vikram},
title = {NoteVideo: Facilitating Navigation of Blackboard-Style Lecture Videos},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466147},
doi = {10.1145/2470654.2466147},
abstract = {Khan Academy's pre-recorded blackboard-style lecture videos attract millions of online users every month. However, current video navigation tools do not adequately support the kinds of goals that students typically have, like quickly finding a particular concept in a blackboard-style lecture video. This paper reports on the development and evaluation of the new NoteVideo and its improved version, NoteVideo+, systems for identifying the conceptual 'objects' of a blackboard-based video - and then creating a summarized image of the video and using it as an in-scene navigation interface that allows users to directly jump to the video frame where that object first appeared instead of navigating it linearly through time. The research consisted of iteratively implementing the system and then having users perform four different navigation tasks using three different interfaces: Scrubbing, Transcript, and NoteVideo. Results of the study show that participants perform significantly better on all four tasks while using the NoteVideo and its improved version - NoteVideo+ - as compared to others.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1139–1148},
numpages = {10},
keywords = {blackboard-style videos, notevideo+, notevideo, online streaming, video, video navigation, video summary},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466148,
author = {Santosa, Stephanie and Chevalier, Fanny and Balakrishnan, Ravin and Singh, Karan},
title = {Direct Space-Time Trajectory Control for Visual Media Editing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466148},
doi = {10.1145/2470654.2466148},
abstract = {We explore the design space for using object motion trajectories to create and edit visual elements in various media across space and time. We introduce a suite of pen-based techniques that facilitate fluid stylization, annotation and editing of space-time content such as video, slide presentations and 2D animation, utilizing pressure and multi-touch input. We implemented and evaluated these techniques in DirectPaint, a system for creating free-hand painting and annotation over video.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1149–1158},
numpages = {10},
keywords = {sketching, pressure, video navigation, pen-based interface, optical flow, bimodal},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466149,
author = {Matejka, Justin and Grossman, Tovi and Fitzmaurice, George},
title = {Swifter: Improved Online Video Scrubbing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466149},
doi = {10.1145/2470654.2466149},
abstract = {Online streaming video systems have become extremely popular, yet navigating to target scenes of interest can be a challenge. While recent techniques have been introduced to enable real-time seeking, they break down for large videos, where scrubbing the timeline causes video frames to skip and flash too quickly to be comprehendible. We present Swifter, a new video scrubbing technique that displays a grid of pre-cached thumbnails during scrubbing actions. In a series of studies, we first investigate possible design variations of the Swifter technique, and the impact of those variations on its performance. Guided by these results we compare an implementation of Swifter to the previously published Swift technique, in addition to the approaches utilized by YouTube and Netfilx. Our results show that Swifter significantly outperforms each of these techniques in a scene locating task, by a factor of up to 48%.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1159–1168},
numpages = {10},
keywords = {video navigation, online streaming, video},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466150,
author = {Nguyen, Cuong and Niu, Yuzhen and Liu, Feng},
title = {Direct Manipulation Video Navigation in 3D},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466150},
doi = {10.1145/2470654.2466150},
abstract = {Direct Manipulation Video Navigation (DMVN) systems allow a user to navigate a video by dragging an object along its motion trajectory. These systems have been shown effective for space-centric video browsing. Their performance, however, is often limited by temporal ambiguities in a video with complex motion, such as recurring motion, self-intersecting motion, and pauses. The ambiguities come from reducing the 3D spatial-temporal motion (x, y, t) to the 2D spatial motion (x, y) in visualizing the motion and dragging the object. In this paper, we present a 3D DMVN system that maps the spatial-temporal motion (x, y, t) to 3D space (x, y, z) by mapping time t to depth z, visualizes the motion and video frame in 3D, and allows to navigate the video by spatial-temporally manipulating the object in 3D. We show that since our 3D DMVN system preserves all the motion information, it resolves the temporal ambiguities and supports intuitive navigation on challenging videos with complex motion.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1169–1172},
numpages = {4},
keywords = {3d visualization, video navigation, direct manipulation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250072,
author = {Zimmerman, John},
title = {Session Details: Papers: Sustainable Energy},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250072},
doi = {10.1145/3250072},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466152,
author = {Rodden, Tom A. and Fischer, Joel E. and Pantidi, Nadia and Bachour, Khaled and Moran, Stuart},
title = {At Home with Agents: Exploring Attitudes towards Future Smart Energy Infrastructures},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466152},
doi = {10.1145/2470654.2466152},
abstract = {Energy systems researchers are proposing a broad range of future "smart" energy infrastructures to promote more efficient management of energy resources. This paper considers how consumers might relate to these future smart grids within the UK. To address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. Users' reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. Users showed a considerable lack of trust in energy companies raising a dilemma of design. While users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. This suggests the need to consider how to design software agents to enhance trust in these socio-economic settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1173–1182},
numpages = {10},
keywords = {agent-based systems, smart grid, participatory design, whiteboard animations, sketching, focus groups, envisioning},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2466152_R49198,
author = {De, Debraj},
title = {Review ID:R49198 for DOI: 10.1145/2470654.2466152},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2466152_R49198}
}

@inproceedings{10.1145/2470654.2466153,
author = {Neustaedter, Carman and Bartram, Lyn and Mah, Aaron},
title = {Everyday Activities and Energy Consumption: How Families Understand the Relationship},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466153},
doi = {10.1145/2470654.2466153},
abstract = {Energy consumption is a growing concern and it is important to inform families of their consumption and how they might reduce it. We conducted an interview study that focuses on the existing routines of families and how they currently understand their power and gas consumption based on standard utility bills. We also investigated how this understanding ties to their everyday activities as might be recorded on their calendars. This allowed us to assess calendars as an artifact for energy consumption awareness. Our results show that many people relate changes in energy consumption to high-level effects such as weather and temperature and not necessarily their own everyday activities. Events on calendars may aid this understanding but people do not currently record enough information on their calendars to make a strong tie. This suggests that if calendars are to be used as artifacts to aid energy consumption understanding, digital calendars need to provide support to include more energy-related information, including both activities and patterns of consumption.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1183–1192},
numpages = {10},
keywords = {energy consumption, families, calendars},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466154,
author = {Schwartz, Tobias and Denef, Sebastian and Stevens, Gunnar and Ramirez, Leonardo and Wulf, Volker},
title = {Cultivating Energy Literacy: Results from a Longitudinal Living Lab Study of a Home Energy Management System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466154},
doi = {10.1145/2470654.2466154},
abstract = {This paper presents results of a three-year research project focused on the emplacement of Home Energy Management Systems (HEMS) in a living lab setting with seven households. The HEMS used in this study allowed householders to monitor energy consumption both in real-time and in retrospective on the TV and on mobile devices. Contrasting with existing research focused on how technology persuades people to consume less energy, our study uses a grounded approach to analyze HEMS emplacement. As an important result, we present here the issue of 'energy literacy'. Our study reveals that, by using HEMS, participants became increasingly literate in understanding domestic electricity consumption. We discuss the role HEMS played in that process and how the acquired literacy changed energy consumption patterns. We conclude that literacy in energy consumption has value on its own and explain how eco feedback system designs can benefit from this understanding.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1193–1202},
numpages = {10},
keywords = {energy monitoring, hems, energy literacy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466155,
author = {Erickson, Thomas and Li, Ming and Kim, Younghun and Deshpande, Ajay and Sahu, Sambit and Chao, Tian and Sukaviriya, Piyawadee and Naphade, Milind},
title = {The Dubuque Electricity Portal: Evaluation of a City-Scale Residential Electricity Consumption Feedback System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466155},
doi = {10.1145/2470654.2466155},
abstract = {This paper describes the Dubuque Electricity Portal, a city-scale system aimed at supporting voluntary reductions of electricity consumption. The Portal provided each household with fine-grained feedback on its electricity use, as well as using incentives, comparisons, and goal setting to encourage conservation. Logs, a survey and interviews were used to evaluate the user experience of the Portal during a 20-week pilot with 765 volunteer households. Although the volunteers had already made a wide range of changes to conserve electricity prior to the pilot, those who used the Portal decreased their electricity use by about 3.7%. They also reported increased understanding of their usage, and reported taking an array of actions - both changing their behavior and their electricity infrastructure. The paper discusses the experience of the system's users, and describes challenges for the design of ECF systems, including balancing accessibility and security, a preference for time-based visualizations, and the advisability of multiple modes of feedback, incentives and information presentation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1203–1212},
numpages = {10},
keywords = {behavior change, electricity, social comparison, sustainability, consumption feedback systems, smart meters, ecf},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2466155_R49760,
author = {Orvalho, Joao},
title = {Review ID:R49760 for DOI: 10.1145/2470654.2466155},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2466155_R49760}
}

@inproceedings{10.1145/3250073,
author = {Moffatt, Karyn},
title = {Session Details: Papers: Impairment and Rehabilitation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250073},
doi = {10.1145/3250073},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466157,
author = {Salivia, Guarionex and Hourcade, Juan Pablo},
title = {PointAssist: Assisting Individuals with Motor Impairments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466157},
doi = {10.1145/2470654.2466157},
abstract = {We tested PointAssist, software that assists in pointing tasks by detecting difficulty through a sub-movement analysis and triggering help, with adjustments proposed to personalize the assistance provided to individuals with motor impairments. A within-subjects study with sixteen individuals with fine motor skills impairments resulted in statistically significant effects on accuracy using Friedman's test with (Χ2(1)=6.4, p=.011 in favor of personalized PointAssist compared to no assistance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1213–1222},
numpages = {10},
keywords = {human-computer interaction, pointing tasks, sub-movements, older adults, motor impairments},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466158,
author = {Anthony, Lisa and Kim, YooJin and Findlater, Leah},
title = {Analyzing User-Generated Youtube Videos to Understand Touchscreen Use by People with Motor Impairments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466158},
doi = {10.1145/2470654.2466158},
abstract = {Most work on the usability of touchscreen interaction for people with motor impairments has focused on lab studies with relatively few participants and small cross-sections of the population. To develop a richer characterization of use, we turned to a previously untapped source of data: YouTube videos. We collected and analyzed 187 non-commercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mainstream mobile touchscreen device. We coded the videos along a range of dimensions to characterize the interaction, the challenges encountered, and the adaptations being adopted in daily use. To complement the video data, we also invited the video uploaders to complete a survey on their ongoing use of touchscreen technology. Our findings show that, while many people with motor impairments find these devices empowering, accessibility issues still exist. In addition to providing implications for more accessible touchscreen design, we reflect on the application of user-generated content to study user interface design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1223–1232},
numpages = {10},
keywords = {iphone, ipad, motor impairments, youtube, physical disabilities, touchscreen, assistive technology},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2466158_R49366,
author = {Mani, Ganapathy},
title = {Review ID:R49366 for DOI: 10.1145/2470654.2466158},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2466158_R49366}
}

@inproceedings{10.1145/2470654.2466159,
author = {Uzor, Stephen and Baillie, Lynne},
title = {Exploring &amp; Designing Tools to Enhance Falls Rehabilitation in the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466159},
doi = {10.1145/2470654.2466159},
abstract = {Falls are the leading cause of accidental injury-related deaths in the elderly; a fall can lead to a loss of independence, and a fear of falling. Rehabilitation programmes involving exercise have proved the most successful way to reduce the risk of falls. However, the limitations of standard care (e.g. booklets) could prevent home users from receiving the full therapeutic benefit that rehabilitation offers. Having consulted users and health experts, we developed games, and visualizations for falls rehabilitation that we believe could potentially overcome the main barriers to effective rehabilitation in the home. In this paper, we describe user studies that we carried out with older adults to evaluate the use of these visual tools versus standard care, both in the laboratory and in the home. Our main findings show that our visualizations and games were able to overcome the major limitations of standard care, and that they were usable and acceptable to the end users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1233–1242},
numpages = {10},
keywords = {rehabilitation, games, visualization, usability, falls, user-centered},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466160,
author = {Boulanger, Cati and Boulanger, Adam and de Greef, Lilian and Kearney, Andy and Sobel, Kiley and Transue, Russell and Sweedyk, Z and Dietz, Paul H. and Bathiche, Steven},
title = {Stroke Rehabilitation with a Sensing Surface},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466160},
doi = {10.1145/2470654.2466160},
abstract = {This paper presents a new sensing and interaction environment for post-stroke and upper extremity limb rehabilitation. The device is a combination of camera-based multitouch sensing and a supporting therapeutic software application that advances the treatment, provides feedback, and records a user's progress. The image-based analysis of hand position provided by a Microsoft Surface is used as an input into a tabletop game environment. Tailored image analysis algorithms assess rehabilitative hand movements. Visual feedback is provided in a game context. Experiments were conducted in a sub-acute rehabilitation center. Preliminary user studies with a stroke-afflicted population determined essential design criteria. Hand and wrist sensing, as well as the goals of the supporting game environment, engage therapeutic flexion and extension as defined by consulted physicians. Participants valued personalization of the activity, novelty, reward and the ability to work at their own pace in an otherwise repetitive therapeutic task. A "character" - game element personifying the participant's movement - was uniquely motivating relative to the media available in the typical therapeutic routine.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1243–1246},
numpages = {4},
keywords = {gesture recognition, tabletop, stroke, rehabilitation, hci},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466161,
author = {Ananthanarayan, Swamy and Sheh, Miranda and Chien, Alice and Profita, Halley and Siek, Katie},
title = {Pt Viz: Towards a Wearable Device for Visualizing Knee Rehabilitation Exercises},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466161},
doi = {10.1145/2470654.2466161},
abstract = {We present a wearable sensory display for visualizing knee rehabilitation as part of an in-home physical therapy program. Currently, patients undergoing knee rehabilitation have limited ways of assessing exercise form and extent of movement at home. To address this issue, we developed an exploratory wearable electronic prototype to visualize knee bend. We evaluated the device with physical therapy patients to get feedback on the design and to help us understand some of the challenges they face. We discovered that our current design is better suited for patients recovering from surgery as opposed to patients with chronic conditions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1247–1250},
numpages = {4},
keywords = {user interface device, wearable display, knee rehabilitation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250074,
author = {Poole, Erika},
title = {Session Details: Papers: Exergames and Beyond},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250074},
doi = {10.1145/3250074},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466163,
author = {Macvean, Andrew and Robertson, Judy},
title = {Understanding Exergame Users' Physical Activity, Motivation and Behavior over Time},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466163},
doi = {10.1145/2470654.2466163},
abstract = {Effective exergames should increase the proportion of time users regularly spend in moderate to vigorous physical activity. There are currently few studies of exergame systems which evaluate the impact on physical activity over time. Those which do, show increases in light intensity exercise which although valuable, do not increase the proportion of moderate to vigorous activity required for optimal health benefits. Furthermore, longitudinal studies to date have encountered a plateau effect in physical activity as the novelty of the game wears off. This paper suggests how exergame designs based on deeper understandings of player motivations could address these problems.We report on longitudinal patterns of users' physical activity, motivations and behaviour when using exergames, based on case studies from a seven week long school based field trial. These new insights, interpreted through Bandura's theory of self efficacy, are of value to designers in the HCI community who wish to motivate users with a range of attitudes towards exercise to undertake regular moderate to vigorous physical activity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1251–1260},
numpages = {10},
keywords = {self-efficacy, motivation, behavior change, exergames, classroom intervention},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466164,
author = {Hernandez, Hamilton A. and Ye, Zi and Graham, T.C. Nicholas and Fehlings, Darcy and Switzer, Lauren},
title = {Designing Action-Based Exergames for Children with Cerebral Palsy},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466164},
doi = {10.1145/2470654.2466164},
abstract = {Children with cerebral palsy (CP) want to play fast-paced action-oriented videogames similar to those played by their peers without motor disabilities. This is particularly true of exergames, whose physically-active gameplay matches the fast pace of action games. But disabilities resulting from CP can make it difficult to play action games. Guidelines for developing games for people with motor disabilities steer away from high-paced action, including recommendations to avoid the need for time-sensitive actions and to keep game pace slow. Through a year-long participatory design process with children with CP, we have discovered that it is in fact possible to develop action-oriented exergames for children with CP at level III on the Gross Motor Function Classification Scale. We followed up the design process with an eight-week home trial, in which we found the games to be playable and enjoyable. In this paper, we discuss the design of these games, and present a set of design recommendations for how to achieve both action-orientation and playability.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1261–1270},
numpages = {10},
keywords = {exergame, children with cerebral palsy., video game design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466165,
author = {Pijnappel, Sebastiaan and Mueller, Florian},
title = {4 Design Themes for Skateboarding},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466165},
doi = {10.1145/2470654.2466165},
abstract = {Interactive technology can support exertion activities, with many examples focusing on improving athletic performance. We see an opportunity for technology to also support extreme sports such as skateboarding, which often focus primarily on the experience of doing tricks rather than on athletic performance. However, there is little knowledge on how to design for such experiences. In response, we designed 12 basic skateboarding prototypes inspired by skateboarding theory. Using an autoethnographical approach, we skated with each of these and reflected on our experiences in order to derive four design themes : location of feedback in relation to the skater's body, timing of feedback in relation to peaks in emotions after attempts, aspects of the trick emphasized by feedback, and aesthetic fittingness of feedback. We hope our work will guide designers of interactive systems for skateboarding, and extreme sports in general, and will therefore further our understanding of how to design for the active human body.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1271–1274},
numpages = {4},
keywords = {skateboarding, autoethnography, exertion, extreme sports, experience of attempting tricks},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466166,
author = {Vongsathorn, Linden and O'Hara, Kenton and Mentis, Helena M.},
title = {Bodily Interaction in the Dark},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466166},
doi = {10.1145/2470654.2466166},
abstract = {In light of the growing interest in designing for new body-movement based interfaces through somaesthetics and somatic awareness, we created a sound-based interaction using the Microsoft Kinect device, which is performed in the dark. The absence of visual feedback led participants to deeply focus on the movement of their bodies, and to have a different awareness of their bodies and the space around them. The notable difference between performing this interaction in light and dark suggests that non-visual based interfaces are a fruitful area to explore in somaesthetic interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1275–1278},
numpages = {4},
keywords = {body, vision, dark, movement, somaesthetics, awareness},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250075,
author = {MacLean, Karon},
title = {Session Details: Papers: Full-Body Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250075},
doi = {10.1145/3250075},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466168,
author = {Jung, Jinyung and Bae, Seok-Hyung and Lee, Joon Hyub and Kim, Myung-Suk},
title = {Make It Move: A Movement Design Method of Simple Standing Products Based on Systematic Mapping of Torso Movements &amp; Product Messages},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466168},
doi = {10.1145/2470654.2466168},
abstract = {Human communication significantly relies on the expressivity of their body movements. Based on these body language experiences, humans tend to extract meanings even from movements of objects. This paper begins with the above human tendencies to create a design method that can help product designers make their products move to communicate. As a research vehicle, we created a robotic torso prototype and utilized it to collaborate with movement experts, and listed up possible expressive movement components. We then built a mapping matrix that links these movements to general product messages. A method which utilizes this mapping matrix was developed to help designers determine a set of effective movements that can communicate specific product messages. Lastly, a design workshop was conducted to identify the usefulness of the proposed method. We expect the procedures and findings of this study to help researchers and designers approach affective user experience through product movement design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1279–1288},
numpages = {10},
keywords = {product movement, design method},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466169,
author = {Oulasvirta, Antti and Roos, Teemu and Modig, Arttu and Lepp\"{a}nen, Laura},
title = {Information Capacity of Full-Body Movements},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466169},
doi = {10.1145/2470654.2466169},
abstract = {We present a novel metric for information capacity of full-body movements. It accommodates HCI scenarios involving continuous movement of multiple limbs. Throughput is calculated as mutual information in repeated motor sequences. It is affected by the complexity of movements and the precision with which an actor reproduces them. Computation requires decorrelating co-dependencies of movement features (e.g., wrist and elbow) and temporal alignment of sequences. HCI researchers can use the metric as an analysis tool when designing and studying user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1289–1298},
numpages = {10},
keywords = {full-body movement, throughput, information theory, gesture-based interfaces, measurement, information capacity},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466170,
author = {Wagner, Julie and Nancel, Mathieu and Gustafson, Sean G. and Huot, Stephane and Mackay, Wendy E.},
title = {Body-Centric Design Space for Multi-Surface Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466170},
doi = {10.1145/2470654.2466170},
abstract = {We introduce BodyScape, a body-centric design space that allows us to describe, classify and systematically compare multi-surface interaction techniques, both individually and in combination. BodyScape reflects the relationship between users and their environment, specifically how different body parts enhance or restrict movement within particular interaction techniques and can be used to analyze existing techniques or suggest new ones. We illustrate the use of BodyScape by comparing two free-hand techniques, on-body touch and mid-air pointing, first separately, then combined. We found that touching the torso is faster than touching the lower legs, since it affects the user's balance; and touching targets on the dominant arm is slower than targets on the torso because the user must compensate for the applied force.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1299–1308},
numpages = {10},
keywords = {multi-surface interaction, body-centric design space},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466171,
author = {Velloso, Eduardo and Bulling, Andreas and Gellersen, Hans},
title = {MotionMA: Motion Modelling and Analysis by Demonstration},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466171},
doi = {10.1145/2470654.2466171},
abstract = {Particularly in sports or physical rehabilitation, users have to perform body movements in a specific manner for the exercises to be most effective. It remains a challenge for experts to specify how to perform such movements so that an automated system can analyse further performances of it. In a user study with 10 participants we show that experts' explicit estimates do not correspond to their performances. To address this issue we present MotionMA, a system that: (1) automatically extracts a model of movements demonstrated by one user, e.g. a trainer, (2) assesses the performance of other users repeating this movement in real time, and (3) provides real-time feedback on how to improve their performance. We evaluated the system in a second study in which 10 other participants used the system to demonstrate arbitrary movements. Our results demonstrate that MotionMA is able to extract an accurate movement model to spot mistakes and variations in movement execution.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1309–1318},
numpages = {10},
keywords = {activity assessment, real-time user feedback, learning by demonstration, weight lifting, motion modelling},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250076,
author = {Harrison, Steve},
title = {Session Details: Papers: Video Communication},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250076},
doi = {10.1145/3250076},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466173,
author = {Pece, Fabrizio and Steptoe, William and Wanner, Fabian and Julier, Simon and Weyrich, Tim and Kautz, Jan and Steed, Anthony},
title = {Panoinserts: Mobile Spatial Teleconferencing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466173},
doi = {10.1145/2470654.2466173},
abstract = {We present PanoInserts: a novel teleconferencing system that uses smartphone cameras to create a surround representation of meeting places. We take a static panoramic image of a location into which we insert live videos from smartphones. We use a combination of marker- and image-based tracking to position the video inserts within the panorama, and transmit this representation to a remote viewer. We conduct a user study comparing our system with fully-panoramic video and conventional webcam video conferencing for two spatial reasoning tasks. Results indicate that our system performs comparably with fully-panoramic video, and better than webcam video conferencing in tasks that require an accurate surrounding representation of the remote space. We discuss the representational properties and usability of varying video presentations, exploring how they are perceived and how they influence users when performing spatial reasoning tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1319–1328},
numpages = {10},
keywords = {remote collaboration, camera tracking, teleconferencing, mixed reality, mobile phones, panoramas, telepresence},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466174,
author = {Norris, James and Schn\"{a}delbach, Holger M. and Luff, Paul K.},
title = {Putting Things in Focus: Establishing Co-Orientation through Video in Context},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466174},
doi = {10.1145/2470654.2466174},
abstract = {In collaborative video communication systems, establishing co-orientation around physical objects, virtual objects and people is a critical requirement. This is problematic as the technical limitations of video fractures the display of conduct in the connected environments. We present the results of a study of one collaborative system, CamBlend, which aims to alleviate some of these problems by using screen based pointing tools to both physical spaces and virtual resources. We report on how participants achieved co-orientation when using this system. We relate these findings to previous research into the fractured ecologies of collaborative spaces, describing how the form and nature of fractures in CamBlend differ from earlier reported work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1329–1338},
numpages = {10},
keywords = {focus+context, collaboration, interaction analysis, cscw},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466175,
author = {Tang, John C. and Xiao, Robert and Hoff, Aaron and Venolia, Gina and Therien, Patrick and Roseway, Asta},
title = {HomeProxy: Exploring a Physical Proxy for Video Communication in the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466175},
doi = {10.1145/2470654.2466175},
abstract = {HomeProxy is a research prototype that explores supporting video communication in the home among distributed family members through a physical proxy. It leverages a physical artifact dedicated to representing remote family members to make it easier to share activities with them. HomeProxy combines a form factor designed for the home environment with a "no-touch" user experience and an interface that responsively transitions between recorded and live video messages. We designed and implemented a prototype and conducted a pilot study with eight pairs of users. Our study demonstrated the challenges of a no-touch interface and the promise of offering quick video messaging in the home.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1339–1342},
numpages = {4},
keywords = {asynchronous video, home, physical proxies, video chat},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250077,
author = {Hurst, Amy},
title = {Session Details: Papers: Ideation Methods},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250077},
doi = {10.1145/3250077},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466177,
author = {Faste, Haakon and Rachmel, Nir and Essary, Russell and Sheehan, Evan},
title = {Brainstorm, Chainstorm, Cheatstorm, Tweetstorm: New Ideation Strategies for Distributed HCI Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466177},
doi = {10.1145/2470654.2466177},
abstract = {In this paper we describe the results of a design-driven study of collaborative ideation. Based on preliminary findings that identified a novel digital ideation paradigm we refer to as chainstorming, or online communication brainstorming, two exploratory studies were performed. First, we developed and tested a distributed method of ideation we call cheatstorming, in which previously generated brainstorm ideas are delivered to targeted local contexts in response to a prompt. We then performed a more rigorous case study to examine the cheatstorming method and consider its possible implementation in the context of a distributed online ideation tool. Based on observations from these studies, we conclude with the somewhat provocative suggestion that ideation need not require the generation of new ideas. Rather, we present a model of ideation suggesting that its value has less to do with the generation of novel ideas than the cultural influence exerted by unconventional ideas on the ideating team. Thus brainstorming is more than the pooling of "invented" ideas, it involves the sharing and interpretation of concepts in unintended and (ideally) unanticipated ways.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1343–1352},
numpages = {10},
keywords = {cheatstorming, ideation, brainstorming, chainstorming, tweetstormer},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466178,
author = {Juhlin, Oskar and Zhang, Yanqing and Sundbom, Cristine and Fernaeus, Ylva},
title = {Fashionable Shape Switching: Explorations in Outfit-Centric Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466178},
doi = {10.1145/2470654.2466178},
abstract = {We present a design exercise illustrating how fashion practices and the fashion design process can be used to create new opportunities both in the mobile domain and in product design, as well as in wearable computing. We investigate the concept of outfit-centric design by extending the support for social and visual interaction with digital devices beyond the currently available shells and stickers, and drawing on the ways in which people vary their dress ensembles. We designed a set of mock-up samples in a local fashion style, as a first step in understanding possible applications of the emerging technology of organic interfaces. Initial user feedback shows how fashion-conscious participants creatively experimented with the set's variations of shape and color in outfits created from their personal wardrobes, which revealed the importance of the objects' size and location on the body. It also points out that a lack of integration with the fashion system's processes reduces the attractiveness of the samples.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1353–1362},
numpages = {10},
keywords = {design, mobile interaction, dressing, product design, organic interface, fashion, wearable computing, outfit},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250078,
author = {Moscovich, Tomer},
title = {Session Details: Papers: Pointing and Fitts Law},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250078},
doi = {10.1145/3250078},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466180,
author = {Bi, Xiaojun and Li, Yang and Zhai, Shumin},
title = {FFitts Law: Modeling Finger Touch with Fitts' Law},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466180},
doi = {10.1145/2470654.2466180},
abstract = {Fitts' law has proven to be a strong predictor of pointing performance under a wide range of conditions. However, it has been insufficient in modeling small-target acquisition with finger-touch based input on screens. We propose a dual-distribution hypothesis to interpret the distribution of the endpoints in finger touch input. We hypothesize the movement endpoint distribution as a sum of two independent normal distributions. One distribution reflects the relative precision governed by the speed-accuracy tradeoff rule in the human motor system, and the other captures the absolute precision of finger touch independent of the speed-accuracy tradeoff effect. Based on this hypothesis, we derived the FFitts model - an expansion of Fitts' law for finger touch input. We present three experiments in 1D target acquisition, 2D target acquisition and touchscreen keyboard typing tasks respectively. The results showed that FFitts law is more accurate than Fitts' law in modeling finger input on touchscreens. At 0.91 or a greater R2 value, FFitts' index of difficulty is able to account for significantly more variance than conventional Fitts' index of difficulty based on either a nominal target width or an effective target width in all the three experiments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1363–1372},
numpages = {10},
keywords = {fitts' law, finger input, touchscreen},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466181,
author = {Banovic, Nikola and Grossman, Tovi and Fitzmaurice, George},
title = {The Effect of Time-Based Cost of Error in Target-Directed Pointing Tasks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466181},
doi = {10.1145/2470654.2466181},
abstract = {One of the fundamental operations in today's user interfaces is pointing to targets, such as menus, buttons, and text. Making an error when selecting those targets in real-life user interfaces often results in some cost to the user. However, the existing target-directed pointing models do not consider the cost of error when predicting task completion time. In this paper, we present a model based on expected value theory that predicts the impact of the error cost on the user's completion time for target-directed pointing tasks. We then present a target-directed pointing user study, which results show that time-based costs of error significantly impact the user's performance. Our results also show that users perform according to an expected completion time utility function and that optimal performance computed using our model gives good prediction of the observed task completion times.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1373–1382},
numpages = {10},
keywords = {speed-accuracy tradeoff, pointing time, pointing errors, movement time, error cost, fitts' law},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466182,
author = {Aceituno, Jonathan and Casiez, G\'{e}ry and Roussel, Nicolas},
title = {How Low Can You Go? Human Limits in Small Unidirectional Mouse Movements},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466182},
doi = {10.1145/2470654.2466182},
abstract = {Computer mouse sensors keep increasing in resolution. The smallest displacement they can detect gets smaller, but little is known on our ability to control such small movements. Small target acquisition has been previously tackled, but the findings do not apply to the problem of finding the useful resolution of a user with a mouse, which corresponds to the smallest displacement (s)he can reliably produce with that device. We detail this definition and provide an associated experimental protocol to measure it. We then report on the results of a study suggesting that high-end mice are not likely to be used to their full potential. We further comment on the different strategies used by participants to acheive best performance, and derive implications for user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1383–1386},
numpages = {4},
keywords = {input device, useful resolution, mouse, resolution},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466183,
author = {Fares, Ribel and Fang, Shaomin and Komogortsev, Oleg},
title = {Can We Beat the Mouse with MAGIC?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466183},
doi = {10.1145/2470654.2466183},
abstract = {MAGIC pointing techniques combine eye tracking with manual input. Since the mouse performs exceptionally well in a desktop setting, previous research on MAGIC pointing either resulted in minor improvements, or the techniques were applied to alternative devices or environments. We design Animated MAGIC, a novel, target-agnostic MAGIC pointing technique, for the specific goal of beating the mouse in a desktop setting. To improve the eye-tracking accuracy, we develop a dynamic local calibration method that uses each selection as a local calibration point. We compare Animated MAGIC to mouse-only and Conservative MAGIC, one of the two original MAGIC pointing methods, in a Fitts' Law experiment. We conduct a user questionnaire to evaluate the usability of the interaction methods. Results suggest that Dynamic Local Calibration improves eye-tracking accuracy and, consequently, MAGIC pointing performance. Powered with Dynamic Local Calibration, Animated MAGIC outperformed mouse-only by 8% in terms of throughput. Both MAGIC pointing methods reduced the amount of hand movement by more than half.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1387–1390},
numpages = {4},
keywords = {tracking, local, dynamic, multimodal, law, calibration, fitts, eye, gaze, mouse, interaction, animated, magic, input},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250079,
author = {Harrison, Chris},
title = {Session Details: Papers: Sensing Touch},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250079},
doi = {10.1145/3250079},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466185,
author = {Liang, Rong-Hao and Cheng, Kai-Yin and Chan, Liwei and Peng, Chuan-Xhyuan and Chen, Mike Y. and Liang, Rung-Huei and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBits: Magnetic Tangible Bits for Portable and Occlusion-Free near-Surface Interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466185},
doi = {10.1145/2470654.2466185},
abstract = {We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391–1400},
numpages = {10},
keywords = {occlusion-free, near-surface tracking, magnetism, tangible interactions, portable},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466186,
author = {Grosse-Puppendahl, Tobias and Braun, Andreas and Kamieth, Felix and Kuijper, Arjan},
title = {Swiss-Cheese Extended: An Object Recognition Method for Ubiquitous Interfaces Based on Capacitive Proximity Sensing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466186},
doi = {10.1145/2470654.2466186},
abstract = {Swiss-Cheese Extended proposes a novel real-time method for recognizing objects with capacitive proximity sensors. Applying this technique to ubiquitous user interfaces, it is possible to detect the 3D-position of multiple human hands in different configurations above a surface that is equipped with a small number of sensors. The retrieved object configurations can significantly improve a user's interaction experience or an application's execution context, for example by detecting multi-hand zoom and rotation gestures or recognizing a grasping hand. We emphasize the broad applicability of the proposed method with a study of a multi-hand gesture recognition device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1401–1410},
numpages = {10},
keywords = {capacitive sensing, capacitive proximity sensing, 3d interaction, ubiquitous interfaces, object tracking, object recognition},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466187,
author = {Hachisu, Taku and Kajimoto, Hiroyuki},
title = {HACHIStack: Dual-Layer Photo Touch Sensing for Haptic and Auditory Tapping Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466187},
doi = {10.1145/2470654.2466187},
abstract = {We present a novel photo touch sensing architecture, HACHIStack. It can measure the approaching velocity of an object and predict its contact time with the touch screen using two optical sensing layers above the surface. The photo sensing layers form three unique capabilities: high-speed sampling, velocity acquisition, and contact time prediction. This work quantitatively examines these capabilities through two laboratory experiments, and confirms that the capabilities of HACHIStack are sufficient for multimodal interaction, in particular, touch-based interaction with haptic enhancement. We then present three applications with HACHIStack: 1) chromatic percussions (xylophone and glockenspiel) with haptic feedback; 2) no-delay haptic feedback with the sensation of tapping on various simulated materials (e.g., rubber, wood and aluminum); and 3) a virtual piano instrument that allows players to perform weak and strong strokes by changing the tapping velocity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1411–1420},
numpages = {10},
keywords = {approaching velocity, touch sensor, hachistack, multimodal interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466188,
author = {Gu, Jiseong and Heo, Seongkook and Han, Jaehyun and Kim, Sunjun and Lee, Geehyuk},
title = {LongPad: A Touchpad Using the Entire Area below the Keyboard of a Laptop Computer},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466188},
doi = {10.1145/2470654.2466188},
abstract = {In this paper, we explore the possibility of a long touchpad that utilizes the entire area below the keyboard of a laptop computer. An essential prerequisite for such a touchpad is a robust palm rejection method, which we satisfy using a proximity-sensing touchpad. We developed LongPad, a proximity-sensing optical touchpad that is as wide as a laptop keyboard, and implemented a palm rejection algorithm that utilizes proximity images from LongPad. In a user study conducted, we observed that LongPad rejected palm touches almost perfectly while participants were repeating typing and pointing tasks. We also summarize the new design space enabled by LongPad and demonstrate a few of the interaction techniques it facilitates.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1421–1430},
numpages = {10},
keywords = {bimanual interaction, per-finger force sensing, proximity-sensing, longpad, palm rejection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250080,
author = {Roudaut, Anne},
title = {Session Details: Papers: Displays Everywhere},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250080},
doi = {10.1145/3250080},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466190,
author = {Thimbleby, Harold},
title = {Reasons to Question Seven Segment Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466190},
doi = {10.1145/2470654.2466190},
abstract = {Seven segment number displays are ubiquitous and popular. They are simple and familiar. They seem to make economic sense, and with only seven segments they require little wiring and electronics to support. They are cheap to buy and cheap to use; they make seemingly effective and unproblematic products.This paper illustrates many examples of problematic uses of seven segment displays that could have been avoided. More generally, the paper raises design questions and some solutions to be considered when designing numerical displays, and certainly before uncritically using seven segment displays. Although there are markets and applications where cost may be an overriding consideration, for safety critical and other dependable types of use (including general purpose devices that may sometimes be used for critical tasks) more legible alternatives than standard seven segment displays should be preferred.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1431–1440},
numpages = {10},
keywords = {number display, dependable interaction, procurement, number error, seven segment display, calculators},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466191,
author = {Leithinger, Daniel and Follmer, Sean and Olwal, Alex and Luescher, Samuel and Hogge, Akimitsu and Lee, Jinha and Ishii, Hiroshi},
title = {Sublimate: State-Changing Virtual and Physical Rendering to Augment Interaction with Shape Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466191},
doi = {10.1145/2470654.2466191},
abstract = {Recent research in 3D user interfaces pushes towards immersive graphics and actuated shape displays. Our work explores the hybrid of these directions, and we introduce sublimation and deposition, as metaphors for the transitions between physical and virtual states. We discuss how digital models, handles and controls can be interacted with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can rapidly and fluidly switch between those representations. To explore this space, we developed two systems that integrate actuated shape displays and augmented reality (AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through display provides a single user with head-tracked stereoscopic augmentation, whereas our handheld devices enable multi-user interaction through video seethrough AR. We describe interaction techniques and applications that explore 3D interaction for these new modalities. We conclude by discussing the results from a user study that show how freehand interaction with physical shape displays and co-located graphics can outperform wand-based interaction with virtual 3D graphics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1441–1450},
numpages = {10},
keywords = {3d interaction, spatial augmented reality, actuated tangibles, shape display},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466192,
author = {Perrault, Simon T. and Lecolinet, Eric and Eagan, James and Guiard, Yves},
title = {Watchit: Simple Gestures and Eyes-Free Interaction for Wristwatches and Bracelets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466192},
doi = {10.1145/2470654.2466192},
abstract = {We present WatchIt, a prototype device that extends interaction beyond the watch surface to the wristband, and two interaction techniques for command selection and execution. Because the small screen of wristwatch computers suffers from visual occlusion and the fat finger problem, we investigated the use of the wristband as an available interaction resource. Not only does WatchIt use a cheap, energy efficient and invisible technology, but it involves simple, basic gestures that allow good performance after little training, as suggested by the results of a pilot study. We propose a novel gesture technique and an adaptation of an existing menu technique suitable for wristband interaction. In a user study, we investigated their usage in eyes-free contexts, finding that they perform well. Finally, we present techniques where the bracelet is used in addition to the screen to provide precise continuous control over list scrolling. We also report on a preliminary survey of traditional and digital jewelry that points to the high frequency of watches and bracelets in both genders and gives a sense of the tasks people feel like performing on such devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1451–1460},
numpages = {10},
keywords = {watch, continuous input, watchstrap, watchband, eyes-free interaction, watch bracelet, digital jewelry, scrolling, input, wearable computing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466193,
author = {Su, Chao-Huai and Chan, Liwei and Weng, Chien-Ting and Liang, Rong-Hao and Cheng, Kai-Yin and Chen, Bing-Yu},
title = {NailDisplay: Bringing an Always Available Visual Display to Fingertips},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466193},
doi = {10.1145/2470654.2466193},
abstract = {This work presents a novel and always-available nail mounted display known as NailDisplay. The proposed display augments the use of a finger by allowing for always-available visual feedback owing to its fast accessibility and binding user controls with the display, i.e. what you control is what you see (through the display). Potential benefits of NailDisplay are demonstrated in three applications: from displaying to combining it with user controls. In the first application, NailDisplay can reveal what is occluded under a finger touch, making it a solution to operate small UI elements. In the second application, NailDisplay is complementary to an imaginary interface, helping users to learn an imaginary interface (e.g., on the users' arms) and allowing them to reassure the interface when their memory of it becomes unclear. In the third application, NailDisplay is integrated with rich finger interactions, such as swiping in the air. We also report users' feedbacks gathered from an explorative user study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1461–1464},
numpages = {4},
keywords = {transparent finger, always-available display, nail-mounted device},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2466193_R49572,
author = {Goldfarb, David E.},
title = {Review ID:R49572 for DOI: 10.1145/2470654.2466193},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2466193_R49572}
}

@inproceedings{10.1145/2470654.2466194,
author = {Pohl, Norman and Hodges, Steve and Helmes, John and Villar, Nicolas and Paek, Tim},
title = {An Interactive Belt-Worn Badge with a Retractable String-Based Input Mechanism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466194},
doi = {10.1145/2470654.2466194},
abstract = {In this paper we explore a new type of wearable computing device, an interactive identity badge. An embedded LCD presents dynamic information to the wearer and interaction is facilitated by sensing movement of the retractable string which attaches the unit to the wearer's belt. This form-factor makes it possible to interact using a single hand, providing lightweight and immediate access to a variety of information when it's not convenient to pick up, unlock and interact directly with a device like a smartphone. In this paper we present our prototype interactive badge, demonstrate the underlying technology and describe a number of usage scenarios and interaction techniques},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1465–1468},
numpages = {4},
keywords = {interaction techniques, memory lcd, retractable string, smart interactive badge},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250081,
author = {Zhou, Xiaomu},
title = {Session Details: Papers: Clinical Settings},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250081},
doi = {10.1145/3250081},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466196,
author = {von Zadow, Ulrich and Buron, Sandra and Harms, Tina and Behringer, Florian and Sostmann, Kai and Dachselt, Raimund},
title = {SimMed: Combining Simulation and Interactive Tabletops for Medical Education},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466196},
doi = {10.1145/2470654.2466196},
abstract = {A large body of work asserts that interactive tabletops are well suited for group work, and numerous studies have examined these devices in educational contexts. However, few of the described systems support simulations for collaborative learning, and none of them explicitly address immersion. We present SimMed, a system allowing medical students to collaboratively diagnose and treat a virtual patient using an interactive tabletop. The hybrid user interface combines elements of virtual reality with multitouch input. The paper delineates the development process of the system and rationale behind a range of interface design decisions. Thereby, the role of realism in gaining procedural knowledge is discussed - in particular, the interplay between realism, immersion and training goals. We implemented several medical test cases and evaluated our approach with a user study that suggests the great potential of the system. Results show a high level of immersion, cooperation and engagement by the students.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1469–1478},
numpages = {10},
keywords = {learning, procedural knowledge, interactive surfaces, multitouch, education, tabletop, collaboration, medicine},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466197,
author = {Mentis, Helena M. and Taylor, Alex S.},
title = {Imaging the Body: Embodied Vision in Minimally Invasive Surgery},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466197},
doi = {10.1145/2470654.2466197},
abstract = {Recent years have seen the possibilities of new imaging and interaction technologies for minimally invasive surgery such as touchless interaction and high definition renderings of three-dimensional anatomy. With this paper we take a step back to review the historical introduction and assimilation of imaging technologies in the surgical theatre in parallel with the productive and cross-referential nature of surgical practice and image use. We present findings from a field study of image use during neurosurgery where we see that the work to see medical images is highly constructed and embodied with the action of manipulating the body. This perspective lends itself to a discussion of the directions for new imaging interaction technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1479–1488},
numpages = {10},
keywords = {vision, surgery, embodiment, movement, imaging., health},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466198,
author = {Bird, Jon and Byass, Peter and Kahn, Kathleen and Mee, Paul and Fottrell, Edward},
title = {A Matter of Life and Death: Practical and Ethical Constraints in the Development of a Mobile Verbal Autopsy Tool},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466198},
doi = {10.1145/2470654.2466198},
abstract = {Verbal autopsy (VA) involves interviewing relatives of the deceased to identify the probable cause of death and is typically used in settings where there is no official system for recording deaths or their causes. Following the interview, physician assessment to determine probable cause can take several years to complete. The World Health Organization (WHO) recognizes that there is a pressing need for a mobile device that combines direct data capture and analysis if this technique is to become part of routine health surveillance. We conducted a field test in rural South Africa to evaluate a mobile system that we designed to meet WHO requirements (namely, simplicity, feasibility, adaptability to local contexts, cost-effectiveness and program relevance). If desired, this system can provide immediate feedback to respondents about the probable cause of death at the end of a VA interview. We assessed the ethical implications of this technological development by interviewing all the stakeholders in the VA process (respondents, fieldworkers, physicians, population scientists, data managers and community engagement managers) and highlight the issues that this community needs to debate and resolve.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1489–1498},
numpages = {10},
keywords = {verbal autopsy, ethics, hci4d., mobile devices},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250082,
author = {Mandryk, Regan},
title = {Session Details: Papers: Game Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250082},
doi = {10.1145/3250082},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466200,
author = {Mirza-Babaei, Pejman and Nacke, Lennart E. and Gregory, John and Collins, Nick and Fitzpatrick, Geraldine},
title = {How Does It Play Better? Exploring User Testing and Biometric Storyboards in Games User Research},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466200},
doi = {10.1145/2470654.2466200},
abstract = {Improving game design is a hard task. Few methods are available in games user research (GUR) to test formally how game designs work for players. In particular, the usefulness of user tests (UTs) for game designers has not been fully studied in the CHI community. We propose a novel GUR method called Biometric Storyboards (BioSt) and present a study demonstrating how a Classic UT and a BioSt UT both help designers create a better gameplay experience. In addition, we show that BioSt can help designers deliver significantly better visuals, more fun, and higher gameplay quality than designing without UTs and that classic UTs do not provide this significant advantage. Our interviews support the idea that BioSt provides more nuanced game design improvement. The design implication is that a game designed with the BioSt method will result in high gameplay quality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1499–1508},
numpages = {10},
keywords = {visualization, storyboards, user experience, user testing, physiological measures, games user research, games},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466201,
author = {Khaled, Rilla and Nelson, Mark J. and Barr, Pippin},
title = {Design Metaphors for Procedural Content Generation in Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466201},
doi = {10.1145/2470654.2466201},
abstract = {Procedural content generation (PCG), the algorithmic creation of game content with limited or indirect user input, has much to offer to game design. In recent years, it has become a mainstay of game AI, with significant research being put towards the investigation of new PCG systems, algorithms, and techniques. But for PCG to be absorbed into the practice of game design, it must be contextualised within design-centric as opposed to AI or engineering perspectives. We therefore provide a set of design metaphors for understanding potential relationships between a designer and PCG. These metaphors are: tool, material, designer, and domain expert. By examining PCG through these metaphors, we gain the ability to articulate qualities, consequences, affordances, and limitations of existing PCG approaches in relation to design. These metaphors are intended both to aid designers in understanding and appropriating PCG for their own contexts, and to advance PCG research by highlighting the assumptions implicit in existing systems and discourse.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1509–1518},
numpages = {10},
keywords = {metaphor, game ai, procedural content generation, adaptive games, game design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466202,
author = {Bowser, Anne E. and Hansen, Derek L. and Raphael, Jocelyn and Reid, Matthew and Gamett, Ryan J. and He, Yurong R. and Rotman, Dana and Preece, Jenny J.},
title = {Prototyping in PLACE: A Scalable Approach to Developing Location-Based Apps and Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466202},
doi = {10.1145/2470654.2466202},
abstract = {The rising popularity of location-based applications and games (LBAGs) that break spatial, temporal, and social boundaries creates new challenges for designers. This paper introduces PLACE, an iterative, mixed-fidelity approach to Prototyping Location, Activities, Collective experience, and Experience over time in LBAGs. PLACE consists of 6 design principles: start small and scale up the fidelity, treat participants as co-designers, test in a representative space, focus on activities more than interfaces, respect authentic social experience, and represent time authentically. The effectiveness of PLACE was evaluated by prototyping Floracaching, a geocaching game for citizen science. This revealed the types of insights that PLACE provides, best practices for implementing PLACE, and how PLACE com-pares to other prototyping methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1519–1528},
numpages = {10},
keywords = {co-design, place, mobile apps, mixed-fidelity prototype, location-based games, location},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466203,
author = {Hansen, Derek and Bonsignore, Elizabeth and Ruppel, Marc and Visconti, Amanda and Kraus, Kari},
title = {Designing Reusable Alternate Reality Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466203},
doi = {10.1145/2470654.2466203},
abstract = {Successful Alternate Reality Games (ARGs), such as The Lost Experience, I Love Bees and Urgent EVOKE have solicited thousands of active participants and, often, millions of spectators from around the world. ARGs require significant resources not only in terms of initial design, but also in implementation, since live, dynamic interplay between players and designers is an inherent aspect of their interactive storylines. This paper outlines a novel design framework for creating reusable ARGs that will help extend the lifespan of ARGs and allow them to permeate new domains such as education. The framework includes three key reusable design objectives (replayability, adaptability, extensibility), each of which can be enacted at different levels of depth. We also identify barriers to reusable ARGs and design strategies for overcoming those barriers, drawing upon ARG designer interviews and existing ARGs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1529–1538},
numpages = {10},
keywords = {serious games, alternate reality games, reusable, extensible, adaptable, replayable, design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250083,
author = {Schmidt, Albrecht},
title = {Session Details: Papers: Design for the Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250083},
doi = {10.1145/3250083},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466205,
author = {Ogonowski, Corinna and Ley, Benedikt and Hess, Jan and Wan, Lin and Wulf, Volker},
title = {Designing for the Living Room: Long-Term User Involvement in a Living Lab},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466205},
doi = {10.1145/2470654.2466205},
abstract = {Living Labs provide a research infrastructure for long-term user involvement in Participatory Design processes. Users take part in software co-creation during context analysis, for concept development, reflecting on early-stage prototypes and evaluations in the field. In this paper we describe lessons learned from our Living Lab in the area of home entertainment, with 27 participants from 16 households, over a 2.5 year period. We show that this kind of long-term participation of users involves various challenges over the lifetime of the project. We highlight several aspects that need to be considered carefully when setting up such a Living Lab, concerning the selection of participants, maintenance of participants' motivation, establishment of a trust relationship, and the coordination of collaboration.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1539–1548},
numpages = {10},
keywords = {domestic domain, long-term user study, living lab, participatory design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466206,
author = {Taylor, Nick and Cheverst, Keith and Wright, Peter and Olivier, Patrick},
title = {Leaving the Wild: Lessons from Community Technology Handovers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466206},
doi = {10.1145/2470654.2466206},
abstract = {As research increasingly turns to work 'in the wild' to design and evaluate technologies under real-world conditions, little consideration has been given to what happens when research ends. In many cases, users are heavily involved in the design process and encouraged to integrate the resulting technologies into their lives before they are withdrawn, while in some cases technologies are being left in place after research concludes. Often, little is done to assess the impact and legacy of these deployments. In this paper, we return to two examples in which we designed technologies with the involvement of communities and examine what steps were taken to ensure their long-term viability and what happened following the departure of researchers. From these examples, we provide guidelines for planning and executing technology handovers when conducting research with communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1549–1558},
numpages = {10},
keywords = {action research, longitudinal, community, research in the wild},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466207,
author = {Chong, Ming Ki and Gellersen, Hans W.},
title = {How Groups of Users Associate Wireless Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466207},
doi = {10.1145/2470654.2466207},
abstract = {Group association, the process of connecting a group of devices, opens up new opportunities for users to spontaneously share resources. Research has shown numerous techniques and protocols for group association; however, what people intuitively do to associate a group of devices remains an open question. We contribute a study of eliciting device association techniques from groups of non-technical people. In all, we collected and analysed 496 techniques from 61 participants. Our results show that mobility and physicality of devices influence how people perceive groups association. We present a complete set of user-defined techniques with subjective ratings and popularity scores. We examined people's rationale and the effects of different device form factors. We analysed the techniques based on the roles that users assume with respect to device association. Our findings draw out insights from the perspective of users for design of group association.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1559–1568},
numpages = {10},
keywords = {group, guessability study, pairing, device association, wireless, input techniques, spontaneous interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466208,
author = {Brown, Anthony and Mortier, Richard and Rodden, Tom},
title = {MultiNet: Reducing Interaction Overhead in Domestic Wireless Networks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466208},
doi = {10.1145/2470654.2466208},
abstract = {We present MultiNet, a novel method for securely associating devices with a domestic wireless network. We show that MultiNet has usability benefits over currently deployed commercial solutions while being backwards compatible with existing devices. MultiNet reduces the interaction overhead of secure association by focusing on users' interactions rather than the network's requirements. This leads to a novel architectural arrangement of the home network infrastructure: the network is dynamically re-configured to accept each pre-configured device, rather than the current norm where each device is configured to be acceptable to the pre-configured network. Assuming devices are pre-configured for a unique, device-specific network name and passphrase, MultiNet constructs an out-of-band visual channel via an intermediary network controller device to convey the device's configuration to the network. This makes the interaction to join a device to the wireless network lightweight and identical across all devices, considerably reducing the interaction overheads for users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1569–1578},
numpages = {10},
keywords = {domestic environments, 802.11, usable security},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250084,
author = {Burnett, Margaret},
title = {Session Details: Papers: Novel Programming},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250084},
doi = {10.1145/3250084},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466210,
author = {Prior, Suzanne and Waller, Annalu and Black, Rolf and Kroll, Thilo},
title = {Use of an Agile Bridge in the Development of Assistive Technology},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466210},
doi = {10.1145/2470654.2466210},
abstract = {Engaging with end users in the development of assistive technologies remains one of the major challenges for researchers and developers in the field of accessibility and HCI. Developing usable software systems for people with complex disabilities is problematic, software developers are wary of using user-centred design, one of the main methods by which usability can be improved, due to concerns about how best to work with adults with complex disabilities, in particular Severe Speech and Physical Impairments (SSPI) and how to involve them in research. This paper reports on how the adoption of an adapted agile approach involving the incorporation of a user advocate on the research team helped in meeting this challenge in one software project and offers suggestions for how this could be used by other development teams.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1579–1588},
numpages = {10},
keywords = {user centred design, agile methodology, severe speech and physical impairments, assistive technology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466211,
author = {Jacobs, Jennifer and Buechley, Leah},
title = {Codeable Objects: Computational Design and Digital Fabrication for Novice Programmers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466211},
doi = {10.1145/2470654.2466211},
abstract = {The combination of computational design and digital fabrication offers many exciting possibilities for art, design, and creative expression. We seek to make computational design accessible by developing tools that allow novices to use programming and digital fabrication to produce personal and functional objects. In this paper, we describe our development of Codeable Objects, a preliminary computational-design programing tool developed to work in conjunction with digital-fabrication machines. We also present our evaluation of the tool based on a set of user studies in which people built computationally generated crafts, clothing, and accessories. These studies illuminated the viability (and challenges) of engaging novice programmers through design and digital fabrication, and provide a platform for future work in developing programming tools to support personal expression.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1589–1598},
numpages = {10},
keywords = {software, art and craft, accessibility, computational design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466212,
author = {Yang, Huahai and Pupons-Wickham, Daina and Chiticariu, Laura and Li, Yunyao and Nguyen, Benjamin and Carreno-Fuentes, Arnaldo},
title = {I Can Do Text Analytics! Designing Development Tools for Novice Developers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466212},
doi = {10.1145/2470654.2466212},
abstract = {Text analytics, an increasingly important application domain, is hampered by the high barrier to entry due to the many conceptual difficulties novice developers encounter. This work addresses the problem by developing a tool to guide novice developers to adopt the best practices employed by expert developers in text analytics and to quickly harness the full power of the underlying system. Taking a user centered task analytical approach, the tool development went through multiple design iterations and evaluation cycles. In the latest evaluation, we found that our tool enables novice developers to develop high quality extractors on par with the state of art within a few hours and with minimal training. Finally, we discuss our experience and lessons learned in the context of designing user interfaces to reduce the barriers to entry into complex domains of expertise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1599–1608},
numpages = {10},
keywords = {best practices, information extraction, text analytics, extraction plan, novice developer, workflow guide},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466213,
author = {Kuttal, Sandeep Kaur and Sarma, Anita and Rothermel, Gregg},
title = {Debugging Support for End User Mashup Programming},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466213},
doi = {10.1145/2470654.2466213},
abstract = {Programming for the web can be an intimidating task, particularly for non-professional ("end-user") programmers. Mashup programming environments attempt to remedy this by providing support for such programming. It is well known, however, that mashup programmers create applications that contain bugs. Furthermore, mashup programmers learn from examples and reuse other mashups, which causes bugs to propagate to other mashups. In this paper we classify the bugs that occur in a large corpus of Yahoo! Pipes mashups. We describe support we have implemented in the Yahoo! Pipes environment to provide automatic error detection techniques that help mashup programmers localize and correct these bugs. We present the results of a think-aloud study comparing the experiences of end-user mashup programmers using and not using our support. Our results show that our debugging enhancements do help these programmers localize and correct bugs more effectively and efficiently.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1609–1618},
numpages = {10},
keywords = {end-user software engineering, debugging, end-user programming, yahoo! pipes, programming barriers, mashups},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250085,
author = {Blandford, Ann},
title = {Session Details: Papers: Temporal Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250085},
doi = {10.1145/3250085},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466215,
author = {Thiry, Elizabeth and Lindley, Si\^{a}n and Banks, Richard and Regan, Tim},
title = {Authoring Personal Histories: Exploring the Timeline as a Framework for Meaning Making},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466215},
doi = {10.1145/2470654.2466215},
abstract = {It has been argued that technologies for 'memory' should be designed to support creativity and meaning building, rather than the passive capture of cues for remembering [25]. We report findings from a study inspired by this insight, in which older people made personal digital timelines using a new tool called Project Greenwich. We explore how the constraints of the timeline metaphor offer a framework for authoring, and examine how timelines can be used to underpin meaning building in relation to personal content. We highlight the importance of making, this being a vehicle for connecting with others in the present, and a potential means of emphasizing those elements of the past felt to be most salient when looking back.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1619–1628},
numpages = {10},
keywords = {recipient design, storytelling, craft, legacy, authorship, project greenwich, older adults, making, memory},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466216,
author = {Mankoff, Jennifer and Rode, Jennifer A. and Faste, Haakon},
title = {Looking Past Yesterday's Tomorrow: Using Futures Studies Methods to Extend the Research Horizon},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466216},
doi = {10.1145/2470654.2466216},
abstract = {Doing research is, in part, an act of foresight. Even though it is not explicit in many projects, we especially value research that is still relevant five, ten or more years after it is completed. However, published research in the field of interactive computing (and technology research in general) often lacks evidence of systematic thinking about the long-term impacts of current trends. For example, trends on an exponential curve change much more rapidly than intuition predicts. As a result, research may accidentally emphasize near-term thinking. When thinking about the future is approached systematically, we can critically examine multiple potential futures, expand the set of externalities under consideration, and address both negative and positive forecasts of the future. The field of Futures Studies provides methods that can support analysis of long-term trends, support the identification of new research areas and guide design and evaluation. We survey methods for futuristic thinking and discuss their relationship to Human Computer Interaction. Using the sustainability domain an example, we present a case study of a Futures Studies approach - the Delphi Method. We show how Futures Studies can be incorporated into Human Computer Interaction and highlight future work such as rethinking the role of externalities in the validation process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1629–1638},
numpages = {10},
keywords = {sustainability, futures studies},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466217,
author = {Lundgren, Sus},
title = {Toying with Time: Considering Temporal Themes in Interactive Artifacts},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466217},
doi = {10.1145/2470654.2466217},
abstract = {This paper argues that there is a value in deliberately and systematically exploring potential temporal behaviors of an interactive artifact, either as a means to add new functions, or to change the interaction with it. An improved version of Temporal Themes [23] - a vocabulary describing how software can "use" time or sequences of events - will be presented, alongside a series of design cases. These exemplify how adding or changing temporal themes in existing applications can enhance functionality and/or interaction. Moreover, the cases also serve as a basis for a discussion of the issues coupled to temporality, control and interaction strategies. Finally, a design approach with focus on temporal aspects is outlined. As a result, the paper opens up for a more conscious use of time and temporality in interaction design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1639–1648},
numpages = {10},
keywords = {interaction design, temporality, temporal themes, time, design method},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466218,
author = {Rosner, Daniela K. and Ikemiya, Miwa and Kim, Diana and Koch, Kristin},
title = {Designing with Traces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466218},
doi = {10.1145/2470654.2466218},
abstract = {This paper draws on new materialist perspectives to introduce the analytic category of "material traces" to the field of human-computer interaction (HCI). Material traces reveal the dynamic and evocative nature of form by concretizing a unique location in time and space. Traces of skill, use, and time, for example, are valued for their emotional resonance in addition to the pragmatic goals in which they are embedded. Using this category, we develop a framework for design pedagogy that offers the lenses of attributes, entanglements, and trajectories as tools for gaining critical purchase on the objects produced. Mobilizing this framework within a classroom, design students envision poignant relationships to the non-human, engaged physics learning, and opportunities for reflection around breakage and repair. These design examples reveal how the category of material traces comes alive in practice and pedagogy. We end by discussing how this study of traces points to new opportunities for critical reflection in HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1649–1658},
numpages = {10},
keywords = {design theory, temporality, archeology, design pedagogy, prove-nance, critical making, traces, materiality, craft},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250086,
author = {McGee-Lennon, Marilyn},
title = {Session Details: Papers: Tactile Experiences},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250086},
doi = {10.1145/3250086},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466220,
author = {Obrist, Marianna and Seah, Sue Ann and Subramanian, Sriram},
title = {Talking about Tactile Experiences},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466220},
doi = {10.1145/2470654.2466220},
abstract = {A common problem with designing and developing applications with tactile interfaces is the lack of a vocabulary that allows one to describe or communicate about haptics. Here we present the findings from a study exploring participants' verbalizations of their tactile experiences across two modulated tactile stimuli (16Hz and 250Hz) related to two important mechanoreceptors in the human hand. The study, with 14 participants, applied the explicitation interview technique to capture detailed descriptions of the diachronic and synchronic structure of tactile experiences. We propose 14 categories for a human-experiential vocabulary based on the categorization of the findings and tie them back to neurophysiological and psychophysical data on the human hand. We finally discuss design opportunities created through this experiential understanding in relation to the two mechanoreceptors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1659–1668},
numpages = {10},
keywords = {human hand, mechanoreceptors, tactile experiences, explicitation interview technique, user study, human-experiential vocabulary, non-contact haptic system, ultrasound},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466221,
author = {Atkinson, Douglas and Orzechowski, Pawel and Petreca, Bruna and Bianchi-Berthouze, Nadia and Watkins, Penelope and Baurley, Sharon and Padilla, Stefano and Chantler, Mike},
title = {Tactile Perceptions of Digital Textiles: A Design Research Approach},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466221},
doi = {10.1145/2470654.2466221},
abstract = {Current interactive media presentations of textiles provide an impoverished communication of their 'textile hand', that is their weight, drape, how they feel to touch. These are complex properties experienced through the visual, tactile, auditory and proprioceptive senses and are currently lost when textile materials are presented in interactive video. This paper offers a new perspective from which the production of multi-touch interactive video representations of the tactile qualities of materials is considered. Through an understanding of hand properties of textiles and how people inherently touch and handle them, we are able to develop methods to animate and bring these properties alive using design methods. Observational studies were conducted, noting gestures consumers used to evaluate textile hand. Replicating the appropriate textile deformations for these gestures in interactive video was explored as a design problem. The resulting digital textile swatches and their interactive behavior were then evaluated for their ability to communicate tactile qualities similar to those of the real textiles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1669–1678},
numpages = {10},
keywords = {visualisation, multimodal interfaces, design methods, methodology, user interactions, design research},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466222,
author = {Park, Young-Woo and Baek, Kyoung-Min and Nam, Tek-Jin},
title = {The Roles of Touch during Phone Conversations: Long-Distance Couples' Use of POKE in Their Homes},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466222},
doi = {10.1145/2470654.2466222},
abstract = {We report the roles of touch during phone conversations by observing long-distance couples' one month use of POKE in their homes. POKE enables users to deliver touches through an inflatable surface on the front of the device that receives index finger pressure inputs on the back of another device, while allowing the callers to maintain a conventional phone-calling posture. After a month of use by three couples, we found unexpected roles of touch in that it supported the couples in developing and sharing their tactile vocabularies by applying POKE during various conversational situations. Moreover, the findings confirmed the roles that touch play in face-to-face communication. In particular, POKE was useful for expressing and understanding emotions, resolving conversations smoothly by replacing the words, feeling close to the partner at a distance, and concentrating on the phone conversations. We conclude by discussing the unused situations, privacy issues, and usable targets to improve POKE as a way of future tactile phone conversations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1679–1688},
numpages = {10},
keywords = {tactile vocabulary, role of touch, tactile phone call, field trial},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466223,
author = {Tam, Diane and MacLean, Karon E. and McGrenere, Joanna and Kuchenbecker, Katherine J.},
title = {The Design and Field Observation of a Haptic Notification System for Timing Awareness during Oral Presentations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466223},
doi = {10.1145/2470654.2466223},
abstract = {To moderate oral presentations a chair must manage time, and communicate time parameters to speakers through a variety of means. But speakers often miss time cues, chairs cannot confirm their receipt, and the broken dialogue can be a sideshow for the audience. We developed HaNS, a wireless wrist-worn chair-speaker Haptic Notification System that delivers tactile cues for time-managing oral presentations, and performed field observations at university research seminars and two mid-sized academic conferences (input from 66 speakers, 21 chairs, and 65 audience members). Results indicate that HaNS can improve a user's awareness of time, facilitate chair-speaker coordination, and reduce distraction of speaker and audience through its private communication channel. Eliminating overruns will require improvement in speaker 'internal' control, which our results suggest HaNS can also support given practice. We conclude with design guidelines for both conference-deployed and personal timing tools, using touch or another notification modality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1689–1698},
numpages = {10},
keywords = {vibrotactile, wearable haptics, field study, oral presentation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250087,
author = {Gellersen, Hans},
title = {Session Details: Papers: Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250087},
doi = {10.1145/3250087},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466225,
author = {Kukka, Hannu and Oja, Heidi and Kostakos, Vassilis and Gon\c{c}alves, Jorge and Ojala, Timo},
title = {What Makes You Click: Exploring Visual Signals to Entice Interaction on Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466225},
doi = {10.1145/2470654.2466225},
abstract = {Most studies take for granted the critical first steps that prelude interaction with a public display: awareness of the interactive affordances of the display, and enticement to interact. In this paper we investigate mechanisms for enticing interaction on public displays, and study the effectiveness of visual signals in overcoming the 'first click' problem. We combined 3 atomic visual elements (color/greyscale, animation/static, and icon/text) to form 8 visual signals that were deployed on 8 interactive public displays on a university campus for 8 days. Our findings show that text is more effective in enticing interaction than icons, color more than greyscale, and static signals are more effective than animated. Further, we identify gender differences in the effectiveness of these signals. Finally, we identify a behavior termed "display avoidance" that people exhibit with interactive public displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1699–1708},
numpages = {10},
keywords = {visual signals, attracting attention, public displays, interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466226,
author = {Alt, Florian and Shirazi, Alireza Sahami and Kubitza, Thomas and Schmidt, Albrecht},
title = {Interaction Techniques for Creating and Exchanging Content with Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466226},
doi = {10.1145/2470654.2466226},
abstract = {Falling hardware prices and ever more displays being connected to the Internet will lead to large public display networks, potentially forming a novel communication medium. We envision that such networks are not restricted to display owners and advertisers anymore, but allow also passersby (e.g., customers) to exchange content, similar to traditional public notice areas, such as bulletin boards. In this context it is crucial to understand emerging practices and provide easy and straight forward interaction techniques to be used for creating and exchanging content. In this paper, we present Digifieds, a digital public notice area we built to investigate and compare possible interaction techniques. Based on a lab study we show that using direct touch at the display as well as using the mobile phone as a complementing interaction technology are most suitable. Direct touch at the display closely resembles the interaction known from classic bulletin boards and provides the highest usability. Mobile phones preserve the users' privacy as they exchange (sensitive) data with the display and at the same time allow content to be created on-the-go or to be retrieved.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1709–1718},
numpages = {10},
keywords = {public displays, classified ads, digifieds, interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466227,
author = {Schmidt, Constantin and M\"{u}ller, J\"{o}rg and Bailly, Gilles},
title = {Screenfinity: Extending the Perception Area of Content on Very Large Public Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466227},
doi = {10.1145/2470654.2466227},
abstract = {We propose and validate a model of the perception area of content on public displays in order to predict from where users can read. From this model, we derive Screenfinity, a technique to rotate, translate, and zoom content in order to enable reading while passing by very large displays. Screenfinity is comfortable to read when close, supports different content for different users, does not waste screen real estate and allows expert passers-by to read content while walking. A laboratory study shows that expert users are able to perceive content when it moves. A field study evaluates the effect of Screenfinity on novice users in an ecologically valid setting. We find 1) first time users can read content without slowing down or stopping; 2) Passers-by stopping did so to explore the technology. Users explore the interaction, the limits of the system, manipulate the technology, and look behind the screen.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1719–1728},
numpages = {10},
keywords = {visual acuity, perception area, large public displays},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466228,
author = {Beyer, Gilbert and K\"{o}ttner, Florian and Schiewe, Manuel and Haulsen, Ivo and Butz, Andreas},
title = {Squaring the Circle: How Framing Influences User Behavior around a Seamless Cylindrical Display},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466228},
doi = {10.1145/2470654.2466228},
abstract = {Recent research has presented large public displays in novel non-flat shapes such as spheres, curved planes and cylinders, and looked at the influence of the form factor on user behavior. Yet, the basic shape cannot be considered in isolation when interpreting the behavior of passers-by around such displays. In this paper we investigate two further display factors, framedness and seamlessness, that have to be considered in conjunction with the form factor to understand user behavior in front of large non-flat displays. We present the findings from a field study with an interactive column display and take a closer look at how these factors influence actor and bystander behavior. Our results show that rectangular frames act as a sort of funnel for user position and can easily override effects of the non-flat shape on user position and interaction, even though the users didn't recall the presence of these frames.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1729–1738},
numpages = {10},
keywords = {non-flat displays, seamless, public displays, framing, form factor, audience behavior},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250088,
author = {Chen, Yunan},
title = {Session Details: Papers: Communicating Health},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250088},
doi = {10.1145/3250088},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466230,
author = {Sun, Si and Zhou, Xiaomu and Denny, Joshua C. and Rosenbloom, Trent S. and Xu, Hua},
title = {Messaging to Your Doctors: Understanding Patient-Provider Communications via a Portal System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466230},
doi = {10.1145/2470654.2466230},
abstract = {The patient portal is a relatively new healthcare information technology that enables patients more convenient access to their healthcare information and allows them to send messages to their doctors. Our study examines the themes discussed in these messages and the different ways in which patients communicate with their providers via a portal employed in a large medical center. We also explore the differences between the patient portal and more traditional communication media, and investigated the advantages and potential problems of the portal system. Our findings show a wide variety of topics discussed in the communication messages (such as medication, appointments, laboratory tests, etc.) and how patients provide information, consult with their providers, and express psychosocial and emotional needs. We argue that the patient portal improves the accuracy of communication and could facilitate illness management for patients, especially over a longer term. However, messaging through the patient portal is not popular among patients and the simultaneous use of multiple communication media may create information gaps. More research is needed to better elucidate barriers to the use of patient portals and the optimal methods of communication and information integration given different contexts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1739–1748},
numpages = {10},
keywords = {patient-provider communication, health information system, emr, patient portal, computer mediated communication},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466231,
author = {Curmi, Franco and Ferrario, Maria Angela and Southern, Jen and Whittle, Jon},
title = {HeartLink: Open Broadcast of Live Biometric Data to Social Networks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466231},
doi = {10.1145/2470654.2466231},
abstract = {A number of studies in the literature have looked into the use of real-time biometric data to improve one's own physiological performance and wellbeing. However, there is limited research that looks into the effects that sharing biometric data with others could have on one's social network. Following a period of research on existing mobile applications and prototype testing, we developed a system, HeartLink, which collects real-time personal biometric data such as heart rate and broadcasts this data online. Insights gained on designing systems to broadcast real-time biometric data are presented. In this paper we also report emerging results from testing HeartLink in a pilot study and a user study that were conducted during sport events. The results showed that sharing heart rate data does influence the relationship of the persons involved and that the degree of influence seems related to the tie strength prior to visualizing the data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1749–1758},
numpages = {10},
keywords = {mobile computing, data broadcast, biometric data, social networks, digital economy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466232,
author = {Pang, Carolyn E. and Neustaedter, Carman and Riecke, Bernhard E. and Oduor, Erick and Hillman, Serena},
title = {Technology Preferences and Routines for Sharing Health Information during the Treatment of a Chronic Illness},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466232},
doi = {10.1145/2470654.2466232},
abstract = {When a patient has a chronic illness, such as heart disease or cancer, it can be challenging for distributed family members to stay aware of the patient's health status. A variety of technologies are available to support health information sharing (e.g., phone, video chat, social media), yet we still do not have a detailed understanding of which technologies are preferred and what challenges people still face when sharing information with them. To explore this, we conducted a mixed-method study-involving a survey and in-depth interviews--with people about their health information sharing routines and preferences for different technologies. Regardless of physical distance between distributed family members, synchronous methods of communication afforded the opportunity to provide affective support while asynchronous methods of communication were deemed to be the least intrusive. With family members adopting certain roles during the treatment of chronic illnesses, our findings suggest the need to design tools that mediate sharing health information across distance and age gaps, with consideration to respecting patient privacy while sharing health information.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1759–1768},
numpages = {10},
keywords = {social support, health informatics, families, communication},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466233,
author = {Yun, Tae-Jung and Arriaga, Rosa I.},
title = {A Text Message a Day Keeps the Pulmonologist Away},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466233},
doi = {10.1145/2470654.2466233},
abstract = {The goal of this study was to extend and replicate an SMS health intervention for pediatric asthma patients. This intervention was designed using the Health Belief Model (HBM). Thirty patients were randomly assigned to one of three conditions. In the Knowledge condition patients were queried about their asthma knowledge every other day. In the Knowledge and Symptoms condition patients received a daily text message. They were queried about their symptoms and knowledge of asthma on alternate days. The Control group received no texts. Our main finding is that daily text messages lead to improved health outcomes.We explain our results in the context of interview data and the HBM. We conclude by suggesting that the HBM can be used to inform and evaluate system design for chronic care beyond asthma and by considering the role that replication studies can play in HCI research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1769–1778},
numpages = {10},
keywords = {asthma, sms, replichi, text message, rct},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250089,
author = {Ren, Xiangshi},
title = {Session Details: Papers: Reading and Writing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250089},
doi = {10.1145/3250089},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466235,
author = {Lafreniere, Benjamin and Grossman, Tovi and Fitzmaurice, George},
title = {Community Enhanced Tutorials: Improving Tutorials with Multiple Demonstrations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466235},
doi = {10.1145/2470654.2466235},
abstract = {Web-based tutorials are a popular help resource for learning how to perform unfamiliar tasks in complex software. However, in their current form, web tutorials are isolated from the applications that they support. In this paper we present FollowUs, a web-tutorial system that integrates a fully-featured application into a web-based tutorial. This novel architecture enables community enhanced tutorials, which continuously improve as more users work with them. FollowUs captures video demonstrations of users as they perform a tutorial. Subsequent users can use the original tutorial, or choose from a library of captured community demonstrations of each tutorial step. We conducted a user study to test the benefits of making multiple demonstrations available to users, and found that users perform significantly better using our system with a library of multiple demonstrations in comparison to its equivalent baseline system with only the original authored content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1779–1788},
numpages = {10},
keywords = {community, learning, help, tutorials},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466236,
author = {Leitner, Jakob F. and Perteneder, Florian and Liu, Can and Rendl, Christian and Haller, Michael},
title = {Kolibri: Tiny and Fast Gestures for Large Pen-Based Surfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466236},
doi = {10.1145/2470654.2466236},
abstract = {Triggering commands on large interactive surfaces is less efficient than on desktop PCs. It requires either large physical movements to reach an interaction area (e.g., buttons) or additional operations to call context menus (e.g., dwell). There is a lack of efficient ways to trigger shortcuts. We introduce Kolibri - a pen-based gesture system that allows fast access of commands on interactive whiteboards. Users can draw tiny gestures (approx. 3 mm) anywhere on the surface to trigger commands without interfering with normal inking. This approach does neither require entering a gesture mode, nor dedicated gesture areas. The implementation relies on off-the-shelf hardware only. We tested the feasibility and explored the properties of this technique with several studies. The results from a controlled experiment show significant benefits of Kolibri comparing to an existing approach.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1789–1798},
numpages = {10},
keywords = {pen-input, large interactive interfaces, small gestures, fluid inking, whiteboard application, shortcuts},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466237,
author = {Chen, Nicholas and Guimbreti\`{e}re, Fran\c{c}ois and Sellen, Abigail},
title = {Graduate Student Use of a Multi-Slate Reading System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466237},
doi = {10.1145/2470654.2466237},
abstract = {In laboratory studies, multi-surface slate-based reading systems have shown great promise as platforms for active reading. However, the true utility of such a system can only be ascertained through the rigors of real world use. We conducted month-long deployments of a multi-slate reading system to support the active reading activities of graduate students in the humanities. During these deployments we documented how the added display area and increased micro-mobility of multiple devices enhanced navigation and reading comfort. We also noted the essential role of writing and annotation. Finally, we observed how electronic affordances like synchronization across devices helped provide functionality that would not have been possible with paper documents. This paper contributes new information about how electronic reading solutions fit into real world reading workflows.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1799–1808},
numpages = {10},
keywords = {e-reading, academia, multi-screen computing, reading, deployment, multi-slate, tablet, e-book, graduate students},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466238,
author = {Wilfinger, David and Murer, Martin and Osswald, Sebastian and Meschtscherjakov, Alexander and Tscheligi, Manfred},
title = {The Wheels Are Turning: Content Rotation on Steering Wheel Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466238},
doi = {10.1145/2470654.2466238},
abstract = {The steering wheel is a promising space for the integration of displays since in the car there is very limited space for integrating interactive modalities for the driver that are close to the preferred field of view as well as in an easy to reach position. When the wheel is turned, the screen content could change its orientation to increase the readability and therefore reduce the distraction from the road. Thus, this paper describes three different content rotation behaviors for steering wheel displays. To investigate what effect these behaviors have on the driver in terms of visual distraction from the road we conducted a user study with eye tracking asking participants to read the current speed. We found no differences in terms of distraction and response time between the different rotation behaviors. Compared to a similar display in a dashboard position the visual distraction was reduced.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1809–1812},
numpages = {4},
keywords = {display, distraction, steering wheel, rotation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250090,
author = {Lindley, Si\^{a}n},
title = {Session Details: Papers: Studying Digital Artifacts},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250090},
doi = {10.1145/3250090},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466240,
author = {Gulotta, Rebecca and Odom, William and Forlizzi, Jodi and Faste, Haakon},
title = {Digital Artifacts as Legacy: Exploring the Lifespan and Value of Digital Data},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466240},
doi = {10.1145/2470654.2466240},
abstract = {Legacy is the meaningful and complex way in which information, values, and possessions are passed on to others. As digital systems and information become meaningfully parts of people's everyday and social relationships, it is essential to develop new insights about how technology intersects with legacy and inheritance practices. We designed three interactive systems to investigate how digital materials might be passed down in the future. We conducted in-home interviews with ten parents using the systems to provoke discussion about how technology might support or complicate their existing practices. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. Findings are interpreted to describe design considerations for future work in this emerging space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1813–1822},
numpages = {10},
keywords = {legacy, speculative design, digital artifacts, design, inheritance, interviews, technology probes, reflective design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466241,
author = {Sas, Corina and Whittaker, Steve},
title = {Design for Forgetting: Disposing of Digital Possessions after a Breakup},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466241},
doi = {10.1145/2470654.2466241},
abstract = {People are increasingly acquiring huge collections of digital possessions. Despite some pleas for 'forgetting', most theorists argue for retaining all these possessions to enhance 'total recall' of our everyday lives. However, there has been little exploration of the negative role of digital possessions when people want to forget aspects of their lives. We report on interviews with 24 people about their possessions after a romantic breakup. We found that digital possessions were often evocative and upsetting in this context, leading to distinct disposal strategies with different outcomes. We advance theory by finding strong evidence for the value of intentional forgetting and provide new data about complex practices associated with the disposal of digital possessions. Our findings led to a number of design implications to help people better manage this process, including automatic harvesting of digital possessions, tools for self-control, artifact crafting as sense-making, and digital spaces for shared possessions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1823–1832},
numpages = {10},
keywords = {digital possessions, sense of self, disposal, autobiographical memories, intentional forgetting, relationship dissolution},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466242,
author = {Odom, William and Zimmerman, John and Forlizzi, Jodi and L\'{o}pez Higuera, Ana and Marchitto, Mauro and Ca\~{n}as, Jos\'{e} and Lim, Youn-kyung and Nam, Tek-Jin and Lee, Moon-Hwan and Lee, Yeoreum and Kim, Da-jung and Row, Yea-kyung and Seok, Jinmin and Sohn, Bokyung and Moore, Heather},
title = {Fragmentation and Transition: Understanding Perceptions of Virtual Possessions among Young Adults in Spain, South Korea and the United States},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466242},
doi = {10.1145/2470654.2466242},
abstract = {People worldwide are increasingly acquiring collections of virtual possessions. While virtual possessions have become ubiquitous, little work exists on how people value and form attachments to these things. To investigate, we conducted a study with 48 young adults from South Korea, Spain and the United States. The study probed on participants' perceived value of their virtual possessions as compared to their material things, and the comparative similarities and differences across cultures. Findings show that young adults live in unfinished spaces and that they often experience a sense of fragmentation when trying to integrate their virtual possessions into their lives. These findings point to several design opportunities, such as tools for life story-oriented archiving, and insights on better forms of Cloud storage.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1833–1842},
numpages = {10},
keywords = {young adults, interactive systems design, digital things, virtual possessions, human-centered architectures},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466243,
author = {Weilenmann, Alexandra and Hillman, Thomas and Jungselius, Beata},
title = {Instagram at the Museum: Communicating the Museum Experience through Social Photo Sharing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466243},
doi = {10.1145/2470654.2466243},
abstract = {The everyday use of smartphones with high quality built-in cameras has lead to an increase in museum visitors' use of these devices to document and share their museum experiences. In this paper, we investigate how one particular photo sharing application, Instagram, is used to communicate visitors' experiences while visiting a museum of natural history. Based on an analysis of 222 instagrams created in the museum, as well as 14 interviews with the visitors who created them, we unpack the compositional resources and concerns contributing to the creation of instagrams in this particular context. By re-categorizing and re-configuring the museum environment, instagrammers work to construct their own narratives from their visits. These findings are then used to discuss what emerging multimedia practices imply for the visitors' engagement with and documentation of museum exhibits. Drawing upon these practices, we discuss the connection between online social media dialogue and the museum site.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1843–1852},
numpages = {10},
keywords = {photography, smartphones., camera phones, instagram, museum studies, social media, museum of natural history},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250091,
author = {Massimi, Michael},
title = {Session Details: Papers: Ethics in HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250091},
doi = {10.1145/3250091},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466245,
author = {McMillan, Donald and Morrison, Alistair and Chalmers, Matthew},
title = {Categorised Ethical Guidelines for Large Scale Mobile HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466245},
doi = {10.1145/2470654.2466245},
abstract = {The recent rise in large scale trials of mobile software using 'app stores' has moved current researcher practice beyond available ethical guidelines. By surveying this recent and growing body of literature, as well as established professional principles adopted in psychology, we propose a set of ethical guidelines for large scale HCI user trials. These guidelines come in two parts: a set of general principles and a framework into which individual app store-based trials can be assessed and ethical concerns exposed. We categorise existing literature using our scheme, and explain how researchers could use our framework to classify their future user trials to determine ethical responsibility, and the steps required to meet these obligations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1853–1862},
numpages = {10},
keywords = {app stores, mass participation, large-scale trials, ethics},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466246,
author = {Adar, Eytan and Tan, Desney S. and Teevan, Jaime},
title = {Benevolent Deception in Human Computer Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466246},
doi = {10.1145/2470654.2466246},
abstract = {Though it has been asserted that "good design is honest", [42] deception exists throughout human-computer interaction research and practice. Because of the stigma associated with deception - in many cases rightfully so - the research community has focused its energy on eradicating malicious deception, and ignored instances in which deception is positively employed. In this paper we present the notion of benevolent deception, deception aimed at benefitting the user as well as the developer. We frame our discussion using a criminology-inspired model and ground components in various examples. We assert that this provides us with a set of tools and principles that not only helps us with system and interface design, but that opens new research areas. After all, as Cockton claims in his 2004 paper "Value-Centered HCI" [13], "Traditional disciplines have delivered truth. The goal of HCI is to deliver value."},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1863–1872},
numpages = {10},
keywords = {benevolent deception, design principles, criminology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466247,
author = {Vines, John and Thieme, Anja and Comber, Rob and Blythe, Mark and Wright, Peter C. and Olivier, Patrick},
title = {HCI in the Press: Online Public Reactions to Mass Media Portrayals of HCI Research},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466247},
doi = {10.1145/2470654.2466247},
abstract = {HCI researchers working in publically funded institutions are increasingly encouraged to engage the public in their research. Mass media is often seen as an effective medium with which to communicate research to large parts of the population. We present an account of three HCI projects that have used engagements with mass media in order to communicate research to the public. We describe the motivations for working with mass media and the mechanics of writing press releases. A grounded theory analysis of online public responses to the projects in the mass media leads us to identify a number of concerns about how research is portrayed by news outlets and thus interpreted by the public. Tensions about technologies and wider societal issues were revealed that might normally be hidden when using traditional user-centred methods. We critically reflect on the efficacy of using the mass media in research and provide guidance for HCI researchers wishing to engage in dialogues with the public in the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1873–1882},
numpages = {10},
keywords = {sustainability, older people, mass media, public engagement, navigation systems, digital banking},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466248,
author = {Moncur, Wendy},
title = {The Emotional Wellbeing of Researchers: Considerations for Practice},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466248},
doi = {10.1145/2470654.2466248},
abstract = {As technology progressively pervades all aspects of our lives, members of the HCI community are engaging with increasingly sensitive contexts in their research - for example, end of life, genocide, computer-mediated communication under oppressive regimes. The considerations generated by research in such contexts can go well beyond those addressed by generic ethical approval processes and institutional practice. Whilst it is standard to ensure that the wellbeing of participants is taken into account in research design and the ethical approval process, it is much less common for the researcher's own emotional wellbeing to be considered explicitly. This paper describes the role that a researcher's emotions may play in research, and the impact which research in sensitive contexts can have on researchers' emotional wellbeing and on research validity. A qualitative survey is described which investigated the support mechanisms which HCI researchers have in place in case they are distressed/troubled as a result of their research. The results of the survey are used, in combination with insights into how other disciplines address the topic, to synthesize suggestions for ways in which the HCI community can proactively incorporate consideration for the emotional wellbeing of the researcher into the research process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1883–1890},
numpages = {8},
keywords = {ethics, emotion, participatory design, research governance, validity, methodology, reflection, end of life, qualitative research, thanatosensitive design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250092,
author = {Loke, Lian},
title = {Session Details: Papers: Embodied Interaction 2},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250092},
doi = {10.1145/3250092},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466250,
author = {Doucette, Andre and Mandryk, Regan L. and Gutwin, Carl and Nacenta, Miguel and Pavlovych, Andriy},
title = {The Effects of Tactile Feedback and Movement Alteration on Interaction and Awareness with Digital Embodiments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466250},
doi = {10.1145/2470654.2466250},
abstract = {Collaborative tabletop systems can employ direct touch, where people's real arms and hands manipulate objects, or indirect input, where people are represented on the table with digital embodiments. The input type and the resulting embodiment dramatically influence tabletop interaction: in particular, the touch avoidance that naturally governs people's touching and crossing behavior with physical arms is lost with digital embodiments. One result of this loss is that people are less aware of each others' arms, and less able to coordinate actions and protect personal territories. To determine whether there are strategies that can influence group interaction on shared digital tabletops, we studied augmented digital arm embodiments that provide tactile feedback or movement alterations when people touched or crossed arms. The study showed that both augmentation types changed people's behavior (people crossed less than half as often) and also changed their perception (people felt more aware of the other person's arm, and felt more awkward when touching). This work shows how groupware designers can influence people's interaction, awareness, and coordination abilities when physical constraints are absent.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1891–1900},
numpages = {10},
keywords = {awareness, coordination, tabletop groupware, embodiments},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466251,
author = {Deckers, Eva and Wensveen, Stephan and Levy, Pierre and Ahn, Rene},
title = {Designing for Perceptual Crossing: Designing and Comparing Three Behaviors},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466251},
doi = {10.1145/2470654.2466251},
abstract = {Perceptual crossing is the reciprocal interplay of perceiving while being perceived. In this paper we discuss the last iteration of our ongoing research project on designing for perceptive qualities in systems of interactive products. We describe the design of explorative behavior in an artifact to enable the artifact and a person to engage in perceptual crossing. The explorative behavior is compared to the following and active behavior, the results of two earlier iterations. Through the iterations we formulated, applied and evaluated design relevant knowledge in the form of seven design notions. These notions inform design-researchers and design-practitioners on how to design for perceptive qualities in systems of interactive products. Here we specifically focus on how the artifact detects active perceptive behavior of a person, and how the artifact becomes aware of bygone perception and anticipates on future perception. An experiment shows how participants preferred the resulting explorative behavior that is closest to our theoretical framework based on phenomenology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1901–1910},
numpages = {10},
keywords = {product behavior, design theory, perceptual crossing, perceptive qualities, research through design, phenomenology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466252,
author = {Cafaro, Francesco and Panella, Alessandro and Lyons, Leilah and Roberts, Jessica and Radinsky, Josh},
title = {I See You There! Developing Identity-Preserving Embodied Interaction for Museum Exhibits},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466252},
doi = {10.1145/2470654.2466252},
abstract = {Museums are increasingly embracing technologies that provide highly-individualized and highly-interactive experiences to visitors. With embodied interaction experiences, increased localization accuracy supports greater nuance in interaction design, but there is usually a tradeoff between fast, accurate tracking and the ability to preserve the identity of users. Customization of experience relies on the ability to detect the identity of visitors, however. We present a method that combines fine-grained indoor tracking with robust preservation of the unique identities of multiple users. Our model merges input from an RFID reader with input from a commercial camera-based tracking system. We developed a probabilistic Bayesian model to infer at run-time the correct identification of the subjects in the camera's field of view. This method, tested in a lab and at a local museum, requires minimal modification to the exhibition space, while addressing several identity-preservation problems for which many indoor tracking systems do not have robust solutions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1911–1920},
numpages = {10},
keywords = {localization, identification, rfid, ambient displays, embodied interaction, tracking, museum exhibits, cameras},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466253,
author = {Rae, Irene and Takayama, Leila and Mutlu, Bilge},
title = {In-Body Experiences: Embodiment, Control, and Trust in Robot-Mediated Communication},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466253},
doi = {10.1145/2470654.2466253},
abstract = {Communication technologies are becoming increasingly diverse in form and functionality, making it important to identify which aspects of these technologies actually improve geographically distributed communication. Our study examines two potentially important aspects of communication technologies which appear in robot-mediated communication - physical embodiment and control of this embodiment. We studied the impact of physical embodiment and control upon interpersonal trust in a controlled laboratory experiment using three different videoconferencing settings: (1) a handheld tablet controlled by a local user, (2) an embodied system controlled by a local user, and (3) an embodied system controlled by a remote user (n = 29 dyads). We found that physical embodiment and control by the local user increased the amount of trust built between partners. These results suggest that both physical embodiment and control of the system influence interpersonal trust in mediated communication and have implications for future system designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1921–1930},
numpages = {10},
keywords = {trust, computer-supported collaborative work, videoconferencing, robot-mediated communication, computer-mediated communication, control, embodiment},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250093,
author = {Busse, Daniela K.},
title = {Session Details: Papers: Design Research},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250093},
doi = {10.1145/3250093},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466255,
author = {Vermeulen, Jo and Luyten, Kris and van den Hoven, Elise and Coninx, Karin},
title = {Crossing the Bridge over Norman's Gulf of Execution: Revealing Feedforward's True Identity},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466255},
doi = {10.1145/2470654.2466255},
abstract = {Feedback and affordances are two of the most well-known principles in interaction design. Unfortunately, the related and equally important notion of feedforward has not been given as much consideration. Nevertheless, feedforward is a powerful design principle for bridging Norman's Gulf of Execution. We reframe feedforward by disambiguating it from related design principles such as feedback and perceived affordances, and identify new classes of feedforward. In addition, we present a reference framework that provides a means for designers to explore and recognize different opportunities for feedforward.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1931–1940},
numpages = {10},
keywords = {design, theory, feedforward, feedback, affordances},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466256,
author = {O'Leary, Kathleen and Wobbrock, Jacob O. and Riskin, Eve A.},
title = {Q-Methodology as a Research and Design Tool for HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466256},
doi = {10.1145/2470654.2466256},
abstract = {A "discount" version of Q-methodology for HCI, called "HCI-Q", can be used in iterative design cycles to explore, from the point of view of users and other stakeholders, what makes technologies personally significant. Initially, designers critically reflect on their own assumptions about how a design may affect social and individual behavior. Then, designers use these assumptions as stimuli to elicit other people's points of view. This process of critical self-reflection and evaluation helps the designer to assess the fit between a design and its intended social context of use. To demonstrate the utility of HCI-Q for research and design, we use HCI-Q to explore stakeholders' responses to a prototype Alternative and Augmentative Communication (AAC) application called Vid2Speech. We show that our adaptation of Q-methodology is useful for revealing the structure of consensus and conflict among stakeholder perspectives, helping to situate design within the context of relevant value tensions and norms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1941–1950},
numpages = {10},
keywords = {qualitative methods, design methodology, personal significance, user studies, quantitative methods, psychology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466257,
author = {Roedl, David J. and Stolterman, Erik},
title = {Design Research at CHI and Its Applicability to Design Practice},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466257},
doi = {10.1145/2470654.2466257},
abstract = {This note describes our analysis of 35 papers from CHI 2011 that aim to improve or support interaction design practice. In our analysis, we characterize how these CHI authors conceptualize design practice and the types of contributions they propose. This work is motivated by the recognition that design methods proposed by HCI researchers often do not fit the needs and constraints of professional design practice. As a complement to the analysis of the CHI papers we also interviewed 13 practitioners about their attitudes towards learning new methods and approaches. We conclude the note by offering some critical reflections about how HCI research can better support actual design practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1951–1954},
numpages = {4},
keywords = {design practice, design research, interaction design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466258,
author = {Bauer, Jared S. and Kientz, Julie A.},
title = {DesignLibs: A Scenario-Based Design Method for Ideation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466258},
doi = {10.1145/2470654.2466258},
abstract = {Generating potential design ideas through ideation often benefits from the spontaneity of random ideas. Having potential users participate in this process can be beneficial, but is often difficult to implement. We present a new method for generating design ideas with potential users. The method uses scenarios with missing words, which potential users fill in to generate ideas for features and attributes of new technology designs, similar to the children's game of Mad Libs. We developed three different formats of DesignLibs, including 1) "Mad Libs-style": blanks presented before seeing the scenario, 2) "Fill-in-the-Blanks": blanks presented within the context of the scenario, and 3) "Q&amp;A": blanks presented as questions and answers. We found that Design-Libs generated a number of new ideas, with the Fill-in-the-Blanks method providing the highest ratings for usefulness, feasibility, and diversity of answers. All three formats provided equal ratings for creativity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1955–1958},
numpages = {4},
keywords = {scenarios, ideation, design methods, user-centered design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250094,
author = {Froehlich, Jon},
title = {Session Details: Papers: Developing the World},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250094},
doi = {10.1145/3250094},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466260,
author = {Wyche, Susan P. and Murphy, Laura L.},
title = {Powering the Cellphone Revolution: Findings from Mobile Phone Charging Trials in off-Grid Kenya},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466260},
doi = {10.1145/2470654.2466260},
abstract = {Can human-powered devices solve the electricity gap for the millions of rural Africans adopting mobile phones? Findings from our long-term evaluation of two personal crank-based charging systems in Kenya reveal that small hand and leg-powered devices do have potential to meet the needs of rural mobile phone users. Unfortunately, device breakage, theft and incompatibility with handsets, coupled with lack of consumer credit and poorly functioning markets for these goods mean these represent only a partial solution to the mobile phone charging problem. Drawing from our fieldwork, we motivate a HCI4D/ICTD design and evaluation agenda that better accounts for unique individuals' geographic, financial, and economic circumstances or their human computer ecosystem. Key strategies for implementing this agenda are engaging with diverse users on their own terms and conducting long-term qualitative evaluations to reveal how acceptance and usability change over time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1959–1968},
numpages = {10},
keywords = {mobile phones, rural africa, hci4d/ictd, human-powered, design, off-grid power, human factors},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466261,
author = {Shrinivasan, Yedendra B. and Jain, Mohit and Seetharam, Deva P. and Choudhary, Abhishek and Huang, Elaine M. and Dillahunt, Tawanna and Mankoff, Jennifer},
title = {Deep Conservation in Urban India and Its Implications for the Design of Conservation Technologies},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466261},
doi = {10.1145/2470654.2466261},
abstract = {Rapid depletion of fossil fuels and water resources has become an international problem. Urban residential households are among the primary consumers of resources and are deeply affected by resource shortages. Despite the global nature of these problems, most of the solutions being developed to address these issues are based on studies done in the developed world. We present a study of energy, water and fuel conservation practices in urban India. Our study highlights a culture of deep conservation and the results raise questions about the viability of typical solutions such as home energy monitors. We identify new opportunities for design such as point-of-use feedback technologies, modular solutions, distributed energy storage, harnessing by-products and automated load shifting.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1969–1978},
numpages = {10},
keywords = {sustainability, developing world, ict4d, energy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466262,
author = {Wulf, Volker and Aal, Konstantin and Abu Kteish, Ibrahim and Atam, Meryem and Schubert, Kai and Rohde, Markus and Yerousis, George P. and Randall, David},
title = {Fighting against the Wall: Social Media Use by Political Activists in a Palestinian Village},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466262},
doi = {10.1145/2470654.2466262},
abstract = {We analyze practices of political activists in a Palestinian village located in the West Bank. Activists organize weekly demonstrations against Israel's settlement policy and the separation wall. Over a period of 28 months, we conducted a field study consisting of eight days 'on the ground' observation and interviewing, and extensive monitoring of Internet communication. We describe the activists' background and their efforts to organize these demonstrations under conditions of military occupation. Over time, we observe the role both digital and material factors play in the organization of protest. Specifically, we analyze how Email and Facebook were appropriated to facilitate interaction 'on the ground'.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1979–1988},
numpages = {10},
keywords = {social media, appropriation, field study, political protest},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466263,
author = {Kumar, Neha and Rangaswamy, Nimmi},
title = {The Mobile Media Actor-Network in Urban India},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466263},
doi = {10.1145/2470654.2466263},
abstract = {Building on a growing body of human-computer interaction (HCI) literature on information and communication technology (ICT) use in the developing world, this paper describes the vast, growing mobile media consumption culture in India, which relies on the ubiquity of informal socioeconomic practices for reproducing, sharing, and distributing pirated digital media. Using an Actor-Network Theory (ANT) based approach, we show how piracy not only fuels media consumption, but also drives further technology adoption and promotes digital literacy. To do this, we first uncover the role of piracy as a legitimate actor that brings ICT capability to underserved communities and reveal the heterogeneous character of the pirated mobile media distribution and consumption infrastructure in India. We then emphasize the benefits of an ANT-based theory-driven analysis to HCI's efforts in this arena. In particular, ANT enables us to one, draw attention to the ties in the pirate media network that facilitate the increased decentralization of piracy in India; two, highlight the progressive transition from the outsourcing to the self-sourcing of users' media needs as this network evolves; and three, recognize the agency of human and non-human entities in this inherently sociotechnical ecosystem.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1989–1998},
numpages = {10},
keywords = {mobile, hci4d, actor-network theory, piracy, ictd, entertainment, media},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250095,
author = {Ding, Xianghua},
title = {Session Details: Papers: Collaborative Creation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250095},
doi = {10.1145/3250095},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466265,
author = {Chilton, Lydia B. and Little, Greg and Edge, Darren and Weld, Daniel S. and Landay, James A.},
title = {Cascade: Crowdsourcing Taxonomy Creation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466265},
doi = {10.1145/2470654.2466265},
abstract = {Taxonomies are a useful and ubiquitous way of organizing information. However, creating organizational hierarchies is difficult because the process requires a global understanding of the objects to be categorized. Usually one is created by an individual or a small group of people working together for hours or even days. Unfortunately, this centralized approach does not work well for the large, quickly changing datasets found on the web. Cascade is an automated workflow that allows crowd workers to spend as little at 20 seconds each while collectively making a taxonomy. We evaluate Cascade and show that on three datasets its quality is 80-90% of that of experts. Cascade has a competitive cost to expert information architects, despite taking six times more human labor. Fortunately, this labor can be parallelized such that Cascade will run in as fast as four minutes instead of hours or days.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1999–2008},
numpages = {10},
keywords = {crowdsourcing, human computation, information architecture, algorithm},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466266,
author = {Settles, Burr and Dow, Steven},
title = {Let's Get Together: The Formation and Success of Online Creative Collaborations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466266},
doi = {10.1145/2470654.2466266},
abstract = {In online creative communities, members work together to produce music, movies, games, and other cultural products. Despite the proliferation of collaboration in these communities, we know little about how these teams form and what leads to their ultimate success. Building on theories of social identity and exchange, we present an exploratory study of an online songwriting community. We analyze four years of longitudinal behavioral data using a novel path-based regression model that accurately predicts and reveals key variables about collab formation. Combined with a large-scale survey of members, we find that communication, nuanced complementary interest and status, and a balanced effort from both parties contribute to successful collaborations. We also discuss several applications of these findings for socio-technical infrastructures that support online creative production.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2009–2018},
numpages = {10},
keywords = {computer-supported cooperative work, social creativity, music composition, online communities, collaboration},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466267,
author = {Pace, Tyler and Toombs, Austin and Gross, Shad and Pattin, Tony and Bardzell, Jeffrey and Bardzell, Shaowen},
title = {A Tribute to Mad Skill: Expert Amateur Visuality and World of Warcraft Machinima},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466267},
doi = {10.1145/2470654.2466267},
abstract = {In this paper, we look at the prominent World of Warcraft machinima community as an expert amateur online com-munity and present a multi-part study of a canon of the most successful works (i.e., machinima videos) produced by this community. By focusing our study on its roughly 300 most successful examples, the determination of which we explain in the paper, we are able to highlight the evolv-ing visual practices, tools, and aesthetic sensibilities of the community. Chiefly, our study identifies how creativity support tools and visual practices are inextricably linked and mutually support the in-kind development of the other. For WoW machinima and its producers, the affordance of creativity tools and the cultivation of visual skill synced at key moments and in powerful ways to support the rapid growth, experimentation, and refinement of amateur exper-tise at the individual and community levels.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2019–2028},
numpages = {10},
keywords = {creativity, expert amateurs, machinima, visuality},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466268,
author = {Cottman-Fields, Mark and Brereton, Margot and Roe, Paul},
title = {Virtual Birding: Extending an Environmental Pastime into the Virtual World for Citizen Science},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466268},
doi = {10.1145/2470654.2466268},
abstract = {This paper investigates engaging experienced birders, as volunteer citizen scientists, to analyze large recorded audio datasets gathered through environmental acoustic monitoring. Although audio data is straightforward to gather, automated analysis remains a challenging task; the existing expertise, local knowledge and motivation of the birder community can complement computational approaches and provide distinct benefits. We explored both the culture and practice of birders, and paradigms for interacting with recorded audio data. A variety of candidate design elements were tested with birders.This study contributes an understanding of how virtual interactions and practices can be developed to complement existing practices of experienced birders in the physical world. In so doing this study contributes a new approach to engagement in e-science. Whereas most citizen science projects task lay participants with discrete real world or artificial activities, sometimes using extrinsic motivators, this approach builds on existing intrinsically satisfying practices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2029–2032},
numpages = {4},
keywords = {citizen science, bioacoustics, domain-specific expertise, bird watching, biodiversity monitoring, birder},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466269,
author = {Lasecki, Walter S. and Miller, Christopher D. and Bigham, Jeffrey P.},
title = {Warping Time for More Effective Real-Time Crowdsourcing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466269},
doi = {10.1145/2470654.2466269},
abstract = {In this paper, we introduce the idea of "warping time" to improve crowd performance on the difficult task of captioning speech in real-time. Prior work has shown that the crowd can collectively caption speech in real-time by merging the partial results of multiple workers. Because non-expert workers cannot keep up with natural speaking rates, the task is frustrating and prone to errors as workers buffer what they hear to type later. The TimeWarp approach automatically increases and decreases the speed of speech playback systematically across individual workers who caption only the periods played at reduced speed. Studies with 139 remote crowd workers and 24 local participants show that this approach improves median coverage (14.8%), precision (11.2%), and per-word latency (19.1%). Warping time may also help crowds outperform individuals on other difficult real-time performance tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2033–2036},
numpages = {4},
keywords = {captioning, human computation, real-time crowdsourcing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250131,
author = {Law, Effie},
title = {Session Details: Papers: Aesthetics and the Web},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250131},
doi = {10.1145/3250131},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481281,
author = {Reinecke, Katharina and Yeh, Tom and Miratrix, Luke and Mardiko, Rahmatri and Zhao, Yuechen and Liu, Jenny and Gajos, Krzysztof Z.},
title = {Predicting Users' First Impressions of Website Aesthetics with a Quantification of Perceived Visual Complexity and Colorfulness},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481281},
doi = {10.1145/2470654.2481281},
abstract = {Users make lasting judgments about a website's appeal within a split second of seeing it for the first time. This first impression is influential enough to later affect their opinions of a site's usability and trustworthiness. In this paper, we demonstrate a means to predict the initial impression of aesthetics based on perceptual models of a website's colorfulness and visual complexity. In an online study, we collected ratings of colorfulness, visual complexity, and visual appeal of a set of 450 websites from 548 volunteers. Based on these data, we developed computational models that accurately measure the perceived visual complexity and colorfulness of website screenshots. In combination with demographic variables such as a user's education level and age, these models explain approximately half of the variance in the ratings of aesthetic appeal given after viewing a website for 500ms only.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2049–2058},
numpages = {10},
keywords = {modeling, perception, complexity, first impression, colorfulness, prediction, website aesthetics},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481282,
author = {Hart, Jennefer and Sutcliffe, Alistair G. and De Angeli, Antonella},
title = {Love It or Hate It! Interactivity and User Types},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481282},
doi = {10.1145/2470654.2481282},
abstract = {This paper investigates general and individual evaluations of User Experience (UX) with interactive web sites. A series of studies investigate user judgment on web sites with different interactivity levels over repeated exposures. The more interactive websites produced more positive affect, had better design quality ratings, which improved with exposure, and were preferred. Differences between the more interactive sites indicated overall UX was influenced by users' preferences for interactive styles, with both sites having enthusiast, potential adopter, and non-adopter users. The implications for models and frameworks of UX are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2059–2068},
numpages = {10},
keywords = {interactivity, design features, affect, user experience, quality judgement, individual differences},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481283,
author = {Flatla, David R. and Reinecke, Katharina and Gutwin, Carl and Gajos, Krzysztof Z.},
title = {SPRWeb: Preserving Subjective Responses to Website Colour Schemes through Automatic Recolouring},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481283},
doi = {10.1145/2470654.2481283},
abstract = {Colours are an important part of user experiences on the Web. Colour schemes influence the aesthetics, first impressions and long-term engagement with websites. However, five percent of people perceive a subset of all colours because they have colour vision deficiency (CVD), resulting in an unequal and less-rich user experience on the Web. Traditionally, people with CVD have been supported by recolouring tools that improve colour differentiability, but do not consider the subjective properties of colour schemes while recolouring. To address this, we developed SPRWeb, a tool that recolours websites to preserve subjective responses and improve colour differentiability - thus enabling users with CVD to have similar online experiences. To develop SPRWeb, we extended existing models of non-CVD subjective responses to CVD, then used this extended model to steer the recolouring process. In a lab study, we found that SPRWeb did significantly better than a standard recolouring tool at preserving the temperature and naturalness of websites, while achieving similar weight and differentiability preservation. We also found that recolouring did not preserve activity, and hypothesize that visual complexity influences activity more than colour. SPRWeb is the first tool to automatically preserve the subjective and perceptual properties of website colour schemes thereby equalizing the colour-based web experience for people with CVD.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2069–2078},
numpages = {10},
keywords = {colour vision deficiency, colour, automatic recolouring},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250132,
author = {Tscheligi, Manfred},
title = {Session Details: Papers: Evaluation Methods 2},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250132},
doi = {10.1145/3250132},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481285,
author = {Tuch, Alexandre N. and Trusell, Rune and Hornb\ae{}k, Kasper},
title = {Analyzing Users' Narratives to Understand Experience with Interactive Products},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481285},
doi = {10.1145/2470654.2481285},
abstract = {Recent research in user experience (UX) has studied narratives, users' account of their interaction with technology. It has emphasized specific constructs (e.g., affect, needs, hedonics) and their interrelation, but rarely analyzed the content of the narratives. We analyze the content and structure of 691 user-generated narratives on positive and negative experiences with technology. We use a multi-method approach consisting of manual (structural analysis of narratives) as well as of automated content analysis methods (psycholinguistic analysis and machine learning). These analyses show converging evidence that positive narratives predominantly concern social aspects such as family and friends. In addition, technology is positively experienced when it enables users to do things more efficiently or in a new way. In contrast, negative narratives often express anger and frustration due to technological failures. Our multi-method approach illustrates the potential of automated (as opposed to manual) content analysis methods for studying text-based experience reports.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2079–2088},
numpages = {10},
keywords = {user experience},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481286,
author = {Hedegaard, Steffen and Simonsen, Jakob Grue},
title = {Extracting Usability and User Experience Information from Online User Reviews},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481286},
doi = {10.1145/2470654.2481286},
abstract = {Internet review sites allow consumers to write detailed reviews of products potentially containing information related to user experience (UX) and usability. Using 5198 sentences from 3492 online reviews of software and video games, we investigate the content of online reviews with the aims of (i) charting the distribution of information in reviews among different dimensions of usability and UX, and (ii) extracting an associated vocabulary for each dimension using techniques from natural language processing and machine learning. We (a) find that 13%-49% of sentences in our online reviews pool contain usability or UX information; (b) chart the distribution of four sets of dimensions of usability and UX across reviews from two product categories; (c) extract a catalogue of important word stems for a number of dimensions. Our results suggest that a greater understanding of users' preoccupation with different dimensions of usability and UX may be inferred from the large volume of self-reported experiences online, and that research focused on identifying pertinent dimensions of usability and UX may benefit further from empirical studies of user-generated experience reports.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2089–2098},
numpages = {10},
keywords = {usability, end user reviews, natural language processing, user experience, machine learning},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2481286_R48999,
author = {Fowler, Susan Loretta},
title = {Review ID:R48999 for DOI: 10.1145/2470654.2481286},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2481286_R48999}
}

@inproceedings{10.1145/2470654.2481287,
author = {Lewis, James R. and Utesch, Brian S. and Maher, Deborah E.},
title = {UMUX-LITE: When There's No Time for the SUS},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481287},
doi = {10.1145/2470654.2481287},
abstract = {In this paper we present the UMUX-LITE, a two-item questionnaire based on the Usability Metric for User Experience (UMUX) [6]. The UMUX-LITE items are This system's capabilities meet my requirements and This system is easy to use." Data from two independent surveys demonstrated adequate psychometric quality of the questionnaire. Estimates of reliability were .82 and .83 -- excellent for a two-item instrument. Concurrent validity was also high, with significant correlation with the SUS (.81, .81) and with likelihood-to-recommend (LTR) scores (.74, .73). The scores were sensitive to respondents' frequency-of-use. UMUX-LITE score means were slightly lower than those for the SUS, but easily adjusted using linear regression to match the SUS scores. Due to its parsimony (two items), reliability, validity, structural basis (usefulness and usability) and, after applying the corrective regression formula, its correspondence to SUS scores, the UMUX-LITE appears to be a promising alternative to the SUS when it is not desirable to use a 10-item instrument.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2099–2102},
numpages = {4},
keywords = {sus, umux, psychometric evaluation, umux-lite, standardized questionnaires, usability metric for user experience, system usability scale, satisfaction measures, usability evaluation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481288,
author = {Sko, Torben and Gardner, Henry J. and Martin, Michael},
title = {Non-Parametric Decision Trees and Online HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481288},
doi = {10.1145/2470654.2481288},
abstract = {This paper proposes that online HCI studies (such as web-surveys and remotely monitored usability tests) can benefit from statistical data analysis using modern statistical learning methods such as classification and regression trees (CARTs). Applying CARTs to the often large amount of data yielded by online studies can easily provide clarity concerning the most important effects underlying experimental data in situations where myriad possible factors are under consideration. The feedback provided by such an analysis can also provide valuable reflection on the experimental methodology. We discuss these matters with reference to a study of 1300 participants in a structured experiment concerned with head-interaction techniques for first-person-shooter games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2103–2106},
numpages = {4},
keywords = {online studies, non-parametric, parametric, decision trees, games, classification, regression},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250133,
author = {Kane, Shaun},
title = {Session Details: Papers: Design for the Blind},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250133},
doi = {10.1145/3250133},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481290,
author = {Pan\"{e}els, Sabrina A. and Olmos, Adriana and Blum, Jeffrey R. and Cooperstock, Jeremy R.},
title = {Listen to It Yourself! Evaluating Usability of What's around Me? For the Blind},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481290},
doi = {10.1145/2470654.2481290},
abstract = {Although multiple GPS-based navigation applications exist for the visually impaired, these are typically poorly suited for in-situ exploration, require cumbersome hardware, lack support for widely accessible geographic databases, or do not take advantage of advanced functionality such as spatialized audio rendering. These shortcomings led to our development of a novel spatial awareness application that leverages the capabilities of a smartphone coupled with worldwide geographic databases and spatialized audio rendering to convey surrounding points of interest. This paper describes the usability evaluation of our system through a task-based study and a longer-term deployment, each conducted with six blind users in real settings. The findings highlight the importance of testing in ecologically valid contexts over sufficient periods to face real-world challenges, including balancing quality versus quantity for audio information, overcoming limitations imposed by sensor accuracy and quality of database information, and paying appropriate design attention to physical interaction with the device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2107–2116},
numpages = {10},
keywords = {visually impaired, mobile interface, audio feedback},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481291,
author = {Brady, Erin and Morris, Meredith Ringel and Zhong, Yu and White, Samuel and Bigham, Jeffrey P.},
title = {Visual Challenges in the Everyday Lives of Blind People},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481291},
doi = {10.1145/2470654.2481291},
abstract = {The challenges faced by blind people in their everyday lives are not well understood. In this paper, we report on the findings of a large-scale study of the visual questions that blind people would like to have answered. As part of this year-long study, 5,329 blind users asked 40,748 questions about photographs that they took from their iPhones using an application called VizWiz Social. We present a taxonomy of the types of questions asked, report on a number of features of the questions and accompanying photographs, and discuss how individuals changed how they used VizWiz Social over time. These results improve our understanding of the problems blind people face, and may help motivate new projects more accurately targeted to help blind people live more independently in their everyday lives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2117–2126},
numpages = {10},
keywords = {accessibility, blind users, q&amp;a, crowdsourcing, mobile},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481292,
author = {Harada, Susumu and Sato, Daisuke and Adams, Dustin W. and Kurniawan, Sri and Takagi, Hironobu and Asakawa, Chieko},
title = {Accessible Photo Album: Enhancing the Photo Sharing Experience for People with Visual Impairment},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481292},
doi = {10.1145/2470654.2481292},
abstract = {While a photograph is a visual artifact, studies reveal that a number of people with visual impairments are also interested in being able to share their memories and experiences with their sighted counterparts in the form of a photograph. We conducted an online survey to better understand the challenges faced by people with visual impairments in sharing and organizing photos, and reviewed existing tools and their limitations. Based on our analysis, we developed an accessible mobile application that enables a visually impaired user to capture photos along with audio recordings for the ambient sound and memo description and to browse through them eyes-free. Five visually impaired participants took part in a study in which they used our app to take photographs in naturalistic settings and to share them later with a sighted viewer. The participants were able to use our app to identify each photograph on their own during the photo sharing session, and reported high satisfaction in having been able to take the initiative during the process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2127–2136},
numpages = {10},
keywords = {blind, audiophotography, photo sharing, visual impairment},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250134,
author = {Hudson, Scott},
title = {Session Details: Papers: Mobile Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250134},
doi = {10.1145/3250134},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481294,
author = {B\"{o}hmer, Matthias and Kr\"{u}ger, Antonio},
title = {A Study on Icon Arrangement by Smartphone Users},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481294},
doi = {10.1145/2470654.2481294},
abstract = {The number of available mobile applications is steadily increasing. People have rapidly adopted application stores as means to customize their devices with various functionalities that go beyond communication. Understanding the principles of mobile application usage is crucial for supporting users within this new ecosystem. In this paper, we investigate how people organize applications they have installed on their devices. We asked more than 130 participants for their habits for icon arrangement and collected more than 1,400 screenshots of their devices' menus to further ground our findings. Based on this data we can distinguish five different concepts for arranging icons on smartphone menus, e.g. based on application usage frequency and applications' functional relatedness. Additionally, we investigated how these concepts emerge in relation to frequency of application installations, removals and icon rearrangements, as well as users' experience levels. Finally we discuss implications for the design of smartphone launchers, and highlight differences to icon arrangement on stationary computers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2137–2146},
numpages = {10},
keywords = {mobile applications, icon arrangement, user behavior},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481295,
author = {Shirali-Shahreza, Sajad and Penn, Gerald and Balakrishnan, Ravin and Ganjali, Yashar},
title = {SeeSay and HearSay CAPTCHA for Mobile Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481295},
doi = {10.1145/2470654.2481295},
abstract = {Speech certainly has advantages as an input modality for smartphone applications, especially in scenarios where using touch or keyboard entry is difficult, on increasingly miniaturized devices where useable keyboards are difficult to accommodate, or in scenarios where only small amounts of text need to be input, such as when entering SMS texts or responding to a CAPTCHA challenge. In this paper, we propose two new alternative ways to design CAPTCHAs in which the user says the answer instead of typing it with (a) output stimuli provided visually (SeeSay) or (b) auditorily (HearSay). Our user study results show that SeeSay CAPTCHA requires less time to be solved and users prefer it over current text-based CAPTCHA methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2147–2156},
numpages = {10},
keywords = {captcha, mobile phone, speech recognition},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481296,
author = {Wiese, Jason and Saponas, T. Scott and Brush, A.J. Bernheim},
title = {Phoneprioception: Enabling Mobile Phones to Infer Where They Are Kept},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481296},
doi = {10.1145/2470654.2481296},
abstract = {Enabling phones to infer whether they are currently in a pocket, purse or on a table facilitates a range of new interactions from placement-dependent notifications setting to preventing "pocket dialing". We collected data from 693 participants to understand where people keep their phone in different contexts and why. Using this data, we identified three placement personas: Single Place Pat, Consistent Casey, and All-over Alex. Based on these results, we collected two weeks of labeled accelerometer data in-situ from 32 participants. We used this data to build models for inferring phone placement, achieving an accuracy of approximately 85% for inferring whether the phone is in an enclosed location and for inferring if the phone is on the user. Finally, we prototyped a capacitive grid and a multispectral sensor and collected data from 15 participants in a laboratory to understand the added value of these sensors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2157–2166},
numpages = {10},
keywords = {mobile sensors, context awareness, phone placement},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481297,
author = {Xu, Wenchang and Yu, Chun and Zhao, Songmin and Liu, Jie and Shi, Yuanchun},
title = {Facilitating Parallel Web Browsing through Multiple-Page View},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481297},
doi = {10.1145/2470654.2481297},
abstract = {Parallel web browsing describes the behavior where users visit web pages in multiple concurrent threads. Qualitative studies have observed this activity being performed with multiple browser windows or tabs. However, these solutions are not satisfying since a large amount of time is wasted on switch among windows and tabs. In this paper, we propose the multiple-page view to facilitate parallel web browsing. Specifically, we provide users with the experience of visiting multiple web pages in one browser window and tab with extensions of prevalent desktop web browsers. Through user study and survey, we found that 2-4 pages within the window size were preferred for multiple-page view in spite of the diverse screen sizes and resolutions. Analytical results of logs from the user study also showed an improvement of 26.3% in users' efficiency of performing parallel web browsing tasks, compared to traditional browsing with multiple windows or tabs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2167–2170},
numpages = {4},
keywords = {user study, parallel web browsing, multiple-page view},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481298,
author = {Warr, Andrew and Chi, Ed H.},
title = {Swipe vs. Scroll: Web Page Switching on Mobile Browsers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481298},
doi = {10.1145/2470654.2481298},
abstract = {Tabbed web browsing interfaces enable users to multi-task and easily switch between open web pages. However, tabbed browsing is difficult for mobile web browsers due to the limited screen space and the reduced precision of touch. We present an experiment comparing Safari's pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome. The results of our experiment show that cards-based switching interface allows for faster switching and is less frustrating, with no significant effect on error rates. We generalize these findings, and provide design implications for mobile information spaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2171–2174},
numpages = {4},
keywords = {web browser interfaces, task spaces, information spaces, web browser, mobile},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250135,
author = {Findlater, Leah},
title = {Session Details: Papers: Performing Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250135},
doi = {10.1145/3250135},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481300,
author = {Letondal, Catherine and Hurter, Christophe and Lesbordes, R\'{e}mi and Vinot, Jean-Luc and Conversy, St\'{e}phane},
title = {Flights in My Hands: Coherence Concerns in Designing Strip'TIC, a Tangible Space for Air Traffic Controllers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481300},
doi = {10.1145/2470654.2481300},
abstract = {We reflect upon the design of a paper-based tangible interactive space to support air traffic control. We have observed, studied, prototyped and discussed with controllers a new mixed interaction system based on Anoto, video projection, and tracking. Starting from the understanding of the benefits of tangible paper strips, our goal is to study how mixed physical and virtual augmented data can support the controllers' mental work. The context of the activity led us to depart from models that are proposed in tangible interfaces research where coherence is based on how physical objects are representative of virtual objects. We propose a new account of coherence in a mixed interaction system that integrates externalization mechanisms. We found that physical objects play two roles: they act both as representation of mental objects and as tangible artifacts for interacting with augmented features. We observed that virtual objects represent physical ones, and not the reverse, and, being virtual representations of physical objects, should seamlessly converge with the cognitive role of the physical object. Finally, we show how coherence is achieved by providing a seamless interactive space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2175–2184},
numpages = {10},
keywords = {participatory design, ethnography, pen-based uis, transport, air traffic control, security., distributed cognition, augmented paper, tangible interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481301,
author = {Laput, Gierad P. and Dontcheva, Mira and Wilensky, Gregg and Chang, Walter and Agarwala, Aseem and Linder, Jason and Adar, Eytan},
title = {PixelTone: A Multimodal Interface for Image Editing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481301},
doi = {10.1145/2470654.2481301},
abstract = {Photo editing can be a challenging task, and it becomes even more difficult on the small, portable screens of mobile devices that are now frequently used to capture and edit images. To address this problem we present PixelTone, a multimodal photo editing interface that combines speech and direct manipulation. We observe existing image editing practices and derive a set of principles that guide our design. In particular, we use natural language for expressing desired changes to an image, and sketching to localize these changes to specific regions. To support the language commonly used in photo-editing we develop a customized natural language interpreter that maps user phrases to specific image processing operations. Finally, we perform a user study that evaluates and demonstrates the effectiveness of our interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2185–2194},
numpages = {10},
keywords = {image editing, multimodal interfaces, natural language},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481302,
author = {McPherson, Andrew P. and Gierakowski, Adrian and Stark, Adam M.},
title = {The Space between the Notes: Adding Expressive Pitch Control to the Piano Keyboard},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481302},
doi = {10.1145/2470654.2481302},
abstract = {This paper addresses the question of how to extend the capabilities of a well-established interface in a way that respects users' existing expertise. The piano-style keyboard is among the most widely used and versatile of digital musical interfaces. However, it lacks the ability to alter the pitch of a note after it has been played, a limitation which prevents the performer from executing common expressive techniques including vibrato and pitch bending. We present a system for controlling pitch from the keyboard surface using capacitive touch sensors to measure the locations of the player's fingers on the keys. The large community of trained pianists makes the keyboard a compelling target for augmentation, but it also poses a challenge: how can a musical interface be extended while making use of the existing techniques performers have spent thousands of hours learning? In this paper, user studies with conservatory pianists explore the constraints of traditional keyboard technique and evaluate the usability of the continuous pitch control system. The paper also discusses implications for the extension of other established interfaces in musical and non-musical contexts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2195–2204},
numpages = {10},
keywords = {digital arts, capacitive touch sensing, musical interfaces, piano keyboard, expressivity, performance technique},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481303,
author = {Pachet, Fran\c{c}ois and Roy, Pierre and Moreira, Julian and d'Inverno, Mark},
title = {Reflexive Loopers for Solo Musical Improvisation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481303},
doi = {10.1145/2470654.2481303},
abstract = {Loop pedals are real-time samplers that playback audio played previously by a musician. Such pedals are routinely used for music practice or outdoor "busking". However, loop pedals always playback the same material, which can make performances monotonous and boring both to the musician and the audience, preventing their widespread uptake in professional concerts. In response, we propose a new approach to loop pedals that addresses this issue, which is based on an analytical multi-modal representation of the audio input. Instead of simply playing back prerecorded audio, our system enables real-time generation of an audio accompaniment reacting to what is currently being performed by the musician. By combining different modes of performance - e.g. bass line, chords, solo - from the musician and system automatically, solo musicians can perform duets or trios with themselves, without engendering the so-called canned (boringly repetitive and unresponsive) music effect of loop pedals. We describe the technology, based on supervised classification and concatenative synthesis, and then illustrate our approach on solo performances of jazz standards by guitar. We claim this approach opens up new avenues for concert performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2205–2208},
numpages = {4},
keywords = {loop pedals, classification, synthesis, music interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481304,
author = {Hirsch, Matthew and Izadi, Shahram and Holtzman, Henry and Raskar, Ramesh},
title = {8D: Interacting with a Relightable Glasses-Free 3D Display},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481304},
doi = {10.1145/2470654.2481304},
abstract = {We present an 8-dimensional (8D) display that allows glasses-free viewing of 3D imagery, whist capturing and reacting to incident environmental and user controlled light sources. We demonstrate two interactive possibilities enabled by our lens-array-based hardware prototype, and realtime GPU-accelerated software pipeline. Additionally, we describe a path to deploying such displays in the future, using current Sensor-in-Pixel (SIP) LCD panels, which physically collocate sensing and display elements.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2209–2212},
numpages = {4},
keywords = {light-based interaction, light fields, glasses-free 3d, relightable display},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250136,
author = {Hornecker, Eva},
title = {Session Details: Papers: Engagement},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250136},
doi = {10.1145/3250136},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481306,
author = {Akpan, Imeh and Marshall, Paul and Bird, Jon and Harrison, Daniel},
title = {Exploring the Effects of Space and Place on Engagement with an Interactive Installation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481306},
doi = {10.1145/2470654.2481306},
abstract = {Very little research has concurrently explored the influence of both physical space and social context (or place) on the way people engage with a public interactive display. We addressed this issue with a novel approach: studying how people engaged with the same interactive installation in ten situations with varying spatial and social properties. The main finding across these studies is that place trumps space: a conducive social context could overcome a poor physical space and encourage interaction; conversely, an inappropriate social context could inhibit interaction in spaces that might normally facilitate engagement. We discuss this finding in terms of the salience of the display within the space, the visibility of incidental interactions with the installation, the different understandings of place that people can have in the same location and the role of emergent champions and comperes in encouraging interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2213–2222},
numpages = {10},
keywords = {public display, situated display, interaction, space, place},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481307,
author = {Pohl, Henning and Murray-Smith, Roderick},
title = {Focused and Casual Interactions: Allowing Users to Vary Their Level of Engagement},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481307},
doi = {10.1145/2470654.2481307},
abstract = {We describe the focused-casual continuum, a framework for describing interaction techniques according to the degree to which they allow users to adapt how much attention and effort they choose to invest in an interaction conditioned on their current situation. Casual interactions are particularly appropriate in scenarios where full engagement with devices is frowned upon socially, is unsafe, physically challenging or too mentally taxing. Novel sensing approaches which go beyond direct touch enable wider use of casual interactions, which will often be 'around device' interactions. We consider the degree to which previous commercial products and research prototypes can be considered as fitting the focused-casual framework, and describe the properties using control theoretic concepts. In an experimental study we observe that users naturally apply more precise and more highly engaged interaction techniques when faced with a more challenging task and use more relaxed gestures in easier tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2223–2232},
numpages = {10},
keywords = {foreground/background, interaction techniques, peripheral interaction, sensing, casual interaction, deliberate interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481308,
author = {Xu, Qianli and Li, Liyuan and Wang, Gang},
title = {Designing Engagement-Aware Agents for Multiparty Conversations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481308},
doi = {10.1145/2470654.2481308},
abstract = {Recognizing users' engagement state and intentions is a pressing task for computational agents to facilitate fluid conversations in situated interactions. We investigate how to quantitatively evaluate high-level user engagement and intentions based on low-level visual cues, and how to design engagement-aware behaviors for the conversational agents to behave in a sociable manner. Drawing on machine learning techniques, we propose two computational models to quantify users' attention saliency and engagement intentions. Their performances are validated by a close match between the predicted values and the ground truth annotation data. Next, we design a novel engagement-aware behavior model for the agent to adjust its direction of attention and manage the conversational floor based on the estimated users' engagement. In a user study, we evaluated the agent's behaviors in a multiparty dialog scenario. The results show that the agent's engagement-aware behaviors significantly improved the effectiveness of communication and positively affected users' experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2233–2242},
numpages = {10},
keywords = {gaze, multiparty conversation, intention, engagement, human-robot interaction, visual perception.},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481309,
author = {Lanir, Joel and Stone, Ran and Cohen, Benjamin and Gurevich, Pavel},
title = {Ownership and Control of Point of View in Remote Assistance},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481309},
doi = {10.1145/2470654.2481309},
abstract = {In this paper we investigate user performance and user behavior, related to the issue of who controls the point of view in a remote assistance scenario. We describe an experiment that examined users completing two different tasks with the aid of a remote gesturing device under two conditions: when control of the camera and gesturing point of view was in the hands of the remote helper, and when it was in the hands of the worker. Results indicate that in general, when most of the knowledge is with the helper, it is preferable to leave control in the hands of the helper. However, these results may depend on the situation and task at hand.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2243–2252},
numpages = {10},
keywords = {remote gesturing, remote assistance, point of view, control, cscw},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250137,
author = {Wulf, Volker},
title = {Session Details: Papers: Knowledge Managment},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250137},
doi = {10.1145/3250137},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481311,
author = {Zhu, Haiyi and Zhang, Amy and He, Jiping and Kraut, Robert E. and Kittur, Aniket},
title = {Effects of Peer Feedback on Contribution: A Field Experiment in Wikipedia},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481311},
doi = {10.1145/2470654.2481311},
abstract = {One of the most significant challenges for many online communities is increasing members' contributions over time. Prior studies on peer feedback in online communities have suggested its impact on contribution, but have been limited by their correlational nature. In this paper, we conducted a field experiment on Wikipedia to test the effects of different feedback types (positive feedback, negative feedback, directive feedback, and social feedback) on members' contribution. Our results characterize the effects of different feedback types, and suggest trade-offs in the effects of feedback between the focal task and general motivation, as well as differences in how newcomers and experienced editors respond to peer feedback. This research provides insights into the mechanisms underlying peer feedback in online communities and practical guidance to design more effective peer feedback systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2253–2262},
numpages = {10},
keywords = {field experiment, peer feedback, online communities, wikipedia.},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481312,
author = {Houben, Steven and Bardram, Jakob E. and Vermeulen, Jo and Luyten, Kris and Coninx, Karin},
title = {Activity-Centric Support for Ad Hoc Knowledge Work: A Case Study of Co-Activity Manager},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481312},
doi = {10.1145/2470654.2481312},
abstract = {Modern knowledge work consists of both individual and highly collaborative activities that are typically composed of a number of configuration, coordination and articulation processes. The desktop interface today, however, provides very little support for these processes and rather forces knowledge workers to adapt to the technology. We introduce co-Activity Manager, an activity-centric desktop system that (i) provides tools for ad hoc dynamic configuration of a desktop working context, (ii) supports both explicit and implicit articulation of ongoing work through a built-in collaboration manager and (iii) provides the means to coordinate and share working context with other users and devices. In this paper, we discuss the activity theory informed design of co-Activity Manager and report on a 14 day field deployment in a multi-disciplinary software development team. The study showed that the activity-centric workspace supports different individual and collaborative work configuration practices and that activity-centric collaboration is a two-phase process consisting of an activity sharing and per-activity coordination phase.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2263–2272},
numpages = {10},
keywords = {collaborative work, activity-centric computing, activity theory, desktop interface},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481313,
author = {Voida, Amy and Olson, Judith S. and Olson, Gary M.},
title = {Turbulence in the Clouds: Challenges of Cloud-Based Information Work},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481313},
doi = {10.1145/2470654.2481313},
abstract = {We report on a qualitative study of the user experience of cloud-based information work. We characterize the information work practices and challenges that exist largely at the different intersections of three constructs - cloud-based services, collaborations, and digital identifiers. We also demonstrate how the misalignment of these three constructs is experienced as a "losing battle" that has led to miscommunication among collaborators, the abandonment of cloud-based services, and the irreparable blurring of digital identities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2273–2282},
numpages = {10},
keywords = {information management, information work, cloud computing, digital identifiers},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481314,
author = {Howley, Iris and Newman, Todd},
title = {Factors Impacting Community Response in an Interest-Sharing Network},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481314},
doi = {10.1145/2470654.2481314},
abstract = {The arrival of a new interest-sharing network, So.cl, provides for a new opportunity to explore human behavior as it relates to constructing public contributions and receiving community response. This study looks at archival data in order to better understand how types of shared content receive interaction from others. The results suggest that a So.cl user should include more photos and less links on their post to increase the quantity of likes and comments the community gives to the post, among other discoveries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2283–2286},
numpages = {4},
keywords = {social networks, log analysis},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481315,
author = {Cassidy, Brendan and Antani, Dipti Saurabh and Read, Janet C C.},
title = {Using an Open Card Sort with Children to Categorize Games in a Mobile Phone Application Store},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481315},
doi = {10.1145/2470654.2481315},
abstract = {This paper presents a study aimed at better understanding how children categorize different games. The paper reports the results of an open card sort where participants were asked to categorize games from the Google Play Store (formerly the 'Android Marketplace'). The key contribution of the paper is that when compared with existing categories in the Google Play Store, children used categorization criteria much more aligned to the goals of the game rather than more abstract categories currently found in mobile phone application stores. The paper provides examples of existing categories that are not generally used by children and provides new examples of categorization criteria that are used by children to categorize existing games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2287–2290},
numpages = {4},
keywords = {information retrieval, cluster analysis, mobile, games, classification, card sort, categorization, recall, children},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250138,
author = {Pietriga, Emmanuel},
title = {Session Details: Papers: Touch Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250138},
doi = {10.1145/3250138},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481317,
author = {Jota, Ricardo and Ng, Albert and Dietz, Paul and Wigdor, Daniel},
title = {How Fast is Fast Enough? A Study of the Effects of Latency in Direct-Touch Pointing Tasks},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481317},
doi = {10.1145/2470654.2481317},
abstract = {Although advances in touchscreen technology have provided us with more precise devices, touchscreens are still laden with latency issues. Common commercial devices present with latency up to 125ms. Although these levels have been shown to impact users' perception of the responsiveness of the system [16], relatively little is known about the impact of latency on the performance of tasks common to direct-touch interfaces, such as direct physical manipulation.In this paper, we study the effect of latency of a direct-touch pointing device on dragging tasks. Our tests show that user performance decreases as latency increases. We also find that user performance is more severely affected by latency when targets are smaller or farther away. We present a detailed analysis of users' coping mechanisms for latency, and present the results of a follow-up study demonstrating user perception of latency in the land-on phase of the dragging task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2291–2300},
numpages = {10},
keywords = {latency, touch input, direct manipulations, direct input},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481318,
author = {Drucker, Steven M. and Fisher, Danyel and Sadana, Ramik and Herron, Jessica and schraefel, m.c.},
title = {TouchViz: A Case Study Comparing Two Interfaces for Data Analytics on Tablets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481318},
doi = {10.1145/2470654.2481318},
abstract = {As more applications move from the desktop to touch devices like tablets, designers must wrestle with the costs of porting a design with as little revision of the UI as possible from one device to the other, or of optimizing the interaction per device. We consider the tradeoffs between two versions of a UI for working with data on a touch tablet. One interface is based on using the conventional desktop metaphor (WIMP) with a control panel, push buttons, and checkboxes -- where the mouse click is effectively replaced by a finger tap. The other interface (which we call FLUID) eliminates the control panel and focuses touch actions on the data visualization itself. We describe our design process and evaluation of each interface. We discuss the significantly better task performance and preference for the FLUID interface, in particular how touch design may challenge certain assumptions about the performance benefits of WIMP interfaces that do not hold on touch devices, such as the superiority of gestural vs. control panel based interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2301–2310},
numpages = {10},
keywords = {user studies, touch displays, gesture interfaces, data visualization.},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481319,
author = {Nebeling, Michael and Speicher, Maximilian and Norrie, Moira},
title = {W3touch: Metrics-Based Web Page Adaptation for Touch},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481319},
doi = {10.1145/2470654.2481319},
abstract = {Web designers currently face the increased proliferation and diversity of new touch devices which pose major challenges to the design task. This paper presents W3Touch - an interface instrumentation toolkit for web designers to collect user performance data for different device characteristics in order to help them identify potential design problems for touch interaction. Web designers can visualise the data aggregated by W3Touch and use simple metrics to automate the adaptation process for many different viewing and interaction contexts. In a series of experiments with web designers and users, we show that W3Touch is able to detect interaction problems that are hard to find using conventional methods and demonstrate how the tool was successfully used to automate the desktop-to-mobile migration of Wikipedia as an example.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2311–2320},
numpages = {10},
keywords = {adaptive interfaces, touch interaction, usability metrics},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481320,
author = {Ogata, Masa and Sugiura, Yuta and Osawa, Hirotaka and Imai, Michita},
title = {FlashTouch: Data Communication through Touchscreens},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481320},
doi = {10.1145/2470654.2481320},
abstract = {FlashTouch is a new technology that enables data communication between touchscreen-based mobile devices and digital peripheral devices. Touchscreen can be used as communication media using visible light and capacitive touch. In this paper, we designed a stylus prototype to describe the concept of FlashTouch. With this prototype, users can easily transfer data from one mobile device to another. It eliminates the complexity associated with data sharing among mobile users, which is currently achieved by online data sharing services or wireless connections for data sharing that need a pairing operation to establish connections between devices. Therefore, it can prove to be of particular significance to people who are not adept at current software services and hardware functions. Finally, we demonstrate the valuable applications in online settlements via mobile device, and data communication for mobile robots.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2321–2324},
numpages = {4},
keywords = {tangible, stylus, mobile, data sharing, touchscreen based communication},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481321,
author = {Roy, Quentin and Malacria, Sylvain and Guiard, Yves and Lecolinet, Eric and Eagan, James},
title = {Augmented Letters: Mnemonic Gesture-Based Shortcuts},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481321},
doi = {10.1145/2470654.2481321},
abstract = {We propose Augmented Letters, a new technique aimed at augmenting gesture-based techniques such as Marking Menus [9] by giving them natural, mnemonic associations. Augmented Letters gestures consist of the initial of command names, sketched by hand in the Unistroke style, and affixed with a straight tail. We designed a tentative touch device interaction technique that supports fast interactions with large sets of commands, is easily discoverable, improves user's recall at no speed cost, and supports fluid transition from novice to expert mode. An experiment suggests that Augmented Letters outperform Marking Menu in terms of user recall.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2325–2328},
numpages = {4},
keywords = {semantics, gestures, learning, handwriting, recall, unistroke},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250139,
author = {Bunt, Andrea},
title = {Session Details: Papers: Data Navigation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250139},
doi = {10.1145/3250139},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481323,
author = {Fitchett, Stephen and Cockburn, Andy and Gutwin, Carl},
title = {Improving Navigation-Based File Retrieval},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481323},
doi = {10.1145/2470654.2481323},
abstract = {Navigating through a file hierarchy is one of the most common methods for accessing files, yet it can be slow and repetitive. New algorithms that predict upcoming file accesses have the potential to improve navigation-based file retrieval, but it is unknown how best to present their predictions to users. We present three design goals aiming to improve navigation-based file retrieval interfaces: minimise the time spent at each hierarchical level en route to the target file; reduce the number of levels traversed by providing shortcuts; and promote rehearsal of the retrieval mechanics to facilitate expertise. We introduce three interfaces that augment standard file browsers based on each of these goals: Icon Highlights give greater prominence to predicted items in the current folder; Hover Menus provide shortcuts to predicted folder content; and Search Directed Navigation uses predictive highlighting to guide users through the hierarchy in response to query terms. Results from a user evaluation show that all three interfaces improve file retrieval times, with Icon Highlights and Hover Menus best suited for frequently accessed items and Search Directed Navigation best suited for infrequent ones. We also show that the benefits are larger when folder content is spatially unstable. Finally, we discuss how the interfaces could be combined and deployed in existing file browsers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2329–2338},
numpages = {10},
keywords = {prediction, file retrieval, file navigation, revisitation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481324,
author = {Van Kleek, Max and Smith, Daniel A. and Packer, Heather S. and Skinner, Jim and Shadbolt, Nigel R.},
title = {Carp\'{e} Data: Supporting Serendipitous Data Integration in Personal Information Management},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481324},
doi = {10.1145/2470654.2481324},
abstract = {The information processing capabilities of humans enable them to opportunistically draw and integrate knowledge from nearly any information source. However, the integration of digital, structured data from diverse sources remains difficult, due to problems of heterogeneity that arise when data modelled separately are brought together. In this paper, we present an investigation of the feasibility of extending Personal Information Management (PIM) tools to support lightweight, user-driven mixing of previously un-integrated data, with the objective of allowing users to take advantage of the emerging ecosystems of structured data currently becoming available. In this study, we conducted an exploratory, sequential, mixed-method investigation, starting with two pre-studies of the data integration needs and challenges, respectively, of Web-based data sources. Observations from these pre-studies led to DataPalette, an interface that introduced simple co-reference and group multi-path-selection mechanisms for working with terminologically and structurally heterogeneous data. Our lab study showed that participants readily understood the new interaction mechanisms which were introduced. Participants made more carefully justified decisions, even while weighing a greater number of factors, moreover expending less effort, during subjective-choice tasks when using DataPalette, than with a control set-up.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2339–2348},
numpages = {10},
keywords = {sensemaking with data, end-user data integration, personal information management, mash-ups},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481325,
author = {Monroe, Megan and Lan, Rongjian and Morales del Olmo, Juan and Shneiderman, Ben and Plaisant, Catherine and Millstein, Jeff},
title = {The Challenges of Specifying Intervals and Absences in Temporal Queries: A Graphical Language Approach},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481325},
doi = {10.1145/2470654.2481325},
abstract = {In our burgeoning world of ubiquitous sensors and affordable data storage, records of timestamped events are being produced across nearly every domain of personal and professional computing. The resulting data surge has created an overarching need to search these records for meaningful patterns of events. This paper reports on a two-part user study, as well as a series of early tests and interviews with clinical researchers, that informed the development of two temporal query interfaces: a basic, menu-based interface and an advanced, graphic-based interface. While the scope of temporal query is very broad, this work focuses on two particularly complex and critical facets of temporal event sequences: intervals (events with both a start time and an end time), and the absence of an event. We describe how users encounter a common set of difficulties when specifying such queries, and propose solutions to help overcome them. Finally, we report on two case studies with epidemiologists at the US Army Pharmacovigilance Center, illustrating how both query interfaces were used to study patterns of drug use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2349–2358},
numpages = {10},
keywords = {event sequences, query interfaces, temporal query, electronic health records., query languages},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481326,
author = {Liao, Q. Vera and Fu, Wai-Tat},
title = {Beyond the Filter Bubble: Interactive Effects of Perceived Threat and Topic Involvement on Selective Exposure to Information},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481326},
doi = {10.1145/2470654.2481326},
abstract = {We investigated participants' preferential selection of information and their attitude moderation in an online environment. Results showed that even when opposing views were presented side-to-side, people would still preferentially select information that reinforced their existing attitudes. Preferential selection of information was, however, influenced by both situational (e.g., perceived threat) and personal (e.g., topic involvement) factors. Specifically, perceived threat induced selective exposure to attitude consistent information for topics that participants had low involvement. Participants had a higher tendency to select peer user opinions in topics that they had low than high involvement, but only when there was no perception of threat. Overall, participants' attitudes were moderated after being exposed to diverse views, although high topic involvement led to higher resistance to such moderation. Perceived threat also weakened attitude moderation, especially for low involvement topics. Results have important implication to the potential effects of "information bubble" - selective exposure can be induced by situational and personal factors even when competing views are presented side-by-side.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2359–2368},
numpages = {10},
keywords = {peer opinions, filter bubble, perceived threat, information seeking, attitude change, topic involvement},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250140,
author = {Oakley, Ian},
title = {Session Details: Papers: Passwords and Errors},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250140},
doi = {10.1145/3250140},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481328,
author = {Egelman, Serge},
title = {My Profile is My Password, Verify Me! The Privacy/Convenience Tradeoff of Facebook Connect},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481328},
doi = {10.1145/2470654.2481328},
abstract = {We performed a laboratory experiment to study the privacy tradeoff offered by Facebook Connect: disclosing Facebook profile data to third-party websites for the convenience of logging in without creating separate accounts. We controlled for trustworthiness and amount of information each website requested, as well as the consent dialog layout. We discovered that these factors had no observable effects, likely because participants did not read the dialogs. Yet, 15% still refused to use Facebook Connect, citing privacy concerns. A likely explanation for subjects ignoring the dialogs while also understanding the privacy tradeoff - our exit survey indicated that 88% broadly understood what data would be collected - is that subjects were already familiar with the dialogs prior to the experiment. We discuss how our results demonstrate informed consent, but also how habituation prevented subjects from understanding the nuances between individual websites' data collection policies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2369–2378},
numpages = {10},
keywords = {facebook connect, privacy, user study},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481329,
author = {Egelman, Serge and Sotirakopoulos, Andreas and Muslukhov, Ildar and Beznosov, Konstantin and Herley, Cormac},
title = {Does My Password Go up to Eleven? The Impact of Password Meters on Password Selection},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481329},
doi = {10.1145/2470654.2481329},
abstract = {Password meters tell users whether their passwords are "weak" or "strong." We performed a laboratory experiment to examine whether these meters influenced users' password selections when they were forced to change their real passwords, and when they were not told that their passwords were the subject of a study. We observed that the presence of meters yielded significantly stronger passwords. We performed a followup field experiment to test a different scenario: creating a password for an unimportant account. In this scenario, we found that the meters made no observable difference: participants simply reused weak passwords that they used to protect similar low-risk accounts. We conclude that meters result in stronger passwords when users are forced to change existing passwords on "important" accounts and that individual meter design decisions likely have a marginal impact.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2379–2388},
numpages = {10},
keywords = {user study, security, passwords},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2481329_R49567,
author = {Olagunju, Amos O},
title = {Review ID:R49567 for DOI: 10.1145/2470654.2481329},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2481329_R49567}
}

@inproceedings{10.1145/2470654.2481330,
author = {De Luca, Alexander and von Zezschwitz, Emanuel and Nguyen, Ngo Dieu Huong and Maurer, Max-Emanuel and Rubegni, Elisa and Scipioni, Marcello Paolo and Langheinrich, Marc},
title = {Back-of-Device Authentication on Smartphones},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481330},
doi = {10.1145/2470654.2481330},
abstract = {This paper presents BoD Shapes, a novel authentication method for smartphones that uses the back of the device for input. We argue that this increases the resistance to shoulder surfing while remaining reasonably fast and easy-to-use. We performed a user study (n=24) comparing BoD Shapes to PIN authentication, Android grid unlock, and a front version of our system. Testing a front version allowed us to directly compare performance and security measures between front and back authentication. Our results show that BoD Shapes is significantly more secure than the three other approaches. While performance declined, our results show that BoD Shapes can be very fast (up to 1.5 seconds in the user study) and that learning effects have an influence on its performance. This indicates that speed improvements can be expected in long-term use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2389–2398},
numpages = {10},
keywords = {authentication, security, back of device interaction},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481331,
author = {De Luca, Alexander and von Zezschwitz, Emanuel and Pichler, Laurent and Hussmann, Heinrich},
title = {Using Fake Cursors to Secure On-Screen Password Entry},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481331},
doi = {10.1145/2470654.2481331},
abstract = {In this paper, we present a concept using fake cursors to disguise on-screen password entry. We performed two user studies with different amounts of dummy cursors and differently colored cursors. The results show that dummy cursors significantly improve security. At the same time, decrease in performance is kept within an acceptable range. Depending on the required degree of security, the studies favor 8 or 16 differently colored cursors as the best trade-off between security and usability.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2399–2402},
numpages = {4},
keywords = {authentication, security, ninja cursors},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481332,
author = {Wiseman, Sarah and Cox, Anna L. and Brumby, Duncan P. and Gould, Sandy J.J. and O'Carroll, Sarah},
title = {Using Checksums to Detect Number Entry Error},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481332},
doi = {10.1145/2470654.2481332},
abstract = {Number entry is a common task in many domains. In safety-critical environments such as air traffic control or on hospital wards, incorrect number entry can have serious harmful consequences. Research has investigated how interface designs can help prevent users from making number entry errors. In this paper, we present an experimental evaluation of two possible interface designs aimed at helping users detect number entry errors using the idea of a checksum: an additional (redundant) number that is related to the to-be-entered numbers in such a way that it is sufficient to verify the correctness of the checksum, as opposed to checking each of the entered numbers. The first interface requires users to check their own work with the help of the checksum; the second requires the user to enter the checksum along with the other numbers so that the system can do the checking. In each case, two numbers needed to be entered, while the third number served as a checksum. With the first interface, users caught only 36% of their errors. The second interface resulted in all errors being caught, but the need to enter the checksum increased entry time by 46%. When participants were allowed to choose between the two interfaces, they chose the second interface in only 12% of the cases. Although these results cannot be generalized to other specific contexts, the results illustrate the strengths and weaknesses of each way of using checksums to catch number entry errors. Hence our study can serve as a starting point for efforts to improve each method.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2403–2406},
numpages = {4},
keywords = {redundancy, checksums, error detection, number entry},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250141,
author = {Brereton, Margot},
title = {Session Details: Papers: Social Tagging},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250141},
doi = {10.1145/3250141},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481334,
author = {Kulkarni, Chinmay and Chi, Ed},
title = {All the News That's Fit to Read: A Study of Social Annotations for News Reading},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481334},
doi = {10.1145/2470654.2481334},
abstract = {As news reading becomes more social, how do different types of annotations affect people's selection of news articles? This paper reports on results from two experiments looking at social annotations in two different news reading contexts. The first experiment simulates a logged-out experience with annotations from strangers, a computer agent, and a branded company. Results indicate that, perhaps unsurprisingly, annotations by strangers have no persuasive effects. However, surprisingly, unknown branded companies still had a persuasive effect. The second experiment simulates a logged-in experience with annotations from friends, finding that friend annotations are both persuasive and improve user satisfaction over their article selections. In post-experiment interviews, we found that this increased satisfaction is due partly because of the context that annotations add. That is, friend annotations both help people decide what to read, and provide social context that improves engagement. Interviews also suggest subtle expertise effects. We discuss implications for design of social annotation systems and suggestions for future research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2407–2416},
numpages = {10},
keywords = {experiment, news reading, social computing, user study, recommendations, social annotation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481335,
author = {Hillman, Serena and Neustaedter, Carman and Pang, Carolyn and Oduor, Erick},
title = {"Shared Joy is Double Joy": The Social Practices of User Networks within Group Shopping Sites},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481335},
doi = {10.1145/2470654.2481335},
abstract = {Group shopping sites are beginning to rise in popularity amongst eCommerce users. Yet we do not know how or why people are using such sites, and whether or not the design of group shopping sites map to the real shopping needs of end users. To address this, we describe an interview study that investigates the friendship networks of people who participate in group shopping sites (e.g., Groupon) with the goal of understanding how to best design for these experiences. Our results show that group shopping sites are predominently used to support social activities; that is, users do not use them first and foremost to find 'deals'. Instead, group shopping sites are used for planning group activities, extending and building friendships, and constructing one's social identity. Based on these findings, we suggest improved social network integration and impression management tools to improve user experience within group shopping sites.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2417–2426},
numpages = {10},
keywords = {impression management, group shopping, social shopping, ecommerce, group buying, social commerce, user interfaces, user-centered design, shopping},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481336,
author = {Gilbert, Eric and Bakhshi, Saeideh and Chang, Shuo and Terveen, Loren},
title = {"I Need to Try This"? A Statistical Overview of Pinterest},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481336},
doi = {10.1145/2470654.2481336},
abstract = {Over the past decade, social network sites have become ubiquitous places for people to maintain relationships, as well as loci of intense research interest. Recently, a new site has exploded into prominence: Pinterest became the fastest social network to reach 10M users, growing 4000% in 2011 alone. While many Pinterest articles have appeared in the popular press, there has been little scholarly work so far. In this paper, we use a quantitative approach to study three research questions about the site. What drives activity on Pinterest? What role does gender play in the site's social connections? And finally, what distinguishes Pinterest from existing networks, in particular Twitter? In short, we find that being female means more repins, but fewer followers, and that four verbs set Pinterest apart from Twitter: use, look, want and need. This work serves as an early snapshot of Pinterest that later work can leverage.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2427–2436},
numpages = {10},
keywords = {pinterest, cmc, twitter, social network sites},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250142,
author = {Isbister, Katherine},
title = {Session Details: Papers: Food and Health},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250142},
doi = {10.1145/3250142},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481338,
author = {Parker, Andrea Grimes and McClendon, Ian and Grevet, Catherine and Ayo, Victoria and Chung, WonTaek and Johnson, Veda and Mynatt, Elizabeth D.},
title = {I Am What i Eat: Identity &amp; Critical Thinking in an Online Health Forum for Kids},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481338},
doi = {10.1145/2470654.2481338},
abstract = {As kids encounter food advertisements, it is important that they be able to critically evaluate the message's claims, the healthiness of the promoted product and their desire for it. To explore how technology might help kids develop these skills, we created an online forum called TalkBack that encourages children to critically analyze the messaging in food ads and their attitudes towards marketed foods. We evaluated TalkBack with twenty-eight middle school students in a summer camp program. We discuss how participants appeared to project and protect their sense of self through their interaction with TalkBack. We also describe the limited analytic depth of their forum contributions and suggest directions for HCI research that attempts to encourage critical thinking and health promotion in adolescents.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2437–2446},
numpages = {10},
keywords = {online community, cscw, health, kids, identity, nutrition},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481339,
author = {Clear, Adrian K. and Hazas, Mike and Morley, Janine and Friday, Adrian and Bates, Oliver},
title = {Domestic Food and Sustainable Design: A Study of University Student Cooking and Its Impacts},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481339},
doi = {10.1145/2470654.2481339},
abstract = {In four university student kitchens over twenty-one days, we captured participants' food preparation activity, quantified the greenhouse gas emissions and direct energy connected to the food and cooking, and talked to participants about their food practices. Grounded in this uniquely detailed micro-account, our findings inform sustainable design for cooking and eating at home and quantify the potential impacts. We outline the relation of the impacts to our participants' approaches to everyday food preparation, the organisation of their time, and the role of social meals. Our technique allows evaluation of opportunities for sustainable intervention design: at the appliance, in the digitally-mediated organisation of meals and inventory management, and more broadly in reflecting upon and reshaping diet.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2447–2456},
numpages = {10},
keywords = {food, greenhouse gas, practices, everyday life, sustainability, energy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481340,
author = {Comber, Rob and Hoonhout, Jettie and van Halteren, Aart and Moynihan, Paula and Olivier, Patrick},
title = {Food Practices as Situated Action: Exploring and Designing for Everyday Food Practices with Households},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481340},
doi = {10.1145/2470654.2481340},
abstract = {Household food practices are complex. Many people are unable to effectively respond to challenges in their food environment to maintain diets considered to be in line with national and international standards for healthy eating. We argue that recognizing food practices as situated action affords opportunities to identify and design for practiced, local and achievable solutions to such food problems. Interviews and shop-a-longs were carried as part of a contextual inquiry with ten households. From this, we identify food practices, such as fitting food, stocking up, food value transitions, and having fun with others and how these practices are enacted in different ways with varied outcomes. We explore how HCI might respond to these practices through issues of social fooding, the presence of others, conceptions about food practices and food routines.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2457–2466},
numpages = {10},
keywords = {situated action, health, food, everyday practice},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481341,
author = {Orji, Rita and Mandryk, Regan L. and Vassileva, Julita and Gerling, Kathrin M.},
title = {Tailoring Persuasive Health Games to Gamer Type},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481341},
doi = {10.1145/2470654.2481341},
abstract = {Persuasive games are an effective approach for motivating health behavior, and recent years have seen an increase in games designed for changing human behaviors or attitudes. However, these games are limited in two major ways: first, they are not based on theories of what motivates healthy behavior change. This makes it difficult to evaluate why a persuasive approach works. Second, most persuasive games treat players as a monolithic group. As an attempt to resolve these weaknesses, we conducted a large-scale survey of 642 gamers' eating habits and their associated determinants of healthy behavior to understand how health behavior relates to gamer type. We developed seven different models of healthy eating behavior for the gamer types identified by BrainHex. We then explored the differences between the models and created two approaches for effective persuasive game design based on our results. The first is a one-size-fits-all approach that will motivate the majority of the population, while not demotivating any players. The second is a personalized approach that will best motivate a particular type of gamer. Finally, to make our approaches actionable in persuasive game design, we map common game mechanics to the determinants of healthy behavior.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2467–2476},
numpages = {10},
keywords = {behavior theory, persuasive game, serious games, hbm, health, player typology, gamer types, games design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250143,
author = {Consolvo, Sunny},
title = {Session Details: Papers: Mobile Applications},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250143},
doi = {10.1145/3250143},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481343,
author = {Sen, Soumya and Joe-Wong, Carlee and Ha, Sangtae and Bawa, Jasika and Chiang, Mung},
title = {When the Price is Right: Enabling Time-Dependent Pricing of Broadband Data},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481343},
doi = {10.1145/2470654.2481343},
abstract = {In an era of 108% annual growth in demand for mobile data and $10/GB overage fees, Internet Service Providers (ISPs) are experiencing severe congestion and in turn are hurting consumers with aggressive pricing measures. But smarter practices, such as time-dependent pricing (TDP), reward users for shifting their non-critical demand to off-peak hours and can potentially benefit both users and ISPs. Although dynamic TDP ideas have existed for many years, dynamic pricing for mobile data is only now gaining interest among ISPs. Yet TDP plans require not only systems engineering but also an understanding of economic incentives, user behavior and interface design. In particular, the HCI aspects of communicating price feedback signals from the network and the response of mobile data users need to be studied in the real world. But investigating these issues by deploying a virtual TDP data plan for real ISP customers is challenging and rarely explored. To this end, we carried out the first TDP trial for mobile data in the US with 10 families. We describe the insights gained from the trial, which can help the HCI community as well as ISPs, app developers and designers create tools that empower users to better control their usage and save on their monthly bills, while also alleviating network congestion.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2477–2486},
numpages = {10},
keywords = {economics, dynamic pricing, time- and usage-based pricing, mobile application interface, broadband access pricing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481344,
author = {de Sa, Marco and Navalpakkam, Vidhya and Churchill, Elizabeth F.},
title = {Mobile Advertising: Evaluating the Effects of Animation, User and Content Relevance},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481344},
doi = {10.1145/2470654.2481344},
abstract = {The potential for user-relevant, context-appropriate, targeted advertising on mobile devices is enormous given device improvements and advances in personal and location-based data collection. However, little is known about how users experience display advertisements ('ads') on mobile devices, or what factors drive mobile ad effectiveness. In this paper, we investigate users' experiences of display advertising on mobile devices. We consider three factors that are often studied in desktop settings the ad's level of personal relevance to the user, its relevance to the page content, and within-ad properties, with a particular focus on the level of animation in the ad. Our findings reveal a few surprises. First, personal relevance to the user has little or no impact on ad efficacy measured by recall. Instead, content relevance boosts ad recall. Second, user relevance leads to a more pleasant and interesting experience, but content relevance has no effect. Third, contrary to the popular notion that animation often leads to more effective ads by garnering more user attention, we find that a simple type of animation, such as blinking animation, negatively affects user experience and reduces ad recall. Our findings, while focused on advertising, offer insights for design of mobile content presentation in general.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2487–2496},
numpages = {10},
keywords = {relevance, evaluation, mobile devices, advertising, user experience, animation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481345,
author = {Lawson, Shaun and Jamison-Powell, Sue and Garbett, Andrew and Linehan, Conor and Kucharczyk, Erica and Verbaan, Sanne and Rowland, Duncan A. and Morgan, Kevin},
title = {Validating a Mobile Phone Application for the Everyday, Unobtrusive, Objective Measurement of Sleep},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481345},
doi = {10.1145/2470654.2481345},
abstract = {There is an identified need for objective, reliable, and scalable methods of measuring and recording sleep. Such methods must be designed for easy integration into people's lives in order to support both sleep therapy and everyday personal informatics. This paper describes the design and evaluation of a mobile phone application to record sleep, the design of which has substantive foundation in clinical sleep research. Two user studies were carried out which demonstrate that the application produces valid measurements of sleep quality and high levels of usability, whilst not seriously disturbing sleep or the sleep environment. These findings suggest that the app is suitable for both everyday sleep monitoring in a personal informatics context, and for integration into sleep interventions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2497–2506},
numpages = {10},
keywords = {sleep, insomnia, personal informatics, mobile computing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250144,
author = {Bardzell, Jeffrey},
title = {Session Details: Papers: Crime and Conflicts},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250144},
doi = {10.1145/3250144},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481347,
author = {Erete, Sheena Lewis},
title = {Protecting the Home: Exploring the Roles of Technology and Citizen Activism from a Burglar's Perspective},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481347},
doi = {10.1145/2470654.2481347},
abstract = {For decades, HCI scholars have designed technology for the domestic space. Many of these systems aim to protect the home and its residents by requesting help from local authorities during emergency situations. While the use of these systems have been examined, few studies attempt to understand the behavior of potential offenders who can create such emergency situations (e.g., by attempting a burglary). This paper analyzes three panel sessions with 15 people who have been convicted of burglarizing homes, cars, and/or businesses. Participants describe in detail what they looked for when deciding to burglarize a home and what deterred them. Technologies such as security systems, alarms, and cameras do not dissuade burglars. Instead, evidence of neighborhood cohesion was named the strongest deterrent. This paper presents implications for designing technologies that will effectively discourage burglary and support citizen activism.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2507–2516},
numpages = {10},
keywords = {burglary, crime prevention technology, domestic space},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481348,
author = {Clarke, Rachel and Wright, Peter and Balaam, Madeline and McCarthy, John},
title = {Digital Portraits: Photo-Sharing after Domestic Violence},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481348},
doi = {10.1145/2470654.2481348},
abstract = {This paper explores how technology could support the re-building of lives after domestic violence. We worked in the context of a women's centre where women are accessing support after leaving abusive relationships. The paper contributes a feminist participatory arts action research approach to studying photo-sharing practices and helps to frame an understanding of the ongoing tensions in the construction of self with others that the women experience. We argue that the affirmation of new bonds, control in sharing the process of 'moving on', and supporting discursive negotiations of privacy are important considerations for design focused on interpersonal social processes around the use of digital technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2517–2526},
numpages = {10},
keywords = {action research, domestic violence, photo-sharing, participation, privacy, feminism},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481349,
author = {Yoo, Daisy and Lake, Milli and Nilsen, Trond and Utter, Molly E. and Alsdorf, Robert and Bizimana, Theoneste and Nathan, Lisa P. and Ring, Mark and Utter, Elizabeth J. and Utter, Robert F. and Friedman, Batya},
title = {Envisioning across Generations: A Multi-Lifespan Information System for International Justice in Rwanda},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481349},
doi = {10.1145/2470654.2481349},
abstract = {With this research we investigate how to account for multi-generational perspectives in the design of multi-lifespan information systems, particularly in support of long-term peace-building and international justice. We do our work in the context of the publicly available Voices from the Rwanda Tribunal testbed, a historically significant collection of video interviews with personnel from the International Criminal Tribunal for Rwanda. In the research reported here, we worked with 109 Rwandan adults and youth from perpetrator and survivor communities in three provincial cities in Rwanda (Byumba, Kibuye, and Gisenyi) to understand the potentials and challenges they envision for the interview collection. Participants envisioned five categories of long-term positive outcomes for individuals and society from a multi-lifespan information system for the interview collection; and eight categories of challenges to realize those potential outcomes. In terms of multi-generational perspectives, while adults and youth tended to share an overall vision for the long-term potential of such a system, adults emphasized actionable tasks while youth educational benefits. Based on the findings, we highlight issues for appropriation of multi-lifespan information systems and reflect on our methods for eliciting multi-generational perspectives on information system design in a post-conflict society.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2527–2536},
numpages = {10},
keywords = {multi-lifespan information system design, cyclical violence, generational perspectives, peace-building, justice, cultural sensitivity, value sensitive design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481350,
author = {Pritchard, Gary W. and Vines, John},
title = {Digital Apartheid: An Ethnographic Account of Racialised Hci in Cape Town Hip-Hop},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481350},
doi = {10.1145/2470654.2481350},
abstract = {We describe findings from a 15-month ethnography of hip-hop performers in Cape Town, South Africa. Mobile communications and social media are hugely important to the development of these performers' careers, opening access to collaborators, production tools, audiences and distribution channels. This group go to extraordinary lengths to gain and maintain access to these technologies, often by exploiting their social capital through musical and ethnic networks. We document that even after nearly twenty years of democracy, a ridged separation along racial lines persists, which can be seen in all areas of life including access to and proficiency in digital technologies. We illustrate how hip-hop performers harness these divisions both on and offline in order to distinguish themselves from other artists. Our research raises a number of implications for post-colonial computing, highlighting difficulties related to discontinuous access, and how international preconceptions of identity and authenticity emerge as a consequence of the increased use of communication technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2537–2546},
numpages = {10},
keywords = {south africa, music-making, racial inequality, identity, hip-hop, hci4d},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250145,
author = {Yatani, Koji},
title = {Session Details: Papers: Haptics},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250145},
doi = {10.1145/3250145},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481352,
author = {Roudaut, Anne and Rau, Andreas and Sterz, Christoph and Plauth, Max and Lopes, Pedro and Baudisch, Patrick},
title = {Gesture Output: Eyes-Free Output Using a Force Feedback Touch Surface},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481352},
doi = {10.1145/2470654.2481352},
abstract = {We propose using spatial gestures not only for input but also for output. Analogous to gesture input, the proposed gesture output moves the user's finger in a gesture, which the user then recognizes. We use our concept in a mobile scenario where a motion path forming a "5" informs users about new emails, or a heart-shaped path serves as a mes- sage from a friend. We built two prototypes: (1) The long- RangeOuija is a stationary prototype that offers a motion range of up to 4cm; (2) The pocketOuija is self-contained mobile device based on an iPhone with up to 1cm motion range. Both devices actuate the user's fingers by means of an actuated transparent foil overlaid onto a touchscreen. We conducted three studies with the longRangeOuija in which participants recognized 2cm marks with 97% accu- racy, Graffiti digits with 98.8%, pairs of Graffiti digits with 90.5%, and Graffiti letters with 93.4%. Participants previ- ously unfamiliar with Graffiti identified 96.2% of digits and 76.4% of letters, suggesting that properly designed gesture output is guessable. After the experiment, the same participants were able to enter 100% of Graffiti digits by heart and 92.2% of letters. This suggests that participants learned gesture input as a side effect of using gesture output on our prototypes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2547–2556},
numpages = {10},
keywords = {eyes free, gestures, force feedback, touch},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481353,
author = {Fan, Kevin and Izumi, Hideyuki and Sugiura, Yuta and Minamizawa, Kouta and Wakisaka, Sohei and Inami, Masahiko and Fujii, Naotaka and Tachi, Susumu},
title = {Reality Jockey: Lifting the Barrier between Alternate Realities through Audio and Haptic Feedback},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481353},
doi = {10.1145/2470654.2481353},
abstract = {We present Reality Jockey, a system that confuses the participant's perception of the reality by mixing in a recorded past-reality. The participant will be immersed in a spatialized 3D sound environment that is a mix of sounds from the reality and from the past. The sound environment from the past is augmented with haptic feedback in cross-modality. The haptic feedback is associated with certain sounds such as the vibration in the table when stuff is placed on the table to make the illusion of it happening in live. The seamless transition between live and past creates immersive experience of past events. The blending of live and past allows interactivity. To validate our system, we conducted user studies on 1) does blending live sensations improve such experiences, and 2) how beneficial is it to provide haptic feedbacks in recorded pasts. Potential applications are suggested to illustrate the significance of Reality Jockey.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2557–2566},
numpages = {10},
keywords = {substitutional reality, spatial sound, illusion, haptic, cross-modality},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481354,
author = {Lee, Jaebong and Choi, Seungmoon},
title = {Real-Time Perception-Level Translation from Audio Signals to Vibrotactile Effects},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481354},
doi = {10.1145/2470654.2481354},
abstract = {In this paper, we propose a real-time perception-level audio-to-vibrotactile translation algorithm. Unlike previous signal-level conversion methods, our algorithm considers only perceptual characteristics, such as loudness and roughness, of audio and tactile stimuli. This perception-level approach allows for designing intuitive and explicit conversion models with clear understandings of their perceptual consequences. Our current implementation is tailored to accurate detection of special sound effects to provide well-synchronized audio-tactile feedback in immersive applications. We also assessed the performance of our translation algorithm in terms of the detection rate of special sound effects, computational performance, and user preference. All the experimental results supported that our algorithm works well as intended with better performance than the signal-level conversion methods, especially for games. Our algorithm can be easily realized in current products, including mobile devices, gaming devices, and 4D home theater systems, for richer user experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2567–2576},
numpages = {10},
keywords = {perceived roughness, perceived intensity, haptics, vibrotactile effect, automatic conversion, audio},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481355,
author = {Lopes, Pedro and Baudisch, Patrick},
title = {Muscle-Propelled Force Feedback: Bringing Force Feedback to Mobile Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481355},
doi = {10.1145/2470654.2481355},
abstract = {Force feedback devices resist miniaturization, because they require physical motors and mechanics. We propose mobile force feedback by eliminating motors and instead actuating the user's muscles using electrical stimulation. Without the motors, we obtain substantially smaller and more energy-efficient devices. We present a prototype that fits on the back of a mobile phone. It actuates users' forearm muscles via four electrodes, which causes users' muscles to contract involuntarily, so that they tilt the device sideways. As users resist this motion using their other arm, they perceive force feedback. We demonstrate the interaction at the example of an interactive videogame in which users steer an airplane through winds rendered using force feedback. In a first user study, we found our device to cause users to produce up to 18.7N of force, when used to actuate their palm flexors. In a second study, participants played the video game de-scribed above; all ten participants reported to prefer the experience of muscle-propelled force feedback to vibrotactile feedback.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2577–2580},
numpages = {4},
keywords = {mobile, force feedback, ems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481356,
author = {Chen, Ke-Yu and Cohn, Gabe A. and Gupta, Sidhant and Patel, Shwetak N.},
title = {UTouch: Sensing Touch Gestures on Unmodified LCDs},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481356},
doi = {10.1145/2470654.2481356},
abstract = {Current solutions for enabling touch interaction on existing non-touch LCD screens require adding additional sensors to the interaction surface. We present uTouch, a system that detects and classifies touches and hovers without any modification to the display, and without adding any sensors to the user. Our approach utilizes existing signals in an LCD that are amplified when a user brings their hand near or touches the LCD's front panel. These signals are coupled onto the power lines, where they appear as electromagnetic interference (EMI) which can be sensed using a single device connected elsewhere on the power line infrastructure. We validate our approach with an 11 user, 8 LCD study, and demonstrate a real-time system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2581–2584},
numpages = {4},
keywords = {lcd, capacitive sensing, touch, emi},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250146,
author = {Olwal, Alex},
title = {Session Details: Papers: Fabrication},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250146},
doi = {10.1145/3250146},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481358,
author = {Mueller, Stefanie and Kruck, Bastian and Baudisch, Patrick},
title = {LaserOrigami: Laser-Cutting 3D Objects},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481358},
doi = {10.1145/2470654.2481358},
abstract = {We present LaserOrigami, a rapid prototyping system that produces 3D objects using a laser cutter. LaserOrigami is substantially faster than traditional 3D fabrication techniques such as 3D printing and unlike traditional laser cutting the resulting 3D objects require no manual assembly. The key idea behind LaserOrigami is that it achieves three-dimensionality by folding and stretching the workpiece, rather than by placing joints, thereby eliminating the need for manual assembly. LaserOrigami achieves this by heating up selected regions of the workpiece until they become compliant and bend down under the force of gravity. LaserOrigami administers the heat by defocusing the laser, which distributes the laser's power across a larger surface. LaserOrigami implements cutting and bending in a single integrated process by automatically moving the cutting table up and down--when users take out the workpiece, it is already fully assembled. We present the three main design elements of LaserOrigami: the bend, the suspender, and the stretch, and demonstrate how to use them to fabricate a range of physical objects. Finally, we demonstrate an interactive fabrication version of LaserOrigami, a process in which user interaction and fabrication alternate step-by-step.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2585–2592},
numpages = {8},
keywords = {physical prototyping, 3d, interactive fabrication, rapid prototyping, laser cutting},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481359,
author = {Jansen, Yvonne and Dragicevic, Pierre and Fekete, Jean-Daniel},
title = {Evaluating the Efficiency of Physical Visualizations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481359},
doi = {10.1145/2470654.2481359},
abstract = {Data sculptures are an increasingly popular form of physical visualization whose purposes are essentially artistic, communicative or educational. But can physical visualizations help carry out actual information visualization tasks? We present the first infovis study comparing physical to on-screen visualizations. We focus on 3D visualizations, as these are common among physical visualizations but known to be problematic on computers. Taking 3D bar charts as an example, we show that moving visualizations to the physical world can improve users' efficiency at information retrieval tasks. In contrast, augmenting on-screen visualizations with stereoscopic rendering alone or with prop-based manipulation was of limited help. The efficiency of physical visualizations seems to stem from features that are unique to physical objects, such as their ability to be touched and their perfect visual realism. These findings provide empirical motivation for current research on fast digital fabrication and self-reconfiguring interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2593–2602},
numpages = {10},
keywords = {evaluation, physical visualization, 3d visualization},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481360,
author = {Tanenbaum, Joshua G. and Williams, Amanda M. and Desjardins, Audrey and Tanenbaum, Karen},
title = {Democratizing Technology: Pleasure, Utility and Expressiveness in DIY and Maker Practice},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481360},
doi = {10.1145/2470654.2481360},
abstract = {DIY, hacking, and craft have recently drawn attention in HCI and CSCW, largely as a collaborative and creative hobbyist practice. We shift the focus from the recreational elements of this practice to the ways in which it democratizes design and manufacturing. This democratized technological practice, we argue, unifies playfulness, utility, and expressiveness, relying on some industrial infrastructures while creating demand for new types of tools and literacies. Thriving on top of collaborative digital systems, the Maker movement both implicates and impacts professional designers. As users move more towards personalization and reappropriation, new design opportunities are created for HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2603–2612},
numpages = {10},
keywords = {craft, steampunk, appropriation, hacking, design theory, maker culture, diy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481361,
author = {Zoran, Amit and Paradiso, Joseph A.},
title = {FreeD: A Freehand Digital Sculpting Tool},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481361},
doi = {10.1145/2470654.2481361},
abstract = {In this paper, we present an approach to combining digital fabrication and craft, emphasizing the user experience. While many researchers strive to enable makers to design and produce 3D objects, our research seeks to present a new fabrication approach to make unique, one-of-a-kind artifacts. To that end, we developed the FreeD, a hand-held digital milling device. The system is guided and monitored by a computer while preserving the maker's freedom to sculpt and carve, and to manipulate the work in many creative ways. Relying on a predesigned 3D model, the computer gets into action only when the milling bit risks the object's integrity, by slowing down the spindle's speed or by drawing back the shaft, while the rest of the time it allows complete gestural freedom. We describe the key concepts of our work and its motivation, present the FreeD's architecture and technology, and discuss two projects made with the tool.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2613–2616},
numpages = {4},
keywords = {milling, computer-aided design (cad), craft, carving, digital fabrication},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2481361_R49199,
author = {Ou, Jiawei},
title = {Review ID:R49199 for DOI: 10.1145/2470654.2481361},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2481361_R49199}
}

@inproceedings{10.1145/3250147,
author = {Doherty, Gavin},
title = {Session Details: Papers: Mental Health},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250147},
doi = {10.1145/3250147},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481363,
author = {Wallace, Jayne and Wright, Peter C. and McCarthy, John and Green, David Philip and Thomas, James and Olivier, Patrick},
title = {A Design-Led Inquiry into Personhood in Dementia},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481363},
doi = {10.1145/2470654.2481363},
abstract = {Writers and practitioners in dementia care have invoked personhood to offer potential for preserving the agency of people living with dementia. In this context we use personhood to explore how relationships bring agentive potential to experience-centered design through a co-creative, design-led inquiry with Gillian, a woman living with dementia, and John her husband. We designed bespoke probes to empathically engage the couple in the design of both jewellery and digital jewellery to support Gillian's personhood. Our design activity addressed the relationships involved in the context of Gillian's family life and the progression of her illness and how they could be mediated technologically. Reminiscence became, through Gillian and John's own hands, acts of sense making and legacy. The process of design became the way of conducting the inquiry and the designed artifacts became ways of posing questions to make sense of our experiences together.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2617–2626},
numpages = {10},
keywords = {dementia, personhood, empathy, reflection, reminiscence, probes, self, experience-centered design, memory},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481364,
author = {Bardram, Jakob E. and Frost, Mads and Sz\'{a}nt\'{o}, K\'{a}roly and Faurholt-Jepsen, Maria and Vinberg, Maj and Kessing, Lars Vedel},
title = {Designing Mobile Health Technology for Bipolar Disorder: A Field Trial of the Monarca System},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481364},
doi = {10.1145/2470654.2481364},
abstract = {An increasing number of pervasive healthcare systems are being designed, that allow people to monitor and get feedback on their health and wellness. To address the challenges of self-management of mental illnesses, we have developed the MONARCA system - a personal monitoring system for bipolar patients. We conducted a 14 week field trial in which 12 patients used the system, and we report findings focusing on their experiences. The results were positive; compared to using paper-based forms, the adherence to self-assessment improved; the system was considered very easy to use; and the perceived usefulness of the system was high. Based on this study, the paper discusses three HCI questions related to the design of personal health technologies; how to design for disease awareness and self-treatment, how to ensure adherence to personal health technologies, and the roles of different types of technology platforms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2627–2636},
numpages = {10},
keywords = {mental health, mobile application, bipolar disorder, personal health systems},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481365,
author = {Yamashita, Naomi and Kuzuoka, Hideaki and Hirata, Keiji and Kudo, Takashi},
title = {Understanding the Conflicting Demands of Family Caregivers Caring for Depressed Family Members},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481365},
doi = {10.1145/2470654.2481365},
abstract = {Depression is one of the most common disabilities in developed countries. Despite its often devastating impact on families, scant research has focused on how to facilitate the well-being of family caregivers. The aim of this paper is to uncover the challenges faced by family caregivers and support their well-being with the use of technologies. To understand the emotional and social burden of caregivers and how they handle their stress, we conducted in-depth interviews with 15 individuals who have cared for a depressed family member. Our findings reveal the multifaceted dilemma of caring for a depressed family member as well as the various strategies engaged in by caregivers to improve their own situations. Based on our findings, we suggest design implications for healthcare technologies to improve the wellness of caregivers who are looking after depressed family members.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2637–2646},
numpages = {10},
keywords = {depression, healthcare technology, stress, family caregivers},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481366,
author = {Thieme, Anja and Wallace, Jayne and Johnson, Paula and McCarthy, John and Lindley, Si\^{a}n and Wright, Peter and Olivier, Patrick and Meyer, Thomas D.},
title = {Design to Promote Mindfulness Practice and Sense of Self for Vulnerable Women in Secure Hospital Services},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481366},
doi = {10.1145/2470654.2481366},
abstract = {In the field of mental health care technologies, very limited attention has been given to the design of interventions for individuals who undergo treatment for severe mental health problems in intense care contexts. Exploring novel designs to engage vulnerable psychiatric patients in therapeutic skills practice and expanding on the potential of technology to promote mental health, the paper introduces the design concept of the Spheres of Wellbeing. A set of interactive artifacts is developed specifically for women with a dual diagnosis of a Learning Disability and Borderline Personality Disorder, living in the medium secure services of a forensic hospital in the UK. The women present a difficult to treat group due to extremely challenging behaviors and a fundamental lack of motivation to engage in therapy. The Spheres are designed to assist the women in practices of mindfulness, to help them tolerate emotional distress and to strengthen their sense of self, all of which are vital components of their specialist treatment Dialectical Behavioral Therapy (DBT). The Spheres are intended to supplement the therapy of the women and to contribute to our understanding of designing technology to enhance mental wellbeing and quality of life more generally.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2647–2656},
numpages = {10},
keywords = {mindfulness, materiality, mental wellbeing, sense of self, interaction design, hospital, mental health technology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250148,
author = {Patil, Sameer},
title = {Session Details: Papers: Consent and Privacy},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250148},
doi = {10.1145/3250148},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481368,
author = {Kang, Ruogu and Brown, Stephanie and Kiesler, Sara},
title = {Why Do People Seek Anonymity on the Internet? Informing Policy and Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481368},
doi = {10.1145/2470654.2481368},
abstract = {In this research we set out to discover why and how people seek anonymity in their online interactions. Our goal is to inform policy and the design of future Internet architecture and applications. We interviewed 44 people from America, Asia, Europe, and Africa who had sought anonymity and asked them about their experiences. A key finding of our research is the very large variation in interviewees' past experiences and life situations leading them to seek anonymity, and how they tried to achieve it. Our results suggest implications for the design of online communities, challenges for policy, and ways to improve anonymity tools and educate users about the different routes and threats to anonymity on the Internet.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2657–2666},
numpages = {10},
keywords = {information disclosure, anonymity, privacy, online community},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481369,
author = {Knijnenburg, Bart P. and Kobsa, Alfred and Jin, Hongxia},
title = {Preference-Based Location Sharing: Are More Privacy Options Really Better?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481369},
doi = {10.1145/2470654.2481369},
abstract = {We examine the effect of coarse-grained vs. fine-grained location sharing options on users' disclosure decisions when configuring a sharing profile in a location-sharing service. Our results from an online user experiment (N=291) indicate that users who would otherwise select one of the finer-grained options will employ a compensatory decision strategy when this option is removed. This means that they switch either in the direction of more privacy and less benefit, or less privacy and more benefit, depending on the subjective distance between the omitted option and the remaining options. This explanation of users' disclosure behavior is in line with fundamental decision theories, as well as the well-established notion of "privacy calculus". Two alternative hypotheses that we tested were not supported by our experimental data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2667–2676},
numpages = {10},
keywords = {location-sharing services, privacy calculus, information disclosure, decision making},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481370,
author = {Eriksson, Elina and Artman, Henrik and Swartling, Anna},
title = {The Secret Life of a Persona: When the Personal Becomes Private},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481370},
doi = {10.1145/2470654.2481370},
abstract = {Some organizations fail to involve users in systems development due to a widespread organization, high workload or secrecy issues. A remedy against this situation could be the persona method in which users and main stakeholders as represented as fictitious characters. Personas help eliciting user needs and requirements, facilitate design choices and are an overall communication aid where users cannot be present. An important part of the persona method, as portrayed in literature, is the personal details that make the personas trustworthy and alive. In this paper we present two cases in which personas have been developed and used, but where the personal is scarce or even non-existent because of a dispersed organisation, the organisational culture and secrecy issues. The paper describes how the personas were developed, used and received and how the method was altered in order to work in these special circumstances.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2677–2686},
numpages = {10},
keywords = {user centred design, secrecy issues, stakeholder, persona, systems development},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481371,
author = {Luger, Ewa and Moran, Stuart and Rodden, Tom},
title = {Consent for All: Revealing the Hidden Complexity of Terms and Conditions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481371},
doi = {10.1145/2470654.2481371},
abstract = {Terms and conditions are central in acquiring user consent by service providers. Such documents are frequently highly complex and unreadable, placing doubts on the validity of so called 'informed consent'. While readability and web accessibility have been major themes for some time in HCI, the core principles have yet to be applied beyond webpage content and are absent from the underpinning terms and conditions. Our concern is that accessible web pages will encourage consent, masking the complexities of the terms of usage.Using the SMOG readability formula and UK Energy services as a case study, we observed that a series of supplier terms and conditions were far beyond what a functionally literate adult could be expected to understand. We also present a browser based plug-in which compares SMOG readability scores to popular books. The intention is to use this plug-in to assist in surfacing the hidden complexities underpinning online consent.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2687–2696},
numpages = {10},
keywords = {usability, consent, readability, energy, smog, literacy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250149,
author = {schraefel, m.c.},
title = {Session Details: Papers: Text Visualization},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250149},
doi = {10.1145/3250149},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481373,
author = {Correll, Michael A. and Alexander, Eric C. and Gleicher, Michael},
title = {Quantity Estimation in Visualizations of Tagged Text},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481373},
doi = {10.1145/2470654.2481373},
abstract = {A valuable task in text visualization is to have viewers make judgments about text that has been annotated (either by hand or by some algorithm such as text clustering or entity extraction). In this work we look at the ability of viewers to make judgments about the relative quantities of tags in annotated text (specifically text tagged with one of a set of qualitatively distinct colors), and examine design choices that can improve performance at extracting statistical information from these texts. We find that viewers can efficiently and accurately estimate the proportions of tag levels over a range of situations; however accuracy can be improved through color choice and area adjustments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2697–2706},
numpages = {10},
keywords = {information visualization, text analytics, perceptual study, text visualization},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481374,
author = {Hullman, Jessica and Diakopoulos, Nicholas and Adar, Eytan},
title = {Contextifier: Automatic Generation of Annotated Stock Visualizations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481374},
doi = {10.1145/2470654.2481374},
abstract = {Online news tools - for aggregation, summarization and automatic generation - are an area of fruitful development as reading news online becomes increasingly commonplace. While textual tools have dominated these developments, annotated information visualizations are a promising way to complement articles based on their ability to add context. But the manual effort required for professional designers to create thoughtful annotations for contextualizing news visualizations is difficult to scale. We describe the design of Contextifier, a novel system that automatically produces custom, annotated visualizations of stock behavior given a news article about a company. Contextifier's algorithms for choosing annotations is informed by a study of professionally created visualizations and takes into account visual salience, contextual relevance, and a detection of key events in the company's history. In evaluating our system we find that Contextifier better balances graphical salience and relevance than the baseline.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2707–2716},
numpages = {10},
keywords = {time series, information visualization, annotation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481375,
author = {Wang, Yiran and Echenique, Andy and Shelton, Martin and Mark, Gloria},
title = {A Comparative Evaluation of Multiple Chat Stream Interfaces for Information-Intensive Environments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481375},
doi = {10.1145/2470654.2481375},
abstract = {For information workers who monitor numerous constantly updating data streams, conserving cognitive resources is crucial. This study evaluated how an interface affects information workers' ability to grasp critical information from multiple text-based chat streams under time pressure. We designed and built a working prototype that displays ten chat streams simultaneously in standard chat windows (ST) and ticker tapes (TT). We conducted a lab experiment to evaluate differences in how these two interfaces support signal and context detection. We found that with ST, participants detected significantly more target words (SAT words) with rarer frequency and significantly more context information (disaster facts) than with TT. Our results show that while TT is potentially better for overview scanning of multiple streams, ST is likely to be better for multi-tasking. Our study informs the design of future multi-chat systems so that large amounts of information can be easier to detect and process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2717–2720},
numpages = {4},
keywords = {interface evaluation, empirical study, information workers, monitoring multiple text-based streams},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481376,
author = {Goyal, Nitesh and Leshed, Gilly and Fussell, Susan R.},
title = {Effects of Visualization and Note-Taking on Sensemaking and Analysis},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481376},
doi = {10.1145/2470654.2481376},
abstract = {Many sophisticated tools have been developed to help analysts detect patterns in large datasets, but the value of these tools' individual features is rarely tested. In an experiment in which participants played detectives solving homicides, we tested the utility of a visualization of data links and a notepad for collecting and organizing annotations. The visualization significantly improved participants' ability to solve the crime whereas the notepad did not. Having both features available provided no benefit over having just the visualization. The results raise questions about the potential constraints on the usefulness of intelligence analysis tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2721–2724},
numpages = {4},
keywords = {interface design, sensemaking, visualization, analysis},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250150,
author = {Huang, Elaine},
title = {Session Details: Papers: Sustainability},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250150},
doi = {10.1145/3250150},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inbook{10.1145/2470654.2481378,
author = {H\r{a}kansson, Maria and Sengers, Phoebe},
title = {Beyond Being Green: Simple Living Families and ICT},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481378},
abstract = {Motivated by a need in sustainable HCI for studies of everyday practices, and a belief that a holistic view on sustainability is crucial to deeper understanding of how to design ICT to support sustainability, we here present a qualitative study of 11 simple living families in the US. Simple living refers to a lifestyle which is voluntarily simple out of concern for both the environment and quality of life. Our goal was to learn about a holistic view on sustainability and the role of ICT in helping and hindering families to live simply. The study contributes new insights about how holistic sustainability could be a valuable lens for HCI, revealing that sustainability is important to a wider range of areas in HCI than previously discussed. We conclude with implications for HCI for how to support sustainable practices beyond being "about" being green.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2725–2734},
numpages = {10}
}

@inbook{10.1145/2470654.2481379,
author = {Lomas, Derek and Kumar, Anuj and Patel, Kishan and Ching, Dixie and Lakshmanan, Meera and Kam, Matthew and Forlizzi, Jodi L.},
title = {The Power of Play: Design Lessons for Increasing the Lifespan of Outdated Computers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481379},
abstract = {One consequence of rapid advances in computer technology is the obsolescence of hundreds of millions of computers each year. This paper explores strategies for increasing the reuse of outdated computers through an investigation of an 8-bit home computer that is still popular in developing countries. We observed the use of the computers in 16 households in Ahmedabad and Bangalore, India in order to gain insight into the contextual factors that support the continued popularity of the device. While most computers become obsolete in less than a decade, this 30-year-old computer technology remains useful because it provides exciting, multi-user family entertainment. While having minimal processing power and virtually no connectivity, the 8-bit computer supports input and output channels that are especially suited for co-located social game play. In contrast, PCs are primarily designed for individual use. Therefore, we offer low-cost design recommendations that would enable outdated PCs to support greater shared use and increased utility within the constrained material context of low-income households. These simple interventions, if adopted by computer refurbishment industries, have the potential to significantly extend the useful lifespan of PCs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2735–2744},
numpages = {10}
}

@inproceedings{10.1145/2470654.2481380,
author = {Kim, Sunyoung and Paulos, Eric and Mankoff, Jennifer},
title = {InAir: A Longitudinal Study of Indoor Air Quality Measurements and Visualizations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481380},
doi = {10.1145/2470654.2481380},
abstract = {Indoor air quality (IAQ) is important for health as people spend the majority of time indoors, and it is particularly interesting over outdoor air because it strongly ties to indoor activities. Some activities easily exacerbate IAQ, resulting in serious pollution. However, people may not notice such changes because many pollutants are colorless and odorless, while many activities are inconspicuous and routine. We implemented inAir, a system that measures and visualizes IAQ that households appropriate and integrate into everyday life. The research goals of this work include understanding the IAQ dynamics with respect to habitual behaviors and analyzing behavioral and quantitative changes towards improving IAQ by the use of inAir. From our longitudinal study for four months, we found that inAir successfully elicited the reflection upon, and the modification of habitual behaviors for healthy domestic environments, which resulted in the significant improvement of IAQ.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2745–2754},
numpages = {10},
keywords = {sustainability, domestic computing, health, air quality},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481381,
author = {Wyche, Susan P. and Chetty, Marshini},
title = {"I Want to Imagine How That Place Looks": Designing Technologies to Support Connectivity between Africans Living Abroad and Home},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481381},
doi = {10.1145/2470654.2481381},
abstract = {Uneven access to Information and Communication Technologies (ICTs) in parts of the African continent make it challenging for some Africans who migrate to the U.S. to communicate with family members in their countries of origin. However, Internet access is becoming more widespread throughout the continent and this development presents an opportunity to explore how future interactive systems can support exchanges between families with members living in developed and less developed countries. To investigate these design possibilities we interviewed 27 African-born students, currently living in Virginia, U.S., and asked them how they used ICTs to connect with family members in their home countries. Our findings informed the development of a low-fidelity prototype that eight students lived with for four to five months. Findings from this deployment study motivate a discussion regarding features to include in interfaces designed to support transnational family communication. Features include personally meaningful imagery, country specific content, and the ability to monitor the weather and changing currency rates in migrants' countries of origin.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2755–2764},
numpages = {10},
keywords = {interaction design, diaspora communities, family communication, research through design, hci4d/ictd, transnational},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250151,
author = {Appert, Caroline},
title = {Session Details: Papers: Mobile Text Entry},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250151},
doi = {10.1145/3250151},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481383,
author = {Oulasvirta, Antti and Reichel, Anna and Li, Wenbin and Zhang, Yan and Bachynskyi, Myroslav and Vertanen, Keith and Kristensson, Per Ola},
title = {Improving Two-Thumb Text Entry on Touchscreen Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481383},
doi = {10.1145/2470654.2481383},
abstract = {We study the design of split keyboards for fast text entry with two thumbs on mobile touchscreen devices. The layout of KALQ was determined through first studying how users should grip a device with two hands. We then assigned letters to keys computationally, using a model of two-thumb tapping. KALQ minimizes thumb travel distance and maximizes alternation between thumbs. An error correction algorithm was added to help address linguistic and motor errors. Users reached a rate of 37 words per minute (with a 5% error rate) after a training program.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2765–2774},
numpages = {10},
keywords = {two-thumb text entry, soft keyboards, touchscreen devices, keyboard optimization, bimanual performance},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481384,
author = {Yin, Ying and Ouyang, Tom Yu and Partridge, Kurt and Zhai, Shumin},
title = {Making Touchscreen Keyboards Adaptive to Keys, Hand Postures, and Individuals: A Hierarchical Spatial Backoff Model Approach},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481384},
doi = {10.1145/2470654.2481384},
abstract = {We propose a new approach for improving text entry accuracy on touchscreen keyboards by adapting the underlying spatial model to factors such as input hand postures, individuals, and target key positions. To combine these factors together, we introduce a hierarchical spatial backoff model (SBM) that consists of submodels with different levels of complexity. The most general model includes no adaptive factors, whereas the most specific model includes all three. Considering that in practice people may switch hand postures (e.g., from two-thumb to one-finger) to better suit a situation, and that the specific submodels may take time to train for each user, a specific submodel should be applied only if its corresponding input posture can be identified with confidence, and if the submodel has enough training data from the user. We introduce the backoff mechanism to fall back to a simpler model if either of these conditions are not met. We implemented a prototype system capable of reducing the language-model-independent error rate by 13.2% using an online posture classifier with 86.4% accuracy. Further improvements in error rate may be possible with even better posture classification.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2775–2784},
numpages = {10},
keywords = {posture adaptation, adaptive model, personalization, touchscreen text input},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481385,
author = {Fuccella, Vittorio and Isokoski, Poika and Martin, Benoit},
title = {Gestures and Widgets: Performance in Text Editing on Multi-Touch Capable Mobile Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481385},
doi = {10.1145/2470654.2481385},
abstract = {We describe the design and evaluation of a gestural text editing technique for touchscreen devices. The gestures are drawn on top of the soft keyboard and interpreted as commands for moving the caret, performing selections, and controlling the clipboard. Our implementation is an Android service that can be used in any text editing task on Android-based devices. We conducted an experiment to compare the gestural editing technique against the widget-based technique available on a smartphone (Samsung Galaxy II with Android 2.3.5). The results show a performance benefit of 13-24% for the gestural technique depending on the font size. Subjective feedback from the participants was also positive. Because the two editing techniques use different input areas, they can co-exist on a device. This means that the gestural editing can be added on any soft keyboard without interfering with user experience for those users that choose not to use it.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2785–2794},
numpages = {10},
keywords = {text editing, gestures, clipboard, caret movement, android},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481386,
author = {Goel, Mayank and Jansen, Alex and Mandel, Travis and Patel, Shwetak N. and Wobbrock, Jacob O.},
title = {ContextType: Using Hand Posture Information to Improve Mobile Touch Screen Text Entry},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481386},
doi = {10.1145/2470654.2481386},
abstract = {The challenge of mobile text entry is exacerbated as mobile devices are used in a number of situations and with a number of hand postures. We introduce ContextType, an adaptive text entry system that leverages information about a user's hand posture (using two thumbs, the left thumb, the right thumb, or the index finger) to improve mobile touch screen text entry. ContextType switches between various keyboard models based on hand posture inference while typing. ContextType combines the user's posture-specific touch pattern information with a language model to classify the user's touch events as pressed keys. To create our models, we collected usage patterns from 16 participants in each of the four postures. In a subsequent study with the same 16 participants comparing ContextType to a control condition, ContextType reduced total text entry error rate by 20.6%.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2795–2798},
numpages = {4},
keywords = {touch screen, grip, situational impairments, mobile devices, hand posture, text entry, virtual keyboard},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481387,
author = {Oney, Stephen and Harrison, Chris and Ogan, Amy and Wiese, Jason},
title = {ZoomBoard: A Diminutive Qwerty Soft Keyboard Using Iterative Zooming for Ultra-Small Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481387},
doi = {10.1145/2470654.2481387},
abstract = {The proliferation of touchscreen devices has made soft keyboards a routine part of life. However, ultra-small computing platforms like the Sony SmartWatch and Apple iPod Nano lack a means of text entry. This limits their potential, despite the fact they are quite capable computers. In this work, we present a soft keyboard interaction technique called ZoomBoard that enables text entry on ultra-small devices. Our approach uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size. We based our design on a QWERTY layout, so that it is immediately familiar to users and leverages existing skill. As the ultimate test, we ran a text entry experiment on a keyboard measuring just 16 x 6mm - smaller than a US penny. After eight practice trials, users achieved an average of 9.3 words per minute, with accuracy comparable to a full-sized physical keyboard. This compares favorably to existing mobile text input methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2799–2802},
numpages = {4},
keywords = {zooming user interfaces, interaction technique, text entry, mobile input, handheld device, fat finger},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250152,
author = {Thomas, John},
title = {Session Details: Papers: Design for Development},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250152},
doi = {10.1145/3250152},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481389,
author = {Raza, Agha Ali and Ul Haq, Farhan and Tariq, Zain and Pervaiz, Mansoor and Razaq, Samia and Saif, Umar and Rosenfeld, Roni},
title = {Job Opportunities through Entertainment: Virally Spread Speech-Based Services for Low-Literate Users},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481389},
doi = {10.1145/2470654.2481389},
abstract = {We explore how telephone-based services might be mass adopted by low-literate users in the developing world. We focus on speech and push-button dialog systems requiring neither literacy nor training. Building on the success of Polly, a simple telephone-based voice manipulation and forwarding system that was first tested in 2011, we report on its first large-scale sustained deployment. In 24/7 operation in Pakistan since May 9, 2012, as of mid-September Polly has spread to 85,000 users, engaging them in 495,000 interactions, and is continuing to spread to 1,000 new people daily. It has also attracted 27,000 people to a job search service, who in turn listened 279,000 times to job ads and forwarded them 22,000 times to their friends. We report users' activity over time and across demographics, analyze user behavior within several randomized controlled trials, and describe lessons learned regarding spread, scalability and sustainability of telephone-based speech-based services.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2803–2812},
numpages = {10},
keywords = {ict4d, low-literate, cellular phones, information services, illiteracy, job search, communication services, low-skill jobs, entertainment, mobile phones, telephone, viral, hci4d, speech interfaces},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481390,
author = {Medhi, Indrani and Lakshmanan, Meera and Toyama, Kentaro and Cutrell, Edward},
title = {Some Evidence for the Impact of Limited Education on Hierarchical User Interface Navigation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481390},
doi = {10.1145/2470654.2481390},
abstract = {One of the greatest challenges in designing applications for economically poor communities is that potential users may have little or no education. We investigated how limited education appears to impact the ability to navigate a hierarchical UI, even when it has no text. We scored 60 participants from low-income communities in India using tests of textual literacy and Raven's Progressive Matrices. These were used as proxies for educational level and a subset of cognitive abilities. We then evaluated participants' performance on a UI task involving hierarchical navigation. First, our results confirm that textual literacy is correlated with scores on the Raven's test. In addition, we found that performance on both instruments are predictive of performance in navigating UI hierarchies, even when the UI is text-free. This provides statistically significant confirmation of previous anecdotal hypotheses. We conclude with design recommendations for UI hierarchies for people with limited education.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2813–2822},
numpages = {10},
keywords = {abstract reasoning, limited education, hierarchy navigation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481391,
author = {Wyche, Susan P. and Forte, Andrea and Yardi Schoenebeck, Sarita},
title = {Hustling Online: Understanding Consolidated Facebook Use in an Informal Settlement in Nairobi},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481391},
doi = {10.1145/2470654.2481391},
abstract = {Facebook is a global phenomenon, yet little is known about use of the site in urban parts of the developing world where the social network's users are increasingly located. We qualitatively studied Facebook use among 28 young adults living in Viwandani, an informal settlement, or slum, in Nairobi, Kenya. We find that to overcome the costs associated with Internet use, participants consolidated diverse online activities onto Facebook; here we focus on the most common practice--using Facebook to support income generation. Viwandani residents used the site to look for employment opportunities, market themselves, and seek remittances from friends and family abroad. We use our findings to motivate a design agenda for the urban poor built on an understanding that Facebook is used, with mixed-success, to support income generation. A key part of this agenda calls for developing ICT interventions grounded in users' existing practices rather than introducing new and unfamiliar ones.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2823–2832},
numpages = {10},
keywords = {facebook, social computing, social media, kenya, nairobi, youth, ictd, informal settlements},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481392,
author = {Cuendet, Sebastien and Medhi, Indrani and Bali, Kalika and Cutrell, Edward},
title = {VideoKheti: Making Video Content Accessible to Low-Literate and Novice Users},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481392},
doi = {10.1145/2470654.2481392},
abstract = {Designing ICT systems for rural users in the developing world is difficult for a variety of reasons ranging from problems with infrastructure to wide differences in user contexts and capabilities. Developing regions may include huge variability in spoken languages, and users are often low- or non-literate, with very little experience interacting with digital technologies. Researchers have explored the use of text-free graphical interfaces as well as speech-based applications to overcome some of the issues related to language and literacy. While there are benefits and drawbacks to each of these approaches, they can be complementary when used together. In this work, we present VideoKheti, a mobile system using speech, graphics, and touch interaction for low-literate farmers in rural India. VideoKheti helps farmers to find and watch agricultural extension videos in their own language and dialect. In this paper, we detail the design and development of VideoKheti and report on a field study with 20 farmers in rural India who were asked to find videos based on a scenario. The results show that farmers could use VideoKheti, but their success still greatly depended on their education level. While participants were enthusiastic about using the system, the multimodal interface did not overcome many obstacles for low-literate users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2833–2842},
numpages = {10},
keywords = {speech interface, novice users, ictd, multimodal interfaces, mobile design, hci4d, low-literate users},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250153,
author = {Pipek, Volkmar},
title = {Session Details: Papers: Narrative and Materiality},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250153},
doi = {10.1145/3250153},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481394,
author = {Spaulding, Eric and Faste, Haakon},
title = {Design-Driven Narrative: Using Stories to Prototype and Build Immersive Design Worlds},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481394},
doi = {10.1145/2470654.2481394},
abstract = {This paper examines the role of narrative in the process of interactive experience design, focusing on the potential uses of narrative in prototyping and iteration efforts to uncover deeper and more meaningful responses from users by engaging them in the co-creation of narratives of use around the design. We created a series of narrative fictions with embedded design concepts, and built low-fi prototype artifacts for directed storytelling sessions with twelve participants. We conclude with a discussion of findings regarding the opportunities to more effectively use narrative techniques and immersive storytelling to create valuable experiences between designers and users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2843–2852},
numpages = {10},
keywords = {prototyping, scenario building, narrative-driven design, reader-response theory, design evaluation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481395,
author = {Fuchsberger, Verena and Murer, Martin and Tscheligi, Manfred},
title = {Materials, Materiality, and Media},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481395},
doi = {10.1145/2470654.2481395},
abstract = {In HCI, and especially in interaction design, the material aspect of interactions is currently emphasized. Nevertheless, it is challenging to theoretically frame the variety of digital or immaterial, and physical materials. In order to contribute to this materiality discourse, we reflect on McLuhan's work on media analysis and on Latour's Actor-Network Theory in this paper. Both emphasize the active role of the material - be it media or any other kind of non-human actors - in the interplay with the human. Thus, we establish junctures between their findings and materials, as used in interaction design in HCI. We discuss McLuhan's claim to focus on new sensory effects and ways of interaction brought forth by new media. Furthermore, we illustrate how describing the connections between materials, designers, and users in terms of Latour's Actor-Networks can be beneficial for interaction design. Finally, we discuss the respective methodology and its relation to research through design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2853–2862},
numpages = {10},
keywords = {materiality, design, materials, media theory, actor-network theory},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481396,
author = {Kumar, Neha and Parikh, Tapan S.},
title = {Mobiles, Music, and Materiality},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481396},
doi = {10.1145/2470654.2481396},
abstract = {Building on recent HCI contributions that assert the materiality of digital information, we examine the material nature of digital media and information technology in the context of mobile music production, reproduction, and reception in rural and semi-urban India. We use ethnographic methods to study the recent adoption and use of mobile technology and discuss our findings in relation to the evolving materiality of music. We also investigate the sociotechnical configurations that emerge as a consequence of this materiality. Thus we contribute to HCI research by showing how the material representations of digital media affect the interactions of humans with technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2863–2872},
numpages = {10},
keywords = {music, media, mobile, ictd, materiality, hci4d},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481397,
author = {Jackson, Steven J. and Barbrow, Sarah},
title = {Infrastructure and Vocation: Field, Calling and Computation in Ecology},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481397},
doi = {10.1145/2470654.2481397},
abstract = {HCI studies of computational change in the sciences have made important design and analytic contributions, to other fields of science and to HCI itself. But some of the longer-term effects and complexities of infrastructural change in the sciences aren't easily captured under short-term, design- or artifact-centered accounts. Drawing on extended ethnographic study of computational development in ecology, this paper explores the relationship between new computational infrastructure and the nature of ecology as a vocation: roughly, the deeply held sense of what it means to 'be' an ecologist, and to 'do' ecology. We analyze in particular the nature of the field and field work as a central site of ecological practice and identity; how new computational developments are remediating this crucial relation; and the emergent vocational values that new and more computationally-intensive forms of ecology may give rise to.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2873–2882},
numpages = {10},
keywords = {ecology, values in design, vocation, infrastructure, collaboration, science},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250154,
author = {Muller, Michael},
title = {Session Details: Papers: Design for Children},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250154},
doi = {10.1145/3250154},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481399,
author = {van Doorn, Fenne and Stappers, Pieter Jan and Gielen, Mathieu},
title = {Design Research by Proxy: Using Children as Researchers to Gain Contextual Knowledge about User Experience.},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481399},
doi = {10.1145/2470654.2481399},
abstract = {This paper explores the use of participants as research collaborators in the domain of contextual user research. In participatory- and co-design, users participate increasingly early in the design process. When conducting user research in order to gain contextual knowledge about the lives, experiences and wishes of users, collaborators can be of help in setting up, conducting research and analyzing the data. A case study was conducted to investigate if and how children are able to perform as research collaborators. Children conducted interviews with other participants, and in doing increased their knowledge about people close to them, and about themselves. The gained insights were personal and the used personas proved to be a valuable tool. In the role of researcher, the children discovered similarities and differences between themselves and others. Besides gaining valuable insights from their participants, they accessed and shared their own experiences, so while listening to others, the children got sensitized themselves. In other words, the current study found that next to gathering more data, "super-sources" are created when children become research collaborators.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2883–2892},
numpages = {10},
keywords = {research collaborators, co-research, design research, contextual user research, children},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481400,
author = {Walsh, Greg and Foss, Elizabeth and Yip, Jason and Druin, Allison},
title = {FACIT PD: A Framework for Analysis and Creation of Intergenerational Techniques for Participatory Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481400},
doi = {10.1145/2470654.2481400},
abstract = {In this paper, we present a framework that describes commonly used design techniques for Participatory Design with children. Although there are many currently used techniques for designing with children, researchers working in differing contexts and in a changing technological landscape find themselves facing difficult design situations. The FACIT PD framework presented in this paper can aid in choosing existing design techniques or in developing new techniques regardless of the stage in the design cycle, the technology being developed, or philosophical approach to design method. The framework consists of eight dimensions, concerning the design partners, the design goal, and the design technique. The partner dimensions are partner experience and need for accommodation. The design goal dimensions are design space and maturity of design. The technique dimensions include: cost, portability, technology and physical interaction. Three cases will be presented which describe new techniques developed using the framework and two cases will describe existing techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2893–2902},
numpages = {10},
keywords = {design techniques, children, design methods, design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481401,
author = {Holone, Harald and Herstad, Jo},
title = {Three Tensions in Participatory Design for Inclusion},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481401},
doi = {10.1145/2470654.2481401},
abstract = {One ideal of Participatory Design (PD) is active involvement by all stakeholders as co-designers. However, when PD is applied to real projects, certain compromises are unavoidable, no matter what stakeholders are involved. With this paper we want to shed light on some of the challenges in implementing "true" PD in the case of designing with children, in particular children with severe disabilities. We do this work to better understand challenges in an ongoing project, RHYME, and by doing so we hope to provide insight and inspiration for others.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2903–2906},
numpages = {4},
keywords = {participatory design, universal design, familiarity, inclusion},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481402,
author = {Price, Sara and Jewitt, Carey},
title = {Interview Approaches to Researching Embodiment},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481402},
doi = {10.1145/2470654.2481402},
abstract = {The methods of data collection that we choose determine the kinds of data that we have access to, and thus shape analyses. In the context of novel interfaces where different modes, available through the environment and context, mediate the interaction, understanding methodological approaches is critical. This paper examines alternative methods of data collection for exploring student's embodied interaction with novel technology in a learning context. Specifically it analyses non-facilitated interaction in a tangible learning environment, in conjunction with three different post activity interview approaches: semi-structured interviews; semi-structured interview with video prompted recall; and interviews using the technology itself. Findings suggest that the different interview approaches change the nature of information elicited, and that non-facilitated interaction offers clearer insight into interpretation, both in terms of the meaning that emerges through, and is, therefore, embodied in the interaction, and in terms of representation, directly informing design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2907–2910},
numpages = {4},
keywords = {interview approaches, research methods, learning, tangible interfaces, multimodality},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250155,
author = {Mark, Gloria},
title = {Session Details: Papers: Evaluation Methods 3},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250155},
doi = {10.1145/3250155},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481404,
author = {Birnbaum, Benjamin and Borriello, Gaetano and Flaxman, Abraham D. and DeRenzi, Brian and Karlin, Anna R.},
title = {Using Behavioral Data to Identify Interviewer Fabrication in Surveys},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481404},
doi = {10.1145/2470654.2481404},
abstract = {Surveys conducted by human interviewers are one of the principal means of gathering data from all over the world, but the quality of this data can be threatened by interviewer fabrication. In this paper, we investigate a new approach to detecting interviewer fabrication automatically. We instrument electronic data collection software to record logs of low-level behavioral data and show that supervised classification, when applied to features extracted from these logs, can identify interviewer fabrication with an accuracy of up to 96%. We show that even when interviewers know that our approach is being used, have some knowledge of how it works, and are incentivized to avoid detection, it can still achieve an accuracy of 86%. We also demonstrate the robustness of our approach to a moderate amount of label noise and provide practical recommendations, based on empirical evidence, on how much data is needed for our approach to be effective.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2911–2920},
numpages = {10},
keywords = {user logging, supervised classification, data collection, surveys, data quality, hci4d, behavioral data, curbstoning},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481405,
author = {Gouveia, R\'{u}ben and Karapanos, Evangelos},
title = {Footprint Tracker: Supporting Diary Studies with Lifelogging},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481405},
doi = {10.1145/2470654.2481405},
abstract = {As HCI shifts "to the wild", in-situ methods such as Diary Methods and the Experience Sampling Method are gaining momentum. However, researchers have acknowledged the intrusiveness and lack of realism in these methods and have proposed solutions, notably through lightweight and rich media capture. In this paper we explore the concept of lifelogging as an alternative solution to these two challenges. We describe Footprint Tracker, a tool that allows the review of lifelogs with the aim to support recall and reflection over daily activities and experiences. In a field trial, we study how four different types of cues, namely visual, location, temporal and social context, trigger memories of recent events and associated emotions. We conclude with a number of implications for the design of lifelogging systems that support recall and reflection upon recent events as well as ones lying further in our past.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2921–2930},
numpages = {10},
keywords = {lifelogging, diary methods, experience sampling},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481406,
author = {M\"{o}ller, Andreas and Kranz, Matthias and Schmid, Barbara and Roalter, Luis and Diewald, Stefan},
title = {Investigating Self-Reporting Behavior in Long-Term Studies},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481406},
doi = {10.1145/2470654.2481406},
abstract = {Self-reporting techniques, such as data logging or a diary, are frequently used in long-term studies, but prone to subjects' forgetfulness and other sources of inaccuracy. We conducted a six-week self-reporting study on smartphone usage in order to investigate the accuracy of self-reported information, and used logged data as ground truth to compare the subjects' reports against. Subjects never recorded more than 70% and, depending on the requested reporting interval, down to less than 40% of actual app usages. They significantly overestimated how long they used apps. While subjects forgot self-reports when no automatic reminders were sent, a high reporting frequency was perceived as uncomfortable and burdensome. Most significantly, self-reporting even changed the actual app usage of users and hence can lead to deceptive measures if a study relies on no other data sources.With this contribution, we provide empirical quantitative long-term data on the reliability of self-reported data collected with mobile devices. We aim to make researchers aware of the caveats of self-reporting and give recommendations for maximizing the reliability of results when conducting large-scale, long-term app usage studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2931–2940},
numpages = {10},
keywords = {survey, self-reporting, long-term study, application usage},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481407,
author = {McDonald, Sharon and Petrie, Helen},
title = {The Effect of Global Instructions on Think-Aloud Testing},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481407},
doi = {10.1145/2470654.2481407},
abstract = {Verbal protocols are the primary tool for understanding users' task-solving behaviors during usability testing. We investigated whether the classic think-aloud and a think-aloud with an explicit instruction leads to different task-solving performance compared to silent working. The results suggest that the classic method had no impact on task performance whereas the explicit instruction led to an increase in within-page and between-page navigation and scrolling activity. The classic method was linked to an increase in mental workload in terms of effort and frustration. The explicit think-aloud led to an increase in mental demand, performance, effort and frustration.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2941–2944},
numpages = {4},
keywords = {think-aloud instructions, think-aloud testing, reactivity},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481408,
author = {Fouse, Adam and Weibel, Nadir and Johnson, Christine and Hollan, James D.},
title = {Reifying Social Movement Trajectories},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481408},
doi = {10.1145/2470654.2481408},
abstract = {In this paper we describe the development of a novel paper-digital interface for recording movement trajectories, designed to assist ethnographers and ethologists in analysis of social movement. While we focus on development of a system to aid analysis of elephant movement, the resulting interaction techniques and facilities are quite general. The paper highlights how our design evolved to balance the goals of researchers, their current practices, and the challenges of integrating the relatively unconstrained world of pen and paper with the relatively constrained world of digital systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2945–2948},
numpages = {4},
keywords = {paper-digital interfaces, digital ethnography, ethology},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250156,
author = {Marshall, Paul},
title = {Session Details: Papers: Visual Perception},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250156},
doi = {10.1145/3250156},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481410,
author = {Harrison, Lane and Skau, Drew and Franconeri, Steven and Lu, Aidong and Chang, Remco},
title = {Influencing Visual Judgment through Affective Priming},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481410},
doi = {10.1145/2470654.2481410},
abstract = {Recent research suggests that individual personality differences can influence performance with visualizations. In addition to stable personality traits, research in psychology has found that temporary changes in affect (emotion) can also significantly impact performance during cognitive tasks. In this paper, we show that affective priming also influences user performance on visual judgment tasks through an experiment that combines affective priming with longstanding graphical perception experiments. Our results suggest that affective priming can influence accuracy in common graphical perception tasks. We discuss possible explanations for these findings, and describe how these findings can be applied to design visualizations that are less (or more) susceptible to error in common visualization contexts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2949–2958},
numpages = {10},
keywords = {visualization, emotion, charts, affect},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481411,
author = {Ankolekar, Anupriya and Sandholm, Thomas and Yu, Louis},
title = {Play It by Ear: A Case for Serendipitous Discovery of Places with Musicons},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481411},
doi = {10.1145/2470654.2481411},
abstract = {Current location-based services (LBS) typically allow users to locate points of interest (POI) in their vicinity but can detract from the user's emotional experience of exploring a new location. In this paper, we examine how cues in the form of popular music (musicons) can emotionally engage users and enhance their experience of discovering nearby POIs serendipitously in unfamiliar places. The primary contribution of this paper is a field study, in which we evaluate the performance and emotional engagement of different types of audio-based cues for directing users' attention to specific POIs. Musicons and mixed-modality cues performed close to visual and speech cues, and significantly better than auditory icons, for POI identification while creating a much more pleasant and engaging user experience. We conclude that cues for POI discovery need not always be as explicit as the baseline visual cues. Indeed, the most challenging cues, auditory icons, led to a heightened sense of autonomy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2959–2968},
numpages = {10},
keywords = {audio interfaces, emotion, mobility, affective computing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481412,
author = {Hook, Jonathan and McCarthy, John and Wright, Peter and Olivier, Patrick},
title = {Waves: Exploring Idiographic Design for Live Performance},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481412},
doi = {10.1145/2470654.2481412},
abstract = {We explore whether idiographic design, a category of interaction design that focuses upon responding to detailed personal accounts of individuals' practices, can be used to support interaction designers in responding to the complex and multifaceted design space posed by live performance. We describe and reflect upon the application of an idiographic approach during the design of Waves, an interface for live VJ performance. This approach involved a close and dialogical engagement with the practices and experiences of an individual live performer, during a series of semi-structured interviews and then the discussion and iteration of an evolving prototypical design. Reflection on the experience of applying this approach highlights idiographic design as a practical means to support interaction designers in proposing innovative designs that respond sensitively to the kinds of subtle and complex issues that underpin people's lived and felt experiences of live performance and, potentially, many other domains.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2969–2978},
numpages = {10},
keywords = {vjing, idiographic design, experience-centered design, interaction design, live performance, liveness, multi-touch},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481413,
author = {Ichino, Junko and Isoda, Kazuo and Hanai, Ayako and Ueda, Tetsuya},
title = {Effects of the Display Angle in Museums on User's Cognition, Behavior, and Subjective Responses},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481413},
doi = {10.1145/2470654.2481413},
abstract = {In order to achieve the intended level of communication with visitors in museums where large displays are installed, it is essential to understand how various display factors affect visitors. We explore the effects of the display angle on individual users. In our experiment, we set up three types of flat displays - vertical, horizontal, and tilted - and comprehensively tested users' cognitive, behavioral, and subjective aspects. The results showed that a significant difference could be discerned in regards to cognitive and subjective aspects. Test results for the cognitive aspect showed that the display angle on which the displayed content was easy to understand and remember differed depending on age. Test results for the subjective aspect showed that irrespective of age, users rated tilted displays as being quicker to attract attention and easier to peruse, to understand and remember the content, and to interact with, and such displays were the most preferred.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2979–2988},
numpages = {10},
keywords = {display angle, large interactive display, museum},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250157,
author = {Teo, Leong-Hwee},
title = {Session Details: Papers: Searching and Finding},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250157},
doi = {10.1145/3250157},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481415,
author = {Kittur, Aniket and Peters, Andrew M. and Diriye, Abdigani and Telang, Trupti and Bove, Michael R.},
title = {Costs and Benefits of Structured Information Foraging},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481415},
doi = {10.1145/2470654.2481415},
abstract = {People spend an enormous amount of time searching for and saving information online. Existing tools capture only a small portion of the cognitive processing a user engages in while making sense of a new domain. In this paper we introduce a novel interface for capturing online information in a structured but lightweight way. We use this interface as a platform to experimentally characterize the costs and benefits of structuring information during the sensemaking process. Our results contribute empirical knowledge relevant to theories of information seeking and sensemaking, and practical implications for the development of tools to capture and share online information.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2989–2998},
numpages = {10},
keywords = {structure, sensemaking, search, foraging},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481416,
author = {Feild, Henry and White, Ryen W. and Fu, Xin},
title = {Supporting Orientation during Search Result Examination},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481416},
doi = {10.1145/2470654.2481416},
abstract = {Search engines help their users decide which results to visit using captions comprising titles, URLs, and snippets containing the query keywords and proximal text from landing pages (the search results linked from the result page). Although caption content can be a key factor in these decisions, snippets provide only basic support for orienting users with landing page content from the search-engine result page (SERP), and no support during the transition to landing pages or once users reach the page following a selection decision. As a result, many searchers must employ inefficient strategies such as skimming and scanning the content of the landing page. In this paper we propose a novel method, called clickable snippets, to address this shortcoming. Clickable snippets provide searchers with a direct and actionable link between SERP captions and landing-page content. We describe a user study comparing clickable snippets with extant methods of orientation support such as query-term highlighting on the landing page and thumbnail previews on the SERP. We show that clickable snippets are preferred by participants, and lead to more effective and efficient searching. Our findings have implications for the design of the user experience in search systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2999–3008},
numpages = {10},
keywords = {clickable snippets, search-result examination, orientation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481417,
author = {Zhao, Jian and Wigdor, Daniel and Balakrishnan, Ravin},
title = {TrailMap: Facilitating Information Seeking in a Multi-Scale Digital Map via Implicit Bookmarking},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481417},
doi = {10.1145/2470654.2481417},
abstract = {Web applications designed for map exploration in local neighborhoods have become increasingly popular and important in everyday life. During the information-seeking process, users often revisit previously viewed locations, repeat earlier searches, or need to memorize or manually mark areas of interest. To facilitate rapid returns to earlier views during map exploration, we propose a novel algorithm to automatically generate map bookmarks based on a user's interaction. TrailMap, a web application based on this algorithm, is developed, providing a fluid and effective neighborhood exploration experience. A one-week study is conducted to evaluate TrailMap in users' everyday web browsing activities. Results showed that TrailMap's implicit bookmarking mechanism is efficient for map exploration and the interactive and visual nature of the tool is intuitive to users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3009–3018},
numpages = {10},
keywords = {multi-scale exploration, digital map browsing, revisitation, interaction history, implicit bookmarking},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481418,
author = {Agapie, Elena and Golovchinsky, Gene and Qvarfordt, Pernilla},
title = {Leading People to Longer Queries},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481418},
doi = {10.1145/2470654.2481418},
abstract = {Although longer queries can produce better results for information seeking tasks, people tend to type short queries. We created an interface designed to encourage people to type longer queries, and evaluated it in two Mechanical Turk experiments. Results suggest that our interface manipulation may be effective for eliciting longer queries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3019–3022},
numpages = {4},
keywords = {persuasive computing, query construction, interactive information seeking},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481419,
author = {Baxter, Kathy and Malahy, Lori Wu and Lubin, Jeremy},
title = {Pirates of the Search Results Page},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481419},
doi = {10.1145/2470654.2481419},
abstract = {Search malware redirects nearly 100% of infected users' clicks on web search results to unintended websites. Most published research details how web-based malware works and technological interventions to stop it before users ever see it; however, the constant evolution of obfuscation techniques makes it difficult to prevent infection altogether. User interventions in the form of toolbars, dialogs, and user education have seen limited success. Previous research has focused on a prototypical type of malware; a sophisticated program that conceals itself (e.g., surreptitious download onto a host computer) or tries to fool the user by mimicking known, trusted websites (e.g., phishing attacks). The goal of our research is to understand users' experience, understanding of and response to search malware. The present research shows that even when confronted with blatantly unusual search behavior, people are unlikely to attribute blame to malware or to engage in behavior that may remedy the situation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3023–3026},
numpages = {4},
keywords = {user experience, redirect, search malware, detection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250158,
author = {Huot, Stephane},
title = {Session Details: Papers: Mobile Gestures},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250158},
doi = {10.1145/3250158},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481421,
author = {Serrano, Marcos and Lecolinet, Eric and Guiard, Yves},
title = {Bezel-Tap Gestures: Quick Activation of Commands from Sleep Mode on Tablets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481421},
doi = {10.1145/2470654.2481421},
abstract = {We present Bezel-Tap Gestures, a novel family of interaction techniques for immediate interaction on handheld tablets regardless of whether the device is alive or in sleep mode. The technique rests on the close succession of two input events: first a bezel tap, whose detection by accelerometers will awake an idle tablet almost instantly, then a screen contact. Field studies confirmed that the probability of this input sequence occurring by chance is very low, excluding the accidental activation concern. One experiment examined the optimal size of the vocabulary of commands for all four regions of the bezel (top, bottom, left, right). Another experiment evaluated two variants of the technique which both allow two-level selection in a hierarchy of commands, the initial bezel tap being followed by either two screen taps or a screen slide. The data suggests that Bezel-Tap Gestures may serve to design large vocabularies of micro-interactions with a sleeping tablet.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3027–3036},
numpages = {10},
keywords = {accelerometers, mobile devices, bezel gestures, marking menus, micro-interaction, interaction techniques},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481422,
author = {Cheng, Lung-Pan and Liang, Hsiang-Sheng and Wu, Che-Yang and Chen, Mike Y.},
title = {IGrasp: Grasp-Based Adaptive Keyboard for Mobile Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481422},
doi = {10.1145/2470654.2481422},
abstract = {Multitouch tablets, such as iPad and Android tablets, support virtual keyboards for text entry. Our 64-user study shows that 98% of the users preferred different keyboard layouts and positions depending on how they were holding these devices. However, current tablets either do not allow keyboard adjustment or require users to manually adjust the keyboards. We present iGrasp, which automatically adapts the layout and position of virtual keyboards based on how and where users are grasping the devices without requiring explicit user input. Our prototype uses 46 capacitive sensors positioned along the sides of an iPad to sense users' grasps, and supports two types of grasp-based automatic adaptation: layout switching and continuous positioning. Our two 18-user studies show that participants were able to begin typing 42% earlier using iGrasp's adaptive keyboard compared to the manually adjustable keyboard. Participants also rated iGrasp much easier to use than the manually adjustable keyboard (4.2 vs 2.9 on five-point Likert scale.)},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3037–3046},
numpages = {10},
keywords = {adaptive user interfaces, mobile devices, virtual keyboard, grasp detection},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481423,
author = {Hoggan, Eve and Williamson, John and Oulasvirta, Antti and Nacenta, Miguel and Kristensson, Per Ola and Lehti\"{o}, Anu},
title = {Multi-Touch Rotation Gestures: Performance and Ergonomics},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481423},
doi = {10.1145/2470654.2481423},
abstract = {Rotations performed with the index finger and thumb involve some of the most complex motor action among common multi-touch gestures, yet little is known about the factors affecting performance and ergonomics. This note presents results from a study where the angle, direction, diameter, and position of rotations were systematically manipulated. Subjects were asked to perform the rotations as quickly as possible without losing contact with the display, and were allowed to skip rotations that were too uncomfortable. The data show surprising interaction effects among the variables, and help us identify whole categories of rotations that are slow and cumbersome for users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3047–3050},
numpages = {4},
keywords = {ergonomics, gestures, multi-touch interaction, rotation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481424,
author = {Cheng, Lung-Pan and Lee, Meng Han and Wu, Che-Yang and Hsiao, Fang-I and Liu, Yen-Ting and Liang, Hsiang-Sheng and Chiu, Yi-Ching and Lee, Ming-Sui and Chen, Mike Y.},
title = {IrotateGrasp: Automatic Screen Rotation Based on Grasp of Mobile Devices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481424},
doi = {10.1145/2470654.2481424},
abstract = {Automatic screen rotation improves viewing experience and usability of mobile devices, but current gravity-based approaches do not support postures such as lying on one side, and manual rotation switches require explicit user input. iRotateGrasp automatically rotates screens of mobile devices to match users' viewing orientations based on how users are grasping the devices. Our insight is that users' grasps are consistent for each orientation, but significantly differ between different orientations. Our prototype used a total of 44 capacitive sensors along the four sides and the back of an iPod Touch, and uses support vector machine (SVM) to recognize grasps at 25Hz. We collected 6-users' usage under 108 different combinations of posture, orienta-tion, touchscreen operation, and left/right/both hands. Our offline analysis showed that our grasp-based approach is promising, with 80.9% accuracy when training and testing on different users, and up to 96.7% if users are willing to train the system. Our user study (N=16) showed that iRo-tateGrasp had an accuracy of 78.8% and was 31.3% more accurate than gravity-based rotation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3051–3054},
numpages = {4},
keywords = {mobile device, device orientation, grasp recognition, auto rotation, adaptive user interface},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250096,
author = {Drucker, Steven},
title = {Session Details: Papers: Design for Developers},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250096},
doi = {10.1145/3250096},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466418,
author = {Piorkowski, David J. and Fleming, Scott D. and Kwan, Irwin and Burnett, Margaret M. and Scaffidi, Christopher and Bellamy, Rachel K.E. and Jordahl, Joshua},
title = {The Whats and Hows of Programmers' Foraging Diets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466418},
doi = {10.1145/2470654.2466418},
abstract = {One of the least studied areas of Information Foraging Theory is diet: the information foragers choose to seek. For example, do foragers choose solely based on cost, or do they stubbornly pursue certain diets regardless of cost? Do their debugging strategies vary with their diets? To investigate "what" and "how" questions like these for the domain of software debugging, we qualitatively analyzed 9 professional developers' foraging goals, goal patterns, and strategies. Participants spent 50% of their time foraging. Of their foraging, 58% fell into distinct dietary patterns - mostly in patterns not previously discussed in the literature. In general, programmers' foraging strategies leaned more heavily toward enrichment than we expected, but different strategies aligned with different goal types. These and our other findings help fill the gap as to what programmers' dietary goals are and how their strategies relate to those goals.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3063–3072},
numpages = {10},
keywords = {debugging strategies, information foraging theory, information diet},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466419,
author = {Kr\"{a}mer, Jan-Peter and Karrer, Thorsten and Kurz, Joachim and Wittenhagen, Moritz and Borchers, Jan},
title = {How Tools in IDEs Shape Developers' Navigation Behavior},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466419},
doi = {10.1145/2470654.2466419},
abstract = {Understanding source code is crucial for successful software maintenance, and navigating the call graph is especially helpful to understand source code [12]. We compared maintenance performance across four different development environments: an IDE without any call graph exploration tool, a Call Hierarchy tool as found in Eclipse, and the tools Stacksplorer [7]and Blaze [11]. Using any of the call graph exploration tools more developers could solve certain maintenance tasks correctly. Only Stacksplorer and Blaze, however, were also able to decrease task completion times, although the Call Hierarchy offers access to a larger part of the call graph. To investigate if this result was caused by a change in navigation behavior between the tools, we used a set of predictive models to create formally comparable descriptions of programmer navigation. The results suggest that the decrease in task completion times has been caused by Stacksplorer and Blaze promoting call graph navigation more than the Call Hierarchy tool.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3073–3082},
numpages = {10},
keywords = {development tools / toolkits / programming environments, analysis methods},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466420,
author = {Kumar, Ranjitha and Satyanarayan, Arvind and Torres, Cesar and Lim, Maxine and Ahmad, Salman and Klemmer, Scott R. and Talton, Jerry O.},
title = {Webzeitgeist: Design Mining the Web},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466420},
doi = {10.1145/2470654.2466420},
abstract = {Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes. This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools. This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3083–3092},
numpages = {10},
keywords = {data mining, web design},
location = {Paris, France},
series = {CHI '13}
}

@dataset{10.1145/review-2470654.2466420_R49478,
author = {Kurfess, Franz J},
title = {Review ID:R49478 for DOI: 10.1145/2470654.2466420},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2470654.2466420_R49478}
}

@inproceedings{10.1145/2470654.2466421,
author = {Grigoreanu, Valentina and Mohanna, Manal},
title = {Informal Cognitive Walkthroughs (ICW): Paring down and Pairing up for an Agile World},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466421},
doi = {10.1145/2470654.2466421},
abstract = {Agile software teams' frequent releases and fast iterations present a growing need for rigorous user experience research methods that are faster, lighter-weight, and more flexible. To this end, we developed the Informal Cognitive Walkthrough (ICW). This agile research methodology grew organically, over the course of three years, while working with a very large agile software development team. ICWs involve conducting one or more Simplified 'Streamlined Cognitive Walkthroughs' (SSCW), followed by one or more Simplified 'Pluralistic Walkthroughs' (SPW). In this paper, we present the ICW and provide a real-world example of its application. Preliminary experiences with the method revealed potential advantages over traditional lab studies, ranging from more quickly uncovering and fixing usability issues, to a stronger collaboration between the disciplines, and to acting as a forcing function in aligning diverse engineers to deliver on a common user goal.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3093–3096},
numpages = {4},
keywords = {usability testing, user-centered design, agile},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466422,
author = {Kato, Jun and Sakamoto, Daisuke and Igarashi, Takeo},
title = {Picode: Inline Photos Representing Posture Data in Source Code},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466422},
doi = {10.1145/2470654.2466422},
abstract = {Current programming environments use textual or symbolic representations. While these representations are appropriate for describing logical processes, they are not appropriate for representing raw values such as human and robot posture data, which are necessary for handling gesture input and controlling robots. To address this issue, we propose Picode, a text-based development environment integrated with visual representations: photos of human and robots. With Picode, the user first takes a photo to bind it to posture data. S/he then drag-and-drops the photo into the code editor, where it is displayed as an inline image. A preliminary in-house user study implied positive effects of taking photos on the programming experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3097–3100},
numpages = {4},
keywords = {development environment, posture data, inline photo},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250097,
author = {McGrenere, Joanna},
title = {Session Details: Papers: Perception and Awareness},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250097},
doi = {10.1145/3250097},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466424,
author = {Lin, Sharon and Hanrahan, Pat},
title = {Modeling How People Extract Color Themes from Images},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466424},
doi = {10.1145/2470654.2466424},
abstract = {Color choice plays an important role in works of graphic art and design. However, it can be difficult to choose a compelling set of colors, or color theme, from scratch. In this work, we present a method for extracting color themes from images using a regression model trained on themes created by people. We collect 1600 themes from Mechanical Turk as well as from artists. We find that themes extracted by Turk participants were similar to ones extracted by artists. In addition, people tended to select diverse colors and focus on colors in salient image regions. We show that our model can match human-extracted themes more closely compared to previous work. Themes extracted by our model were also rated higher as representing the image than previous approaches in a Mechanical Turk study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3101–3110},
numpages = {10},
keywords = {crowdsourcing, color theme extraction, color themes, color names, algorithms},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466425,
author = {Ofek, Eyal and Iqbal, Shamsi T. and Strauss, Karin},
title = {Reducing Disruption from Subtle Information Delivery during a Conversation: Mode and Bandwidth Investigation},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466425},
doi = {10.1145/2470654.2466425},
abstract = {With proliferation of mobile devices that provide ubiquitous access to information, the question arises of how distracting processing information in social settings can be, especially during face-to-face conversations. However, relevant information presented at opportune moments may help enhance conversation quality. In this paper, we study how much information users can consume during a conversation and what information delivery mode, via audio or visual aids, helps them effectively conceal the fact that they are receiving information. We observe that users can internalize more information while still disguising this fact the best when information is delivered visually in batches (multiple pieces of information at a time) and perform better on both dimensions if information is delivered while they are not speaking. Interestingly, participants qualitatively did not prefer this mode as being the easiest to use, preferring modes that displayed one piece of information at a time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3111–3120},
numpages = {10},
keywords = {human factors, attention, design, augmented reality},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466426,
author = {Gartenberg, Daniel and Breslow, Leonard A. and Park, Joo and McCurry, J. Malcolm and Trafton, J. Gregory},
title = {Adaptive Automation and Cue Invocation: The Effect of Cue Timing on Operator Error},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466426},
doi = {10.1145/2470654.2466426},
abstract = {Adaptive automation (AA) can improve performance while addressing the problems associated with a fully automated system. The best way to invoke AA is unclear, but two ways include critical events and the operator's state. A hybrid model of AA invocation, the dynamic model of operator overload (DMOO), that takes into account critical events and the operator's state was recently shown to improve performance. The DMOO initiates AA using critical events and attention allocation, informed by eye movements. We compared the DMOO with an inaccurate automation invocation system and a system that invoked AA based only on critical events. Fewer errors were made with DMOO than with the inaccurate system. In the critical event condition, where automation was invoked at an earlier point in time, there were more memory and planning errors, while for the DMOO condition, which invocated automation at a later point in time, there were more perceptual errors. These findings provide a framework for reducing specific types of errors through different automation invocation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3121–3130},
numpages = {10},
keywords = {errors, fan-out, supervisory control, eye tracking, adaptive automation, trust in automation, situation awareness},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466427,
author = {Salvucci, Dario D.},
title = {Distraction beyond the Driver: Predicting the Effects of in-Vehicle Interaction on Surrounding Traffic},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466427},
doi = {10.1145/2470654.2466427},
abstract = {Recent studies of driver distraction have reported a number of detrimental effects of in-vehicle interaction on driver performance. This paper examines and predicts the potential effects of such interaction on other vehicles around the driver's vehicle. Specifically, the paper describes how computational cognitive models can be used to predict the complex interactions among several vehicles driving in a line when one or more of the vehicles' drivers are performing a secondary task (phone dialing). The results of simulating two distinct car-following scenarios illustrate that in-vehicle interaction by one driver can have significant downstream effects on other drivers, especially with respect to speed deviations relative to a lead vehicle. This work generalizes recent work developing computational evaluation tools for user interfaces in complex domains, and further serves as an example of how user interaction in some domains can have broader effects on the community at large.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3131–3134},
numpages = {4},
keywords = {driving, driver distraction, cognitive models, multitasking},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466428,
author = {You, Sangseok and Sundar, S. Shyam},
title = {I Feel for My Avatar: Embodied Perception in VEs},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466428},
doi = {10.1145/2470654.2466428},
abstract = {Visual perception is dependent upon one's physical state. The apparent inclination of a hill is overestimated when the observer is carrying a heavy backpack. But, what if the hill is a virtual one and the user is about to navigate the virtual environment through an avatar? In a 2 (user with a backpack vs. user without the backpack) \texttimes{} 2 (avatar with a virtual backpack vs. avatar without a virtual backpack) \texttimes{} 2 (customized avatar vs. assigned avatar) between-subjects experiment (N = 121), participants estimated the hill as being steeper when using a customized avatar rather than an assigned one. When the avatar is encumbered by a heavy virtual backpack, those with a customized avatar perceived the virtual hill as being more difficult to climb. Avatar customization and the physical resources of the avatar (operationalized here in the form of a 'virtual' backpack) were found to be key predictors of embodied perception in virtual environments (VE). This has implications for the design of games and interventions that make use of VEs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3135–3138},
numpages = {4},
keywords = {avatars, customization, virtual worlds, embodied perception},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250098,
author = {Wigdor, Daniel},
title = {Session Details: Papers: Spatial Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250098},
doi = {10.1145/3250098},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466430,
author = {Scarr, Joey and Cockburn, Andy and Gutwin, Carl and Malacria, Sylvain},
title = {Testing the Robustness and Performance of Spatially Consistent Interfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466430},
doi = {10.1145/2470654.2466430},
abstract = {Relative spatial consistency - that is, the stable arrangement of objects in a 2D presentation - provides several benefits for interactive interfaces. Spatial consistency allows users to develop memory of object locations, reducing the time needed for visual search, and because spatial memory is long lasting and has a large capacity these performance benefits are enduring and scalable. This suggests that spatial consistency could be used as a fundamental principle for the design of interfaces. However, there are many display situations where the standard presentation is altered in some way: e.g., a window is moved to a new location, scaled, or rotated on a mobile or tabletop display. It is not known whether the benefits of spatial organization are robust to these common kinds of view transformation. To assess these effects, we tested user performance with a spatial interface that had been transformed in several ways, including different degrees of translation, rotation, scaling, and perspective change. We found that performance was not strongly affected by the changes, except in the case of large rotations. To demonstrate the value of spatial consistency over existing mechanisms for dealing with view changes, we compared user performance with a spatially-stable presentation (using scaling) with that of a 'reflowing' presentation (widely used in current interfaces). This study showed that spatial stability with scaling dramatically outperforms reflowing. This research provides new evidence of spatial consistency's value in interface design: it is robust to the view transformations that occur in typical environments, and it provides substantial performance advantages over traditional methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3139–3148},
numpages = {10},
keywords = {spatial memory, expertise, revisitation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466431,
author = {Ion, Alexandra and Chang, Y.-L. Betty and Haller, Michael and Hancock, Mark and Scott, Stacey D.},
title = {Canyon: Providing Location Awareness of Multiple Moving Objects in a Detail View on Large Displays},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466431},
doi = {10.1145/2470654.2466431},
abstract = {Overview+Detail interfaces can be used to examine the details of complex data while retaining the data's overall context. Dynamic data introduce challenges for these interfaces, however, as moving objects may exit the detail view, as well as a person's field of view if they are working at a large interactive surface. To address this "off-view" problem, we propose a new information visualization technique, called Canyon. This technique attaches a small view of an off-view object, including some surrounding context, to the external boundary of the detail view. The area between the detail view and the region containing the off-view object is virtually "folded" to conserve space. A comparison study was conducted contrasting the benefits and limitations of Canyon to an established technique, called Wedge. Canyon was more accurate across a number of tasks, especially more complex tasks, and was comparably efficient.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3149–3158},
numpages = {10},
keywords = {large display, information visualization, overview+detail, map data, dynamic data},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466432,
author = {Samp, Krystian},
title = {Designing Graphical Menus for Novices and Experts: Connecting Design Characteristics with Design Goals},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466432},
doi = {10.1145/2470654.2466432},
abstract = {This paper presents a design space for graphical menus. We model the design space as a set of design goals, a set of design characteristics, and connections between the two. The design goals are based on novice and expert behaviors. The connections link the choices for design characteristics with the positive or negative effects that these choices have on the design goals. The paper further synthesizes the design space into a succinct form of structured design recommendations. A case study demonstrates how these recommendations can be used to assess and compare the strengths and weaknesses of two menu designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3159–3168},
numpages = {10},
keywords = {cascading menus, radial menus, graphical menus, guides, guidelines, design characteristics, menus, design space},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466433,
author = {Lee, Joon Hyub and Bae, Seok-Hyung},
title = {Binocular Cursor: Enabling Selection on Transparent Displays Troubled by Binocular Parallax},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466433},
doi = {10.1145/2470654.2466433},
abstract = {Binocular parallax is a problem for any interaction system that has a transparent display and objects behind it, as users will see duplicated and overlapped images. In this note, we propose a quantitative measure called Binocular Selectability Discriminant (BSD) to predict the ability of the user to perform selection task in such a setup. In addition, we propose a technique called Binocular Cursor (BC) which takes advantage of this duplicating and overlapping phenomenon, rather than being hampered by it, to resolve binocular selection ambiguity by visualizing the correct selection point. An experiment shows that selection with BC is not slower than monocular selection, and that it can be significantly more precise, depending on the design of BC.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3169–3172},
numpages = {4},
keywords = {binocular parallax, transparent display},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466434,
author = {Kaufmann, Bonifaz and Ahlstr\"{o}m, David},
title = {Studying Spatial Memory and Map Navigation Performance on Projector Phones with Peephole Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466434},
doi = {10.1145/2470654.2466434},
abstract = {Smartphones are useful personal assistants and omnipresent communication devices. However, collaboration is not among their strengths. With the advent of embedded projectors this might change. We conducted a study with 56 participants to find out if map navigation and spatial memory performance among users and observers can be improved by using a projector phone with a peephole interface instead of a smartphone with its touchscreen interface. Our results show that users performed map navigation equally well on both interfaces. Spatial memory performance, however, was 41% better for projector phone users. Moreover, observers of the map navigation on the projector phone were 25% more accurate when asked to recall locations of points of interest after they watched a user performing map navigation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3173–3176},
numpages = {4},
keywords = {handheld projector, spatial memory, peephole interaction, touch interaction, map navigation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250099,
author = {Mutlu, Bilge},
title = {Session Details: Papers: Autism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250099},
doi = {10.1145/3250099},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466436,
author = {Marcu, Gabriela and Tassini, Kevin and Carlson, Quintin and Goodwyn, Jillian and Rivkin, Gabrielle and Schaefer, Kevin J. and Dey, Anind K. and Kiesler, Sara},
title = {Why Do They Still Use Paper? Understanding Data Collection and Use in Autism Education},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466436},
doi = {10.1145/2470654.2466436},
abstract = {Autism education programs for children collect and use large amounts of behavioral data on each student. Staff use paper almost exclusively to collect these data, despite significant problems they face in tracking student data in situ, filling out data sheets and graphs on a daily basis, and using the sheets in collaborative decision making. We conducted fieldwork to understand data collection and use in the domain of autism education to explain why current technology had not met staff needs. We found that data needs are complex and unstandardized, immediate demands of the job interfere with staff ability to collect in situ data, and existing technology for data collection is inadequate. We also identified opportunities for technology to improve sharing and use of data. We found that data sheets are idiosyncratic and not useful without human mediation; improved communication with parents could benefit children's development; and staff are willing, and even eager, to incorporate technology. These factors explain the continued dependence on paper for data collection in this environment, and reveal opportunities for technology to support data collection and improve use of collected data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3177–3186},
numpages = {10},
keywords = {fieldwork, cscw, contextual inquiry},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466437,
author = {Venkatesh, Svetha and Phung, Dinh and Duong, Thi and Greenhill, Stewart and Adams, Brett},
title = {TOBY: Early Intervention in Autism through Technology},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466437},
doi = {10.1145/2470654.2466437},
abstract = {We describe TOBY Playpad, an early intervention program for children with Autism Spectrum Disorder (ASD). TOBY teaches the teacher -- the parent -- during the crucial period following diagnosis, which often coincides with no access to formal therapy. We reflect on TOBY's evolution from table-top aid for flashcards to an iPad app covering a syllabus of 326 activities across 51 skills known to be deficient for ASD children, such imitation, joint attention and language. The design challenges unique to TOBY are the need to adapt to marked differences in each child's skills and rate of development (a trait of ASD) and teach parents unfamiliar concepts core to behavioural therapy, such as reinforcement, prompting, and fading. We report on three trials that successively decrease oversight and increase parental autonomy, and demonstrate clear evidence of learning. TOBY's uniquely intertwined Natural Environment Tasks are found to be effective for children and popular with parents.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3187–3196},
numpages = {10},
keywords = {early intervention, autism, wait-list, toby, therapy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466438,
author = {Hourcade, Juan Pablo and Williams, Stacy R. and Miller, Ellen A. and Huebner, Kelsey E. and Liang, Lucas J.},
title = {Evaluation of Tablet Apps to Encourage Social Interaction in Children with Autism Spectrum Disorders},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466438},
doi = {10.1145/2470654.2466438},
abstract = {The increasing rates of diagnosis for Autism Spectrum Disorders (ASDs) have brought unprecedented attention to these conditions. Interventions during childhood can increase the likelihood of independent living later in life, but most adults with ASDs who benefited from early intervention do not live independently. There is a need for novel therapies and interventions that can help children with ASDs develop the social skills necessary to live independently. Since the launch of the iPad, there has been a great deal of excitement in the autism community about multitouch tablets and their possible use in interventions. There are hundreds of apps listed as possibly helping children with ASDs, yet there is little empirical evidence that any of them have positive effects. In this paper we present a study on the use of a set of apps from Open Autism Software at an afterschool program for children with ASDs. The apps are designed to naturally encourage positive social interactions through creative, expressive, and collaborative activities. The study compared activities conducted with the apps to similar activities conducted without the apps. We video recorded the activities, and coded children's behavior. We found that during the study children spoke more sentences, had more verbal interactions, and were more physically engaged with the activities when using the apps. We also found that children made more supportive comments during activities conducted with two of the apps. The results suggest the approach to using apps evaluated in this paper can increase positive social interactions in children with ASDs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3197–3206},
numpages = {10},
keywords = {tablet, social skills, autism, app},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466439,
author = {Hong, Hwajung and Yarosh, Svetlana and Kim, Jennifer G. and Abowd, Gregory D. and Arriaga, Rosa I.},
title = {Investigating the Use of Circles in Social Networks to Support Independence of Individuals with Autism},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466439},
doi = {10.1145/2470654.2466439},
abstract = {Building social support networks is crucial both for less-independent individuals with autism and for their primary caregivers. In this paper, we describe a four-week exploratory study of a social network service (SNS) that allows young adults with autism to garner support from their family and friends. We explore the unique benefits and challenges of using SNSs to mediate requests for help or advice. In particular, we examine the extent to which specialized features of an SNS can engage users in communicating with their network members to get advice in varied situations. Our findings indicate that technology-supported communication particularly strengthened the relationship between the individual and extended network members, mitigating concerns about over-reliance on primary caregivers. Our work identifies implications for the design of social networking services tailored to meet the needs of this special needs population.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3207–3216},
numpages = {10},
keywords = {autism, independence, social networks, social support},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250100,
author = {Dragicevic, Pierre},
title = {Session Details: Papers: Information Visualization},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250100},
doi = {10.1145/3250100},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466441,
author = {Perin, Charles and Vernier, Fr\'{e}d\'{e}ric and Fekete, Jean-Daniel},
title = {Interactive Horizon Graphs: Improving the Compact Visualization of Multiple Time Series},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466441},
doi = {10.1145/2470654.2466441},
abstract = {Many approaches have been proposed for the visualization of multiple time series. Two prominent approaches are reduced line charts (RLC), which display small multiples for time series, and the more recent horizon graphs (HG). We propose to unify RLC and HG using a new technique - interactive horizon graphs (IHG) - which uses pan and zoom interaction to increase the number of time series that can be analysed in parallel. In a user study we compared RLC, HG, and IHG across several tasks and numbers of time series, focusing on datasets with both large scale and small scale variations. Our results show that IHG outperform the other two techniques in complex comparison and matching tasks where the number of charts is large. In the hardest task PHG have a significantly higher number of good answers (correctness) than HG (+14%) and RLC (+51%) and a lower error magnitude than HG (-64%) and RLC (-86%).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3217–3226},
numpages = {10},
keywords = {visualization, time series, horizon graphs, evaluation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466442,
author = {Matejka, Justin and Grossman, Tovi and Fitzmaurice, George},
title = {Patina: Dynamic Heatmaps for Visualizing Application Usage},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466442},
doi = {10.1145/2470654.2466442},
abstract = {We present Patina, an application independent system for collecting and visualizing software application usage data. Patina requires no instrumentation of the target application, all data is collected through standard window metrics and accessibility APIs. The primary visualization is a dynamic heatmap overlay which adapts to match the content, location, and shape of the user interface controls visible in the active application. We discuss a set of design guidelines for the Patina system, describe our implementation of the system, and report on an initial evaluation based on a short-term deployment of the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3227–3236},
numpages = {10},
keywords = {social learning, visualization},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466443,
author = {Fuchs, Johannes and Fischer, Fabian and Mansmann, Florian and Bertini, Enrico and Isenberg, Petra},
title = {Evaluation of Alternative Glyph Designs for Time Series Data in a Small Multiple Setting},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466443},
doi = {10.1145/2470654.2466443},
abstract = {We present the results of a controlled experiment to investigate the performance of different temporal glyph designs in a small multiple setting. Analyzing many time series at once is a common yet difficult task in many domains, for example in network monitoring. Several visualization techniques have, thus, been proposed in the literature. Among these, iconic displays or glyphs are an appropriate choice because of their expressiveness and effective use of screen space. Through a controlled experiment, we compare the performance of four glyphs that use different combinations of visual variables to encode two properties of temporal data: a) the position of a data point in time and b) the quantitative value of this data point. Our results show that depending on tasks and data density, the chosen glyphs performed differently. Line Glyphs are generally a good choice for peak and trend detection tasks but radial encodings are more effective for reading values at specific temporal locations. From our qualitative analysis we also contribute implications for designing temporal glyphs for small multiple settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3237–3246},
numpages = {10},
keywords = {small multiples, evaluation, information visualization, time series, glyphs},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466444,
author = {Dunne, Cody and Shneiderman, Ben},
title = {Motif Simplification: Improving Network Visualization Readability with Fan, Connector, and Clique Glyphs},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466444},
doi = {10.1145/2470654.2466444},
abstract = {Analyzing networks involves understanding the complex relationships between entities, as well as any attributes they may have. The widely used node-link diagrams excel at this task, but many are difficult to extract meaning from because of the inherent complexity of the relationships and limited screen space. To help address this problem we introduce a technique called motif simplification, in which common patterns of nodes and links are replaced with compact and meaningful glyphs. Well-designed glyphs have several benefits: they (1) require less screen space and layout effort, (2) are easier to understand in the context of the network, (3) can reveal otherwise hidden relationships, and (4) preserve as much underlying information as possible. We tackle three frequently occurring and high-payoff motifs: fans of nodes with a single neighbor, connectors that link a set of anchor nodes, and cliques of completely connected nodes. We contribute design guidelines for motif glyphs; example glyphs for the fan, connector, and clique motifs; algorithms for detecting these motifs; a free and open source reference implementation; and results from a controlled study of 36 participants that demonstrates the effectiveness of motif simplification.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3247–3256},
numpages = {10},
keywords = {network visualization, graph drawing, node-link diagram, visual analytics, motif simplification},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250101,
author = {Munson, Sean},
title = {Session Details: Papers: Social Media Practices},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250101},
doi = {10.1145/3250101},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466446,
author = {Baumer, Eric P.S. and Adams, Phil and Khovanskaya, Vera D. and Liao, Tony C. and Smith, Madeline E. and Schwanda Sosik, Victoria and Williams, Kaiton},
title = {Limiting, Leaving, and (Re)Lapsing: An Exploration of Facebook Non-Use Practices and Experiences},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466446},
doi = {10.1145/2470654.2466446},
abstract = {Despite the abundance of research on social networking sites, relatively little research has studied those who choose not to use such sites. This paper presents results from a questionnaire of over 400 Internet users, focusing specifically on Facebook and those users who have left the service. Results show the lack of a clear, binary distinction between use and non-use, that various practices enable diverse ways and degrees of engagement with and disengagement from Facebook. Furthermore, qualitative analysis reveals numerous complex and interrelated motivations and justifications, both for leaving and for maintaining some type of connection. These motivations include: privacy, data misuse, productivity, banality, addiction, and external pressures. These results not only contribute to our understanding of online sociality by examining this under-explored area, but they also build on previous work to help advance how we conceptually account for the sociological processes of non-use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3257–3266},
numpages = {10},
keywords = {facebook, non-use, technology refusal},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466447,
author = {De Choudhury, Munmun and Counts, Scott and Horvitz, Eric},
title = {Predicting Postpartum Changes in Emotion and Behavior via Social Media},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466447},
doi = {10.1145/2470654.2466447},
abstract = {We consider social media as a promising tool for public health, focusing on the use of Twitter posts to build predictive models about the forthcoming influence of childbirth on the behavior and mood of new mothers. Using Twitter posts, we quantify postpartum changes in 376 mothers along dimensions of social engagement, emotion, social network, and linguistic style. We then construct statistical models from a training set of observations of these measures before and after the reported childbirth, to forecast significant postpartum changes in mothers. The predictive models can classify mothers who will change significantly following childbirth with an accuracy of 71%, using observations about their prenatal behavior, and as accurately as 80-83% when additionally leveraging the initial 2-3 weeks of postnatal data. The study is motivated by the opportunity to use social media to identify mothers at risk of postpartum depression, an underreported health concern among large populations, and to inform the design of low-cost, privacy-sensitive early-warning systems and intervention programs aimed at promoting wellness postpartum.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3267–3276},
numpages = {10},
keywords = {language, postpartum, wellness, health, emotion, social media, depression, childbirth, behavioral health, twitter, ppd},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466448,
author = {Sleeper, Manya and Cranshaw, Justin and Kelley, Patrick Gage and Ur, Blase and Acquisti, Alessandro and Cranor, Lorrie Faith and Sadeh, Norman},
title = {"i Read My Twitter the next Morning and Was Astonished": A Conversational Perspective on Twitter Regrets},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466448},
doi = {10.1145/2470654.2466448},
abstract = {We present the results of an online survey of 1,221 Twitter users, comparing messages individuals regretted either saying during in-person conversations or posting on Twitter. Participants generally reported similar types of regrets in person and on Twitter. In particular, they often regretted messages that were critical of others. However, regretted messages that were cathartic/expressive or revealed too much information were reported at a higher rate for Twitter. Regretted messages on Twitter also reached broader audiences. In addition, we found that participants who posted on Twitter became aware of, and tried to repair, regret more slowly than those reporting in-person regrets. From this comparison of Twitter and in-person regrets, we provide preliminary ideas for tools to help Twitter users avoid and cope with regret.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3277–3286},
numpages = {10},
keywords = {regrets, messaging, twitter, conversation, survey},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466449,
author = {Spiliotopoulos, Tasos and Oakley, Ian},
title = {Understanding Motivations for Facebook Use: Usage Metrics, Network Structure, and Privacy},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466449},
doi = {10.1145/2470654.2466449},
abstract = {This study explores the links between motives for using a social network service and numerical measures of that activity. Specifically, it identified motives for Facebook use by employing a Uses and Gratifications (U&amp;G) approach and then investigated the extent to which these motives can be predicted through usage and network metrics collected automatically via the Facebook API. In total, 11 Facebook usage metrics and eight personal network metrics served as predictors. Results showed that all three variable types in this expanded U&amp;G frame of analysis (covering social antecedents, usage metrics, and personal network metrics) effectively predicted motives and highlighted interesting behaviors. To further illustrate the power of this framework, the intricate nature of privacy in social media was explored and relationships drawn between privacy attitudes (and acts) and measures of use and network structure.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3287–3296},
numpages = {10},
keywords = {social networks, social network sites, uses and gratifications, computer-mediated communication, facebook, privacy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250102,
author = {Vertesi, Janet},
title = {Session Details: Papers: Different Perspectives},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250102},
doi = {10.1145/3250102},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466451,
author = {Bardzell, Jeffrey and Bardzell, Shaowen},
title = {What is "Critical" about Critical Design?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466451},
doi = {10.1145/2470654.2466451},
abstract = {Critical design is a research through design methodology that foregrounds the ethics of design practice, reveals potentially hidden agendas and values, and explores alternative design values. While it seems to be a timely fit for today's socially, aesthetically, and ethically oriented approaches to HCI, its adoption seems surprisingly limited. We argue that its central concepts and methods are unclear and difficult to adopt. Rather than merely attempting to decode the intentions of its originators, Dunne and Raby, we instead turn to traditions of critical thought in the past 150 years to explore a range of critical ideas and their practical uses. We then suggest ways that these ideas and uses can be leveraged as practical resources for HCI researchers interested in critical design. We also offer readings of two designs, which are not billed as critical designs, but which we argue are critical using a broader formulation of the concept than the one found in the current literature.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3297–3306},
numpages = {10},
keywords = {design methodology, critical theory, hci, critical design},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466452,
author = {Hekler, Eric B. and Klasnja, Predrag and Froehlich, Jon E. and Buman, Matthew P.},
title = {Mind the Theoretical Gap: Interpreting, Using, and Developing Behavioral Theory in HCI Research},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466452},
doi = {10.1145/2470654.2466452},
abstract = {Researchers in HCI and behavioral science are increasingly exploring the use of technology to support behavior change in domains such as health and sustainability. This work, however, remain largely siloed within the two communities. We begin to address this silo problem by attempting to build a bridge between the two disciplines at the level of behavioral theory. Specifically, we define core theoretical terms to create shared understanding about what theory is, discuss ways in which behavioral theory can be used to inform research on behavior change technologies, identify shortcomings in current behavioral theories, and outline ways in which HCI researchers can not only interpret and utilize behavioral science theories but also contribute to improving them.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3307–3316},
numpages = {10},
keywords = {behavior change, persuasive technology, behavioral science, theory, behavior change technologies, sustainability, health},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466453,
author = {Feinberg, Melanie},
title = {Beyond Digital and Physical Objects: The Intellectual Work as a Concept of Interest for HCI},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466453},
doi = {10.1145/2470654.2466453},
abstract = {To understand activities of personal collecting and preservation, HCI researchers have investigated why people become attached to particular objects. These studies have examined ways that people relate to physical and digital objects, observing, for example, that people tend to cherish physical objects more than digital ones. This paper proposes that the value of digital objects may inhere less in an object's identity as a particular item and more in the object's ability to provide access to an intellectual work. The work, a familiar concept in information studies and textual studies, designates a general product of intellectual creation that may be instantiated in many versions. (For example, Shakespeare's Hamlet exists in many editions and forms, which may differ in both content and carrier and yet still are all Hamlet.) The paper demonstrates how the concept of the work can extend research on the perceived value of digital objects. It also shows how a flexible definition of the work can reveal new aspects of a design situation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3317–3326},
numpages = {10},
keywords = {memory, works, collecting, design, digital media, preserving, documents, texts, information studies, textual studies},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466454,
author = {Yetim, Fahri},
title = {Critical Perspective on Persuasive Technology Reconsidered},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466454},
doi = {10.1145/2470654.2466454},
abstract = {Critical researchers in HCI have recently faulted Persuasive Technology (PT) for taking a modernist approach and suggested ways for redirecting research. This paper reflects on this critical perspective and compares it with Habermas's critical perspective. I claim that the recent critiques of PT are grounded on a narrow and pessimistic concept of modernism, and that Habermas's works, rarely taken into account in the HCI community, can serve as an alternative lens for reflective analysis and design and can provide a foundation for justifying design decisions while realizing the unfulfilled potentials of PT. Beyond offering critical analysis and reflections, this paper contributes to the HCI field by calling attention to alternative reflective concepts and emerging relevant works.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3327–3330},
numpages = {4},
keywords = {persuasive technology, critical reflection, modernism, critical research, reflective hci},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466455,
author = {Leahu, Lucian and Cohn, Marisa and March, Wendy},
title = {How Categories Come to Matter},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466455},
doi = {10.1145/2470654.2466455},
abstract = {In a study of users' interactions with Siri, the iPhone personal assistant application, we noticed the emergence of overlaps and blurrings between explanatory categories such as "human" and "machine". We found that users work to purify these categories, thus resolving the tensions related to the overlaps. This "purification work" demonstrates how such categories are always in flux and are redrawn even as they are kept separate. Drawing on STS analytic techniques, we demonstrate the mechanisms of such "purification work." We also describe how such category work remained invisible to us during initial data analysis, due to our own forms of latent purification, and outline the particular analytic techniques that helped lead to this discovery. We thus provide an illustrative case of how categories come to matter in HCI research and design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3331–3334},
numpages = {4},
keywords = {Diffractive analysis, materiality for design, category flux},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250103,
author = {Hornb?k, Kasper},
title = {Session Details: Papers: Multi-Device Interaction},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250103},
doi = {10.1145/3250103},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466457,
author = {Schmidt, Dominik and Sas, Corina and Gellersen, Hans},
title = {Personal Clipboards for Individual Copy-and-Paste on Shared Multi-User Surfaces},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466457},
doi = {10.1145/2470654.2466457},
abstract = {Clipboards are omnipresent on today's personal computing platforms. They provide copy-and-paste functionalities that let users easily reorganize information and quickly transfer data across applications. In this work, we introduce personal clipboards to multi-user surfaces. Personal clipboards enable individual and independent copy-and-paste operations, in the presence of multiple users concurrently sharing the same direct-touch interface. As common surface computing platforms do not distinguish touch input of different users, we have developed clipboards that leverage complementary personalization strategies. Specifically, we have built a context menu clipboard based on implicit user identification of every touch, a clipboard based on personal subareas dynamically placed on the surface, and a handheld clipboard based on integration of personal devices for surface interaction. In a user study, we demonstrate the effectiveness of personal clipboards for shared surfaces, and show that different personalization strategies enable clipboards, albeit with different impacts on interaction characteristics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3335–3344},
numpages = {10},
keywords = {multi-touch surfaces, copy-and-paste, clipboards},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466458,
author = {Wallace, James R. and Scott, Stacey D. and MacGregor, Carolyn G.},
title = {Collaborative Sensemaking on a Digital Tabletop and Personal Tablets: Prioritization, Comparisons, and Tableaux},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466458},
doi = {10.1145/2470654.2466458},
abstract = {We describe an investigation of the support that three different display configurations provided for a collaborative sensemaking task: a digital table; personal tablets; and both the tabletop and personal tablets. Mixed-methods analyses revealed that the presence of a digital tabletop display led to improved sensemaking performance, and identified activities that were supported by the shared workspace. The digital tabletop supported a group's ability to prioritize information, to make comparisons between task data, and to form and critique the group's working hypothesis. Analyses of group performance revealed a positive correlation with equity of member participation using the shared digital table, and a negative correlation of equity of member participation using personal tablets. Implications for the support of sensemaking groups, and the use of equity of member participation as a predictive measure of their performance are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3345–3354},
numpages = {10},
keywords = {equity of participation, sensemaking, process, cscw},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466459,
author = {Jokela, Tero and Lucero, Andr\'{e}s},
title = {A Comparative Evaluation of Touch-Based Methods to Bind Mobile Devices for Collaborative Interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466459},
doi = {10.1145/2470654.2466459},
abstract = {We present a comparative evaluation of two touch-based group-binding methods, a leader-driven method and a peer-based method, against a more conventional group-binding method based on scanning and passwords. The results indicate that the participants strongly preferred the touch-based methods in both pragmatic and hedonic qualities as well as in the overall attractiveness. While the leader-driven method allowed better control over the group and required only one participant to be able to form a group, the peer-based method helped to create a greater sense of community and scaled better for larger group sizes and distances. As the optimal group-binding method depends on the social situation and physical environment, the binding methods should be flexible, allowing the users to adapt them to different contexts of use. For determining the order of the devices, manual arrangement was preferred over defining the order by touching.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3355–3364},
numpages = {10},
keywords = {group association, mobile phones, user interfaces, pairing, collocated interaction, device ecosystem binding},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250104,
author = {Mueller, Florian},
title = {Session Details: Papers: On the Move},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250104},
doi = {10.1145/3250104},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466461,
author = {M\'{a}rquez Segura, Elena and Waern, Annika and Moen, Jin and Johansson, Carolina},
title = {The Design Space of Body Games: Technological, Physical, and Social Design},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466461},
doi = {10.1145/2470654.2466461},
abstract = {The past decade has seen an increased focus on body movement in computer games. We take a step further to look at body games: games in which the main source of enjoyment comes from bodily engagement. We argue that for these games, the physical and social settings become just as important design resources as the technology. Although all body games benefit from an integrated design approach, the social and physical setting become particularly useful as design resources when the technology has limited sensing capabilities. We develop our understanding of body games through a literature study and a concrete design experiment with designing multiplayer games for the BodyBug, a mobile device with limited sensing capabilities. Although the device was designed for free and natural movements, previous games fell short in realizing this design ideal. By designing the technology function together with its physical and social context, we were able to overcome device limitations. One of the games was subsequently incorporated in its commercial release.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3365–3374},
numpages = {10},
keywords = {play, exertion game, body game, game, gesture, sensing, bodybug, interactive toy, social play, children, movement, dance, design, oriboo},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466462,
author = {Mentis, Helena M. and Johansson, Carolina},
title = {Seeing Movement Qualities},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466462},
doi = {10.1145/2470654.2466462},
abstract = {With the increased availability of movement based interactive devices there is a growing interest in exploring the potential design space for engaging movement-based interactions. This has led to the exploration of different ways to sense and model movement such as Laban Movement Analysis' Effort qualities. However, little is understood in how movement qualities are perceived and experienced by users. We explored this in an interactive improvisational dance performance setting. From video analysis with a Laban Movement expert and post-performance interviews with audience members, we discuss the differences in how a movement quality was perceived. From these findings, we discuss implications for further efforts in designing interactive movement-based systems that strive to capitalize on movement qualities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3375–3384},
numpages = {10},
keywords = {kinect, laban, movement qualities, vision},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466463,
author = {Hincapi\'{e}-Ramos, Juan David and Irani, Pourang},
title = {CrashAlert: Enhancing Peripheral Alertness for Eyes-Busy Mobile Interaction While Walking},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466463},
doi = {10.1145/2470654.2466463},
abstract = {Mobile device use while walking, or eyes-busy mobile interaction, is a leading cause of life-threatening pedestrian collisions. We introduce CrashAlert, a system that augments mobile devices with a depth camera, to provide distance and location visual cues of obstacles on the user's path. In a realistic environment outside the lab, CrashAlert users improve their handling of potential collisions, dodging and slowing down for simple ones while lifting their head in more complex situations. Qualitative results outline the value of extending users' peripheral alertness in eyes-busy mobile interaction through non-intrusive depth cues, as used in CrashAlert. We present the design features of our system and lessons learned from our evaluation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3385–3388},
numpages = {4},
keywords = {texting and walking, eyes-busy interaction, walking user interfaces, obstacle avoidance},
location = {Paris, France},
series = {CHI '13}
}

@inbook{10.1145/2470654.2466464,
author = {Tanenbaum, Joshua G. and Antle, Alissa N. and Robinson, John},
title = {Three Perspectives on Behavior Change for Serious Games},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466464},
abstract = {Research into the effects of serious games often engages with interdisciplinary models of how human behaviors are shaped and changed over time. To better understand these different perspectives we articulate three cognitive models of behavior change and consider the potential of these models to support a deeper understanding of behavior change in serious games. Two of these models -- Information Deficit and Procedural Rhetoric -- have already been employed in the design of serious games, while the third -- Emergent Dialogue -- is introduced from the field of Environmental Studies. We situate this discussion within a context of designing games for public engagement with issues of environmental sustainability.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3389–3392},
numpages = {4}
}

@inproceedings{10.1145/3250105,
author = {Egelman, Serge},
title = {Session Details: Papers: Understanding Privacy},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250105},
doi = {10.1145/3250105},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466466,
author = {Kelley, Patrick Gage and Cranor, Lorrie Faith and Sadeh, Norman},
title = {Privacy as Part of the App Decision-Making Process},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466466},
doi = {10.1145/2470654.2466466},
abstract = {Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short "Privacy Facts' display, which we tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3393–3402},
numpages = {10},
keywords = {interface, android, mobile, privacy, decision-making},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466467,
author = {Khovanskaya, Vera and Baumer, Eric P.S. and Cosley, Dan and Voida, Stephen and Gay, Geri},
title = {"Everybody Knows What You're Doing": A Critical Design Approach to Personal Informatics},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466467},
doi = {10.1145/2470654.2466467},
abstract = {We present an alternative approach to the design of personal informatics systems: instead of motivating people to examine their own behaviors, this approach promotes awareness of and reflection on the infrastructures behind personal informatics and the modes of engagement that they promote. Specifically, this paper presents an interface that displays personal web browsing data. The interface aims to reveal underlying infrastructure using several methods: drawing attention to the scope of mined data by displaying deliberately selected sensitive data, using purposeful malfunction as a way to encourage reverse engineering, and challenging normative expectations around data mining by displaying information in unconventional ways. Qualitative results from a two-week deployment show that these strategies can raise people's awareness about data mining, promote efficacy and control over personal data, and inspire reflection on the goals and assumptions embedded in infrastructures for personal data analytics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3403–3412},
numpages = {10},
keywords = {personal informatics, critical design, design strategies},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466468,
author = {Yarosh, Svetlana},
title = {Shifting Dynamics or Breaking Sacred Traditions? The Role of Technology in Twelve-Step Fellowships},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466468},
doi = {10.1145/2470654.2466468},
abstract = {Twelve-step fellowships are the most common long-term maintenance program for recovery from alcoholism and addiction. Informed by six months of participatory observation of twelve-step fellowship meetings and service structure, I conducted in-depth interviews with twelve members of Alcoholics Anonymous (AA) and Narcotics Anonymous (NA) about the role of technology in recovery. I found that there are a number of tensions in how technology is perceived and adopted. As technology and twelve-step fellowships interact, issues of anonymity, identity, consensus, access, unity, autonomy, and physical presence are foregrounded. I relate these findings to the broader research landscape and provide implications for future design in this space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3413–3422},
numpages = {10},
keywords = {spirituality, addiction, twelve-step fellowships, recovery},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466469,
author = {Ronen, Shahar and Riva, Oriana and Johnson, Maritza and Thompson, Donald},
title = {Taking Data Exposure into Account: How Does It Affect the Choice of Sign-in Accounts?},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466469},
doi = {10.1145/2470654.2466469},
abstract = {Online services collect personal data from their users, sometimes with no clear need. We studied how users sign-in to web sites using federated IDs, and found that most survey respondents were not aware of the data they expose. However, when presented with the tradeoffs behind each sign-in option, respondents reported a willingness to change how they sign-in to reduce their data exposure or, in fewer cases, to increase it to receive more benefits from the service. Our findings suggest that data exposure is a concern for users, and that there is a need for finding clearer ways for communicating it for each sign-in option.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3423–3426},
numpages = {4},
keywords = {sign in, online services, federated identity, data exposure},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466470,
author = {Panjwani, Saurabh and Shrivastava, Nisheeth and Shukla, Saurabh and Jaiswal, Sharad},
title = {Understanding the Privacy-Personalization Dilemma for Web Search: A User Perspective},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466470},
doi = {10.1145/2470654.2466470},
abstract = {Contemporary search engines use a variety of techniques to personalize search results based on users' past queries. While studies have found that users generally prefer personalized search results to non-personalized ones, recent surveys also indicate growing reservations with respect to personalization because of its privacy implications. In this paper, we take a deeper look at privacy considerations of users during web search and explore how users' preferences for privacy and personalization interact when undertaking this activity. We conduct an empirical study over Google search, involving 25 participants in India and their respective web search histories. Our finding is that users exhibit a slight preference for personalization in their search results but are usually willing to "give up" personalization when searching for topics they deem sensitive. We discuss implications of these results for the design of privacy-preserving tools for web search.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3427–3430},
numpages = {4},
keywords = {web search, personalization, user study, privacy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250106,
author = {Selby, Mark},
title = {Session Details: Papers: Design Strategies},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250106},
doi = {10.1145/3250106},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466472,
author = {Grosse-Hering, Barbara and Mason, Jon and Aliakseyeu, Dzmitry and Bakker, Conny and Desmet, Pieter},
title = {Slow Design for Meaningful Interactions},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466472},
doi = {10.1145/2470654.2466472},
abstract = {In this paper we report on an exploration of how to apply the theory of Slow Design to mass produced products to establish more mindful usage of products; the intention behind this is to promote product attachment and the associated sustainable benefits of long term use. Slow Design is a design philosophy that focuses on promoting well-being for individuals, society, and the natural environment. It encourages people to do things at the right time and at the right speed which helps them to understand and reflect on their actions. Several authors have proposed Slow Design principles and cases have been reported in which these principles were applied in cultural design projects. These applications indicated that Slow Design can indeed have a positive impact on wellbeing. Although promising, this philosophy has not yet been used in the design of mass consumer products. In this paper we present a design case study in which we explored how the Slow Design principles can be applied in the design of an electric fruit juicer. Two studies are reported on where the conditions for implementing Slow Design are explored. The results led to a revision of the principles for use by product designers. The main finding from the case study is that the Slow Design principles can be used to create more 'mindful' interactions that stimulate positive user involvement. This is not from designing interactions that require more time per se, but by stimulating the user to use more time for those parts of the interaction that are meaningful and less for those that are not meaningful.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3431–3440},
numpages = {10},
keywords = {slow design, sustainability, product attachment},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466473,
author = {Wallace, Jayne and McCarthy, John and Wright, Peter C. and Olivier, Patrick},
title = {Making Design Probes Work},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466473},
doi = {10.1145/2470654.2466473},
abstract = {Probes have been adopted with great enthusiasm in both Design and HCI. The heterogeneity with which they have been used in practice reflects how the method has proved elusive for many. Originators and commentators of probes have discussed misinterpretations of the method, highlighting the lack of accounts that describe in detail the design of probes and their use with participants. This paper discusses our particular use of Design Probes as directed craft objects that are both tools for design and tools for exploration across a number of projects, spanning a decade, centered on self-identity and personal significance. In offering an example of what a framework for probe design and use might look like, we attempt to address the identified lacuna, providing a synthetic account of probe design and use over an extended period and conceptualizing the relationship between the properties of probes and their use in design projects.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3441–3450},
numpages = {10},
keywords = {trust, materiality, probes, interaction design, design, craft, investment, reciprocity, empathy},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466474,
author = {Gaver, William W. and Bowers, John and Boehner, Kirsten and Boucher, Andy and Cameron, David W.T. and Hauenstein, Mark and Jarvis, Nadine and Pennington, Sarah},
title = {Indoor Weather Stations: Investigating a Ludic Approach to Environmental HCI through Batch Prototyping},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466474},
doi = {10.1145/2470654.2466474},
abstract = {In this project, we investigated how a ludic approach might open new possibilities for environmental HCI by designing three related devices that encourage environmental awareness while eschewing utilitarian or persuasive agendas. In addition, we extended our methodological approach by batch-producing multiple copies of each device and deploying them to 20 households for several months, gathering a range of accounts about how people engaged and used them. The devices, collectively called the 'Indoor Weather Stations', reveal the home's microclimate by highlighting small gusts of wind, the colour of ambient light, and temperature differentials within the home. We found that participants initially tended to relate to the devices in line with two 'orienting narratives' of environmental tools or ludic designs, finding the devices disappointing from either perspective. Most of our participants showed lingering affection for the devices, however, for a variety of reasons. We discuss the implications of this 'sporadic interaction', and the more general lessons from the project, both for environmental HCI and ludic design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3451–3460},
numpages = {10},
keywords = {ludic design, research through design, sensing, environmental hci, ubiquitous computing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3250107,
author = {Nisi, Valentina},
title = {Session Details: Papers: Tensions in Social Media},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250107},
doi = {10.1145/3250107},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466476,
author = {Valkanova, Nina and Jorda, Sergi and Tomitsch, Martin and Vande Moere, Andrew},
title = {Reveal-It! The Impact of a Social Visualization Projection on Public Awareness and Discourse},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466476},
doi = {10.1145/2470654.2466476},
abstract = {Public displays and projections are becoming increasingly available in various informal urban settings. However, their potential impact on informing and engaging citizens on relevant issues has still been largely unexplored. In this paper, we show that visualizations displayed in public settings are able to increase social awareness and discourse by exposing underlying patterns in data that is submitted by citizens. We thus introduce the design and evaluation of Reveal-it!, a public, interactive projection that facilitates the comparison of the energy consumptions of individuals and communities. Our in-the-wild deployment in three distinct physical locations provided insights into: 1) how people responded to this form of display in different contexts; 2) how it influenced people's perception and discussion of individual and communal data; and 3) the implications for a public visualization as a tool for increasing awareness and discourse. We conclude by discussing emerging participant behaviors, as well as some challenges involved in facilitating a socially motivated crowd-sourced visualization in the public context.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3461–3470},
numpages = {10},
keywords = {urban visualization, energy consumption, awareness, urban screen, sustainability, evaluation, captology, public display, reflection, in-the-wild study, persuasive computing},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466477,
author = {Denef, Sebastian and Bayerl, Petra S. and Kaptein, Nico A.},
title = {Social Media and the Police: Tweeting Practices of British Police Forces during the August 2011 Riots},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466477},
doi = {10.1145/2470654.2466477},
abstract = {With this paper we take a first step to understand the appropriation of social media by the police. For this purpose we analyzed the Twitter communication by the London Metropolitan Police (MET) and the Greater Manchester Police (GMP) during the riots in August 2011. The systematic comparison of tweets demonstrates that the two forces developed very different practices for using Twitter. While MET followed an instrumental approach in their communication, in which the police aimed to remain in a controlled position and keep a distance to the general public, GMP developed an expressive approach, in which the police actively decreased the distance to the citizens. In workshops and interviews, we asked the police officers about their perspectives, which confirmed the identified practices. Our study discusses benefits and risks of the two approaches and the potential impact of social media on the evolution of the role of police in society.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3471–3480},
numpages = {10},
keywords = {twitter, police, uk riots, microblogging, crisis communication},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466478,
author = {Hu, Yuheng and Farnham, Shelly D. and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {Whoo.Ly: Facilitating Information Seeking for Hyperlocal Communities Using Social Media},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466478},
doi = {10.1145/2470654.2466478},
abstract = {Social media systems promise powerful opportunities for people to connect to timely, relevant information at the hyper local level. Yet, finding the meaningful signal in noisy social media streams can be quite daunting to users. In this paper, we present and evaluate Whoo.ly, a web service that provides neighborhood-specific information based on Twitter posts that were automatically inferred to be hyperlocal. Whoo.ly automatically extracts and summarizes hyperlocal information about events, topics, people, and places from these Twitter posts. We provide an overview of our design goals with Whoo.ly and describe the system including the user interface and our unique event detection and summarization algorithms. We tested the usefulness of the system as a tool for finding neighborhood information through a comprehensive user study. The outcome demonstrated that most participants found Whoo.ly easier to use than Twitter and they would prefer it as a tool for exploring their neighborhoods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3481–3490},
numpages = {10},
keywords = {twitter, civic engagement, event detection, hyperlocal community, location-based social networks, social media},
location = {Paris, France},
series = {CHI '13}
}

