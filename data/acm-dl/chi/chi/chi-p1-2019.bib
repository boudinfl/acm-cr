@proceedings{10.1145/3290605,
title = {CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are excited to welcome you to CHI 2019 in Glasgow! This is the first time CHI has been in the UK and we very happy to host it in Scotland. Our theme is 'Weaving the Threads of CHI', reflected in our celtic knot symbol of strength and friendship. The threads of CHI are people from different disciplines, cultures, communities, backgrounds - designers, researchers, practitioners - weaving together around the common purpose of technology that works for people and society.The theme of weaving informed all our planning and we are excited to present a vibrant programme for you to experience. Apart from an outstanding technical programme, we have created many other opportunities for 'weaving' to happen: Lunch CHI on Monday-Wednesday; CHI Stories on Tuesday evening; and an evening UX Industry event with a special invited speaker. We have also organised open social events every evening, including a Newcomers reception on Sunday and a sponsors reception on Wednesday in the Science Centre.A particular highlight is the Interactivity and Demonstrations programme, launched at the Reception on Monday evening, giving a live glimpse into the future with 50 hands-on prototypes, artworks, design experiences as well as inspirational technologies, and including a special 20 year anniversary exhibition from Nottingham University's Mixed Reality Lab.We are thrilled with our dynamic keynote speakers. Aleks Krotoski is a broadcaster, journalist and academic who presents the BBC Digital Human series and The Guardian newspaper's Tech Weekly podcast. Ivan Poupyrev (Google) is an award-winning technology leader, scientist and designer working at the cutting edge of interactive technologies and textiles.We are also excited to continue the commitment to making CHI, and CHI content, more widely accessible. We will be live-streaming most paper sessions. We will support remote attendance to social sessions through a new form of telepresence being trialed this year. We also support diversity and inclusion by providing a nursing room, all-gender bathrooms, badge pronouns, a desensitization room and a prayer room. We have appointed Equity chairs for the first time to take a broader overview of equity concerns. Our new Sustainability chairs are also helping us take steps towards making the CHI event more sustainable.},
location = {Glasgow, Scotland Uk}
}

@inproceedings{10.1145/3290605.3300692,
author = {Abbott, Jacob and MacLeod, Haley and Nurain, Novia and Ekobe, Gustave and Patil, Sameer},
title = {Local Standards for Anonymization Practices in Health, Wellness, Accessibility, and Aging Research at CHI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300692},
doi = {10.1145/3290605.3300692},
abstract = {When studying technologies pertaining to health, wellness, accessibility, and aging, researchers are often required to perform a balancing act between controlling and sharing sensitive data of the people in their studies and protecting the privacy of these participants. If the data can be anonymized and shared, it can boost the impact of the research by facilitating replication and extension. Despite anonymization, data reporting and sharing may lead to re-identification of participants, which can be particularly problematic when the research deals with sensitive topics, such as health. We analyzed 509 CHI papers in the domains of health, wellness, accessibility, and aging to examine data reporting and sharing practices. Our analysis revealed notable patterns and trends regarding the reporting of age, gender, participant types, sample sizes, methodology, ethical considerations, anonymization techniques, and data sharing. Based on our findings, we propose several suggestions for community standards and practices that could facilitate data reporting and sharing while limiting the privacy risks for study participants.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {data sharing, privacy, anonymization, methodology, meta-hci, research reporting},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300602,
author = {Liu, Guanhong and Ding, Xianghua and Yu, Chun and Gao, Lan and Chi, Xingyu and Shi, Yuanchun},
title = {"I Bought This for Me to Look More Ordinary": A Study of Blind People Doing Online Shopping},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300602},
doi = {10.1145/3290605.3300602},
abstract = {Online shopping, by reducing the needs for traveling, has become an essential part of lives for people with visual impairments. However, in HCI, research on online shopping for them has only been limited to the analysis of accessibility and usability issues. To develop a broader and better understanding of how visually impaired people shop online and design accordingly, we conducted a qualitative study with twenty blind people. Our study highlighted that blind people's desire of being treated as ordinary had significantly shaped their online shopping practices: very attentive to the visual appearance of the goods even they themselves could not see and taking great pain to find and learn what commodities are visually appropriate for them. This paper reports how their trying to appear ordinary is manifested in online shopping and suggests design implications to support these practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {visual impairment, ordinariness, blindness, online shopping},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300366,
author = {Chen, Anita and Yuan, Chien-Wen and Ma, Ning F. and Hsu, Chi-Yang and Hanrahan, Benjamin V.},
title = {Navigating Ride-Sharing Regulations: How Regulations Changed the 'Gig' of Ride-Sharing for Drivers in Taiwan},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300366},
doi = {10.1145/3290605.3300366},
abstract = {Ride-sharing platforms have rapidly spread and disrupted ride hailing markets, resulting in conflicts between ride-sharing and taxi drivers. Taxi drivers claim that their counterparts have unfair advantages in terms of lower prices and a more stable customer base, making it difficult to earn a living. Local government entities have dealt with this disruption and conflict in different ways, often looking towards some form of regulation. While there have been discussions about what the regulation should be, there has been less work looking at what impacts regulations have on ride-sharing drivers and their usage of the platforms. In this paper we present our interview study of ride-sharing drivers in Taiwan, who have gone through three distinct phases of regulation. Drivers felt that regulations legitimized their work, while having to navigate consequences related to regulated access to platforms and fundamental changes to the "gig'' of ride-sharing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ride-sharing, uber, on-demand work, regulation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300792,
author = {Brudy, Frederik and Holz, Christian and R\"{a}dle, Roman and Wu, Chi-Jui and Houben, Steven and Klokmose, Clemens Nylandsted and Marquardt, Nicolai},
title = {Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300792},
doi = {10.1145/3290605.3300792},
abstract = {Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–28},
numpages = {28},
keywords = {taxonomy, cross-device interaction, cross-surface, distributed user interfaces, survey, multi-device, cross-device computing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300902,
author = {Teng, Shan-Yuan and Huang, Da-Yuan and Wang, Chi and Gong, Jun and Seyed, Teddy and Yang, Xing-Dong and Chen, Bing-Yu},
title = {Aarnio: Passive Kinesthetic Force Output for Foreground Interactions on an Interactive Chair},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300902},
doi = {10.1145/3290605.3300902},
abstract = {We propose a new type of haptic output for foreground interactions on an interactive chair, where input is carried out explicitly in the foreground of the user's consciousness. This type of force output restricts a user's motion by modulating the resistive force when rotating a seat, tilting the backrest, or rolling the chair. These interactions are useful for many applications in a ubiquitous computing environment, ranging from immersive VR games to rapid and private query of information for people who are occupied with other tasks (e.g. in a meeting). We carefully designed and implemented our proposed haptic force output on a standard office chair and determined the recognizability of five force profiles for rotating, tilting, and rolling the chair. We present the result of our studies, as well as a set of novel interaction techniques enabled by this new force output for chairs.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {haptics, interactive chair, passive kinesthetic force output},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300709,
author = {Phelan, Chanda and Hullman, Jessica and Kay, Matthew and Resnick, Paul},
title = {Some Prior(s) Experience Necessary: Templates for Getting Started With Bayesian Analysis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300709},
doi = {10.1145/3290605.3300709},
abstract = {Bayesian statistical analysis has gained attention in recent years, including in HCI. The Bayesian approach has several advantages over traditional statistics, including producing results with more intuitive interpretations. Despite growing interest, few papers in CHI use Bayesian analysis. Existing tools to learn Bayesian statistics require significant time investment, making it difficult to casually explore Bayesian methods. Here, we present a tool that lowers the barrier to exploration: a set of R code templates that guide Bayesian novices through their first analysis. The templates are tailored to CHI, supporting analyses found to be most common in recent CHI papers. In a user study, we found that the templates were easy to understand and use. However, we found that participants without a statistical background were not confident in their use. Together our contributions provide a concise analysis tool and empirical results for understanding and addressing barriers to using Bayesian analysis in HCI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {tutorials, bayesian statistics, hypothesis testing, statistics, evaluation, code templates},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300449,
author = {Martens, Jean-Bernard},
title = {Interpreting the Diversity in Subjective Judgments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300449},
doi = {10.1145/3290605.3300449},
abstract = {In a CHI paper from 10 years ago, entitled "Accounting for Diversity in Subjective Judgments", an interesting dichotomy was reported between, on the one side, the increased use of idiosyncratic constructs when judging the user experience of diverse products and, on the other hand, the statistical methods available to analyze such data. The paper more specifically proposed a method to extract diverse perspectives (called views) from experimental data. The current paper provides three improvements of this existing method by: 1) showing that a little-known approach for clustering attributes, called VARCLUS, can be applied and extended to provide a more optimal algorithm, 2) showing how the VARCLUS method can be applied to perform both within- and across-subject analysis, and 3) providing access to the VARCLUS method by incorporating it in ILLMO, a user-friendly and freely available program for interactive statistics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {user experience, diversity, repertory grid, clustering, quantitative methods},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300455,
author = {Mekler, Elisa D. and Hornb\ae{}k, Kasper},
title = {A Framework for the Experience of Meaning in Human-Computer Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300455},
doi = {10.1145/3290605.3300455},
abstract = {The view of quality in human-computer interaction continuously develops, having in past decades included consistency, transparency, usability, and positive emotions. Recently, meaning is receiving increased interest in the user experience literature and in industry, referring to the end, purpose or significance of interaction with computers. However, the notion of meaning remains elusive and a bewildering number of senses are in use. We present a framework of meaning in interaction, based on a synthesis of psychological meaning research. The framework outlines five distinct senses of the experience of meaning: connectedness, purpose, coherence, resonance, and significance. We illustrate the usefulness of the framework by analyzing a selection of recent papers at the CHI conference and by raising a series of open research questions about the interplay of meaning, user experience, reflection, and well-being.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {meaningfulness, user experience, meaning, meaningful interaction, meaning-making},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300495,
author = {Feuston, Jessica L. and Piper, Anne Marie},
title = {Everyday Experiences: Small Stories and Mental Illness on Instagram},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300495},
doi = {10.1145/3290605.3300495},
abstract = {Despite historical precedence and modern prevalence, mental illness and associated disorders are frequently aligned with notions of deviance and, by association, abnormality. The view that mental illness deviates from an implicit social norm permeates the CHI community, impacting how scholars approach research in this space. In this paper, we challenge community and societal norms aligning mental illness with deviance. We combine semi-structured interviews with digital ethnography of public Instagram accounts to examine how Instagram users express mental illness. Drawing on small stories research, we find that individuals situate mental illness within their everyday lives and negotiate their tellings of experience due to the influence of various social control structures. We discuss implications for incorporating 'the everyday' into the design of technological solutions for marginalized communities and the ways in which researchers and designers may inadvertently perpetuate and instantiate stigma related to mental illness.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mental illness, small stories research, social control, social media, instagram},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300508,
author = {Inman, Sarah and Ribes, David},
title = {"Beautiful Seams": Strategic Revelations and Concealments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300508},
doi = {10.1145/3290605.3300508},
abstract = {This paper tracks a debate that occurred, first, within the field of Ubiquitous Computing but quickly spread to CHI and beyond, in which design scholars argued that seamlessness had long been an implicit and privileged design virtue, often at the expense of seamfulness. Seamless design emphasizes clarity, simplicity, ease of use, and consistency to facilitate technological interaction. Seamful design emphasizes configurability, user appropriation, and revelation of complexity, ambiguity or inconsistency. Here we review these literatures together and argue that, rather than rival approaches, seamful and seamless design are complements, each emphasizing different aspects of downstream user agency. Ultimately, we situate this debate within the larger, perennial discussion about the strategic revelation and concealment of human and technological operations, and therein the role of design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {seamful and seamless design, infrastructure, ubiquitous computing, temporality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300236,
author = {Schofield, Tom and Foster Smith, Daniel and Bozoglu, G\"{o}n\"{u}l and Whitehead, Christopher},
title = {Design and Plural Heritages: Composing Critical Futures},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300236},
doi = {10.1145/3290605.3300236},
abstract = {We make theoretical and methodological contributions to the CHI community by introducing comparisons between contemporary Critical Heritage research and some forms of experimental design practice. Beginning by identifying three key approaches in contemporary heritage research: Critical Heritage, Plural Heritages and Future Heritage we introduce these in turn, while exploring their significance for thinking about design, knowledge and diversity. We discuss our efforts to apply ideas integrating Critical Heritage and design through the adoption of known Research through Design techniques in a research project in Istanbul, Turkey describing the design of our study and how this was productive of sensory and speculative reflection on the past. Finally, we reflect on the usefulness of such methods in developing new interactive technologies in heritage contexts and go on to propose a series of recommendations for a future Critical Heritage Design practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {critical heritage, plural heritages, cultural probes, future heritage},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300569,
author = {Keyes, Os and Hoy, Josephine and Drouhard, Margaret},
title = {Human-Computer Insurrection: Notes on an Anarchist HCI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300569},
doi = {10.1145/3290605.3300569},
abstract = {The HCI community has worked to expand and improve our consideration of the societal implications of our work and our corresponding responsibilities. Despite this increased engagement, HCI continues to lack an explicitly articulated politic, which we argue re-inscribes and amplifies systemic oppression. In this paper, we set out an explicit political vision of an HCI grounded in emancipatory autonomy-an anarchist HCI, aimed at dismantling all oppressive systems by mandating suspicion of and a reckoning with imbalanced distributions of power. We outline some of the principles and accountability mechanisms that constitute an anarchist HCI. We offer a potential framework for radically reorienting the field towards creating prefigurative counterpower-systems and spaces that exemplify the world we wish to see, as we go about building the revolution in increment.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {oppression, power, intersectionality, theory, anti-capitalism, design, autonomy, prefigurative politics, social change, anarchism},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300580,
author = {Vishwanath, Aditya and Karusala, Naveena and Wong-Villacres, Marisol and Kumar, Neha},
title = {Engaging Lived and Virtual Realities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300580},
doi = {10.1145/3290605.3300580},
abstract = {We examined the integration of VR into informal and less-structured learning environments in Atlanta (USA) and Mumbai (India) through a process of co-design, co-creation, and co-learning with students and teachers where students learned to use VR to engage with their economic, social, and cultural realities. Using qualitative methods, we engaged students and teachers at both sites in VR content creation activities; through these activities, we attempt to uncover a deeper understanding of the challenges and opportunities of introducing low-cost mobile VR for content generation, consumption, and sharing in underserved learning contexts. We also motivate future work that looks at integrating VR in new contexts, using flexible methods, across borders. The larger vision of our research is to advance us towards greater accessibility and inclusivity of VR across diverse learning environments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {hci4d, india, usa, vr, classrooms},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300490,
author = {Mustafa, Maryam and Mazhar, Noor and Asghar, Ayesha and Usmani, Maryem Zafar and Razaq, Lubna and Anderson, Richard},
title = {Digital Financial Needs of Micro-Entrepreneur Women in Pakistan: Is Mobile Money The Answer?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300490},
doi = {10.1145/3290605.3300490},
abstract = {This paper studies the use of Digital Financial Services (DFS) as a solution to women's financial inclusion in deeply patriarchal, resource constrained communities. Through a qualitative, empirical study we map the financial life cycles of 20 women micro-entrepreneurs in different cities in Pakistan and the challenges they face. We explore how technology is currently influencing these women's businesses and personal lives and reveal how mobile money is not tuned to the problems they face and their financial needs. We present alternate design directions for meeting the technological and financial needs of these women, circumnavigating the patriarchal structures that constrain them.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {low-resource, gender, women, dfs, financial inclusion},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300242,
author = {Zhang, Xujing and Braley, Sean and Rubens, Calvin and Merritt, Timothy and Vertegaal, Roel},
title = {LightBee: A Self-Levitating Light Field Display for Hologrammatic Telepresence},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300242},
doi = {10.1145/3290605.3300242},
abstract = {LightBee is a novel "hologrammatic" telepresence system featuring a self-levitating light field display. It consists of a drone that flies a projection of a remote user's head through 3D space. The movements of the drone are controlled by the remote user's head movements, offering unique support for non-verbal cues, especially physical proxemics. The light field display is created by a retro-reflective sheet that is mounted on the cylindrical quadcopter. 45 smart projectors, one per 1.3 degrees, are mounted in a ring, each projecting a video stream rendered from a unique perspective onto the retroreflector. This creates a light field that naturally provides motion parallax and stereoscopy without requiring any headset nor stereo glasses. LightBee allows multiple local users to experience their own unique and correct perspective of the remote user's head. The system is currently one-directional: 2 small cameras mounted on the drone allow the remote user to observe the local scene.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {light field, quadcopter, cylindrical display, telepresence, glasses-free 3d, projector array},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300565,
author = {Marsden, Nicola and Pr\"{o}bster, Monika},
title = {Personas and Identity: Looking at Multiple Identities to Inform the Construction of Personas},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300565},
doi = {10.1145/3290605.3300565},
abstract = {Personas are valuable tools to help designers get to know their users and adopt their perspectives. Yet people are complex and multiple identities have to be considered in their interplay to account for a comprehensive representation otherwise, personas might be superficial and prone to activate stereotypes. Therefore, the way users' identities are presented in a limited set of personas is crucial to account for diversity and highlight facets which otherwise would go unnoticed. In this paper, we introduce an approach to the development of personas informed by social identity theory. The effectiveness of this approach is investigated in a qualitative study in the context of the design process for an e-learning platform for women in tech. The results suggest that considering multiple identities in the construction of personas adds value when designing technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {personas, qualitative study, social identity, gender, co-design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300353,
author = {Alahmadi, Alaa and Davies, Alan and Royle, Jennifer and Vigo, Markel and Jay, Caroline},
title = {Evaluating the Impact of Pseudo-Colour and Coordinate System on the Detection of Medication-Induced ECG Changes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300353},
doi = {10.1145/3290605.3300353},
abstract = {The electrocardiogram (ECG), a graphical representation of the heart's electrical activity, is used for detecting cardiac pathologies. Certain medications can produce a complication known as 'long QT syndrome', shown on the ECG as an increased gap between two parts of the waveform. Self-monitoring for this could be lifesaving, as the syndrome can result in sudden death, but detecting it on the ECG is difficult. Here we evaluate whether using pseudo-colour to highlight wave length and changing the coordinate system can support lay people in identifying increases in the QT interval. The results show that introducing colour significantly improves accuracy, and that whilst it is easier to detect a difference without colour with Cartesian coordinates, the greatest accuracy is achieved when Polar coordinates are combined with colour. The results show that applying simple visualisation techniques has the potential to improve ECG interpretation accuracy, and support people in monitoring their own ECG.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visual perception, visualisation, drug-induced lqts, ecg},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300910,
author = {Howell, Noura and Niemeyer, Greg and Ryokai, Kimiko},
title = {Life-Affirming Biosensing in Public: Sounding Heartbeats on a Red Bench},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300910},
doi = {10.1145/3290605.3300910},
abstract = {"Smart city" narratives promise IoT data-driven innovations leveraging biosensing technologies. We argue this overlooks a potential benefit of city living: affirmation. We designed the Heart Sounds Bench, which amplifies the heart sounds of those sitting on it, as well as recording and playing back the heart sounds of previous sitters. We outline our design intent to invite rest, reflection, and recognition of others' lives in public space. We share results from a study with 19 participants. Participants expressed feeling connected to a shared life energy including others and the environment, and described heart sounds as feeling intimate yet anonymous. Finally, we elaborate the concept of life-affirmation in terms of recognition of others' lives, feeling connection, and respecting untranslatable differences with opacity, as a way of helping "smart city" designs embrace a multiplicity of desires.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {public space, heartrate, biosensing, heart sounds, affirmation, bench, smart city},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300566,
author = {Lee, Kyungjun and Kacorri, Hernisa},
title = {Hands Holding Clues for Object Recognition in Teachable Machines},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300566},
doi = {10.1145/3290605.3300566},
abstract = {Camera manipulation confounds the use of object recognition applications by blind people. This is exacerbated when photos from this population are also used to train models, as with teachable machines, where out-of-frame or partially included objects against cluttered backgrounds degrade performance. Leveraging prior evidence on the ability of blind people to coordinate hand movements using proprioception, we propose a deep learning system that jointly models hand segmentation and object localization for object classification. We investigate the utility of hands as a natural interface for including and indicating the object of interest in the camera frame. We confirm the potential of this approach by analyzing existing datasets from people with visual impairments for object recognition. With a new publicly available egocentric dataset and an extensive error analysis, we provide insights into this approach in the context of teachable recognizers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {k-shot learning, hand, object recognition, egocentric, blind},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300344,
author = {Rogers, Jon and Clarke, Loraine and Skelly, Martin and Taylor, Nick and Thomas, Pete and Thorne, Michelle and Larsen, Solana and Odrozek, Katarzyna and Kloiber, Julia and Bihr, Peter and Jain, Anab and Arden, Jon and von Grafenstein, Max},
title = {Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300344},
doi = {10.1145/3290605.3300344},
abstract = {Emerging technologies---such as the voice enabled internet---present many opportunities and challenges for HCI research and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {internet of things, critical design, internet, design research, advocacy, voice, product design, speculative design, film},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300867,
author = {Semmens, Rob and Martelaro, Nikolas and Kaveti, Pushyami and Stent, Simon and Ju, Wendy},
title = {Is Now A Good Time? An Empirical Study of Vehicle-Driver Communication Timing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300867},
doi = {10.1145/3290605.3300867},
abstract = {Advances in automotive sensing systems and speech interfaces provide new opportunities for smarter driving assistants or infotainment systems. For both safety and consumer satisfaction reasons, any new system which interacts with drivers must do so at appropriate times. We asked 63 drivers, ''Is now a good time?'' to receive non-driving information during a 50-minute drive. We analyzed 2,734 responses and synchronized automotive and video data, and show that while the chances of choosing a good time can be determined with better success using easily accessible automotive data, certain nuances in the problem require a richer understanding of the driver and environment states in order to achieve higher performance. We illustrate several of these nuances with quantitative and qualitative analyses to contribute to the understanding of how to design a system that might simultaneously minimize the risk of interacting at a bad time while maximizing the window of allowable interruption.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {verbal interaction, datasets, timing, automotive, driving, navigation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300335,
author = {Kim, Nam Wook and Henry Riche, Nathalie and Bach, Benjamin and Xu, Guanpeng and Brehmer, Matthew and Hinckley, Ken and Pahud, Michel and Xia, Haijun and McGuffin, Michael J. and Pfister, Hanspeter},
title = {DataToon: Drawing Dynamic Network Comics With Pen + Touch Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300335},
doi = {10.1145/3290605.3300335},
abstract = {Comics are an entertaining and familiar medium for presenting compelling stories about data. However, existing visualization authoring tools do not leverage this expressive medium. In this paper, we seek to incorporate elements of comics into the construction of data-driven stories about dynamic networks. We contribute DataToon, a flexible data comic storyboarding tool that blends analysis and presentation with pen and touch interactions. A storyteller can use DataToon rapidly generate visualization panels, annotate them, and position them within a canvas to produce a visually compelling narrative. In a user study, participants quickly learned to use DataToon for producing data comics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {direct manipulation, dynamic networks, storytelling, data visualization, pen + touch interfaces, data comics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300911,
author = {Wang, Qianwen and Ming, Yao and Jin, Zhihua and Shen, Qiaomu and Liu, Dongyu and Smith, Micah J. and Veeramachaneni, Kalyan and Qu, Huamin},
title = {ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300911},
doi = {10.1145/3290605.3300911},
abstract = {To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and in analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data visualization, automated machine learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300234,
author = {Cai, Carrie J. and Reif, Emily and Hegde, Narayan and Hipp, Jason and Kim, Been and Smilkov, Daniel and Wattenberg, Martin and Viegas, Fernanda and Corrado, Greg S. and Stumpe, Martin C. and Terry, Michael},
title = {Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300234},
doi = {10.1145/3290605.3300234},
abstract = {Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {human-ai interaction, machine learning, clinical health},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300469,
author = {Jakesch, Maurice and French, Megan and Ma, Xiao and Hancock, Jeffrey T. and Naaman, Mor},
title = {AI-Mediated Communication: How the Perception That Profile Text Was Written by AI Affects Trustworthiness},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300469},
doi = {10.1145/3290605.3300469},
abstract = {We are entering an era of AI-Mediated Communication (AI-MC) where interpersonal communication is not only mediated by technology, but is optimized, augmented, or generated by artificial intelligence. Our study takes a first look at the potential impact of AI-MC on online self-presentation. In three experiments we test whether people find Airbnb hosts less trustworthy if they believe their profiles have been written by AI. We observe a new phenomenon that we term the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI. Our findings have implications for the design of systems that involve AI technologies in online self-presentation and chart a direction for future work that may upend or augment key aspects of Computer-Mediated Communication theory.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {artificial intelligence, ai-mc, trust, cmc},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300423,
author = {Ritchie, Jacob and Wigdor, Daniel and Chevalier, Fanny},
title = {A Lie Reveals the Truth: Quasimodes for Task-Aligned Data Presentation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300423},
doi = {10.1145/3290605.3300423},
abstract = {Designers are often discouraged from creating data visualizations that omit or distort information, because they can easily be misleading. However, the same representations that could be used to deceive can provide benefits when chosen to appropriately align with user tasks. We present an interaction technique, Perceptual Glimpses, which allows for the transparent presentation of so-called 'deceptive' views of information that are made temporary using quasimodes. When presented using Perceptual Glimpses, message-level exaggeration caused by a truncated axis on a bar chart was reduced under some conditions, but users require guidance to avoid errors, and view presentation order may affect trust. When Perceptual Glimpses was extended to display a range of views that might otherwise be deceptive or difficult to understand if shown out of context, users were able to understand and leverage these transformations to perform a range of low-level tasks. Design recommendations and examples suggest extensions of the technique.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {animation, deceptive visualization, perception},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300929,
author = {Groeger, Daniel and Steimle, J\"{u}rgen},
title = {LASEC: Instant Fabrication of Stretchable Circuits Using a Laser Cutter},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300929},
doi = {10.1145/3290605.3300929},
abstract = {This paper introduces LASEC, the first technique for instant do-it-yourself fabrication of circuits with custom stretchability on a conventional laser cutter and in a single pass. The approach is based on integrated cutting and ablation of a two-layer material using parametric design patterns. These patterns enable the designer to customize the desired stretchability of the circuit, to combine stretchable with non-stretchable areas, or to integrate areas of different stretchability. For adding circuits on such stretchable cut patterns, we contribute routing strategies and a real-time routing algorithm. An interactive design tool assists designers by automatically generating patterns and circuits from a high-level specification of the desired interface. The approach is compatible with off-the-shelf materials and can realize transparent interfaces. Several application examples demonstrate the versatility of the novel technique for applications in wearable computing, interactive textiles, and stretchable input devices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {stretchable circuits, laser cutting, rapid prototyping, fabrication, laser ablation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300661,
author = {Auda, Jonas and Pascher, Max and Schneegass, Stefan},
title = {Around the (Virtual) World: Infinite Walking in Virtual Reality Using Electrical Muscle Stimulation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300661},
doi = {10.1145/3290605.3300661},
abstract = {Virtual worlds are infinite environments in which the user can move around freely. When shifting from controller-based movement to regular walking as an input, the limitation of the real world also limits the virtual world. Tackling this challenge, we propose the use of electrical muscle stimulation to limit the necessary real-world space to create an unlimited walking experience. We thereby actuate the users` legs in a way that they deviate from their straight route and thus, walk in circles in the real world while still walking straight in the virtual world. We report on a study comparing this approach to vision shift - the state of the art approach - as well as combining both approaches. The results show that particularly combining both approaches yield high potential to create an infinite walking experience.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {locomotion, electrical muscle stimulation, virtual reality, walking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300866,
author = {Zhang, Mingrui Ray and Zhai, Shumin and Wobbrock, Jacob O.},
title = {Text Entry Throughput: Towards Unifying Speed and Accuracy in a Single Performance Metric},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300866},
doi = {10.1145/3290605.3300866},
abstract = {Human-computer input performance inherently involves speed-accuracy tradeoffs---the faster users act, the more inaccurate those actions are. Therefore, comparing speeds and accuracies separately can result in ambiguous outcomes: Does a fast but inaccurate technique perform better or worse overall than a slow but accurate one? For pointing, speed and accuracy has been unified for over 60 years as throughput (bits/s) (Crossman 1957, Welford 1968), but to date, no similar metric has been established for text entry. In this paper, we introduce a text entry method-independent throughput metric based on Shannon information theory (1948). To explore the practical usability of the metric, we conducted an experiment in which 16 participants typed with a laptop keyboard using different cognitive sets, i.e., speed-accuracy biases. Our results show that as a performance metric, text entry throughput remains relatively stable under different speed-accuracy conditions. We also evaluated a smartphone keyboard with 12 participants, finding that throughput varied least compared to other text entry metrics. This work allows researchers to characterize text entry performance with a single unified measure of input efficiency.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {text entry, efficiency, information theory, throughput, speed-accuracy tradeoff, accuracy, speed, text input, human performance},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300759,
author = {Lee, Sooyeon and Hubert-Wallander, Bjorn and Stevens, Molly and Carroll, John M.},
title = {Understanding and Designing for Deaf or Hard of Hearing Drivers on Uber},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300759},
doi = {10.1145/3290605.3300759},
abstract = {We used content analysis of in-app driver survey responses, customer support tickets, and tweets, and face-to-face interviews of DHH Uber drivers to better understand the DHH driver experience. Here we describe challenges DHH drivers experience and how they address those difficulties via Uber's accessibility features and their own workarounds. We also identify and discuss design and product opportunities to improve the DHH driver experience on Uber.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {communication, deaf or hard of hearing drivers, uber, accessibility},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300897,
author = {Li, Jie and Kong, Yiping and R\"{o}ggla, Thomas and De Simone, Francesca and Ananthanarayan, Swamy and de Ridder, Huib and El Ali, Abdallah and Cesar, Pablo},
title = {Measuring and Understanding Photo Sharing Experiences in Social Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300897},
doi = {10.1145/3290605.3300897},
abstract = {Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {social, virtual reality, presence, questionnaire, immersion, photo sharing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300785,
author = {Gutwin, Carl and van der Kamp, Michael and Uddin, Md. Sami and Stanley, Kevin and Stavness, Ian and Vail, Sally},
title = {Improving Early Navigation in Time-Lapse Video with Spread-Frame Loading},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300785},
doi = {10.1145/3290605.3300785},
abstract = {Time-lapse videos are often navigated by scrubbing with a slider. When networks are slow or images are large, however, even thumbnail versions load so slowly that scrubbing is limited to the start of the video. We developed a frame-loading technique called spread-loading that enables scrubbing regardless of delivery rate. Spread-loading orders frame delivery to maximize coverage of the entire sequence; this provides a temporal overview of the entire video that can be fully navigated at any time during delivery. The overview initially has a coarse temporal resolution, becoming finer-grained with each new frame. We compared spread-loading with traditional linear loading in a study where participants were asked to find specific episodes in a long time-lapse sequence, using three views with increasing levels of detail. Results show that participants found target episodes significantly and substantially faster with spread-loading, regardless of whether they could click to change the load point. Users rated spread-loading as requiring less effort, and strongly preferred the new technique.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {video navigation, scrubbing, temporal overviews},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300357,
author = {G\"{u}ldenpfennig, Florian and Mayer, Peter and Panek, Paul and Fitzpatrick, Geraldine},
title = {An Autonomy-Perspective on the Design of Assistive Technology Experiences of People with Multiple Sclerosis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300357},
doi = {10.1145/3290605.3300357},
abstract = {In HCI and Assistive Technology design, autonomy is regularly equated with independence. This is a shortcut and leaves out design opportunities by omitting a more nuanced idea of autonomy. To improve our understanding of how people with severe physical disabilities experience autonomy, particularly in the context of Assistive Technologies, we engaged in in-depth fieldwork with 15 people with Multiple Sclerosis who were used to assistive devices. We constructed a grounded theory from a series of interviews, focus groups and observations, pointing to strategies in which participants sought autonomy either in the short-term (managing their daily energy reserve) or in the long-term (making future plans). The theory shows how factors like enabling technologies, capital (human, social, psychological resources), and compatibility with daily practices facilitated a sense of being in control for our participants. Moreover, we show how over-ambitious or bad design (e.g., paternalism) can lead to opposite results and restrict autonomy.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {robotic toilet, ambient assisted living, autonomy, active and assisted living, multiple sclerosis, grounded theory},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300734,
author = {Manzoor, Ahtsham and Arooj, Safa and Zulfiqar, Shaban and Parvez, Murayyiam and Shahid, Suleman and Karim, Asim},
title = {ALAP: Accessible LaTeX Based Mathematical Document Authoring and Presentation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300734},
doi = {10.1145/3290605.3300734},
abstract = {Assistive technologies such as screen readers and text editors have been used in past to improve the accessibility and authoring of scientific and mathematical documents. However, most screens readers fail to narrate complex mathematical notations and expressions as they skip symbols and necessary information required for the accurate narration of mathematical content. This study aims at evaluating a new Accessible LaTeX Based Mathematical Document Authoring and Presentation (ALAP) tool, which assist people with visual impairments in reading and writing mathematical documents. ALAP includes features like, assistive debugging, Math Mode for reading and writing mathematical notations, and automatic generation of an accessible PDF document. These features aim to improve the LaTeX debugging experience and make it simple for blind users to author mathematical content by narrating it in natural language through the use of integrated text to speech (TTS) engine. We evaluated ALAP by conducting a study with 18 visually impaired LaTeX users. The results showed that users preferred ALAP over another comparable LaTeX based authoring tool and were relatively more comfortable in completing the tasks while using ALAP.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visually impaired, accessible latex, navigation, assistive debugging, pdf accessibility, accessible math, text to speech, computers},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300831,
author = {Wang, Danding and Yang, Qian and Abdul, Ashraf and Lim, Brian Y.},
title = {Designing Theory-Driven User-Centric Explainable AI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300831},
doi = {10.1145/3290605.3300831},
abstract = {From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical application-specific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building human-centered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {clinical decision making, decision making, explainable artificial intelligence, intelligibility, explanations},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300581,
author = {Desjardins, Audrey and Viny, Jeremy E. and Key, Cayla and Johnston, Nouela},
title = {Alternative Avenues for IoT: Designing with Non-Stereotypical Homes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300581},
doi = {10.1145/3290605.3300581},
abstract = {We report on the findings of a co-speculative design inquiry that investigates alternative visions of the Internet of Things (IoT) for the home. We worked with 16 people living in non-stereotypical homes to develop situated and personal concepts attuned to their home. As a prompt for co-speculation and discussion, we created handmade booklets where we took turns overlaying sketched design concepts on top of photos taken with participants in their homes. Our findings reveal new avenues for the design of IoT systems such as: acknowledging porous boundaries of the home, exposing neighborly relations, exploring diverse timescales, revisiting agency, and embracing imaginary and potential uses. We invite human-computer interaction and design researchers to use these avenues as starting points to broaden current assumptions embedded in design and research practices for domestic technologies. We conclude by highlighting the value of examining divergent perspectives and surfacing the unseen.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {non-stereotypical, home, internet of things, bespoke, smart home, research-through-design, domestic technology},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300899,
author = {Smart, Stephen and Szafir, Danielle Albers},
title = {Measuring the Separability of Shape, Size, and Color in Scatterplots},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300899},
doi = {10.1145/3290605.3300899},
abstract = {Scatterplots commonly use multiple visual channels to encode multivariate datasets. Such visualizations often use size, shape, and color as these dimensions are considered separable--dimensions represented by one channel do not significantly interfere with viewers' abilities to perceive data in another. However, recent work shows the size of marks significantly impacts color difference perceptions, leading to broader questions about the separability of these channels. In this paper, we present a series of crowdsourced experiments measuring how mark shape, size, and color influence data interpretation in multiclass scatterplots. Our results indicate that mark shape significantly influences color and size perception, and that separability among these channels functions asymmetrically: shape more strongly influences size and color perceptions in scatterplots than size and color influence shape. Models constructed from the resulting data can help designers anticipate viewer perceptions to build more effective visualizations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {graphical perception, crowdsourcing, separability, visualization, visual channels},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300933,
author = {Salai, Ana-Maria and Baillie, Lynne},
title = {A Wee Bit More Interaction: Designing and Evaluating an Overactive Bladder App},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300933},
doi = {10.1145/3290605.3300933},
abstract = {Overactive Bladder (OAB) is a widespread condition, affecting 20% of the population. Even though it is a treatable condition, people often do not seek treatment. In this paper, we describe how we co-designed and evaluated with 30 stakeholders (9 medical professionals and 21 end-users) an OAB mobile health application that aims to increase adherence to self-managed treatment. Our results support previous research that visualizing progress, setting goals, receiving reminders and feedback increases use. We discovered that games could be used successfully as a distraction technique for urge suppression. Contrary to the current research direction, automatically calculated features could be a detriment to app interaction. Regarding evaluation, we found that designers may not want to rely only on questionnaires when assessing the success of a game and its emotional impact on users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mobile health applications, overactive bladder, assistive technology, usability, co-design, interviews},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300883,
author = {Tomprou, Maria and Dabbish, Laura and Kraut, Robert E. and Liu, Fannie},
title = {Career Mentoring in Online Communities: Seeking and Receiving Advice from an Online Community},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300883},
doi = {10.1145/3290605.3300883},
abstract = {Although people frequently seek mentoring or advice for their career, most mentoring is performed in person. Little research has examined the nature and quality of career mentoring online. To address this gap, we study how people use online Q&amp;A forums for career advice. We develop a taxonomy of career advice requests based on a qualitative analysis of posts in a career-related online forum, identifying three key types: best practices, career threats, and time-sensitive requests. Our quantitative analysis of responses shows that both requesters and external viewers value general information, encouragement, and guidance, but not role modeling. We found no relation between the type of requests and features of responses, nor differences in responses valued by requesters versus external viewers. We present design recommendations for supporting online career advice exchange.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {career advice, online mentoring interactions, online communities, employment, working adults, q&amp;a},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300284,
author = {Pollmann, Kathrin and Stefani, Oilver and Bengsch, Amelie and Peissner, Matthias and Vukeli\'{c}, Mathias},
title = {How to Work in the Car of the Future? A Neuroergonomical Study Assessing Concentration, Performance and Workload Based on Subjective, Behavioral and Neurophysiological Insights},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300284},
doi = {10.1145/3290605.3300284},
abstract = {Autonomous driving provides new opportunities for the use of time during a car ride. One such important scenario is working. We conducted a neuroergonomical study to compare three configurations of a car interior (based on lighting, visual stimulation, sound) regarding their potential to support productive work. We assessed participants? concentration, performance and workload with subjective, behavioral and EEG measures while they carried out two different concentration tasks during simulated autonomous driving. Our results show that a configuration with a large-area, bright light with high blue components, and reduced visual and auditory stimuli promote performance, quality, efficiency, increased concentration and lower cognitive workload. Increased visual and auditory stimulation paired with linear, darker light with very few blue components resulted in lower performance, reduced subjective concentration, and higher cognitive workload, but did not differ from a normal car configuration. Our multi-method approach thus reveals possible car interior configurations for an ideal workspace.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {autonomous driving, eeg, multi-method hci evaluation, neurergonomics, workload},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300425,
author = {Brewer, Robin N. and Kameswaran, Vaishnav},
title = {Understanding Trust, Transportation, and Accessibility through Ridesharing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300425},
doi = {10.1145/3290605.3300425},
abstract = {Relatively few studies of accessibility and transportation for people with vision impairments have investigated forms of transportation besides public transportation and walking. To develop a more nuanced understanding of this context, we turn to ridesharing, an increasingly used mode of transportation. We interviewed 16 visually-impaired individuals about their active use of ridesharing services like Uber and Lyft. Our findings show that, while people with vision impairments value independence, ridesharing involves building trust across a complex network of stakeholders and technologies. This data is used to start a discussion on how other systems can facilitate trust for people with vision impairments by considering the role of conversation, affordances of system incentives, and increased agency.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {ridesharing, blind, trust, transportation, vision impairment, accessibility},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300588,
author = {Ambe, Aloha Hufana and Brereton, Margot and Soro, Alessandro and Buys, Laurie and Roe, Paul},
title = {The Adventures of Older Authors: Exploring Futures through Co-Design Fictions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300588},
doi = {10.1145/3290605.3300588},
abstract = {This paper presents co-design fiction as an approach to engaging users in imagining, envisioning and speculating not just on future technology but future life through co-created fictional works. Design fiction in research is often created or written by researchers. There is relatively little critical discussion of how to co-create design fictions with end-users, with the concomitant opportunities and challenges this poses. To fill this gap in knowledge, we conducted co-design fiction workshops with nine older creative writers, utilising prompts to inspire discussion and engage their imaginative writing about the trend towards tracking and monitoring older people. Their stories revealed futures of neither dystopia nor utopia but of social and moral dilemmas narrating their wish not just to "maintain their independence", but a palpable desire for adventure and very nuanced senses of how they wish to take control. We discuss inherent tensions in the control of the co-design fiction process; balancing the author's need for freedom and creativity with the researcher's desire to guide the process toward the design investigation at hand.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {co-creation, creative writers, older adults, design fiction, monitoring technology},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300643,
author = {Jiang, Yue and Du, Ruofei and Lutteroth, Christof and Stuerzlinger, Wolfgang},
title = {ORC Layout: Adaptive GUI Layout with OR-Constraints},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300643},
doi = {10.1145/3290605.3300643},
abstract = {We propose a novel approach for constraint-based graphical user interface (GUI) layout based on OR-constraints (ORC) in standard soft/hard linear constraint systems. ORC layout unifies grid layout and flow layout, supporting both their features as well as cases where grid and flow layouts individually fail. We describe ORC design patterns that enable designers to safely create flexible layouts that work across different screen sizes and orientations. We also present the ORC Editor, a GUI editor that enables designers to apply ORC in a safe and effective manner, mixing grid, flow and new ORC layout features as appropriate. We demonstrate that our prototype can adapt layouts to screens with different aspect ratios with only a single layout specification, easing the burden of GUI maintenance. Finally, we show that ORC specifications can be modified interactively and solved efficiently at runtime.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {constraint-based layout, visual interface design, visual programming, gui builder, layout manager},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300718,
author = {Hamdan, Nur Al-huda and Wagner, Adrian and Voelker, Simon and Steimle, J\"{u}rgen and Borchers, Jan},
title = {Springlets: Expressive, Flexible and Silent On-Skin Tactile Interfaces},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300718},
doi = {10.1145/3290605.3300718},
abstract = {We introduce Springlets, expressive, non-vibrating mechanotactile interfaces on the skin. Embedded with shape memory alloy springs, we implement Springlets as thin and flexible stickers to be worn on various body locations, thanks to their silent operation even on the neck and head. We present a technically simple and rapid technique for fabricating a wide range of Springlet interfaces and computer-generated tactile patterns. We developed Springlets for six tactile primitives: pinching, directional stretching, pressing, pulling, dragging, and expanding. A study placing Springlets on the arm and near the head demonstrates Springlets' effectiveness and wearability in both stationary and mobile situations. We explore new interactive experiences in tactile social communication, physical guidance, health interfaces, navigation, and virtual reality gaming, enabled by Springlets' unique and scalable form factor.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {on-body interaction, wearable computing, shape memory alloys, shape-changing, fabrication, tactile display},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300231,
author = {Colusso, Lucas and Jones, Ridley and Munson, Sean A. and Hsieh, Gary},
title = {A Translational Science Model for HCI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300231},
doi = {10.1145/3290605.3300231},
abstract = {Using scientific discoveries to inform design practice is an important, but difficult, objective in HCI. In this paper, we provide an overview of Translational Science in HCI by triangulating literature related to the research-practice gap with interview data from many parties engaged (or not) in translating HCI knowledge. We propose a model for Translational Science in HCI based on the concept of a continuum to describe how knowledge progresses (or stalls) through multiple steps and translations until it can influence design practice. The model offers a conceptual framework that can be used by researchers and practitioners to visualize and describe the progression of HCI knowledge through a sequence of translations. Additionally, the model may facilitate a precise identification of translational barriers, which allows devising more effective strategies to increase the use of scientific findings in design practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {translational research, research-practice gap, translational science},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300803,
author = {Guo, Shunan and Du, Fan and Malik, Sana and Koh, Eunyee and Kim, Sungchul and Liu, Zhicheng and Kim, Donghyun and Zha, Hongyuan and Cao, Nan},
title = {Visualizing Uncertainty and Alternatives in Event Sequence Predictions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300803},
doi = {10.1145/3290605.3300803},
abstract = {Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviews with five machine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {event sequence analysis, decision making, uncertainty visualization, predictive visual analytics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300530,
author = {Feiz, Shirin and Billah, Syed Masum and Ashok, Vikas and Shilkrot, Roy and Ramakrishnan, IV},
title = {Towards Enabling Blind People to Independently Write on Printed Forms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300530},
doi = {10.1145/3290605.3300530},
abstract = {Filling out printed forms (e.g., checks) independently is currently impossible for blind people, since they cannot pinpoint the locations of the form fields, and quite often, they cannot even figure out what fields (e.g., name) are present in the form. Hence, they always depend on sighted people to write on their behalf, and help them affix their signatures. Extant assistive technologies have exclusively focused on reading, with no support for writing. In this paper, we introduce WiYG, a Write-it-Yourself guide that directs a blind user to the different form fields, so that she can independently fill out these fields without seeking assistance from a sighted person. Specifically, WiYG uses a pocket-sized custom 3D printed smartphone attachment, and well-established computer vision algorithms to dynamically generate audio instructions that guide the user to the different form fields. A user study with 13 blind participants showed that with WiYG, users could correctly fill out the form fields at the right locations with an accuracy as high as 89.5%.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {blind, 3d print, wiy, paper, form, writing, write-it-yourself},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300651,
author = {Bipat, Taryn and Bos, Maarten Willem and Vaish, Rajan and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {Analyzing the Use of Camera Glasses in the Wild},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300651},
doi = {10.1145/3290605.3300651},
abstract = {Camera glasses enable people to capture point-of-view videos using a common accessory, hands-free. In this paper, we investigate how, when, and why people used one such product: Spectacles. We conducted 39 semi-structured interviews and surveys with 191 owners of Spectacles. We found that the form factor elicits sustained usage behaviors, and opens opportunities for new use-cases and types of content captured. We provide a usage typology, and highlight societal and individual factors that influence the classification of behaviors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {usability, wearables, camera glasses, smart glasses},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300291,
author = {Hope, Alexis and D'Ignazio, Catherine and Hoy, Josephine and Michelson, Rebecca and Roberts, Jennifer and Krontiris, Kate and Zuckerman, Ethan},
title = {Hackathons as Participatory Design: Iterating Feminist Utopias},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300291},
doi = {10.1145/3290605.3300291},
abstract = {Breastfeeding is not only a public health issue, but also a matter of economic and social justice. This paper presents an iteration of a participatory design process to create spaces for re-imagining products, services, systems, and policies that support breastfeeding in the United States. Our work contributes to a growing literature around making hackathons more inclusive and accessible, designing participatory processes that center marginalized voices, and incorporating systems- and relationship-based approaches to problem solving. By presenting an honest assessment of the successes and shortcomings of the first iteration of a hackathon, we explain how we re-structured the second "Make the Breast Pump Not Suck" hackathon in service of equity and systems design. Key to our re-imagining of conventional innovation structures is a focus on experience design, where joy and play serve as key strategies to help people and institutions build relationships across lines of difference. We conclude with a discussion of design principles applicable not only to designers of events, but to social movement researchers and HCI scholars trying to address oppression through the design of technologies and socio-technical systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {hackathons, feminist hci, breastfeeding, maternal health, participatory design, intersectional hci, equity},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300839,
author = {Wang, Xi and Ley, Andreas and Koch, Sebastian and Lindlbauer, David and Hays, James and Holmqvist, Kenneth and Alexa, Marc},
title = {The Mental Image Revealed by Gaze Tracking},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300839},
doi = {10.1145/3290605.3300839},
abstract = {Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user's eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {eye tracking, mental imagery, gaze pattern},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300493,
author = {Kross, Sean and Guo, Philip J.},
title = {Practitioners Teaching Data Science in Industry and Academia: Expectations, Workflows, and Challenges},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300493},
doi = {10.1145/3290605.3300493},
abstract = {Data science has been growing in prominence across both academia and industry, but there is still little formal consensus about how to teach it. Many people who currently teach data science are practitioners such as computational researchers in academia or data scientists in industry. To understand how these practitioner-instructors pass their knowledge onto novices and how that contrasts with teaching more traditional forms of programming, we interviewed 20 data scientists who teach in settings ranging from small-group workshops to large online courses. We found that: 1) they must empathize with a diverse array of student backgrounds and expectations, 2) they teach technical workflows that integrate authentic practices surrounding code, data, and communication, 3) they face challenges involving authenticity versus abstraction in software setup, finding and curating pedagogically-relevant datasets, and acclimating students to live with uncertainty in data analysis. These findings can point the way toward better tools for data science education and help bring data literacy to more people around the world.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {data science education, teaching programming},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300750,
author = {Roy, Quentin and Zhang, Futian and Vogel, Daniel},
title = {Automation Accuracy Is Good, but High Controllability May Be Better},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300750},
doi = {10.1145/3290605.3300750},
abstract = {When automating tasks using some form of artificial intelligence, some inaccuracy in the result is virtually unavoidable. In many cases, the user must decide whether to try the automated method again, or fix it themselves using the available user interface. We argue this decision is influenced by both perceived automation accuracy and degree of task "controllability" (how easily and to what extent an automated result can be manually modified). This relationship between accuracy and controllability is investigated in a 750-participant crowdsourced experiment using a controlled, gamified task. With high controllability, self-reported satisfaction remained constant even under very low accuracy conditions, and overall, a strong preference was observed for using manual control rather than automation, despite much slower performance and regardless of very poor controllability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {automation, controllability, accuracy, controlled experiment},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300255,
author = {Lee, Sangyoon and Lee, Jaeyeon and Lee, Geehyuk},
title = {Diagnosing and Coping with Mode Errors in Korean-English Dual-Language Keyboard},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300255},
doi = {10.1145/3290605.3300255},
abstract = {In countries where languages with non-Latin characters are prevalent, people use a keyboard with two language modes namely, the native language and English, and often experience mode errors. To diagnose the mode error problem, we conducted a field study and observed that 78% of the mode errors occurred immediately after application switching. We implemented four methods (Auto-switch, Preview, Smart-toggle, and Preview &amp; Smart-toggle) based on three strategies to deal with the mode error problem and conducted field studies to verify their effectiveness. In the studies considering Korean-English dual input, Auto-switch was ineffective. On the contrary, Preview significantly reduced the mode errors from 75.1% to 41.3%, and Smart-toggle saved typing cost for recovering from mode errors. In Preview &amp; Smart-toggle, Preview reduced mode errors and Smart-toggle handled 86.2% of the mode errors that slipped past Preview. These results suggest that Preview &amp; Smart-toggle is a promising method for preventing mode errors for the Korean-English dual-input environment.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {dual language keyboard, input language mode, mode error},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300312,
author = {Fernando, Piyum and Weiler, Jennifer and Kuznetsov, Stacey},
title = {A Rough Sketch of the Freehand Drawing Process: Blending the Line between Action and Artifact},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300312},
doi = {10.1145/3290605.3300312},
abstract = {Dynamic elements of the drawing process (e.g., order of compilation, speed, length, and pressure of strokes) are considered important because they can reveal the technique, process, and emotions of the artist. To explore how sensing, visualizing, and sharing these aspects of the creative process might shape art making and art viewing experiences, we designed a research probe which unobtrusively tracks and visualizes the movement and pressure of the artist's pencil on an easel. Using our probe, we conducted studies with artists and art viewers, which reveal digital and physical representations of creative process as a means of reflecting on a multitude of factors about the finished artwork, including technique, style, and the emotions of the artists. We conclude by discussing future directions for HCI systems that sense and visualize aspects of the creative process in digitally-mediated arts, as well as the social considerations of sharing and curating intimate process information.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {curation, fine arts, process, digitally-mediated art},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300324,
author = {Jain, Dhruv and Lin, Angela and Guttman, Rose and Amalachandran, Marcus and Zeng, Aileen and Findlater, Leah and Froehlich, Jon},
title = {Exploring Sound Awareness in the Home for People Who Are Deaf or Hard of Hearing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300324},
doi = {10.1145/3290605.3300324},
abstract = {The home is filled with a rich diversity of sounds from mundane beeps and whirs to dog barks and children's shouts. In this paper, we examine how deaf and hard of hearing (DHH) people think about and relate to sounds in the home, solicit feedback and reactions to initial domestic sound awareness systems, and explore potential concerns. We present findings from two qualitative studies: in Study 1, 12 DHH participants discussed their perceptions of and experiences with sound in the home and provided feedback on initial sound awareness mockups. Informed by Study 1, we designed three tablet-based sound awareness prototypes, which we evaluated with 10 DHH participants using a Wizard-of-Oz approach. Together, our findings suggest a general interest in smarthome-based sound awareness systems particularly for displaying contextually aware, personalized and glanceable visualizations but key concerns arose related to privacy, activity tracking, cognitive overload, and trust.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sound awareness, smart home, deaf and hard of hearing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300652,
author = {Noortman, Renee and Schulte, Britta F. and Marshall, Paul and Bakker, Saskia and Cox, Anna L.},
title = {HawkEye - Deploying a Design Fiction Probe},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300652},
doi = {10.1145/3290605.3300652},
abstract = {This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {dementia care, informal caregiving, monitoring technologies, design fiction, technology probes, future scenarios},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300586,
author = {Sultana, Sharifa and Ahmed, Syed Ishtiaque},
title = {Witchcraft and HCI: Morality, Modernity, and Postcolonial Computing in Rural Bangladesh},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300586},
doi = {10.1145/3290605.3300586},
abstract = {While Human-Computer Interaction (HCI) research on health and well-being is increasingly becoming more aware and inclusive of its social and political dimensions, spiritual practices are still largely overlooked there. For a large number of people around the world, especially in the global south, witchcraft, sorcery, and other occult practices are the primary means of achieving health, wealth, satisfaction, and happiness. Building on an eight-month long ethnography in six villages in Jessore, Bangladesh, this paper explores the knowledge, materials, and politics involved in the local witchcraft practices there. By drawing from a rich body of anthropological work on witchcraft, this paper discusses how those findings contribute to the broader issues in HCI around morality, modernity, and postcolonial computing. This paper concludes by recommending ways for smooth integration of traditional occult practices with HCI through design and policy. We argue for occult practices as an under-appreciated site for HCI to learn how to combat ideological hegemony.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {wellbeing, ictd, rural, witchcraft, postcolonial, faith},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300816,
author = {Srivastava, Namrata and Velloso, Eduardo and Lodge, Jason M. and Erfani, Sarah and Bailey, James},
title = {Continuous Evaluation of Video Lectures from Real-Time Difficulty Self-Report},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300816},
doi = {10.1145/3290605.3300816},
abstract = {With the increased reach and impact of video lectures, it is crucial to understand how they are experienced. Whereas previous studies typically present questionnaires at the end of the lecture, they fail to capture students' experience in enough granularity. In this paper we propose recording the lecture difficulty in real-time with a physical slider, enabling continuous and fine-grained analysis of the learning experience. We evaluated our approach in a study with 100 participants viewing two variants of two short lectures. We demonstrate that our approach helps us paint a more complete picture of the learning experience. Our analysis has design implications for instructors, providing them with a method that helps them compare their expectations with students' beliefs about the lectures and to better understand the specific effects of different instructional design decisions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {education, video lectures, audio-visual instruction, e-learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300525,
author = {Takahashi, Haruki and Kim, Jeeeun},
title = {3D Pen + 3D Printer: Exploring the Role of Humans and Fabrication Machines in Creative Making},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300525},
doi = {10.1145/3290605.3300525},
abstract = {The emergence of a 3D pen brings 3D modeling from a screen-based computer-aided design (CAD) system and 3D printing to direct and rapid crafting by 3D doodling. However, 3D doodling remains challenging, requiring craft skills to rapidly express an idea, which is critical in creative making. We explore a new process of 3D modeling using 3D pen + 3D printer. Our pilot study shows that users need support to reduce the number of non-creative tasks to explore a wide design strategy. With the opportunity to invent a new 3D modeling process that needs to incorporate both a pen and printer, we propose techniques and a system that empower users to print while doodling to focus on creative exploration. Our user study shows that users can create diverse 3D models using a pen and printer. We discuss the roles of the human and fabrication machine for the future of fabrication.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3d printer, 3d pen, digital fabrication, creativity},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300383,
author = {Jones, Ridley and Colusso, Lucas and Reinecke, Katharina and Hsieh, Gary},
title = {R/Science: Challenges and Opportunities in Online Science Communication},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300383},
doi = {10.1145/3290605.3300383},
abstract = {Online discussion websites, such as Reddit's r/science forum, have the potential to foster science communication between researchers and the general public. However, little is known about who participates, what is discussed, and whether such websites are successful in achieving meaningful science discussions. To find out, we conducted a mixed-methods study analyzing 11,859 r/science posts and conducting interviews with 18 community members. Our results show that r/science facilitates rich information exchange and that the comments section provides a unique science communication document that guides engagement with scientific research. However, this community-sourced science communication comes largely from a knowledgeable public. We conclude with design suggestions for a number of critical problems that we uncovered: addressing the problem of topic newsworthiness and balancing broader participation and rigor.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {reddit, outreach, r/science, online discussion forums, science communication},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300725,
author = {Kimura-Thollander, Philippe and Kumar, Neha},
title = {Examining the "Global" Language of Emojis: Designing for Cultural Representation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300725},
doi = {10.1145/3290605.3300725},
abstract = {Emojis are becoming an increasingly popular mode of communication between individuals worldwide, with researchers claiming them to be a type of "ubiquitous language'' that can span different languages due to its pictorial nature. Our study uses a combination of methods to examine how emojis are adopted and perceived by individuals from diverse cultural backgrounds and 45 countries. Our survey and interview findings point to the existence of a cultural gap between user perceptions and the current emoji standard. Using participatory design, we sought to address this gap by designing 40 emojis and conducted another survey to evaluate their acceptability compared to existing Japanese emojis. We also draw on participant observation from a Unicode Consortium meeting on emoji addition. Our analysis leads us to discuss how emojis might be made more inclusive, diverse, and representative of the populations that use them.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {emoji, non-verbal, representation, multi-cultural},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300419,
author = {Colley, Ashley and Mayer, Sven and Henze, Niels},
title = {Investigating the Effect of Orientation and Visual Style on Touchscreen Slider Performance},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300419},
doi = {10.1145/3290605.3300419},
abstract = {Sliders are one of the most fundamental components used in touchscreen user interfaces (UIs). When entering data using a slider, errors occur due e.g. to visual perception, resulting in inputs not matching what is intended by the user. However, it is unclear if the errors occur uniformly across the full range of the slider or if there are systematic offsets. We conducted a study to assess the errors occurring when entering values with horizontal and vertical sliders as well as two common visual styles. Our results reveal significant effects of slider orientation and style on the precision of the entered values. Furthermore, we identify systematic offsets that depend on the visual style and the target value. As the errors are partially systematic, they can be compensated to improve users' precision. Our findings provide UI designers with data to optimize user experiences in the wide variety of application areas where slider based touchscreen input is used.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {visual analogue scale, touchscreen, slider, mobile device, input},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300535,
author = {Talton, Jerry O. and Dusad, Krishna and Koiliaris, Konstantinos and Kumar, Ranjitha S.},
title = {How Do People Sort by Ratings?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300535},
doi = {10.1145/3290605.3300535},
abstract = {Sorting items by user rating is a fundamental interaction pattern of the modern Web, used to rank products (Amazon), posts (Reddit), businesses (Yelp), movies (YouTube), and more. To implement this pattern, designers must take in a distribution of ratings for each item and define a sensible total ordering over them. This is a challenging problem, since each distribution is drawn from a distinct sample population, rendering the most straightforward method of sorting --- comparing averages --- unreliable when the samples are small or of different sizes. Several statistical orderings for binary ratings have been proposed in the literature (e.g., based on the Wilson score, or Laplace smoothing), each attempting to account for the uncertainty introduced by sampling. In this paper, we study this uncertainty through the lens of human perception, and ask "How do people sort by ratings?" In an online study, we collected 48,000 item-ranking pairs from 4,000 crowd workers along with 4,800 rationales, and analyzed the results to understand how users make decisions when comparing rated items. Our results shed light on the cognitive models users employ to choose between rating distributions, which sorts of comparisons are most contentious, and how the presentation of rating information affects users' preferences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {user ratings, ranking, uncertainty},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300868,
author = {Mueller, Florian Floyd and Li, Zhuying and Byrne, Richard and Mehta, Yash Dhanpal and Arnold, Peter and Kari, Tuomas},
title = {A 2nd Person Social Perspective on Bodily Play},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300868},
doi = {10.1145/3290605.3300868},
abstract = {Recent HCI work on digital games highlighted the advantage for designers to take on a 1st person perspective on the human body (referring to the phenomenological "lived" body) and a 3rd person perspective (the material "fleshy" body, similar to looking in the mirror). This is useful when designing bodily play, however, we note that there is not much game design discussion on the 2nd person social perspective that highlights the unique interplay between human bodies. To guide designers interested in supporting players to experience their bodies as play, we describe how game designers can engage with the 2nd person social perspective through a set of design tactics based on four of our own play systems. With our work, we hope we can aid designers in embracing this 2nd person perspective so that more people can benefit from engaging their bodies through games and play.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {exertion games, whole-body interaction, social, play},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300582,
author = {Bell, Jeanette and Leong, Tuck Wah},
title = {Collaborative Futures: Co-Designing Research Methods for Younger People Living with Dementia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300582},
doi = {10.1145/3290605.3300582},
abstract = {Designing new technologies to support the lived experience of dementia is of increasing interest within HCI. While there is guidance on qualitative research methods to use in areas such as dementia, there is a need for more appropriate ways to research in the younger demographic. In Younger Onset Dementia (YOD), the circumstances and experiences are markedly different from dementia in the later stage of life requiring a different approach. This paper presents insights into the methods and approaches used in fieldwork with five people living with YOD; where they engaged as co-researchers in a co-directed inquiry into their lived experiences. Through this, we make a number of methodological contributions to HCI and Participatory Action Research (PAR) for research in the YOD setting. This includes productive approaches that are sensitive, respectful and empowering to the participants. It also extends current approaches to using probes in HCI and dementia research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {co-researcher, ethics, younger onset dementia, ethnography, empathy, collaboration, trust, sensitive cultures, probes, participatory action research, co-design, methods, hci},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300870,
author = {Mairena, Aristides and Gutwin, Carl and Cockburn, Andy},
title = {Peripheral Notifications in Large Displays: Effects of Feature Combination and Task Interference},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300870},
doi = {10.1145/3290605.3300870},
abstract = {Visual notifications are integral to interactive computing systems. With large displays, however, much of the content is in the user's visual periphery, where human capacity to notice visual effects is diminished. One design strategy for enhancing noticeability is to combine visual features, such as motion and colour. Yet little is known about how feature combinations affect noticeability across the visual field, or about how peripheral noticeability changes when a user's primary task involves the same visual features as the notification. We addressed these questions by conducting two studies. Results of the first study showed that noticeability of feature combinations were approximately equal to the better of the individual features. Results of the second study suggest that there can be interference between the features of primary tasks and the visual features in the notifications. Our findings contribute to a better understanding of how visual features operate when used as peripheral notifications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visualization, popout, notification, peripheral vision},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300561,
author = {Deeb-Swihart, Julia and Endert, Alex and Bruckman, Amy},
title = {Understanding Law Enforcement Strategies and Needs for Combating Human Trafficking},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300561},
doi = {10.1145/3290605.3300561},
abstract = {In working to rescue victims of human trafficking, law enforcement officers face a host of challenges. Working in complex, layered organizational structures, they face challenges of collaboration and communication. Online information is central to every phase of a human-trafficking investigation. With terabytes of available data such as sex work ads, policing is increasingly a big-data research problem. In this study, we interview sixteen law enforcement officers working to rescue victims of human trafficking to try to understand their computational needs. We highlight three major areas where future work in human-computer interaction can help. First, combating human trafficking requires advances in information visualization of large, complex, geospatial data, as victims are frequently forcibly moved across jurisdictions. Second, the need for unified information databases raises critical research issues of usable security and privacy. Finally, the archaic nature of information systems available to law enforcement raises policy issues regarding resource allocation for software development.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {qualitative, law enforcement, needs analysis, human trafficking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300722,
author = {Koushik, Varsha and Guinness, Darren and Kane, Shaun K.},
title = {StoryBlocks: A Tangible Programming Game To Create Accessible Audio Stories},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300722},
doi = {10.1145/3290605.3300722},
abstract = {Block-based programming languages can support novice programmers through features such as simplified code syntax and user-friendly libraries. However, most block-based programming languages are highly visual, which makes them inaccessible to blind and visually impaired students. To address the inaccessibility of block-based languages, we introduce StoryBlocks, a tangible block-based game that enables blind programmers to learn basic programming concepts by creating audio stories. In this paper, we document the design of StoryBlocks and report on a series of design activities with groups of teachers, Braille experts, and students. Participants in our design sessions worked together to create accessible stories, and their feedback offers insights for the future development of accessible, tangible programming tools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {storytelling, tangible user interfaces, audio interfaces, computer science education, cross-ability collaboration},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300536,
author = {Diefenbach, Sarah and Borrmann, Kim},
title = {The Smartphone as a Pacifier and Its Consequences: Young Adults' Smartphone Usage in Moments of Solitude and Correlations to Self-Reflection},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300536},
doi = {10.1145/3290605.3300536},
abstract = {The smartphone plays a dominant role in everyday life. Among young adults, the average daily usage time is almost four hours. The present study [N=399] examines the specific psychological role of smartphone usage during alone time (e.g. in the subway, waiting, in bed). Particularly, we explore its role in coping with negative emotions in the sense of an "attachment object", providing comfort like a pacifier for infants. Results underlined the pacifying role of smartphone usage to cope with negative emotions in moments of alone time. Moreover, particular personality dispositions (e.g., high need to belong, high proneness to boredom) were associated with more extensive self-reported smartphone usage and mediated by the perception of the smartphone as an attachment object. Finally, smartphone usage was negatively correlated to self-insight, possibly substituting intense inner debates or self-realizations during alone time. Implications for HCI research and practice are discussed.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {proneness to boredom, attachment object, smartphone usage, positive technology design, alone time, self-reflection, need to belong, self-insight, capacity for solitude},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300327,
author = {Howard, Dorothy and Irani, Lilly},
title = {Ways of Knowing When Research Subjects Care},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300327},
doi = {10.1145/3290605.3300327},
abstract = {This paper investigates a hidden dimension of research with real world stakes: research subjects who care -- sometimes deeply -- about the topic of the research in which they participate. They manifest this care, we show, by managing how they are represented in the research process, by exercising politics in shaping knowledge production, and sometimes in experiencing trauma in the process. We draw first-hand reflections on participation in diversity research on Wikipedia, transforming participants from objects of study to active negotiators of research process. We depict how care, vulnerability, harm, and emotions shape ethnographic and qualitative data. We argue that, especially in reflexive cultures, research subjects are active agents with agendas, accountabilities, and political projects of their own. We propose ethics of care and collaboration to open up new possibilities for knowledge production and socio-technical intervention in HCI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {feminism, qualitative methods, care, gender, ethics, online communities},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300678,
author = {Zhu, Suwen and Zheng, Jingjie and Zhai, Shumin and Bi, Xiaojun},
title = {I'sFree: Eyes-Free Gesture Typing via a Touch-Enabled Remote Control},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300678},
doi = {10.1145/3290605.3300678},
abstract = {Entering text without having to pay attention to the keyboard is compelling but challenging due to the lack of visual guidance. We propose i'sFree to enable eyes-free gesture typing on a distant display from a touch-enabled remote control. i'sFree does not display the keyboard or gesture trace but decodes gestures drawn on the remote control into text according to an invisible and shifting Qwerty layout. i'sFree decodes gestures similar to a general gesture typing decoder, but learns from the instantaneous and historical input gestures to dynamically adjust the keyboard location. We designed it based on the understanding of how users perform eyes-free gesture typing. Our evaluation shows eyes-free gesture typing is feasible: reducing visual guidance on the distant display hardly affects the typing speed. Results also show that the i'sFree gesture decoding algorithm is effective, enabling an input speed of 23 WPM, 46% faster than the baseline eyes-free condition built on a general gesture decoder. Finally, i'sFree is easy to learn: participants reached 22 WPM in the first ten minutes, even though 40% of them were first-time gesture typing users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touchscreen, eyes-free text entry, gesture typing, text entry},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300552,
author = {Ambe, Aloha Hufana and Brereton, Margot and Soro, Alessandro and Chai, Min Zhen and Buys, Laurie and Roe, Paul},
title = {Older People Inventing Their Personal Internet of Things with the IoT Un-Kit Experience},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300552},
doi = {10.1145/3290605.3300552},
abstract = {We introduce the IoT Un-Kit Experience, a co-design approach that engages people in exploring, designing and generating personally meaningful IoT applications and that also serves as a means to explore IoT kit design through in-home workshops. Un-Kit represents a seemingly uncompleted set of sensors, actuators and media elements that have a decontextualized appearance - unfinished state, undefined purpose and unboxed form. The approach emphasises users contemplating and experiencing the IoT elements in their familiar space through detailed and layered conversation with researchers; rather than focusing on connecting up the kit itself, thus their ideas are not constrained by the kit or their competence with it. We illustrate the approach through in-home workshops with older adults, envisioned users of IoT who have had limited voice in its conception. The Un-kit approach supported participants to lead the process and to imagine new artfully integrated designs, with personally legible interactions and aesthetic qualities that fit their desire. We offer insights for a more situated and responsive approach to design of the IoT and its constituent kits.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {internet of things, older adults, situated, toolkit, co-design, iot},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300295,
author = {Dragicevic, Pierre and Jansen, Yvonne and Sarma, Abhraneel and Kay, Matthew and Chevalier, Fanny},
title = {Increasing the Transparency of Research Papers with Explorable Multiverse Analyses},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300295},
doi = {10.1145/3290605.3300295},
abstract = {We present explorable multiverse analysis reports, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two recent ideas: i) multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and ii) explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation. Based on five examples and a design space analysis, we show how combining those two ideas can complement existing reporting approaches and constitute a step towards more transparent research papers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {explorable explanation, multiverse analysis, transparent reporting, interactive documents, statistics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300629,
author = {Doyle, Julie and Murphy, Emma and Kuiper, Janneke and Smith, Suzanne and Hannigan, Caoimhe and Jacobs, An and Dinsmore, John},
title = {Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300629},
doi = {10.1145/3290605.3300629},
abstract = {Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {multimorbidity, digital health, self-management, older adults},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300410,
author = {Ahmed, Syed Ishtiaque and Haque, Md. Romael and Haider, Irtaza and Chen, Jay and Dell, Nicola},
title = {"Everyone Has Some Personal Stuff": Designing to Support Digital Privacy with Shared Mobile Phone Use in Bangladesh},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300410},
doi = {10.1145/3290605.3300410},
abstract = {People in South Asia frequently share a single device among multiple individuals, resulting in digital privacy challenges. This paper explores a design concept that aims to mitigate some of these challenges through a 'tiered' privacy model. Using this model, a person creates a 'shared' account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate 'secret' account that contains data they prefer to keep secret and that uses a password they do not share with anyone. When a friend or family member asks to check their device, the user can tell them the password for their shared account, with their private data secure in the secret account that the other person is unaware of. We explore the benefits and trade-offs of our design through a three-week deployment with 21 participants in Bangladesh, presenting findings that show how our work aids digital privacy while also exposing the challenges that remain.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {shared use, mobile devices, access, hci4d, privacy, ictd},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300808,
author = {Dillahunt, Tawanna R. and Lu, Alex},
title = {DreamGigs: Designing a Tool to Empower Low-Resource Job Seekers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300808},
doi = {10.1145/3290605.3300808},
abstract = {Technology allows us to scale the number of jobs we search for and apply to, train for work, and earn money online. However, these technologies do not benefit all job seekers equally and must be designed to better support the needs of underserved job seekers. Research suggests that underserved job seekers prefer employment technologies that can support them in articulating their skills and experiences and in identifying pathways to achieve their career goals. Therefore, we present the design, implementation, and evaluation of DreamGigs, a tool that identifies the skills job seekers need to reach their dream jobs and presents volunteer and employment opportunities for them to acquire those skills. Our evaluation results show that DreamGigs aids in the process of personal empowerment. We contribute design implications for mitigating aspects of powerlessness that low-resource job seekers experience and discuss ways to promote action-taking in these job seekers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {empowerment, employability, low resource, agile development, job seekers, employment},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300699,
author = {Carucci, Kayla and Toyama, Kentaro},
title = {Making Well-Being: Exploring the Role of Makerspaces in Long Term Care Facilities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300699},
doi = {10.1145/3290605.3300699},
abstract = {Fourth-age residents in long-term care facilities (LTCF) are known to suffer declines in well-being due to their advanced age and resulting loss of independence. Using an action research approach, we set up a makerspace in a New Jersey LTCF for eight weeks to see whether it could improve well-being for residents. Based on engaged observation over 280 hours and semi-structured interviews with participants, we find that people aged 80-99 years will spend (sometimes significant) time in a makerspace for the purposes of making and companionship; that makerspaces can contribute to both autonomy and well-being for older residents; and participants produced not only decorative art, but novel artifacts that solved real challenges in their daily lives. We situate these findings in the literature on art and activity therapy for fourth-age people, and make recommendations for makerspaces in long-term care facilities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {older adults, nursing homes, maker culture, well-being},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300589,
author = {Abtahi, Parastoo and Landry, Benoit and Yang, Jackie (Junrui) and Pavone, Marco and Follmer, Sean and Landay, James A.},
title = {Beyond The Force: Using Quadcopters to Appropriate Objects and the Environment for Haptics in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300589},
doi = {10.1145/3290605.3300589},
abstract = {Quadcopters have been used as hovering encountered-type haptic devices in virtual reality. We suggest that quadcopters can facilitate rich haptic interactions beyond force feedback by appropriating physical objects and the environment. We present HoverHaptics, an autonomous safe-to-touch quadcopter and its integration with a virtual shopping experience. HoverHaptics highlights three affordances of quadcopters that enable these rich haptic interactions: (1) dynamic positioning of passive haptics, (2) texture mapping, and (3) animating passive props. We identify inherent challenges of hovering encountered-type haptic devices, such as their limited speed, inadequate control accuracy, and safety concerns. We then detail our approach for tackling these challenges, including the use of display techniques, visuo-haptic illusions, and collision avoidance. We conclude by describing a preliminary study (n = 9) to better understand the subjective user experience when interacting with a quadcopter in virtual reality using these techniques.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {robotic graphics, haptics, human-drone interaction, quadcopter, virtual reality, drone, uav, encountered-type},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300341,
author = {Zhao, Yuhang and Cutrell, Edward and Holz, Christian and Morris, Meredith Ringel and Ofek, Eyal and Wilson, Andrew D.},
title = {SeeingVR: A Set of Tools to Make Virtual Reality More Accessible to People with Low Vision},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300341},
doi = {10.1145/3290605.3300341},
abstract = {Current virtual reality applications do not support people who have low vision, i.e., vision loss that falls short of complete blindness but is not correctable by glasses. We present SeeingVR, a set of 14 tools that enhance a VR application for people with low vision by providing visual and audio augmentations. A user can select, adjust, and combine different tools based on their preferences. Nine of our tools modify an existing VR application post hoc via a plugin without developer effort. The rest require simple inputs from developers using a Unity toolkit we created that allows integrating all 14 of our low vision support tools during development. Our evaluation with 11 participants with low vision showed that SeeingVR enabled users to better enjoy VR and complete tasks more quickly and accurately. Developers also found our Unity toolkit easy and convenient to use.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {accessibility, low vision, unity, virtual reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300421,
author = {Bartlett, Rachel and Khoo, Yi Xuan and Hourcade, Juan Pablo and Rector, Kyle K.},
title = {Exploring the Opportunities for Technologies to Enhance Quality of Life with People Who Have Experienced Vision Loss},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300421},
doi = {10.1145/3290605.3300421},
abstract = {Research predicts that 196 million people will be diagnosed with Age-Related Macular Degeneration (AMD) by 2020. People who experience AMD and other vision loss face barriers that affect their Quality of Life (QoL). People experience only modest improvement from technologies (e.g., screen readers, CCTV), tools (e.g., magnifying glasses, tactile buttons), and human help (e.g., friends, blindness organizations). Further, there are issues to accessing these resources based on one's place of residence. To explore these challenges and determine design implications to support people who have experienced vision loss (PVL), we conducted a qualitative semi-structured interview study exploring QoL with 10 PVL. We uncovered themes of supporting creative work, recognizing the impact of one's living in a non-urban setting on QoL, and increasing efficiency at accomplishing tasks. We motivate the inclusion of PVL in the design process because they learned skills while sighted and are now low vision or blind.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {accessibility, quality of life (qol), vision loss},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300387,
author = {B\"{o}rjesson, Peter and Barendregt, Wolmet and Eriksson, Eva and Torgersson, Olof and Bekker, Tilde},
title = {Teachers' Expected and Perceived Gains of Participation in Classroom Based Design Activities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300387},
doi = {10.1145/3290605.3300387},
abstract = {This paper explores teachers' expected and perceived gains from classroom participation in design projects. The results indicate that teachers hope the experience will be fun for the children, and that it will increase both children's and their own knowledge about technology. Although they consider learning goals important, these do not necessarily have to be communicated to the children, since the teachers experience that the children are learning several skills anyway. However, early involvement in the definition of learning goals could make participation more beneficial. The teachers also see several gains from partication for themselves, especially related to using a design approach in the classroom. We discuss the implications of these finding and suggest a way to increase the user gains for both children and teachers by considering the opportunity to use classroom participation as a way to support teachers' competence development, thereby fulfilling the promise of mutual learning as advocated in Participatory Design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {children, teachers, user gains, cci, participatory design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300509,
author = {Yin, Ming and Wortman Vaughan, Jennifer and Wallach, Hanna},
title = {Understanding the Effect of Accuracy on Trust in Machine Learning Models},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300509},
doi = {10.1145/3290605.3300509},
abstract = {We address a relatively under-explored aspect of human-computer interaction: people's abilities to understand the relationship between a machine learning model's stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized human-subject experiments to examine whether laypeople's trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on the model's stated accuracy on held-out data and on its observed accuracy in practice. We find that people's trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {trust, human-subject experiments, machine learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300606,
author = {Billah, Syed Masum and Ko, Yu-Jung and Ashok, Vikas and Bi, Xiaojun and Ramakrishnan, IV},
title = {Accessible Gesture Typing for Non-Visual Text Entry on Smartphones},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300606},
doi = {10.1145/3290605.3300606},
abstract = {Gesture typing--entering a word by gliding the finger sequentially over letter to letter-- has been widely supported on smartphones for sighted users. However, this input paradigm is currently inaccessible to blind users: it is difficult to draw shape gestures on a virtual keyboard without access to key visuals. This paper describes the design of accessible gesture typing, to bring this input paradigm to blind users. To help blind users figure out key locations, the design incorporates the familiar screen-reader supported touch exploration that narrates the keys as the user drags the finger across the keyboard. The design allows users to seamlessly switch between exploration and gesture typing mode by simply lifting the finger. Continuous touch-exploration like audio feedback is provided during word shape construction that helps the user glide in the right direction of the key locations constituting the word. Exploration mode resumes once word shape is completed. Distinct earcons help distinguish gesture typing mode from touch exploration mode, and thereby avoid unintended mix-ups. A user study with 14 blind people shows 35% increment in their typing speed, indicative of the promise and potential of gesture typing technology for non-visual text entry.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {accessible text entry, non-visual, blind, gesture-typing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300806,
author = {Li, Zhuying and Wang, Yan and Wang, Wei and Chen, Weikang and Hoang, Ti and Greuter, Stefan and Mueller, Florian Floyd},
title = {HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300806},
doi = {10.1145/3290605.3300806},
abstract = {Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present "HeatCraft", a two-player system that translates the user's body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {play, body temperature, ingestible sensors, thermal stimuli, localized sensation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300528,
author = {Bennett, Cynthia L. and Rosner, Daniela K.},
title = {The Promise of Empathy: Design, Disability, and Knowing the "Other"},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300528},
doi = {10.1145/3290605.3300528},
abstract = {This paper examines the promise of empathy, the name commonly given to the initial phase of the human-centered design process in which designers seek to understand their intended users in order to inform technology development. By analyzing popular empathy activities aimed at understanding people with disabilities, we examine the ways empathy works to both powerfully and problematically align designers with the values of people who may use their products. Drawing on disability studies and feminist theorizing, we describe how acts of empathy building may further distance people with disabilities from the processes designers intend to draw them into. We end by reimagining empathy as guided by the lived experiences of people with disabilities who are traditionally positioned as those to be empathized.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {disability, design methods, empathy},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300767,
author = {Speicher, Maximilian and Hall, Brian D. and Nebeling, Michael},
title = {What is Mixed Reality?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300767},
doi = {10.1145/3290605.3300767},
abstract = {What is Mixed Reality (MR)? To revisit this question given the many recent developments, we conducted interviews with ten AR/VR experts from academia and industry, as well as a literature survey of 68 papers. We find that, while there are prominent examples, there is no universally agreed on, one-size-fits-all definition of MR. Rather, we identified six partially competing notions from the literature and experts' responses. We then started to isolate the different aspects of reality relevant for MR experiences, going beyond the primarily visual notions and extending to audio, motion, haptics, taste, and smell. We distill our findings into a conceptual framework with seven dimensions to characterize MR applications in terms of the number of environments, number of users, level of immersion, level of virtuality, degree of interaction, input, and output. Our goal with this paper is to support classification and discussion of MR applications' design and provide a better means to researchers to contextualize their work within the increasingly fragmented MR landscape.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {taxonomy, literature review, mixed reality, expert interviews, virtual reality, conceptual framework, augmented reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300770,
author = {Taneja, Harsh and Yaeger, Katie},
title = {Do People Consume the News They Trust?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300770},
doi = {10.1145/3290605.3300770},
abstract = {It is reasonable to expect trusted news organizations to have more engaged users. However, given the lowest levels of trust in media and the several intermediaries involved in digital news consumption, recent studies posit that trust and usage may not be related. We argue that while trust may not relate to overall news usage, given that much of it is incidental, but it could still explain intentional usage. We correlated passively metered usage from digital trace data on 35 national news outlets in the US with their trustworthiness from a nationally representative survey, for three discrete months. We find no association between trust and overall user engagement, but a positive relationship between trustworthiness and direct visits, the latter a measure of intentional usage. These relationships held for outlets despite their partisan leanings, multi-platform presence and their mainstream nature.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {trustworthiness, online news, news media, rational choice, media choice, trust, media use},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300372,
author = {Dosono, Bryan and Semaan, Bryan},
title = {Moderation Practices as Emotional Labor in Sustaining Online Communities: The Case of AAPI Identity Work on Reddit},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300372},
doi = {10.1145/3290605.3300372},
abstract = {We examine how and why Asian American and Pacific Islander (AAPI) moderators on Reddit shape the norms of their online communities through the analytic lens of emotional labor. We conduct interviews with 21 moderators who facilitate identity work discourse in AAPI subreddits and present a thematic analysis of their moderation practices. We report on their challenges to sustaining moderation, which include burning out from volunteer work, navigating hierarchical structures, and balancing unfulfilled expectations. We then describe strategies that moderators employ to manage emotional labor, which involve distancing away from drama, building solidarity from shared struggles, and integrating an ecology of tools for self-organized moderation. We provide recommendations for improving moderation in online communities centered around identity work and discuss implications of emotional labor in the design of Reddit and similar platforms.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {reddit, online communities, bot, identity work, moderation, harassment, microaggressions, emotional labor, aapi, race},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300554,
author = {Gong, Jun and Anderson, Fraser and Fitzmaurice, George and Grossman, Tovi},
title = {Instrumenting and Analyzing Fabrication Activities, Users, and Expertise},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300554},
doi = {10.1145/3290605.3300554},
abstract = {The recent proliferation of fabrication and making activities has introduced a large number of users to a variety of tools and equipment. Monitored, reactive and adaptive fabrication spaces are needed to provide personalized information, feedback and assistance to users. This paper explores the sensorization of making and fabrication activities, where the environment, tools, and users were considered to be separate entities that could be instrumented for data collection. From this exploration, we present the design of a modular system that can capture data from the varied sensors and infer contextual information. Using this system, we collected data from fourteen participants with varying levels of expertise as they performed seven representative making tasks. From the collected data, we predict which activities are being performed, which users are performing the activities, and what expertise the users have. We present several use cases of this contextual information for future interactive fabrication spaces.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {skills evaluation, activity recognition, user identification, fabrication},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300794,
author = {McVeigh-Schultz, Joshua and Kolesnichenko, Anya and Isbister, Katherine},
title = {Shaping Pro-Social Interaction in VR: An Emerging Design Framework},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300794},
doi = {10.1145/3290605.3300794},
abstract = {Commercial social VR applications represent a diverse and evolving ecology with competing models of what it means to be social in VR. Drawing from expert interviews, this paper examines how the creators of different social VR applications think about how their platforms frame, support, shape, or constrain social interaction. The study covers a range of applications including: Rec Room, High Fidelity, VRChat, Mozilla Hubs, Altspace VR, AnyLand, and Facebook Spaces. We contextualize design choices underlying these applications, with particular attention paid to the ways that industry experts perceive, and seek to shape, the relationship between user experiences and design choices. We underscore considerations related to: (1) aesthetics of place (2) embodied affordances, (3) social mechanics, (4) and tactics for shaping social norms and mitigating harassment. Drawing on this analysis, we discuss the stakes of these choices, suggest future research directions, and propose an emerging design framework for shaping pro-social behavior in VR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, pro-social interaction, social vr},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300375,
author = {Fedosov, Anton and Kitazaki, Masako and Odom, William and Langheinrich, Marc},
title = {Sharing Economy Design Cards},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300375},
doi = {10.1145/3290605.3300375},
abstract = {Sharing economy services have become increasingly popular. In addition to various well-known for-profit activities in this space (e.g., ride and apartment sharing), many community groups and non-profit organizations offer collections of shared things (e.g., books, tools) that explicitly aim to benefit local communities. We expect that both non-profit and for-profit approaches will see an increased use in the future. To support designers in devising new sharing economy services, we developed the Sharing Economy Design Cards, a design toolkit in the form of a card deck. We present two deployments of the cards: (1) in individual interviews with 16 designers and sharing economy domain experts; and (2) in two workshops with 5 participants each. Our findings show that the use of the cards not only facilitates the creation of future sharing platforms and services in a collaborative setting, but also helps to evaluate existing sharing economy services as an individual activity.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sharing economy, collaborative workshop, design process},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300665,
author = {McGookin, David},
title = {Reveal: Investigating Proactive Location-Based Reminiscing with Personal Digital Photo Repositories},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300665},
doi = {10.1145/3290605.3300665},
abstract = {Recording experiences and memories is an important role for digital photography, with smartphone cameras leading to individuals taking increasing numbers of pictures of everyday experiences. Increasingly, these are automatically stored in personal, cloud-backed, photo repositories. However, such experiences can be forgotten quickly, with images 'lost' within the user's library, loosing their role in supporting reminiscing. We investigate how users might be provoked to view these images and the benefits they bring through the development and evaluation of a proactive, location-based reminiscing tool, called Reveal. We outline how a location-based approach allowed participants to reflect more widely on their photo practice, and the potential of such reminiscing tools to support effective management and curation of individual's increasingly large personal photo collections.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {reminiscence, location-based systems, personal digital photography},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300486,
author = {Ashktorab, Zahra and Weisz, Justin D. and Ashoori, Maryam},
title = {Thinking Too Classically: Research Topics in Human-Quantum Computer Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300486},
doi = {10.1145/3290605.3300486},
abstract = {Quantum computing is a fundamentally different way of performing computation than classical computing. Many problems that are considered hard for classical computers may have efficient solutions using quantum computers. Recently, technology companies including IBM, Microsoft, and Google have invested in developing both quantum computing hardware and software to explore the potential of quantum computing. Because of the radical shift in computing paradigms that quantum represents, we see an opportunity to study the unique needs people have when interacting with quantum systems, what we call Quantum HCI (QHCI). Based on interviews with experts in quantum computing, we identify four areas in which HCI researchers can contribute to the field of quantum computing. These areas include understanding current and future quantum users, tools for programming and debugging quantum algorithms, visualizations of quantum states, and educational materials to train the first generation of "quantum native" programmers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {qhci, human-quantum computer interaction, quantum computing education},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300711,
author = {Kou, Yubo and Gui, Xinning and Chen, Yunan and Nardi, Bonnie},
title = {Turn to the Self in Human-Computer Interaction: Care of the Self in Negotiating the Human-Technology Relationship},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300711},
doi = {10.1145/3290605.3300711},
abstract = {Everyday life is increasingly mediated by technology. Technology is rapidly growing capacity and complexity, especially evident in developments in artificial intelligence and big data analytics. As human-computer interaction (HCI) endeavors to examine and theorize how people act and interact with the ever-evolving technology, an important, emerging concern is how the self-the totality of internal qualities such as consciousness and agency-plays out in relation to the technology-mediated external world. To analyze this question, we draw from Michel Foucault's ethics of "care of the self," which examines how the self is constituted through conscious and reflective work on self-transformation. We present three case studies to illustrate how individuals carry out practices of the self to reflect upon and negotiate their relationship with technology. We discuss the importance of examining the self and foreground the notion of care of the self in HCI research and design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {foucault, censorship, healthcare, ethics, existential hci, quantified-self, care of the self, politics, power, political economy, neoliberalism},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300269,
author = {Echeverria, Vanessa and Martinez-Maldonado, Roberto and Buckingham Shum, Simon},
title = {Towards Collaboration Translucence: Giving Meaning to Multimodal Group Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300269},
doi = {10.1145/3290605.3300269},
abstract = {Collocated, face-to-face teamwork remains a pervasive mode of working, which is hard to replicate online. Team members' embodied, multimodal interaction with each other and artefacts has been studied by researchers, but due to its complexity, has remained opaque to automated analysis. However, the ready availability of sensors makes it increasingly affordable to instrument work spaces to study teamwork and groupwork. The possibility of visualising key aspects of a collaboration has huge potential for both academic and professional learning, but a frontline challenge is the enrichment of quantitative data streams with the qualitative insights needed to make sense of them. In response, we introduce the concept of collaboration translucence, an approach to make visible selected features of group activity. This is grounded both theoretically (in the physical, epistemic, social and affective dimensions of group activity), and contextually (using domain-specific concepts). We illustrate the approach from the automated analysis of healthcare simulations to train nurses, generating four visual proxies that fuse multimodal data into higher order patterns.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {learning analytics, pervasive computing, collaboration, cscw},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300542,
author = {Tran, Jonathan A. and Yang, Katie S. and Davis, Katie and Hiniker, Alexis},
title = {Modeling the Engagement-Disengagement Cycle of Compulsive Phone Use},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300542},
doi = {10.1145/3290605.3300542},
abstract = {Many smartphone users engage in compulsive and habitual phone checking they find frustrating, yet our understanding of how this phenomenon is experienced is limited. We conducted a semi-structured interview, a think-aloud phone-use demonstration, and a sketching exercise with 39 smartphone users (ages 14-64) to probe their experiences with compulsive phone checking. Their insights revealed a small taxonomy of common triggers that lead up to instances of compulsive phone use and a second set that end compulsive phone use sessions. Though participants expressed frustration with their lack of self-control, they also reported that the activities they engage in during these sessions can be meaningful, which they defined as transcending the current instance of use. Participants said they periodically reflect on their compulsive use and delete apps that drive compulsive checking without providing sufficient meaning. We use these findings to create a descriptive model of the cycle of compulsive checking, and we call on designers to craft experiences that meet users' definition of meaningfulness rather than creating lock-out mechanisms to help them police their own use.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interview, habits, smartphone, self-regulation, compulsive phone use},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300514,
author = {Thoravi Kumaravel, Balasaravanan and Nguyen, Cuong and DiVerdi, Stephen and Hartmann, Bj\"{o}rn},
title = {TutoriVR: A Video-Based Tutorial System for Design Applications in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300514},
doi = {10.1145/3290605.3300514},
abstract = {Virtual Reality painting is a form of 3D-painting done in a Virtual Reality (VR) space. Being a relatively new kind of art form, there is a growing interest within the creative practices community to learn it. Currently, most users learn using community posted 2D-videos on the internet, which are a screencast recording of the painting process by an instructor. While such an approach may suffice for teaching 2D-software tools, these videos by themselves fail in delivering crucial details that required by the user to understand actions in a VR space. We conduct a formative study to identify challenges faced by users in learning to VR-paint using such video-based tutorials. Informed by results of this study, we develop a VR-embedded tutorial system that supplements video tutorials with 3D and contextual aids directly in the user's VR environment. An exploratory evaluation showed users were positive about the system and were able to use the proposed system to recreate painting tasks in VR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, software tutorials, design applications},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300356,
author = {Muller, Michael and Lange, Ingrid and Wang, Dakuo and Piorkowski, David and Tsay, Jason and Liao, Q. Vera and Dugan, Casey and Erickson, Thomas},
title = {How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300356},
doi = {10.1145/3290605.3300356},
abstract = {With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {data creation, grounded theory, work-practices, data science, data curation, data discovery, data design, data capture},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300691,
author = {Bi, Tao and Bianchi-Berthouze, Nadia and Singh, Aneesha and Costanza, Enrico},
title = {Understanding the Shared Experience of Runners and Spectators in Long-Distance Running Events},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300691},
doi = {10.1145/3290605.3300691},
abstract = {Increasingly popular, long-distance running events (LDRE) attract not just runners but an exponentially increasing number of spectators. Due to the long duration and broad geographic spread of such events, interactions between them are limited to brief moments when runners (R) pass by their supporting spectators (S). Current technology is limited in its potential for supporting interactions and mainly measures and displays basic running information to spectators who passively consume it. In this paper, we conducted qualitative studies for an in-depth understanding of the R&amp;S' shared experience during LDRE and how technology can enrich this experience. We propose a two-layer DyPECS framework, highlighting the rich dynamics of the R&amp;S multi-faceted running journey and of their micro-encounters. DyPECS is enriched by the findings from our in depth qualitative studies. We finally present design implications for the multi-facet co-experience of R&amp;S during LDRE.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {long-distance running, runner experience, spectator technology, shared experience, spectator experience, running technology, runner-spectator connection},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300332,
author = {Simon, Florine and Roudaut, Anne and Irani, Pourang and Serrano, Marcos},
title = {Finding Information on Non-Rectangular Interfaces},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300332},
doi = {10.1145/3290605.3300332},
abstract = {With upcoming breakthroughs in free-form display technologies, new user interface design challenges have emerged. Here, we investigate a question, which has been widely explored on traditional GUIs but unexplored on non-rectangular interfaces: what are the user strategies in terms of visual search when information is not presented in a traditional rectangular layout? To achieve this, we present two complementary studies investigating eye movements in different visual search tasks. Our results unveil which areas are seen first according to different visual structures. By doing so we address the question of where to place relevant content for the UI designers of non-rectangular displays.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {non-rectangular interface, user interfaces design, visual search, visualisation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300796,
author = {Baudisch, Patrick and Silber, Arthur and Kommana, Yannis and Gruner, Milan and Wall, Ludwig and Reuss, Kevin and Heilman, Lukas and Kovacs, Robert and Rechlitz, Daniel and Roumen, Thijs},
title = {Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300796},
doi = {10.1145/3290605.3300796},
abstract = {We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint "boxel"-a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb's various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {laser cutting, interactive editing, personal fabrication},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300918,
author = {Kim, Lawrence H. and Follmer, Sean},
title = {SwarmHaptics: Haptic Display with Swarm Robots},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300918},
doi = {10.1145/3290605.3300918},
abstract = {This paper seeks to better understand the use of haptic feedback in abstract, ubiquitous robotic interfaces. We introduce and provide preliminary evaluations of SwarmHaptics, a new type of haptic display using a swarm of small, wheeled robots. These robots move on a flat surface and apply haptic patterns to the user's hand, arm, or any other accessible body parts. We explore the design space of SwarmHaptics including individual and collective robot parameters, and demonstrate example scenarios including remote social touch using the Zooids platform. To gain insights into human perception, we applied haptic patterns with varying number of robots, force type, frequency, and amplitude and obtained user's perception in terms of emotion, urgency, and Human-Robot Interaction metrics. In a separate elicitation study, users generated a set of haptic patterns for social touch. The results from the two studies help inform how users perceive and generate haptic patterns with SwarmHaptics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ubiquitous robotic interfaces, swarm haptics, swarm user interface, haptics, human-robot interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300498,
author = {Geeng, Christine and Roesner, Franziska},
title = {Who's In Control? Interactions In Multi-User Smart Homes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300498},
doi = {10.1145/3290605.3300498},
abstract = {Adoption of commercial smart home devices is rapidly increasing, allowing in-situ research in people's homes. As these technologies are deployed in shared spaces, we seek to understand interactions among multiple people and devices in a smart home. We conducted a mixed-methods study with 18 participants (primarily people who drive smart device adoption in their homes) living in multi-user smart homes, combining semi-structured interviews and experience sampling. Our findings surface tensions and cooperation among users in several phases of smart device use: device selection and installation, ordinary use, when the smart home does not work as expected, and over longer term use. We observe an outsized role of the person who installs devices in terms of selecting, controlling, and fixing them; negotiations between parents and children; and minimally voiced privacy concerns among co-occupants, possibly due to participant sampling. We make design recommendations for supporting long-term smart homes and non-expert household members.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user experience, qualitative study, privacy, experience sampling, smart home, multi-user},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300893,
author = {Chidambaram, Subramanian and Zhang, Yunbo and Sundararajan, Venkatraghavan and Elmqvist, Niklas and Ramani, Karthik},
title = {Shape Structuralizer: Design, Fabrication, and User-Driven Iterative Refinement of 3D Mesh Models},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300893},
doi = {10.1145/3290605.3300893},
abstract = {Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users towards designs ready for fabrication. We propose Shape Structuralizer (SS), an interactive design support system that repurposes surface models into structural constructions using rods and custom 3D-printed joints. Shape Structuralizer embeds a recommendation system that computationally supports the user during design ideation by providing design suggestions on local refinements of the design. This strategy enables novice users to choose designs that both satisfy stress constraints as well as their personal design intent. The interactive guidance enables users to repurpose existing surface mesh models, analyze them in-situ for stress and displacement constraints, add movable joints to increase functionality, and attach a customized appearance. This also empowers novices to fabricate even complex constructs while ensuring structural soundness. We validate the Shape Structuralizer tool with a qualitative user study where we observed that even novice users were able to generate a large number of structurally safe designs for fabrication.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {cad, fabrication, 3d modeling, design recommendation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300497,
author = {Badillo-Urquiola, Karla and Page, Xinru and Wisniewski, Pamela J.},
title = {Risk vs. Restriction: The Tension between Providing a Sense of Normalcy and Keeping Foster Teens Safe Online},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300497},
doi = {10.1145/3290605.3300497},
abstract = {Foster youth are particularly vulnerable to offline risks; yet, little is known about their online risk experiences or how foster parents mediate technology use in the home. We conducted 29 interviews with foster parents of 42 teens (ages 13-17) who were part of the child welfare system. Foster parents faced significant challenges relating to technology mediation in the home. Based on parental accounts, over half of the foster teens encountered high-risk situations that involved interacting with unsafe people online, resulting in rape, sex trafficking, and/or psychological harm. Overall, foster parents were at a loss for how to balance online safety with technology access in a way that engendered positive relationships with their foster teens. Instead, parents often resorted to outright restriction. Our research highlights the importance of considering the unique needs of foster families and designing technologies to address the challenges faced by this vulnerable population of teens and parents.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {foster care system, parental mediation strategies, adolescent online safety, foster parents},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300840,
author = {Foley, Sarah and Pantidi, Nadia and McCarthy, John},
title = {Care and Design: An Ethnography of Mutual Recognition in the Context of Advanced Dementia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300840},
doi = {10.1145/3290605.3300840},
abstract = {While there have been considerable developments in designing for dementia within HCI, there is still a lack of empirical understanding of the experience of people with advanced dementia and the ways in which design can support and enrich their lives. In this paper, we present our findings from a long-term ethnographic study, which aimed to gain an understanding of their lived experience and inform design practices for and with people with advanced dementia in residential care. We present our findings using the social theory of recognition as an analytic lens to account for recognition in practice and its challenges in care and research. We discuss how we, as the HCI community, can pragmatically engage with people with advanced dementia and propose a set of considerations for those who wish to design for and with the values of recognition theory to promote collaboration, agency and social identity in advanced dementia care.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {ethnography, experience-centered design, recognition theory, dementia},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300775,
author = {Shahmiri, Fereshteh and Chen, Chaoyu and Waghmare, Anandghan and Zhang, Dingtian and Mittal, Shivan and Zhang, Steven L. and Wang, Yi-Cheng and Wang, Zhong Lin and Starner, Thad E. and Abowd, Gregory D.},
title = {Serpentine: A Self-Powered Reversibly Deformable Cord Sensor for Human Input},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300775},
doi = {10.1145/3290605.3300775},
abstract = {We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions---Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant user study illustrates 95.7% accuracy for a user-dependent recognition model using a realtime system and 92.17% for user-independent offline detection. We conclude by demonstrating how Serpentine can be employed in everyday ubiquitous computing applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {triboelectric nanogenerator, input devices, ubiquitous computing, self-powered sensor, soft electronics, tangible interfaces},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300864,
author = {Xia, Meng and Sun, Mingfei and Wei, Huan and Chen, Qing and Wang, Yong and Shi, Lei and Qu, Huamin and Ma, Xiaojuan},
title = {PeerLens: Peer-Inspired Interactive Learning Path Planning in Online Question Pool},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300864},
doi = {10.1145/3290605.3300864},
abstract = {Online question pools like LeetCode provide hands-on exercises of skills and knowledge. However, due to the large volume of questions and the intent of hiding the tested knowledge behind them, many users find it hard to decide where to start or how to proceed based on their goals and performance. To overcome these limitations, we present PeerLens, an interactive visual analysis system that enables peer-inspired learning path planning. PeerLens can recommend a customized, adaptable sequence of practice questions to individual learners, based on the exercise history of other users in a similar learning scenario. We propose a new way to model the learning path by submission types and a novel visual design to facilitate the understanding and planning of the learning path. We conducted a within-subject experiment to assess the efficacy and usefulness of PeerLens in comparison with two baseline systems. Experiment results show that users are more confident in arranging their learning path via PeerLens and find it more informative and intuitive.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {question pool, learning path planning, visualization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300762,
author = {Vinayagamoorthy, Vinoba and Glancy, Maxine and Ziegler, Christoph and Sch\"{a}ffer, Richard},
title = {Personalising the TV Experience Using Augmented Reality: An Exploratory Study on Delivering Synchronised Sign Language Interpretation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300762},
doi = {10.1145/3290605.3300762},
abstract = {Augmented Reality (AR) technology has the potential to extend the screen area beyond the rigid frames of televisions. The additional display area can be used to augment televisions (TVs) with extra information tailored to individuals, for instance, the provision of access services like sign language interpretations. We invited 23 (11 in the UK, 12 in Germany) users of signed content to evaluate three methods of watching a sign language interpreted programme - one traditional in-vision method with signed programme content on TV and two AR-enabled methods in which an AR sign language interpreter (a 'half-body' version and a 'full-body' version) is projected just outside the frame of the TV presenting the programme. In the UK, participants were split 3-ways in their preferences while in Germany, half the participants preferred the traditional method followed closely by the 'half-body' version. We discuss our participants reasoning behind their preferences and implications for future research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {television, augmented reality, interaction techniques, bsl, companion screen, personalisation, connected experiences, second screen, dgs, sign language, hbbtv 2.0, sse, accessibility, hololens, synchronisation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300257,
author = {Mott, Martez E. and Wobbrock, Jacob O.},
title = {Cluster Touch: Improving Touch Accuracy on Smartphones for People with Motor and Situational Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300257},
doi = {10.1145/3290605.3300257},
abstract = {We present Cluster Touch, a combined user-independent and user-specific touch offset model that improves the accuracy of touch input on smartphones for people with motor impairments, and for people experiencing situational impairments while walking. Cluster Touch combines touch examples from multiple users to create a shared user-independent touch model, which is then updated with touch examples provided by an individual user to make it user-specific. Owing to this combination, Cluster Touch allows people to quickly improve the accuracy of their smartphones by providing only 20 touch examples. In a user study with 12 people with motor impairments and 12 people without motor impairments, but who were walking, Cluster Touch improved touch accuracy by 14.65% for the former group and 6.81% for the latter group over the native touch sensor. Furthermore, in an offline analysis of existing mobile interfaces, Cluster Touch improved touch accuracy by 8.21% and 4.84% over the native touch sensor for the two user groups, respectively.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {touch input, touch modeling, ability-based design, situational impairments, accessibility, smartphones, motor impairments},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300304,
author = {Lee, David T. and Hamedian, Emily S. and Wolff, Greg and Liu, Amy},
title = {Causeway: Scaling Situated Learning with Micro-Role Hierarchies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300304},
doi = {10.1145/3290605.3300304},
abstract = {While educational technologies such as MOOCs have helped scale content-based learning, scaling situated learning is still challenging. The time it takes to define a real-world project and to mentor learners is often prohibitive, especially given the limited contributions that novices are able to make. This paper introduces micro-role hierarchies, a form of coordination that integrates workflows and hierarchies to help short-term novices predictably contribute to complex projects. Individuals contribute through micro-roles, small experiential assignments taking roughly 2 hours. These micro-roles support execution of the desired work process, but also sequence into learning pathways, resulting in a learning dynamic similar to moving up an organizational hierarchy. We demonstrate micro-role hierarchies through Causeway, a platform for learning web development while building websites for nonprofits. We carry out a proof-of-concept study in which learners built static websites for refugee resettlement agencies in 2 hour long roles.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social computing, learnersourcing, situated learning, complex crowd work, learning-at-scale, micro-role hierarchies, crowdsourcing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300739,
author = {Mirnig, Alexander G. and Meschtscherjakov, Alexander},
title = {Trolled by the Trolley Problem: On What Matters for Ethical Decision Making in Automated Vehicles},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300739},
doi = {10.1145/3290605.3300739},
abstract = {Automated vehicles have to make decisions, such as driving maneuvers or rerouting, based on environment data and decision algorithms. There is a question whether ethical aspects should be considered in these algorithms. When all available decisions within a situation have fatal consequences, this leads to a dilemma. Contemporary discourse surrounding this issue is dominated by the trolley problem, a specific version of such a dilemma. Based on an outline of its origins, we discuss the trolley problem and its viability to help solve the questions regarding ethical decision making in automated vehicles. We show that the trolley problem serves several important functions but is an ill-suited benchmark for the success or failure of an automated algorithm. We argue that research and design should focus on avoiding trolley-like problems at all rather than trying to solve an unsolvable dilemma and discuss alternative approaches on how to feasibly address ethical issues in automated agents.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {trolley problem, dilemma, automated vehicles, ethics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300626,
author = {Iivari, Netta},
title = {Power Struggles and Disciplined Designers - A Nexus Analytic Inquiry on Cross-Disciplinary Research and Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300626},
doi = {10.1145/3290605.3300626},
abstract = {Design is at the heart of Human Computer Interaction research and practice. In the research community, there has emerged an increasing interest in understanding and conceptualizing our research practice, particularly such entailing design. However, reflective discussion around the associated challenges and practicalities is yet limited. Moreover, so far there is limited discussion on the cross-disciplinary nature of our research and design practices: although cross-disciplinarity has been brought up as an ideal and a necessity, its practicalities and complexities remain yet poorly explored. This study examines a cross-disciplinary research project with a number of researcher-designers representing different disciplines acting as 'designers', while having a divergent understanding of it and of who has authority to do it. The study relies on nexus analysis as a sensitizing device and shows how various discourses, epistemologies and histories shape cross-disciplinary research and design. Critical reflection around our research practice entailing design is called for.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {research into design, cross-disciplinary, inter-disciplinary, nexus analysis, transdisciplinary, design research, research through design, multi-disciplinary},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300303,
author = {Yip, Jason C. and Sobel, Kiley and Gao, Xin and Hishikawa, Allison Marie and Lim, Alexis and Meng, Laura and Ofiana, Romaine Flor and Park, Justin and Hiniker, Alexis},
title = {Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300303},
doi = {10.1145/3290605.3300303},
abstract = {In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves find concerning in everyday technologies. We examine children's technology-related fears by probing their use of the colloquial term "creepy." To understand children's perceptions of "creepy technologies," we conducted four participatory design sessions with children (ages 7 - 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children's fear reactions emphasized physical harm and threats to their relationships (particularly with attachment figures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is "creepy." By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {participatory design, threats, fear, privacy and surveillance, creepy, children and parents},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300766,
author = {Tan, Sheng and Zhang, Linghan and Wang, Zi and Yang, Jie},
title = {MultiTrack: Multi-User Tracking and Activity Recognition Using Commodity WiFi},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300766},
doi = {10.1145/3290605.3300766},
abstract = {This paper presents MultiTrack, a commodity WiFi based human sensing system that can track multiple users and recognize activities of multiple users performing them simultaneously. Such a system can enable easy and large-scale deployment for multi-user tracking and sensing without the need for additional sensors through the use of existing WiFi devices (e.g., desktops, laptops and smart appliances). The basic idea is to identify and extract the signal reflection corresponding to each individual user with the help of multiple WiFi links and all the available WiFi channels at 5GHz. Given the extracted signal reflection of each user, MultiTrack examines the path of the reflected signals at multiple links to simultaneously track multiple users. It further reconstructs the signal profile of each user as if only a single user has performed activity in the environment to facilitate multi-user activity recognition. We evaluate MultiTrack in different multipath environments with up to 4 users for multi-user tracking and up to 3 users for activity recognition. Experimental results show that our system can achieve decimeter localization accuracy and over 92% activity recognition accuracy under multi-user scenarios.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {activity recognition, wifi sensing, human tracking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300744,
author = {Koushik, Varsha and Kane, Shaun K.},
title = {"It Broadens My Mind": Empowering People with Cognitive Disabilities through Computing Education},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300744},
doi = {10.1145/3290605.3300744},
abstract = {Computer science education is widely viewed as a path to empowerment for young people, potentially leading to higher education, careers, and development of computational thinking skills. However, few resources exist for people with cognitive disabilities to learn computer science. In this paper, we document our observations of a successful program in which young adults with cognitive disabilities are trained in computing concepts. Through field observations and interviews, we identify instructional strategies used by this group, accessibility challenges encountered by this group, and how instructors and students leverage peer learning to support technical education. Our findings lead to guidelines for developing tools and curricula to support young adults with cognitive disabilities in learning computer science.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {cognitive disability, accessibility, computer science education},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300898,
author = {Akbar, Fatema and Bayraktaroglu, Ayse Elvan and Buddharaju, Pradeep and Da Cunha Silva, Dennis Rodrigo and Gao, Ge and Grover, Ted and Gutierrez-Osuna, Ricardo and Jones, Nathan Cooper and Mark, Gloria and Pavlidis, Ioannis and Storer, Kevin and Wang, Zelun and Wesley, Amanveer and Zaman, Shaila},
title = {Email Makes You Sweat: Examining Email Interruptions and Stress Using Thermal Imaging},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300898},
doi = {10.1145/3290605.3300898},
abstract = {Workplace environments are characterized by frequent interruptions that can lead to stress. However, measures of stress due to interruptions are typically obtained through self-reports, which can be affected by memory and emotional biases. In this paper, we use a thermal imaging system to obtain objective measures of stress and investigate personality differences in contexts of high and low interruptions. Since a major source of workplace interruptions is email, we studied 63 participants while multitasking in a controlled office environment with two different email contexts: managing email in batch mode or with frequent interruptions. We discovered that people who score high in Neuroticism are significantly more stressed in batching environments than those low in Neuroticism. People who are more stressed finish emails faster. Last, using Linguistic Inquiry Word Count on the email text, we find that higher stressed people in multitasking environments use more anger in their emails. These findings help to disambiguate prior conflicting results on email batching and stress.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {empirical study, interruptions, sensors, stress, email, multitasking, personality, thermal imaging},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300669,
author = {Kozubaev, Sandjar and Rochaix, Fernando and DiSalvo, Carl and Le Dantec, Christopher A.},
title = {Spaces and Traces: Implications of Smart Technology in Public Housing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300669},
doi = {10.1145/3290605.3300669},
abstract = {Smart home technologies are beginning to become more widespread and common, even as their deployment and implementation remain complex and spread across different competing commercial ecosystems. Looking beyond the middle-class, single-family home often at the center of the smart home narrative, we report on a series of participatory design workshops held with residents and building managers to better understand the role of smart home technologies in the context of public housing in the U.S. The design workshops enabled us to gather insight into the specific challenges and opportunities of deploying smart home technologies in a setting where issues of privacy, data collection and ownership, and autonomy collide with diverse living arrangements, where income, age, and the consequences of monitoring and data aggregation setup an expanding collection of design implications in the ecosystems of smart home technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart homes, participatory design, privacy, public housing, design research},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300412,
author = {Altmeyer, Maximilian and Dernbecher, Kathrin and Hnatovskiy, Vladislav and Schubhan, Marc and Lessel, Pascal and Kr\"{u}ger, Antonio},
title = {Gamified Ads: Bridging the Gap Between User Enjoyment and the Effectiveness of Online Ads},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300412},
doi = {10.1145/3290605.3300412},
abstract = {While the use of ad blockers prevents negative impacts of advertising on user experience, it poses a serious threat to the business model of commercial web services and freely available content on the web. As an alternative, we investigate the user enjoyment and the advertising effectiveness of playfully deactivating online ads. We created eight game concepts, performed a pre-study assessing the users' perception of them (N=50) and implemented three well-perceived ones. In a lab study (N=72), we found that these game concepts are more enjoyable than deactivating ads without game elements. Additionally, one game concept was even preferred over using an ad blocker. Notably, playfully deactivating ads was shown to have a positive impact on users' brand and product memory, enhancing the advertising effectiveness. Thus, our results indicate that playfully deactivating ads is a promising way of bridging the gap between user enjoyment and effective advertising.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {advertising, enjoyment, recall, effectiveness, gamification, recognition},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300746,
author = {Wu, Shaomei and Reynolds, Lindsay and Li, Xian and Guzm\'{a}n, Francisco},
title = {Design and Evaluation of a Social Media Writing Support Tool for People with Dyslexia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300746},
doi = {10.1145/3290605.3300746},
abstract = {People with dyslexia face challenges expressing themselves in writing on social networking sites (SNSs). Such challenges come from not only the technicality of writing, but also the self-representation aspect of sharing and communicating publicly on social networking sites such as Facebook. To empower people with dyslexia-style writing to express them-selves more confidently on SNSs, we designed and implemented Additional Writing Help(AWH) - a writing assistance tool to proofread text produced by users with dyslexia before they post on Facebook. AWH was powered by a neural machine translation (NMT) model that translates dyslexia style to non-dyslexia style writing. We evaluated the performance and the design of AWH through a week-long field study with 19 people with dyslexia and received highly positive feedback. Our field study demonstrated the value of providing better and more extensive writing support on SNSs, and the potential of AI for building a more inclusive Internet.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {accessibility, dyslexia, artificial intelligence, social media},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300309,
author = {Kim, Nam Wook and Im, Hyejin and Henry Riche, Nathalie and Wang, Alicia and Gajos, Krzysztof and Pfister, Hanspeter},
title = {DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300309},
doi = {10.1145/3290605.3300309},
abstract = {Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {personal informatics, self-tracking, data selfies, visualization, visual vocabulary, data portraits, personal visualization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300453,
author = {Iacovides, Ioanna and Mekler, Elisa D.},
title = {The Role of Gaming During Difficult Life Experiences},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300453},
doi = {10.1145/3290605.3300453},
abstract = {HCI has become increasingly interested in the use of technology during difficult life experiences. Yet despite considerable popularity, little is known about how and why people engage with games in times of personal difficulty. Based on a qualitative analysis of an online survey (N=95), our findings indicate that games offered players much needed respite from stress, supported them in dealing with their feelings, facilitated social connections, stimulated personal change and growth, and provided a lifeline in times of existential doubt. However, despite an emphasis on gaming as being able to support coping in ways other activities did not, participants also referred to games as unproductive and as an obstacle to living well. We discuss these findings in relation to both coping process and outcome, while considering tensions around the potential benefits and perceived value of gaming.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {sensitive life experiences, games, difficult life experiences},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300637,
author = {Hube, Christoph and Fetahu, Besnik and Gadiraju, Ujwal},
title = {Understanding and Mitigating Worker Biases in the Crowdsourced Collection of Subjective Judgments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300637},
doi = {10.1145/3290605.3300637},
abstract = {Crowdsourced data acquired from tasks that comprise a subjective component (e.g. opinion detection, sentiment analysis) is potentially affected by the inherent bias of crowd workers who contribute to the tasks. This can lead to biased and noisy ground-truth data, propagating the undesirable bias and noise when used in turn to train machine learning models or evaluate systems. In this work, we aim to understand the influence of workers' own opinions on their performance in the subjective task of bias detection. We analyze the influence of workers' opinions on their annotations corresponding to different topics. Our findings reveal that workers with strong opinions tend to produce biased annotations. We show that such bias can be mitigated to improve the overall quality of the data collected. Experienced crowd workers also fail to distance themselves from their own opinions to provide unbiased annotations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {crowdsourcing, microtasks, bias, workers},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300369,
author = {Rankin, Yolanda A. and Han, Na-eun},
title = {Exploring the Plurality of Black Women's Gameplay Experiences},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300369},
doi = {10.1145/3290605.3300369},
abstract = {Few gender-focused studies of video games explore the gameplay experiences of women of color, and those that do tend to only emphasize negative phenomena (i.e., racial or gender discrimination). In this paper, we conduct an exploratory case study attending to the motivations and gaming practices of Black college women. Questionnaire responses and focus group discussion illuminate the plurality of gameplay experiences for this specific population of Black college women. Sixty-five percent of this population enjoy the ubiquity of mobile games with casual and puzzle games being the most popular genres. However, academic responsibilities and competing recreational interests inhibit frequent gameplay. Consequently, this population of Black college women represent two types of casual gamers who report positive gameplay experiences, providing insights into creating a more inclusive gaming subculture.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {gendered game studies, black women, gaming, intersectionality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300285,
author = {Zhang, Yang and Pahud, Michel and Holz, Christian and Xia, Haijun and Laput, Gierad and McGuffin, Michael and Tu, Xiao and Mittereder, Andrew and Su, Fei and Buxton, William and Hinckley, Ken},
title = {Sensing Posture-Aware Pen+Touch Interaction on Tablets},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300285},
doi = {10.1145/3290605.3300285},
abstract = {Many status-quo interfaces for tablets with pen + touch input capabilities force users to reach for device-centric UI widgets at fixed locations, rather than sensing and adapting to the user-centric posture. To address this problem, we propose sensing techniques that transition between various nuances of mobile and stationary use via postural awareness. These postural nuances include shifting hand grips, varying screen angle and orientation, planting the palm while writing or sketching, and detecting what direction the hands approach from. To achieve this, our system combines three sensing modalities: 1) raw capacitance touchscreen images, 2) inertial motion, and 3) electric field sensors around the screen bezel for grasp and hand proximity detection. We show how these sensors enable posture-aware pen+touch techniques that adapt interaction and morph user interface elements to suit fine-grained contexts of body-, arm-, hand-, and grip-centric frames of reference.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {tablets, pen + touch, electric field sensing, sensing, posture, grip},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300452,
author = {Davies, Tabby and Jones, Simon L. and Kelly, Ryan M.},
title = {Patient Perspectives on Self-Management Technologies for Chronic Fatigue Syndrome},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300452},
doi = {10.1145/3290605.3300452},
abstract = {Chronic Fatigue Syndrome (CFS) is a debilitating medical condition that is characterized by a range of physical, cognitive and social impairments. This paper investigates CFS patients' perspectives on the potential for technological support for self-management of their symptoms. We report findings from three studies in which people living with CFS 1) prioritized symptoms that they would like technologies to address, 2) articulated their current approaches to self-management alongside challenges they face, and 3) reflected on their experiences with three commercial smartphone apps related to symptom management. We contribute an understanding of the specific needs of the ME/CFS population and the ways in which they currently engage in self-management using technology. The paper ends by describing five high-level design recommendations for ME/CFS self-management technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {chronic fatigue syndrome, myalgic encephalomyelitis, self-management, self-tracking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300347,
author = {Hirskyj-Douglas, Ilyena and Lucero, Andr\'{e}s},
title = {On the Internet, Nobody Knows You're a Dog... Unless You're Another Dog},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300347},
doi = {10.1145/3290605.3300347},
abstract = {How humans use computers has evolved from human-machine interfaces to human-human computer mediated communication. Whilst the field of animal-computer interaction has roots in HCI, technology developed in this area currently only supports animal? computer communication. This design fiction paper presents animal-animal connected interfaces, using dogs as an instance. Through a co-design workshop, we created six proposals. The designs focused on what a dog internet could look like and how interactions might be presented. Analysis of the narratives and conceived designs indicated that participants' concerns focused around asymmetries within the interaction. This resulted in the use of objects seen as familiar to dogs. This was conjoined with interest in how to initiate and end interactions, which was often achieved through notification systems. This paper builds upon HCI methods for unconventional users, and applies a design fiction approach to uncover key questions towards the creation of animal-to-animal interfaces.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {dog-computer interaction, design fiction, animal-computer interaction, animal internet},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300592,
author = {Cockburn, Andy and Gutwin, Carl},
title = {Anchoring Effects and Troublesome Asymmetric Transfer in Subjective Ratings},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300592},
doi = {10.1145/3290605.3300592},
abstract = {Within-subjects experiments are prone to asymmetric transfer, which confounds results interpretation. While HCI researchers routinely test asymmetric transfer in objective data, doing so for subjective data is rare. Yet literature suggests that anchoring effects should make subjective measures particularly susceptible to asymmetric transfer. We report on four analyses of NASA-TLX data from four previously published HCI papers, with four main findings. First, asymmetric transfer is common, occurring in 42% of tests analysed. Second, the data conforms to predictions of anchoring effects. Third, the magnitude of the anchor's effect correlates with the magnitude of the difference between the interface ratings -- that is, the anchor's 'pull' correlates with the anchoring stimulus. Fourth, several of the previously published findings are changed when data are reanalysed using between-subjects treatment. We urge caution when analysing within-subjects subjective measures and recommend that researchers test for and report the occurrence of asymmetric transfer.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {order effects, asymmetric transfer, nasa-tlx, subjective measures, anchoring effects},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300862,
author = {Markvicka, Eric and Wang, Guanyun and Lee, Yi-Chin and Laput, Gierad and Majidi, Carmel and Yao, Lining},
title = {ElectroDermis: Fully Untethered, Stretchable, and Highly-Customizable Electronic Bandages},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300862},
doi = {10.1145/3290605.3300862},
abstract = {Wearables have emerged as an increasingly promising interactive platform, imbuing the human body with always-available computational capabilities. This unlocks a wide range of applications, including discreet information access, health monitoring, fitness, and fashion. However, unlike previous platforms, wearable electronics require structural conformity, must be comfortable for the wearer, and should be soft, elastic, and aesthetically appealing. We envision a future where electronics can be temporarily attached to the body (like bandages or party masks), but in functional and aesthetically pleasing ways. Towards this vision, we introduce ElectroDermis, a fabrication approach that simplifies the creation of highly-functional and stretchable wearable electronics that are conformal and fully untethered by discretizing rigid circuit boards into individual components. These individual components are wired together using stretchable electrical wiring and assembled on a spandex blend fabric, to provide high functionality in a robust form-factor that is reusable. We describe our system in detail- including our fabrication parameters and its operational limits-which we hope researchers and practitioners can leverage. We describe a series of example applications that illustrate the feasibility and utility of our system. Overall, we believe ElectroDermis offers a complementary approach to wearable electronics-one that places value on the notion of impermanence (i.e., unlike tattoos and implants), better conforming to the dynamic nature of the human body.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {fabrication, spandex, wearable electronics, on-skin devices},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300916,
author = {Khamis, Mohamed and Seitz, Tobias and Mertl, Leonhard and Nguyen, Alice and Schneller, Mario and Li, Zhe},
title = {Passquerade: Improving Error Correction of Text Passwords on Mobile Devices by Using Graphic Filters for Password Masking},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300916},
doi = {10.1145/3290605.3300916},
abstract = {Entering text passwords on mobile devices is a significant challenge. Current systems either display passwords in plain text: making them visible to bystanders, or replace characters with asterisks shortly after they are typed: making editing them harder. This work presents a novel approach to mask text passwords by distorting them using graphical filters. Distorted passwords are difficult to observe by attackers because they cannot mentally reverse the distortions. Yet passwords remain readable by their owners because humans can recognize visually distorted versions of content they saw before. We present results of an online questionnaire and a user study where we compared Color-halftone, Crystallize, Blurring, and Mosaic filters to Plain text and Asterisks when 1) entering, 2) editing, and 3) shoulder surfing one-word passwords, random character passwords, and passphrases. Rigorous analysis shows that Color-halftone and Crystallize filters significantly improve editing speed, editing accuracy and observation resistance compared to current approaches.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {smartphones, human-centered security, usable security, tablets, authentication},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300914,
author = {Wong-Villacres, Marisol and Kumar, Neha and DiSalvo, Betsy},
title = {The Parenting Actor-Network of Latino Immigrants in the United States},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300914},
doi = {10.1145/3290605.3300914},
abstract = {The field of Human-Computer Interaction (HCI) has shown a growing interest in how technology might support parenting. An area that remains underexplored is the design of technology to support parents from nondominant groups in positively impacting their children's education. Drawing on Actor-Network Theory (ANT), our paper takes a sociotechnical view of low-income Latino Spanish-speaking immigrants in the U.S.---a large nondominant group---attempting to form alliances with other actors such as teachers, the broader community, and technology to exchange information that might enrich their children's education. The use of ANT allowed us to advance work on parenting in HCI by providing a deeper understanding of the reasons---including attributes embedded in technology---impacting the quality of information channels in the parental engagement network of a nondominant group. Further, our ANT analysis illuminates a discussion of challenges and opportunities for technology to intervene in the network in ways that align with all actors' needs and harness their potentialities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {parenting, actor-network theory, latino, education},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300732,
author = {Salmela, Tarja and Colley, Ashley and H\"{a}kkil\"{a}, Jonna},
title = {Together in Bed? Couples' Mobile Technology Use in Bed},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300732},
doi = {10.1145/3290605.3300732},
abstract = {In this paper, we investigate the use of mobile technology in an underexplored context, the bed that couples share. Despite large amounts of research on the impact of pre-bedtime technology use on our sleep and mental state, scant research in the HCI field focuses on the physical bed as a negotiated site of technology use by couples. This paper explores (a) the meaning of the bed accessed by mobile technology and (b) the strategies of both individual and shared technology use in bed, in the context of couple's relationships. We investigate the effects of mobile technology to couples' bed-sharing practices through in-depth interviews (n = 12) and an online survey (n = 117). We report on creative and negotiated bodily practices of mobile technology use by couples in bed, and the perceived effects on couples' verbal and physical interaction and the intimacy of the bed.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {intimacy, mobile technology, smartphones, sleep, disconnecting, couple relationships, bed, bedroom},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300673,
author = {Alzayat, Ayman and Hancock, Mark and Nacenta, Miguel A.},
title = {Quantitative Measurement of Tool Embodiment for Virtual Reality Input Alternatives},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300673},
doi = {10.1145/3290605.3300673},
abstract = {Virtual reality (VR) strives to replicate the sensation of the physical environment by mimicking people's perceptions and experience of being elsewhere. These experiences are of-ten mediated by the objects and tools we interact with in the virtual world (e.g., a controller). Evidence from psychology posits that when using the tool proficiently, it becomes em-bodied (i.e., an extension of one's body). There is little work,however, on how to measure this phenomenon in VR, andon how different types of tools and controllers can affect the experience of interaction. In this work, we leverage cognitive psychology and philosophy literature to construct the Locus-of-Attention Index (LAI), a measure of tool embodiment. We designed and conducted a study that measures readiness-to-hand and unreadiness-to-hand for three VR interaction techniques: hands, a physical tool, and a VR controller. The study shows that LAI can measure differences in embodiment with working and broken tools and that using the hand directly results in more embodiment than using controllers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {virtual reality, embodied interaction, tools, ready-to-hand, unready-to-hand},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300795,
author = {Kempe-Cook, Lucas and Sher, Stephen Tsung-Han and Su, Norman Makoto},
title = {Behind the Voices: The Practice and Challenges of Esports Casters},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300795},
doi = {10.1145/3290605.3300795},
abstract = {Casters commentate on a live, streamed video game for a large online audience. Drawing from 20 semi-structured interviews with amateur casters of either Dota 2 or Rocket League video games and over 20 hours of participant observations, we describe the distinctive practices of two types of casters, play-by-play and color commentary. Play-by-play casters are adept at improvising a rich narrative of hype on top of live games, whereas color commentators methodically prepare to fill in the gaps of live play with informative analysis. Casters often start out alone, relying upon reflective practice to hone their craft. Through examining challenges faced by amateur casters, we identified three design opportunities for game designers to support casters and would-be casters as first-class users. Such designs would provide an antidote to the challenges faced by amateur casters: those of the lack of social support for casting, camerawork, and data availability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {casting, play-by-play, video games, esports, live streaming, color commentary, commentary},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300772,
author = {Yang, Xi and Aurisicchio, Marco and Baxter, Weston},
title = {Understanding Affective Experiences with Conversational Agents},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300772},
doi = {10.1145/3290605.3300772},
abstract = {While previous studies of Conversational Agents (e.g. Siri, Google Assistant, Alexa and Cortana) have focused on evaluating usability and exploring capabilities of these systems, little work has examined users' affective experiences. In this paper we present a survey study with 171 participants to examine CA users' affective experiences. Specifically, we present four major usage scenarios, users' affective responses in these scenarios, and the factors which influenced the affective responses. We found that users' overall experience was positive with interest being the most salient positive emotion. Affective responses differed depending on the scenarios. Both pragmatic and hedonic qualities influenced affect. The factors underlying pragmatic quality are: helpfulness, proactivity, fluidity, seamlessness and responsiveness. The factors underlying hedonic quality are: comfort in human-machine conversation, pride of using cutting-edge technology, fun during use, perception of having a human-like assistant, concern about privacy and fear of causing distraction.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {emotional design, affect, positive design, conversational agents, user experience},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300299,
author = {Baumgartner, Juergen and Frei, Naomi and Kleinke, Mascha and Sauer, Juergen and Sonderegger, Andreas},
title = {Pictorial System Usability Scale (P-SUS): Developing an Instrument for Measuring Perceived Usability},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300299},
doi = {10.1145/3290605.3300299},
abstract = {We have developed a pictorial multi-item scale, called P-SUS (Pictorial System Usability Scale), which aims to measure the perceived usability of mobile devices. The scale is based on the established verbal usability questionnaire SUS (System Usability Scale). A user-centred design process was employed to develop and refine its 10 pictorial items. The scale was tested in a first validation study (N=60) using student participants. Psychometric properties (convergent validity, criterion-related validity, sensitivity, and reliability), as well as the motivation to fill in the scale were assessed. The results indicated satisfactory convergent validity for about two-thirds of the items. Furthermore, strong correlations were obtained for the sum scores between verbal and pictorial SUS, and the pictorial scale was perceived as more motivating than the verbal questionnaire. The P-SUS represents a first attempt to provide a pictorial usability scale for the evaluation of (mobile) devices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {perceived usability, pictorial scale, consumer product, mobile device evaluation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300688,
author = {Gui, Xinning and Chen, Yunan},
title = {Making Healthcare Infrastructure Work: Unpacking the Infrastructuring Work of Individuals},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300688},
doi = {10.1145/3290605.3300688},
abstract = {The U.S. healthcare infrastructure is fragmented with various breakdowns. Patients or caregivers have to rely on their own to overcome barriers and fix breakdowns in order to obtain necessary service, that is, infrastructuring work to make the healthcare infrastructure work for them. So far little attention has been paid to such infrastructuring work in healthcare. We present an interview study of 32 U.S. parents of young children to discuss the work of infrastructuring our participants carry out to deal with breakdowns within the healthcare infrastructure. We report how they repaired unexpected failures happening at the individual level, aligned components at organizational and cross-organizational level, and circumvented infrastructural constraints (e.g., policy and financial ones) that were perceived as ambiguous and demanding. We discuss infrastructuring work in light of the literature on patients' and caregivers' work, reflect upon the notion of patient engagement, and explore nuances along several dimensions of infrastructuring work.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {infrastructuring work, healthcare infrastructure, patients and caregivers, patient work, new parents, healthcare consumers},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300386,
author = {Leen, Danny and Veuskens, Tom and Luyten, Kris and Ramakers, Raf},
title = {JigFab: Computational Fabrication of Constraints to Facilitate Woodworking with Power Tools},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300386},
doi = {10.1145/3290605.3300386},
abstract = {We present JigFab, an integrated end-to-end system that supports casual makers in designing and fabricating constructions with power tools. Starting from a digital version of the construction, JigFab achieves this by generating various types of constraints that configure and physically aid the movement of a power tool. Constraints are generated for every operation and are custom to the work piece. Constraints are laser cut and assembled together with predefined parts to reduce waste. JigFab's constraints are used according to an interactive step-by-step manual. JigFab internalizes all the required domain knowledge for designing and building intricate structures, consisting of various types of finger joints, tenon &amp; mortise joints, grooves, and dowels. Building such structures is normally reserved for artisans or automated with advanced CNC machinery.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {computational fabrication, cad, wood working},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300603,
author = {Gordon, Mitchell L. and Zhai, Shumin},
title = {Touchscreen Haptic Augmentation Effects on Tapping, Drag and Drop, and Path Following},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300603},
doi = {10.1145/3290605.3300603},
abstract = {We study the effects of haptic augmentation on tapping, path following, and drag &amp; drop tasks based on a recent flagship smartphone with refined touch sensing and haptic actuator technologies. Results show actuated haptic confirmation on tapping targets was subjectively appreciated by some users but did not improve tapping speed or accuracy. For drag &amp; drop, a clear performance improvement was measured when haptic feedback is applied to target boundary crossing, particularly when the targets are small. For path following tasks, virtual haptic feedback improved accuracy at a reduced speed in a sitting condition. Stronger results were achieved in a physical haptic mock-up. Overall, we found actuated touchscreen haptic feedback particularly effective when the touched object was visually interfered by the finger. Participants subjective experience of haptic feedback in all tasks tended to be more positive than their time or accuracy performance suggests. We compare and discuss these findings with previous results on early generations of devices. The work provides an empirical foundation to product design and future research of touch input and haptic systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {empirical study, haptics, mobile devices: phones/tablets},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300352,
author = {Bellini, Rosanna and Strohmayer, Angelika and Olivier, Patrick and Crivellaro, Clara},
title = {Mapping the Margins: Navigating the Ecologies of Domestic Violence Service Provision},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300352},
doi = {10.1145/3290605.3300352},
abstract = {Work addressing the negative impacts of domestic violence on victim-survivors and service providers has slowly been contributing to the HCI discourse. However, work discussing the necessary, pre-emptive steps for researchers to enter these spaces sensitively and considerately, largely remains opaque. Heavily-politicised specialisms that are imbued with conflicting values and practices, such as domestic violence service delivery can be especially difficult to navigate. In this paper, we report on a mixed methods study consisting of interviews, a design dialogue and an ideation workshop with domestic violence service providers to explore the potential of an online service directory to support their work. Through this three-stage research process, we were able to characterise this unique service delivery landscape and identify tensions in services' access, understandings of technologies and working practices. Drawing from our findings, we discuss opportunities for researchers to work with and sustain complex information ecologies in sensitive settings.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {civic technology, public service mapping, design approaches, domestic violence},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300777,
author = {Kulp, Leah and Sarcevic, Aleksandra and Cheng, Megan and Zheng, Yinan and Burd, Randall S.},
title = {Comparing the Effects of Paper and Digital Checklists on Team Performance in Time-Critical Work},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300777},
doi = {10.1145/3290605.3300777},
abstract = {This mixed-methods study examines the effects of a tablet-based checklist system on team performance during a dynamic and safety-critical process of trauma resuscitation. We compared team performance from 47 resuscitations that used a paper checklist to that from 47 cases with a digital checklist to determine if digitizing a checklist led to improvements in task completion rates and in how fast the tasks were initiated for 18 most critical assessment and treatment tasks. We also compared if the checklist compliance increased with the digital design. We found that using the digital checklist led to more frequent completions of the initial airway assessment task but fewer completions of ear and lower extremities exams. We did not observe any significant differences in time to task performance, but found increased compliance with the checklist. Although improvements in team performance with the digital checklist were minor, our findings are important because they showed no adverse effects as a result of the digital checklist introduction. We conclude by discussing the takeaways and implications of these results for effective digitization of medical work.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {medical records, team performance, technology implementation, user interface design, trauma resuscitation, digital checklist},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300659,
author = {Reusser, Dorothea and Knoop, Espen and Siegwart, Roland and Beardsley, Paul},
title = {Feeling Fireworks: An Inclusive Tactile Firework Display},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300659},
doi = {10.1145/3290605.3300659},
abstract = {This paper presents a novel design for a large-scale interactive tactile display. Fast dynamic tactile effects are created at high spatial resolution on a flexible screen, using directable nozzles that spray water jets onto the rear of the screen. The screen further has back-projected visual content and touch interaction. The technology is demonstrated in Feeling Fireworks, a tactile firework show. The goal is to make fireworks more inclusive for the Blind and Low-Vision (BLV) community. A BLV focus group provided input during the development process, and a user study with BLV users showed that Feeling Fireworks is an enjoyable and meaningful experience. A user study with sighted users showed that users could accurately label the correspondence between the designed tactile firework effects and corresponding visual fireworks. Beyond the Feeling Fireworks application, this is a novel approach for scalable tactile displays with potential for broader use.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {haptic device, accessibility, large interactive screen},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300642,
author = {Raza, Agha Ali and Tariq, Zain and Randhawa, Shan and Saleem, Bilal and Athar, Awais and Saif, Umar and Rosenfeld, Roni},
title = {Voice-Based Quizzes for Measuring Knowledge Retention in Under-Connected Populations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300642},
doi = {10.1145/3290605.3300642},
abstract = {Information dissemination using automated phone calls allows reaching low-literate and tech-naive populations. Open challenges include rapid verification of expected knowledge gaps in the community, dissemination of specific information to address these gaps, and follow-up measurement of knowledge retention. We report Sawaal, a voice-based telephone service that uses audio-quizzes to address these challenges. Sawaal allows its open community of users to post and attempt multiple-choice questions and to vote and comment on them. Sawaal spreads virally as users challenge friends to quiz competitions. Administrator-posted questions allow confirming specific knowledge gaps, spreading correct information and measuring knowledge retention via rephrased, repeated questions. In 14 weeks and with no advertisement, Sawaal reached 3,433 users (120,119 calls) in Pakistan, who contributed 13,276 questions that were attempted 455,158 times by 2,027 users. Knowledge retention remained significant for up to two weeks. Surveys revealed that 71% of the mostly low-literate, young, male users were blind.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {knowledge impact, hci4d, non-literate, ivr, low-literate, interactive voice response, impact evaluation, blind, learning, mobile phone, ict4d},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300427,
author = {Shi, Lei and Lawson, Holly and Zhang, Zhuohao and Azenkot, Shiri},
title = {Designing Interactive 3D Printed Models with Teachers of the Visually Impaired},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300427},
doi = {10.1145/3290605.3300427},
abstract = {Students with visual impairments struggle to learn various concepts in the academic curriculum because diagrams, images, and other visual are not accessible to them. To address this, researchers have design interactive 3D printed models (I3Ms) that provide audio descriptions when a user touches components of a model. In prior work, I3Ms were designed on an ad hoc basis, and it is currently unknown what general guidelines produce effective I3M designs. To address this gap, we conducted two studies with Teachers of the Visually Impaired (TVIs). First, we led two design workshops with 35 TVIs, who modified sample models and added interactive elements to them. Second, we worked with three TVIs to design three I3Ms in an iterative instructional design process. At the end of this process, the TVIs used the I3Ms we designed to teach their students. We conclude that I3Ms should (1) have effective tactile features (e.g., distinctive patterns between components), (2) contain both auditory and visual content (e.g., explanatory animations), and (3) consider pedagogical methods (e.g., overview before details).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interactive 3d printed models, user-centered design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300863,
author = {Koch, Janin and Lucero, Andr\'{e}s and Hegemann, Lena and Oulasvirta, Antti},
title = {May AI? Design Ideation with Cooperative Contextual Bandits},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300863},
doi = {10.1145/3290605.3300863},
abstract = {Design ideation is a prime creative activity in design. However, it is challenging to support computationally due to its quickly evolving and exploratory nature. The paper presents cooperative contextual bandits (CCB) as a machine-learning method for interactive ideation support. A CCB can learn to propose domain-relevant contributions and adapt their exploration/exploitation strategy. We developed a CCB for an interactive design ideation tool that 1) suggests inspirational and situationally relevant materials ("may AI?"); 2) explores and exploits inspirational materials with the designer; and 3) explains its suggestions to aid reflection. The application case of digital mood board design is presented, wherein visual inspirational materials are collected and curated in collages. In a controlled study, 14 of 16 professional designers preferred the CCB-augmented tool. The CCB approach holds promise for ideation activities wherein adaptive and steerable support is welcome but designers must retain full outcome control.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mood board design, ideation support, interactive machine-learning, creativity support tools},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300858,
author = {Yamaoka, Junichi and Dogan, Mustafa Doga and Bulovic, Katarina and Saito, Kazuya and Kawahara, Yoshihiro and Kakehi, Yasuaki and Mueller, Stefanie},
title = {FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300858},
doi = {10.1145/3290605.3300858},
abstract = {We present FoldTronics, a 2D-cutting based fabrication technique to integrate electronics into 3D folded objects. The key idea is to cut and perforate a 2D sheet to make it foldable into a honeycomb structure using a cutting plotter; before folding the sheet into a 3D structure, users place the electronic components and circuitry onto the sheet. The fabrication process only takes a few minutes allowing to rapidly prototype functional interactive devices. The resulting objects are lightweight and rigid, thus allowing for weight-sensitive and force-sensitive applications. Finally, due to the nature of the honeycomb structure, the objects can be folded flat along one axis and thus can be efficiently transported in this compact form factor. We describe the structure of the foldable sheet, and present a design tool that enables users to quickly prototype the desired objects. We showcase a range of examples made with our design tool, including objects with integrated sensors and display elements.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {electronics, personal fabrication, 2d folding},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300927,
author = {Kim, Jaejeung and Park, Joonyoung and Lee, Hyunsoo and Ko, Minsam and Lee, Uichin},
title = {LocknType: Lockout Task Intervention for Discouraging Smartphone App Use},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300927},
doi = {10.1145/3290605.3300927},
abstract = {Instant access and gratification make it difficult for us to self-limit the use of smartphone apps. We hypothesize that a slight increase in the interaction cost of accessing an app could successfully discourage app use. We propose a proactive intervention that requests users to perform a simple lockout task (e.g., typing a fixed length number) whenever a target app is launched. We investigate how a lockout task with varying workloads (i.e., pause only without number input, 10-digit input, and 30-digit input) influence a user's decision making, by a 3-week, in-situ experiment with 40 participants. Our findings show that even the pause-only task that requires a user to press a button to proceed discouraged an average of 13.1% of app use, and the 30-digit-input task discouraged 47.5%. We derived determinants of app use and non-use decision making for a given lockout task. We further provide implications for persuasive technology design for discouraging undesired behaviors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interaction restraint, smartphone overuse, intervention design, lockout task},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300451,
author = {Berkovsky, Shlomo and Taib, Ronnie and Koprinska, Irena and Wang, Eileen and Zeng, Yucheng and Li, Jingjie and Kleitman, Sabina},
title = {Detecting Personality Traits Using Eye-Tracking Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300451},
doi = {10.1145/3290605.3300451},
abstract = {Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans' physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {personality detection, field study, eye tracking, framework},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300262,
author = {Mason, Liam and Gerling, Kathrin and Dickinson, Patrick and De Angeli, Antonella},
title = {Design Goals for Playful Technology to Support Physical Activity Among Wheelchair Users},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300262},
doi = {10.1145/3290605.3300262},
abstract = {Playful technology has the potential to support physical activity (PA) among wheelchair users, but little is known about design considerations for this audience, who experience significant access barriers. In this paper, we lever-age the Integrated Behavioural Model (IBM) to understand wheelchair users' perspectives on PA, technology, and play.First, we present findings from an interview study with eight physically active wheelchair users. Second, we build on the interviews in a survey that received 44 responses from a broader group of wheelchair users. Results show that the anticipation of positive experiences was the strongest predictor of engagement with PA, and that accessibility concerns act as barriers both in terms of PA participation and technology use. We present four design goals - emphasizing enjoyment,involving others, building knowledge and enabling flexibility - to make our findings actionable for researchers and designers wishing to create accessible playful technology to support PA.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {integrated behavioral model, accessibility, wheelchair, games},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300320,
author = {Candello, Heloisa and Pinhanez, Claudio and Pichiliani, Mauro and Cavalin, Paulo and Figueiredo, Flavio and Vasconcelos, Marisa and Do Carmo, Haylla},
title = {The Effect of Audiences on the User Experience with Conversational Interfaces in Physical Spaces},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300320},
doi = {10.1145/3290605.3300320},
abstract = {How does the presence of an audience influence the social interaction with a conversational system in a physical space? To answer this question, we analyzed data from an art exhibit where visitors interacted in natural language with three chatbots representing characters from a book. We performed two studies to explore the influence of audiences. In Study 1, we did fieldwork cross-analyzing the reported perception of the social interaction, the audience conditions (visitor is alone, visitor is observed by acquaintances and/or strangers), and control variables such as the visitor's familiarity with the book and gender. In Study 2, we analyzed over 5,000 conversation logs and video recordings, identifying dialogue patterns and how they correlated with the audience conditions. Some significant effects were found, suggesting that conversational systems in physical spaces should be designed based on whether other people observe the user or not.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {audience effects, chatbot design, conversational interfaces},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300270,
author = {Braun, Michael and Mainz, Anja and Chadowitz, Ronee and Pfleging, Bastian and Alt, Florian},
title = {At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300270},
doi = {10.1145/3290605.3300270},
abstract = {This paper investigates personalized voice characters for in-car speech interfaces. In particular, we report on how we designed different personalities for voice assistants and compared them in a real world driving study. Voice assistants have become important for a wide range of use cases, yet current interfaces are using the same style of auditory response in every situation, despite varying user needs and personalities. To close this gap, we designed four assistant personalities (Friend, Admirer, Aunt, and Butler) and compared them to a baseline (Default) in a between-subject study in real traffic conditions. Our results show higher likability and trust for assistants that correctly match the user's personality while we observed lower likability, trust, satisfaction, and usefulness for incorrectly matched personalities, each in comparison with the Default character. We discuss design aspects for voice assistants in different automotive use cases.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {voice assistant, personalization, personality, automotive ui},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300908,
author = {Altarriba Bertran, Ferran and Jhaveri, Samvid and Lutz, Rosa and Isbister, Katherine and Wilde, Danielle},
title = {Making Sense of Human-Food Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300908},
doi = {10.1145/3290605.3300908},
abstract = {Activity in Human-Food Interaction (HFI) research is skyrocketing across a broad range of disciplinary interests and concerns. The dynamic and heterogeneous nature of this emerging field presents a challenge to scholars wishing to critically engage with prior work, identify gaps and ensure impact. It also challenges the formation of community. We present a Systematic Mapping Study of HFI research and an online data visualisation tool developed to respond to these issues. The tool allows researchers to engage in new ways with the HFI literature, propose modifications and additions to the review, and thereby actively engage in community-making. Our contribution is threefold: (1) we characterize the state of HFI, reporting trends, challenges and opportunities; (2) we provide a taxonomy and tool for diffractive reading of the literature; and (3) we offer our approach for adaptation by research fields facing similar challenges, positing value of the tool and approach beyond HFI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {literature review, scientific mapping tools, human-food interaction, data visualization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300733,
author = {Caraban, Ana and Karapanos, Evangelos and Gon\c{c}alves, Daniel and Campos, Pedro},
title = {23 Ways to Nudge: A Review of Technology-Mediated Nudging in Human-Computer Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300733},
doi = {10.1145/3290605.3300733},
abstract = {Ten years ago, Thaler and Sunstein introduced the notion of nudging to talk about how subtle changes in the 'choice architecture' can alter people's behaviors in predictable ways. This idea was eagerly adopted in HCI and applied in multiple contexts, including health, sustainability and privacy. Despite this, we still lack an understanding of how to design effective technology-mediated nudges. In this paper we present a systematic review of the use of nudging in HCI research with the goal of laying out the design space of technology-mediated nudging - the why (i.e., which cognitive biases do nudges combat) and the how (i.e., what exact mechanisms do nudges employ to incur behavior change). All in all, we found 23 distinct mechanisms of nudging, grouped in 6 categories, and leveraging 15 different cognitive biases. We present these as a framework for technology-mediated nudging, and discuss the factors shaping nudges' effectiveness and their ethical implications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {behavioral economics, persuasive technology, nudging},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300313,
author = {Tian, Feng and Fan, Xiangmin and Fan, Junjun and Zhu, Yicheng and Gao, Jing and Wang, Dakuo and Bi, Xiaojun and Wang, Hongan},
title = {What Can Gestures Tell? Detecting Motor Impairment in Early Parkinson's from Common Touch Gestural Interactions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300313},
doi = {10.1145/3290605.3300313},
abstract = {Parkinson's disease (PD) is a chronic neurological disorder causing progressive disability that severely affects patients' quality of life. Although early interventions can provide significant benefits, PD diagnosis is often delayed due to both the mildness of early signs and the high requirements imposed by traditional screening and diagnosis methods. In this paper, we explore the feasibility and accuracy of detecting motor impairment in early PD via sensing and analyzing users' common touch gestural interactions on smartphones. We investigate four types of common gestures, including flick, drag, pinch, and handwriting gestures, and propose a set of features to capture PD motor signs. Through a 102-subject (35 early PD subjects and 67 age-matched controls) study, our approach achieved an AUC of 0.95 and 0.89/0.88 sensitivity/specificity in discriminating early PD subjects from healthy controls. Our work constitutes an important step towards unobtrusive, implicit, and convenient early PD detection from routine smartphone interactions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {touch gestures, passive monitoring, parkinson's disease (pd)},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300881,
author = {Pater, Jessica A. and Reining, Lauren E. and Miller, Andrew D. and Toscos, Tammy and Mynatt, Elizabeth D.},
title = {"Notjustgirls": Exploring Male-Related Eating Disordered Content across Social Media Platforms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300881},
doi = {10.1145/3290605.3300881},
abstract = {Eating disorders (EDs) are a worldwide public health concern that impact approximately 10% of the U.S. population. Our previous research characterized these behaviors across online spaces. These characterizations have used clinical terminology, and their lexical variants, to identify ED content online. However, previous HCI research on EDs (including our own) suffers from a lack of gender and cultural diversity. In this paper, we designed a follow-up study of online ED characterizations, extending our previous methodologies to focus specifically on male/masculine-related content. We highlight the similarities and differences found in the terminology utilized and media archetypes associated with the social media content. Finally, we discuss other considerations highlighted through our analysis of the male-related content that is missing from the previous research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {eating disorder, tumblr, manorexia, bigorexia, gender, twitter, social media, instagram, bulimia, male, anorexia},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300488,
author = {Cho, Eugene},
title = {Hey Google, Can I Ask You Something in Private?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300488},
doi = {10.1145/3290605.3300488},
abstract = {MModern day voice-activated virtual assistants allow users to share and ask for information that could be considered as personal through different input modalities and devices. Using Google Assistant, this study examined if the differences in modality (i.e., voice vs. text) and device (i.e., smartphone vs. smart home device) affect user perceptions when users attempt to retrieve sensitive health information from voice assistants. Major findings from this study suggest that voice (vs. text) interaction significantly enhanced perceived social presence of the voice assistant, but only when the users solicited less sensitive health-related information. Furthermore, when individuals reported less privacy concerns, voice (vs. text) interaction elicited positive attitudes toward the voice assistant via increased social presence, but only in the low (vs. high) information sensitivity condition. Contrary to modality, the device difference did not exert any significant impact on the attitudes toward the voice assistant regardless of the sensitivity level of the health information being asked or the level of individuals' privacy concerns.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {modality, virtual assistant(s), information sensitivity, conversational agent(s), social presence, voice assistant(s), privacy concerns},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300245,
author = {Iravantchi, Yasha and Goel, Mayank and Harrison, Chris},
title = {BeamBand: Hand Gesture Sensing with Ultrasonic Beamforming},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300245},
doi = {10.1145/3290605.3300245},
abstract = {BeamBand is a wrist-worn system that uses ultrasonic beamforming for hand gesture sensing. Using an array of small transducers, arranged on the wrist, we can ensem-ble acoustic wavefronts to project acoustic energy at spec-ified angles and focal lengths. This allows us to interro-gate the surface geometry of the hand with inaudible sound in a raster-scan-like manner, from multiple view-points. We use the resulting, characteristic reflections to recognize hand pose at 8 FPS. In our user study, we found that BeamBand supports a six-class hand gesture set at 94.6% accuracy. Even across sessions, when the sensor is removed and reworn later, accuracy remains high: 89.4%. We describe our software and hardware, and future ave-nues for integration into devices such as smartwatches and VR controllers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {acoustic reflectrometry, acoustic beamforming, hand input, hand gesture, wearables, acoustic, interaction techniques},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300232,
author = {Sambasivan, Nithya and Batool, Amna and Ahmed, Nova and Matthews, Tara and Thomas, Kurt and Gayt\'{a}n-Lugo, Laura Sanely and Nemer, David and Bursztein, Elie and Churchill, Elizabeth and Consolvo, Sunny},
title = {"They Don't Leave Us Alone Anywhere We Go": Gender and Digital Abuse in South Asia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300232},
doi = {10.1145/3290605.3300232},
abstract = {South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women's safety online in South Asia.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {privacy, leakages, pakistan, bangladesh, stalking, impersonation, coping, women, impacts, india, online abuse},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300233,
author = {Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N. and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric},
title = {Guidelines for Human-AI Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300233},
doi = {10.1145/3290605.3300233},
abstract = {Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ai-infused systems, design guidelines, human-ai interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300894,
author = {Dema, Tshering and Brereton, Margot and Roe, Paul},
title = {Designing Participatory Sensing with Remote Communities to Conserve Endangered Species},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300894},
doi = {10.1145/3290605.3300894},
abstract = {The increasing loss of species globally calls for effective monitoring tools and strategies to inform conservation action. The dominant approach to citizens engagement has been smart phone and platform-centric, tasking crowds to collect and analyze data. However, many critically endangered species inhabit remote areas, characterized by sparsely populated communities with poor internet connectivity. Approaches need to garner high engagement relative to population size, with data collection and knowledge synthesis suited to the local context. We conducted a field study in remote communities to understand how to enhance conservation of Bhutan's critically endangered White-bellied heron by exploring existing monitoring practices and trialing acoustic sensing technologies. We found that knowledge about the species is partial, heterogeneous, situated within and across communities and rooted in cultural beliefs. Sensors, acoustic interfaces, and playful probes provided new ways for the community to 'see' and discuss their local environment fostering them to share and grow their knowledge together. We contribute a synthesis of key considerations for designing effective participatory sensing to conserve species in remote communities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {remote communities, conservation technologies, participatory sensing, endangered species, social computing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300437,
author = {Barrera Machuca, Mayra Donaji and Stuerzlinger, Wolfgang},
title = {The Effect of Stereo Display Deficiencies on Virtual Hand Pointing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300437},
doi = {10.1145/3290605.3300437},
abstract = {The limitations of stereo display systems affect depth perception, e.g., due to the vergence-accommodation conflict or diplopia. We performed three studies to understand how stereo display deficiencies impact 3D pointing for targets in front of a screen and close to the user, i.e., in peripersonal space. Our first two experiments compare movements with and without a change in visual depth for virtual respectively physical targets. Results indicate that selecting targets along the depth axis is slower and has less throughput for virtual targets, while physical pointing demonstrates the opposite result. We then propose a new 3D extension for Fitts' law that models the effect of stereo display deficiencies. Next, our third experiment verifies the model and measures more broadly how the change in visual depth between targets affects pointing performance in peripersonal space and confirms significant effects on time and throughput. Finally, we discuss implications for 3D user interface design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {selection, fitt's law, cursor, 3d pointing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300805,
author = {Chen, Fanglin and Xia, Kewei and Dhabalia, Karan and Hong, Jason I.},
title = {MessageOnTap: A Suggestive Interface to Facilitate Messaging-Related Tasks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300805},
doi = {10.1145/3290605.3300805},
abstract = {Text messages are sometimes prompts that lead to information related tasks, e.g. checking one's schedule, creating reminders, or sharing content. We introduce MessageOnTap, a suggestive inter-face for smartphones that uses the text in a conversation to suggest task shortcuts that can streamline likely next actions. When activated, MessageOnTap uses word embeddings to rank relevant external apps, and parameterizes associated task shortcuts using key phrases mentioned in the conversation, such as times, persons, or events. MessageOnTap also tailors the auto-complete dictionary based on text in the conversation, to streamline any text input.We first conducted a month-long study of messaging behaviors(N=22) that informed our design. We then conducted a lab study to evaluate the effectiveness of MessageOnTap's suggestive interface, and found that participants can complete tasks 3.1x faster withMessageOnTap than their typical task flow.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {messaging/communication, information seeking &amp; search, text/speech/language, productivity, contextual computing, personal data/tracking, user experience design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300329,
author = {Ismail, Azra and Kumar, Neha},
title = {Empowerment on the Margins: The Online Experiences of Community Health Workers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300329},
doi = {10.1145/3290605.3300329},
abstract = {Research in Human-Computer Interaction for Development (HCI4D) routinely relies on and engages with the increasing penetration of smartphones and the internet. We examine the mobile, internet, and social media practices of women community health workers, for whom internet access has newly become possible. These workers are uniquely positioned at the intersections of various communities of practice---their familial units, workplaces, networks of health workers, larger communities, and the online world. However, they remain at the margins of each, on account of difference in gender, class, literacies, professional expertise, and more. Our findings unpack the legitimate peripheral participation of these workers; examining how they appropriate smartphones and the internet to move away from the peripheries to fully participate in these communities. We discuss how their activities are motivated by moves towards empowerment, digitization, and improved healthcare provision. We consider how future work might support, leverage, and extend their efforts.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {healthcare, india, ictd, internet, qualitative, hci4d},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300817,
author = {Bhattacharya, Arpita and Windleharth, Travis W. and Ishii, Rio Anthony and Acevedo, Ivy M. and Aragon, Cecilia R. and Kientz, Julie A. and Yip, Jason C. and Lee, Jin Ha},
title = {Group Interactions in Location-Based Gaming: A Case Study of Raiding in Pok\'{e}Mon GO},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300817},
doi = {10.1145/3290605.3300817},
abstract = {Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the location-based mobile game Pok\'{e}mon GO, which offers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pok\'{e}mon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social affordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {raiding, mixed reality game, location based game, groups},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300243,
author = {Surale, Hemant Bhaskar and Gupta, Aakar and Hancock, Mark and Vogel, Daniel},
title = {TabletInVR: Exploring the Design Space for Using a Multi-Touch Tablet in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300243},
doi = {10.1145/3290605.3300243},
abstract = {Complex virtual reality (VR) tasks, like 3D solid modelling, are challenging with standard input controllers. We propose exploiting the affordances and input capabilities when using a 3D-tracked multi-touch tablet in an immersive VR environment. Observations gained during semi-structured interviews with general users, and those experienced with 3D software, are used to define a set of design dimensions and guidelines. These are used to develop a vocabulary of interaction techniques to demonstrate how a tablet's precise touch input capability, physical shape, metaphorical associations, and natural compatibility with barehand mid-air input can be used in VR. For example, transforming objects with touch input, "cutting" objects by using the tablet as a physical "knife", navigating in 3D by using the tablet as a viewport, and triggering commands by interleaving bare-hand input around the tablet. Key aspects of the vocabulary are evaluated with users, with results validating the approach.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interaction techniques, touch interaction, virtual reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300428,
author = {Yao, Yaxing and Basdeo, Justin Reed and Kaushik, Smirity and Wang, Yang},
title = {Defending My Castle: A Co-Design Study of Privacy Mechanisms for Smart Homes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300428},
doi = {10.1145/3290605.3300428},
abstract = {Home is a person's castle, a private and protected space. Internet-connected devices such as locks, cameras, and speakers might make a home "smarter" but also raise privacy issues because these devices may constantly and inconspicuously collect, infer or even share information about people in the home. To explore user-centered privacy designs for smart homes, we conducted a co-design study in which we worked closely with diverse groups of participants in creating new designs. This study helps fill the gap in the literature between studying users' privacy concerns and designing privacy tools only by experts. Our participants' privacy designs often relied on simple strategies, such as data localization, disconnection from the Internet, and a private mode. From these designs, we identified six key design factors: data transparency and control, security, safety, usability and user experience, system intelligence, and system modality. We discuss how these factors can guide design for smart home privacy.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {internet of things, co-design, smart home, privacy},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300583,
author = {Sannon, Shruti and Murnane, Elizabeth L. and Bazarova, Natalya N. and Gay, Geri},
title = {"I Was Really, Really Nervous Posting It": Communicating about Invisible Chronic Illnesses across Social Media Platforms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300583},
doi = {10.1145/3290605.3300583},
abstract = {People with invisible chronic illnesses (ICIs) can use social media to seek both informational and emotional support, but these individuals also face social and health-related challenges in posting about their often-stigmatized conditions online. To understand how they evaluate different platforms for disclosure, we interviewed 19 people with ICIs who post on general social media about their illnesses, such as Facebook, Instagram, and Twitter. We present a cross-platform analysis of how platforms varied in their suitability to achieve participants' goals, as well as the challenges posed by each platform. We also found that as participants' ICIs progressed, their goals, challenges, and social media use similarly evolved over time. Our findings highlight how people with ICIs select platforms from a broader ecology of social media and suggest a general need to understand shifts in social media use for populations with chronic but changing health concerns.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social media, health, invisible chronic illness, media ecology},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300548,
author = {Vermette, Laton and McGrenere, Joanna and Birge, Colin and Kelly, Adam and Chilana, Parmit K.},
title = {Freedom to Personalize My Digital Classroom: Understanding Teachers' Practices and Motivations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300548},
doi = {10.1145/3290605.3300548},
abstract = {Although modern classrooms are increasingly moving towards digital immersion and personalized learning, we have few insights into K-12 teachers' current practices, motivations, and barriers in setting up their digital classroom ecosystems. We interviewed 20 teachers on their process of discovering and integrating a vast range of productivity software and educational platforms in their classrooms, with a particular focus on how they personalize the UI and content of these tools (e.g., with plugins, templates, or option menus). We found that teachers largely depended on their own experimentation and professional circles to find, personalize, and troubleshoot software tools to support student needs or their own preferences. Teachers were often hesitant to attempt more advanced personalizations due to concerns over student confusion and increased troubleshooting load. We derive several design implications for HCI to better support teachers in sharing their personalized setups and helping their students benefit from digital immersion.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {personalization, educational technology, digital classroom tools},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300502,
author = {Khan, Md. Nafiz Hasan and Neustaedter, Carman},
title = {An Exploratory Study of the Use of Drones for Assisting Firefighters During Emergency Situations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300502},
doi = {10.1145/3290605.3300502},
abstract = {In the near future, emergency services within Canada will be supporting new technologies for 9-1-1 call centres and firefighters to learn about an emergency situation. One such technology is drones. To understand the benefits and challenges of using drones within emergency response, we conducted a study with citizens who have called 9-1-1 and firefighters who respond to a range of everyday emergencies. Our results show that drones have numerous benefits to both firefighters and 9-1-1 callers which include context awareness and social support for callers who receive feelings of assurance that help is on the way. Privacy was largely not an issue, though safety issues arose especially for complex uses of drones such as indoor flying. Our results point to opportunities for designing drone systems that help people to develop a sense of trust with emergency response drones, and mitigate privacy and safety concerns with more complex drone systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {emergency calling, drone, firefighters, surveillance},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300390,
author = {Wohn, Donghee Yvette},
title = {Volunteer Moderators in Twitch Micro Communities: How They Get Involved, the Roles They Play, and the Emotional Labor They Experience},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300390},
doi = {10.1145/3290605.3300390},
abstract = {The ability to engage in real-time text conversations is an important feature on live streaming platforms. The moderation of this text content relies heavily on the work of unpaid volunteers. This study reports on interviews with 20 people who moderate for Twitch micro communities, defined as channels that are built around a single or group of streamers, rather than the broadcast of an event. The study identifies how people become moderators, their different styles of moderating, and the difficulties that come with the job. In addition to the hardships of dealing with negative content, moderators also have complex interpersonal relationships with the streamers and viewers, where the boundaries between emotional labor, physical labor, and fun are intertwined.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online harassment, live streaming, qualitative, online community, moderation, twitch},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300315,
author = {Ogbonnaya-Ogburu, Ihudiya Finda and Toyama, Kentaro and Dillahunt, Tawanna R.},
title = {Towards an Effective Digital Literacy Intervention to Assist Returning Citizens with Job Search},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300315},
doi = {10.1145/3290605.3300315},
abstract = {Returning citizens (formerly incarcerated individuals) face great challenges finding employment, and these are exacerbated by the need for digital literacy in modern job search. Through 23 semi-structured interviews and a pilot digital literacy course with returning citizens in the Greater Detroit area, we explore tactics and needs with respect to job search and digital technology. Returning citizens exhibit great diversity, but overall, we find our participants to have striking gaps in digital literacy upon release, even as they are quickly introduced to smartphones by friends and family. They tend to have employable skills and ability to use offline social networks to find opportunities, but have little understanding of formal job search processes, online or offline. They mostly mirror mainstream use of mobile technology, but they have various reasons to avoid social media. These and other findings lead to recommendations for digital literacy programs for returning citizens.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {employment, digital literacy, returning citizen, formerly incarcerated},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300821,
author = {Vertanen, Keith and Gaines, Dylan and Fletcher, Crystal and Stanage, Alex M. and Watling, Robbie and Kristensson, Per Ola},
title = {VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300821},
doi = {10.1145/3290605.3300821},
abstract = {Virtual keyboard typing is typically aided by an auto-correct method that decodes a user's noisy taps into their intended text. This decoding process can reduce error rates and possibly increase entry rates by allowing users to type faster but less precisely. However, virtual keyboard decoders sometimes make mistakes that change a user's desired word into another. This is particularly problematic for challenging text such as proper names. We investigate whether users can guess words that are likely to cause auto-correct problems and whether users can adjust their behavior to assist the decoder. We conduct computational experiments to decide what predictions to offer in a virtual keyboard and design a smartwatch keyboard named VelociWatch. Novice users were able to use the features of VelociWatch to enter challenging text at 17 words-per-minute with a corrected error rate of 3%. Interestingly, they wrote slightly faster and just as accurately on a simpler keyboard with limited correction options. Our finding suggest users may be able to type difficult words on a smartwatch simply by tapping precisely without the use of auto-correct.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {decoder, smartwatch, virtual keyboard, text entry},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300556,
author = {Gallego Casc\'{o}n, Pablo and Matthies, Denys J.C. and Muthukumarana, Sachith and Nanayakkara, Suranga},
title = {ChewIt. An Intraoral Interface for Discreet Interactions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300556},
doi = {10.1145/3290605.3300556},
abstract = {Sensing interfaces relying on head or facial gestures provide effective solutions for hands-free scenarios. Most of these interfaces utilize sensors attached to the face, as well as into the mouth, being either obtrusive or limited in input bandwidth. In this paper, we propose ChewIt -- a novel intraoral input interface. ChewIt resembles an edible object that allows users to perform various hands-free input operations, both simply and discreetly. Our design is informed by a series of studies investigating the implications of shape, size, locations for comfort, discreetness, maneuverability, and obstructiveness. Additionally, we evaluated potential gestures that users could use to interact with such an intraoral interface.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {input device, reflexive interaction, hands-free, intraoral interface, discreet interaction, interaction modality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300568,
author = {Laput, Gierad and Harrison, Chris},
title = {Sensing Fine-Grained Hand Activity with Smartwatches},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300568},
doi = {10.1145/3290605.3300568},
abstract = {Capturing fine-grained hand activity could make computational experiences more powerful and contextually aware. Indeed, philosopher Immanuel Kant argued, "the hand is the visible part of the brain." However, most prior work has focused on detecting whole-body activities, such as walking, running and bicycling. In this work, we explore the feasibility of sensing hand activities from commodity smartwatches, which are the most practical vehicle for achieving this vision. Our investigations started with a 50 participant, in-the-wild study, which captured hand activity labels over nearly 1000 worn hours. We then studied this data to scope our research goals and inform our technical approach. We conclude with a second, in-lab study that evaluates our classification stack, demonstrating 95.2% accuracy across 25 hand activities. Our work highlights an underutilized, yet highly complementary contextual channel that could unlock a wide range of promising applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {bio-acoustics, activity recognition, context-sensing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300301,
author = {Lee, Jaeyeon and Sinclair, Mike and Gonzalez-Franco, Mar and Ofek, Eyal and Holz, Christian},
title = {TORC: A Virtual Reality Controller for In-Hand High-Dexterity Finger Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300301},
doi = {10.1145/3290605.3300301},
abstract = {Recent hand-held controllers have explored a variety of haptic feedback sensations for users in virtual reality by producing both kinesthetic and cutaneous feedback from virtual objects. These controllers are grounded to the user's hand and can only manipulate objects through arm and wrist motions, not using the dexterity of their fingers as they would in real life. In this paper, we present TORC, a rigid haptic controller that renders virtual object characteristics and behaviors such as texture and compliance. Users hold and squeeze TORC using their thumb and two fingers and interact with virtual objects by sliding their thumb on TORC's trackpad. During the interaction, vibrotactile motors produce sensations to each finger that represent the haptic feel of squeezing, shearing or turning an object. Our evaluation showed that using TORC, participants could manipulate virtual objects more precisely (e.g., position and rotate objects in 3D) than when using a conventional VR controller.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {haptic texture, haptics, haptic compliance, vr object manipulation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300473,
author = {Beneteau, Erin and Richards, Olivia K. and Zhang, Mingrui and Kientz, Julie A. and Yip, Jason and Hiniker, Alexis},
title = {Communication Breakdowns Between Families and Alexa},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300473},
doi = {10.1145/3290605.3300473},
abstract = {We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in pre- and post- deployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa's responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants' abilities to collaborate together with users to repair communication breakdowns.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {communication repairs, digital home assistants, human computer interaction, joint media engagement, families},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300563,
author = {Chandra, Priyank and Pal, Joyojeet},
title = {Rumors and Collective Sensemaking: Managing Ambiguity in an Informal Marketplace},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300563},
doi = {10.1145/3290605.3300563},
abstract = {Rumors are an enduring form of communication across socio-cultural landscapes globally. Counter to their typical negative association, rumors play a nuanced role, helping people collectively deal with problems through constructing a representation of an uncertain situation. Drawing on unstructured interviews and participant observation from a technology goods marketplace in Bangalore, India, we study the circulation of rumors related to the government's recent policy of demonetization and entry of online marketplaces and digital wallets, all of which disrupted existing market practices. These rumors emerge as attempts at sensemaking when a community is faced with ambiguity. Through highlighting the relationship of institutional trust with rumors, the paper argues that the study of rumors can help us identify the concerns of a community in the face of differential power relations. Further, rumors are a form of social bonding which help communities make sense of their place in society and shape existing practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {informal markets, marketplaces, rumors, institutions, informality, informal communication, uncertainty},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300407,
author = {Kim, Yoonji and Choi, Youngkyung and Lee, Hyein and Lee, Geehyuk and Bianchi, Andrea},
title = {VirtualComponent: A Mixed-Reality Tool for Designing and Tuning Breadboarded Circuits},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300407},
doi = {10.1145/3290605.3300407},
abstract = {Prototyping electronic circuits is an increasingly popular activity, supported by researchers, who develop toolkits to improve the design, debugging, and fabrication of electronics. Although past work mainly dealt with circuit topology, in this paper we propose a system for determining or tuning the values of the circuit components. Based on the results of a formative study with seventeen makers, we designed VirtualComponent, a mixed-reality tool that allows users to digitally place electronic components on a real breadboard, tune their values in software, and see these changes applied to the physical circuit in real-time. VirtualComponent is composed of a set of plug-and-play modules containing banks of components, and a custom breadboard managing the connections and components' values. Through demonstrations and the results of an informal study with twelve makers, we show that VirtualComponent is easy to use and allows users to test components' value configurations with little effort.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {component tuning, physical computing, circuits, toolkit},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300828,
author = {Kwak, Il-Youp and Huh, Jun Ho and Han, Seung Taek and Kim, Iljoo and Yoon, Jiwon},
title = {Voice Presentation Attack Detection through Text-Converted Voice Command Analysis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300828},
doi = {10.1145/3290605.3300828},
abstract = {Voice assistants are quickly being upgraded to support advanced, security-critical commands such as unlocking devices, checking emails, and making payments. In this paper, we explore the feasibility of using users' text-converted voice command utterances as classification features to help identify users' genuine commands, and detect suspicious commands. To maintain high detection accuracy, our approach starts with a globally trained attack detection model (immediately available for new users), and gradually switches to a user-specific model tailored to the utterance patterns of a target user. To evaluate accuracy, we used a real-world voice assistant dataset consisting of about 34.6 million voice commands collected from 2.6 million users. Our evaluation results show that this approach is capable of achieving about 3.4% equal error rate (EER), detecting 95.7% of attacks when an optimal threshold value is used. As for those who frequently use security-critical (attack-like) commands, we still achieve EER below 5%.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {voice assistant security, voice command analysis, attack detection},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300685,
author = {Feger, Sebastian S. and Dallmeier-Tiessen, S\"{u}nje and Schmidt, Albrecht and Woundefinedniak, Pawe\l{} W.},
title = {Designing for Reproducibility: A Qualitative Study of Challenges and Opportunities in High Energy Physics},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300685},
doi = {10.1145/3290605.3300685},
abstract = {Reproducibility should be a cornerstone of scientific research and is a growing concern among the scientific community and the public. Understanding how to design services and tools that support documentation, preservation and sharing is required to maximize the positive impact of scientific research. We conducted a study of user attitudes towards systems that support data preservation in High Energy Physics, one of science's most data-intensive branches. We report on our interview study with 12 experimental physicists, studying requirements and opportunities in designing for research preservation and reproducibility. Our findings suggest that we need to design for motivation and benefits in order to stimulate contributions and to address the observed scalability challenge. Therefore, researchers' attitudes towards communication, uncertainty, collaboration and automation need to be reflected in design. Based on our findings, we present a systematic view of user needs and constraints that define the design space of systems supporting reproducible practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interview study, secondary usage forms, reproducible research, design requirements},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300776,
author = {Hoppe, Matthias and Karolus, Jakob and Dietz, Felix and Woundefinedniak, Pawe\l{} W. and Schmidt, Albrecht and Machulla, Tonja-Katrin},
title = {VRsneaky: Increasing Presence in VR Through Gait-Aware Auditory Feedback},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300776},
doi = {10.1145/3290605.3300776},
abstract = {While Virtual Reality continues to increase in fidelity, it remains an open question how to effectively reflect the user's movements and provide congruent feedback in virtual environments. We present VRsneaky, a system for producing auditory movement feedback, which helps participants orient themselves in a virtual environment by providing footstep sounds. The system reacts to the user's specific gait features and adjusts the audio accordingly. In a user study with 28 participants, we found that VRsneaky increases users' sense of presence as well as awareness of their own posture and gait. Additionally, we find that increasing auditory realism significantly influences certain characteristics of participants' gait. Our work shows that gait-aware audio feedback is a means to increase presence in virtual environments. We discuss opportunities and design requirements for future scenarios where users walk through immersive virtual worlds.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {virtual reality, auditory feedback, gait awareness, presence},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300439,
author = {Grudin, Jonathan and Jacques, Richard},
title = {Chatbots, Humbots, and the Quest for Artificial General Intelligence},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300439},
doi = {10.1145/3290605.3300439},
abstract = {What began as a quest for artificial general intelligence branched into several pursuits, including intelligent assistants developed by tech companies and task-oriented chatbots that deliver more information or services in specific domains. Progress quickened with the spread of low-latency networking, then accelerated dramatically a few years ago. In 2016, task-focused chatbots became a centerpiece of machine intelligence, promising interfaces that are more engaging than robotic answering systems and that can accommodate our increasingly phone-based information needs. Hundreds of thousands were built. Creating successful non-trivial chatbots proved more difficult than anticipated. Some developers now design for human-chatbot (humbot) teams, with people handling difficult queries. This paper describes the conversational agent space, difficulties in meeting user expectations, potential new design approaches, uses of human-bot hybrids, and implications for the ultimate goal of creating software with general intelligence.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {natural language interfaces, artificial general intelligence (agi), conversational agent, humbot, chatbot, artificial intelligence, virtual companion, intelligent assistant},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300702,
author = {Menking, Amanda and Erickson, Ingrid and Pratt, Wanda},
title = {People Who Can Take It: How Women Wikipedians Negotiate and Navigate Safety},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300702},
doi = {10.1145/3290605.3300702},
abstract = {Wikipedia is one of the most successful online communities in history, yet it struggles to attract and retain women editors-a phenomenon known as the gender gap. We investigate this gap by focusing on the voices of experienced women Wikipedians. In this interview-based study (N=25), we identify a core theme among these voices: safety. We reveal how our participants perceive safety within their community, how they manage their safety both conceptually and physically, and how they act on this understanding to create safe spaces on and off Wikipedia. Our analysis shows Wikipedia functions as both a multidimensional and porous space encompassing a spectrum of safety. Navigating this space requires these women to employ sophisticated tactics related to identity management, boundary management, and emotion work. We conclude with a set of provocations to spur the design of future online environments that encourage equity, inclusivity, and safety for historically marginalized users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {gender gap, safe spaces, participation, wikipedia, online communities, safety},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300682,
author = {Sun, Yuqian and Yoshida, Shigeo and Narumi, Takuji and Hirose, Michitaka},
title = {PaCaPa: A Handheld VR Device for Rendering Size, Shape, and Stiffness of Virtual Objects in Tool-Based Interactions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300682},
doi = {10.1145/3290605.3300682},
abstract = {We present PaCaPa, a handheld device that renders haptics on a user's palm when the user interacts with virtual objects using virtual tools such as a stick. PaCaPa is a cuboid device with two wings that open and close. As the user's stick makes contact with a virtual object, the wings open by a specific degree to dynamically change the pressure on the palm and fingers. The open angle of the wings is calculated from the angle between the virtual stick and hand direction. As the stick bites into the target object, a large force is generated. Our device enables three kinds of renderings: size, shape, and stiffness. We conducted user studies to evaluate the performance of our device. We also evaluated our device in two application scenarios. User feedback and qualitative ratings indicated that our device can make indirect interaction with handheld tools more realistic.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {haptics, virtual reality, tool-based interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300760,
author = {Alkhatib, Ali and Bernstein, Michael},
title = {Street-Level Algorithms: A Theory at the Gaps Between Policy and Decisions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300760},
doi = {10.1145/3290605.3300760},
abstract = {Errors and biases are earning algorithms increasingly malignant reputations in society. A central challenge is that algorithms must bridge the gap between high-level policy and on-the-ground decisions, making inferences in novel situations where the policy or training data do not readily apply. In this paper, we draw on the theory of street-level bureaucracies, how human bureaucrats such as police and judges interpret policy to make on-the-ground decisions. We present by analogy a theory of street-level algorithms, the algorithms that bridge the gaps between policy and decisions about people in a socio-technical system. We argue that unlike street-level bureaucrats, who reflexively refine their decision criteria as they reason through a novel situation, street-level algorithms at best refine their criteria only after the decision is made. This loop-and-a-half delay results in illogical decisions when handling new or extenuating circumstances. This theory suggests designs for street-level algorithms that draw on historical design patterns for street-level bureaucracies, including mechanisms for self-policing and recourse in the case of error.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {artificial intelligence, street-level algorithms, street-level bureaucracies},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300697,
author = {Tseng, Vincent W.-S. and Lee, Matthew L. and Denoue, Laurent and Avrahami, Daniel},
title = {Overcoming Distractions during Transitions from Break to Work Using a Conversational Website-Blocking System},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300697},
doi = {10.1145/3290605.3300697},
abstract = {Work breaks--both physical and digital--play an important role in productivity and workplace wellbeing. Yet, the growing availability of digital distractions from online content can turn breaks into prolonged "cyberloafing". In this paper, we present UpTime, a system that aims to support workers' transitions from breaks back to work--moments susceptible to digital distractions. Combining a browser extension and chatbot, users interact with UpTime through proactive and reactive chat prompts. By sensing transitions from inactivity, UpTime helps workers avoid distractions by automatically blocking distracting websites temporarily, while still giving them control to take necessary digital breaks. We report findings from a 3-week comparative field study with 15 workers. Our results show that automatic, temporary blocking at transition points can significantly reduce digital distractions and stress without sacrificing workers' sense of control. Our findings, however, also emphasize that overloading users' existing communication channels for chatbot interaction should be done thoughtfully.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {conversational agents, work breaks, wellbeing, workplace, interruption management, cyberloafing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300859,
author = {Khairuddin, Irni Eliana and Sas, Corina},
title = {An Exploration of Bitcoin Mining Practices: Miners' Trust Challenges and Motivations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300859},
doi = {10.1145/3290605.3300859},
abstract = {Bitcoin blockchain technology is a distributed ledger of nodes authorizing transactions between anonymous parties. Its key actors are miners using computational power to solve mathematical problems for validating transactions. By sharing blockchain's characteristics, mining is a decentralized, transparent and unregulated practice, less explored in HCI, so we know little about miners' motivations and experiences, and how these may impact on different dimensions of trust. This paper reports on interviews with 20 bitcoin miners about their practices and trust challenges. Findings contribute to HCI theories by extending the exploration of blockchain's characteristics relevant to trust with the competitiveness dimension underpinning the social organization of mining. We discuss the risks of collaborative mining due to centralization and dishonest administrators, and conclude with design implications highlighting the need for tools monitoring the distribution of rewards in collaborative mining, tools tracking data centers' authorization and reputation, and tools supporting the development of decentralized pools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {blockchain, bitcoin miners, trust, dishonest administrators},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300861,
author = {da Rocha Tom\'{e} Filho, Frederico and Mirza-Babaei, Pejman and Kapralos, Bill and Moreira Mendon\c{c}a Junior, Glaudiney},
title = {Let's Play Together: Adaptation Guidelines of Board Games for Players with Visual Impairment},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300861},
doi = {10.1145/3290605.3300861},
abstract = {Board games present accessibility barriers for players with visual impairment since they often employ visuals alone to communicate gameplay information. Our research focuses on board game accessibility for those with visual impairment. This paper describes a three-phase study conducted to develop board game accessibility adaptation guidelines. These guidelines were developed through a user-centered design approach that included in-depth interviews and a series of user studies using two adapted board games. Our findings indicate that participants with and without visual impairment were able to play the adapted games, exhibiting a balanced experience whereby participants had complete autonomy and were provided with equal chances of victory. Our paper also contributes to the game and accessibility communities through the development of adaptation guidelines that allow board games to become inclusive irrespective of a player's visual impairment.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {visual impairment, board games, guidelines, accessibility},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300886,
author = {Shi, Joshua and Shah, Armaan and Hedman, Garrett and O'Rourke, Eleanor},
title = {Pyrus: Designing A Collaborative Programming Game to Promote Problem Solving Behaviors},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300886},
doi = {10.1145/3290605.3300886},
abstract = {While problem solving is a crucial aspect of programming, few learning opportunities in computer science focus on teaching problem-solving skills like planning. In this paper, we present Pyrus, a collaborative game designed to encourage novices to plan in advance while programming. Through Pyrus, we explore a new approach to designing educational games we call behavior-centered game design, in which designers first identify behaviors that learners should practice to reach desired learning goals and then select game mechanics that incentivize those behaviors. Pyrus leverages game mechanics like a failure condition, distributed resources, and enforced turn-taking to encourage players to plan and collaborate. In a within-subjects user study, we found that pairs of novices spent more time planning and collaborated more equally when solving problems in Pyrus than in pair programming. These findings show that game mechanics can be used to promote desirable learning behaviors like planning in advance, and suggest that our behavior-centered approach to educational game design warrants further study.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300399,
author = {Vashistha, Aditya and Garg, Abhinav and Anderson, Richard},
title = {ReCall: Crowdsourcing on Basic Phones to Financially Sustain Voice Forums},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300399},
doi = {10.1145/3290605.3300399},
abstract = {Although voice forums are widely used to enable marginalized communities to produce, consume, and share information, their financial sustainability is a key concern among HCI4D researchers and practitioners. We present ReCall, a crowdsourcing marketplace accessible via phone calls where low-income rural residents vocally transcribe audio files to gain free airtime to participate in voice forums as well as to earn money. We conducted a series of experimental and usability evaluations with 28 low-income people in rural India to examine the effect of phone types, channel types, and review modes on speech transcription performance. We then deployed ReCall for two weeks to 24 low-income rural residents who placed 5,879 phone calls, completed 29,000 micro tasks to yield transcriptions with 85% accuracy, and earned INR 20,500. Our mixed-methods analysis indicates that each minute of crowd work on ReCall gives users eight minutes of free airtime on another voice forum, and thus illustrates a way to address the financial sustainability of voice forums.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {voice forums, hci4d, financial sustainability, crowdsourcing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300815,
author = {Mohr, Peter and Tatzgern, Markus and Langlotz, Tobias and Lang, Andreas and Schmalstieg, Dieter and Kalkofen, Denis},
title = {TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300815},
doi = {10.1145/3290605.3300815},
abstract = {The latest generation of consumer market Head-mounted displays (HMD) now include self-contained inside-out tracking of head motions, which makes them suitable for mobile applications. However, 3D tracking of input devices is either not included at all or requires to keep the device in sight, so that it can be observed from a sensor mounted on the HMD. Both approaches make natural interactions cumbersome in mobile applications. TrackCap, a novel approach for 3D tracking of input devices, turns a conventional smartphone into a precise 6DOF input device for an HMD user. The device can be conveniently operated both inside and outside the HMD's field of view, while it provides additional 2D input and output capabilities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {hmd, augmented reality, mixed reality, wearable computing, input devices, 3d pointing, mobile devices},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300601,
author = {Samson, Briane Paul V. and Sumi, Yasuyuki},
title = {Exploring Factors That Influence Connected Drivers to (Not) Use or Follow Recommended Optimal Routes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300601},
doi = {10.1145/3290605.3300601},
abstract = {Navigation applications are becoming ubiquitous in our daily navigation experiences. With the intention to circumnavigate congested roads, their route guidance always follows the basic assumption that drivers always want the fastest route. However, it is unclear how their recommendations are followed and what factors affect their adoption. We present the results of a semi-structured qualitative study with 17 drivers, mostly from the Philippines and Japan. We recorded their daily commutes and occasional trips, and inquired into their navigation practices, route choices and on-the-fly decision-making. We found that while drivers choose a recommended route in urgent situations, many still preferred to follow familiar routes. Drivers deviated because of a recommendation's use of unfamiliar roads, lack of local context, perceived driving unsuitability, and inconsistencies with realized navigation experiences. Our findings and implications emphasize their personalization needs, and how the right amount of algorithmic sophistication can encourage behavioral adaptation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {navigation applications, navigation behavior, recommender systems, driving, advanced driver-assistance system},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300278,
author = {Strasnick, Evan and Follmer, Sean and Agrawala, Maneesh},
title = {Pinpoint: A PCB Debugging Pipeline Using Interruptible Routing and Instrumentation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300278},
doi = {10.1145/3290605.3300278},
abstract = {Difficulties in accessing, isolating, and iterating on the components and connections of a printed circuit board (PCB) create unique challenges in PCB debugging. Manual probing methods are slow and error prone, and even dedicated PCB testing equipment remains limited by its inability to modify the circuit during testing. We present Pinpoint, a tool that facilitates in-circuit PCB debugging through techniques such as programmatically probing signals, dynamically disconnecting components and subcircuits to test in isolation, and splicing in new elements to explore potential modifications. Pinpoint automatically instruments a PCB design and generates designs for a physical jig board that interfaces the user's PCB to our custom testing hardware and to software tools. We evaluate Pinpoint's ability to facilitate the debugging of various PCB issues by instrumenting and testing different classes of boards, as well as by characterizing its technical limitations and by soliciting feedback through a guided exploration with PCB designers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {jig, pcb, in-circuit testing, instrumentation, design tool, design-for-test, debugging, printed circuit board},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300576,
author = {Kong, Ha-Kyung and Liu, Zhicheng and Karahalios, Karrie},
title = {Trust and Recall of Information across Varying Degrees of Title-Visualization Misalignment},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300576},
doi = {10.1145/3290605.3300576},
abstract = {Visualizations are emerging as a means of spreading digital misinformation. Prior work has shown that visualization interpretation can be manipulated through slanted titles that favor only one side of the visual story, yet people still think the visualization is impartial. In this work, we study whether such effects continue to exist when titles and visualizations exhibit greater degrees of misalignment: titles whose message differs from the visually cued message in the visualization, and titles whose message contradicts the visualization. We found that although titles with a contradictory slant triggered more people to identify bias compared to titles with a miscued slant, visualizations were persistently perceived as impartial by the majority. Further, people's recall of the visualization's message more frequently aligned with the titles than the visualization. Based on these results, we discuss the potential of leveraging textual components to detect and combat visual-based misinformation with text-based slants.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {confirmation bias, misinformation, visualization title},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300570,
author = {Kiani, Kimia and Cui, George and Bunt, Andrea and McGrenere, Joanna and Chilana, Parmit K.},
title = {Beyond "One-Size-Fits-All": Understanding the Diversity in How Software Newcomers Discover and Make Use of Help Resources},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300570},
doi = {10.1145/3290605.3300570},
abstract = {For most modern feature-rich software, considerable external help and learning resources are available on the web (e.g., documentation, tutorials, videos, Q&amp;A forums). But, how do users new to an application discover and make use of such resources? We conducted in-lab and diary studies with 26 software newcomers from a variety of different backgrounds who were all using Fusion 360, a 3D modeling application, for the first time. Our results illustrate newcomers' diverse needs, perceptions, and help-seeking behaviors. We found a number of distinctions in how technical and non-technical users approached help-seeking, including: when and how they initiated the help-seeking process, their struggles in recognizing relevant help, the degree to which they made coordinated use of the application and different resources, and in how they perceived the utility of different help formats. We discuss implications for moving beyond "one-size-fits-all" help resources towards more structured, personalized, and curated help and learning materials.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {help-seeking, software help, software learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300656,
author = {Wang, Guanyun and Tao, Ye and Capunaman, Ozguc Bertug and Yang, Humphrey and Yao, Lining},
title = {A-Line: 4D Printing Morphing Linear Composite Structures},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300656},
doi = {10.1145/3290605.3300656},
abstract = {This paper presents A-line, a 4D printing system for designing and fabricating morphing three-dimensional shapes out of simple linear elements. In addition to the commonly known benefit of 4D printing to save printing time, printing materials, and packaging space, A-line also takes advantage of the unique properties of thin lines, including their suitability for compliant mechanisms and ability to travel through narrow spaces and self-deploy or self-lock on site. A-line integrates a method of bending angle control in up to eight directions for one printed line segment, using a single type of thermoplastic material. A software platform to support the design, simulation and tool path generation is developed to support the design and manufacturing of various A-line structures. Finally, the design space of A-line is explored through four application areas, including line sculpting, compliant mechanisms, self-deploying, and self-locking structures.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {4d printing, line-based structure, self-folding, shape-changing interface, 3d printing, line-shaped interface, morphing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300290,
author = {Gulay, Emrecan and Lucero, Andr\'{e}s},
title = {Integrated Workflows: Generating Feedback Between Digital and Physical Realms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300290},
doi = {10.1145/3290605.3300290},
abstract = {As design thinking shifted away from conventional methods with the rapid adoption of computer-aided design and fabrication technologies, architects have been seeking ways to initiate a comprehensive dialogue between the virtual and the material realms. Current methodologies do not offer embodied workflows that utilize the feedback obtained through a subsequent transition process between physical and digital design. Therefore, narrowing the separation between these two platforms remains as a research problem. This literature review elaborates the divide between physical and digital design, testing and manufacturing techniques in the morphological process of architectural form. We first review the digital transformation in the architectural design discourse. Then, we proceed by introducing a variety of methods that are integrating digital and physical workflows and suggesting an alternative approach. Our work unveils that there is a need for empirical research with a focus on integrated approaches to create intuitively embodied experiences for architectural designers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {fabrication, embodied interaction, design methods, creativity support},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300594,
author = {Danyluk, Kurtis and Jenny, Bernhard and Willett, Wesley},
title = {Look-From Camera Control for 3D Terrain Maps},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300594},
doi = {10.1145/3290605.3300594},
abstract = {We introduce three lightweight interactive camera control techniques for 3D terrain maps on touch devices based on a look-from metaphor (Discrete Look-From-At, Continuous Look-From-Forwards, and Continuous Look-From-Towards). These techniques complement traditional touch screen pan, zoom, rotate, and pitch controls allowing viewers to quickly transition between top-down, oblique, and ground-level views. We present the results of a study in which we asked participants to perform elevation comparison and line-of-sight determination tasks using each technique. Our results highlight how look-from techniques can be integrated on top of current direct manipulation navigation approaches by combining several direct manipulation operations into a single look-from operation. Additionally, they show how look-from techniques help viewers complete a variety of common and challenging map-based tasks.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {look-from camera control, touch, terrain, map interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300443,
author = {Wu, Ziming and Kim, Taewook and Li, Quan and Ma, Xiaojuan},
title = {Understanding and Modeling User-Perceived Brand Personality from Mobile Application UIs},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300443},
doi = {10.1145/3290605.3300443},
abstract = {Designers strive to make their mobile apps stand out in a competitive market by creating a distinctive brand personality. However, it is unclear whether users can form a consistent impression of brand personality by looking at a few user interface (UI) screenshots in the app store, and if this process can be modeled computationally. To bridge this gap, we first collect crowd assessment on brand personalities depicted by the UIs of 318 applications, and statistically confirm that users can reach substantial agreement. To further model how users process mobile UI visually, we compute UI descriptors including Color, Organization, and Texture at both element and page levels. We feed these descriptors to a computational model, achieving a high accuracy of predicting perceived brand personality (MSE = 0.035 and R^2 = 0.78). This work could benefit designers by highlighting contributing visual factors to brand personality creation and providing quick, low-cost design feedback.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {computational design assessment, mobile user interfaces, brand personality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300371,
author = {Wedoff, Ryan and Ball, Lindsay and Wang, Amelia and Khoo, Yi Xuan and Lieberman, Lauren and Rector, Kyle},
title = {Virtual Showdown: An Accessible Virtual Reality Game with Scaffolds for Youth with Visual Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300371},
doi = {10.1145/3290605.3300371},
abstract = {Virtual Reality (VR) is a growing source of entertainment, but people who are visually impaired have not been effectively included. Audio cues are motivated as a complement to visuals, making experiences more immersive, but are not a primary cue. To address this, we implemented a VR game called Virtual Showdown. We based Virtual Showdown on an accessible real-world game called Showdown, where people use their hearing to locate and hit a ball against an opponent. Further, we developed Verbal and Verbal/Vibration Scaffolds to teach people how to play Virtual Showdown. We assessed the acceptability of Virtual Showdown and compared our scaffolds in an empirical study with 34 youth who are visually impaired. Thirty-three participants wanted to play Virtual Showdown again, and we learned that participants scored higher with the Verbal Scaffold or if they had prior Showdown experience. Our empirical findings inform the design of future accessible VR experiences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {low vision, youth, virtual reality, haptics, blind, spatial audio},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300373,
author = {Kruijff, Ernst and Biswas, Saugata and Trepkowski, Christina and Maiero, Jens and Ghinea, George and Stuerzlinger, Wolfgang},
title = {Multilayer Haptic Feedback for Pen-Based Tablet Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300373},
doi = {10.1145/3290605.3300373},
abstract = {We present a novel, multilayer interaction approach that enables state transitions between spatially above-screen and 2D on-screen feedback layers. This approach supports the exploration of haptic features that are hard to simulate using rigid 2D screens. We accomplish this by adding a haptic layer above the screen that can be actuated and interacted with (pressed on) while the user interacts with on-screen content using pen input. The haptic layer provides variable firmness and contour feedback, while its membrane functionality affords additional tactile cues like texture feedback. Through two user studies, we look at how users can use the layer in haptic exploration tasks, showing that users can discriminate well between different firmness levels, and can perceive object contour characteristics. Demonstrated also through an art application, the results show the potential of multilayer feedback to extend on-screen feedback with additional widget, tool and surface properties, and for user guidance.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {multilayer interaction, pen interaction, haptic feedback},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300921,
author = {Poretski, Lev and Arazy, Ofer and Lanir, Joel and Shahar, Shalev and Nov, Oded},
title = {Virtual Objects in the Physical World: Relatedness and Psychological Ownership in Augmented Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300921},
doi = {10.1145/3290605.3300921},
abstract = {As technology advances, people increasingly interact with virtual objects in settings such as augmented reality (AR) where the virtual layer is superimposed on top of the physical world. Similarly to interactions with physical objects, users may assign virtual objects with value, experience a sense of relatedness, and develop psychological ownership over these objects. The objective of this study is to understand how AR's unique characteristics influences the emergence of meaning and ownership perceptions amongst users. We conducted a study of users' interactions with a virtual dog over a three-week period, comparing AR and fully virtual settings. Our findings show that engagement with the application is a key determinant of the relation users develop with virtual objects. However, the effect of the background layer-whether physical or virtual-dominates the development of relatedness and ownership feelings, highlighting the importance of the "real" physical layer in shaping users' perceptions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {material culture, augmented reality, relatedness, ownership, virtual possessions, qualitative analysis},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300666,
author = {Wu, Yiying and Lyckvi, Sus and Roto, Virpi},
title = {"What is Fair Shipping, Anyway?": Using Design Fiction to Raise Ethical Awareness in an Industrial Context},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300666},
doi = {10.1145/3290605.3300666},
abstract = {The HCI community cares for the human and social aspects of technologies. Ethical discussion on the social implications of new technologies often happen among researchers, but it is important to raise this discussion also in the industry that designs and implements new systems. In this paper, we introduce a case in which design fiction was used as an ethical discussion tool among company partners. We report the process of creating and prototyping a fictional world embedded with conflicting values that aimed to shift the focus from industrial merits towards societal values and raise discussion among participants. Moreover, we examine the challenges and propose suggestions in crafting critiques and friction to the industrial context. Our findings suggest why and how one should use design fiction as a means to raise ethical awareness in a technology- and profit-focused context, to support further activities on developing more humane technological futures.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {value fiction, design methods, design fiction, ethics of automation, design methodology, b2b industries},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300871,
author = {Goguey, Alix and Sahoo, Deepak Ranjan and Robinson, Simon and Pearson, Jennifer and Jones, Matt},
title = {Pulp Friction: Exploring the Finger Pad Periphery for Subtle Haptic Feedback},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300871},
doi = {10.1145/3290605.3300871},
abstract = {Current haptic feedback techniques on handheld devices are applied to the finger pad or the palm of the user. These state-of-the-art approaches are coarse-grained and tend to be intrusive, rather than subtle. In contrast, we present a new feedback technique that applies stimuli around the periphery of the finger pulp, demonstrating how this can provide rich, nuanced haptic information. We use a reconfigurable haptic device employing a ferromagnetic marble for back-of-the device handheld use, which, for the first time, probes, without instrumenting the user, the periphery of the distal phalanx with localised stimulation. We present the design-space afforded by this new technique and evaluate the human-factors of finger-peripheral touch interaction in a controlled user-study. We report results with marbles of different diameters, speeds and a combination of poking, lateral vibration and patterns; present the resulting design guidelines for finger-periphery haptic feedback; and, illustrate its potential with use case scenarios.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {haptic, finger pad periphery},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300250,
author = {Holloway, Leona and Marriott, Kim and Butler, Matthew and Borning, Alan},
title = {Making Sense of Art: Access for Gallery Visitors with Vision Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300250},
doi = {10.1145/3290605.3300250},
abstract = {While there is widespread recognition of the need to provide people with vision impairments (PVI) equitable access to cultural institutions such as art galleries, this is not easy. We present the results of a collaboration with a regional art gallery who wished to open their collection to PVIs in the local community. We describe a novel model that provides three different ways of accessing the gallery, depending upon visual acuity and mobility: virtual tours, self-guided tours and guided tours. As far as possible the model supports autonomous exploration by PVIs. It was informed by a value sensitive design exploration of the values and value conflicts of the primary stakeholders.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {art, blindness, 3d printing, value sensitive design, accessibility, vision impairment},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300701,
author = {Ma, Shuai and Wei, Zijun and Tian, Feng and Fan, Xiangmin and Zhang, Jianming and Shen, Xiaohui and Lin, Zhe and Huang, Jin and M\v{e}ch, Radom\'{\i}r and Samaras, Dimitris and Wang, Hongan},
title = {SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300701},
doi = {10.1145/3290605.3300701},
abstract = {Instant photo taking and sharing has become one of the most popular forms of social networking. However, taking high-quality photos is difficult as it requires knowledge and skill in photography that most non-expert users lack. In this paper we present SmartEye, a novel mobile system to help users take photos with good compositions in-situ. The back-end of SmartEye integrates the View Proposal Network (VPN), a deep learning based model that outputs composition suggestions in real time, and a novel, interactively updated module (P-Module) that adjusts the VPN outputs to account for personalized composition preferences. We also design a novel interface with functions at the front-end to enable real-time and informative interactions for photo taking. We conduct two user studies to investigate SmartEye qualitatively and quantitatively. Results show that SmartEye effectively models and predicts personalized composition preferences, provides instant high-quality compositions in-situ, and outperforms the non-personalized systems significantly.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interactive feedback, user preference modeling, deep learning, photo composition},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300462,
author = {Zhao, Mingqian and Qu, Huamin and Sedlmair, Michael},
title = {Neighborhood Perception in Bar Charts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300462},
doi = {10.1145/3290605.3300462},
abstract = {In this paper, we report three user experiments that investigate in how far the perception of a bar in a bar chart changes based on the height of its neighboring bars. We hypothesized that the perception of the very same bar, for instance, might differ when it is surrounded by the top highest vs. the top lowest bars. Our results show that such neighborhood effects exist: a target bar surrounded by high neighbor bars, is perceived to be lower as the same bar surrounded with low neighbors. Yet, the effect size of this neighborhood effect is small compared to other data-inherent effects: the judgment accuracy largely depends on the target bar rank, number of data items, and other data characteristics of the dataset. Based on the findings, we discuss design implications for perceptually optimizing bar charts.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {empirical study that tells us about people, visualization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300614,
author = {Ju, Somi and Lee, Kyung-Ryong and Kim, Subin and Park, Young-Woo},
title = {Bookly: An Interactive Everyday Artifact Showing the Time of Physically Accumulated Reading Activity},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300614},
doi = {10.1145/3290605.3300614},
abstract = {We introduce Bookly, an interactive artifact that physically represents the accumulated time of users' reading activity through abstract volumetric changes. Bookly accumulates the time of actions (e.g., picking up and putting down books) that users performed for reading and provides a designated space for the ongoing book being read. The results of our 2-week in-field study with six participants showed that continuous exposure to volumetric changes representing the accumulated time of reading activities helped the users to understand their unsettled reading patterns. Bookly also motivated the users to improve their reading behavior by gradually making reading part of their schedules. Additionally, the definite distinction of the ongoing book improved its visual affordance and accessibility for the users to start reading books. Based on the findings, we confirmed the possibility of making intangible data physical for self-reflection to enhance changes in behaviors that are difficult to perform due to weak motivation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {book, data physicalization, reading motivation, self-reflection},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300909,
author = {Wood, Gavin and Dylan, Thomas and Durrant, Abigail and Torres, Pablo E. and Ulrich, Philip and Carr, Amanda and Cukurova, Mutlu and Downey, Denise and McGrath, Phil and Balaam, Madeline and Ferguson, Alice and Vines, John and Lawson, Shaun},
title = {Designing for Digital Playing Out},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300909},
doi = {10.1145/3290605.3300909},
abstract = {We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) 'playing out' in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children's free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting 'digital playing out' that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {children, internet of things, open-ended play, outdoor play, digital playing out, pervasive play},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300444,
author = {Komkaite, Aida and Lavrinovica, Liga and Vraka, Maria and Skov, Mikael B.},
title = {Underneath the Skin: An Analysis of YouTube Videos to Understand Insertable Device Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300444},
doi = {10.1145/3290605.3300444},
abstract = {During the last decade, people have started to experiment with insertable technology like RFID or NFC chips and use them for e.g. identification. However, little is known about how people in fact interact with and adapt insertables. We conducted a video analysis of 122 YouTube videos to gain insight into the interaction with the insertables. Second, we implemented an online survey to complement our data from the video analysis. Our findings show that there are many opportunities for interaction with insertables both for task-oriented and creative purposes. However, there are also multiple challenges and obstacles as well as side effects and health concerns. Our findings conclude that the current infrastructure is not ready to support the use of insertables yet, and we discuss implications of this.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {rfid, interaction, in the body, nfc, insertables, survey, hobbyist, youtube},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300483,
author = {Wang, Zezhong and Wang, Shunming and Farinella, Matteo and Murray-Rust, Dave and Henry Riche, Nathalie and Bach, Benjamin},
title = {Comparing Effectiveness and Engagement of Data Comics and Infographics},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300483},
doi = {10.1145/3290605.3300483},
abstract = {This paper compares the effectiveness of data comics and infographics for data-driven storytelling. While infographics are widely used, comics are increasingly popular for explaining complex and scientific concepts. However, empirical evidence comparing the effectiveness and engagement of infographics, comics and illustrated texts is still lacking. We report on the results of two complementary studies, one in a controlled setting and one in the wild. Our results suggest participants largely prefer data comics in terms of enjoyment, focus, and overall engagement and that comics improve understanding and recall of information in the stories. Our findings help to understand the respective roles of the investigated formats as well as inform the design of more effective data comics and infographics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {engagement, effectiveness, visualization, comics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300510,
author = {Corbett, Eric and Loukissas, Yanni},
title = {Engaging Gentrification as a Social Justice Issue in HCI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300510},
doi = {10.1145/3290605.3300510},
abstract = {Gentrification-the spatial expression of economic inequality-is fundamentally a matter of social justice. Yet, even as work outside of HCI has begun to discuss how computing can enable or challenge gentrification, HCI's growing social justice agenda has not engaged with this issue. This omission creates an opportunity for HCI to develop a research and design agenda at the intersection of computing, social justice, and gentrification. We begin this work by outlining existing scholarship describing how the consumption side dynamics of gentrification are mediated by contemporary socio-technical systems. Subsequently, we build on the social justice framework introduced by Dombrowski, Harmon, and Fox to discuss how HCI may resist or counter such forces. We offer six modes of research that HCI scholars can pursue to engage gentrification.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {gentrification, design, social justice},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300503,
author = {Goguey, Alix and Steer, Cameron and Lucero, Andr\'{e}s and Nigay, Laurence and Sahoo, Deepak Ranjan and Coutrix, C\'{e}line and Roudaut, Anne and Subramanian, Sriram and Tokuda, Yutaka and Neate, Timothy and Pearson, Jennifer and Robinson, Simon and Jones, Matt},
title = {PickCells: A Physically Reconfigurable Cell-Composed Touchscreen},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300503},
doi = {10.1145/3290605.3300503},
abstract = {Touchscreens are the predominant medium for interactions with digital services; however, their current fixed form factor narrows the scope for rich physical interactions by limiting interaction possibilities to a single, planar surface. In this paper we introduce the concept of PickCells, a fully re-configurable device concept composed of cells, that breaks the mould of rigid screens and explores a modular system that affords rich sets of tangible interactions and novel across-device relationships. Through a series of co-design activities -- involving HCI experts and potential end-users of such systems -- we synthesised a design space aimed at inspiring future research, giving researchers and designers a framework in which to explore modular screen interactions. The design space we propose unifies existing works on modular touch surfaces under a general framework and broadens horizons by opening up unexplored spaces providing new interaction possibilities. In this paper, we present the PickCells concept, a design space of modular touch surfaces, and propose a toolkit for quick scenario prototyping.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {modular, touchscreen, interface, shape changing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300781,
author = {Sarkar, Anurag and Cooper, Seth},
title = {Transforming Game Difficulty Curves Using Function Composition},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300781},
doi = {10.1145/3290605.3300781},
abstract = {Player engagement within a game is often influenced by its difficulty curve: the pace at which in-game challenges become harder. Thus, finding an optimal difficulty curve is important. In this paper, we present a flexible and formal approach to transforming game difficulty curves by leveraging function composition. This allows us to describe changes to difficulty curves, such as making them "smoother", in a more precise way. In an experiment with 400 players, we used function composition to modify the existing difficulty curve of the puzzle game Paradox to generate new curves. We found that transforming difficulty curves in this way impacted player engagement, including the number of levels completed and the estimated skill needed to complete those levels, as well as perceived competence. Further, we found some transformed curves dominated others with respect to engagement, indicating that different design goals can be traded-off by considering a subset of curves.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {difficulty curve, difficulty, adaptivity, games},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300562,
author = {Kim, Yea-Seul and Dontcheva, Mira and Adar, Eytan and Hullman, Jessica},
title = {Vocal Shortcuts for Creative Experts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300562},
doi = {10.1145/3290605.3300562},
abstract = {Vocal shortcuts, short spoken phrases to control interfaces, have the potential to reduce cognitive and physical costs of interactions. They may benefit expert users of creative applications (e.g., designers, illustrators) by helping them maintain creative focus. To aid the design of vocal shortcuts and gather use cases and design guidelines for speech interaction, we interviewed ten creative experts. Based on our findings, we built VoiceCuts, a prototype implementation of vocal shortcuts in the context of an existing creative application. In contrast to other speech interfaces, VoiceCuts targets experts' unique needs by handling short and partial commands and leverages document model and application context to disambiguate user utterances. We report on the viability and limitations of our approach based on feedback from creative experts.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {expert users, creative applications, speech interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300724,
author = {Eslami, Motahhare and Vaccaro, Kristen and Lee, Min Kyung and Elazari Bar On, Amit and Gilbert, Eric and Karahalios, Karrie},
title = {User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300724},
doi = {10.1145/3290605.3300724},
abstract = {Algorithms exert great power in curating online information, yet are often opaque in their operation, and even existence. Since opaque algorithms sometimes make biased or deceptive decisions, many have called for increased transparency. However, little is known about how users perceive and interact with potentially biased and deceptive opaque algorithms. What factors are associated with these perceptions, and how does adding transparency into algorithmic systems change user attitudes? To address these questions, we conducted two studies: 1) an analysis of 242 users' online discussions about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users disclosing the algorithm's existence via a tool. We found that users question or defend this algorithm and its opacity depending on their engagement with and personal gain from the algorithm. We also found adding transparency into the algorithm changed users' attitudes towards the algorithm: users reported their intention to either write for the algorithm in future reviews or leave the platform.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {algorithm's operation, transparency, reviewing platforms, algorithm's existence, algorithmic opacity},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300707,
author = {M\"{u}ller, Florian and McManus, Joshua and G\"{u}nther, Sebastian and Schmitz, Martin and M\"{u}hlh\"{a}user, Max and Funk, Markus},
title = {Mind the Tap: Assessing Foot-Taps for Interacting with Head-Mounted Displays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300707},
doi = {10.1145/3290605.3300707},
abstract = {From voice commands and air taps to touch gestures on frames: Various techniques for interacting with head-mounted displays (HMDs) have been proposed. While these techniques have both benefits and drawbacks dependent on the current situation of the user, research on interacting with HMDs has not concluded yet. In this paper, we add to the body of research on interacting with HMDs by exploring foot-tapping as an input modality. Through two controlled experiments with a total of 36 participants, we first explore direct interaction with interfaces that are displayed on the floor and require the user to look down to interact. Secondly, we investigate indirect interaction with interfaces that, although operated by the user's feet, are always visible as they are floating in front of the user. Based on the results of the two experiments, we provide design recommendations for direct and indirect foot-based user interfaces.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user study, human factors, hmd, foot interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300420,
author = {Fortin, Pascal E. and Sulmont, Elisabeth and Cooperstock, Jeremy},
title = {Detecting Perception of Smartphone Notifications Using Skin Conductance Responses},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300420},
doi = {10.1145/3290605.3300420},
abstract = {Today's smartphone notification systems are incapable of determining whether a notification has been successfully perceived without explicit interaction from the user. If the system incorrectly assumes that a notification has not been perceived, it may repeat it redundantly, disrupting the user and others (e.g., phone ringing). Or, if it incorrectly assumes that a notification was perceived, and therefore fails to repeat it, the notification will be missed altogether (e.g., text message). Results from a laboratory study confirm, for the first time, that both vibrotactile and auditory smartphone notifications induce skin conductance responses (SCR), that the induced responses differ from that of arbitrary stimuli, and that they could be employed to predict perception of smartphone notifications after their presentation using wearable sensors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {electrodermal activity, physiological interaction, smartphone notifications},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300773,
author = {Barbosa, Nat\~{a} M. and Chen, Monchu},
title = {Rehumanized Crowdsourcing: A Labeling Framework Addressing Bias and Ethics in Machine Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300773},
doi = {10.1145/3290605.3300773},
abstract = {The increased use of machine learning in recent years led to large volumes of data being manually labeled via crowdsourcing microtasks completed by humans. This brought about dehumanization effects, namely, when task requesters overlook the humans behind the task, leading to issues of ethics (e.g., unfair payment) and amplification of human biases, which are transferred into training data and affect machine learning in the real world. We propose a framework that allocates microtasks considering human factors of workers such as demographics and compensation. We deployed our framework to a popular crowdsourcing platform and conducted experiments with 1,919 workers collecting 160,345 human judgments. By routing microtasks to workers based on demographics and appropriate pay, our framework mitigates biases in the contributor sample and increases the hourly pay given to contributors. We discuss potential extensions and how it can promote transparency in crowdsourcing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {machine learning, ethics, crowdsourcing, bias},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300321,
author = {An, Pengcheng and Bakker, Saskia and Ordanovski, Sara and Taconis, Ruurd and Paffen, Chris L.E. and Eggen, Berry},
title = {Unobtrusively Enhancing Reflection-in-Action of Teachers through Spatially Distributed Ambient Information},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300321},
doi = {10.1145/3290605.3300321},
abstract = {Reflecting on their performance during classroom-teaching is an important competence for teachers. Such reflection-in-action (RiA) enables them to optimize teaching on the spot. But RiA is also challenging, demanding extra thinking in teachers' already intensive routines. Little is known on how HCI systems can facilitate teachers' RiA during classroom-teaching. To fill in this gap, we evaluate ClassBeacons, a system that uses spatially distributed lamps to depict teachers' ongoing performance on how they have divided their time and attention over students in the classroom. Empirical qualitative data from eleven teachers in 22 class periods show that this ambient information facilitated teachers' RiA without burdening teaching in progress. Based on our theoretical grounding and field evaluation, we contribute empirical knowledge about how an HCI system enhanced teachers' process of RiA as well as a set of design principles for unobtrusively supporting RiA.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {distributed cognition, reflection-in-action, teacher, ambient information system, periphery of attention, reflective practitioner},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300930,
author = {Marshall, Joe and Benford, Steve and Byrne, Richard and Tennent, Paul},
title = {Sensory Alignment in Immersive Entertainment},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300930},
doi = {10.1145/3290605.3300930},
abstract = {When we use digital systems to stimulate the senses, we typically stimulate only a subset of users' senses, leaving other senses stimulated by the physical world. This creates potential for misalignment between senses, where digital and physical stimulation give conflicting signals to users. We synthesize knowledge from HCI, traditional entertainments, and underlying sensory science research relating to how senses work when given conflicting signals. Using this knowledge we present a design dimension of sensory alignment, and show how this dimension presents opportunities for a range of creative strategies ranging from full alignment of sensory stimulation, up to extreme conflict between senses.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {senses, sensory misalignment, immersive computing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300355,
author = {Franinovi\'{c}, Karmen and Franzke, Luke},
title = {Shape Changing Surfaces and Structures: Design Tools and Methods for Electroactive Polymers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300355},
doi = {10.1145/3290605.3300355},
abstract = {Electroactive polymers (EAP) are a promising material for shape changing interfaces, soft robotics and other novel design explorations. However, the uptake of EAP prototyping in design, art and architecture has been slow due to limited commercial availability, challenging high voltage electronics and lack of simple fabrication techniques. This paper introduces DIY tools for building and activating EAP prototypes, together with design methods for making novel shape-changing surfaces and structures, outside of material science labs. We present iterations of our methods and tools, their use and evaluation in participatory workshops and public installations and how they affect the design outcomes. We discuss unique aesthetic and interactive experiences enabled by the organic and subtle movement of semi-transparent EAP membranes. Finally, we summarise the potential of design tools and methods to facilitate increased exploration of interactive EAP prototypes and outline future steps.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {embodied interaction, smart material interfaces, programmable materials, shape-changing interfaces, active materials, electroactive polymers},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300537,
author = {Kumar, Priya C. and Chetty, Marshini and Clegg, Tamara L. and Vitak, Jessica},
title = {Privacy and Security Considerations For Digital Technology Use in Elementary Schools},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300537},
doi = {10.1145/3290605.3300537},
abstract = {Elementary school educators increasingly use digital technologies to teach students, manage classrooms, and complete everyday tasks. Prior work has considered the educational and pedagogical implications of technology use, but little research has examined how educators consider privacy and security in relation to classroom technology use. To better understand what privacy and security mean to elementary school educators, we conducted nine focus groups with 25 educators across three metropolitan regions in the northeast U.S. Our findings suggest that technology use is an integral part of elementary school classrooms, that educators consider digital privacy and security through the lens of curricular and classroom management goals, and that lessons to teach children about digital privacy and security are rare. Using Bronfenbrenner's ecological systems theory, we identify design opportunities to help educators integrate privacy and security into decisions about digital technology use and to help children learn about digital privacy and security.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {technology use, privacy, elementary school, security},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300266,
author = {Antle, Alissa N. and McLaren, Elgin-Skye and Fiedler, Holly and Johnson, Naomi},
title = {Evaluating the Impact of a Mobile Neurofeedback App for Young Children at School and Home},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300266},
doi = {10.1145/3290605.3300266},
abstract = {About 18% of children in industrialized countries suffer from anxiety. We designed a mobile neurofeedback app, called Mind-Full, based on existing design guidelines. Our goal was for young children in lower socio-economic status schools to improve their ability to self-regulate anxiety by using Mind-Full. In this paper we report on quantitative outcomes from a sixteen-week field evaluation with 20 young children (aged 5 to 8). Our methodological contribution includes using a control group, validated measures of anxiety and stress, and assessing transfer and maintenance. Results from teacher and parent behavioral surveys indicated gains in children's ability to self-regulate anxiety at school and home; a decrease in anxious behaviors at home; and cortisol tests showed variable improvement in physiological stress levels. We contribute to HCI for mental health with evidence that it is viable to use a mobile app in lower socio-economic status schools to improve children's mental health.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {positive computing, children, field studies, self-regulation, brain computer interfaces, hci for mental health},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300546,
author = {Shin, Jo and Aceves Sep\'{u}lveda, Gabriela and Odom, William},
title = {"Collective Wisdom": Inquiring into Collective Homes as a Site for HCI Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300546},
doi = {10.1145/3290605.3300546},
abstract = {The home has been a major focus of the HCI community for over two decades. Despite this body of research, nascent works have argued that HCI's characterization of 'the home' remains narrow and requires more diverse accounts of domestic configurations. Our work contributes to this area through a four-month ethnography of three collective homes in Vancouver, Canada. Collective homes represent an alternative housing model that offers agency to individual members and the collective group by sharing values, resources, labour, space and memory. Our paper offers two contributions. First, we offer an in-depth design ethnography of three collective homes, attending to the values, ownership models, practices, and everyday interactions observed in the ongoing making of these domestic settings. Second, we interpret and synthesize our findings to provide new opportunities for expanding the way we conceptualize and design for 'the home' in HCI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {collective homes, domestic computing, ownership},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300765,
author = {Schuetz, Immo and Murdison, T. Scott and MacKenzie, Kevin J. and Zannoli, Marina},
title = {An Explanation of Fitts' Law-like Performance in Gaze-Based Selection Tasks Using a Psychophysics Approach},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300765},
doi = {10.1145/3290605.3300765},
abstract = {Eye gaze as an input method has been studied since the 1990s, to varied results: some studies found gaze to be more efficient than traditional input methods like a mouse, others far behind. Comparisons are often backed up by Fitts' Law without explicitly acknowledging the ballistic nature of saccadic eye movements. Using a vision science-inspired model, we here show that a Fitts'-like distribution of movement times can arise due to the execution of secondary saccades, especially when targets are small. Study participants selected circular targets using gaze. Seven different target sizes and two saccade distances were used. We then determined performance across target sizes for different sampling windows ("dwell times") and predicted an optimal dwell time range. Best performance was achieved for large targets reachable by a single saccade. Our findings highlight that Fitts' Law, while a suitable approximation in some cases, is an incomplete description of gaze interaction dynamics.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {saccades, eye movements, user interfaces, gaze input, fitts' law, gaze selection},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300263,
author = {Dagan, Ella and M\'{a}rquez Segura, Elena and Altarriba Bertran, Ferran and Flores, Miguel and Isbister, Katherine},
title = {Designing 'True Colors': A Social Wearable That Affords Vulnerability},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300263},
doi = {10.1145/3290605.3300263},
abstract = {Vulnerability is a common experience in everyday life and is frequently perceived as a flaw to be excised in technology design. Yet, research indicates it is an essential aspect of wholehearted living among others. In this paper, we present the design and deployment of 'True Colors', a novel wearable device intended to support social interaction in a live action roleplay game (LARP) setting. We describe the Research-through-Design process that helped us to discover and articulate the possibility space of vulnerability in the design of social wearables, as support for producing a sense of social empowerment and connection among wearers within the LARP. We draw conclusions that may be of value to others designing wearables and related technologies aimed at supporting co-located social interaction in games/play.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {caring, social touch", larp, co- located social play, "social wearables, research through design, embodied interaction, play-to-lose, vulnerability, social affordances, rtd, wearables, interruptions},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300573,
author = {Mentis, Helena M. and Madjaroff, Galina and Massey, Aaron K.},
title = {Upside and Downside Risk in Online Security for Older Adults with Mild Cognitive Impairment},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300573},
doi = {10.1145/3290605.3300573},
abstract = {Older adults are rapidly increasing their use of online services such as banking, social media, and email - services that come with subtle and serious security and privacy risks. Older adults with mild cognitive impairment (MCI) are particularly vulnerable to these risks because MCI can reduce their ability to recognize scams such as email phishing, follow recommended password guidelines, and consider the implications of sharing personal information. Older adults with MCI often cope with their impairments with the help of caregivers, including partners, children, and professional health personnel, when using and managing online services. Yet, this too carries security and privacy risks: sharing personal information with caregivers can create issues of agency, autonomy, and even risk embarrassment and information leakage; caregivers also do not always act in their charges' best interest. Through a series of interviews conducted in the US, we identify a spectrum of safeguarding strategies used and consider them through the lens of 'upside and downside risk' where there are tradeoffs between reduced privacy and maintaining older adults' autonomy and access to online services.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {dementia, cybersecurity, scams, risk, discussion},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300429,
author = {Cheng, Justin and Burke, Moira and Davis, Elena Goetz},
title = {Understanding Perceptions of Problematic Facebook Use: When People Experience Negative Life Impact and a Lack of Control},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300429},
doi = {10.1145/3290605.3300429},
abstract = {While many people use social network sites to connect with friends and family, some feel that their use is problematic, seriously affecting their sleep, work, or life. Pairing a survey of 20,000 Facebook users measuring perceptions of problematic use with behavioral and demographic data, we examined Facebook activities associated with problematic use as well as the kinds of people most likely to experience it. People who feel their use is problematic are more likely to be younger, male, and going through a major life event such as a breakup. They spend more time on the platform, particularly at night, and spend proportionally more time looking at profiles and less time browsing their News Feeds. They also message their friends more frequently. While they are more likely to respond to notifications, they are also more likely to deactivate their accounts, perhaps in an effort to better manage their time. Further, they are more likely to have seen content about social media or phone addiction. Notably, people reporting problematic use rate the site as more valuable to them, highlighting the complex relationship between technology use and well-being. A better understanding of problematic Facebook use can inform the design of context-appropriate and supportive tools to help people become more in control.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {facebook, problematic use},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300670,
author = {Nonnis, Antonella and Bryan-Kinns, Nick},
title = {Mazi: Tangible Technologies as a Channel for Collaborative Play},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300670},
doi = {10.1145/3290605.3300670},
abstract = {This paper investigates how haptic and auditory stimulation can be playfully implemented as an accessible and stimulating form of interaction for children. We present the design of Mazi, a sonic Tangible User Interface (TUI) designed to encourage spontaneous and collaborative play between children with high support needs autism. We report on a five week study of Mazi with five children aged between 6 and 9 years old at a Special Education Needs (SEN) school in London, UK. We found that collaborative play emerged from the interaction with the system especially in regards to socialization and engagement. Our study contributes to exploring the potential of user-centered TUI development as a channel to facilitate social interaction while providing sensory regulation for children with SENs.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social interaction, play, smart textiles, children, autism, tangible user interfaces, sensory integration},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300404,
author = {Elvitigala, Don Samitha and Matthies, Denys J.C. and David, L\"{o}ic and Weerasinghe, Chamod and Nanayakkara, Suranga},
title = {GymSoles: Improving Squats and Dead-Lifts by Visualizing the User's Center of Pressure},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300404},
doi = {10.1145/3290605.3300404},
abstract = {The correct execution of exercises, such as squats and dead-lifts, is essential to prevent various bodily injuries. Existing solutions either rely on expensive motion tracking or multiple Inertial Measurement Units (IMU) systems require an extensive set-up and individual calibration. This paper introduces a proof of concept, GymSoles, an insole prototype that provides feedback on the Centre of Pressure (CoP) at the feet to assist users with maintaining the correct body posture, while performing squats and dead-lifts. GymSoles was evaluated with 13 users in three conditions: 1) no feedback, 2) vibrotactile feedback, and 3) visual feedback. It has shown that solely providing feedback on the current CoP, results in a significantly improved body posture.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {workout performance, visual feedback, dead-lifts, centre of pressure, smart insoles, improving body posture, vibrotactile feedback, squats},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300874,
author = {Boukhelifa, Nadia and Bezerianos, Anastasia and Trelea, Ioan Cristian and Perrot, Nathalie M\'{e}jean and Lutton, Evelyne},
title = {An Exploratory Study on Visual Exploration of Model Simulations by Multiple Types of Experts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300874},
doi = {10.1145/3290605.3300874},
abstract = {Experts in different domains rely increasingly on simulation models of complex processes to reach insights, make decisions, and plan future projects. These models are often used to study possible trade-offs, as experts try to optimise multiple conflicting objectives in a single investigation. Understanding all the model intricacies, however, is challenging for a single domain expert. We propose a simple approach to support multiple experts when exploring complex model results. First, we reduce the model exploration space, then present the results on a shared interactive surface, in the form of a scatterplot matrix and linked views. To explore how multiple experts analyse trade-offs using this setup, we carried out an observational study focusing on the link between expertise and insight generation during the analysis process. Our results reveal the different exploration strategies and multi-storyline approaches that domain experts adopt during trade-off analysis, and inform our recommendations for collaborative model exploration systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visualization, collaboration, trade-off analysis, qualitative study, common ground, insight, scatterplot matrix, expertise, model exploration},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300779,
author = {Mayer, Peter and Gerber, Nina and Reinheimer, Benjamin and Rack, Philipp and Braun, Kristoffer and Volkamer, Melanie},
title = {I (Don't) See What You Typed There! Shoulder-Surfing Resistant Password Entry on Gamepads},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300779},
doi = {10.1145/3290605.3300779},
abstract = {Using gamepad-driven devices like games consoles is an activity frequently shared with others. Thus, shoulder-surfing is a serious threat. To address this threat, we present the first investigation of shoulder-surfing resistant text password entry on gamepads by (1) identifying the requirements of this context; (2) assessing whether shoulder-surfing resistant authentication schemes proposed in non-gamepad contexts can be viably adapted to meet these requirements; (3) proposing "Colorwheels", a novel shoulder-surfing resistant authentication scheme specifically geared towards this context; (4) using two different methodologies proposed in the literature for evaluating shoulder-surfing resistance to compare "Colorwheels", on-screen keyboards (the de facto standard in this context), and an existing shoulder-surfing resistant scheme which we identified during our assessment and adapted for the gamepad context; (5) evaluating all three schemes regarding their usability. Having applied different methodologies to measure shoulder-surfing resistance, we discuss their strengths and pitfalls and derive recommendations for future research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user study, authentication, gamepads, shoulder-surfng},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300297,
author = {Ma, Xiao and Cheng, Justin and Iyer, Shankar and Naaman, Mor},
title = {When Do People Trust Their Social Groups?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300297},
doi = {10.1145/3290605.3300297},
abstract = {Trust facilitates cooperation and supports positive outcomes in social groups, including member satisfaction, information sharing, and task performance. Extensive prior research has examined individuals' general propensity to trust, as well as the factors that contribute to their trust in specific groups. Here, we build on past work to present a comprehensive framework for predicting trust in groups. By surveying 6,383 Facebook Groups users about their trust attitudes and examining aggregated behavioral and demographic data for these individuals, we show that (1) an individual's propensity to trust is associated with how they trust their groups, (2) smaller, closed, older, more exclusive, or more homogeneous groups are trusted more, and (3) a group's overall friendship-network structure and an individual's position within that structure can also predict trust. Last, we demonstrate how group trust predicts outcomes at both individual and group level such as the formation of new friendship ties.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {facebook, trust, communities, groups},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300415,
author = {Yang, Qian and Cranshaw, Justin and Amershi, Saleema and Iqbal, Shamsi T. and Teevan, Jaime},
title = {Sketching NLP: A Case Study of Exploring the Right Things To Design with Language Intelligence},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300415},
doi = {10.1145/3290605.3300415},
abstract = {This paper investigates how to sketch NLP-powered user experiences. Sketching is a cornerstone of design innovation. When sketching, designers rapidly experiment with a number of abstract ideas using simple, tangible instruments such as drawings and paper prototypes. Sketching NLP-powered experiences, however, presents challenges, i.e. How to visualize abstract language interaction? How to ideate a broad range of technically feasible intelligent functionalities? As a first step towards understanding these challenges, we present a first-person account of our sketching process when designing intelligent writing assistance. We detail the challenges we encountered and emergent solutions, such as a new format of wireframe for sketching language interactions and a new wizard-of-oz-based NLP rapid prototyping method. Drawing on these findings, we discuss the importance of abstraction in sketching and other implications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {natural language processing, writing assistance, artificial intelligence, user experience},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300810,
author = {de Castro Leal, D\'{e}bora and Kr\"{u}ger, Max and Misaki, Kaoru and Randall, David and Wulf, Volker},
title = {Guerilla Warfare and the Use of New (and Some Old) Technology: Lessons from FARC's Armed Struggle in Colombia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300810},
doi = {10.1145/3290605.3300810},
abstract = {Studying armed political struggles from a CSCW perspective can throw the complex interactions between culture, technology, materiality and political conflict into sharp relief. Such studies highlight interrelations that otherwise remain under-remarked upon, despite their severe consequences. The present paper provides an account of the armed struggle of one of the Colombian guerrillas, FARC-EP, with the Colombian army. We document how radio-based communication became a crucial, but ambiguous infrastructure of war. The sudden introduction of localization technologies by the Colombian army presented a lethal threat to the guerrilla group. Our interviewees report a severe learning process to diminish this new risk, relying on a combination of informed beliefs and significant technical understanding. We end with a discussion of the role of HCI in considerations of ICT use in armed conflicts and introduce the concept of counter-appropriation as process of adapting one's practices to other's appropriation of technology in conflict.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {appropriation, political conflict, infrastructure, war},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300631,
author = {Berger, Arne and Odom, William and Storz, Michael and Bischof, Andreas and Kurze, Albrecht and Hornecker, Eva},
title = {The Inflatable Cat: Idiosyncratic Ideation of Smart Objects for the Home},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300631},
doi = {10.1145/3290605.3300631},
abstract = {Research on product experience has a history in investigating the sensory and emotional qualities of interacting with objects. However, this notion has not been fully expanded to the design space of co-designing smart objects. In this paper, we report on findings from a series of co-design workshops where we used the toolkit Loaded Dice in conjunction with a card set that aimed to support participants in reflecting the sensory qualities of domestic smart objects. We synthesize and interpret findings from our study to help illustrate how the workshops supported co-designers in creatively ideating concepts for emotionally valuable smart objects that better connect personal inputs with the output of smart objects. Our work contributes a case example of how a co-design approach that emphasizes situated sensory exploration can be effective in enabling co-designers to ideate concepts of idiosyncratic smart objects that closely relate to the characteristics of their domestic living situations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {sensory qualities, co-design method, emotional qualities, smart things, co-speculation, internet of things, co-design tool},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300276,
author = {Findlater, Leah and Chinh, Bonnie and Jain, Dhruv and Froehlich, Jon and Kushalnagar, Raja and Lin, Angela Carey},
title = {Deaf and Hard-of-Hearing Individuals' Preferences for Wearable and Mobile Sound Awareness Technologies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300276},
doi = {10.1145/3290605.3300276},
abstract = {To investigate preferences for mobile and wearable sound awareness systems, we conducted an online survey with 201 DHH participants. The survey explores how demographic factors affect perceptions of sound awareness technologies, gauges interest in specific sounds and sound characteristics, solicits reactions to three design scenarios (smartphone, smartwatch, head-mounted display) and two output modalities (visual, haptic), and probes issues related to social context of use. While most participants were highly interested in being aware of sounds, this interest was modulated by communication preference--that is, for sign or oral communication or both. Almost all participants wanted both visual and haptic feedback and 75% preferred to have that feedback on separate devices (e.g., haptic on smartwatch, visual on head-mounted display). Other findings related to sound type, full captions vs. keywords, sound filtering, notification styles, and social context provide direct guidance for the design of future mobile and wearable sound awareness systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {deaf, hard of hearing, hearing loss, mobile, online survey, sound awareness, user study, wearable},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300567,
author = {T\"{u}rkay, Selen and Adinolf, Sonam},
title = {Friending to Flame: How Social Features Affect Player Behaviours in an Online Collectible Card Game},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300567},
doi = {10.1145/3290605.3300567},
abstract = {Online Collectible Card Games (OCCGs) are enormously popular worldwide. Previous studies found that the social aspects of physical CCGs are crucial for player engagement. However, we know little about the different types of sociability that OCCGs afford. Nor to what extent they influence players' social experiences. This mixed method online survey study focuses on a representative OCCG, Hearthstone [24] to 1) identify and define social design features and examine the extent to which players' use of these features predict their sense of community; 2) investigate participants' attitudes towards and experiences with the game community. The results show that players rarely use social features, and these features contribute differently to predicting players' sense of community. We also found emergent toxic behaviors, afforded by the social features. Findings can inform the best practices and principles in the design of OCCGs, and contribute to our understanding of players' perceptions of OCCG communities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online collectible card games, player behaviors, social features},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300405,
author = {Oberd\"{o}rfer, Sebastian and Heidrich, David and Latoschik, Marc Erich},
title = {Usability of Gamified Knowledge Learning in VR and Desktop-3D},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300405},
doi = {10.1145/3290605.3300405},
abstract = {Affine Transformations (ATs) often escape an intuitive approach due to their high complexity. Therefore, we developed GEtiT that directly encodes ATs in its game mechanics and scales the knowledge's level of abstraction. This results in an intuitive application as well as audiovisual presentation of ATs and hence in a knowledge learning. We also developed a specific Virtual Reality (VR) version to explore the effects of immersive VR on the learning outcomes. This paper presents our approach of directly encoding abstract knowledge in game mechanics, the conceptual design of GEtiT and its technical implementation. Both versions are compared in regard to their usability in a user study. The results show that both GEtiT versions induce a high degree of flow and elicit a good intuitive use. They validate the effectiveness of the design and the resulting knowledge application requirements. Participants favored GEtiT VR thus showing a potentially higher learning quality when using VR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gamification, knowledge learning, serious games design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300804,
author = {Semertzidis, Nathan Arthur and Sargeant, Betty and Dwyer, Justin and Mueller, Florian Floyd and Zambetta, Fabio},
title = {Towards Understanding the Design of Positive Pre-Sleep Through a Neurofeedback Artistic Experience},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300804},
doi = {10.1145/3290605.3300804},
abstract = {Poor sleep has been acknowledged as an increasingly prevalent global health concern, however, how to design for promoting sleep is relatively underexplored. We propose neurofeedback technology may potentially facilitate restfulness and sleep onset, and we explore this through the creation and study of "Inter-Dream", a novel multisensory interactive artistic experience driven by neurofeedback. Twelve participants individually rested, augmented by Inter-Dream. Results demonstrated: statistically significant decreases in pre-sleep cognitive arousal (p = .01), negative emotion (p = .008), and negative affect (p = .004). EEG readings were also indicative of restorative restfulness and cognitive stillness, while interview responses described experiences of mindfulness and playful self-exploration. Taken together, our work highlights neurofeedback as a potential pathway for future research in the promotion of sleep, while also suggesting strategies for designing towards this within the context of pre-sleep.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {brain-computer interface, interactive art, multisensory experience, neurofeedback, pre-sleep},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300741,
author = {Hsueh, Stacy and Alaoui, Sarah Fdili and Mackay, Wendy E.},
title = {Understanding Kinaesthetic Creativity in Dance},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300741},
doi = {10.1145/3290605.3300741},
abstract = {Kinaesthetic creativity refers to the body's ability to generate alternate futures in activities such as role-playing in participatory design workshops. This has relevance not only to the design of methods for inspiring creativity but also to the design of systems that promote engaging experiences via bodily interaction. This paper probes this creative process by studying how dancers interact with technology to generate ideas. We developed a series of parameterized interactive visuals and asked dance practitioners to use them in generating movement materials. From our study, we define a taxonomy that comprises different relationships and movement responses dancers form with the visuals. Against this taxonomy, we describe six types of interaction patterns and demonstrate how dance creativity is driven by the ability to shift between these patterns. We then propose a set of interaction design qualities to support kinaesthetic creativity.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {movement generation, dance, embodied interaction, kinaesthetic creativity},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300674,
author = {Xu, Wenge and Liang, Hai-Ning and Zhao, Yuxuan and Yu, Difeng and Monteiro, Diego},
title = {DMove: Directional Motion-Based Interaction for Augmented Reality Head-Mounted Displays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300674},
doi = {10.1145/3290605.3300674},
abstract = {We present DMove, directional motion-based interaction for Augmented Reality (AR) Head-Mounted Displays (HMDs) that is both hands- and device-free. It uses directional walk-ing as a way to interact with virtual objects. To use DMove, a user needs to perform directional motions such as mov-ing one foot forward or backward. In this research, we first investigate the recognition accuracy of the motion direc-tions of our method and the social acceptance of this type of interactions together with users' comfort rating for each direction. We then optimize its design and conduct a sec-ond study to compare DMove in task performance and user preferences (workload, motion sickness, user experience), with two approaches-Hand interaction (Meta 2-like) and Head+Hand interaction (HoloLens-like) for menu selection tasks. Based on the results of these two studies, we provide a set of guidelines for DMove and further demonstrate two applications that utilize directional motions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {menu selection, augmented reality, head-mounted display, motion direction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300414,
author = {Albaugh, Lea and Hudson, Scott and Yao, Lining},
title = {Digital Fabrication of Soft Actuated Objects by Machine Knitting},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300414},
doi = {10.1145/3290605.3300414},
abstract = {With recent interest in shape-changing interfaces, material-driven design, wearable technologies, and soft robotics, digital fabrication of soft actuatable material is increasingly in demand. Much of this research focuses on elastomers or non-stretchy air bladders. Computationally-controlled machine knitting offers an alternative fabrication technology which can rapidly produce soft textile objects that have a very different character: breathable, lightweight, and pleasant to the touch. These machines are well established and optimized for the mass production of garments, but compared to other digital fabrication techniques such as CNC machining or 3D printing, they have received much less attention as general purpose fabrication devices. In this work, we explore new ways to employ machine knitting for the creation of actuated soft objects. We describe the basic operation of this type of machine, then show new techniques for knitting tendon-based actuation into objects. We explore a series of design strategies for integrating tendons with shaping and anisotropic texture design. Finally, we investigate different knit material properties, including considerations for motor control and sensing.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {soft materials, soft actuator, computational crafts, additive manufacturing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300854,
author = {Guzdial, Matthew and Liao, Nicholas and Chen, Jonathan and Chen, Shao-Yu and Shah, Shukan and Shah, Vishwa and Reno, Joshua and Smith, Gillian and Riedl, Mark O.},
title = {Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300854},
doi = {10.1145/3290605.3300854},
abstract = {Machine learning advances have afforded an increase in algorithms capable of creating art, music, stories, games, and more. However, it is not yet well-understood how machine learning algorithms might best collaborate with people to support creative expression. To investigate how practicing designers perceive the role of AI in the creative process, we developed a game level design tool for Super Mario Bros.-style games with a built-in AI level designer. In this paper we discuss our design of the Morai Maker intelligent tool through two mixed-methods studies with a total of over one-hundred participants. Our findings are as follows: (1) level designers vary in their desired interactions with, and role of, the AI, (2) the AI prompted the level designers to alter their design practices, and (3) the level designers perceived the AI as having potential value in their design practice, varying based on their desired role for the AI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {artificial intelligence, human-ai interaction, human computer collaboration},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300480,
author = {Baytas, Mehmet Aydin and \c{C}ay, Damla and Zhang, Yuchong and Obaid, Mohammad and Yanta\c{c}, Asim Evren and Fjeld, Morten},
title = {The Design of Social Drones: A Review of Studies on Autonomous Flyers in Inhabited Environments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300480},
doi = {10.1145/3290605.3300480},
abstract = {The design space of social drones, where autonomous flyers operate in close proximity to human users or bystanders, is distinct from use cases involving a remote human operator and/or an uninhabited environment; and warrants foregrounding human-centered design concerns. Recently, research on social drones has followed a trend of rapid growth. This paper consolidates the current state of the art in human-centered design knowledge about social drones through a review of relevant studies, scaffolded by a descriptive framework of design knowledge creation. Our analysis identified three high-level themes that sketch out knowledge clusters in the literature, and twelve design concerns which unpack how various dimensions of drone aesthetics and behavior relate to pertinent human responses. These results have the potential to inform and expedite future research and practice, by supporting readers in defining and situating their future contributions. The materials and results of our analysis are also published in an open online repository that intends to serve as a living hub for a community of researchers and designers working with social drones.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {drone design, design knowledge, autonomous agents, user studies, social drones, human-drone interaction, empirical studies, drones},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300715,
author = {Henderson, Jay and Avery, Jeff and Grisoni, Laurent and Lank, Edward},
title = {Leveraging Distal Vibrotactile Feedback for Target Acquisition},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300715},
doi = {10.1145/3290605.3300715},
abstract = {Many touch based interactions provide limited opportunities for direct tactile feedback; examples include multi-user touch displays, augmented reality based projections on passive surfaces, and mid-air input. In this paper, we consider distal feedback, through vibrotactile stimulation on a smart-watch placed on the user's non-dominant wrist, as an alternative feedback mechanism to interaction location vibrotactile feedback, under the user's finger. We compare the effectiveness of interaction location feedback vs. distal feedback through a Fitts's Law task completed on a smartphone. Results show that distal and interaction location feedback both reduce errors in target acquisition and exhibit statistically comparable performance, suggesting that distal vibrotactile feedback is a suitable alternative when interaction location feedback is not readily available.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {targeting, vibrotactile feedback, smartwatch, touchscreen},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300890,
author = {Forman, Jack and Tabb, Taylor and Do, Youngwook and Yeh, Meng-Han and Galvin, Adrian and Yao, Lining},
title = {ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300890},
doi = {10.1145/3290605.3300890},
abstract = {Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction (HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics, and human hair, accessible line-based actuators are very limited beyond shape memory alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel, yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled nylon thread actuator with a silicone coating. This composite thread actuator exhibits unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily woven or sewn, hence it has a great potential as an embedded line-based actuator for HCI purposes. In this paper, we explain the material mechanisms and manufacturing approaches, followed by some performance tests and application demonstrations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {artificial muscles, shrinking actuator, coiled thread actuators, thread actuators, twisting actuator, reversibility, soft actuator, torsional actuator, linear actuator},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300917,
author = {Li, Zhen and Annett, Michelle and Hinckley, Ken and Singh, Karan and Wigdor, Daniel},
title = {HoloDoc: Enabling Mixed Reality Workspaces That Harness Physical and Digital Content},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300917},
doi = {10.1145/3290605.3300917},
abstract = {Prior research identified that physical paper documents have many positive attributes, for example natural tangibility and inherent physical flexibility. When documents are presented on digital devices, however, they can provide unique functionality to users, such as the ability to search, view dynamic multimedia content, and make use of indexing. This work explores the fusion of physical and digital paper documents. It first presents the results of a study that probed how users perform document-intensive analytical tasks when both physical and digital versions of documents were available. The study findings then informed the design of HoloDoc, a mixed reality system that augments physical artifacts with rich interaction and dynamic virtual content. Finally, we present the interaction techniques that HoloDoc affords, and the results of a second study that assessed HoloDoc's utility when working with digital and physical copies of academic articles.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mixed reality, digital pen input, reading behavior, augmented reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300845,
author = {Kim, Young-Ho and Choe, Eun Kyoung and Lee, Bongshin and Seo, Jinwook},
title = {Understanding Personal Productivity: How Knowledge Workers Define, Evaluate, and Reflect on Their Productivity},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300845},
doi = {10.1145/3290605.3300845},
abstract = {Productivity tracking tools often determine productivity based on the time interacting with work-related applications. To deconstruct productivity's diverse and nebulous nature, we investigate how knowledge workers conceptualize personal productivity and delimit productive tasks in both work and non-work contexts. We report a 2-week diary study followed by a semi-structured interview with 24 knowledge workers. Participants captured productive activities and provided the rationale for why the activities were assessed to be productive. They reported a wide range of productive activities beyond typical desk-bound work-ranging from having a personal conversation with dad to getting a haircut. We found six themes that characterize the productivity assessment-work product, time management, worker's state, attitude toward work, impact &amp; benefit, and compound task and identified how participants interleaved multiple facets when assessing their productivity. We discuss how these findings could inform the design of a comprehensive productivity tracking system that covers a wide range of productive activities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {self-tracking, self-monitoring, knowledge worker, diary study, productivity tracking, productivity, personal informatics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300789,
author = {Cheng, Hao-Fei and Wang, Ruotong and Zhang, Zheng and O'Connell, Fiona and Gray, Terrance and Harper, F. Maxwell and Zhu, Haiyi},
title = {Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300789},
doi = {10.1145/3290605.3300789},
abstract = {Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' "right to explanation". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and "white-box" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {algorithmic decision-making, explanation interfaces},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300515,
author = {Kelly, Ryan M. and Ferdous, Hasan Shahid and Wouters, Niels and Vetere, Frank},
title = {Can Mobile Augmented Reality Stimulate a Honeypot Effect? Observations from Santa's Lil Helper},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300515},
doi = {10.1145/3290605.3300515},
abstract = {In HCI, the honeypot effect describes a form of audience engagement in which a person's interaction with a technology stimulates passers-by to observe, approach and engage in an interaction themselves. In this paper we explore the potential for honeypot effects to arise in the use of mobile augmented reality (AR) applications in urban spaces. We present an observational study of Santa's Lil Helper, a mobile AR game that created a Christmas-themed treasure hunt in a metropolitan area. Our study supports a consideration of three factors that may impede the honeypot effect: the presence of people in relation to the game and its interactive components; the visibility of gameplay in urban space; and the extent to which the game permits a shared experience. We consider how these factors can inform the design of future AR experiences that are capable of stimulating honeypot effects in public space.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {augmented reality, public space, honeypot effect, audience},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300560,
author = {Kovacs, Geza and Gregory, Drew Mylander and Ma, Zilin and Wu, Zhengxuan and Emami, Golrokh and Ray, Jacob and Bernstein, Michael S.},
title = {Conservation of Procrastination: Do Productivity Interventions Save Time Or Just Redistribute It?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300560},
doi = {10.1145/3290605.3300560},
abstract = {Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {distractions and interruptions, behavior change},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300877,
author = {Ion, Alexandra and Lindlbauer, David and Herholz, Philipp and Alexa, Marc and Baudisch, Patrick},
title = {Understanding Metamaterial Mechanisms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300877},
doi = {10.1145/3290605.3300877},
abstract = {In this paper, we establish the underlying foundations of mechanisms that are composed of cell structures---known as metamaterial mechanisms. Such metamaterial mechanisms were previously shown to implement complete mechanisms in the cell structure of a 3D printed material, without the need for assembly. However, their design is highly challenging. A mechanism consists of many cells that are interconnected and impose constraints on each other. This leads to unobvious and non-linear behavior of the mechanism, which impedes user design. In this work, we investigate the underlying topological constraints of such cell structures and their influence on the resulting mechanism. Based on these findings, we contribute a computational design tool that automatically creates a metamaterial mechanism from user-defined motion paths. This tool is only feasible because our novel abstract representation of the global constraints highly reduces the search space of possible cell arrangements.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mechanism, metamaterials, fabrication, computational design, microstructure},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300314,
author = {Spaa, Anne and Durrant, Abigail and Elsden, Chris and Vines, John},
title = {Understanding the Boundaries between Policymaking and HCI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300314},
doi = {10.1145/3290605.3300314},
abstract = {There is a growing body of literature in HCI examining the intersection between policymaking and technology research. However, what it means to engage in policymaking in our field, or the ways in which evidence from HCI studies is translated into policy, is not well understood. We report on interviews with 11 participants working at the intersection of technology research and policymaking. Analysis of this data highlights how evidence is understood and made sense of in policymaking processes, what forms of evidence are privileged over others, and the work that researchers engage in to meaningfully communicate their work to policymaking audiences. We discuss how our findings pose challenges for certain traditions of research in HCI, yet also open up new policy opportunities for those engaging in more speculative research practices. We conclude by discussing three ways forward that the HCI community can explore to increase engagement with policymaking contexts.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {public policy, research impact, qualitative studies, think tanks},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300786,
author = {Schwab, Michail and Hao, Sicheng and Vitek, Olga and Tompkin, James and Huang, Jeff and Borkin, Michelle A.},
title = {Evaluating Pan and Zoom Timelines and Sliders},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300786},
doi = {10.1145/3290605.3300786},
abstract = {Pan and zoom timelines and sliders help us navigate large time series data. However, designing efficient interactions can be difficult. We study pan and zoom methods via crowd-sourced experiments on mobile and computer devices, asking which designs and interactions provide faster target acquisition. We find that visual context should be limited for low-distance navigation, but added for far-distance navigation; that timelines should be oriented along the longer axis, especially on mobile; and that, as compared to default techniques, double click, hold, and rub zoom appear to scale worse with task difficulty, whereas brush and especially ortho zoom seem to scale better. Software and data used in this research are available as open source.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {zoom, touch, interaction, multiscale, mobile, evaluation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300912,
author = {Kim, Yea-Seul and Walls, Logan A. and Krafft, Peter and Hullman, Jessica},
title = {A Bayesian Cognition Approach to Improve Data Visualization},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300912},
doi = {10.1145/3290605.3300912},
abstract = {People naturally bring their prior beliefs to bear on how they interpret the new information, yet few formal models exist for accounting for the influence of users' prior beliefs in interactions with data presentations like visualizations. We demonstrate a Bayesian cognitive model for understanding how people interpret visualizations in light of prior beliefs and show how this model provides a guide for improving visualization evaluation. In a first study, we show how applying a Bayesian cognition model to a simple visualization scenario indicates that people's judgments are consistent with a hypothesis that they are doing approximate Bayesian inference. In a second study, we evaluate how sensitive our observations of Bayesian behavior are to different techniques for eliciting people subjective distributions, and to different datasets. We find that people don't behave consistently with Bayesian predictions for large sample size datasets, and this difference cannot be explained by elicitation technique. In a final study, we show how normative Bayesian inference can be used as an evaluation framework for visualizations, including of uncertainty.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visualization, uncertainty elicitation, bayesian cognition},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300836,
author = {Seering, Joseph and Fang, Tianmi and Damasco, Luca and Chen, Mianhong 'Cherie' and Sun, Likang and Kaufman, Geoff},
title = {Designing User Interface Elements to Improve the Quality and Civility of Discourse in Online Commenting Behaviors},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300836},
doi = {10.1145/3290605.3300836},
abstract = {Ensuring high-quality, civil social interactions remains a vexing challenge in many online spaces. In the present work, we introduce a novel approach to address this problem: using psychologically "embedded'' CAPTCHAs containing stimuli intended to prime positive emotions and mindsets. An exploratory randomized experiment (N = 454 Mechanical Turk workers) tested the impact of eight new CAPTCHA designs implemented on a simulated, politically charged comment thread. Results revealed that the two interventions that were the most successful at activating positive affect also significantly increased the positivity of tone and analytical complexity of argumentation in participants' responses. A focused follow-up experiment (N = 120 Mechanical Turk workers) revealed that exposure to CAPTCHAs featuring image sets previously validated to evoke low-arousal positive emotions significantly increased the positivity of sentiment and the levels of complexity and social connectedness in participants' posts. We offer several explanations for these results and discuss the practical and ethical implications of designing interfaces to influence discourse in online forums.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {commenting, captchas, online communities, persuasive design, user interfaces},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300635,
author = {Stevens, Gunnar and Bossauer, Paul and Vonholdt, Stephanie and Pakusch, Christina},
title = {Using Time and Space Efficiently in Driverless Cars: Findings of a Co-Design Study},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300635},
doi = {10.1145/3290605.3300635},
abstract = {The alternative use of travel time is a widely discussed benefits of driverless cars. We therefore conducted 14 co-design sessions to examine how people manage their time, to determine how they perceive the value of time in driverless cars and derive design implications. Our findings suggest that driverless mobility will affect people's use of travel time and their time management in general. The participants repeatedly stated the desire of completing tasks while traveling to save time for activities that are normally neglected in everyday life. Using travel time efficiently requires using car space efficiently. We found out that the design concept of tiny houses could serve as common design pattern to deal with the limited space within cars and support diverse needs.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {co-design, car interior design, value of time, self-driving cars, design-fiction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300484,
author = {Ashktorab, Zahra and Jain, Mohit and Liao, Q. Vera and Weisz, Justin D.},
title = {Resilient Chatbots: Repair Strategy Preferences for Conversational Breakdowns},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300484},
doi = {10.1145/3290605.3300484},
abstract = {Text-based conversational systems, also referred to as chatbots, have grown widely popular. Current natural language understanding technologies are not yet ready to tackle the complexities in conversational interactions. Breakdowns are common, leading to negative user experiences. Guided by communication theories, we explore user preferences for eight repair strategies, including ones that are common in commercially-deployed chatbots (e.g., confirmation, providing options), as well as novel strategies that explain characteristics of the underlying machine learning algorithms. We conducted a scenario-based study to compare repair strategies with Mechanical Turk workers (N=203). We found that providing options and explanations were generally favored, as they manifest initiative from the chatbot and are actionable to recover from breakdowns. Through detailed analysis of participants' responses, we provide a nuanced understanding on the strengths and weaknesses of each repair strategy.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {grounding, chatbots, repair, conversational breakdown, conversational agents},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300708,
author = {Reinhardt, Daniel and Hurtienne, J\"{o}rn},
title = {Only One Item Left? Heuristic Information Trumps Calorie Count When Supporting Healthy Snacking Under Low Self-Control},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300708},
doi = {10.1145/3290605.3300708},
abstract = {Pursuing the goal of a healthy diet may be challenging, especially when self-control resources are low. Yet many persuasive user interfaces fostering healthy choices are designed for situations with ample self-control, e.g. showing nutritional information to support reflective decision making. In this paper we propose that under low self-control, persuasive user interfaces need to rely on simple heuristic decision making to be successful. We report an experiment that tested this assumption in a 2 (low vs. high self-control) x 2 (calorie vs. heuristic information) design. The results reveal a significant interaction effect. Participants with low self-control resources chose the healthy snack more often when snacks were labelled with heuristic information than when they were labelled with calorie information. Both strategies were about equally successful for participants with high self-control. Exploiting situations of low self-control with heuristic information is a new and promising approach to designing persuasive technology for healthy eating.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {persuasive technology, heuristics, food choice, ego depletion, self-control},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300440,
author = {Di Campli San Vito, Patrizia and Shakeri, G\"{o}zel and Brewster, Stephen and Pollick, Frank and Brown, Edward and Skrypchuk, Lee and Mouzakitis, Alexandros},
title = {Haptic Navigation Cues on the Steering Wheel},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300440},
doi = {10.1145/3290605.3300440},
abstract = {Haptic feedback is used in cars to reduce visual inattention. While tactile feedback like vibration can be influenced by the car's movement, thermal and cutaneous push feedback should be independent of such interference. This paper presents two driving simulator studies investigating novel tactile feedback on the steering wheel for navigation. First, devices on one side of the steering wheel were warmed, indicating the turning direction, while those on the other side were cooled. This thermal feedback was compared to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m before the turn and to 91.7% correct turns. Speech had perfect recognition for both. In the second experiment, only the destination side was indicated thermally, and this design was compared to cutaneous push feedback. The simplified thermal feedback design did not increase recognition, but cutaneous push feedback had high recognition rates (100% for 200 m warnings, 98% for turns).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {tactile, in-car, cutaneous push, audio, thermal, haptic, feedback},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300696,
author = {Widdicks, Kelly and Hazas, Mike and Bates, Oliver and Friday, Adrian},
title = {Streaming, Multi-Screens and YouTube: The New (Unsustainable) Ways of Watching in the Home},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300696},
doi = {10.1145/3290605.3300696},
abstract = {Internet use and online services underpin everyday life, and the resultant energy demand is almost entirely hidden, yet significant and growing: it is anticipated to reach 21% of global electricity demand by 2030 and to eclipse half the greenhouse gas emissions of transportation by 2040. Driving this growth, real-time video streaming ('watching') is estimated at around 50% of all peak data traffic. Using a mixed-methods analysis of the use of 66 devices (e.g. smart TVs, tablets) across 20 participants in 9 households, we reveal the online activity of domestic watching and provide a detailed exploration of video-on-demand activities. We identify new ways in which watching is transitioning in more rather than less data demanding directions; and explore the role HCI may play in reducing this growing data demand. We further highlight implications for key HCI and societal stakeholders (policy makers, service providers, network engineers) to tackle this important issue.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {data demand, watching, hci, households, sustainability, devices, policy, video streaming, everyday life, service design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300435,
author = {Ding, Xianghua and Jiang, Yanqi and Qin, Xiankang and Chen, Yunan and Zhang, Wenqiang and Qi, Lizhe},
title = {Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300435},
doi = {10.1145/3290605.3300435},
abstract = {With the recent advancement in computer vision, Artificial Intelligence (AI), and mobile technologies, it has become technically feasible for computerized Face Reading Technologies (FRTs) to learn about one's health in everyday settings. However, how to design FRT-based applications for everyday health practices remains unexplored. This paper presents a design study with a technology probe called Faced, a mobile health checkup application based on the facial diagnosis method from Traditional Chinese Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage modes and highlights a number of critical design issues in the use of FRTs for everyday health, including adaptability, practicality, sensitivity, and trustworthiness. We end by discussing design implications to address the unique challenges of fully integrating FRTs into everyday health practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {self care, health monitoring, design study, health, facial diagnosis, wellbeing, face reading technologies, traditional chinese medicine, everyday healthcare, tcm},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300359,
author = {Young, Alyson L. and Miller, Andrew D.},
title = {"This Girl is on Fire": Sensemaking in an Online Health Community for Vulvodynia},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300359},
doi = {10.1145/3290605.3300359},
abstract = {Online health communities (OHCs) allow people living with a shared diagnosis or medical condition to connect with peers for social support and advice. OHCs have been well studied in conditions like diabetes and cancer, but less is known about their role in enigmatic diseases with unknown or complex causal mechanisms. In this paper, we study one such condition: Vulvodynia, a chronic pain syndrome of the vulvar region. Through observations of and interviews with members of a vulvodynia Facebook group, we found that while the interaction types are broadly similar to those found in other OHCs, the women spent more time seeking basic information and building individualized management plans. They also encounter significant emotional and interpersonal challenges, which they discuss with each other. We use this study to extend the field's understanding of OHCs, and to propose implications for the design of self-tracking tools to support sensemaking in enigmatic conditions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sensemaking, self-tracking, enigmatic disease, online health communities, vulvodynia},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300896,
author = {Dereshev, Dmitry and Kirk, David and Matsumura, Kohei and Maeda, Toshiyuki},
title = {Long-Term Value of Social Robots through the Eyes of Expert Users},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300896},
doi = {10.1145/3290605.3300896},
abstract = {Socially-enabled digital technologies have attracted academic interest for decades, with recent commercial examples of Siri and Alexa, capturing public attention. However, despite ubiquitous visions of a robotic future, very few fully-fledged social robots are currently available to consumers. To improve their designs, studies of their long-term use are particularly valuable, but are currently unavailable. To address this gap, we report on interviews with four long-term users of Pepper - a social robot introduced in 2014. Our thematic analysis elicited insights across three kinds of value Pepper brought to its users: utilitarian functionality; the community that formed around Pepper; and a personal value of affection. We focus on two contributions those values bring to social robot design: social robots as social proxies, alleviating disabilities or acting akin to social media profiles; and robot nurturing as a design construct, going beyond purely utilitarian or hedonistic perspectives on robots.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social, acceptance, value, long-term, pepper, robot, human-robot interaction (hri), interview},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300474,
author = {Peck, Evan M. and Ayuso, Sofia E. and El-Etr, Omar},
title = {Data is Personal: Attitudes and Perceptions of Data Visualization in Rural Pennsylvania},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300474},
doi = {10.1145/3290605.3300474},
abstract = {Many of the guidelines that inform how designers create data visualizations originate in studies that unintentionally exclude populations that are most likely to be among the 'data poor'. In this paper, we explore which factors may drive attention and trust in rural populations with diverse economic and educational backgrounds - a segment that is largely underrepresented in the data visualization literature. In 42 semi-structured interviews in rural Pennsylvania (USA), we find that a complex set of factors intermix to inform attitudes and perceptions about data visualization - including educational background, political affiliation, and personal experience. The data and materials for this research can be found at https://osf.io/uxwts/},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {information literacy, rural, data, information visualization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300331,
author = {Baloup, Marc and Pietrzak, Thomas and Casiez, G\'{e}ry},
title = {RayCursor: A 3D Pointing Facilitation Technique Based on Raycasting},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300331},
doi = {10.1145/3290605.3300331},
abstract = {Raycasting is the most common target pointing technique in virtual reality environments. However, performance on small and distant targets is impacted by the accuracy of the pointing device and the user's motor skills. Current pointing facilitation techniques are currently only applied in the context of the virtual hand, i.e. for targets within reach. We propose enhancements to Raycasting: filtering the ray, and adding a controllable cursor on the ray to select the nearest target. We describe a series of studies for the design of the visual feedforward, filtering technique, as well as a comparative study between different 3D pointing techniques. Our results show that highlighting the nearest target is one of the most efficient visual feedforward technique. We also show that filtering the ray reduces error rate in a drastic way. Finally we show the benefits of RayCursor compared to Raycasting and another technique from the literature.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual feedforward, pointing technique, virtual reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300850,
author = {Matviienko, Andrii and Ananthanarayan, Swamy and El Ali, Abdallah and Heuten, Wilko and Boll, Susanne},
title = {NaviBike: Comparing Unimodal Navigation Cues for Child Cyclists},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300850},
doi = {10.1145/3290605.3300850},
abstract = {Navigation systems for cyclists are commonly screen-based devices mounted on the handlebar which show map information. Typically, adult cyclists have to explicitly look down for directions. This can be distracting and challenging for children, given their developmental differences in motor and perceptual-motor abilities compared with adults. To address this issue, we designed different unimodal cues and explored their suitability for child cyclists through two experiments. In the first experiment, we developed an indoor bicycle simulator and compared auditory, light, and vibrotactile navigation cues. In the second experiment, we investigated these navigation cues in-situ in an outdoor practice test track using a mid-size tricycle. To simulate road distractions, children were given an additional auditory task in both experiments. We found that auditory navigational cues were the most understandable and the least prone to navigation errors. However, light and vibrotactile cues might be useful for educating younger child cyclists.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {unimodal navigation cues, bicycle simulator, navigation for child cyclists},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300763,
author = {Fafard, Dylan and Stavness, Ian and Dechant, Martin and Mandryk, Regan and Zhou, Qian and Fels, Sidney},
title = {FTVR in VR: Evaluation of 3D Perception With a Simulated Volumetric Fish-Tank Virtual Reality Display},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300763},
doi = {10.1145/3290605.3300763},
abstract = {Spherical fish tank virtual reality (FTVR) displays attempt to create a virtual "crystal ball" experience using head-tracked rendering. Almost all of these systems have omitted stereo cues, making them easy to build, but it is not clear how much this omission degrades the 3D experience. In this study, we evaluate performance and subjective effects of stereo on 3D perception and interaction tasks with a spherical FTVR display. To control for calibration error and tracking latency, we perform the evaluation on a simulated spherical display in VR. The results of our study provide a clear recommendation for the design and use of spherical FTVR displays: while omitting stereo may not be readily apparent for users, their performance will be significantly degraded (20% - 91% increase in median task time). Therefore, including stereo viewing in spherical displays is critical for use in FTVR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3d perception, fish tank virtual reality, spherical display},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300252,
author = {Nontasil, Pawarat and Payne, Stephen J.},
title = {Emotional Utility and Recall of the Facebook News Feed},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300252},
doi = {10.1145/3290605.3300252},
abstract = {We report a laboratory study (N=53) in which participants browsed their own Facebook news feeds for 10-15 minutes, choosing exactly when to quit, and later rated the overall emotional utility of the episode before attempting to recall threads. Finally, the emotional utility of each encountered thread was rated while looking over a recording of the interaction. We report that Facebook browsing was, overall, an emotionally positive experience; that recall of threads exhibited classic primacy and recency serial order effects; that recalled threads were both more positive and more valenced (less neutral) on average, than forgotten threads; and that overall emotional valence judgments were predicted, statistically, by the peak and end thread judgments. We find no evidence that local quit decisions were driven by the emotional utility of threads. In the light of these findings, we discuss the suggestion that emotional utility might partly explain the attractiveness of reading the news feed, and that an emotional memory bias might further increase the attractiveness of the newsfeed in prospect.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {information addiction, facebook, emotional utility, the peak-end rule},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300625,
author = {Kim, Minju and Lee, Jungjin},
title = {PicMe: Interactive Visual Guidance for Taking Requested Photo Composition},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300625},
doi = {10.1145/3290605.3300625},
abstract = {PicMe is a mobile application that provides interactive on-screen guidance that helps the user take pictures of a composition that another person requires. Once the requester captures a picture of the desired composition and delivers it to the user (photographer), a 2.5D guidance system, called the virtual frame, guides the user in real-time by showing a three-dimensional composition of the target image (i.e., size and shape). In addition, according to the matching accuracy rate, we provide a small-sized target image in an inset window as feedback and edge visualization for further alignment of the detail elements. We implemented PicMe to work fully in mobile environments. We then conducted a preliminary user study to evaluate the effectiveness of PicMe compared to traditional 2D guidance methods. The results show that PicMe helps users reach their target images more accurately and quickly by giving participants more confidence in their tasks.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {photography assistance, interactive visual guidance, photo composition, mobile application},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300703,
author = {Ramirez Gomez, Argenis and Gellersen, Hans},
title = {SuperVision: Playing with Gaze Aversion and Peripheral Vision},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300703},
doi = {10.1145/3290605.3300703},
abstract = {In this work, we challenge the Gaze interaction paradigm "What you see is what you get" to introduce "playing with peripheral vision". We developed the conceptual framework to introduce this novel gaze-aware game dynamic. We illustrated the concept with SuperVision, a collection of three games that play with peripheral vision. We propose perceptual and interaction challenges that require players not to look and rely on their periphery. To validate the game dynamic and experience, we conducted a user study with twenty-four participants. Results show how the game concept created an engaging and playful experience playing with peripheral vision. Participants showed proficiency in overcoming the game challenges, developing clear strategies to succeed. Moreover, we found evidence that playing the game can affect our visual skills, with greater peripheral awareness.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {eye tracking, gaze interaction, play, peripheral vision, games, interaction design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300380,
author = {Lessel, Pascal and Altmeyer, Maximilian and Schmeer, Lea Verena and Kr\"{u}ger, Antonio},
title = {"Enable or Disable Gamification?": Analyzing the Impact of Choice in a Gamified Image Tagging Task},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300380},
doi = {10.1145/3290605.3300380},
abstract = {This paper investigates a simple form of customization: giving users the choice to enable or disable gamification. We present a study (N=77) in the context of image tagging, in which a gamification approach was shown to be effective in previous work. In our case, some participants could enable or disable gamification after they had experienced the task with and without it. Other participants had no choice and did the task with or without game elements. The results indicate that those who are not attracted by the elements can be motivated to tag more through this choice. In contrast, those that like the elements are not affected by it. This suggests that systems should provide the option to disable gamification in the absence of more sophisticated tailoring.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {decisions, "bottom-up", customization, self-tailoring},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300494,
author = {Martelaro, Nikolas and Teevan, Jaime and Iqbal, Shamsi T.},
title = {An Exploration of Speech-Based Productivity Support in the Car},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300494},
doi = {10.1145/3290605.3300494},
abstract = {In-car intelligent assistants offer the opportunity to help drivers productively use previously unclaimed time during their commute. However, engaging in secondary tasks can reduce attention on driving and thus may affect road safety. Any interface used while driving, even if speech-based, cannot consider non-driving tasks in isolation of driving---alerts for safer driving and timing of the non-driving tasks are crucial to maintaining safety. In this work, we explore experiences with a speech-based assistant that attempts to help drivers safely complete complex productivity tasks. Via a controlled simulator study, we look at how level of support and road context alerts from the assistant influence a driver's ability to drive safely while writing a document or creating slides via speech. Our results suggest ways to support speech-based productivity interactions and how speech-based road context alerts may influence driver behavior.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {attention management, multitasking, driving, productivity},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300931,
author = {Chang, Minsuk and Truong, Anh and Wang, Oliver and Agrawala, Maneesh and Kim, Juho},
title = {How to Design Voice Based Navigation for How-To Videos},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300931},
doi = {10.1145/3290605.3300931},
abstract = {When watching how-to videos related to physical tasks, users' hands are often occupied by the task, making voice input a natural fit. To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. From the studies, we distill seven navigation objectives and their underlying intents: pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. Our analysis found that users' navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 2) allow users to identify and refine their navigation objectives explicitly, and 3) support the seven interaction intents.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {voice user interface, video navigation, how-to videos, video tutorials, conversational interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300654,
author = {Baker, Catherine M. and Milne, Lauren R. and Ladner, Richard E.},
title = {Understanding the Impact of TVIs on Technology Use and Selection by Children with Visual Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300654},
doi = {10.1145/3290605.3300654},
abstract = {The use of technology in educational settings is extremely common. For many visually impaired children, educational settings are the first place they are exposed to the assistive technology that they will need to access mainstream computing devices. Current laws provide support for students to receive training from Teachers of the Visually Impaired (TVIs) on these assistive devices. Therefore, TVIs play an important role in the selection and training of technology. Through our interviews with TVIs, we discovered the factors that impact which technologies they select, how they attempt to mitigate the stigma associated with certain technologies, and the challenges that students face in learning assistive technologies. Through this research, we identified three needs that future research on assistive technology should address: (1) increasing focus on built-in accessibility features, (2) providing support for independent learning and exploration, and (3) creating technologies that can support users with progressive vision loss.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {teachers of the visually impaired, assistive technology, children with visual impairments},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300409,
author = {Law, Po-Ming and Das, Subhajit and Basole, Rahul C.},
title = {Comparing Apples and Oranges: Taxonomy and Design of Pairwise Comparisons within Tabular Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300409},
doi = {10.1145/3290605.3300409},
abstract = {Asking pairwise comparison questions is common. Yet, we often find ourselves comparing apples and oranges --- the two entities of interest are not readily comparable. To understand how technologies can extend our capabilities to conduct pairwise comparisons during data analysis, we analyzed pairwise comparison questions collected from crowd workers and propose a taxonomy of pairwise comparisons. We demonstrate how the taxonomy can be adopted by incorporating pairwise comparison capabilities into Duo, a spreadsheet application that supports comparing two groups of records in a data table. Duo decomposes a pairwise comparison question into rules and showcases sloppy rules, a query technique for specifying pairwise comparisons. We conducted a user study comparing sloppy rules and natural language. The findings suggest that for easier pairwise comparison tasks, the two techniques are comparable in efficiency and preference and that for more difficult pairwise comparison tasks, sloppy rules allow faster specification and are more preferable.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {natural language, spreadsheet, data analysis, query specification, comparison},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300787,
author = {Lopez, Sarah and Yang, Yi and Beltran, Kevin and Kim, Soo Jung and Cruz Hernandez, Jennifer and Simran, Chelsy and Yang, Bingkun and Yuksel, Beste F.},
title = {Investigating Implicit Gender Bias and Embodiment of White Males in Virtual Reality with Full Body Visuomotor Synchrony},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300787},
doi = {10.1145/3290605.3300787},
abstract = {Previous research has shown that when White people embody a black avatar in virtual reality (VR) with full body visuomotor synchrony, this can reduce their implicit racial bias. In this paper, we put men in female and male avatars in VR with full visuomotor synchrony using wearable trackers and investigated implicit gender bias and embodiment. We found that participants embodied in female avatars displayed significantly higher levels of implicit gender bias than those embodied in male avatars. The implicit gender bias actually increased after exposure to female embodiment in contrast to male embodiment. Results also showed that participants felt embodied in their avatars regardless of gender matching, demonstrating that wearable trackers can be used for a realistic sense of avatar embodiment in VR. We discuss the future implications of these findings for both VR scenarios and embodiment technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {embodied avatars, implicit gender bias, implicit association test, virtual reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300361,
author = {Lyngs, Ulrik and Lukoff, Kai and Slovak, Petr and Binns, Reuben and Slack, Adam and Inzlicht, Michael and Van Kleek, Max and Shadbolt, Nigel},
title = {Self-Control in Cyberspace: Applying Dual Systems Theory to a Review of Digital Self-Control Tools},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300361},
doi = {10.1145/3290605.3300361},
abstract = {Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–18},
numpages = {18},
keywords = {attention, self-regulation, addiction, interruptions, self-control, focus, ict non-use, distraction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300520,
author = {Rader, Emilee and Munasinghe, Anjali},
title = {"Wait, Do I Know This Person?": Understanding Misdirected Email},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300520},
doi = {10.1145/3290605.3300520},
abstract = {Email is an essential tool for communication and social interaction. It also functions as a broadcast medium connecting businesses with their customers, as an authentication mechanism, and as a vector for scams and security threats. These uses are enabled by the fact that the only barrier to reaching someone by email is knowing his or her email address. This feature has given rise to the spam email industry but also has another side-effect that is becoming increasingly common: misdirected email, or legitimate emails that are intended for somebody else but are sent to the wrong recipient. In this paper we present findings from an interview study and survey focusing on characteristics of misdirected email messages, possible reasons why they happen, and how people manage these messages when they receive them. Misdirected email arises as a result of signifiers (usernames) which were selected by people for social and self-representation purposes, that are also used by machines for addressing. Because there is no mechanism for dealing with misdirected emails in a systematic way, individual recipients must choose whether to take action and how much effort to put forth to prevent potential negative consequences for themselves and others.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mixed-method, authentication, usernames, misdirected email},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300350,
author = {Yamanaka, Shota and Stuerzlinger, Wolfgang},
title = {Modeling Fully and Partially Constrained Lasso Movements in a Grid of Icons},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300350},
doi = {10.1145/3290605.3300350},
abstract = {Lassoing objects is a basic function in illustration software and presentation tools. Yet, for many common object arrangements lassoing is sometimes time-consuming to perform and requires precise pen operation. In this work, we studied lassoing movements in a grid of objects similar to icons. We propose a quantitative model to predict the time to lasso such objects depending on the margins between icons, their sizes, and layout, which all affect the number of stopping and crossing movements. Results of two experiments showed that our models predict fully and partially constrained movements with high accuracy. We also analyzed the speed profiles and pen stroke trajectories and identified deeper insights into user behaviors, such as that an unconstrained area can induce higher movement speeds even in preceding path segments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {steering, graphical user interfaces, lassoing, human motor performance},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300723,
author = {Fox, Sarah E. and Sobel, Kiley and Rosner, Daniela K.},
title = {Managerial Visions: Stories of Upgrading and Maintaining the Public Restroom with IoT},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300723},
doi = {10.1145/3290605.3300723},
abstract = {This paper examines the entangled development of governance strategies and networked technologies in the pervasive but under-examined domain of public restrooms. Drawing on a mix of archival materials, participant observation, and interviews within and beyond the city of Seattle, Washington, we look at the motivations of public restroom facilities managers as they introduce (or consider introducing) networked technology in the spaces they administer. Over the course of the research, we found internet of things technologies-or, connected devices imbued with computational capacity-became increasingly tied up with cost-reducing efficiencies and exploitative regulatory techniques. Drawing from this case study, we develop the concept of managerial visions: ways of seeing that structure labor, enforce compliance, and define access to resources. We argue that these ways of seeing prove increasingly critical to HCI research as it attends to computer-mediated collaboration beyond white-collar settings.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {internet of things, restrooms, governance},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300872,
author = {Kuo, Pei-Yi and Saran, Rajiv and Argentina, Marissa and Heung, Michael and Bragg-Gresham, Jennifer L. and Chatoth, Dinesh and Gillespie, Brenda and Krein, Sarah and Wingard, Rebecca and Zheng, Kai and Veinot, Tiffany C.},
title = {Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300872},
doi = {10.1145/3290605.3300872},
abstract = {Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension ("IDH"). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {co-design, clinicians, activity theory, dialysis, checklist},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300657,
author = {Gehrke, Lukas and Akman, Sezen and Lopes, Pedro and Chen, Albert and Singh, Avinash Kumar and Chen, Hsiang-Ting and Lin, Chin-Teng and Gramann, Klaus},
title = {Detecting Visuo-Haptic Mismatches in Virtual Reality Using the Prediction Error Negativity of Event-Related Brain Potentials},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300657},
doi = {10.1145/3290605.3300657},
abstract = {Designing immersion is the key challenge in virtual reality; this challenge has driven advancements in displays, rendering and recently, haptics. To increase our sense of physical immersion, for instance, vibrotactile gloves render the sense of touching, while electrical muscle stimulation (EMS) renders forces. Unfortunately, the established metric to assess the effectiveness of haptic devices relies on the user's subjective interpretation of unspecific, yet standardized, questions.Here, we explore a new approach to detect a conflict in visuo-haptic integration (e.g., inadequate haptic feedback based on poorly configured collision detection) using electroencephalography (EEG). We propose analyzing event-related potentials (ERPs) during interaction with virtual objects. In our study, participants touched virtual objects in three conditions and received either no haptic feedback, vibration, or vibration and EMS feedback. To provoke a brain response in unrealistic VR interaction, we also presented the feedback prematurely in 25% of the trials.We found that the early negativity component of the ERP (so called prediction error) was more pronounced in the mismatch trials, indicating we successfully detected haptic conflicts using our technique. Our results are a first step towards using ERPs to automatically detect visuo-haptic mismatches in VR, such as those that can cause a loss of the user's immersion.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {virtual reality, elecrical muscle stimulation, erp, prediction error, eeg, force feedback},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300286,
author = {Arora, Jatin and Saini, Aryan and Mehra, Nirmita and Jain, Varnit and Shrey, Shwetank and Parnami, Aman},
title = {VirtualBricks: Exploring a Scalable, Modular Toolkit for Enabling Physical Manipulation in VR},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300286},
doi = {10.1145/3290605.3300286},
abstract = {Often Virtual Reality (VR) experiences are limited by the design of standard controllers. This work aims to liberate a VR developer from these limitations in the physical realm to provide an expressive match to the limitless possibilities in the virtual realm. VirtualBricks is a LEGO based toolkit that enables construction of a variety of physical-manipulation enabled controllers for VR, by offering a set of feature bricks that emulate as well as extend the capabilities of default controllers. Based on the LEGO platform, the toolkit provides a modular, scalable solution for enabling passive haptics in VR. We demonstrate the versatility of our designs through a rich set of applications including re-implementations of artifacts from recent research. We share a VR Integration package for integration with Unity VR IDE, the CAD models for the feature bricks, for easy deployment of VirtualBricks within the community.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {construction toolkit, passive haptics, physical manipulation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300468,
author = {Yang, Qian and Steinfeld, Aaron and Zimmerman, John},
title = {Unremarkable AI: Fitting Intelligent Decision Support into Critical, Clinical Decision-Making Processes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300468},
doi = {10.1145/3290605.3300468},
abstract = {Clinical decision support tools (DST) promise improved healthcare outcomes by offering data-driven insights. While effective in lab settings, almost all DSTs have failed in practice. Empirical research diagnosed poor contextual fit as the cause. This paper describes the design and field evaluation of a radically new form of DST. It automatically generates slides for clinicians' decision meetings with subtly embedded machine prognostics. This design took inspiration from the notion of Unremarkable Computing, that by augmenting the users' routines technology/AI can have significant importance for the users yet remain unobtrusive. Our field evaluation suggests clinicians are more likely to encounter and embrace such a DST. Drawing on their responses, we discuss the importance and intricacies of finding the right level of unremarkableness in DST design, and share lessons learned in prototyping critical AI systems as a situated experience.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {healthcare, decision support systems, user experience},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300687,
author = {Terzimehi\'{c}, Naundefineda and H\"{a}uslschmid, Renate and Hussmann, Heinrich and schraefel, m.c.},
title = {A Review &amp; Analysis of Mindfulness Research in HCI: Framing Current Lines of Research and Future Opportunities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300687},
doi = {10.1145/3290605.3300687},
abstract = {Mindfulness is a term seen with increasing frequency in HCI literature, and yet the term itself is used almost as variously as the number of papers in which it appears. This diversity makes comparing or evaluating HCI approaches around mindfulness or understanding the design space itself a challenging task. We conducted a structured ACM literature search based on the term mindfulness. Our selection process yielded 38 relevant papers, which we analyzed for their definition, motivation, practice, evaluation and technology use around mindfulness. We identify similarities, divergences and areas of interest for each aspect, resulting in a framework composed of four perspectives and seven lines of research. We highlight challenges and opportunities for future HCI research and design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {practice, perspectives, reflection, well-being, literature review, meditation, conceptualization, mindfulness, interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300752,
author = {Abtahi, Parastoo and Gonzalez-Franco, Mar and Ofek, Eyal and Steed, Anthony},
title = {I'm a Giant: Walking in Large Virtual Environments at High Speed Gains},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300752},
doi = {10.1145/3290605.3300752},
abstract = {Advances in tracking technology and wireless headsets enable walking as a means of locomotion in Virtual Reality. When exploring virtual environments larger than room-scale, it is often desirable to increase users' perceived walking speed, for which we investigate three methods. (1) Ground-Level Scaling increases users' avatar size, allowing them to walk farther. (2) Eye-Level Scaling enables users to walk through a World in Miniature, while maintaining a street-level view. (3) Seven-League Boots amplifies users' movements along their walking path. We conduct a study comparing these methods and find that users feel most embodied using Ground-Level Scaling and consequently increase their stride length. Using Seven-League Boots, unlike the other two methods, diminishes positional accuracy at high gains, and users modify their walking behavior to compensate for the lack of control. We conclude with a discussion on each technique's strength and weaknesses and the types of situation they might be appropriate for.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {seven-league boots, body scale, translationalgain, locomotion, world in miniuature, virtual reality, walking speed},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300302,
author = {Vashistha, Aditya and Garg, Abhinav and Anderson, Richard and Raza, Agha Ali},
title = {Threats, Abuses, Flirting, and Blackmail: Gender Inequity in Social Media Voice Forums},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300302},
doi = {10.1145/3290605.3300302},
abstract = {HCI4D researchers and practitioners have leveraged voice forums to enable people with literacy, socioeconomic, and connectivity barriers to access, report, and share information. Although voice forums have received impassioned usage from low-income, low-literate, rural, tribal, and disabled communities in diverse HCI4D contexts, the participation of women in these services is almost non-existent. In this paper, we investigate the reasons for the low participation of women in social media voice forums by examining the use of Sangeet Swara in India and Baang in Pakistan by marginalized women and men. Our mixed-methods approach spanning content analysis of audio posts, quantitative analysis of interactions between users, and qualitative interviews with users indicate gender inequity due to deep-rooted patriarchal values. We found that women on these forums faced systemic discrimination and encountered abusive content, flirts, threats, and harassment. We discuss design recommendations to create social media voice forums that foster gender equity in use of these services.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gender, ivr, india, women, hci4d, pakistan, social media, voice forum},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300679,
author = {Yuan, Ye and Yarosh, Svetlana},
title = {Beyond Tutoring: Opportunities for Intergenerational Mentorship at a Community Level},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300679},
doi = {10.1145/3290605.3300679},
abstract = {Community intergenerational mentorship offers an opportunity to address older adults' social isolation while providing valuable one-on-one or small group learning experiences for elementary school students. Current organizations that support this kind of engagement focus on in-person visits that place the burden of logistics and transportation on the older adult. However, as older adults become less independent while aging, coming to schools in person becomes more challenging. We present a qualitative analysis of current intergenerational mentorship practices to understand opportunities for technology to expand access to this experience. We highlight elements critical for building successful mentorship: the importance of relationship building between older adults and children during mentoring activities, the skills mentors acquired to carry out mentoring activities, and support needed from teachers and schools. We contribute a rich description of current intergenerational mentorship practices and provide insights for opportunities for novel HCI technologies in this context.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mentoring, tutoring, intergenerational communication, intergenerational mentorship, older adults, community, children},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300395,
author = {Cui, Wenzhe and Zheng, Jingjie and Lewis, Blaine and Vogel, Daniel and Bi, Xiaojun},
title = {HotStrokes: Word-Gesture Shortcuts on a Trackpad},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300395},
doi = {10.1145/3290605.3300395},
abstract = {Expert interaction techniques like hotkeys are efficient, but poorly adopted because they are hard to learn. HotStrokes removes the need for learning arbitrary mappings of commands to hotkeys. A user enters a HotStroke by holding a modifier key, then gesture typing a command name on a laptop trackpad as if on an imaginary virtual keyboard. The gestures are recognized using an adaptation of the SHARK2 algorithm with a new spatial model and a refined method for dynamic suggestions. A controlled experiment shows HotStrokes effectively augments the existing "menu and hotkey" command activation paradigm. Results show the method is efficient by reducing command activation time by 43% compared to linear menus. The method is also easy to learn with a high adoption rate, replacing 91% of linear menu usage. Finally, combining linear menus, hotkeys, and HotStrokes leads to 24% faster command activation overall.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {input techniques, laptop computers, touch, desktop, gesture},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300345,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Lazar, Amanda and Su, Norman Makoto},
title = {(Re-)Framing Menopause Experiences for HCI and Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300345},
doi = {10.1145/3290605.3300345},
abstract = {Informed by considerations from medicine and wellness research, experience design, investigations of new and emerging technologies, and sociopolitical critique, HCI researchers have demonstrated that women's health is a complex and rich topic. Turning these research outputs into productive interventions, however, is difficult. We argue that design is well positioned to address such a challenge thanks to its methodological traditions of problem setting and framing situated in synthetic (rather than analytic) knowledge production. In this paper, we focus on designing for experiences of menopause. Building on our prior empirical work on menopause and our commitment to pursue design informed by women's lived experience, we iteratively generated dozens of design frames and accompanying design crits. We document the unfolding of our design reasoning, showing how good-seeming insights nonetheless often lead to bad designs, while working progressively towards stronger insights and design constructs. The latter we offer as a contribution to researchers and practitioners who work at the intersections of women's health and design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design framing, menopause, scenarios, women's health},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300434,
author = {Rivera, Michael L. and Hudson, Scott E.},
title = {Desktop Electrospinning: A Single Extruder 3D Printer for Producing Rigid Plastic and Electrospun Textiles},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300434},
doi = {10.1145/3290605.3300434},
abstract = {We present a new type of 3D printer that combines rigid plastic printing with melt electrospinning? a technique that uses electrostatic forces to create thin fibers from a molten polymer. Our printer enables custom-shaped textile sheets (similar in feel to wool felt) to be produced alongside rigid plastic using a single material (i.e., PLA) in a single process. We contribute open-source firmware, hardware specifications, and printing parameters to achieve melt electrospinning. Our approach offers new opportunities for fabricating interactive objects and sensors that blend the flexibility, absorbency and softness of produced electrospun textiles with the structure and rigidity of hard plastic for actuation, sensing, and tactile experiences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3d printing, melt electrospinning, textiles, soft material fabrication},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300254,
author = {Wang, Ruolin and Yu, Chun and Yang, Xing-Dong and He, Weijie and Shi, Yuanchun},
title = {EarTouch: Facilitating Smartphone Use for Visually Impaired People in Mobile and Public Scenarios},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300254},
doi = {10.1145/3290605.3300254},
abstract = {Interacting with a smartphone using touch input and speech output is challenging for visually impaired people in mobile and public scenarios, where only one hand may be available for input (e.g., while holding a cane) and using the loudspeaker for speech output is constrained by environmental noise, privacy, and social concerns. To address these issues, we propose EarTouch, a one-handed interaction technique that allows the users to interact with a smartphone using the ear to perform gestures on the touchscreen. Users hold the phone to their ears and listen to speech output from the ear speaker privately. We report how the technique was designed, implemented, and evaluated through a series of studies. Results show that EarTouch is easy, efficient, fun and socially acceptable to use.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {eartouch, vision impairment, smartphone, capacitive sensing, accessibility, one-handed interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300879,
author = {Dillahunt, Tawanna R. and Simioni, Sylvia and Xu, Xuecong},
title = {Online Grocery Delivery Services: An Opportunity to Address Food Disparities in Transportation-Scarce Areas},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300879},
doi = {10.1145/3290605.3300879},
abstract = {Online grocery delivery services present new opportunities to address food disparities, especially in underserved areas. However, such services have not been systematically evaluated. This study evaluates such services' potential to provide healthy-food access and influence healthy-food purchases among individuals living in transportation-scarce and low-resource areas. We conducted a pilot experiment with 20 participants consisting of a randomly assigned group's 1-month use of an online grocery delivery service, and a control group's 1-month collection of grocery receipts, and a set of semi-structured interviews. We found that online grocery delivery services (a) serve as a feasible model to healthy-food access if they are affordable and amenable to multiple payment forms and (b) could lead to healthier selections. We contribute policy recommendations to bolster affordability of healthy-food access and design opportunities to promote healthy foods to support the adoption and use of these services among low-resource and transportation-scarce groups.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {online grocery delivery, food disparities, health},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300543,
author = {Saksono, Herman and Castaneda-Sceppa, Carmen and Hoffman, Jessica and Seif El-Nasr, Magy and Morris, Vivien and Parker, Andrea G.},
title = {Social Reflections on Fitness Tracking Data: A Study with Families in Low-SES Neighborhoods},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300543},
doi = {10.1145/3290605.3300543},
abstract = {Wearable activity trackers can encourage physical activity (PA)-a behavior critical for preventing obesity and reducing the risks of chronic diseases. However, prior work has rarely explored how these tools can leverage family support or help people think about strategies for being active-wo factors necessary for achieving regular PA. In this 2-month qualitative study, we investigated PA tracking practices amongst 14 families living in low-income neighborhoods, where obesity is prevalent. We characterize how social discussions of PA data rarely extended beyond the early stages of experiential learning, thus limiting the utility of PA trackers. Caregivers and children rarely analyzed their experiences to derive insights about the meaning of their PA data for their wellbeing. Those who engaged in these higher-order learning processes were often influenced by parenting beliefs shaped by personal health experiences. We contribute recommendations for how technology can more effectively support family experiential learning using PA tracking data.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {personal health informatics, family, physical activity, reflection, fitness tracking data, low-ses, self-monitoring, wearables, children, experiential learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300873,
author = {Kasahara, Shunichi and Nishida, Jun and Lopes, Pedro},
title = {Preemptive Action: Accelerating Human Reaction Using Electrical Muscle Stimulation Without Compromising Agency},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300873},
doi = {10.1145/3290605.3300873},
abstract = {We enable preemptive force-feedback systems to speed up human reaction time without fully compromising the user's sense of agency. Typically these interfaces actuate by means of electrical muscle stimulation (EMS) or mechanical actuators; they preemptively move the user to perform a task, such as to improve movement performance (e.g., EMS-assisted drumming). Unfortunately, when using preemptive force-feedback users do not feel in control and loose their sense of agency. We address this by actuating the user's body, using EMS, within a particular time window (160 ms after visual stimulus), which we found to speed up reaction time by 80 ms in our first study. With this preemptive timing, when the user and system move congruently, the user feels that they initiated the motion, yet their reaction time is faster than usual. As our second study demonstrated, this particular timing significantly increased agency when compared to the current practice in EMS-based devices. We conclude by illustrating, using examples from the HCI literature, how to leverage our findings to provide more agency to automated haptic interfaces.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {human augmentation, reaction time, agency, electrical muscle stimulation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300506,
author = {Iravantchi, Yasha and Zhang, Yang and Bernitsas, Evi and Goel, Mayank and Harrison, Chris},
title = {Interferi: Gesture Sensing Using On-Body Acoustic Interferometry},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300506},
doi = {10.1145/3290605.3300506},
abstract = {Interferi is an on-body gesture sensing technique using acoustic interferometry. We use ultrasonic transducers resting on the skin to create acoustic interference patterns inside the wearer's body, which interact with anatomical features in complex, yet characteristic ways. We focus on two areas of the body with great expressive power: the hands and face. For each, we built and tested a series of worn sensor configurations, which we used to identify useful transducer arrangements and machine learning fea-tures. We created final prototypes for the hand and face, which our study results show can support eleven- and nine-class gestures sets at 93.4% and 89.0% accuracy, re-spectively. We also evaluated our system in four continu-ous tracking tasks, including smile intensity and weight estimation, which never exceed 9.5% error. We believe these results show great promise and illuminate an inter-esting sensing technique for HCI applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {acoustic, interaction techniques, face gesture, hand gesture, acoustic interferometry, wearables, hand input, biosensing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300337,
author = {Mishra, Sonali R. and Klasnja, Predrag and MacDuffie Woodburn, John and Hekler, Eric B. and Omberg, Larsson and Kellen, Michael and Mangravite, Lara},
title = {Supporting Coping with Parkinson's Disease Through Self Tracking},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300337},
doi = {10.1145/3290605.3300337},
abstract = {Self-tracking can help people understand their medical condition and the factors that influence their symptoms. However, it is unclear how tracking technologies should be tailored to help people cope with the progression of a degenerative disease. To understand how smartphone apps and other tracking technologies can support people in coping with an incurable illness, we interviewed both people with Parkinson's Disease (n=17) and care partners (n=6) who help people with Parkinson's manage their lives. We describe how symptom trackers can help people identify and solve problems to improve their quality of life, the role symptom trackers can play in helping people combat their own tendencies towards avoidance and denial, and the complex role of care partners in defining and tracking ambiguous symptoms. Our findings yield insights that can guide the design of tracking technologies to help people with Parkinson's Disease accept and plan for their condition.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {personal informatics, health informatics, parkinson's disease, coping with chronic disease, symptom tracking, quality of life},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300913,
author = {Peng, Yi-Hao and Lin, Muh-Tarng and Chen, Yi and Chen, TzuChuan and Ku, Pin Sung and Taele, Paul and Lim, Chin Guan and Chen, Mike Y.},
title = {PersonalTouch: Improving Touchscreen Usability by Personalizing Accessibility Settings Based on Individual User's Touchscreen Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300913},
doi = {10.1145/3290605.3300913},
abstract = {Modern touchscreen devices have recently introduced customizable touchscreen settings to improve accessibility for users with motor impairments. For example, iOS 10 introduced the following four Touch Accommodation settings: 1) Hold Duration, 2) Ignore Repeat, 3) Tap Assistance, and 4) Tap Assistance Gesture Delay. These four independent settings lead to a total of more than 1 million possible configurations, making it impractical to manually determine the optimal settings. We present PersonalTouch, which collects and analyzes touchscreen gestures performed by individual users, and recommends personalized, optimal touchscreen accessibility settings. Results from our user study show that PersonalTouch significantly improves touch input success rate for users with motor impairments (20.2%, N=12, p=.00054) and for users without motor impairments (1.28%, N=12, p=.032).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {personalization, motor impairment, touch-screen interaction, accessibility},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300671,
author = {Kyfonidis, Charalampos and Lennon, Marilyn},
title = {Making Diabetes Education Interactive: Tangible Educational Toys for Children with Type-1 Diabetes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300671},
doi = {10.1145/3290605.3300671},
abstract = {Younger children (under 9 years) with type-1 diabetes are often very passive in the management of their condition and can face difficulties in accessing and understanding basic diabetes related information. This can make transitioning to self-management in later years very challenging. Previous research has mostly focused on educational interventions for older children.To create an educational tool which can support the diabetes educational process of younger children, we conducted a multiphase and multi-stakeholder user-centred design process. The result is an interactive tool that illustrates diabetes concepts in an age-appropriate way with the use of tangible toys. The tool was evaluated inside a paediatric diabetes clinic with clinicians, children and parents and was found to be engaging, acceptable and effective. In addition to providing implications for the design and adoption of educational tools for children in a clinical setting, we discuss the challenges for conducting user-centred design in such a setting.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {diabetes education, user-centred design, tangible interaction, children},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300293,
author = {Piazentin Ono, Jorge and Gjoka, Arvi and Salamon, Justin and Dietrich, Carlos and Silva, Claudio T.},
title = {HistoryTracker: Minimizing Human Interactions in Baseball Game Annotation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300293},
doi = {10.1145/3290605.3300293},
abstract = {The sport data tracking systems available today are based on specialized hardware (high-definition cameras, speed radars, RFID) to detect and track targets on the field. While effective, implementing and maintaining these systems pose a number of challenges, including high cost and need for close human monitoring. On the other hand, the sports analytics community has been exploring human computation and crowdsourcing in order to produce tracking data that is trustworthy, cheaper and more accessible. However, state-of-the-art methods require a large number of users to perform the annotation, or put too much burden into a single user. We propose HistoryTracker, a methodology that facilitates the creation of tracking data for baseball games by warm-starting the annotation process using a vast collection of historical data. We show that HistoryTracker helps users to produce tracking data in a fast and reliable way.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {sports tracking, hand annotation, baseball, sports analytics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300374,
author = {Frison, Anna-Katharina and Wintersberger, Philipp and Riener, Andreas and Schartm\"{u}ller, Clemens and Boyle, Linda Ng and Miller, Erika and Weigl, Klemens},
title = {In UX We Trust: Investigation of Aesthetics and Usability of Driver-Vehicle Interfaces and Their Impact on the Perception of Automated Driving},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300374},
doi = {10.1145/3290605.3300374},
abstract = {In the evolution of technical systems, freedom from error and early adoption plays a major role for market success and to maintain competitiveness. In the case of automated driving, we see that faulty systems are put into operation and users trust these systems, often without any restrictions. Trust and use are often associated with users' experience of the driver-vehicle interfaces and interior design. In this work, we present the results of our investigations on factors that influence the perception of automated driving. In a simulator study, N=48 participants had to drive a SAE level 2 vehicle with either perfect or faulty driving function. As a secondary activity, participants had to solve tasks on an infotainment system with varying aesthetics and usability (2x2). Results reveal that the interaction of conditions significantly influences trust and UX of the vehicle system. Our conclusion is that all aspects of vehicle design cumulate to system and trust perception.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user experience, reliability, aesthetic, ux, sae j3016, automated driving systems, trust, distrust},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300334,
author = {Huang, Forrest and Canny, John F. and Nichols, Jeffrey},
title = {Swire: Sketch-Based User Interface Retrieval},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300334},
doi = {10.1145/3290605.3300334},
abstract = {Sketches and real-world user interface examples are frequently used in multiple stages of the user interface design process. Unfortunately, finding relevant user interface examples, especially in large-scale datasets, is a highly challenging task because user interfaces have aesthetic and functional properties that are only indirectly reflected by their corresponding pixel data and meta-data. This paper introduces Swire, a sketch-based neural-network-driven technique for retrieving user interfaces. We collect the first large-scale user interface sketch dataset from the development of Swire that researchers can use to develop new sketch-based data-driven design interfaces and applications. Swire achieves high performance for querying user interfaces: for a known validation task it retrieves the most relevant example as within the top-10 results for over 60% of queries. With this technique, for the first time designers can accurately retrieve relevant user interface examples with free-form sketches natural to their design workflows. We demonstrate several novel applications driven by Swire that could greatly augment the user interface design process.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {data-driven design, user interface design, information retrieval, deep learning, computer vision, design examples, sketching},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300333,
author = {Kljun, Matja\v{z} and Pucihar, Klen \v{C}opi\v{c} and Alexander, Jason and Weerasinghe, Maheshya and Campos, Cuauhtli and Ducasse, Julie and Kopacin, Barbara and Grubert, Jens and Coulton, Paul and \v{C}elar, Miha},
title = {Augmentation Not Duplication: Considerations for the Design of Digitally-Augmented Comic Books},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300333},
doi = {10.1145/3290605.3300333},
abstract = {Digital-augmentation of print-media can provide contextually relevant audio, visual, or haptic content to supplement the static text and images. The design of such augmentation--its medium, quantity, frequency, content, and access technique--can have a significant impact on the reading experience. In the worst case, such as where children are learning to read, the print medium can become a proxy for accessing digital content only, and the textual content is avoided. In this work, we examine how augmented content can change the reader's behaviour with a comic book. We first report on the usage of a commercially available augmented comic for children, providing evidence that a third of all readers converted to simply viewing the digital media when printed content is duplicated. Second, we explore the design space for digital content augmentation in print media. Third, we report a user study with 136 children that examined the impact of both content length and presentation in a digitally-augmented comic book. From this, we report a series of design guidelines to assist designers and editors in the development of digitally-augmented print media.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {digital augmentation, comic books, augmented reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300605,
author = {Choo, Kenny Tsu Wei and Balan, Rajesh Krishna and Lee, Youngki},
title = {Examining Augmented Virtuality Impairment Simulation for Mobile App Accessibility Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300605},
doi = {10.1145/3290605.3300605},
abstract = {With mobile apps rapidly permeating all aspects of daily living with use by all segments of the population, it is crucial to support the evaluation of app usability for specific impaired users to improve app accessibility. In this work, we examine the effects of using our augmented virtuality impairment simulation system--Empath-D--to support experienced designer-developers to redesign a mockup of commonly used mobile application for cataract-impaired users, comparing this with existing tools that aid designing for accessibility. We show that the use of augmented virtuality for assessing usability supports enhanced usability challenge identification, finding more defects and doing so more accurately than with existing methods. Through our user interviews, we also show that augmented virtuality impairment simulation supports realistic interaction and evaluation to provide a concrete understanding over the usability challenges that impaired users face, and complements the existing guidelines-based approaches meant for general accessibility.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {mobile app design, virtual reality, augmented virtuality, empathetic design, accessibility},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300690,
author = {Feger, Sebastian S. and Dallmeier-Tiessen, S\"{u}nje and Woundefinedniak, Pawe\l{} W. and Schmidt, Albrecht},
title = {Gamification in Science: A Study of Requirements in the Context of Reproducible Research},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300690},
doi = {10.1145/3290605.3300690},
abstract = {The need for data preservation and reproducible research is widely recognized in the scientific community. Yet, researchers often struggle to find the motivation to contribute to data repositories and to use tools that foster reproducibility. In this paper, we explore possible uses of gamification to support reproducible practices in High Energy Physics. To understand how gamification can be effective in research tools, we participated in a workshop and performed interviews with data analysts. We then designed two interactive prototypes of a research preservation service that use contrasting gamification strategies. The evaluation of the prototypes showed that gamification needs to address core scientific challenges, in particular the fair reflection of quality and individual contribution. Through thematic analysis, we identified four themes which describe perceptions and requirements of gamification in research: Contribution, Metrics, Applications and Scientific practice. Based on these, we discuss design implications for gamification in science.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {science, gamification, research reproducibility, game design elements},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300339,
author = {Mu\~{n}oz, Diego and Ploderer, Bernd and Brereton, Margot},
title = {Position Exchange Workshops: A Method to Design for Each Other in Families},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300339},
doi = {10.1145/3290605.3300339},
abstract = {Existing methods for researching and designing to support relationships between parents and their adult children tend to lead to designs that respect the differences between them. We conducted 14 Position Exchange Workshops with parents and their adult children, where the child has left home in recent years, aiming to explicate and confront their positions in creative and supportive ways. We designed three co-design methods (Card Sort for Me &amp; You, Would I Lie to You? and A Magic Machine for You) to support participants to explore, understand, empathize, and design for each other. The findings show that the methods facilitated understanding, renegotiating, and reimagining their current positions. We discuss how positions can help consider both perspectives in the design process. This paper seeks to contribute (1) how the notion of positions enables generating understandings of the relationship, and (2) a set of methods influenced by position exchange, empathy, and playful engagement that help explore human relationships.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {family relationships, position exchange, renegotiation of relationships, parent-adult child relationship, position exchange workshops, dialogicality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300280,
author = {Kong, Ha-Kyung and Zhu, Wenjie and Liu, Zhicheng and Karahalios, Karrie},
title = {Understanding Visual Cues in Visualizations Accompanied by Audio Narrations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300280},
doi = {10.1145/3290605.3300280},
abstract = {It is often assumed that visual cues, which highlight specific parts of a visualization to guide the audience's attention, facilitate visualization storytelling and presentation. This assumption has not been systematically studied. We present an in-lab experiment and a Mechanical Turk study to examine the effects of integral and separable visual cues on the recall and comprehension of visualizations that are accompanied by audio narration. Eye-tracking data in the in-lab experiment confirm that cues helped the viewers focus on relevant parts of the visualization faster. We found that in general, visual cues did not have a significant effect on learning outcomes, but for specific cue techniques (e.g. glow) or specific chart types (e.g heatmap), cues significantly improved comprehension. Based on these results, we discuss how presenters might select visual cues depending on the role of the cues and the visualization type.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visual cues, learning, narrative visualization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300686,
author = {Shugrina, Maria and Zhang, Wenjia and Chevalier, Fanny and Fidler, Sanja and Singh, Karan},
title = {Color Builder: A Direct Manipulation Interface for Versatile Color Theme Authoring},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300686},
doi = {10.1145/3290605.3300686},
abstract = {Color themes or palettes are popular for sharing color combinations across many visual domains. We present a novel interface for creating color themes through direct manipulation of color swatches. Users can create and rearrange swatches, and combine them into smooth and step-based gradients and three-color blends -- all using a seamless touch or mouse input. Analysis of existing solutions reveals a fragmented color design workflow, where separate software is used for swatches, smooth and discrete gradients and for in-context color visualization. Our design unifies these tasks, while encouraging playful creative exploration. Adjusting a color using standard color pickers can break this interaction flow with mechanical slider manipulation. To keep interaction seamless, we additionally design an in situ color tweaking interface for freeform exploration of an entire color neighborhood. We evaluate our interface with a group of professional designers and students majoring in this field.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {creativity support, direct manipulation interfaces, gradients, color palettes, color pickers, color themes},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300244,
author = {Gupta, Aakar and Ji, Cheng and Yeo, Hui-Shyong and Quigley, Aaron and Vogel, Daniel},
title = {RotoSwype: Word-Gesture Typing Using a Ring},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300244},
doi = {10.1145/3290605.3300244},
abstract = {We propose RotoSwype, a technique for word-gesture typing using the orientation of a ring worn on the index finger. RotoSwype enables one-handed text-input without encumbering the hand with a device, a desirable quality in many scenarios, including virtual or augmented reality. The method is evaluated using two arm positions: with the hand raised up with the palm parallel to the ground; and with the hand resting at the side with the palm facing the body. A five-day study finds both hand positions achieved speeds of at least 14 words-per-minute (WPM) with uncorrected error rates near 1%, outperforming previous comparable techniques.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {controlled experiments, interaction techniques},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300900,
author = {Rutjes, Heleen and Willemsen, Martijn C. and IJsselsteijn, Wijnand A.},
title = {Beyond Behavior: The Coach's Perspective on Technology in Health Coaching},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300900},
doi = {10.1145/3290605.3300900},
abstract = {Rapid innovations in electronic healthcare and behavior tracking systems are challenging health coaches (dietitians, personal trainers, etc.) to rethink their traditional roles and healthcare practices. At the same time, many current e-coaching systems have been developed without explicitly incorporating the healthcare professionals' perspective into the design process. In the current paper, we present three consecutive qualitative studies, starting from the health coach's perspective on successful coaching, progressively zooming in on the potential role and impact of technology as part of the coaching process. Our main finding is that coaches are concerned that introducing technology in the coaching process puts too much emphasis on behavioral information, lowering the attention for the client's lived experience, while understanding those experiences is key for successful coaching. We summarize our insights in a multi-channel communication model and draw implications for the design of supporting technology in health coaching.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {self-tracking, behavior change support, e-coaching, coach-client relationship, technology acceptance, health coaching, mhealth, patient-generated data},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300932,
author = {Lee, Minha and Ackermans, Sander and van As, Nena and Chang, Hanwen and Lucas, Enzo and IJsselsteijn, Wijnand},
title = {Caring for Vincent: A Chatbot for Self-Compassion},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300932},
doi = {10.1145/3290605.3300932},
abstract = {The digitization of mental health care holds promises of affordable and ubiquitously available treatment, e.g., with conversational agents (chatbots). While technology can guide people to care for themselves, we examined how people can care for another being as a way to care for themselves. We created a self-compassion chatbot (Vincent) and compared between caregiving and care-receiving conditions. Care-giving Vincent asked participants to partake in self-compassion exercises. Care-receiving Vincent shared its foibles, e.g., embarrassingly arriving late at an IP address, and sought out advice. While self-compassion increased for both conditions, only those with care-receiving Vincent significantly improved. In tandem, we offer qualitative data on how participants interacted with Vincent. Our exploratory research shows that when a person cares for a chatbot, the person's self-compassion can be enhanced. We further reflect on design implications for strengthening mental health with chatbots.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {positive computing, chatbot, well-being, compassion},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300433,
author = {Sindhwani, Shyamli and Lutteroth, Christof and Weber, Gerald},
title = {ReType: Quick Text Editing with Keyboard and Gaze},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300433},
doi = {10.1145/3290605.3300433},
abstract = {When a user needs to reposition the cursor during text editing, this is often done using the mouse. For experienced typists especially, the switch between keyboard and mouse can slow down the keyboard editing workflow considerably. To address this we propose ReType, a new gaze-assisted positioning technique combining keyboard with gaze input based on a new 'patching' metaphor. ReType allows users to perform some common editing operations while keeping their hands on the keyboard. We present the result of two studies. A free-use study indicated that ReType enhances the user experience of text editing. ReType was liked by many participants, regardless of their typing skills. A comparative user study showed that ReType is able to match or even beat the speed of mouse-based interaction for small text edits. We conclude that the gaze-augmented user interface can make common interactions more fluent, especially for professional keyboard users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {positioning, patching metaphor, typographical error, text editor, natural user interfaces, keyboard, eye gaze tracking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300675,
author = {Leonardi, Nicola and Manca, Marco and Patern\`{o}, Fabio and Santoro, Carmen},
title = {Trigger-Action Programming for Personalising Humanoid Robot Behaviour},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300675},
doi = {10.1145/3290605.3300675},
abstract = {In the coming years humanoid robots will be increasingly used in a variety of contexts, thereby presenting many opportunities to exploit their capabilities in terms of what they can sense and do. One main challenge is to design technologies that enable those who are not programming experts to personalize robot behaviour. We propose an end user development solution based on trigger-action personalization rules. We describe how it supports editing such rules and its underlying software architecture, and report on a user test that involved end user developers. The test results show that users were able to perform the robot personalization tasks with limited effort, and found the trigger-action environment usable and suitable for the proposed tasks. Overall, we show the potential for using trigger-action programming to make robot behaviour personalization possible even to people who are not professional software developers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {end user development, trigger-action programming, robot personalization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300550,
author = {Samad, Majed and Gatti, Elia and Hermes, Anne and Benko, Hrvoje and Parise, Cesare},
title = {Pseudo-Haptic Weight: Changing the Perceived Weight of Virtual Objects By Manipulating Control-Display Ratio},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300550},
doi = {10.1145/3290605.3300550},
abstract = {In virtual reality, the lack of kinesthetic feedback often prevents users from experiencing the weight of virtual objects. Control-to-display (C/D) ratio manipulation has been proposed as a method to induce weight perception without kinesthetic feedback. Based on the fact that lighter (heavier) objects are easier (harder) to move, this method induces an illusory perception of weight by manipulating the rendered position of users' hands---increasing or decreasing their displayed movements. In a series of experiments we demonstrate that C/D-ratio induces a genuine perception of weight, while preserving ownership over the virtual hand. This means that such a manipulation can be easily introduced in current VR experiences without disrupting the sense of presence. We discuss these findings in terms of estimation of physical work needed to lift an object. Our findings provide the first quantification of the range of C/D-ratio that can be used to simulate weight in virtual reality.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multisensory integration, virtual weight, pseudo-haptics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300251,
author = {Wilson, Cara and Brereton, Margot and Ploderer, Bernd and Sitbon, Laurianne},
title = {Co-Design Beyond Words: 'Moments of Interaction' with Minimally-Verbal Children on the Autism Spectrum},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300251},
doi = {10.1145/3290605.3300251},
abstract = {Existing co-design methods support verbal children on the autism spectrum in the design process, while their minimally-verbal peers are overlooked. We describe Co-Design Beyond Words (CDBW), an approach which merges existing co-design methods with practice-based methods from Speech and Language Therapy which are child-led and interests-based. These emphasise the rich detail that can be conveyed in the moment, through recognising occurrences of, for example, Joint Attention, Turn Taking and Imitation. We worked in an autism-specific primary school over 20 weeks with ten children, aged 5 to 8. We co-designed a playful prototype, the TangiBall, using the three iterative phases of CDBW; the Foundation Phase (preparation for interaction), the Interaction Phase (designing-and-reflecting in the moment) and the Reflection Phase (reflection-on-action). We contribute a novel co-design approach and present moments of interaction, the micro instances in design in which minimally-verbal children on the spectrum can convey meaning beyond words, through their actions, interactions, and attentional foci. These moments of interaction provide design insight, shape design direction, and reveal unique strengths, interests, and abilities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {speech and language therapy, participatory design, non-verbal, minimally-verbal, co-design, child-led, autism},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300639,
author = {Cherng, Fu-Yin and Lee, Yi-Chen and King, Jung-Tai and Lin, Wen-Chieh},
title = {Measuring the Influences of Musical Parameters on Cognitive and Behavioral Responses to Audio Notifications Using EEG and Large-Scale Online Studies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300639},
doi = {10.1145/3290605.3300639},
abstract = {Prior studies have evaluated various designs for audio notifications. However, calls for more in-depth research on how such notifications work, especially at the level of users' cognitive states, have gone unanswered; and studies evaluating audio notifications with large numbers of participants in multiple environments have been rare. This study conducted an electroencephalography study (N=20) and an online study (N=967) to enhance understandings of how three musical parameters - melody (simple, complex), pitch (high, low), and tempo (fast, slow) - influenced users' cognition and behaviors. There are eight different notifications with different combinations of these parameters. The online study analyzed the effects of user-specific and environmental information on users' behaviors while they listened to these notifications. The results revealed that tempo and pitch have the main effect on the speed and strength (accuracy) of users' cognition and behaviors. The users' characteristics and environments influenced the effects of these musical parameters.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {audio notifications, neuroergonomics, brain-computer interface},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300237,
author = {Mallavarapu, Aditi and Lyons, Leilah and Uzzo, Stephen and Thompson, Wren and Levy-Cohen, Rinat and Slattery, Brian},
title = {Connect-to-Connected Worlds: Piloting a Mobile, Data-Driven Reflection Tool for an Open-Ended Simulation at a Museum},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300237},
doi = {10.1145/3290605.3300237},
abstract = {Immersive open-ended museum exhibits promote ludic engagement and can be a powerful draw for visitors, but these qualities may also make learning more challenging. We describe our efforts to help visitors engage more deeply with an interactive exhibit's content by giving them access to visualizations of data skimmed from their use of the exhibit. We report on the motivations and challenges in designing this reflective tool, which positions visitors as a "human in the loop" to understand and manage their engagement with the exhibit. We used an iterative design process and qualitative methods to explore how and if visitors could (1) access and (2) comprehend the data visualizations, (3) reflect on their prior engagement with the exhibit, (4)plan their future engagement with the exhibit, and (5) act on their plans. We further discuss the essential design challenges and the opportunities made possible for visitors through data-driven reflection tools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {informal data literacy, cscl, reflective informatics, museum exhibit design, systems thinking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300663,
author = {Reinfelder, Lena and Landwirth, Robert and Benenson, Zinaida},
title = {Security Managers Are Not The Enemy Either},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300663},
doi = {10.1145/3290605.3300663},
abstract = {Security managers are leading employees whose decisions shape security measures and thus influence the everyday work of all users in their organizations. To understand how security managers handle user requirements and behavior, we conducted semi-structured interviews with seven security managers from large-scale German companies. Our results indicate that due to the absence of organizational structures that include users into security development processes, security managers unintentionally obtain a negative view on users. Their distrust towards users leads to the creation of technical security measures that cannot be influenced by users in any way. However, as previous research has repeatedly shown, rigid security measures lead to frustration and discouragement of users, and also to creative (but usually insecure) methods of security circumvention. We conclude that in order to break through this vicious cycle, security managers need organizational structures, methods and tools that facilitate systematic feedback from users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {security managers, organizational security},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300615,
author = {Neate, Timothy and Roper, Abi and Wilson, Stephanie and Marshall, Jane},
title = {Empowering Expression for Users with Aphasia through Constrained Creativity},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300615},
doi = {10.1145/3290605.3300615},
abstract = {Creative activities allow people to express themselves in rich, nuanced ways. However, being creative does not always come easily. For example, people with speech and language impairments, such as aphasia, face challenges in creative activities that involve language. In this paper, we explore the concept of constrained creativity as a way of addressing this challenge and enabling creative writing. We report an app, MakeWrite, that supports the constrained creation of digital texts through automated redaction. The app was co-designed with and for people with aphasia and was subsequently explored in a workshop with a group of people with aphasia. Participants were not only successful in crafting novel language, but, importantly, self-reported that the app was crucial in enabling them to do so. We refect on the potential of technology-supported constrained creativity as a means of empowering expression amongst users with diverse needs.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {content creation, constrained creativity, speech impairments, poetry, aphasia, creativity, creative writing, accessibility},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300248,
author = {Wang, Anran and Gollakota, Shyamnath},
title = {MilliSonic: Pushing the Limits of Acoustic Motion Tracking},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300248},
doi = {10.1145/3290605.3300248},
abstract = {Recent years have seen interest in device tracking and localization using acoustic signals. State-of-the-art acoustic motion tracking systems however do not achieve millimeter accuracy and require large separation between microphones and speakers, and as a result, do not meet the requirements for many VR/AR applications. Further, tracking multiple concurrent acoustic transmissions from VR devices today requires sacrificing accuracy or frame rate. We present MilliSonic, a novel system that pushes the limits of acoustic based motion tracking. Our core contribution is a novel localization algorithm that can provably achieve sub-millimeter 1D tracking accuracy in the presence of multipath, while using only a single beacon with a small 4-microphone array.Further, MilliSonic enables concurrent tracking of up to four smartphones without reducing frame rate or accuracy. Our evaluation shows that MilliSonic achieves 0.7mm median 1D accuracy and a 2.6mm median 3D accuracy for smartphones, which is 5x more accurate than state-of-the-art systems. MilliSonic enables two previously infeasible interaction applications: a) 3D tracking of VR headsets using the smartphone as a beacon and b) fine-grained 3D tracking for the Google Cardboard VR system using a small microphone array.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {virtual reality, localization, motion tracking, acoustic, mobile system},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300704,
author = {Kizilcec, Ren\'{e} F. and Saltarelli, Andrew J.},
title = {Psychologically Inclusive Design: Cues Impact Women's Participation in STEM Education},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300704},
doi = {10.1145/3290605.3300704},
abstract = {Visual and verbal cues can reinforce barriers to access for women in science, technology, engineering, and math (STEM) disciplines. Psychologically inclusive design is an evidence-based approach to reduce psychological barriers by strategically placing content and design cues in the environment. Two large field experiments provide estimates of the behavioral impact of psychologically inclusive cues on women's and men's enrollment behaviors in an online learning environment. First, a gender-inclusive photo and statement in an online advertisement for a STEM course increased the click-through rate among women but not men by 26% (N=209,000). Second, an inclusivity statement with a gender-inclusive course image to the enrollment page raised the proportion of women enrolling in a STEM course by up to 18% (N=63,000). These findings contribute evidence of the behavioral impact of psychologically inclusive design to the literature and yield practical implications for the presentation of STEM opportunities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {inclusion, diversity, social psychology, education, equality, design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300584,
author = {Al Zayer, Majed and Adhanom, Isayas B. and MacNeilage, Paul and Folmer, Eelke},
title = {The Effect of Field-of-View Restriction on Sex Bias in VR Sickness and Spatial Navigation Performance},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300584},
doi = {10.1145/3290605.3300584},
abstract = {Recent studies show that women are more susceptible to visually-induced VR sickness, which might explain the low adoption rate of VR technology among women. Reducing field-of-view (FOV) during locomotion is already a widely used strategy to reduce VR sickness as it blocks peripheral optical flow perception and mitigates visual/vestibular conflict. Prior studies show that men are more adept at 3D spatial navigation than women, though this sex bias can be minimized by providing women with a larger FOV. Our study provides insight into the relationship between sex and FOV restriction with respect to VR sickness and spatial navigation performance which seem to conflict. We find the use of an FOV restrictor to be effective in mitigating VR sickness in both sexes while we did not find a negative effect of FOV restriction on spatial navigation performance.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {field-of-view manipulation, sex differences, spatial navigation performance, virtual locomotion, virtual reality, vr sickness},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300575,
author = {Friske, Mikhaila and Wu, Shanel and Devendorf, Laura},
title = {AdaCAD: Crafting Software For Smart Textiles Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300575},
doi = {10.1145/3290605.3300575},
abstract = {Woven smart textiles are useful in creating flexible electronics because they integrate circuitry into the structure of the fabric itself. However, there do not yet exist tools that support the specific needs of smart textiles weavers. This paper describes the process and development of AdaCAD, an application for composing smart textile weave drafts. By augmenting traditional weaving drafts, AdaCAD allows weavers to design woven structures and circuitry in tandem and offers specific support for common smart textiles techniques. We describe these techniques, how our tool supports them alongside feedback from smart textiles weavers. We conclude with a reflection on smart textiles practice more broadly and suggest that the metaphor of coproduction can be fruitful in creating effective tools and envisioning future applications in this space.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart textiles, weaving, computer-aided design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300283,
author = {Vorvoreanu, Mihaela and Zhang, Lingyi and Huang, Yun-Han and Hilderbrand, Claudia and Steine-Hanson, Zoe and Burnett, Margaret},
title = {From Gender Biases to Gender-Inclusive Design: An Empirical Investigation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300283},
doi = {10.1145/3290605.3300283},
abstract = {In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases -- not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software's inclusiveness: women succeeded more often in the new version than in the original; men's success rates improved too; and the gender gap entirely disappeared.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {gendermag, gender biases, gender-inclusive software},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300539,
author = {Seetharaman, Prem and Mysore, Gautham and Pardo, Bryan and Smaragdis, Paris and Gomes, Celso},
title = {VoiceAssist: Guiding Users to High-Quality Voice Recordings},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300539},
doi = {10.1145/3290605.3300539},
abstract = {Voice recording is a challenging task with many pitfalls due to sub-par recording environments, mistakes in recording setup, microphone quality, etc. Newcomers to voice recording often have difficulty recording their voice, leading to recordings with low sound quality. Many amateur recordings of poor quality have two key problems: too much reverberation (echo), and too much background noise (e.g. fans, electronics, street noise). We present VoiceAssist, a system that helps inexperienced users produce high quality recordings by providing real-time visual feedback on audio quality. We integrate modern audio quality measures into an interactive human-machine feedback loop, so that the audio quality can be maximized at capture-time. We demonstrate the utility of this feedback for improving the recording quality with a user study. When presented with visual feedback about recording quality, users produced recordings that were strongly preferred by third-party listeners, when compared to recordings made without this feedback.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {active capture, speech, creativity support tools, interfaces, audio quality, feedback, narration, voice recording},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300478,
author = {August, Tal and Reinecke, Katharina},
title = {Pay Attention, Please: Formal Language Improves Attention in Volunteer and Paid Online Experiments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300478},
doi = {10.1145/3290605.3300478},
abstract = {Participant engagement in online studies is key to collecting reliable data, yet achieving it remains an often discussed challenge in the research community. One factor that might impact engagement is the formality of language used to communicate with participants throughout the study. Prior work has found that language formality can convey social cues and power hierarchies, affecting people's responses and actions. We explore how formality influences engagement, measured by attention, dropout, time spent on the study and participant performance, in an online study with 369 participants on Mechanical Turk (paid) and LabintheWild (volunteer). Formal language improves participant attention compared to using casual language in both paid and volunteer conditions, but does not affect dropout, time spent, or participant performance. We suggest using more formal language in studies containing complex tasks where fully reading instructions is especially important. We also highlight trade-offs that different recruitment incentives provide in online experimentation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {attention, data quality, online experiments, language formality, participant engagement},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300275,
author = {Pierce, James},
title = {Smart Home Security Cameras and Shifting Lines of Creepiness: A Design-Led Inquiry},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300275},
doi = {10.1145/3290605.3300275},
abstract = {Through a design-led inquiry focused on smart home security cameras, this research develops three key concepts for research and design pertaining to new and emerging digital consumer technologies. Digital leakage names the propensity for digital information to be shared, stolen, and misused in ways unbeknownst or even harmful to those to whom the data pertains or belongs. Hole-and-corner applications are those functions connected to users' data, devices, and interactions yet concealed from or downplayed to them, often because they are non-beneficial or harmful to them. Foot-in-the-door devices are product and services with functional offerings and affordances that work to normalize and integrate a technology, thus laying groundwork for future adoption of features that might have earlier been rejected as unacceptable or unnecessary. Developed and illustrated through a set of design studies and explorations, this paper shows how these concepts may be used analytically to investigate issues such as privacy and security, anticipatorily to speculate about the future of technology development and use, and generatively to synthesize design concepts and solutions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {speculative design, smart home, research through design, internet of things, design research},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300823,
author = {Harrington, Christina N. and Borgos-Rodriguez, Katya and Piper, Anne Marie},
title = {Engaging Low-Income African American Older Adults in Health Discussions through Community-Based Design Workshops},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300823},
doi = {10.1145/3290605.3300823},
abstract = {Community-based approaches to participatory design, such as the design workshop, promise to engage underserved populations in collaborative dialog and provide a platform for promoting the views of communities who are not typically given a space to engage in design. Yet, we know little about how design workshops as a research site can engage underserved individuals (i.e., due to class, race, or age status) or address personal concerns (e.g., health). As a way of exploring these issues, we conducted a series of five design workshops with low-income African-American older adults to understand their health experiences. Our findings reveal three insights associated with the design workshop and the topic of health: comfort with community versus personal health; the sociocultural configuration of interaction; and empowerment in the context of systematic inequality of opportunity. We discuss the importance of understanding the situated nature of design workshops, particularly when engaging underserved groups in the topic of health, and the potential of the design workshop as a mechanism for activism.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {health, older adults, community-based participatory research, participatory design, community activism},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300377,
author = {Funk, Markus and M\"{u}ller, Florian and Fendrich, Marco and Shene, Megan and Kolvenbach, Moritz and Dobbertin, Niclas and G\"{u}nther, Sebastian and M\"{u}hlh\"{a}user, Max},
title = {Assessing the Accuracy of Point &amp; Teleport Locomotion with Orientation Indication for Virtual Reality Using Curved Trajectories},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300377},
doi = {10.1145/3290605.3300377},
abstract = {Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point &amp; teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three different point &amp; teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, teleportation, orientation indication, point &amp; teleport, locomotion, virtual environments},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300460,
author = {Choi, Minsuk and Park, Cheonbok and Yang, Soyoung and Kim, Yonggyu and Choo, Jaegul and Hong, Sungsoo Ray},
title = {AILA: Attentive Interactive Labeling Assistant for Document Classification through Attention-Based Deep Neural Networks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300460},
doi = {10.1145/3290605.3300460},
abstract = {Document labeling is a critical step in building various machine learning applications. However, the step can be time-consuming and arduous, requiring a significant amount of human efforts. To support an efficient document labeling environment, we present a system called Attentive Interactive Labeling Assistant (AILA). In its core, AILA uses Interactive Attention Module (IAM), a novel module that visually highlights words in a document that labelers may pay attention to when labeling a document. IAM utilizes attention-based Deep Neural Networks which not only support a prediction of which words to highlight but also enable labelers to indicate words that should be assigned a high attention weight while labeling to improve the future quality of word prediction.We evaluated the labeling efficiency and the accuracy by comparing the conditions with and without IAM in our study. The results showed that participants' labeling efficiency increased significantly under the condition with IAM than the condition without IAM, while the two conditions maintained roughly the same labeling accuracy.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interactive attention module, aila, neural language processing, document labeling},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300544,
author = {Hofmann, Megan and Williams, Kristin and Kaplan, Toni and Valencia, Stephanie and Hann, Gabriella and Hudson, Scott E. and Mankoff, Jennifer and Carrington, Patrick},
title = {"Occupational Therapy is Making": Clinical Rapid Prototyping and Digital Fabrication},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300544},
doi = {10.1145/3290605.3300544},
abstract = {Consumer-fabrication technologies potentially improve the effectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and co-designed AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran's Affairs Hospital. We find that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and itsdo-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians' expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {rapid prototyping, adaptive design, 3d printing, occupational therapy, digital fabrication},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300298,
author = {Choi, In Kwon and Childers, Taylor and Raveendranath, Nirmal Kumar and Mishra, Swati and Harris, Kyle and Reda, Khairi},
title = {Concept-Driven Visual Analytics: An Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300298},
doi = {10.1145/3290605.3300298},
abstract = {Visualization tools facilitate exploratory data analysis, but fall short at supporting hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations might support a concept-driven analysis style, where users can optionally share their hypotheses and conceptual models in natural language, and receive customized plots depicting the fit of their models to the data. We report on how participants leveraged these unique affordances for visual analysis. We found that a majority of participants articulated meaningful models and predictions, utilizing them as entry points to sensemaking. We contribute an abstract typology representing the types of models participants held and externalized as data expectations. Our findings suggest ways for rearchitecting visual analytics tools to better support hypothesis- and model-based reasoning, in addition to their traditional role in exploratory analysis. We discuss the design implications and reflect on the potential benefits and challenges involved.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {hypothesis- and model-based reasoning, mental models, sensemaking, visual analytics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300253,
author = {Rifat, Mohammad Rashidujjaman and Prottoy, Hasan Mahmud and Ahmed, Syed Ishtiaque},
title = {The Breaking Hand: Skills, Care, and Sufferings of the Hands of an Electronic Waste Worker in Bangladesh},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300253},
doi = {10.1145/3290605.3300253},
abstract = {While repair work has recently been getting increasing attention in HCI, recycling practices have still remained relatively understudied, especially in the context of the Global South. To this end, building on our eight-month-long ethnography, this paper reports the electronic waste (`e-waste', henceforth) recycling practices among the e-waste recycler (`bhangari') communities in Dhaka, Bangladesh. In doing so, this paper offers the work of the bhangaris through an articulation of their hands and their uses. Drawing from a rich body of scholarly work on social science, we define and contextualize three characteristics of the hand of a bhangari: knowledge, care, and skills and collaboration. Our study also highlights the pains and sufferings involved in this profession. By explaining bhangari work through the hand, we also discuss its implications for design, and its connection to HCI's broader interest in sustainability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {tactile experience, electronic waste, recycle, ictd},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300800,
author = {Yamanaka, Shota},
title = {Steering Performance with Error-Accepting Delays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300800},
doi = {10.1145/3290605.3300800},
abstract = {In steering law tasks, deviating from the path is immediately considered an error operation. However, in navigating a hierarchical menu item, which is a representative application of the law, a deviation within a short duration is sometimes permitted. We tested the validity of the steering law model with various durations of such error-accepting delays and found that it showed high fits for each delay condition (R2 &gt; 0.96) but poor fits if the delay values were not separated (R2 = 0.58). Because the average movement speed linearly increased as the delay increased, we refined the model by taking the delay into account, and the fitness was significantly improved (R2 = 0.97). Our model will help GUI designers estimate the average operational time on the basis of the menu item length, width, and error-accepting delay.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {graphical user interfaces, menu design, delay, indirect pointing, steering law},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300922,
author = {Warner, Mark and Maestre, Juan F. and Gibbs, Jo and Chung, Chia-Fang and Blandford, Ann},
title = {Signal Appropriation of Explicit HIV Status Disclosure Fields in Sex-Social Apps Used by Gay and Bisexual Men},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300922},
doi = {10.1145/3290605.3300922},
abstract = {HIV status disclosure fields in online sex-social applications ("apps") are designed to help increase awareness, reduce stigma, and promote sexual health. Public disclosure could also help those diagnosed relate to others with similar statuses to feel less isolated. However, in our interview study (n=28) with HIV positive and negative men who have sex with men (MSM), we found some users preferred to keep their status private, especially when disclosure could stigmatise and disadvantage them, or risk revealing their status to someone they knew offline in a different context. How do users manage these tensions between health, stigma, and privacy? We analysed our interview data using signalling theory as a conceptual framework and identify participants developing 'signal appropriation' strategies, helping them manage the disclosure of their HIV status. Additionally, we propose a set of design considerations that explore the use of signals in the design of sensitive disclosure fields.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {signal appropriation, hiv disclosure, privacy unraveling, stigmatized populations, online dating, stigma, signalling theory},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300532,
author = {Gaver, William and Boucher, Andy and Vanis, Michail and Sheen, Andy and Brown, Dean and Ovalle, Liliana and Matsuda, Naho and Abbas-Nazari, Amina and Phillips, Robert},
title = {My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300532},
doi = {10.1145/3290605.3300532},
abstract = {My Naturewatch Camera is an inexpensive wildlife camera that we designed for people to make themselves as a way of promoting engagement with nature and digital making. We aligned its development to the interests of the BBC's Natural History Unit as part of an orchestrated engagement strategy also involving our project website and outreach to social media. Since June 2018, when the BBC featured the camera on one of their Springwatch 2018 broadcasts, over 1000 My Naturewatch Cameras have been constructed using instructions and software from our project website and commercially available components, without direct contact with our studio. In this paper, we describe the project and outcomes with a focus on its success in promoting engagement with nature, engagement with digital making, and the effectiveness of this strategy for sharing research products outside traditional commercial channels.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {nature, open-source product, camera, diy design, wildlife, research through design, design research},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300833,
author = {Sutton, Selina Jeanne and Foulkes, Paul and Kirk, David and Lawson, Shaun},
title = {Voice as a Design Material: Sociophonetic Inspired Design Strategies in Human-Computer Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300833},
doi = {10.1145/3290605.3300833},
abstract = {While there is a renewed interest in voice user interfaces (VUI) in HCI, little attention has been paid to the design of VUI voice output beyond intelligibility and naturalness. We draw on the field of sociophonetics - the study of the social factors that influence the production and perception of speech - to highlight how current VUIs are based on a limited and homogenised set of voice outputs. We argue that current systems do not adequately consider the diversity of peoples' speech, how that diversity represents sociocultural identities, and how voices have the potential to shape user perceptions and experiences. Ultimately, as other technological developments have influenced the ideologies of language, the voice outputs of VUIs will influence the ideologies of speech. Based on our argument, we pose three design strategies for VUI voice output design - individualisation, context awareness, and diversification - to motivate new ways of conceptualising and designing these technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sociophonetics, computer synthesized speech, experience-centered design, voice user interface, design material},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300323,
author = {Vaziripour, Elham and Howard, Devon and Tyler, Jake and O'Neill, Mark and Wu, Justin and Seamons, Kent and Zappala, Daniel},
title = {I Don't Even Have to Bother Them! Using Social Media to Automate the Authentication Ceremony in Secure Messaging},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300323},
doi = {10.1145/3290605.3300323},
abstract = {The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {authentication ceremony, social authentication, secure messaging applications},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300392,
author = {Kobayashi, Jumpei and Kawashima, Toshio},
title = {Paragraph-Based Faded Text Facilitates Reading Comprehension},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300392},
doi = {10.1145/3290605.3300392},
abstract = {We propose a new text layout that facilitates reading comprehension. By sequentially fading out characters sentence-by-sentence from the beginning of each paragraph, we highlight the paragraph structure of the entire text and the relative positions of the sentences. To evaluate the effectiveness of the paragraph-based faded text in a reading comprehension, we measure the comprehension, eye movements, and recognition for both the proposed method and a conventional standard method. In the proposed method, rates of correct answers to text comprehension questions are improved. Moreover, the proposed method leads to slower reading speeds and better recognition rates for the first sentences of paragraphs, which are displayed in a relatively thicker mode. With the paragraph-based faded text, the reader is naturally facilitated to pay attention to the first sentence of each paragraph, suggesting that this reading style could result in a more accurate text comprehension.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {eye movements, text comprehension, text layout, reading},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300559,
author = {Laput, Gierad and Harrison, Chris},
title = {SurfaceSight: A New Spin on Touch, User, and Object Sensing for IoT Experiences},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300559},
doi = {10.1145/3290605.3300559},
abstract = {IoT appliances are gaining consumer traction, from smart thermostats to smart speakers. These devices generally have limited user interfaces, most often small buttons and touchscreens, or rely on voice control. Further, these devices know little about their surroundings unaware of objects, people and activities happening around them. Consequently, interactions with these "smart" devices can be cumbersome and limited. We describe SurfaceSight, an approach that enriches IoT experiences with rich touch and object sensing, offering a complementary input channel and increased contextual awareness. For sensing, we incorporate LIDAR into the base of IoT devices, providing an expansive, ad hoc plane of sensing just above the surface on which devices rest. We can recognize and track a wide array of objects, including finger input and hand gestures. We can also track people and estimate which way they are facing. We evaluate the accuracy of these new capabilities and illustrate how they can be used to power novel and contextually-aware interactive experiences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ubiquitous sensing, iot, smart environments},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300632,
author = {Sharma, Adwait and Roo, Joan Sol and Steimle, J\"{u}rgen},
title = {Grasping Microgestures: Eliciting Single-Hand Microgestures for Handheld Objects},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300632},
doi = {10.1145/3290605.3300632},
abstract = {Single-hand microgestures have been recognized for their potential to support direct and subtle interactions. While pioneering work has investigated sensing techniques and presented first sets of intuitive gestures, we still lack a systematic understanding of the complex relationship between microgestures and various types of grasps. This paper presents results from a user elicitation study of microgestures that are performed while the user is holding an object. We present an analysis of over 2,400 microgestures performed by 20 participants, using six different types of grasp and a total of 12 representative handheld objects of varied geometries and size. We expand the existing elicitation method by proposing statistical clustering on the elicited gestures. We contribute detailed results on how grasps and object geometries affect single-hand microgestures, preferred locations, and fingers used. We also present consolidated gesture sets for different grasps and object size. From our findings, we derive recommendations for the design of microgestures compatible with a large variety of handheld objects.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {object, gestures, microgestures, touch, gesture recognition, grasp, elicitation study},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300790,
author = {Lee, Injung and Kim, Sunjun and Lee, Byungjoo},
title = {Geometrically Compensating Effect of End-to-End Latency in Moving-Target Selection Games},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300790},
doi = {10.1145/3290605.3300790},
abstract = {Effects of unintended latency on gamer performance have been reported. End-to-end latency can be corrected by post-input manipulation of activation times, but this gives the player unnatural gameplay experience. For moving-target selection games such as Flappy Bird, the paper presents a predictive model of latency on error rate and a novel compensation method for the latency effects by adjusting the game's geometry design -- e.g., by modifying the size of the selection region. Without manipulation of the game clock, this can keep the user's error rate constant even if the end-to-end latency of the system changes. The approach extends the current model of moving-target selection with two additional assumptions about the effects of latency: (1) latency reduces players' cue-viewing time and (2) pushes the mean of the input distribution backward. The model and method proposed have been validated through precise experiments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {latency compensation, moving-target selection},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300578,
author = {Alghofaili, Rawan and Sawahata, Yasuhito and Huang, Haikun and Wang, Hsueh-Cheng and Shiratori, Takaaki and Yu, Lap-Fai},
title = {Lost in Style: Gaze-Driven Adaptive Aid for VR Navigation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300578},
doi = {10.1145/3290605.3300578},
abstract = {A key challenge for virtual reality level designers is striking a balance between maintaining the immersiveness of VR and providing users with on-screen aids after designing a virtual experience. These aids are often necessary for wayfinding in virtual environments with complex paths. We introduce a novel adaptive aid that maintains the effectiveness of traditional aids, while equipping designers and users with the controls of how often help is displayed. Our adaptive aid uses gaze patterns in predicting user's need for navigation aid in VR and displays mini-maps or arrows accordingly. Using a dataset of gaze angle sequences of users navigating a VR environment and markers of when users requested aid, we trained an LSTM to classify user's gaze sequences as needing navigation help and display an aid. We validated the efficacy of the adaptive aid for wayfinding compared to other commonly-used wayfinding aids.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {eyetracking, vr, games, wayfinding},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300422,
author = {Mylavarapu, Pranathi and Yalcin, Adil and Gregg, Xan and Elmqvist, Niklas},
title = {Ranked-List Visualization: A Graphical Perception Study},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300422},
doi = {10.1145/3290605.3300422},
abstract = {Visualization of ranked lists is a common occurrence, but many in-the-wild solutions fly in the face of vision science and visualization wisdom. For example, treemaps and bubble charts are commonly used for this purpose, despite the fact that the data is not hierarchical and that length is easier to perceive than area. Furthermore, several new visual representations have recently been suggested in this area, including wrapped bars, packed bars, piled bars, and Zvinca plots. To quantify the differences and trade-offs for these ranked-list visualizations, we here report on a crowdsourced graphical perception study involving six such visual representations, including the ubiquitous scrolled barchart, in three tasks: ranking (assessing a single item), comparison (two items), and average (assessing global distribution). Results show that wrapped bars may be the best choice for visualizing ranked lists, and that treemaps are surprisingly accurate despite the use of area rather than length to represent value.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data visualization, graphical perception, ranked lists},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300754,
author = {Li, Qisheng and Morris, Meredith Ringel and Fourney, Adam and Larson, Kevin and Reinecke, Katharina},
title = {The Impact of Web Browser Reader Views on Reading Speed and User Experience},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300754},
doi = {10.1145/3290605.3300754},
abstract = {As reading increasingly shifts from paper to online media, many web browsers now provide a "Reader View,'' which modifies web page layout and design for better readability. However, research has yet to establish whether Reader Views are effective in improving readability and how they might change the user experience. We characterize how Mozilla Firefox's Reader View significantly reduces the visual complexity of websites by excluding menus, images, and content. We then conducted an online study with 391 participants (including 42 who self-reported having been diagnosed with dyslexia), showing that compared to standard websites the Reader View increased reading speed by 5% for readers on average, and significantly improved perceived readability and visual appeal. We suggest guidelines for the design of websites and browsers that better support people with varying reading skills.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {reader view, dyslexia, online reading, website design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300555,
author = {Prouzeau, Arnaud and Cordeil, Maxime and Robin, Clement and Ens, Barrett and Thomas, Bruce H. and Dwyer, Tim},
title = {Scaptics and Highlight-Planes: Immersive Interaction Techniques for Finding Occluded Features in 3D Scatterplots},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300555},
doi = {10.1145/3290605.3300555},
abstract = {Three-dimensional scatterplots suffer from well-known perception and usability problems. In particular, overplotting and occlusion, mainly due to density and noise, prevent users from properly perceiving the data. Thanks to accurate head and hand tracking, immersive Virtual Reality (VR) setups provide new ways to interact and navigate with 3D scatterplots. VR also supports additional sensory modalities such as haptic feedback. Inspired by methods commonly used in Scientific Visualisation to visually explore volumes, we propose two techniques that leverage the immersive aspects of VR: first, a density-based haptic vibration technique (Scaptics) which provides feedback through the controller; and second, an adaptation of a cutting plane for 3D scatterplots (Highlight-Plane). We evaluated both techniques in a controlled study with two tasks involving density (finding high- and low-density areas). Overall, Scaptics was the most time-efficient and accurate technique, however, in some conditions, it was outperformed by Highlight-Plane.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3d scatterplot, virtual reality, vibrotactile feedback, haptic},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300507,
author = {Sabie, Samar and Parikh, Tapan},
title = {Cultivating Care through Ambiguity: Lessons from a Service Learning Course},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300507},
doi = {10.1145/3290605.3300507},
abstract = {Given the focus of professional graduate ICT programs on technical and managerial skills, pedagogical engagement with external organizations tends to be transactional and artifact-centered. This inhibits the students' ability to understand social, technical and ethical issues in context, or to develop affective relationships with users and other stakeholders. To address this, we designed a service learning course that partnered students with non-profit organizations to help with their technology challenges. The service project was deliberately left open-ended to force students (and partners) to tackle important questions around project scoping and impact. By drawing parallels to soil care practices, we explore how "care time" emerged in this context, and how the incorporation of ambiguity galvanized students, community, and faculty to make time to navigate it. This led to non-tangible yet vital outcomes such as overcoming social limitations, building symbiotic relationships, and enacting acts of care necessary for more ethical orchestration of technology.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {relationality, service learning, care, community engagement},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300305,
author = {Swearngin, Amanda and Li, Yang},
title = {Modeling Mobile Interface Tappability Using Crowdsourcing and Deep Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300305},
doi = {10.1145/3290605.3300305},
abstract = {Tapping is an immensely important gesture in mobile touchscreen interfaces, yet people still frequently are required to learn which elements are tappable through trial and error. Predicting human behavior for this everyday gesture can help mobile app designers understand an important aspect of the usability of their apps without having to run a user study. In this paper, we present an approach for modeling tappability of mobile interfaces at scale. We conducted large-scale data collection of interface tappability over a rich set of mobile apps using crowdsourcing and computationally investigated a variety of signifiers that people use to distinguish tappable versus not-tappable elements. Based on the dataset, we developed and trained a deep neural network that predicts how likely a user will perceive an interface element as tappable versus not tappable. Using the trained tappability model, we developed TapShoe, a tool that automatically diagnoses mismatches between the tappability of each element as perceived by a human user---predicted by our model, and the intended or actual tappable state of the element specified by the developer or designer. Our model achieved reasonable accuracy: mean precision 90.2% and recall 87.0%, in matching human perception on identifying tappable UI elements. The tappability model and TapShoe were well received by designers via an informal evaluation with 7 professional interaction designers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {tappability, deep learning, mobile interfaces, crowdsourcing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300587,
author = {Ruan, Sherry and Jiang, Liwei and Xu, Justin and Tham, Bryce Joe-Kun and Qiu, Zhengneng and Zhu, Yeshuang and Murnane, Elizabeth L. and Brunskill, Emma and Landay, James A.},
title = {QuizBot: A Dialogue-Based Adaptive Learning System for Factual Knowledge},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300587},
doi = {10.1145/3290605.3300587},
abstract = {Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with, but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {intelligent systems, pedagogical agents, conversational user interfaces, educational applications, chatbots},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300485,
author = {Ali, Abdullah X. and Morris, Meredith Ringel and Wobbrock, Jacob O.},
title = {Crowdlicit: A System for Conducting Distributed End-User Elicitation and Identification Studies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300485},
doi = {10.1145/3290605.3300485},
abstract = {End-user elicitation studies are a popular design method. Currently, such studies are usually confined to a lab, limiting the number and diversity of participants, and therefore the representativeness of their results. Furthermore, the quality of the results from such studies generally lacks any formal means of evaluation. In this paper, we address some of the limitations of elicitation studies through the creation of the Crowdlicit system along with the introduction of end-user identification studies, which are the reverse of elicitation studies. Crowdlicit is a new web-based system that enables researchers to conduct online and in-lab elicitation and identification studies. We used Crowdlicit to run a crowd-powered elicitation study based on Morris's "Web on the Wall" study (2012) with 78 participants, arriving at a set of symbols that included six new symbols different from Morris's. We evaluated the effectiveness of 49 symbols (43 from Morris and six from Crowdlicit) by conducting a crowd-powered identification study. We show that the Crowdlicit elicitation study resulted in a set of symbols that was significantly more identifiable than Morris's.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mechanical turk, user-driven design, crowdsourcing, end-user elicitation study, end-user identification study},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300277,
author = {Myers, Chelsea M. and Furqan, Anushay and Zhu, Jichen},
title = {The Impact of User Characteristics and Preferences on Performance with an Unfamiliar Voice User Interface},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300277},
doi = {10.1145/3290605.3300277},
abstract = {Voice User Interfaces (VUIs) are increasing in popularity. However, their invisible nature with no or limited visuals makes it difficult for users to interact with unfamiliar VUIs. We analyze the impact of user characteristics and preferences on how users interact with a VUI-based calendar, DiscoverCal. While recent VUI studies analyze user behavior through self-reported data, we extend this research by analyzing both VUI usage data and self-reported data to observe correlations between both data types. Results from our user study (n=50) led to four key findings: 1) programming experience did not have a wide-spread impact on performance metrics while 2) assimilation bias did, 3) participants with more technical confidence exhibited a trial-and-error approach, and 4) desiring more guidance from our VUI correlated with performance metrics that indicate cautious users.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {voice user interfaces, multimodal interfaces, user experience, voice, empirical analysis},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300249,
author = {Hahn, Nathan and Iqbal, Shamsi T. and Teevan, Jaime},
title = {Casual Microtasking: Embedding Microtasks in Facebook},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300249},
doi = {10.1145/3290605.3300249},
abstract = {Microtasks enable people with limited time and context to contribute to a larger task. In this paper we explore casual microtasking, where microtasks are embedded into other primary activities so that they are available to be completed when convenient. We present a casual microtasking experience that inserts writing microtasks from an existing microwriting tool into the user's Facebook feed. From a two-week deployment of the system with nine people, we observe that casual microtasking enabled participants to get things done during their breaks, and that they tended to do so only after first engaging with Facebook's social content. Participants were most likely to complete the writing microtasks during periods of the day associated with low focus, and would occasionally use them as a springboard to open the original document in Word. These findings suggest casual microtasking can help people leverage spare micromoments to achieve meaningful micro-goals, and even encourage them to return to work.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {interruptions, microtasking, tasks, casual microtasking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300620,
author = {Lewis, Makayla and Perry, Mark},
title = {Follow the Money: Managing Personal Finance Digitally},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300620},
doi = {10.1145/3290605.3300620},
abstract = {The move towards digital payments and mobile money, and away from physical cash and banking services offers users opportunities to change the ways that they can spend, save and manage their money through a variety of personal financial management services. However, set against ordinary, everyday patterns of spending, saving and other forms of financial transaction, it is not clear how users might interact with, understand, or value financial management services that utilise rich data and connected digital content for their personal use. In order to explore how people might engage with such systems, we conducted a study of financial activity, following people's transactional activity over time, and interviewing them about their practices, understandings, needs, concerns and expectations of current and future financial technologies. Drawing from the everyday activities and practices observed, we identify implications for the design of digitally enabled, personal financial systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {user experience design, diary study, mobile money, interaction design, digital money, interviews},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300238,
author = {Hiniker, Alexis and Froehlich, Jon E. and Zhang, Mingrui and Beneteau, Erin},
title = {Anchored Audio Sampling: A Seamless Method for Exploring Children's Thoughts During Deployment Studies},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300238},
doi = {10.1145/3290605.3300238},
abstract = {Many traditional HCI methods, such as surveys and interviews, are of limited value when working with preschoolers. In this paper, we present anchored audio sampling (AAS), a remote data collection technique for extracting qualitative audio samples during field deployments with young children. AAS offers a developmentally sensitive way of understanding how children make sense of technology and situates their use in the larger context of daily life. AAS is defined by an anchor event, around which audio is collected. A sliding window surrounding this anchor captures both antecedent and ensuing recording, providing the researcher insight into the activities that led up to the event of interest as well as those that followed. We present themes from three deployments that leverage this technique. Based on our experiences using AAS, we have also developed a reusable open-source library for embedding AAS into any Android application.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {field deployments, context-aware esm, cci, early childhood, data collection tools, study methods},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300904,
author = {Jo, Yonggeol and Kim, Minwoo and Han, Kyungsik},
title = {How Do Humans Assess the Credibility on Web Blogs: Qualifying and Verifying Human Factors with Machine Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300904},
doi = {10.1145/3290605.3300904},
abstract = {The purpose of this paper is to understand the factors involved when a human judges the credibility of information and to develop a classification model for weblogs, a primary source of information for many people. Considering both computational and human-centered approaches, we conducted a user study designed to consider two cognitive procedures--(1) visceral, behavioral and (2) reflective assessments--in the evaluation of information credibility. The results of the 80-participant study highlight that human cognitive processing varies according to an individual's purpose and that humans consider the structures and styles of content in their reflective assessments. We experimentally proved these findings through the development and analysis of classification models using 16,304 real blog posts written by 2,944 bloggers. Our models yield greater accuracy and efficiency than the models with well-known best features identified in prior research},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {weblogs, social networking services, information credibility, cognitive machine learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300824,
author = {Sun, Kaiwen and Mhaidli, Abraham H. and Watel, Sonakshi and Brooks, Christopher A. and Schaub, Florian},
title = {It's My Data! Tensions Among Stakeholders of a Learning Analytics Dashboard},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300824},
doi = {10.1145/3290605.3300824},
abstract = {Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education. Early warning dashboards in higher education analyze student data to enable early identification of underperforming students, allowing timely interventions by faculty and staff. To understand perceptions regarding the ethics and impact of such learning analytics applications, we conducted a multi-stakeholder analysis of an early-warning dashboard deployed at the University of Michigan through semi-structured interviews with the system's developers, academic advisors (the primary users), and students. We identify multiple tensions among and within the stakeholder groups, especially with regard to awareness, understanding, access, and use of the system. Furthermore, ambiguity in data provenance and data quality result in differing levels of reliance and concerns about the system among academic advisors and students. While students see the system's benefits, they argue for more involvement, control, and informed consent regarding the use of student data. We discuss our findings' implications for the ethical design and deployment of learning analytics applications in higher education.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {early warning dashboards, ethics, higher education, privacy, learning analytics, student data},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300310,
author = {Williamson, Julie R. and McGill, Mark and Outram, Khari},
title = {PlaneVR: Social Acceptability of Virtual Reality for Aeroplane Passengers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300310},
doi = {10.1145/3290605.3300310},
abstract = {Virtual reality (VR) headsets allow wearers to escape their physical surroundings, immersing themselves in a virtual world. Although escape may not be realistic or acceptable in many everyday situations, air travel is one context where early adoption of VR could be very attractive. While travelling, passengers are seated in restricted spaces for long durations, reliant on limited seat-back displays or mobile devices. This paper explores the social acceptability and usability of VR for in-flight entertainment. In an initial survey, we captured respondents' attitudes towards the social acceptability of VR headsets during air travel. Based on the survey results, we developed a VR in-flight entertainment prototype and evaluated this in a focus group study. Our results discuss methods for improving the acceptability of VR in-flight, including using mixed reality to help users transition between virtual and physical environments and supporting interruption from other co-located people.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {in-flight entertainment, virtual reality, social acceptability},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300436,
author = {Li, Jingyi and Kim, Son and Miele, Joshua A. and Agrawala, Maneesh and Follmer, Sean},
title = {Editing Spatial Layouts through Tactile Templates for People with Visual Impairments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300436},
doi = {10.1145/3290605.3300436},
abstract = {Spatial layout is a key component in graphic design. While people who are blind or visually impaired (BVI) can use screen readers or magnifiers to access digital content, these tools fail to fully communicate the content's graphic design information. Through semi-structured interviews and contextual inquiries, we identify the lack of this information and feedback as major challenges in understanding and editing layouts. Guided by these insights and a co-design process with a blind hobbyist web developer, we developed an interactive, multimodal authoring tool that lets blind people understand spatial relationships between elements and modify layout templates. Our tool automatically generates tactile print-outs of a web page's layout, which users overlay on top of a tablet that runs our self-voicing digital design tool. We conclude with design considerations grounded in user feedback for improving the accessibility of spatially encoded information and developing tools for BVI authors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {tactile overlays, accessibility, multimodal interfaces, accessible web design, visual impairments, accessible design tools, templates, layout design, blindness},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300837,
author = {Cho, Alexander and Herrera, Roxana G. and Chaidez, Luis and Uriostegui, Adilene},
title = {The "Comadre" Project: An Asset-Based Design Approach to Connecting Low-Income Latinx Families to Out-of-School Learning Opportunities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300837},
doi = {10.1145/3290605.3300837},
abstract = {Participation in out-of-school learning programs has been shown to generate significant academic, social/emotional, and institutional benefits for young learners, and today's wealthy families are disproportionately reaping these benefits. This paper presents the results of an asset-based/human-centered design research process and pilot aimed at connecting low-income families in a Southern California city with local low-cost out-of-school learning opportunities. Based on background research including qualitative interviewing, home visits, technology inventories and use walkthroughs with 40 low-income, majority Latinx families, we created and piloted a free subscription SMS service that automatically pushes bilingual SMS messages with curated information on local low-cost enrichment learning opportunities to low-income families. We framed our human-centered design process through an intersectional, "asset-based approach," which recognizes that marginalized communities have already developed robust, culturally-specific social practices to enable them to navigate the world, seeks to amplify them, and refrains from imposing a top-down or pre-conceived "idea" of intervention.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {education, human-centered design, women, asset-based, sms, hispanic, appreciative inquiry, informal learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300726,
author = {Hutt, Stephen and Grafsgaard, Joseph F. and D'Mello, Sidney K.},
title = {Time to Scale: Generalizable Affect Detection for Tens of Thousands of Students across An Entire School Year},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300726},
doi = {10.1145/3290605.3300726},
abstract = {We developed generalizable affect detectors using 133,966 instances of 18 affective states collected from 69,174 students who interacted with an online math learning platform called Algebra Nation over the entire school year. To enable scalability and generalizability, we used generic interaction features (e.g., viewing a video, taking a quiz), which do not require specialized sensors and are domain- and (to a certain extent) system-independent. We experimented with standard classifiers, recurrent neural networks, and genetically evolved neural networks for affect modeling. Prediction accuracies, quantified with Spearman's rho, were modest and ranged from .08 (for surprise) to .34 (for happiness) with a mean of .25. Our model trained on Algebra students generalized to a different set of Geometry students (n = 28,458) on the same platform. We discuss implications for scaling up affect detection for affect-sensitive online learning environments which aim to improve engagement and learning by detecting and responding to student affect.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {online education, affect detection, sensor-free, machine learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300564,
author = {Jagannath, Swathi and Sarcevic, Aleksandra and Young, Victoria and Myers, Sage},
title = {Temporal Rhythms and Patterns of Electronic Documentation in Time-Critical Medical Work},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300564},
doi = {10.1145/3290605.3300564},
abstract = {We examine nursing documentation on a newly implemented electronic flowsheet in medical resuscitations to identify the temporal patterns of documentation and how the recorded information supported time-critical teamwork. To determine when the information was documented, we compared timestamps from 58 flowsheet logs to those of verbal communications derived from video review. We also drew on observations of 95 resuscitations to understand the behaviors of nurse documenters. We found that only 8% of the verbal reports were documented in near real-time (one minute within the verbal report), while 42% of reports were not documented in the electronic flowsheet. In addition, 38% were documented early (before the verbal report) and 12% were documented with a delay, ranging from one to 58 minutes after the report. Our study showed that the electronic flowsheet design posed many challenges for real-time documentation, leading to paper-based workarounds and the use of free-text fields on the flowsheet to visualize and keep track of time, and to communicate temporal information to the team. These findings suggest that documenters shape the temporal rhythms of not only their own work but also the rhythms of the electronic record and medical process. We discuss the implications of these rhythms for EHR redesign to support real-time documentation in high-risk, safety-critical settings.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {emergency medicine, information behavior, temporality, electronic health records, nursing documentation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300402,
author = {Chilton, Lydia B. and Petridis, Savvas and Agrawala, Maneesh},
title = {VisiBlends: A Flexible Workflow for Visual Blends},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300402},
doi = {10.1145/3290605.3300402},
abstract = {Visual blends are an advanced graphic design technique to draw attention to a message. They combine two objects in a way that is novel and useful in conveying a message symbolically. This paper presents VisiBlends, a flexible workflow for creating visual blends that follows the iterative design process. We introduce a design pattern for blending symbols based on principles of human visual object recognition. Our workflow decomposes the process into both computational techniques and human microtasks. It allows users to collaboratively generate visual blends with steps involving brainstorming, synthesis, and iteration. An evaluation of the workflow shows that decentralized groups can generate blends in independent microtasks, co-located groups can collaboratively make visual blends for their own messages, and VisiBlends improves novices' ability to make visual blends.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {workflow, design, collaboration, visual blends},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300778,
author = {Hsu, Chen-Yu and Hristov, Rumen and Lee, Guang-He and Zhao, Mingmin and Katabi, Dina},
title = {Enabling Identification and Behavioral Sensing in Homes Using Radio Reflections},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300778},
doi = {10.1145/3290605.3300778},
abstract = {Understanding users' behavior at home is central to behavioral research. For example, social researchers are interested in studying domestic abuse, and healthcare professionals are interested in caregiver-patient interaction. Today, such studies rely on diaries and questionnaires, which are subjective, erroneous, and hard to sustain in longitudinal studies. We introduce Marko, a system that automatically collects behavior-related data, without asking people to write diaries or wear sensors. Marko transmits a low power wireless signal and analyses its reflections from the environment. It maps those reflections to how users interact with the environment (e.g., access to medication cabinet) and with each other (e.g., watch TV together). It provides novel algorithms for identifying who-does-what, and bootstrapping the system in new homes without asking users for new annotations. We evaluate Marko with a one-month deployment in six homes, and demonstrate its value for studying couple relationships and caregiver-patient interaction.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {behavioral sensing, user identification, wireless sensing, passive rf sensing, smart environments},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300819,
author = {Marques, Diogo and Guerreiro, Tiago and Carri\c{c}o, Luis and Beschastnikh, Ivan and Beznosov, Konstantin},
title = {Vulnerability &amp; Blame: Making Sense of Unauthorized Access to Smartphones},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300819},
doi = {10.1145/3290605.3300819},
abstract = {Unauthorized physical access to personal devices by people known to the owner of the device is a common concern, and a common occurrence. But how do people experience incidents of unauthorized access? Using an online survey, we collected 102 accounts of unauthorized access. Participants wrote stories about past situations in which either they accessed the smartphone of someone they know, or someone they know accessed theirs. We describe the context leading up to these incidents, the course of events, and the consequences. We then identify two orthogonal themes in how participants conceptualized these incidents. First, participants understood trust as performative vulnerability: trust was necessary to sustain relationships, but building trust required displaying vulnerability to breaches. Second, participants were self-serving in their sensemaking: they blamed the circumstances, or the other person's shortcomings, but rarely themselves. We discuss the implications of our findings for security design and practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {qualitative, mobile, intrusions, access control},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300721,
author = {Kwok, Tiffany C.K. and Kiefer, Peter and Schinazi, Victor R. and Adams, Benjamin and Raubal, Martin},
title = {Gaze-Guided Narratives: Adapting Audio Guide Content to Gaze in Virtual and Real Environments},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300721},
doi = {10.1145/3290605.3300721},
abstract = {Exploring a city panorama from a vantage point is a popular tourist activity. Typical audio guides that support this activity are limited by their lack of responsiveness to user behavior and by the difficulty of matching audio descriptions to the panorama. These limitations can inhibit the acquisition of information and negatively affect user experience. This paper proposes Gaze-Guided Narratives as a novel interaction concept that helps tourists find specific features in the panorama (gaze guidance) while adapting the audio content to what has been previously looked at (content adaptation). Results from a controlled study in a virtual environment (n=60) revealed that a system featuring both gaze guidance and content adaptation obtained better user experience, lower cognitive load, and led to better performance in a mapping task compared to a classic audio guide. A second study with tourists situated at a vantage point (n=16) further demonstrated the feasibility of this approach in the real world.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {outdoor eye tracking, gaze-guided narratives, tourist guide},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300482,
author = {Dudley, John J. and Jacques, Jason T. and Kristensson, Per Ola},
title = {Crowdsourcing Interface Feature Design with Bayesian Optimization},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300482},
doi = {10.1145/3290605.3300482},
abstract = {Designing novel interfaces is challenging. Designers typically rely on experience or subjective judgment in the absence of analytical or objective means for selecting interface parameters. We demonstrate Bayesian optimization as an efficient tool for objective interface feature refinement. Specifically, we show that crowdsourcing paired with Bayesian optimization can rapidly and effectively assist interface design across diverse deployment environments. Experiment 1 evaluates the approach on a familiar 2D interface design problem: a map search and review use case. Adding a degree of complexity, Experiment 2 extends Experiment 1 by switching the deployment environment to mobile-based virtual reality. The approach is then demonstrated as a case study for a fundamentally new and unfamiliar interaction design problem: web-based augmented reality. Finally, we show how the model generated as an outcome of the refinement process can be used for user simulation and queried to deliver various design insights.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {optimization, crowdsourcing, interface design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300577,
author = {Hartmann, Jeremy and Holz, Christian and Ofek, Eyal and Wilson, Andrew D.},
title = {RealityCheck: Blending Virtual Environments with Situated Physical Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300577},
doi = {10.1145/3290605.3300577},
abstract = {Today's virtual reality (VR) systems offer chaperone rendering techniques that prevent the user from colliding with physical objects. Without a detailed geometric model of the physical world, these techniques offer limited possibility for more advanced compositing between the real world and the virtual. We explore this using a realtime 3D reconstruction of the real world that can be combined with a virtual environment. RealityCheck allows users to freely move, manipulate, observe, and communicate with people and objects situated in their physical space without losing the sense of immersion or presence inside their virtual world. We demonstrate RealityCheck with seven existing VR titles, and describe compositing approaches that address the potential conflicts when rendering the real world and a virtual environment together. A study with frequent VR users demonstrate the affordances provided by our system and how it can be used to enhance current VR experiences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {3d compositing, virtual reality, depth cameras},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300892,
author = {Hu, Kevin and Gaikwad, Snehalkumar 'Neil' S. and Hulsebos, Madelon and Bakker, Michiel A. and Zgraggen, Emanuel and Hidalgo, C\'{e}sar and Kraska, Tim and Li, Guoliang and Satyanarayan, Arvind and Demiralp, \c{C}a\u{g}atay},
title = {VizNet: Towards A Large-Scale Visualization Learning and Benchmarking Repository},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300892},
doi = {10.1145/3290605.3300892},
abstract = {Researchers currently rely on ad hoc datasets to train automated visualization tools and evaluate the effectiveness of visualization designs. These exemplars often lack the characteristics of real-world datasets, and their one-off nature makes it difficult to compare different techniques. In this paper, we present VizNet: a large-scale corpus of over 31 million datasets compiled from open data repositories and online visualization galleries. On average, these datasets comprise 17 records over 3 dimensions and across the corpus, we find 51% of the dimensions record categorical data, 44% quantitative, and only 5% temporal. VizNet provides the necessary common baseline for comparing visualization design techniques, and developing benchmark models and algorithms for automating visual analysis. To demonstrate VizNet's utility as a platform for conducting online crowdsourced experiments at scale, we replicate a prior study assessing the influence of user task and data distribution on visual encoding effectiveness, and extend it by considering an additional task: outlier detection. To contend with running such studies at scale, we demonstrate how a metric of perceptual effectiveness can be learned from experimental results, and show its predictive power across test datasets.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {benchmarking, reproducible research, automated visualization, machine learning, active learning, crowd computing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300826,
author = {Nebeling, Michael and Madier, Katy},
title = {360proto: Making Interactive Virtual Reality &amp; Augmented Reality Prototypes from Paper},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300826},
doi = {10.1145/3290605.3300826},
abstract = {We explore 360 paper prototyping to rapidly create AR/VR prototypes from paper and bring them to life on AR/VR devices. Our approach is based on a set of emerging paper prototyping templates specifically for AR/VR. These templates resemble the key components of many AR/VR interfaces, including 2D representations of immersive environments, AR marker overlays and face masks, VR controller models and menus, and 2D screens and HUDs. To make prototyping with these templates effective, we developed 360proto, a suite of three novel physical--digital prototyping tools: (1) the 360proto Camera for capturing paper mockups of all components simply by taking a photo with a smartphone and seeing 360-degree panoramic previews on the phone or stereoscopic previews in Google Cardboard; (2) the 360proto Studio for organizing and editing captures, for composing AR/VR interfaces by layering the captures, and for making them interactive with Wizard of Oz via live video streaming; (3) the 360proto App for running and testing the interactive prototypes on AR/VR capable mobile devices and headsets. Through five student design jams with a total of 86 participants and our own design space explorations, we demonstrate that our approach with 360proto is useful to create relatively complex AR/VR applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wizard of oz, physical-digital prototyping, ar/vr},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300622,
author = {Rudnicka, Anna and Cox, Anna L. and Gould, Sandy J. J.},
title = {Why Do You Need This? Selective Disclosure of Data Among Citizen Scientists},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300622},
doi = {10.1145/3290605.3300622},
abstract = {Recent scandals involving data from participatory research have contributed to broader public concern about online privacy. Such concerns might make people more reluctant to participate in research that asks them to volunteer personal data, compromising many researchers' data collection. We tested several motivational messages that encouraged participation in a citizen science project. We measured people's willingness to disclose personal information. While participants were less likely to share sensitive data than neutral data, disclosure behaviour was not affected by attitudes to privacy. Importantly, we found that citizen scientists who were exposed to a motivational message that emphasised 'learning' were more likely to share sensitive information than those presented with other types of motivational cues. Our results suggest that priming individuals with motivational messages can increase their willingness to contribute personal data to a project, even if the request pertains to sensitive information.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {motivation, disclosure, privacy, dabblers, citizen science},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300523,
author = {Hoffswell, Jane and Liu, Zhicheng},
title = {Interactive Repair of Tables Extracted from PDF Documents on Mobile Devices},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300523},
doi = {10.1145/3290605.3300523},
abstract = {PDF documents often contain rich data tables that offer opportunities for dynamic reuse in new interactive applications. We describe a pipeline for extracting, analyzing, and parsing PDF tables based on existing machine learning and rule-based techniques. Implementing and deploying this pipeline on a corpus of 447 documents with 1,171 tables results in only 11 tables that are correctly extracted and parsed. To improve the results of automatic table analysis, we first present a taxonomy of errors that arise in the analysis pipeline and discuss the implications of cascading errors on the user experience. We then contribute a system with two sets of lightweight interaction techniques (gesture and toolbar), for viewing and repairing extraction errors in PDF tables on mobile devices. In an evaluation with 17 users involving both a phone and a tablet, participants effectively repaired common errors in 10 tables, with an average time of about 2 minutes per table.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {table classification, interaction techniques, error correction, data tables, mobile devices, pdf, error taxonomy},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300895,
author = {Burgess, Eleanor R. and Reddy, Madhu C. and Davenport, Andrew and Laboi, Paul and Blandford, Ann},
title = {"Tricky to Get Your Head around": Information Work of People Managing Chronic Kidney Disease in the UK},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300895},
doi = {10.1145/3290605.3300895},
abstract = {People diagnosed with a chronic health condition have many information needs which healthcare providers, patient groups, and resource designers seek to support. However, as a disease progresses, knowing when, how, and for what purposes patients want to interact with and construct personal meaning from health-related information is still unclear. This paper presents findings regarding the information work of chronic kidney disease patients. We conducted semi-structured interviews with 13 patients and 6 clinicians, and observations at 9 patient group events. We used the stages of the information journey - recognizing need, seeking, interpreting, and using information - to frame our data analysis. We identified two distinct but often overlapping information work phases, 'Learning' and 'Living With' a chronic condition to show how patient information work activities shift over time. We also describe social and individual factors influencing information work, and discuss technology design opportunities including customized education and collaboration tools.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {chronic kidney disease, meaning making, information journey, information work, patient self-management, sensemaking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300571,
author = {Pang, Carolyn and Pan, Rui and Neustaedter, Carman and Hennessy, Kate},
title = {City Explorer: The Design and Evaluation of a Location-Based Community Information System},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300571},
doi = {10.1145/3290605.3300571},
abstract = {Many working professionals commute via public transit, yet they have limited tools for learning about their urban neighborhoods and fellow commuters. We designed a location-based game called City Explorer to investigate how transit commuters capture, share, and view community information that is specifically tied to locations. Through a four-week field study, we found that participants valued the increased awareness of their personal travel routines that they gained through City Explorer. When viewing community information, they preferred information that was factual rather than opinion-based and was presented at the start and end of their commutes. Participants found less value in connecting with other transit riders because transit rides were often seen as opportunities to disengage from others. We discuss how location-based technologies can be designed to display factual community information before, during, and at the end of transit commutes.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mobile computing, location-based games, urban informatics, community},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300822,
author = {Luo, Yuhan and Liu, Peiyi and Choe, Eun Kyoung},
title = {Co-Designing Food Trackers with Dietitians: Identifying Design Opportunities for Food Tracker Customization},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300822},
doi = {10.1145/3290605.3300822},
abstract = {We report co-design workshops with registered dietitians conducted to identify opportunities for designing customizable food trackers. Dietitians typically see patients who have different dietary problems, thus having different information needs. However, existing food trackers such as paper-based diaries and mobile apps are rarely customizable, making it difficult to capture necessary data for both patients and dietitians. During the co-design sessions, dietitians created representative patient personas and designed food trackers for each persona. We found a wide range of potential tracking items such as food, reflection, symptom, activity, and physical state. Depending on patients' dietary problems and dietitians' practice, the necessity and importance of these tracking items vary. We identify opportunities for patients and healthcare providers to collaborate around data tracking and sharing through customization. We also discuss how to structure co-design workshops to solicit the design considerations of self-tracking tools for patients with specific health problems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {food tracking, customization, co-design workshop, self-tracking, personal informatics, health},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300905,
author = {Sra, Misha and Jain, Abhinandan and Maes, Pattie},
title = {Adding Proprioceptive Feedback to Virtual Reality Experiences Using Galvanic Vestibular Stimulation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300905},
doi = {10.1145/3290605.3300905},
abstract = {We present a small and lightweight wearable device that enhances virtual reality experiences and reduces cybersickness by means of galvanic vestibular stimulation (GVS). GVS is a specific way to elicit vestibular reflexes that has been used for over a century to study the function of the vestibular system. In addition to GVS, we support physiological sensing by connecting heart rate, electrodermal activity and other sensors to our wearable device using a plug and play mechanism. An accompanying Android app communicates with the device over Bluetooth (BLE) for transmitting the GVS stimulus to the user through electrodes attached behind the ears. Our system supports multiple categories of virtual reality applications with different types of virtual motion such as driving, navigating by flying, teleporting, or riding. We present a user study in which participants (N = 20) experienced significantly lower cybersickness when using our device and rated experiences with GVS-induced haptic feedback as significantly more immersive than a no-GVS baseline.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interaction design, galvanic vestibular stimulation, wearables, haptic feedback, cybersickness, virtual reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300771,
author = {Veras, Rafael and Collins, Christopher},
title = {Saliency Deficit and Motion Outlier Detection in Animated Scatterplots},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300771},
doi = {10.1145/3290605.3300771},
abstract = {We report the results of a crowdsourced experiment that measured the accuracy of motion outlier detection in multivariate, animated scatterplots. The targets were outliers either in speed or direction of motion, and were presented with varying levels of saliency in dimensions that are irrelevant to the task of motion outlier detection (e.g., color, size, position). We found that participants had trouble finding the outlier when it lacked irrelevant salient features and that visual channels contribute unevenly to the odds of an outlier being correctly detected. Direction of motion contributes the most to accurate detection of speed outliers, and position contributes the most to accurate detection of direction outliers. We introduce the concept of saliency deficit in which item importance in the data space is not reflected in the visualization due to a lack of saliency. We conclude that motion outlier detection is not well supported in multivariate animated scatterplots.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {perception, saliency, visualization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300466,
author = {Tabbaa, Luma and Ang, Chee Siang and Rose, Vienna and Siriaraya, Panote and Stewart, Inga and Jenkins, Keith G. and Matsangidou, Maria},
title = {Bring the Outside In: Providing Accessible Experiences Through VR for People with Dementia in Locked Psychiatric Hospitals},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300466},
doi = {10.1145/3290605.3300466},
abstract = {Many people with dementia (PWD) residing in long-term care may face barriers in accessing experiences beyond their physical premises; this may be due to location, mobility constraints, legal mental health act restrictions, or offence-related restrictions. In recent years, there have been research interests towards designing non-pharmacological interventions aiming to improve the Quality of Life (QoL) for PWD within long-term care. We explored the use of Virtual Reality (VR) as a tool to provide 360°-video based experiences for individuals with moderate to severe dementia residing in a locked psychiatric hospital. We discuss at depth the appeal of using VR for PWD, and the observed impact of such interaction. We also present the design opportunities, pitfalls, and recommendations for future deployment in healthcare services. This paper demonstrates the potential of VR as a virtual alternative to experiences that may be difficult to reach for PWD residing within locked setting.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {dementia, locked psychiatric hospital, person-centred care, virtual reality, long-term care, patient-centred design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300457,
author = {Davis, Katie and Dinhopl, Anja and Hiniker, Alexis},
title = {"Everything's the Phone": Understanding the Phone's Supercharged Role in Parent-Teen Relationships},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300457},
doi = {10.1145/3290605.3300457},
abstract = {Through focus groups (n=61) and surveys (n=2,083) of parents and teens, we investigated how parents and their teen children experience their own and each other's phone use in the context of parent-teen relationships. Both expressed a lack of agency in their own and each other's phone use, feeling overly reliant on their own phone and displaced by the other's phone. In a classic example of the fundamental attribution error, each party placed primary blame on the other, and rationalized their own behavior with legitimizing excuses. We present a conceptual model showing how parents' and teens' relationships to their phones and perceptions of each other's phone use are inextricably linked, and how, together, they contribute to parent-teen tensions and disconnections. We use the model to consider how the phone might play a less highly charged role in family life and contribute to positive connections between parents and their teen children.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {family, parents, smartphones, relationships, teens},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300378,
author = {Ramchurn, Richard and Martindale, Sarah and Wilson, Max L. and Benford, Steve},
title = {From Director's Cut to User's Cut: To Watch a Brain-Controlled Film is to Edit It},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300378},
doi = {10.1145/3290605.3300378},
abstract = {Introducing interactivity to films has proven a longstanding and difficult challenge due to their narrative-driven, linear and theatre-based nature. Previous research has suggested that Brain-Computer Interfaces (BCI) may be a promising approach but also revealed a tension between being immersed in the film and thinking about control. We report a performance-led and in-the-wild study of a BCI film called The MOMENT covering its design rationale and how it was experienced by the public as controllers, non-controllers and repeat viewers. Our findings suggest that BCI movies should be designed to be credibly controllable, generate personal versions, be watchable as linear films, encourage repeat viewing and fit the medium of cinema. They also reveal how viewers appreciated the sense of editing their own personal cuts, suggesting a new stance on introducing interactivity into lean-back media in which filmmakers release editorial control to users to make their own versions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {control, bci, interactive cinema, eeg, film},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300680,
author = {Seering, Joseph and Luria, Michal and Kaufman, Geoff and Hammer, Jessica},
title = {Beyond Dyadic Interactions: Considering Chatbots as Community Members},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300680},
doi = {10.1145/3290605.3300680},
abstract = {Chatbots have grown as a space for research and development in recent years due both to the realization of their commercial potential and to advancements in language processing that have facilitated more natural conversations. However, nearly all chatbots to date have been designed for dyadic, one-on-one communication with users. In this paper we present a comprehensive review of research on chatbots supplemented by a review of commercial and independent chatbots. We argue that chatbots' social roles and conversational capabilities beyond dyadic interactions have been underexplored, and that expansion into this design space could support richer social interactions in online communities and help address the longstanding challenges of maintaining, moderating, and growing these communities. In order to identify opportunities beyond dyadic interactions, we used research-through-design methods to generate more than 400 concepts for new social chatbots, and we present seven categories that emerged from analysis of these ideas.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {chatbots, dyadic communication, social identity, online communities},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300812,
author = {Benton, Laura and Vasalou, Asimina and Barendregt, Wolmet and Bunting, Leona and R\'{e}v\'{e}sz, Andrea},
title = {What's Missing: The Role of Instructional Design in Children's Games-Based Learning},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300812},
doi = {10.1145/3290605.3300812},
abstract = {Learning games that address targeted curriculum areas are widely used in schools. Within games, productive learning episodes can result from breakdowns when followed by a breakthrough, yet their role in children's learning has not been investigated. This paper examines the role of game and instructional design during and after breakdowns. We observed 26 young children playing several popular learning games and conducted a moment-by-moment analysis of breakdown episodes. Our findings show children achieve productive breakthroughs independently less than half of the time. In particular, breakdowns caused by game actions are difficult for children to overcome independently and prevent engagement with the domain skills. Importantly, we identify specific instructional game components and their role in fostering strategies that result in successful breakthroughs. We conclude with intrinsic and extrinsic instructional design implications for both game designers and primary teachers to better enable children's games-based learning.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {reading, learning games, children, instructional design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300279,
author = {Kou, Yubo and Gray, Colin M.},
title = {A Practice-Led Account of the Conceptual Evolution of UX Knowledge},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300279},
doi = {10.1145/3290605.3300279},
abstract = {The contours of user experience (UX) design practice have been shaped by a diverse array of practitioners and disciplines, resulting in a diffuse and decentralized body of UX-specific disciplinary knowledge. The rapidly shifting space that UX knowledge occupies, in conjunction with a long-existing research-practice gap, presents unique challenges and opportunities to UX educators and aspiring UX designers. In this paper, we analyzed a corpus of question and answer communication on UX Stack Exchange using a practice-led approach, identifying and documenting practitioners' conceptions of UX knowledge over a nine year period. Specifically, we used natural language processing techniques and qualitative content analysis to identify a disciplinary vocabulary invoked by UX designers in this online community, as well as conceptual trajectories spanning over nine years which could shed light on the evolution of UX practice. We further describe the implications of our findings for HCI research and UX education.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user experience, practice-led research, q&amp;a, ux design, stack exchange, design practice},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300842,
author = {Mardanbegi, Diako and Langlotz, Tobias and Gellersen, Hans},
title = {Resolving Target Ambiguity in 3D Gaze Interaction through VOR Depth Estimation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300842},
doi = {10.1145/3290605.3300842},
abstract = {Target disambiguation is a common problem in gaze interfaces, as eye tracking has accuracy and precision limitations. In 3D environments this is compounded by objects overlapping in the field of view, as a result of their positioning at different depth with partial occlusion. We introduce VOR depth estimation, a method based on the Vestibulo-ocular reflex of the eyes in compensation of head movement, and explore its application to resolve target ambiguity. The method estimates gaze depth by comparing the rotations of the eye and the head when the users look at a target and deliberately rotate their head. We show that VOR eye movement presents an alternative to vergence for gaze depth estimation, that is feasible also with monocular tracking. In an evaluation of its use for target disambiguation, our method outperforms vergence for targets presented at greater depth.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {vergence, vestibulo-ocular reflex, depth estimation, eye tracking, disambiguation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300928,
author = {Mayer, Sven and Schwind, Valentin and Le, Huy Viet and Weber, Dominik and Vogelsang, Jonas and Wolf, Johannes and Henze, Niels},
title = {Effect of Orientation on Unistroke Touch Gestures},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300928},
doi = {10.1145/3290605.3300928},
abstract = {As touchscreens are the most successful input method of current mobile devices, touch gestures became a widely used input technique. While gestures provide users with advantages to express themselves, they also introduce challenges regarding accuracy and memorability. In this paper, we investigate the effect of a gesture's orientation on how well the gesture can be performed. We conducted a study in which participants performed systematically rotated unistroke gestures. For straight lines as well as for compound lines, we found that users tend to align gestures with the primary axes. We show that the error can be described by a Clausen function with R² = .93. Based on our findings, we suggest design implications and highlight the potential for recognizing flick gestures, visualizing gestures and improving recognition of compound gestures.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {touch unistroke gestures, design guidelines, touch input, mobile device, user study, orientation, gesture set},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300426,
author = {Surale, Hemant Bhaskar and Matulic, Fabrice and Vogel, Daniel},
title = {Experimental Analysis of Barehand Mid-Air Mode-Switching Techniques in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300426},
doi = {10.1145/3290605.3300426},
abstract = {We present an empirical comparison of eleven bare hand, mid-air mode-switching techniques suitable for virtual reality in two experiments. The first evaluates seven techniques spanning dominant and non-dominant hand actions. Techniques represent common classes of actions selected by a methodical examination of 56 examples of prior art. The standard "subtraction method" protocol is adapted for 3D interfaces, with two baseline selection methods, bare hand pinch and device controller button. A second experiment with four techniques explores more subtle dominant-hand techniques and the effect of using a dominant hand device for selection. Results provide guidance to practitioners when choosing bare hand, mid-air mode-switching techniques, and for researchers when designing new mode-switching methods in VR.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interaction techniques, controlled experiment},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300885,
author = {Lim, Catherine Y. and Berry, Andrew B.L. and Hartzler, Andrea L. and Hirsch, Tad and Carrell, David S. and Bermet, Zo\"{e} A. and Ralston, James D.},
title = {Facilitating Self-Reflection about Values and Self-Care Among Individuals with Chronic Conditions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300885},
doi = {10.1145/3290605.3300885},
abstract = {Individuals with multiple chronic conditions (MCC) experience the overwhelming burden of treating MCC and frequently disagree with their providers on priorities for care. Aligning self-care with patients' values may improve healthcare for these patients. However, patients' values are not routinely discussed in clinical conversations and patients may not actively share this information with providers. In a qualitative field study, we interviewed 15 patients in their homes to investigate techniques that encourage patients to articulate values, self-care, and how they relate. Study activities facilitated self-reflection on values and self-care and produced varying responses, including: raising consciousness, evolving perspectives, identifying misalignments, and considering changes. We discuss how our findings extend prior work on supporting reflection in HCI and inform the design of tools for improving care for people with MCC.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {reflection, health, multimorbidity, self-care, values, multiple chronic conditions},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300470,
author = {Yasu, Kentaro},
title = {Magnetact: Magnetic-Sheet-Based Haptic Interfaces for Touch Devices},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300470},
doi = {10.1145/3290605.3300470},
abstract = {We describe a method for rapid prototyping of haptic interfaces for touch devices. A sheet-like touch interface is constructed from magnetic rubber sheets and conductive materials. The magnetic sheet is thin, and the capacitive sensor of the touch device can still detect the user's finger above the sheet because of the rubber's dielectric nature. Furthermore, tactile feedback can be customized with ease by using our magnetizing toolkit to change the magnetic patterns. Using the magnetizing toolkit, we investigated the appropriate size and thickness of haptic interfaces and demonstrated several interfaces such as buttons, sliders, switches, and dials. Our method is an easy and convenient way to customize the size, shape, and haptic feedback of a wide variety of interfaces.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {touch display, diy, rapid prototyping, interface, magnet, haptic, tangible},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300256,
author = {Habib, Hana and Shah, Neil and Vaish, Rajan},
title = {Impact of Contextual Factors on Snapchat Public Sharing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300256},
doi = {10.1145/3290605.3300256},
abstract = {Public sharing is integral to online platforms. This includes the popular multimedia messaging application Snapchat, on which public sharing is relatively new and unexplored in prior research. In mobile-first applications, sharing contexts are dynamic. However, it is unclear how context impacts users' sharing decisions. As platforms increasingly rely on user-generated content, it is important to also broadly understand user motivations and considerations in public sharing. We explored these aspects of content sharing through a survey of 1,515 Snapchat users. Our results indicate that users primarily have intrinsic motivations for publicly sharing Snaps, such as to share an experience with the world, but also have considerations related to audience and sensitivity of content. Additionally, we found that Snaps shared publicly were contextually different from those privately shared. Our findings suggest that content sharing systems can be designed to support sharing motivations, yet also be sensitive to private contexts.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social media, online communities, survey},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300450,
author = {Tsai, Hsin-Ruey and Rekimoto, Jun and Chen, Bing-Yu},
title = {ElasticVR: Providing Multilevel Continuously-Changing Resistive Force and Instant Impact Using Elasticity for VR},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300450},
doi = {10.1145/3290605.3300450},
abstract = {Resistive force (e.g., due to object elasticity) and impact (e.g., due to recoil) are common effects in our daily life. However, resistive force continuously changes due to users' movements while impact instantly occurs when an event triggers it. These feedback are still not realistically provided by current VR haptic methods. In this paper, a wearable device, ElasticVR, which consists of an elastic band, servo motors and mechanical brakes, is proposed to provide the continuously-changing resistive force and instantly-occurring impact upon the user's hand to enhance VR realism. By changing two physical properties, length and extension distance, of the elastic band, ElasticVR provides multilevel resistive force with no delay and impact with little delay, respectively, for realistic and versatile VR applications. A force perception study was performed to observe users' force distinguishability of the resistive force and impact, and the prototype was built based on its results. A VR experience study further proves that the resistive force and impact from ElasticVR both outperform those from current approaches in realism. Applications using ElasticVR are also demonstrated.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {force feedback, impact, wearable device, virtual reality, elastic force, haptic feedback, resistive force},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300636,
author = {Ceha, Jessy and Chhibber, Nalin and Goh, Joslin and McDonald, Corina and Oudeyer, Pierre-Yves and Kuli\'{c}, Dana and Law, Edith},
title = {Expression of Curiosity in Social Robots: Design, Perception, and Effects on Behaviour},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300636},
doi = {10.1145/3290605.3300636},
abstract = {Curiosity-the intrinsic desire for new information-can enhance learning, memory, and exploration. Therefore, understanding how to elicit curiosity can inform the design of educational technologies. In this work, we investigate how a social peer robot's verbal expression of curiosity is perceived, whether it can affect the emotional feeling and behavioural expression of curiosity in students, and how it impacts learning. In a between-subjects experiment, 30 participants played the game LinkIt!, a game we designed for teaching rock classification, with a robot verbally expressing: curiosity, curiosity plus rationale, or no curiosity. Results indicate that participants could recognize the robot's curiosity and that curious robots produced both emotional and behavioural curiosity contagion effects in participants.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {curiosity, education, social robot behaviour},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300446,
author = {Crabb, Michael and Heron, Michael and Jones, Rhianne and Armstrong, Mike and Reid, Hayley and Wilson, Amy},
title = {Developing Accessible Services: Understanding Current Knowledge and Areas for Future Support},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300446},
doi = {10.1145/3290605.3300446},
abstract = {When creating digital artefacts, it is important to ensure that the product being made is accessible to as much of the population as is possible. Many guidelines and supporting tools exist to assist reaching this goal. However, little is known about developers' understanding of accessible practice and the methods that are used to implement this. We present findings from an accessibility design workshop that was carried out with a mixture of 197 developers and digital technology students. We discuss perceptions of accessibility, techniques that are used when designing accessible products, and what areas of accessibility development participants believed were important. We show that there are gaps in the knowledge needed to develop accessible products despite the effort to promote accessible design. Our participants are themselves aware of where these gaps are and have suggested a number of areas where tools, techniques and guidance would improve their practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {accessibility, digital accessibility, web accessibility},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300655,
author = {Rooksby, John and Morrison, Alistair and Murray-Rust, Dave},
title = {Student Perspectives on Digital Phenotyping: The Acceptability of Using Smartphone Data to Assess Mental Health},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300655},
doi = {10.1145/3290605.3300655},
abstract = {There is a mental health crisis facing universities internationally. A growing body of interdisciplinary research has successfully demonstrated that using sensor and interaction data from students' smartphones can give insight into stress, depression, mood, suicide risk and more. The approach, which is sometimes termed Digital Phenotyping, has potential to transform how mental health and wellbeing can be monitored and understood. The approach could also transform how interventions are designed, delivered and evaluated. To date, little work has addressed the human and ethical side of digital phenotyping, including how students feel about being monitored. In this paper we report findings from in-depth focus groups, prototyping and interviews with students. We find they are positive about mental health technology, but also that there are multi-layered issues to address if digital phenotyping is to become acceptable. Using an acceptability framework, we set out the key design challenges that need to be addressed.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {lived informatics, qualitative research, mobile health, mental health, sensors, acceptability, mental wellbeing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300397,
author = {Leung, Weiwen},
title = {How Do One's Peers on a Leaderboard Affect Oneself?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300397},
doi = {10.1145/3290605.3300397},
abstract = {Leaderboards are a workhorse of the gamification literature. While the effect of a leaderboard has been well studied, there is much less evidence how one's peer group affects the treatment effect of a leaderboard. Through a pre-registered field experiment involving more than 1000 users on an online movie recommender website, we expose users to leaderboards, but different sets of users are exposed to different peer groups. Contrary to what a standard behavioral model would predict, we find that a user's contribution increases when their peer's scores are more dispersed. We also find that decreasing average peer contributions motivates a user to contribute more. Moreover, these effects are themselves mediated by group size. This sheds new light on existing theories of motivation and demotivation with regards to leaderboards, and also illustrates the potential of using personalized leaderboards to increase contributions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {social computing, leaderboards, peer groups},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300784,
author = {Zhang, Yongqi and Xie, Biao and Huang, Haikun and Ogawa, Elisa and You, Tongjian and Yu, Lap-Fai},
title = {Pose-Guided Level Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300784},
doi = {10.1145/3290605.3300784},
abstract = {Player's physical experience is a critical factor to consider in designing motion-based games that are played through motion sensor gaming consoles or virtual reality devices. However, adjusting the physical challenge involved in a motion-based game is difficult and tedious, as it is typically done manually by level designers on a trial-and-error basis. In this paper, we propose a novel approach for automatically synthesizing levels for motion-based games that can achieve desired physical movement goals. By formulating the level design problem as a trans-dimensional optimization problem which is solved by a reversible-jump Markov chain Monte Carlo technique, we show that our approach can automatically synthesize a variety of game levels, each carrying the desired physical movement properties. To demonstrate the generality of our approach, we synthesize game levels for two different types of motion-based games and conduct a user study to validate the effectiveness of our approach.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {level design, optimization, exergaming, generative design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300830,
author = {Holstein, Kenneth and Wortman Vaughan, Jennifer and Daum\'{e}, Hal and Dudik, Miro and Wallach, Hanna},
title = {Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300830},
doi = {10.1145/3290605.3300830},
abstract = {The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners' needs.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {empirical study, ux of machine learning, product teams, fair machine learning, algorithmic bias, needfinding},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300649,
author = {Lascau, Laura and Gould, Sandy J. J. and Cox, Anna L. and Karmannaya, Elizaveta and Brumby, Duncan P.},
title = {Monotasking or Multitasking: Designing for Crowdworkers' Preferences},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300649},
doi = {10.1145/3290605.3300649},
abstract = {Crowdworkers receive no formal training for managing their tasks, time or working environment. To develop tools that support such workers, an understanding of their preferences and the constraints they are under is essential. We asked 317 experienced Amazon Mechanical Turk workers about factors that influence their task and time management. We found that a large number of the crowdworkers score highly on a measure of polychronicity; this means that they prefer to frequently switch tasks and happily accommodate regular work and non-work interruptions. While a preference for polychronicity might equip people well to deal with the structural demands of crowdworking platforms, we also know that multitasking negatively affects workers' productivity. This puts crowdworkers' working preferences into conflict with the desire of requesters to maximize workers' productivity. Combining the findings of prior research with the new knowledge obtained from our participants, we enumerate practical design options that could enable workers, requesters and platform developers to make adjustments that would improve crowdworkers' experiences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {amazon mechanical turk, crowdsourcing, crowdwork, polychronicity, multitasking, productivity},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300774,
author = {Radu, Iulian and Schneider, Bertrand},
title = {What Can We Learn from Augmented Reality (AR)? Benefits and Drawbacks of AR for Inquiry-Based Learning of Physics},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300774},
doi = {10.1145/3290605.3300774},
abstract = {Emerging technologies such as Augmented Reality (AR), have the potential to radically transform education by making challenging concepts visible and accessible to novices. In this project, we have designed a Hololens-based system in which collaborators are exposed to an unstructured learning activity in which they learned about the invisible physics involved in audio speakers. They learned topics ranging from spatial knowledge, such as shape of magnetic fields, to abstract conceptual knowledge, such as relationships between electricity and magnetism. We compared participants' learning, attitudes and collaboration with a tangible interface through multiple experimental conditions containing varying layers of AR information. We found that educational AR representations were beneficial for learning specific knowledge and increasing participants' self-efficacy (i.e., their ability to learn concepts in physics). However, we also found that participants in conditions that did not contain AR educational content, learned some concepts better than other groups and became more curious about physics. We discuss learning and collaboration differences, as well as benefits and detriments of implementing augmented reality for unstructured learning activities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {physics education, collaborative learning, augmented reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300791,
author = {Tran O'Leary, Jasper and Zewde, Sara and Mankoff, Jennifer and Rosner, Daniela K.},
title = {Who Gets to Future? Race, Representation, and Design Methods in Africatown},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300791},
doi = {10.1145/3290605.3300791},
abstract = {This paper draws on a collaborative project called the Africatown Activation to examine the role design practices play in contributing to (or conspiring against) the flourishing of the Black community in Seattle, Washington. Specifically, we describe the efforts of a community group called Africatown to design and build an installation that counters decades of disinvestment and ongoing displacement in the historically Black Central Area neighborhood. Our analysis suggests that despite efforts to include community, conventional design practices may perpetuate forms of institutional racism: enabling activities of community engagement that may further legitimate racialized forms of displacement. We discuss how focusing on amplifying the legacies of imagination already at work may help us move beyond a simple reading of design as the solution to systemic forms of oppression.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design methods, gentrification, public art, race},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300849,
author = {Wacker, Philipp and Nowak, Oliver and Voelker, Simon and Borchers, Jan},
title = {ARPen: Mid-Air Object Manipulation Techniques for a Bimanual AR System with Pen &amp; Smartphone},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300849},
doi = {10.1145/3290605.3300849},
abstract = {Modeling in Augmented Reality (AR) lets users create and manipulate virtual objects in mid-air that are aligned to their real environment. We present ARPen, a bimanual input technique for AR modeling that combines a standard smartphone with a 3D-printed pen. Users sketch with the pen in mid-air, while holding their smartphone in the other hand to see the virtual pen traces in the live camera image. ARPen combines the pen's higher 3D input precision with the rich interactive capabilities of the smartphone touchscreen. We studied subjective preferences for this bimanual input technique, such as how people hold the smartphone while drawing, and analyzed the performance of different bimanual techniques for selecting and moving virtual objects. Users preferred a bimanual technique casting a ray through the pen tip for both selection and translation. We provide initial design guidelines for this new class of bimanual AR modeling systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {augmented reality, bimanual interaction, immersive modeling, pen, mid-air interaction, translation, selection, smartphone ar},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300534,
author = {Aslan, Sinem and Alyuz, Nese and Tanriover, Cagri and Mete, Sinem E. and Okur, Eda and D'Mello, Sidney K. and Arslan Esme, Asli},
title = {Investigating the Impact of a Real-Time, Multimodal Student Engagement Analytics Technology in Authentic Classrooms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300534},
doi = {10.1145/3290605.3300534},
abstract = {We developed a real-time, multimodal Student Engagement Analytics Technology so that teachers can provide just-in-time personalized support to students who risk disengagement. To investigate the impact of the technology, we ran an exploratory semester-long study with a teacher in two classrooms. We used a multi-method approach consisting of a quasi-experimental design to evaluate the impact of the technology and a case study design to understand the environmental and social factors surrounding the classroom setting. The results show that the technology had a significant impact on the teacher's classroom practices (i.e., increased scaffolding to the students) and student engagement (i.e., less boredom). These results suggest that the technology has the potential to support teachers' role of being a coach in technology-mediated learning environments.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {affective computing, dashboards, learning analytics, real-time, student engagement},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300813,
author = {Avellino, Ignacio and Bailly, Gilles and Canlorbe, Geoffroy and Belgihti, J\'{e}r\'{e}mie and Morel, Guillaume and Vitrani, Marie-Aude},
title = {Impacts of Telemanipulation in Robotic Assisted Surgery},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300813},
doi = {10.1145/3290605.3300813},
abstract = {Robotic-assisted Minimally Invasive Surgery (MIS) is adopted more and more as it overcomes the shortcomings of classic MIS for surgeons while keeping the benefits of small incisions for patients. However, introducing new technology oftentimes affects the work of skilled practitioners. Our goals are to investigate the impacts of telemanipulated surgical robots on the work practices of surgical teams and to understand their cause. We conducted a field study observing 21 surgeries, conducting 12 interviews and performing 3 data validation sessions with surgeons. Using Thematic Analysis, we find that physically separating surgeons from their teams makes them more autonomous, shifts their use of perceptual senses, and turns the surgeon's assistant into the robot's assistant. We open design opportunities for the HCI field by questioning the telemanipulated approach and discussing alternatives that keep surgeons on the surgical field.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {minimally invasive surgery, robotic assisted surgery, da vinci},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300613,
author = {Mahapatra, Chandan and Jensen, Jonas Kjeldmand and McQuaid, Michael and Ashbrook, Daniel},
title = {Barriers to End-User Designers of Augmented Fabrication},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300613},
doi = {10.1145/3290605.3300613},
abstract = {Augmented fabrication is the practice of designing and fabricating an artifact to work with existing objects. Although common both in the wild and as an area for research tools, little is known about how novices approach the task of designing under the constraints of interfacing with real-world objects. In this paper, we report the results of a study of fifteen novice end users in an augmented fabrication design task. We discuss obstacles encountered in four contexts: capturing information about physical objects, transferring information to 3D~modeling software, digitally modeling a new object, and evaluating whether the new object will work when fabricated. Based on our findings, we suggest how future tools can better support augmented fabrication in each of these contexts.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {3d design, augmented fabrication, 3d printing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300926,
author = {Nishida, Jun and Matsuda, Soichiro and Oki, Mika and Takatori, Hikaru and Sato, Kosuke and Suzuki, Kenji},
title = {Egocentric Smaller-Person Experience through a Change in Visual Perspective},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300926},
doi = {10.1145/3290605.3300926},
abstract = {This paper explores how human perceptions, actions, and interactions can be changed through an embodied and active experience of being a smaller person in a real-world environment, which we call an egocentric smaller person experience. We developed a wearable visual translator that provides the perspective of a smaller person by shifting the wearer's eyesight level down to their waist using a head-mounted display and a stereo camera module, while allowing for field of view control through head movements. In this study, we investigated how the developed device can modify the wearer's body representation and experiences based on a field study conducted at a nursing school and museums, and through lab studies. It was observed that the participants changed their perceptions, actions, and interactions because they are considered to have perceived themselves as being smaller. Using this device, designers and teachers can understand the perspectives of other people in an existing environment.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {embodied interaction, virtual reality, body representation, egocentric experience, wearable device},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300343,
author = {Mauriello, Matthew Louis and McNally, Brenna and Froehlich, Jon E.},
title = {Thermporal: An Easy-To-Deploy Temporal Thermographic Sensor System to Support Residential Energy Audits},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300343},
doi = {10.1145/3290605.3300343},
abstract = {Underperforming, degraded, and missing insulation in US residential buildings is common. Detecting these issues, however, can be difficult. Using thermal cameras during energy audits can aid in locating potential insulation issues, but prior work indicates it is challenging to determine their severity using thermal imagery alone. In this work, we present an easy-to-deploy, temporal thermographic sensor system designed to support residential energy audits through quantitative analysis of building envelope performance. We then offer an evaluation of the system through two studies: (i) a one-week, in-home field study in five homes and (ii) a semi-structured interview study with five professional energy auditors. Our results show our system helps raise awareness, improves homeowners' ability to gauge the severity of issues, and provides opportunities for new interactions between homeowners, building data, and professional auditors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {temporal thermography, quantitative thermography, ubiquitous computing, sustainable hci, building energy audits},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300855,
author = {Hirzle, Teresa and Gugenheimer, Jan and Geiselhart, Florian and Bulling, Andreas and Rukzio, Enrico},
title = {A Design Space for Gaze Interaction on Head-Mounted Displays},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300855},
doi = {10.1145/3290605.3300855},
abstract = {Augmented and virtual reality (AR/VR) has entered the mass market and, with it, will soon eye tracking as a core technology for next generation head-mounted displays (HMDs). In contrast to existing gaze interfaces, the 3D nature of AR and VR requires estimating a user's gaze in 3D. While first applications, such as foveated rendering, hint at the compelling potential of combining HMDs and gaze, a systematic analysis is missing. To fill this gap, we present the first design space for gaze interaction on HMDs. Our design space covers human depth perception and technical requirements in two dimensions aiming to identify challenges and opportunities for interaction design. As such, our design space provides a comprehensive overview and serves as an important guideline for researchers and practitioners working on gaze interaction on HMDs. We further demonstrate how our design space is used in practice by presenting two interactive applications: EyeHealth and XRay-Vision.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, augmented reality, gaze interaction, design space, interaction design, 3d gaze, head-mounted displays},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300607,
author = {Rainey, Jay and Montague, Kyle and Briggs, Pamela and Anderson, Robert and Nappey, Thomas and Olivier, Patrick},
title = {Gabber: Supporting Voice in Participatory Qualitative Practices},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300607},
doi = {10.1145/3290605.3300607},
abstract = {We describe the iterative design, development and learning process we undertook to produce Gabber, a digital platform that aims to support distributed capture of spoken interviews and discussions, and their qualitative analysis. Our aim is to reduce both expertise and cost barriers associated with existing technologies, making the process more inclusive. Gabber structures distributed audio data capture, facilitates participatory sensemaking, and supports collaborative reuse of audio. We describe our design and development journey across three distinct field trials over a two-year period. Reflecting on the iterative design process, we offer insights into the challenges faced by non-experts throughout their qualitative practices, and provide guidance for researchers designing systems to support engagement in these practices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {collaborative sensemaking, qdas, audio annotation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300529,
author = {Hosey, Christine and Vujovi\'{c}, Lara and St. Thomas, Brian and Garcia-Gathright, Jean and Thom, Jennifer},
title = {Just Give Me What I Want: How People Use and Evaluate Music Search},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300529},
doi = {10.1145/3290605.3300529},
abstract = {Music-streaming platforms offer users a large amount of content for consumption. Finding the right music can be challenging and users often need to search through extensive catalogs provided by these platforms. Prior research has focused on general-domain web search, which is designed to meet a broad range of user goals. Here, we study search in the domain of music, seeking to understand how and why people use search and how they evaluate their search experiences on a music-streaming platform. Over two studies, we conducted semi-structured interviews with 27 participants, asking about their search habits and preferences, and observing their behavior while searching for music. Analysis revealed participants evaluated their search experiences along two dimensions: success and effort. Importantly, how participants perceived success and effort differed by their mindset, or the way they assessed the results of their query. We conclude with recommendations to improve the user experience of music search.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user behavior, music, search, mindsets},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300239,
author = {Harris, John and Hancock, Mark},
title = {To Asymmetry and Beyond! Improving Social Connectedness by Increasing Designed Interdependence in Cooperative Play},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300239},
doi = {10.1145/3290605.3300239},
abstract = {Social play can have numerous health benefits but research has shown that not all multiplayer games are effective at promoting social engagement. Asymmetric cooperative games have shown promise in this regard but the design and dynamics of this unique style of play is not yet well understood. To address this, we present the results of two player experience studies using our custom prototype game Beam Me 'Round, Scotty! 2: the first comparing symmetric cooperative play (e.g., where players have the same interface, goals, mechanics, etc.) to asymmetric cooperative play (e.g., where players have differing roles, abilities, interfaces, etc.) and the second comparing the effect of increasing degrees of interdependence between play partners. Our results not only indicate that asymmetric cooperative games may enhance players' perceptions of connectedness, social engagement, immersion, and comfort with a game's controls, but also demonstrate how to further improve these outcomes via deliberate mechanical design changes, such as changes in cooperative action timing and direction of dependence.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {player experience, games user research, symmetric vs asymmetric play, social presence, game design, asymmetric games},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300516,
author = {Soden, Robert and Kauffman, Nate},
title = {Infrastructuring the Imaginary: How Sea-Level Rise Comes to Matter in the San Francisco Bay Area},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300516},
doi = {10.1145/3290605.3300516},
abstract = {Information infrastructures have become integral components of policy debates related to climate change and sustainability. To better understand this relationship, we studied the tools used to forecast and respond to sea-level rise in the San Francisco Bay Area, where active debates on how to best prepare for this issues are underway and will have important consequences for the future of the region. Drawing on 18 months of qualitative research we argue that competing visions of the problem are intimately intertwined with different elements of information infrastructure and beliefs about the role of data in policymaking. Current infrastructure in the region, far from being a neutral actor in these debates, exhibits an infrastructural bias, privileging some approaches over others. We identify some of the tactics that community organizations deploy to subvert the claims of sea-level rise experts and advance their own perspective, which prioritizes considerations of justice over technical expertise.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {crisis informatics, climate change, environment, infrastructure, science and technology studies, civic technology},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300609,
author = {Elsden, Chris and Trotter, Ludwig and Harding, Mike and Davies, Nigel and Speed, Chris and Vines, John},
title = {Programmable Donations: Exploring Escrow-Based Conditional Giving},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300609},
doi = {10.1145/3290605.3300609},
abstract = {This paper reports on a co-speculative interview study with charitable donors to explore the future of programmable, conditional and data-driven donations. Responding to the rapid emergence of blockchain-based and AI-supported financial technologies, we specifically examine the potential of automated, third-party 'escrows', where donations are held before they are released or returned based on specified rules and conditions. To explore this we conducted pilot workshops with 9 participants and an interview study in which 14 further participants were asked about their experiences of donating money, and invited to co-speculate on a service for programmable giving. The study elicited how data-driven conditionality and automation could be leveraged to create novel donor experiences, however also illustrated the inherent tensions and challenges involved in giving programmatically. Reflecting on these findings, our paper contributes implications both for the design of programmable aid platforms, and the design of escrow-based financial services in general.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {conditionality, charity, automation, blockchains},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300793,
author = {Das, Maitraye and Hecht, Brent and Gergle, Darren},
title = {The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300793},
doi = {10.1145/3290605.3300793},
abstract = {Millions of people worldwide contribute content to peer production repositories that serve human information needs and provide vital world knowledge to prominent artificial intelligence systems. Yet, extreme gender participation disparities exist in which men significantly outnumber women. A central concern has been that due to self-focus bias, these disparities can lead to corresponding gender content disparities, in which content of interest to men is better represented than content of interest to women. This paper investigates the relationship between participation and content disparities in OpenStreetMap. We replicate findings that women are dramatically under-represented as OSM contributors, and observe that men and women contribute different types of content and do so about different places. However, the character of these differences confound simple narratives about self-focus bias: we find that on a proportional basis, men produced a higher proportion of contributions in feminized spaces compared to women, while women produced a higher proportion of contributions in masculinized spaces compared to men.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {rural, openstreetmap, self-focus bias, peer production, urban, gender},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300623,
author = {Allison, Fraser and Newn, Joshua and Smith, Wally and Carter, Marcus and Gibbs, Martin},
title = {Frame Analysis of Voice Interaction Gameplay},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300623},
doi = {10.1145/3290605.3300623},
abstract = {Voice control is an increasingly common feature of digital games, but the experience of playing with voice control is often hampered by feelings of embarrassment and dissonance. Past research has recognised these tensions, but has not offered a general model of how they arise and how players respond to them. In this study, we use Erving Goffman's frame analysis, as adapted to the study of games by Conway and Trevillian, to understand the social experience of playing games by voice. Based on 24 interviews with participants who played voice-controlled games in a social setting, we put forward a frame analytic model of gameplay as a social event, along with seven themes that describe how voice interaction enhances or disrupts the player experience. Our results demonstrate the utility of frame analysis for understanding social dissonance in voice interaction gameplay, and point to practical considerations for designers to improve engagement with voice-controlled games.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {frame analysis, voice interaction, games, voice control},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300438,
author = {Long, Michael and Gutwin, Carl},
title = {Effects of Local Latency on Game Pointing Devices and Game Pointing Tasks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300438},
doi = {10.1145/3290605.3300438},
abstract = {Studies have shown certain game tasks such as targeting to be negatively and significantly affected by latencies as low as 41ms. Therefore it is important to understand the relationship between local latency - delays between an input action and resulting change in the display - and common gaming tasks such as targeting and tracking. In addition, games now use a variety of input devices, including touchscreens, mice, tablets and controllers. These devices provide very different combinations of direct/indirect input, absolute/relative movement, and position/rate control, and are likely to be affected by latency in different ways. We performed a study evaluating and comparing the effects of latency across four devices (touchscreen, mouse, controller and drawing tablet) on targeting and interception tasks. We analyze both throughput and path characteristics, identify differences between devices, and provide design considerations for game designers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pointing devices, lag, latency, game experience},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300856,
author = {Shaw, Emily and Roper, Tessa and Nilsson, Tommy and Lawson, Glyn and Cobb, Sue V.G. and Miller, Daniel},
title = {The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300856},
doi = {10.1145/3290605.3300856},
abstract = {Understanding validity of user behaviour in Virtual Environments (VEs) is critical as they are increasingly being used for serious Health and Safety applications such as predicting human behaviour and training in hazardous situations. This paper presents a comparative study exploring user behaviour in VE-based fire evacuation and investigates whether this is affected by the addition of thermal and olfactory simulation. Participants (N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative analyses of participant attitudes and behaviours found deviations from those we would expect in real life (e.g. pre-evacuation actions), but also valid behaviours like fire avoidance. Potentially important differences were found between multisensory and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant potential in safety-related applications, and that multimodality may afford additional uses in this context, but the identified limitations of behavioural validity must be carefully considered to avoid misapplication of the technology.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual environments, multimodal, vr, user studies, behaviour},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300524,
author = {Mikkonen, Jussi and Townsend, Riikka},
title = {Frequency-Based Design of Smart Textiles},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300524},
doi = {10.1145/3290605.3300524},
abstract = {Despite the increasing amount of smart textile design practitioners, the methods and tools commonly available have not progressed to the same scale. Most smart textile interaction designs today rely on detecting changes in resistance. The tools and sensors for this are generally limited to DC-voltage-divider based sensors and multimeters. Furthermore, the textiles and the materials used in smart textile design can exhibit behaviour making it difficult to identify even simple interactions using those means. For instance, steel-based textiles exhibit intrinsic semiconductive properties that are difficult to identify with current methods. In this paper, we show an alternative way to measure interaction with smart textiles. By relying on visualisation known as Lissajous-figures and frequency-based signals, we can detect even subtle and varied forms of interaction with smart textiles. We also show an approach to measuring frequency-based signals and present an Arduino-based system called Teksig to support this type of textile practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {arduino, smart textile design practice, lissajous, frequency},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300365,
author = {Kip, Hanneke and Kelders, Saskia M. and Van Gemert-Pijnen, Lisette J.E.W.C},
title = {Putting the Value in VR: How to Systematically and Iteratively Develop a Value-Based VR Application with a Complex Target Group},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300365},
doi = {10.1145/3290605.3300365},
abstract = {In development, implementation and evaluation of eHealth it is essential to account for stakeholders' perspectives, opinions and values, which are statements that specify what stakeholders want to achieve or improve via a technology. The use of values enables developers to systematically include stakeholders' perspectives and the context of use in an eHealth development process. However, there are relatively few papers that explain how to use values in technology development. Consequently, in this paper we show how we formulated values during the multi-method, interdisciplinary and iterative development process of a VR application for a complex setting: forensic mental healthcare. We report the main foundations for these values: the outcomes of an online questionnaire with patients, therapists and other stakeholders (n=146) and interviews with patients and therapists (n=18). We show how a multidisciplinary project team used these qualitative results to formulate and adapt values and create lo-fi prototypes of a VR application. We discuss the importance of a systematic development process with multiple formative evaluations for eHealth and reflect on the role of values within this.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {iterative development, virtual reality, forensic mental healthcare, ehealth, value-based technology, formative evaluation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300797,
author = {Swaminathan, Saiganesh and Ozutemiz, Kadri Bugra and Majidi, Carmel and Hudson, Scott E.},
title = {FiberWire: Embedding Electronic Function into 3D Printed Mechanically Strong, Lightweight Carbon Fiber Composite Objects},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300797},
doi = {10.1145/3290605.3300797},
abstract = {3D printing offers significant potential in creating highly customized interactive and functional objects. However, at present ability to manufacture functional objects is limited by available materials (e.g., various polymers) and their process properties. For instance, many functional objects need stronger materials which may be satisfied with metal printers. However, to create wholly interactive devices, we need both conductors and insulators to create wiring, and electronic components to complete circuits. Unfortunately, the single material nature of metal printing, and its inherent high temperatures, preclude this. Thus, in 3D printed devices, we have had a choice of strong materials, or embedded interactivity, but not both. In this paper, we introduce a set of techniques we call FiberWire, which leverages a new commercially available capability to 3D print carbon fiber composite objects. These objects are light weight and mechanically strong, and our techniques demonstrate a means to embed circuitry for interactive devices within them. With FiberWire, we describe a fabrication pipeline takes advantage of laser etching and fiber printing between layers of carbon-fiber composite to form low resistance conductors, thereby enabling the fabrication of electronics directly embedded into mechanically strong objects. Utilizing the fabrication pipeline, we show a range of sensor designs, their performance characterization on these new materials and finally three fully printed example object that are both interactive and mechanically strong -- a bicycle handle bar with interactive controls, a swing and impact sensing golf club and an interactive game controller (Figure 1).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {carbon-fiber composites, fabrication, 3d printing, embedded electronics, material processing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300400,
author = {Peiris, Roshan Lalitha and Feng, Yuan-Ling and Chan, Liwei and Minamizawa, Kouta},
title = {ThermalBracelet: Exploring Thermal Haptic Feedback Around the Wrist},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300400},
doi = {10.1145/3290605.3300400},
abstract = {Smartwatches enable the wrist to be used as an ideal location to provide always-available haptic notifications as they are constantly worn with direct contact with the skin. With the wrist straps, the haptic feedback can be extended to the full space around the wrist to provide more spatial and enriched feedback. With ThermalBracelet, we investigate thermal feedback as a haptic feedback modality around the wrist. We present three studies that lead to the development of a smartwatch-integratable thermal bracelet that stimulates six locations around the wrist. Our initial evaluation reports on the selection of the thermal module configurations. Secondly, with the selected six-module configuration, we explore its usability in a real-world scenarios such as walking and reading. Thirdly, we investigate its capability of providing spatio temporal feedback while engaged in distracting tasks. Finally we present application scenarios that demonstrates its usability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {thermal, haptics, wrist, haptic perception},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300545,
author = {Bica, Melissa and Demuth, Julie L. and Dykes, James E. and Palen, Leysia},
title = {Communicating Hurricane Risks: Multi-Method Examination of Risk Imagery Diffusion},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300545},
doi = {10.1145/3290605.3300545},
abstract = {Conveying uncertainty in information artifacts is difficult; the challenge only grows as the demand for mass communication through multiple channels expands. In particular, as natural hazards increase with changing global conditions, including hurricanes which threaten coastal areas, we need better means of communicating uncertainty around risks that empower people to make good decisions. We examine how people share and respond to a range of visual representations of risk from authoritative sources during hurricane events. Because these images are now shared widely on social media platforms, Twitter provides the means to study them on a large scale as close to in vivo as possible. Using mixed methods, this study analyzes diffusion of and reactions to forecast and other risk imagery during the highly damaging 2017 Atlantic hurricane season to describe the collective response to visual representations of risk.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {risk communication, images, information diffusion},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300720,
author = {Himmelsbach, Julia and Schwarz, Stephanie and Gerdenitsch, Cornelia and Wais-Zechmann, Beatrix and Bobeth, Jan and Tscheligi, Manfred},
title = {Do We Care About Diversity in Human Computer Interaction: A Comprehensive Content Analysis on Diversity Dimensions in Research},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300720},
doi = {10.1145/3290605.3300720},
abstract = {In Human-Computer Interaction (HCI) research, awareness for the relevance of diversity of users is increasing. In this work, we analyze whether the articulated need for more diversity-sensitive research led indeed to a higher consideration of diversity in HCI research. Based on a comprehensive collection of diversity dimensions, we present results of a quantitative content analysis of articles accepted in the Proceedings of the Conference on Human Factors in Computing Systems 2006, 2011, and 2016. Results demonstrate how many and how intensively diversity dimensions were considered, and moreover highlight those dimensions that have so far received less attention. Uncovering continuous and discontinuous trends across time and differences between subfields of research, we identify research gaps and aim at contributing to a comprehensive understanding of diversity supporting diversity-sensitive research in HCI.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {hci research, considerations of users, critical diversity studies, study participants, diversity dimensions, diversity-sensitive research},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300585,
author = {Oney, Steve and Krosnick, Rebecca and Brandt, Joel and Myers, Brad},
title = {Implementing Multi-Touch Gestures with Touch Groups and Cross Events},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300585},
doi = {10.1145/3290605.3300585},
abstract = {Multi-touch gestures can be very difficult to program correctly because they require that developers build high-level abstractions from low-level touch events. In this paper, we introduce programming primitives that enable programmers to implement multi-touch gestures in a more understandable way by helping them build these abstractions. Our design of these primitives was guided by a formative study, in which we observed developers' natural implementations of custom gestures. Touch groups provide summaries of multiple fingers rather than requiring that programmers track them manually. Cross events allow programmers to summarize the movement of one or a group of fingers. We implemented these two primitives in two environments: a declarative programming system and in a standard imperative programming language. We found that these primitives are capable of defining nuanced multi-touch gestures, which we illustrate through a series of examples. Further, in two user evaluations of these programming primitives, we found that multi-touch behaviors implemented in these programming primitives are more understandable than those implemented with standard touch events.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {software development, programming, multi-touch, frameworks},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300843,
author = {Shin, Joon-Gi and Onchi, Eiji and Reyes, Maria Jose and Song, Junbong and Lee, Uichin and Lee, Seung-Hee and Saakes, Daniel},
title = {Slow Robots for Unobtrusive Posture Correction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300843},
doi = {10.1145/3290605.3300843},
abstract = {Prolonged static and unbalanced sitting postures during computer usage contribute to musculoskeletal discomfort. In this paper, we investigated the use of a very slow moving monitor for unobtrusive posture correction. In a first study, we identified display velocities below the perception threshold and observed how users (without being aware) responded by gradually following the monitor's motion. From the result, we designed a robotic monitor that moves imperceptible to counterbalance unbalanced sitting postures and induces posture correction. In an evaluation study (n=12), we had participants work for four hours without and with our prototype (8 in total). Results showed that actuation increased the frequency of non-disruptive swift posture corrections and significantly reduced the duration of unbalanced sitting. Most users appreciated the monitor correcting their posture and reported less physical fatigue. With slow robots, we make the first step toward using actuated objects for unobtrusive behavioral changes.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {slow interaction, ergonomics, robot monitor},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300729,
author = {Venn-Wycherley, Megan and Kharrufa, Ahmed},
title = {HOPE for Computing Education: Towards the Infrastructuring of Support for University-School Partnerships},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300729},
doi = {10.1145/3290605.3300729},
abstract = {The state of computing education in the UK is described as "patchy and fragile" with universities tasked to provide further support to schools. However, little guidance exists towards the provision of this support. To explore the development of university-school partnerships, we present findings of an extended educational engagement coordinated by Newcastle University, as part of the national "Create, Learn and Inspire with the micro:bit and the BBC" initiative. Following an action research approach, we explore the experiences of undergraduate students, schoolteachers and an educational broker through the process, including recruitment, content development, and delivery of over 30 computing lessons by nine undergraduates. We identify a number of design considerations towards the development of High Opportunity Progression Ecosystems for the improvement of computing education, such as student identity, workload model,and process visibility. We then discuss the potential role of technology in infrastructuring support for university-school partnerships},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {brokerage, computing education, learning ecologies, university-school partnerships},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300915,
author = {Du, Ruofei and Li, David and Varshney, Amitabh},
title = {Geollery: A Mixed Reality Social Media Platform},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300915},
doi = {10.1145/3290605.3300915},
abstract = {We present Geollery, an interactive mixed reality social media platform for creating, sharing, and exploring geotagged information. Geollery introduces a real-time pipeline to progressively render an interactive mirrored world with three-dimensional (3D) buildings, internal user-generated content, and external geotagged social media. This mirrored world allows users to see, chat, and collaborate with remote participants with the same spatial context in an immersive virtual environment. We describe the system architecture of Geollery, its key interactive capabilities, and our design decisions. Finally, we conduct a user study with 20 participants to qualitatively compare Geollery with another social media system, Social Street View. Based on the participants' responses, we discuss the benefits and drawbacks of each system and derive key insights for designing an interactive mirrored world with geotagged social media. User feedback from our study reveals several use cases for Geollery including travel planning, virtual meetings, and family gathering.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {3d reconstruction, visualization, mixed reality, geographic information system, street view, gis, virtual reality, social media, 3d user interface, augmented reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300825,
author = {Roffo, Giorgio and Vo, Dong-Bach and Tayarani, Mohammad and Rooksby, Maki and Sorrentino, Alessandra and Di Folco, Simona and Minnis, Helen and Brewster, Stephen and Vinciarelli, Alessandro},
title = {Automating the Administration and Analysis of Psychiatric Tests: The Case of Attachment in School Age Children},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300825},
doi = {10.1145/3290605.3300825},
abstract = {This article presents the School Attachment Monitor, a novel interactive system that can reliably administer the Manchester Child Attachment Story Task (a standard psychiatric test for the assessment of attachment in children) without the supervision of trained professionals. Attachment problems in children cause significant mental health issues and costs to society which technology has the potential to reduce. SAM collects, through instrumented doll-play games, enough information to allow a human assessor to manually identify the attachment status of children. Experiments show that the system successfully does this in 87.5% of cases. In addition, the experiments show that an automatic approach based on deep neural networks can map the information collected into the attachment condition of the children. The outcome SAM matches the judgment of expert human assessors in 82.8% of cases. This is the first time an automated tool has been successful in measuring attachment. This work has significant implications for psychiatry as it allows professionals to assess many more children cost effectively and to direct healthcare resources more accurately and efficiently to improve mental health.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {attachment, mental health, child computer interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300597,
author = {Hasan, Rakibul and Li, Yifang and Hassan, Eman and Caine, Kelly and Crandall, David J. and Hoyle, Roberto and Kapadia, Apu},
title = {Can Privacy Be Satisfying? On Improving Viewer Satisfaction for Privacy-Enhanced Photos Using Aesthetic Transforms},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300597},
doi = {10.1145/3290605.3300597},
abstract = {Pervasive photo sharing in online social media platforms can cause unintended privacy violations when elements of an image reveal sensitive information. Prior studies have identified image obfuscation methods (e.g., blurring) to enhance privacy, but many of these methods adversely affect viewers' satisfaction with the photo, which may cause people to avoid using them. In this paper, we study the novel hypothesis that it may be possible to restore viewers' satisfaction by 'boosting' or enhancing the aesthetics of an obscured image, thereby compensating for the negative effects of a privacy transform. Using a between-subjects online experiment, we studied the effects of three artistic transformations on images that had objects obscured using three popular obfuscation methods validated by prior research. Our findings suggest that using artistic transformations can mitigate some negative effects of obfuscation methods, but more exploration is needed to retain viewer satisfaction.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {privacy, image filtering, image obfuscation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300780,
author = {Kim, Joohwan and Stengel, Michael and Majercik, Alexander and De Mello, Shalini and Dunn, David and Laine, Samuli and McGuire, Morgan and Luebke, David},
title = {NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300780},
doi = {10.1145/3290605.3300780},
abstract = {Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomically-informed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with sub-millisecond latency. Our gaze estimation network achieves 2.06(±0.44)° of accuracy across a wide 30°\texttimes{}40° field of view on real subjects excluded from training and 0.5° best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, dataset, machine learning, eye tracking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300757,
author = {Auxier, Brooke E. and Buntain, Cody L. and Jaeger, Paul and Golbeck, Jennifer and Kacorri, Hernisa},
title = {#HandsOffMyADA: A Twitter Response to the ADA Education and Reform Act},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300757},
doi = {10.1145/3290605.3300757},
abstract = {Twitter continues to be used increasingly for communication related advocacy, activism, and social change. This is also the case for the disability community. In light of the recently proposed ADA Education and Reform in the United States, we investigate factors for effectiveness of sharing or retweeting messages about topics affecting the rights of people with disabilities. We perform a multifaceted study of the #HandsOffMyADA campaign against the proposed H.R.620 bill to: (1) explore how communication via Twitter compares to previous disability rights movements; (2) characterize the campaign in terms of hashtags, user groups, and content such as accessible multimedia that contribute to dissemination of campaign messages; (3) identify major themes in tweets and responses, and their variation among user groups; and (4) understand how the disability community mobilized for this campaign compared to previous Twitter initiatives.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {accessibility, activism, disability rights, social media},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300714,
author = {Kim, Da-jung and Lim, Youn-kyung},
title = {Co-Performing Agent: Design for Building User-Agent Partnership in Learning and Adaptive Services},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300714},
doi = {10.1145/3290605.3300714},
abstract = {Intelligent agents have become prevalent in everyday IT products and services. To improve an agent's knowledge of a user and the quality of personalized service experience, it is important for the agent to cooperate with the user (e.g., asking users to provide their information and feedback). However, few works inform how to support such user-agent co-performance from a human-centered perspective. To fill this gap, we devised Co-Performing Agent, a Wizard-of-Oz-based research probe of an agent that cooperates with a user to learn by helping users to have a partnership mindset. By incorporating the probe, we conducted a two-month exploratory study, aiming to understand how users experience co-performing with their agent over time. Based on the findings, this paper presents the factors that affected users' co-performing behaviors and discusses design implications for supporting constructive co-performance and building a resilient user-agent partnership over time.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {intelligent agents, co-performance, adaptive services, personalization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300809,
author = {Hohman, Fred and Head, Andrew and Caruana, Rich and DeLine, Robert and Drucker, Steven M.},
title = {Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300809},
doi = {10.1145/3290605.3300809},
abstract = {Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {data visualization, machine learning interpretability, design probe, interactive interfaces, visual analytics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300641,
author = {Kocielnik, Rafal and Amershi, Saleema and Bennett, Paul N.},
title = {Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-User Expectations of AI Systems},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300641},
doi = {10.1145/3290605.3300641},
abstract = {AI technologies have been incorporated into many end-user applications. However, expectations of the capabilities of such systems vary among people. Furthermore, bloated expectations have been identified as negatively affecting perception and acceptance of such systems. Although the intelligibility of ML algorithms has been well studied, there has been little work on methods for setting appropriate expectations before the initial use of an AI-based system. In this work, we use a Scheduling Assistant - an AI system for automated meeting request detection in free-text email - to study the impact of several methods of expectation setting. We explore two versions of this system with the same 50% level of accuracy of the AI component but each designed with a different focus on the types of errors to avoid (avoiding False Positives vs. False Negatives). We show that such different focus can lead to vastly different subjective perceptions of accuracy and acceptance. Further, we design expectation adjustment techniques that prepare users for AI imperfections and result in a significant increase in acceptance.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {shaping ai expectations, ai system on-boarding, perception and acceptance of ai, ai infused systems},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300496,
author = {Jabbar, Karim and Bj\o{}rn, Pernille},
title = {Blockchain Assemblages: <i>Whiteboxing</i> Technology and Transforming Infrastructural Imaginaries},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300496},
doi = {10.1145/3290605.3300496},
abstract = {In this paper we unpack empirical data from two domains within the Blockchain information infrastructure: The cryptocurrency trading domain, and the energy domain. Through these accounts we introduce the relational concepts of Blockchain Assemblages and Whiteboxing. Blockchain assemblages comprise configurations of digital and analogue artefacts that are entangled with imaginaries about the current and future state of the Blockchain information infrastructure. Rather than being a black box, Blockchain assemblages alternate between being dynamic and stable entities. We propose Whiteboxing as the sociomaterial process which drives blockchain assemblages in their dynamic state to be (re)configured, while related artefacts and imaginaries are simultaneously transformed, creating dynamic representations. Whiteboxing is triggered during disconfirming events when representations are discovered as problematic. Complementing existing historical accounts demonstrating technologies in the making, the contribution of this paper, proposes whiteboxing as an analytical concept which allows us to unpack how contemporary technologies are created through entrepreneurial activities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {entrepreneurship, information infrastructures, blockchain, assemblages, renewable energy, sociomaterial, cryptocurrency, embeddedness},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300768,
author = {Sundar, S. Shyam and Kim, Jinyoung},
title = {Machine Heuristic: When We Trust Computers More than Humans with Our Personal Information},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300768},
doi = {10.1145/3290605.3300768},
abstract = {In this day and age of identity theft, are we likely to trust machines more than humans for handling our personal information? We answer this question by invoking the concept of "machine heuristic," which is a rule of thumb that machines are more secure and trustworthy than humans. In an experiment (N = 160) that involved making airline reservations, users were more likely to reveal their credit card information to a machine agent than a human agent. We demonstrate that cues on the interface trigger the machine heuristic by showing that those with higher cognitive accessibility of the heuristic (i.e., stronger prior belief in the rule of thumb) were more likely than those with lower accessibility to disclose to a machine, but they did not differ in their disclosure to a human. These findings have implications for design of interface cues conveying machine vs. human sources of our online interactions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {main model, secure and trustworthy computing, cognitive heuristics, virtual agent, automation bias, machine heuristic},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300553,
author = {Bhattacharyya, Po and Nath, Radha and Jo, Yein and Jadhav, Ketki and Hammer, Jessica},
title = {Brick: Toward A Model for Designing Synchronous Colocated Augmented Reality Games},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300553},
doi = {10.1145/3290605.3300553},
abstract = {Augmented reality (AR) games have been growing in popularity in recent years. However, current AR games offer limited opportunities for a synchronous multiplayer experience. This paper introduces a model for designing AR experiences in which players inhabit a shared, real-time augmented environment and can engage in synchronous and collaborative interactions with other players. We explored the development of this model through the creation of Brick, a two-player mobile AR game at the room scale. We refined Brick over multiple rounds of iteration, and we used our playtests to investigate a range of issues involved in designing shared-world AR games. Our findings suggest that there are five major categories of interactions in a shared-world AR system: single-player, intrapersonal, multiplayer, interpersonal, and environmental. We believe that this model can support the development of collaborative AR games and new forms of social gameplay.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {synchronous, colocated, collaborative, augmented reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300271,
author = {Brown, Anna and Chouldechova, Alexandra and Putnam-Hornstein, Emily and Tobin, Andrew and Vaithianathan, Rhema},
title = {Toward Algorithmic Accountability in Public Services: A Qualitative Study of Affected Community Perspectives on Algorithmic Decision-Making in Child Welfare Services},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300271},
doi = {10.1145/3290605.3300271},
abstract = {Algorithmic decision-making systems are increasingly being adopted by government public service agencies. Researchers, policy experts, and civil rights groups have all voiced concerns that such systems are being deployed without adequate consideration of potential harms, disparate impacts, and public accountability practices. Yet little is known about the concerns of those most likely to be affected by these systems. We report on workshops conducted to learn about the concerns of affected communities in the context of child welfare services. The workshops involved 83 study participants including families involved in the child welfare system, employees of child welfare agencies, and service providers. Our findings indicate that general distrust in the existing system contributes significantly to low comfort in algorithmic decision-making. We identify strategies for improving comfort through greater transparency and improved communication strategies. We discuss the implications of our study for accountable algorithm design for child welfare applications.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {automated decision systems, decision-support, algorithmic bias, child welfare services, algorithmic accountability, participatory design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300624,
author = {Aladwan, Ahed and Kelly, Ryan M. and Baker, Steven and Velloso, Eduardo},
title = {A Tale of Two Perspectives: A Conceptual Framework of User Expectations and Experiences of Instructional Fitness Apps},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300624},
doi = {10.1145/3290605.3300624},
abstract = {We present a conceptual framework grounded in both users' reviews and HCI theories, residing between practices and theories as a form of intermediate-level knowledge in interaction design. Previous research has examined different forms of intermediary knowledge such as conceptual structures, strong concepts, and bridging concepts. Within HCI, these forms are generic and rise either from theories or particular instances. In this work, we created and evaluated a conceptual framework for a specific domain (instructional fitness apps). We first extracted the particular instances using users' online reviews and conceptualised them as an expectations and experiences framework. Second, within the framework, we evaluated the artefact related constructs using Norman's design principles. Third, we evaluated beyond the artefact related constructs using distributed cognition theory. We present an analysis of such intermediate-level knowledge with the aim of informing future designs.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {smartphone, intermediate-level knowledge, fitness, conceptual framework, expectations, online reviews, experience},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300408,
author = {Gray, Colin M. and Chivukula, Shruthi Sai},
title = {Ethical Mediation in UX Practice},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300408},
doi = {10.1145/3290605.3300408},
abstract = {HCI scholars have become increasingly interested in describing the complex nature of UX practice. In parallel, HCI and STS scholars have sought to describe the ethical and value-laden relationship between designers and design outcomes. However, little research describes the ethical engagement of UX practitioners as a form of design complexity, including the multiple mediating factors that impact ethical awareness and decision-making. In this paper, we use a practice-led approach to describe ethical complexity, presenting three varied cases of UX practitioners based onin situ observations and interviews. In each case, we describe salient factors relating to ethical mediation, including organizational practices, self-driven ethical principles, and unique characteristics of specific projects the practitioner is engaged in. Using the concept of mediation from activity theory, we provide a rich account of practitioners' ethical decision making. We propose future work on ethical awareness and design education based on the concept of ethical mediation.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {practice-led research, ux design, mediation, applied ethics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300645,
author = {Hitron, Tom and Orlev, Yoav and Wald, Iddo and Shamir, Ariel and Erel, Hadas and Zuckerman, Oren},
title = {Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300645},
doi = {10.1145/3290605.3300645},
abstract = {Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children's understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children's interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {construction kits, children, design principles, learning system, machine learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300240,
author = {Fl\'{o}rez-Aristiz\'{a}bal, Leandro and Cano, Sandra and Collazos, C\'{e}sar A. and Solano, Andr\'{e}s F. and Brewster, Stephen},
title = {DesignABILITY: Framework for the Design of Accessible Interactive Tools to Support Teaching to Children with Disabilities},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300240},
doi = {10.1145/3290605.3300240},
abstract = {Developing educational tools aimed at children with disabilities is a challenging process for designers and developers because existing methodologies or frameworks do not provide any pedagogical information and/or do not take into account the particular needs of users with some type of impairment. In this study, we propose a framework for the design of tools to support teaching to children with disabilities. The framework provides the necessary stages for the development of tools (hardware-based or software-based) and must be adapted for a specific disability and educational goal. For this study, the framework was adapted to support literacy teaching and contributes to the design of educational/interactive technology for deaf people while making them part of the design process and taking into account their particular needs. The experts' evaluation of the framework shows that it is well structured and may be adapted for other types of disabilities.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {deaf children, literacy, disability, storytelling, design, collaborative learning},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300267,
author = {Gu, Jianzhe and Breen, David E. and Hu, Jenny and Zhu, Lifeng and Tao, Ye and Van de Zande, Tyson and Wang, Guanyun and Zhang, Yongjie Jessica and Yao, Lining},
title = {Geodesy: Self-Rising 2.5D Tiles by Printing along 2D Geodesic Closed Path},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300267},
doi = {10.1145/3290605.3300267},
abstract = {Thermoplastic and Fused Deposition Modeling (FDM) based 4D printing are rapidly expanding to allow for space- and material-saving 2D printed sheets morphing into 3D shapes when heated. However, to our knowledge, all the known examples are either origami-based models with obvious folding hinges, or beam-based models with holes on the morphing surfaces. Morphing continuous double-curvature surfaces remains a challenge, both in terms of a tailored toolpath-planning strategy and a computational model that simulates it. Additionally, neither approach takes surface texture as a design parameter in its computational pipeline. To extend the design space of FDM-based 4D printing, in Geodesy, we focus on the morphing of continuous double-curvature surfaces or surface textures. We suggest a unique tool path - printing thermoplastics along 2D closed geodesic paths to form a surface with one raised continuous double-curvature tiles when exposed to heat. The design space is further extended to more complex geometries composed of a network of rising tiles (i.e., surface textures). Both design components and the computational pipeline are explained in the paper, followed by several printed geometric examples.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {morphing, shell structure, shape-changing interface, non-developable surface, 4d printing, 3d printing, self-folding},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300557,
author = {Dinneen, Jesse David and Julien, Charles-Antoine and Frissen, Ilja},
title = {The Scale and Structure of Personal File Collections},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300557},
doi = {10.1145/3290605.3300557},
abstract = {Although many challenges of managing computer files have been identified in past studies -- and many alternative prototypes made -- the scale and structure of personal file collections remain relatively unknown. We studied 348 such collections, and found they are typically considerably larger in scale (30-190 thousand files) and structure (folder trees twice taller and many times wider) than previously thought, which suggests files and folders are used now more than ever despite advances in Web storage, desktop search, and tagging. Data along many measures within and across collections were log normally distributed, indicating that personal collections resemble imbalanced, group-made collections and confirming the intuition that personal information management behaviour varies greatly. Directions for the generation of test collections and other future research are discussed.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {folder navigation, personal information management, files},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300461,
author = {Herbig, Nico and Pal, Santanu and van Genabith, Josef and Kr\"{u}ger, Antonio},
title = {Multi-Modal Approaches for Post-Editing Machine Translation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300461},
doi = {10.1145/3290605.3300461},
abstract = {Current advances in machine translation increase the need for translators to switch from traditional translation to post-editing (PE) of machine-translated text, a process that saves time and improves quality. This affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Our results of an elicitation study with professional translators indicate that a combination of pen, touch, and speech could well support common PE tasks, and received high subjective ratings by our participants. Therefore, we argue that future translation environment research should focus more strongly on these modalities in addition to mouse- and keyboard-based approaches. On the other hand, eye tracking and gesture modalities seem less important. An additional interview regarding interface design revealed that most translators would also see value in automatically receiving additional resources when a high cognitive load is detected during PE.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {computer-aided translation, post-editing, multi-modality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300472,
author = {Moser, Carol and Schoenebeck, Sarita Y. and Resnick, Paul},
title = {Impulse Buying: Design Practices and Consumer Needs},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300472},
doi = {10.1145/3290605.3300472},
abstract = {E-commerce sites have an incentive to encourage impulse buying, even when not in the consumer's best interest. This study investigates what features e-commerce sites use to encourage impulse buying and what tools consumers desire to curb their online spending. We present two studies: (1) a systematic content analysis of 200 top e-commerce websites in the U.S. and (2) a survey of online impulse buyers (N=151). From Study 1, we find that e-commerce sites contain multiple features that encourage impulsive buying, including those that lower perceived risks, leverage social influence, and enhance perceived proximity to the product. Conversely, from Study 2 we find that online impulse buyers want tools that (a) encourage deliberation and avoidance, (b) enforce spending limits and postponement, (c) increase checkout effort, (d) make costs more salient, and (e) reduce product desire. These findings inform the design of "friction'' technologies that help users make more deliberative consumer choices.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {dark patterns, behavior change, e-commerce, self-control},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300604,
author = {Park, Soya and Zhang, Amy X. and Murray, Luke S. and Karger, David R.},
title = {Opportunities for Automating Email Processing: A Need-Finding Study},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300604},
doi = {10.1145/3290605.3300604},
abstract = {Email management consumes significant effort from senders and recipients. Some of this work might be automatable. We performed a mixed-methods need-finding study to learn: (i) what sort of automatic email handling users want, and (ii) what kinds of information and computation are needed to support that automation. Our investigation included a design workshop to identify categories of needs, a survey to better understand those categories, and a classification of existing email automation software to determine which needs have been addressed. Our results highlight the need for: a richer data model for rules, more ways to manage attention, leveraging internal and external email context, complex processing such as response aggregation, and affordances for senders. To further investigate our findings, we developed a platform for authoring small scripts over a user's inbox. Of the automations found in our studies, half are impossible in popular email clients, motivating new design directions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {personal information management, email, task management},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300728,
author = {Karchemsky, Mitchell and Zamfirescu-Pereira, J.D. and Wu, Kuan-Ju and Guimbreti\`{e}re, Fran\c{c}ois and Hartmann, Bjoern},
title = {Heimdall: A Remotely Controlled Inspection Workbench For Debugging Microcontroller Projects},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300728},
doi = {10.1145/3290605.3300728},
abstract = {Students and hobbyists build embedded systems that combine sensing, actuation and microcontrollers on solderless breadboards. To help students debug such circuits, experienced teachers apply visual inspection, targeted measurements, and circuit modifications to diagnose and localize the problem(s). However, experienced helpers may not always be available to review student projects in person. To enable remote debugging of circuit problems, we introduce Heimdall, a remote electronics workbench that allows experts to visually inspect a student's circuit; perform measurements; and to re-wire and inject test signals. These interactions are enabled by an actuated inspection camera; an augmented breadboard that enables flexible configuration of row connectivity and measurement/injection lines; and a web-based UI that teachers can use to perform measurements through interaction with the captured images. We demonstrate that common issues arising in embedded electronics classes can be successfully diagnosed remotely and report on preliminary user feedback from teaching assistants who frequently debug circuits.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {electronics, remote debugging, embedded systems},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300358,
author = {Hu, Kevin and Bakker, Michiel A. and Li, Stephen and Kraska, Tim and Hidalgo, C\'{e}sar},
title = {VizML: A Machine Learning Approach to Visualization Recommendation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300358},
doi = {10.1145/3290605.3300358},
abstract = {Visualization recommender systems aim to lower the barrier to exploring basic visualizations by automatically generating results for analysts to search and select, rather than manually specify. Here, we demonstrate a novel machine learning-based approach to visualization recommendation that learns visualization design choices from a large corpus of datasets and associated visualizations. First, we identify five key design choices made by analysts while creating visualizations, such as selecting a visualization type and choosing to encode a column along the X- or Y-axis. We train models to predict these design choices using one million dataset-visualization pairs collected from a popular online visualization platform. Neural networks predict these design choices with high accuracy compared to baseline models. We report and interpret feature importances from one of these baseline models. To evaluate the generalizability and uncertainty of our approach, we benchmark with a crowdsourced test set, and show that the performance of our model is comparable to human performance when predicting consensus visualization type, and exceeds that of other visualization recommender systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {crowdsourcing, machine learning, automated visualization},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300273,
author = {Kittley-Davies, Jacob and Alqaraawi, Ahmed and Yang, Rayoung and Costanza, Enrico and Rogers, Alex and Stein, Sebastian},
title = {Evaluating the Effect of Feedback from Different Computer Vision Processing Stages: A Comparative Lab Study},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300273},
doi = {10.1145/3290605.3300273},
abstract = {Computer vision and pattern recognition are increasingly being employed by smartphone and tablet applications targeted at lay-users. An open design challenge is to make such systems intelligible without requiring users to become technical experts. This paper reports a lab study examining the role of visual feedback. Our findings indicate that the stage of processing from which feedback is derived plays an important role in users' ability to develop coherent and correct understandings of a system's operation. Participants in our study showed a tendency to misunderstand the meaning being conveyed by the feedback, relating it to processing outcomes and higher level concepts, when in reality the feedback represented low level features. Drawing on the experimental results and the qualitative data collected, we discuss the challenges of designing interactions around pattern matching algorithms.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {processing pipelines, controlled study, keypoints, computer vision, stop motion animation, feedback},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300464,
author = {Ferdous, Hasan Shahid and Hoang, Thuong and Joukhadar, Zaher and Reinoso, Martin N. and Vetere, Frank and Kelly, David and Remedios, Louisa},
title = {"What's Happening at That Hip?": Evaluating an On-Body Projection Based Augmented Reality System for Physiotherapy Classroom},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300464},
doi = {10.1145/3290605.3300464},
abstract = {We present two studies to discuss the design, usability analysis, and educational outcome resulting from our system Augmented Body in physiotherapy classroom. We build on prior user-centric design work that investigates existing teaching methods and discuss opportunities for intervention. We present the design and implementation of a hybrid system for physiotherapy education combining an on-body projection based virtual anatomy supplemented by pen-based tablets to create real-time annotations. We conducted a usability evaluation of this system, comparing with projection only and traditional teaching conditions. Finally, we focus on a comparative study to evaluate learning outcome among students in actual classroom settings. Our studies showed increased usage of visual representation techniques in students'11 note taking behavior and statistically significant improvement in some learning aspects. We discuss challenges for designing augmented reality systems for education, including minimizing attention split, addressing text-entry issues, and digital annotations on a moving physical body.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pen-based interactions, augmented reality, annotation, projection mapping, educational system},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300259,
author = {D\"{o}rrenb\"{a}cher, Judith and Hassenzahl, Marc},
title = {Changing Perspective: A Co-Design Approach to Explore Future Possibilities of Divergent Hearing},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300259},
doi = {10.1145/3290605.3300259},
abstract = {Conventional hearing aids frame hearing impairment almost exclusively as a problem. In the present paper, we took an alternative approach by focusing on positive future possibilities of 'divergent hearing'. To this end, we developed a method to speculate simultaneously about not-yet-experienced positive meanings and not-yet-existing technology. First, we gathered already existing activities in which divergent hearing was experienced as an advantage rather than as a burden. These activities were then condensed into 'Prompts of Positive Possibilities' (PPP), such as 'Creating a shelter to feel safe in". In performative sessions, participants were given these PPPs and 'Open Probes' to enact novel everyday activities. This led to 26 possible meanings and according devices, such as "Being able to listen back into the past with a rewinder". The paper provides valuable insights into the interests and expectations of people with divergent hearing as well as a methodological contribution to a possibility-driven design.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {possibility-driven design, participation, hearing impairment, enhancement, performative methods, positive design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300274,
author = {Freeman, Guo and Bardzell, Jeffrey and Bardzell, Shaowen and Liu, Szu-Yu (Cyn) and Lu, Xi and Cao, Diandian},
title = {Smart and Fermented Cities: An Approach to Placemaking in Urban Informatics},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300274},
doi = {10.1145/3290605.3300274},
abstract = {What makes a city meaningful to its residents? What attracts people to live in a city and to care for it? Today, we might see such questions as concerns for HCI, given the emerging agendas of smart and connected cities, IoT, and ubiquitous computing: city residents' perceptions of and attitudes towards smart city technologies will play a role in technology acceptance. Theories of "placemaking" from humanist geography and urban planning address themselves to such concerns, and they have been taken up in HCI and urban informatics research. This theory offers ideas for developing community attachment, heightening the legibility of the city, and intensifying lived experiences in the city. We add to this body of research with an analysis of several initiatives of City Yeast, a community-based design collective in Taiwan that proposes the metaphor of fermentation as an approach to placemaking. We unpack how this approach shapes their design practice and link its implications to urban informatics research in HCI. We suggest that smart cities can also be pursued by leveraging the knowledge of city residents and helping to facilitate their participation in acts of perceiving, envisioning, and improving their local communities, including but not limited to smart and connected technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart cities, placemaking, urban informatics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300512,
author = {Sannon, Shruti and Cosley, Dan},
title = {Privacy, Power, and Invisible Labor on Amazon Mechanical Turk},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300512},
doi = {10.1145/3290605.3300512},
abstract = {Tasks on crowdsourcing platforms such as Amazon Mechanical Turk often request workers' personal information, raising privacy risks that may be exacerbated by requester-worker power dynamics. We interviewed 14 workers to understand how they navigate these risks. We found that Turkers' decisions to provide personal information during tasks were based on evaluations of the pay rate, the requester, the purpose, and the perceived sensitivity of the request. Participants also engaged in multiple privacy-protective behaviors, such as abandoning tasks or providing inaccurate data, though there were costs associated with these behaviors, such as wasted time and risk of rejection. Finally, their privacy concerns and practices evolved as they learned about both the platform and worker-designed tools and forums. These findings deepen our understanding of both privacy decision-making and invisible labor in paid crowdsourcing, and emphasize a general need to understand how privacy stances change over time.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {privacy, mturk, crowdsourcing, invisible labor},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300802,
author = {Arakawa, Riku and Yakura, Hiromu},
title = {REsCUE: A Framework for REal-Time Feedback on Behavioral CUEs Using Multimodal Anomaly Detection},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300802},
doi = {10.1145/3290605.3300802},
abstract = {Executive coaching has been drawing more and more attention for developing corporate managers. While conversing with managers, coach practitioners are also required to understand internal states of coachees through objective observations. In this paper, we present REsCUE, an automated system to aid coach practitioners in detecting unconscious behaviors of their clients. Using an unsupervised anomaly detection algorithm applied to multimodal behavior data such as the subject's posture and gaze, REsCUE notifies behavioral cues for coaches via intuitive and interpretive feedback in real-time. Our evaluation with actual coaching scenes confirms that REsCUE provides the informative cues to understand internal states of coachees. Since REsCUE is based on the unsupervised method and does not assume any prior knowledge, further applications beside executive coaching are conceivable using our framework.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multimodal interaction, anomaly detection, nonverbal behavior analysis, executive coaching},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300338,
author = {Wen, Zikai Alex and Lin, Zhiqiu and Chen, Rowena and Andersen, Erik},
title = {What.Hack: Engaging Anti-Phishing Training Through a Role-Playing Phishing Simulation Game},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300338},
doi = {10.1145/3290605.3300338},
abstract = {Phishing attacks are a major problem, as evidenced by the DNC hackings during the 2016 US presidential election, in which staff were tricked into sharing passwords by fake Google security emails, granting access to confidential information. Vulnerabilities such as these are due in part to insufficient and tiresome user training in cybersecurity. Ideally, we would have more engaging training methods that teach cybersecurity in an active and entertaining way. To address this need, we introduce the game What.Hack, which not only teaches phishing concepts but also simulates actual phishing attacks in a role-playing game to encourage the player to practice defending themselves. Our user study shows that our game design is more engaging and effective in improving performance than a standard form of training and a competing training game design (which does not simulate phishing attempts through role-playing).},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {applied game, situated learning, anti-phishing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300391,
author = {Schneider, Hanna and Wayrauther, Julia and Hassib, Mariam and Butz, Andreas},
title = {Communicating Uncertainty in Fertility Prognosis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300391},
doi = {10.1145/3290605.3300391},
abstract = {Communicating uncertainty has been shown to provide positive effects on user understanding and decision-making. Surprisingly however, most personal health tracking applications fail to disclose the accuracy of their measurements and predictions. In the case of fertility tracking applications (FTAs), inaccurate predictions have already led to numerous unwanted pregnancies and law suits. However, integrating uncertainty into FTAs is challenging: Prediction accuracy is hard to understand and communicate, and its effect on users' trust and behavior is not well understood. We created a prototype for uncertainty visualizations for FTAs and evaluated it in a four-week field study with real users and their own data (N=9). Our results uncover far-reaching effects of communicating uncertainty: For example, users interpreted prediction accuracy as a proxy for their cycle health and as a security indicator for contraception. Displaying predicted and detected fertile phases next to each other helped users to understand uncertainty without negative emotional effects.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {personal informatics, women's health, menstrual cycle, uncertainty visualization, fertility tracking applications},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300518,
author = {Ringland, Kathryn E.},
title = {A Place to Play: The (Dis)Abled Embodied Experience for Autistic Children in Online Spaces},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300518},
doi = {10.1145/3290605.3300518},
abstract = {Play is the work of children-but access to play is not equal from child to child. Having access to a place to play is a challenge for marginalized children, such as children with disabilities. For autistic children, playing with other children in the physical world may be uncomfortable or even painful. Yet, having practice in the social skills play provides is essential for childhood development. In this ethnographic work, I explore how one community uses the sense of place and the digital embodied experience in a virtual world specifically to give autistic children access to play with their peers. The contribution of this work is twofold. First, I demonstrate how various physical and virtual spaces work together to make play possible. Second, I demonstrate these spaces, though some of them are digital, are no more or less "real" than the physical spaces making up a schoolyard or playground.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {communication, inclusion, embodied experience, autism, social media, social interaction, virtual worlds, disability},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300376,
author = {Kimura, Naoki and Kono, Michinari and Rekimoto, Jun},
title = {SottoVoce: An Ultrasound Imaging-Based Silent Speech Interaction Using Deep Neural Networks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300376},
doi = {10.1145/3290605.3300376},
abstract = {The availability of digital devices operated by voice is expanding rapidly. However, the applications of voice interfaces are still restricted. For example, speaking in public places becomes an annoyance to the surrounding people, and secret information should not be uttered. Environmental noise may reduce the accuracy of speech recognition. To address these limitations, a system to detect a user's unvoiced utterance is proposed. From internal information observed by an ultrasonic imaging sensor attached to the underside of the jaw, our proposed system recognizes the utterance contents without the user's uttering voice. Our proposed deep neural network model is used to obtain acoustic features from a sequence of ultrasound images. We confirmed that audio signals generated by our system can control the existing smart speakers. We also observed that a user can adjust their oral movement to learn and improve the accuracy of their voice recognition.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {speech interaction, human-ai integration, silent speech, deep neural networks, ultrasonic imaging},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300903,
author = {Muender, Thomas and Reinschluessel, Anke V. and Drewes, Sean and Wenig, Dirk and D\"{o}ring, Tanja and Malaka, Rainer},
title = {Does It Feel Real? Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300903},
doi = {10.1145/3290605.3300903},
abstract = {Professionals in domains like film, theater, or architecture often rely on physical models to visualize spaces. With virtual reality (VR) new tools are available providing immersive experiences with correct perceptions of depth and scale. However, these lack the tangibility of physical models. Using tangible objects in VR can close this gap but creates the challenges of producing suitable objects and interacting with them with only the virtual objects visible. This work addresses these challenges by evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the virtual shapes. We present results from a comparative study on immersion, performance, and intuitive interaction and interviews with domain experts. The results show that 3D-printed objects perform best, but Lego offers a good trade-off between fast creation of tangibles and sufficient fidelity. The experts rate our approach as useful and would use all three versions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {animation, tangibles, virtual reality, expert interview, user study, previsualization, visual tracking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300887,
author = {Spence, Jocelyn},
title = {Inalienability: Understanding Digital Gifts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300887},
doi = {10.1145/3290605.3300887},
abstract = {This paper takes on one of the rarely articulated yet important questions pertaining to digital media objects: how do HCI and design researchers understand 'gifting' when the object can just as easily be 'shared'? This question has often been implied and occasionally answered, though only partially. We propose the concept of 'inalienability', taken from the gifting literature, as a useful theory for clarifying what design researchers mean by gifting in a digital context. We apply 'inalienability' to three papers from the ACM Digital Library and one ongoing project, spanning nearly two decades of HCI and design research, that combine 'gifting and 'sharing' in their frameworks. In this way we show how applying the concept of 'inalienability' can clarify behaviours that mark gifting as a unique activity, frame research questions around gifting and sharing, outline specific next steps for gifting research, and suggest design strategies in this area.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {inalienability, gifting, strong concepts, sharing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300677,
author = {Williams, Randi and Park, Hae Won and Breazeal, Cynthia},
title = {A is for Artificial Intelligence: The Impact of Artificial Intelligence Activities on Young Children's Perceptions of Robots},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300677},
doi = {10.1145/3290605.3300677},
abstract = {We developed a novel early childhood artificial intelligence (AI) platform, PopBots, where preschool children train and interact with social robots to learn three AI concepts: knowledge-based systems, supervised machine learning, and generative AI. We evaluated how much children learned by using AI assessments we developed for each activity. The median score on the cumulative assessment was 70% and children understood knowledge-based systems the best. Then, we analyzed the impact of the activities on children's perceptions of robots. Younger children came to see robots as toys that were smarter than them, but their older counterparts saw them more as people that were not as smart as them. Children who performed worse on the AI assessments believed that robots were like toys that were not as smart as them, however children who did better on the assessments saw robots as people who were smarter than them. We believe early AI education can empower children to understand the AI devices that are increasingly in their lives.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {ai education, social robots, child-robot interaction, early childhood education},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300281,
author = {van Berkel, Niels and Goncalves, Jorge and Koval, Peter and Hosio, Simo and Dingler, Tilman and Ferreira, Denzil and Kostakos, Vassilis},
title = {Context-Informed Scheduling and Analysis: Improving Accuracy of Mobile Self-Reports},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300281},
doi = {10.1145/3290605.3300281},
abstract = {Mobile self-reports are a popular technique to collect participant labelled data in the wild. While literature has focused on increasing participant compliance to self-report questionnaires, relatively little work has assessed response accuracy. In this paper, we investigate how participant context can affect response accuracy and help identify strategies to improve the accuracy of mobile self-report data. In a 3-week study we collect over 2,500 questionnaires containing both verifiable and non-verifiable questions. We find that response accuracy is higher for questionnaires that arrive when the phone is not in ongoing or very recent use. Furthermore, our results show that long completion times are an indicator of a lower accuracy. Using contextual mechanisms readily available on smartphones, we are able to explain up to 13% of the variance in participant accuracy. We offer actionable recommendations to assist researchers in their future deployments of mobile self-report studies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data quality, smartphones, ema, context, questionnaires, ecological momentary assessment, cognition, esm, working memory, experience sampling method},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300681,
author = {Dole, Lorin and Ju, Wendy},
title = {Face and Ecological Validity in Simulations: Lessons from Search-and-Rescue HRI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300681},
doi = {10.1145/3290605.3300681},
abstract = {In fields where in situ performance cannot be measured, ecological validity is difficult to estimate. Drawing on theory from social psychology and virtual reality, we argue that face validity can be a useful proxy for ecological validity. We provide illustrative examples of this relationship from work in search-and-rescue HRI, and conclude with some practical guidelines for the construction of immersive simulations in general.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {search and rescue, face validity, mundane realism, transposition, emergence, ecological validity, immersion, presence, virtual reality, experimental realism, dependents, human-robot interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300360,
author = {Lee, Alexandra and Archambault, Daniel and Nacenta, Miguel},
title = {Dynamic Network Plaid: A Tool for the Analysis of Dynamic Networks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300360},
doi = {10.1145/3290605.3300360},
abstract = {Network data that changes over time can be very useful for studying a wide range of important phenomena, from how social network connections change to epidemiology. However, it is challenging to analyze, especially if it has many actors, connections or if the covered timespan is large with rapidly changing links (e.g., months of changes with changes at second resolution). In these analyses one would often like to compare many periods of time to others, without having to look at the full timeline. To support this kind of analysis we designed and implemented a technique and system to visualize this dynamic data. The Dynamic Network Plaid (DNP) is designed for large displays and based on user-generated interactive timeslicing on the dynamic graph attributes and on linked provenance-preserving representations. We present the technique, interface and the design/evaluation with a group of public health researchers investigating non-suicidal self-harm picture sharing in Instagram.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interaction provenance, information visualization, large display visualization, dynamic network analysis},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300884,
author = {Grundgeiger, Tobias and Huber, Stephan and Reinhardt, Daniel and Steinisch, Andreas and Happel, Oliver and Wurmb, Thomas},
title = {Cognitive Aids in Acute Care: Investigating How Cognitive Aids Affect and Support In-Hospital Emergency Teams},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300884},
doi = {10.1145/3290605.3300884},
abstract = {Cognitive aids - artefacts that support a user in the completion of a task at the time - have raised great interest to support healthcare staff during medical emergencies. However, the mechanisms of how cognitive aids support or affect staff remain understudied. We describe the iterative development of a tablet-based cognitive aid application to support in-hospital resuscitation team leaders. We report a summative evaluation of two different versions of the application. Finally, we outline the limitations of current explanations of how cognitive aids work and suggest an approach based on embodied cognition. We discuss how cognitive aids alter the task of the team leader (distributed cognition), the importance of the present team situation (socially situated), and the result of the interaction between mind and environment (sensorimotor coupling). Understanding and considering the implications of introducing cognitive aids may help to increase acceptance and effectiveness of cognitive aids and eventually improve patient safety.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {simulation, cognitive aid, embodied cognition, cardiac arrest, non-technical performance, cardiopulmonary resuscitation},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300745,
author = {Nissen, Bettina and Neumann, Victoria and Mikusz, Mateusz and Gianni, Rory and Clinch, Sarah and Speed, Chris and Davies, Nigel},
title = {Should I Agree? Delegating Consent Decisions Beyond the Individual},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300745},
doi = {10.1145/3290605.3300745},
abstract = {Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing -- focusing on when and to whom users would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {consent, delegation, design, privacy, permission management, technology probe},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300684,
author = {Schmitz, Martin and Stitz, Martin and M\"{u}ller, Florian and Funk, Markus and M\"{u}hlh\"{a}user, Max},
title = {../Trilaterate: A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300684},
doi = {10.1145/3290605.3300684},
abstract = {Hover, touch, and force are promising input modalities that get increasingly integrated into screens and everyday objects. However, these interactions are often limited to flat surfaces and the integration of suitable sensors is time-consuming and costly. To alleviate these limitations, we contribute Trilaterate: A fabrication pipeline to 3D print custom objects that detect the 3D position of a finger hovering, touching, or forcing them by combining multiple capacitance measurements via capacitive trilateration. Trilaterate places and routes actively-shielded sensors inside the object and operates on consumer-level 3D printers. We present technical evaluations and example applications that validate and demonstrate the wide applicability of Trilaterate.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {touch, capacitive sensing, hover, 3d printing, force},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300558,
author = {Lee, Bokyung and Wu, Sindy and Reyes, Maria Jose and Saakes, Daniel},
title = {The Effects of Interruption Timings on Autonomous Height-Adjustable Desks That Respond to Task Changes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300558},
doi = {10.1145/3290605.3300558},
abstract = {Actuated furniture, such as electric adjustable sit-stand desks, helps users vary their posture and contributes to comfort and health. However, studies found that users rarely initiate height changes. Therefore, in this paper, we look into furniture that adjusts itself to the user's needs. A situated interview study indicated task-changing as an opportune moment for automatic height adjustment. We then performed a Wizard of Oz study to find the best timing for changing desk height to minimize interruption and discomfort. The results are in line with prior work on task interruption in graphical user interfaces and show that the table should change height during a task change. However, results also indicate that until users build trust in the system, they prefer actuation after a task change to experience the impact of the adjustment. Based on the results, we discuss design guidelines for interactive desks with agency.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {tasks/interruptions/notification, robot, workplaces, user experience design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300841,
author = {Feng, Yuanyuan and Li, Katie and Semsar, Azin and McGowan, Hannah and Mun, Jacqueline and Zahiri, H. Reza and George, Ivan and Park, Adrian and Kleinsmith, Andrea and Mentis, Helena M.},
title = {Communication Cost of Single-User Gesturing Tool in Laparoscopic Surgical Training},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300841},
doi = {10.1145/3290605.3300841},
abstract = {Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {team communication, surgical training, shared display, instructional collaborative tasks, communication content, common ground, turn-taking},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300811,
author = {Tennent, Paul and Marshall, Joe and Brundell, Patrick and Walker, Brendan and Benford, Steve},
title = {Abstract Machines: Overlaying Virtual Worlds on Physical Rides},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300811},
doi = {10.1145/3290605.3300811},
abstract = {Overlaying virtual worlds onto existing physical rides and altering the sensations of motion can deliver new experiences of thrill, but designing how motion is mapped between physical ride and virtual world is challenging. In this paper, we present the notion of an abstract machine, a new form of intermediate design knowledge that communicates motion mappings at the level of metaphor, mechanism and implementation. Following a performance-led, in-the-wild approach we report lessons from creating and touring VR Playground, a ride that overlays four distinct abstract machines and virtual worlds on a playground swing. We compare the artist's rationale with riders' reported experiences and analysis of their physical behaviours to reveal the distinct thrills of each abstract machine. Finally, we discuss how to make and use abstract machines in terms of heuristics for designing motion mappings, principles for virtual world design and communicating experiences to riders.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual kinaesthetic experiences, thrill, design knowledge, virtual reality, abstract machines, rides},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300328,
author = {Peng, Zhenhui and Kwon, Yunhwan and Lu, Jiaan and Wu, Ziming and Ma, Xiaojuan},
title = {Design and Evaluation of Service Robot's Proactivity in Decision-Making Support Process},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300328},
doi = {10.1145/3290605.3300328},
abstract = {As service robots are envisioned to provide decision-making support (DMS) in public places, it is becoming essential to design the robot's manner of offering assistance. For example, robot shop assistants that proactively or reactively give product recommendations may impact customers' shopping experience. In this paper, we propose an anticipation-autonomy policy framework that models three levels of proactivity (high, medium and low) of service robots in DMS contexts. We conduct a within-subject experiment with 36 participants to evaluate the effects of DMS robot's proactivity on user perceptions and interaction behaviors. Results show that a highly proactive robot is deemed inappropriate though people can get rich information from it. A robot with medium proactivity helps reduce the decision space while maintaining users' sense of engagement. The least proactive robot grants users more control but may not realize its full capability. We conclude the paper with design considerations for service robot's manner.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-robot interaction, decision-making support, proactivity, robot manner},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300394,
author = {Ofer, Netta and David, Idan and Erel, Hadas and Zuckerman, Oren},
title = {Coding for Outdoor Play: A Coding Platform for Children to Invent and Enhance Outdoor Play Experiences},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300394},
doi = {10.1145/3290605.3300394},
abstract = {Outdoor play is in decline, including its benefits to children's development. Coding, a typically indoor, screen-based activity, can potentially enrich outdoor play, serving as a rule-making medium. We present a coding platform that controls a programmable hardware device, enabling children to technologically-enhance their outdoor play experiences by inventing game ideas, coding them, and playing their games together with their friends. In the evaluation study, 24 children used the system to invent and play outdoor games. Results show children are able to bridge between the different domains of coding and outdoor play. They used the system to modify traditional games and invent new ones, enriching their outdoor experience. Children merged computational concepts with physical game elements, integrated physical outdoor properties as variables in their code, and were excited to see their code come to life. We conclude children can use coding to express their ideas by creating technologically-enhanced outdoor play experiences.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {programming, outdoor play, games/play, children},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300852,
author = {Saquib, Nazmus and Kazi, Rubaiat Habib and Wei, Li-Yi and Li, Wilmot},
title = {Interactive Body-Driven Graphics for Augmented Video Performance},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300852},
doi = {10.1145/3290605.3300852},
abstract = {We present a system that augments live presentation videos with interactive graphics to create a powerful and expressive storytelling environment. Using our system, the presenter interacts with the graphical elements in real-time with gestures and postures, thus leveraging our innate, everyday skills to enhance our communication capabilities with the audience. However, crafting such an interactive and expressive performance typically requires programming, or highly-specialized tools tailored for experts. Our core contribution is a flexible, direct manipulation UI which enables amateurs and experts to craft such presentations beforehand by mapping a variety of body movements to a wide range of graphical manipulations. By simplifying the mapping between gestures, postures, and their corresponding output effects, our UI enables users to craft customized, rich interactions with the graphical elements. Our user study demonstrates the potential usage and unique affordance of this mixed-reality medium for storytelling and presentation across a range of application domains.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mixed/augmented reality, user interface design, gestural input},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300617,
author = {Pschetz, Larissa and Pothong, Kruakae and Speed, Chris},
title = {Autonomous Distributed Energy Systems: Problematising the Invisible through Design, Drama and Deliberation},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300617},
doi = {10.1145/3290605.3300617},
abstract = {Technologies such as blockchains, smart contracts and programmable batteries facilitate emerging models of energy distribution, trade and consumption, and generate a considerable number of opportunities for energy markets. However, these developments complicate relationships between stakeholders, disrupting traditional notions of value, control and ownership. Discussing these issues with the public is particularly challenging as energy consumption habits often obscure the competing values and interests that shape stakeholders' relationships. To make such difficult discussions more approachable and examine the missing relational aspect of autonomous energy systems, we combined the design of speculative hairdryers with performance and deliberation. This integrated method of inquiry makes visible the competing values and interests, eliciting people's wishes to negotiate these terms. We argue that the complexity of mediated energy distribution and its convoluted stakeholder relationships requires more sophisticated methods of inquiry to engage people in debates concerning distributed energy systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {distributed energy, speculative design, performance, deliberation, theatre, critical design, improvisation, blockchain},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300385,
author = {Thinyane, Hannah and Bhat, Karthik S.},
title = {Apprise: Supporting the Critical-Agency of Victims of Human Trafficking in Thailand},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300385},
doi = {10.1145/3290605.3300385},
abstract = {Human trafficking and forced labor are global issues affecting millions of people around the world. This paper describes an initiative that we are currently undertaking to understand the role technology can play to support the critical-agency of migrant workers in these situations of severe exploitation. Building on five consultations with more than 170 direct and indirect stakeholders in Thailand, the paper presents the co-design, development, and evaluation of Apprise, a mobile app to support the identification of victims of human trafficking using a Value Sensitive Design approach. It also provides a critical reflection on the use of digital technology in the initial screening of potential victims of human trafficking, to understand in what ways Apprise can support the critical agency of migrant workers in vulnerable situations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {forced labor, critical-agency, human trafficking, value sensitive design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300292,
author = {Saha, Manaswi and Saugstad, Michael and Maddali, Hanuma Teja and Zeng, Aileen and Holland, Ryan and Bower, Steven and Dash, Aditya and Chen, Sage and Li, Anthony and Hara, Kotaro and Froehlich, Jon},
title = {Project Sidewalk: A Web-Based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data At Scale},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300292},
doi = {10.1145/3290605.3300292},
abstract = {We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mobility impairments, gis, urban informatics, crowdsourcing, accessibility},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300595,
author = {Yamada, Wataru and Manabe, Hiroyuki and Ikeda, Daizo},
title = {ZeRONE: Safety Drone with Blade-Free Propulsion},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300595},
doi = {10.1145/3290605.3300595},
abstract = {We present ZeRONE, a new indoor drone that does not use rotating blades for propulsion. The proposed device is a helium blimp type drone that uses the wind generated by the ultrasonic vibration of piezo elements for propulsion. Compared to normal drones with rotating propellers, the drone is much safer because its only moving parts are the piezo elements whose surfaces vibrate at the order of micrometers. The drone can float for a few weeks and the ultrasonic propulsion system is quiet. We implement a prototype of the drone and evaluate its performance and unique characteristics in experiments. Moreover, application scenarios in which ZeRONE coexists with people are also discussed.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {drone, microblower, blade-free},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300667,
author = {Bartindale, Tom and Varghese, Delvin and Schofield, Guy and Tsukamoto, Miki},
title = {Our Story: Addressing Challenges in Development Contexts for Sustainable Participatory Video},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300667},
doi = {10.1145/3290605.3300667},
abstract = {Participatory Video (PV) is emerging as a rich and valuable method for monitoring and evaluating (M &amp; E) projects in the International Development sector. Although shown to be useful for engaging communities within short-term monitoring exercises or promotion, PV in these contexts presents significant complexity and logistical challenges for sustained uptake by Development organizations. In this paper, we present Our Story, a digitally mediated work flow iteratively designed and deployed on initiatives in Indonesia and Namibia. Developed in collaboration with the International Federation of Red Cross and Red Crescent (IFRC), it supports end-to-end PV production in the field, and was specifically developed to make PV a more sustainable tool for monitoring. We discuss and evaluate Our Story, reporting on how by lowering skills barriers for facilitators and leveraging consumer technology, PV can be delivered at scale.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mobile, ictd, participatory video, editing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300737,
author = {Voit, Alexandra and Mayer, Sven and Schwind, Valentin and Henze, Niels},
title = {Online, VR, AR, Lab, and In-Situ: Comparison of Research Methods to Evaluate Smart Artifacts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300737},
doi = {10.1145/3290605.3300737},
abstract = {Empirical studies are a cornerstone of HCI research. Technical progress constantly enables new study methods. Online surveys, for example, make it possible to collect feedback from remote users. Progress in augmented and virtual reality enables to collect feedback with early designs. In-situ studies enable researchers to gather feedback in natural environments. While these methods have unique advantages and disadvantages, it is unclear if and how using a specific method affects the results. Therefore, we conducted a study with 60 participants comparing five different methods (online, virtual reality, augmented reality, lab setup, and in-situ) to evaluate early prototypes of smart artifacts. We asked participants to assess four different smart artifacts using standardized questionnaires. We show that the method significantly affects the study result and discuss implications for HCI research. Finally, we highlight further directions to overcome the effect of the used methods.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user studies, surveys, prototype evaluation, empirical methods, smart artifacts},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300500,
author = {Head, Andrew and Hohman, Fred and Barik, Titus and Drucker, Steven M. and DeLine, Robert},
title = {Managing Messes in Computational Notebooks},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300500},
doi = {10.1145/3290605.3300500},
abstract = {Data analysts use computational notebooks to write code for analyzing and visualizing data. Notebooks help analysts iteratively write analysis code by letting them interleave code with output, and selectively execute cells. However, as analysis progresses, analysts leave behind old code and outputs, and overwrite important code, producing cluttered and inconsistent notebooks. This paper introduces code gathering tools, extensions to computational notebooks that help analysts find, clean, recover, and compare versions of code in cluttered, inconsistent notebooks. The tools archive all versions of code outputs, allowing analysts to review these versions and recover the subsets of code that produced them. These subsets can serve as succinct summaries of analysis activity or starting points for new analyses. In a qualitative usability study, 12 professional analysts found the tools useful for cleaning notebooks and writing analysis code, and discovered new ways to use them, like generating personal documentation and lightweight versioning.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {code history, exploratory programming, inconsistency, program slicing, messes, clutter, computational notebooks},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300316,
author = {Kim, Soomin and Lee, Joonhwan and Gweon, Gahgene},
title = {Comparing Data from Chatbot and Web Surveys: Effects of Platform and Conversational Style on Survey Response Quality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300316},
doi = {10.1145/3290605.3300316},
abstract = {This study aims to explore the feasibility of a text-based virtual agent as a new survey method to overcome the web survey's common response quality problems, which are caused by respondents' inattention. To this end, we conducted a 2 (platform: web vs. chatbot) \texttimes{} 2 (conversational style: formal vs. casual) experiment. We used satisficing theory to compare the responses' data quality. We found that the participants in the chatbot survey, as compared to those in the web survey, were more likely to produce differentiated responses and were less likely to satisfice; the chatbot survey thus resulted in higher-quality data. Moreover, when a casual conversational style is used, the participants were less likely to satisfice-although such effects were only found in the chatbot condition. These results imply that conversational interactivity occurs when a chat interface is accompanied by messages with effective tone. Based on an analysis of the qualitative responses, we also showed that a chatbot could perform part of a human interviewer's role by applying effective communication strategies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {conversational interface, user experience design, human ai interaction, chatbot, survey interface, conversational agent},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300782,
author = {Brackenbury, Will and Deora, Abhimanyu and Ritchey, Jillian and Vallee, Jason and He, Weijia and Wang, Guan and Littman, Michael L. and Ur, Blase},
title = {How Users Interpret Bugs in Trigger-Action Programming},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300782},
doi = {10.1145/3290605.3300782},
abstract = {Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them. We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {end-user programming, ifttt, internet of things, iot, trigger-action programming, bugs, debugging},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300346,
author = {Andrade, Ronny and Rogerson, Melissa J. and Waycott, Jenny and Baker, Steven and Vetere, Frank},
title = {Playing Blind: Revealing the World of Gamers with Visual Impairment},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300346},
doi = {10.1145/3290605.3300346},
abstract = {Previous research on games for people with visual impairment (PVI) has focused on co-designing or evaluating specific games - mostly under controlled conditions. In this research, we follow a game-agnostic, "in-the-wild" approach, investigating the habits, opinions and concerns of PVI regarding digital games. To explore these issues, we conducted an online survey and follow-up interviews with gamers with VI (GVI). Dominant themes from our analysis include the particular appeal of digital games to GVI, the importance of social trajectories and histories of gameplay, the need to balance complexity and accessibility in both games targeted to PVI and mainstream games, opinions about the state of the gaming industry, and accessibility concerns around new and emerging technologies such as VR and AR. Our study gives voice to an underrepresented group in the gaming community. Understanding the practices, experiences and motivations of GVI provides a valuable foundation for informing development of more inclusive games.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {digital games, audiogames, visual impairment, empowerment},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300418,
author = {Correll, Michael},
title = {Ethical Dimensions of Visualization Research},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300418},
doi = {10.1145/3290605.3300418},
abstract = {Visualizations have a potentially enormous influence on how data are used to make decisions across all areas of human endeavor. However, it is not clear how this power connects to ethical duties: what obligations do we have when it comes to visualizations and visual analytics systems, beyond our duties as scientists and engineers? Drawing on historical and contemporary examples, I address the moral components of the design and use of visualizations, identify some ongoing areas of visualization research with ethical dilemmas, and propose a set of additional moral obligations that we have as designers, builders, and researchers of visualizations.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {information visualization, visual analytics, ethics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300664,
author = {Reuter, Arlind and Bartindale, Tom and Morrissey, Kellie and Scharf, Thomas and Liddle, Jennifer},
title = {Older Voices: Supporting Community Radio Production for Civic Participation in Later Life},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300664},
doi = {10.1145/3290605.3300664},
abstract = {Community radio can support the process of having a voice in one's community as a part of civic action, and promote community dialogue. However, older adults are underrepresented as producers of community radio shows in the UK, and face different challenges to their younger colleagues. By working within the radio production group of an existing organisation of older adults, we identify the motivations and challenges in supporting this type of civic participation in media in later life. Key challenges were identified, including audience engagement, content persistence and process sustainability. In response, we 1) supported the group's audience engagement using Facebook Live and a phone-in option, and 2) developed a digital production tool. Reporting on the continued use of the tool by the organisation, we discuss how tailored and non-intrusive processes mediated by digital technology can support older adults in delivering richer media experiences whilst serving their civic participatory interests.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ageing, civic participation, community radio, digital civics},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300296,
author = {Wauck, Helen C. and Mekler, Elisa D. and Fu, Wai-Tat},
title = {A Player-Centric Approach to Designing Spatial Skill Training Games},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300296},
doi = {10.1145/3290605.3300296},
abstract = {Certain video games show promise as tools for training spatial skills, one of the strongest predictors of future success in STEM. However, little is known about the gaming preferences of those who would benefit the most from such interventions: low spatial skill students. To provide guidance on how to design training games for this population, we conducted a survey of 350 participants from three populations: online college-age, students from a low SES high school, and students from a high SES high school. Participants took a timed test of spatial skills and then answered questions about their demographics, gameplay habits, preferences, and motivations. The only predictors of spatial skill were gender and population: female participants from online and low SES high school populations had the lowest spatial skill. In light of these findings, we provide design recommendations for game-based spatial skill interventions targeting low spatial skill students.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cognitive training, motivation, emotions, spatial reasoning, gender, video games},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300311,
author = {Huber, Bernd and Shin, Hijung Valentina and Russell, Bryan and Wang, Oliver and Mysore, Gautham J.},
title = {B-Script: Transcript-Based B-Roll Video Editing with Recommendations},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300311},
doi = {10.1145/3290605.3300311},
abstract = {In video production, inserting B-roll is a widely used technique to enrich the story and make a video more engaging. However, determining the right content and positions of B-roll and actually inserting it within the main footage can be challenging, and novice producers often struggle to get both timing and content right. We present B-Script, a system that supports B-roll video editing via interactive transcripts. B-Script has a built-in recommendation system trained on expert-annotated data, recommending users B-roll position and content. To evaluate the system, we conducted a within-subject user study with 110 participants, and compared three interface variations: a timeline-based editor, a transcript-based editor, and a transcript-based editor with recommendations. Users found it easier and were faster to insert B-roll using the transcript-based interface, and they created more engaging videos when recommendations were provided.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {machine learning, video editing, video blogging},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300758,
author = {Tanner, Kesler and Johnson, Naomi and Landay, James A.},
title = {Poirot: A Web Inspector for Designers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300758},
doi = {10.1145/3290605.3300758},
abstract = {To better understand the issues designers face as they interact with developers and use developer tools to create websites, we conducted a formative investigation consisting of interviews, a survey, and an analysis of professional design documents. Based on insights gained from these efforts, we developed Poirot, a web inspection tool for designers that enables them to make style edits to websites using a familiar graphical interface. We compared Poirot to Chrome DevTools in a lab study with 16 design professionals. We observed common problems designers experience when using Chrome DevTools and found that when using Poirot, designers were more successful in accomplishing typical design tasks (97% to 63%). In addition, we found that Poirot had a significantly lower perceived cognitive load and was overwhelmingly preferred by the designers in our study.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {designer web tools, inspector tools, web development},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300829,
author = {Singh, Aneesha and Gibbs, Jo and Blandford, Ann},
title = {Emotion and Experience in Negotiating HIV-Related Digital Resources: "It's Not Just a Runny Nose!"},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300829},
doi = {10.1145/3290605.3300829},
abstract = {While digital technologies are increasingly being used to provide support and diagnoses remotely, it is unclear whether they offer adequate emotional support and appropriate messages in navigating complex, stigmatised and sensitive conditions that can have a momentous impact on people's lives. In this paper, we investigate how and why people access existing HIV resources, and their experiences of using these resources through a survey with 197 respondents and an interview and think-aloud study with 28 participants. Our findings indicate that many HIV-related resources do not address the anxiety-provoking reasons for access, reinforce stigma and neglect to provide important information and emotional support. We finally discuss potential ways of addressing these issues in the current environment where more sexual health services are being delivered online.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {hiv, sensemaking, emotion, emotional support, health management, information interaction, remote testing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300919,
author = {Quinn, Philip},
title = {Estimating Touch Force with Barometric Pressure Sensors},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300919},
doi = {10.1145/3290605.3300919},
abstract = {Finger pressure offers a new dimension for touch interaction, where input is defined by its spatial position and orthogonal force. However, the limited availability and complexity of integrated force-sensing hardware in mobile devices is a barrier to exploring this design space. This paper presents a synthesis of two features in recent mobile devices - a barometric sensor (pressure altimeter) and ingress protection - to sense a user's touch force. When a user applies force to a device's display, it flexes inward and causes an increase in atmospheric pressure within the sealed chassis. This increase in pressure can be sensed by the device's internal barometer. However, this change is uncontrolled and requires a calibration model to map atmospheric pressure to touch force. This paper derives such a model and demonstrates its viability on four commercially-available devices (including two with dedicated force sensors). The results show this method is sensitive to forces of less than 1 N, and is comparable to dedicated force sensors.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {touchscreen interaction, sensor fusion, touch pressure},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300322,
author = {Kery, Mary Beth and John, Bonnie E. and O'Flaherty, Patrick and Horvath, Amber and Myers, Brad A.},
title = {Towards Effective Foraging by Data Scientists to Find Past Analysis Choices},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300322},
doi = {10.1145/3290605.3300322},
abstract = {Data scientists are responsible for the analysis decisions they make, but it is hard for them to track the process by which they achieved a result. Even when data scientists keep logs, it is onerous to make sense of the resulting large number of history records full of overlapping variants of code, output, plots, etc. We developed algorithmic and visualization techniques for notebook code environments to help data scientists forage for information in their history. To test these interventions, we conducted a think-aloud evaluation with 15 data scientists, where participants were asked to find specific information from the history of another person's data science project. The participants succeed on a median of 80% of the tasks they performed. The quantitative results suggest promising aspects of our design, while qualitative results motivated a number of design improvements. The resulting system, called Verdant, is released as an open-source extension for JupyterLab.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {data science, exploratory programming, literate programming, end-user programmers (eup), end-user software engineering (euse)},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300644,
author = {Rogers, Katja and Funke, Jana and Frommel, Julian and Stamm, Sven and Weber, Michael},
title = {Exploring Interaction Fidelity in Virtual Reality: Object Manipulation and Whole-Body Movements},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300644},
doi = {10.1145/3290605.3300644},
abstract = {High degrees of interaction fidelity (IF) in virtual reality (VR) are said to improve user experience and immersion, but there is also evidence of low IF providing comparable experiences. VR games are now increasingly prevalent, yet we still do not fully understand the trade-off between realism and abstraction in this context. We conducted a lab study comparing high and low IF for object manipulation tasks in a VR game. In a second study, we investigated players' experiences of IF for whole-body movements in a VR game that allowed players to crawl underneath virtual boulders and "dangle'' along monkey bars. Our findings show that high IF is preferred for object manipulation, but for whole-body movements, moderate IF can suffice, as there is a trade-off with usability and social factors. We provide guidelines for the development of VR games based on our results.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual objects, player experience, interaction fidelity, games, whole body interaction, virtual reality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300717,
author = {Kunkel, Johannes and Donkers, Tim and Michael, Lisa and Barbu, Catalin-Mihai and Ziegler, J\"{u}rgen},
title = {Let Me Explain: Impact of Personal and Impersonal Explanations on Trust in Recommender Systems},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300717},
doi = {10.1145/3290605.3300717},
abstract = {Trust in a Recommender System (RS) is crucial for its overall success. However, it remains underexplored whether users trust personal recommendation sources (i.e. other humans) more than impersonal sources (i.e. conventional RS), and, if they do, whether the perceived quality of explanation provided account for the difference. We conducted an empirical study in which we compared these two sources of recommendations and explanations. Human advisors were asked to explain movies they recommended in short texts while the RS created explanations based on item similarity. Our experiment comprised two rounds of recommending. Over both rounds the quality of explanations provided by users was assessed higher than the quality of the system's explanations. Moreover, explanation quality significantly influenced perceived recommendation quality as well as trust in the recommendation source. Consequently, we suggest that RS should provide richer explanations in order to increase their perceived recommendation quality and trustworthiness.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user study, trust, explanations, structural equation modelling, recommender systems, counterfactual analysis},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300878,
author = {Prabhakar, Annu Sible and Stolterman, Erik and \v{S}abanovi\'{c}, Selma},
title = {Understanding Life Transitions: A Case Study of Support Needs of Low-Income Mothers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300878},
doi = {10.1145/3290605.3300878},
abstract = {Life transitions are an integral part of the human experience. However, research shows that lack of support during life transitions can result in adverse health outcomes. To better understand the support needs and structures of low-income women during transition to motherhood, we interviewed 10 women and their 14 supporters during the transition. Our findings suggest that support needs and structures of mothers evolve during transition, and that they also vary by socio-economic contexts. In this paper, we detail our study design and findings. Informed by our findings, we posit that all life-transitions are not the same, and that therefore, the optimal support intervention point varies for different life transitions. Currently there are no tools available to identify optimal support intervention points during life transitions. To this end, we also introduce a preliminary framework - the Strength-Stress-Analysis (SSA) framework - to identify optimal support intervention points during life-transitions.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {optimal intervention point, motherhood, support interventions, maternal health, life transitions, strength-stress analysis framework, ssa framework},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300593,
author = {Wallner, G\"{u}nter and Halabi, Nour and Mirza-Babaei, Pejman},
title = {Aggregated Visualization of Playtesting Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300593},
doi = {10.1145/3290605.3300593},
abstract = {Playtesting is a key component in the game development process aimed at improving the quality of games through the collection of gameplay data and identification of design issues. Visualization techniques are currently being employed to help integrate quantitative and qualitative data. Despite that, two existing challenges are to determine the level of detail to be presented to developers based on their needs and to effectively communicate the collected data so that informed design changes can be reached. In this paper, we first propose an aggregated visualization technique that makes use of clustering, territory tessellation, and trajectory aggregation to simultaneously display mixed playtesting data. Secondly, to assess the usefulness of our technique we evaluate it through interviews with professional game developers and compare it to a non-aggregated visualization. The results of this study also provide an important contribution towards identifying areas of improvement in the portrayal of gameplay data.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mixed-methods, games user research, data visualization, visual game analytics, physiological measurements},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300517,
author = {Heitlinger, Sara and Bryan-Kinns, Nick and Comber, Rob},
title = {The Right to the Sustainable Smart City},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300517},
doi = {10.1145/3290605.3300517},
abstract = {Environmental concerns have driven an interest in sustainable smart cities, through the monitoring and optimisation of networked infrastructures. At the same time, there are concerns about who these interventions and services are for, and who benefits. HCI researchers and designers interested in civic life have started to call for the democratisation of urban space through resistance and political action to challenge state and corporate claims. This paper contributes to an emerging body of work that seeks to involve citizens in the design of sustainable smart cities, particularly in the context of marginalised and culturally diverse urban communities. We present a study involving co-designing Internet of Things with urban agricultural communities and discuss three ways in which design can participate in the right to the sustainable smart city through designing for the commons, care, and biocultural diversity.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart cities, right to the city, urban agriculture, internet of things, sustainable hci, hybrid cities, anthropocene, spatial autogestion, civic iot},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300832,
author = {Balaam, Madeline and Comber, Rob and Clarke, Rachel E. and Windlin, Charles and St\r{a}hl, Anna and H\"{o}\"{o}k, Kristina and Fitzpatrick, Geraldine},
title = {Emotion Work in Experience-Centered Design},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300832},
doi = {10.1145/3290605.3300832},
abstract = {Experience Centered Design (ECD) implores us to develop empathic relationships and understanding of participants, to actively work with our senses and emotions within the design process. However, theories of experience-centered design do little to account for emotion work undertaken by design researchers when doing this. As a consequence, how a design researcher's emotions are experienced, navigated and used as part of an ECD process are rarely published. So, while emotion is clearly a tool that we use, we don't share with one another how, why and when it gets used. This has a limiting effect on how we understand design processes, and opportunities for training. Here, we share some of our experiences of working with ECD. We analyse these using Hochschild's framework of emotion work to show how and where this work occurs. We use our analysis to question current ECD practices and provoke debate.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {emotion work, design research, experience-centered design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300579,
author = {Nicholson, James and Coventry, Lynne and Briggs, Pamela},
title = {"If It's Important It Will Be A Headline": Cybersecurity Information Seeking in Older Adults},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300579},
doi = {10.1145/3290605.3300579},
abstract = {Older adults are increasingly vulnerable to cybersecurity attacks and scams. Yet we know relatively little about their understanding of cybersecurity, their information-seeking behaviours, and their trusted sources of information and advice in this domain. We conducted 22 semi-structured interviews with community-dwelling older adults in order to explore their cybersecurity information seeking behaviours. Following a thematic analysis of these interviews, we developed a cybersecurity information access framework that highlights shortcomings in older adults' choice of information resources. Specifically, we find that older users prioritise social resources based on availability, rather than cybersecurity expertise, and that they avoid using the Internet for cybersecurity information searches despite using it for other domains. Finally, we discuss the design of cybersecurity information dissemination strategies for older users, incorporating favoured sources such as TV adverts and radio programming.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {information seeking, older adults, social aspects of security, cybersecurity, digital literacy},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

