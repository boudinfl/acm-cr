@inproceedings{10.1145/3250461,
author = {Lau, Tessa},
title = {Session Details: AI &amp; Machine-Learning &amp; Translation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250461},
doi = {10.1145/3250461},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207678,
author = {Kulesza, Todd and Stumpf, Simone and Burnett, Margaret and Kwan, Irwin},
title = {Tell Me More? The Effects of Mental Model Soundness on Personalizing an Intelligent Agent},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207678},
doi = {10.1145/2207676.2207678},
abstract = {What does a user need to know to productively work with an intelligent agent? Intelligent agents and recommender systems are gaining widespread use, potentially creating a need for end users to understand how these systems operate in order to fix their agent's personalized behavior. This paper explores the effects of mental model soundness on such personalization by providing structural knowledge of a music recommender system in an empirical study. Our findings show that participants were able to quickly build sound mental models of the recommender system's reasoning, and that participants who most improved their mental models during the study were significantly more likely to make the recommender operate to their satisfaction. These results suggest that by helping end users understand a system's reasoning, intelligent agents may elicit more and better feedback, thus more closely aligning their output with each user's intentions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {music, debugging, recommenders, intelligent agents, personalization, mental models},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207679,
author = {Szafir, Daniel and Mutlu, Bilge},
title = {Pay Attention! Designing Adaptive Agents That Monitor and Improve User Engagement},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207679},
doi = {10.1145/2207676.2207679},
abstract = {Embodied agents hold great promise as educational assistants, exercise coaches, and team members in collaborative work. These roles require agents to closely monitor the behavioral, emotional, and mental states of their users and provide appropriate, effective responses. Educational agents, for example, will have to monitor student attention and seek to improve it when student engagement decreases. In this paper, we draw on techniques from brain-computer interfaces (BCI) and knowledge from educational psychology to design adaptive agents that monitor student attention in real time using measurements from electroencephalography (EEG) and recapture diminishing attention levels using verbal and nonverbal cues. An experimental evaluation of our approach showed that an adaptive robotic agent employing behavioral techniques to regain attention during drops in engagement improved student recall abilities 43% over the baseline regardless of student gender and significantly improved female motivation and rapport. Our findings offer guidelines for developing effective adaptive agents, particularly for educational settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {adaptive agents, passive brain-computer interfaces (bci), educational agents, human-robot interaction, electroencephalography (eeg), immediacy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207680,
author = {Amershi, Saleema and Fogarty, James and Weld, Daniel},
title = {Regroup: Interactive Machine Learning for on-Demand Group Creation in Social Networks},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207680},
doi = {10.1145/2207676.2207680},
abstract = {We present ReGroup, a novel end-user interactive machine learning system for helping people create custom, on demand groups in online social networks. As a person adds members to a group, ReGroup iteratively learns a probabilistic model of group membership specific to that group. ReGroup then uses its currently learned model to suggest additional members and group characteristics for filtering. Our evaluation shows that ReGroup is effective for helping people create large and varied groups, whereas traditional methods (searching by name or selecting from an alphabetical list) are better suited for small groups whose members can be easily recalled by name. By facilitating on demand group creation, ReGroup can enable in-context sharing and potentially encourage better online privacy practices. In addition, applying interactive machine learning to social network group creation introduces several challenges for designing effective end-user interaction with machine learning. We identify these challenges and discuss how we address them in ReGroup.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {21–30},
numpages = {10},
keywords = {example and feature-based interaction, interactive machine learning, social network access control},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207681,
author = {Leiva, Luis and Alabau, Vicent},
title = {Monsieur, Azonnal K\"{o}Vessen Engem Bitte! An Automatically Generated Interlanguage Tailored to Speakers of Minority but Culturally Influenced Languages},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207681},
doi = {10.1145/2207676.2207681},
abstract = {Automatic localization of cultural resources and UIs is crucial for the survival of minority languages, for which there are insufficient parallel corpora (or no corpus at all) to build machine translation systems. This paper proposes a new way to compensate for such resource-scarce languages, based on the fact that most languages share a common vocabulary. Concretely, our approach leverages a family of languages closely related to the speaker's native language to construct translations in a coherent mix of these languages. Experimental results indicate that these translations can be easily understood, being also a useful aid for users who are not proficient in foreign languages. Therefore this work significantly contributes to HCI in two ways: it establishes a language that can improve how applications communicate to their users, and it reports insights on the user acceptance towards the method.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {31–34},
numpages = {4},
keywords = {machine translation, localization, interlingua, cityspeak},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207682,
author = {Fourney, Adam and Lafreniere, Ben and Mann, Richard and Terry, Michael},
title = {"Then Click Ok!": Extracting References to Interface Elements in Online Documentation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207682},
doi = {10.1145/2207676.2207682},
abstract = {This paper presents a recognizer for identifying references to user interface components in online documentation. The recognizer first extracts phrases matching a list of known components, then employs a classifier to reject coincidental matches. We describe why this seemingly straightforward problem is challenging, then show how informal conventions in documentation writing can be leveraged to perform classification. Using the features identified in this paper, our approach achieves an average F1 score of 0.81, and can correctly distinguish between actual command references and coincidental matches in 93.7% of test cases.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {35–38},
numpages = {4},
keywords = {named entity recognition, online documentation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250462,
author = {Takayama, Leila},
title = {Session Details: Teaching with New Interfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250462},
doi = {10.1145/3250462},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207684,
author = {Ogan, Amy and Finkelstein, Samantha and Mayfield, Elijah and D'Adamo, Claudia and Matsuda, Noboru and Cassell, Justine},
title = {"Oh Dear Stacy!": Social Interaction, Elaboration, and Learning with Teachable Agents},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207684},
doi = {10.1145/2207676.2207684},
abstract = {Understanding how children perceive and interact with teachable agents (systems where children learn through teaching a synthetic character embedded in an intelligent tutoring system) can provide insight into the effects of so-cial interaction on learning with intelligent tutoring systems. We describe results from a think-aloud study where children were instructed to narrate their experience teaching Stacy, an agent who can learn to solve linear equations with the student's help. We found treating her as a partner, primarily through aligning oneself with Stacy using pronouns like you or we rather than she or it significantly correlates with student learning, as do playful face-threatening comments such as teasing, while elaborate explanations of Stacy's behavior in the third-person and formal tutoring statements reduce learning gains. Additionally, we found that the agent's mistakes were a significant predictor for students shifting away from alignment with the agent.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {39–48},
numpages = {10},
keywords = {rapport, eca, teachable agents, impoliteness, peer tutoring},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207685,
author = {Kreitmayer, Stefan and Rogers, Yvonne and Laney, Robin and Peake, Stephen},
title = {From Participatory to Contributory Simulations: Changing the Game in the Classroom},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207685},
doi = {10.1145/2207676.2207685},
abstract = {There is much potential for supporting collaborative learning with interactive computer simulations in formal education and professional training. A number have been developed for single user and remote interaction. In contrast, our research is concerned with how such learning activities can be designed to fit into co-located large group settings, such as whole classrooms. This paper reports on the iterative design process and two in-the-wild evaluations of the 4Decades game, which was developed for a whole classroom of students to engage with a climate simulation. The system allows students to play and change the rules of the simulation, thereby enabling them to be actively engaged at different levels. The notion of Contributory Simulations is proposed as an instructional model that empowers groups to make informed, critical changes to the underlying scientific model. We discuss how large-group collaboration was supported through constraining an ecology of shared devices and public displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {49–58},
numpages = {10},
keywords = {participatory simulations, contributory simulations, tablets, serious games, collaborative learning, ambient displays, ubiquitous technologies},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250463,
author = {Isbister, Katherine},
title = {Session Details: Game Experiences},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250463},
doi = {10.1145/3250463},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207687,
author = {Andersen, Erik and O'Rourke, Eleanor and Liu, Yun-En and Snider, Rich and Lowdermilk, Jeff and Truong, David and Cooper, Seth and Popovic, Zoran},
title = {The Impact of Tutorials on Games of Varying Complexity},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207687},
doi = {10.1145/2207676.2207687},
abstract = {One of the key challenges of video game design is teaching new players how to play. Although game developers frequently use tutorials to teach game mechanics, little is known about how tutorials affect game learnability and player engagement. Seeking to estimate this value, we implemented eight tutorial designs in three video games of varying complexity and evaluated their effects on player engagement and retention. The results of our multivariate study of over 45,000 players show that the usefulness of tutorials depends greatly on game complexity. Although tutorials increased play time by as much as 29% in the most complex game, they did not significantly improve player engagement in the two simpler games. Our results suggest that investment in tutorials may not be justified for games with mechanics that can be discovered through experimentation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {59–68},
numpages = {10},
keywords = {tutorials, multivariate testing, games, analytics},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207688,
author = {Khaled, Rilla and Ingram, Gordon},
title = {Tales from the Front Lines of a Large-Scale Serious Game Project},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207688},
doi = {10.1145/2207676.2207688},
abstract = {Serious games have received much positive attention; correspondingly, many researchers have taken up the challenge of establishing how to best design them. However, the current literature often focuses on best practice design strategies and frameworks. Fine-grained details, contextual descriptions, and organisational factors that are invaluable in helping us to learn from and reflect on project experiences are often overlooked. In this paper, we present five distinct and sometimes competing perspectives that are critical in understanding factors that influence serious game projects: project organisation, technology, domain knowledge, user research, and game design. We explain these perspectives by providing insights from the design and development process of an EU-funded serious game about conflict resolution developed by an interdisciplinary consortium of researchers and industry-based developers. We also point out a set of underlying forces that become evident from viewing the process from different perspectives, to underscore that problems exist in serious game projects and that we should open the conversation about them.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {69–78},
numpages = {10},
keywords = {serious games, game design, interdisciplinary research, reflective design, learning games},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207689,
author = {Cox, Anna and Cairns, Paul and Shah, Pari and Carroll, Michael},
title = {Not Doing but Thinking: The Role of Challenge in the Gaming Experience},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207689},
doi = {10.1145/2207676.2207689},
abstract = {Previous research into the experience of videogames has shown the importance of the role of challenge in producing a good experience. However, defining exactly which challenges are important and which aspects of gaming experience are affected is largely under-explored. In this paper, we investigate if altering the level of challenge in a videogame influences people's experience of immersion. Our first study demonstrates that simply increasing the physical demands of the game by requiring gamers to interact more with the game does not result in increased immersion. In a further two studies, we use time pressure to make games more physically and cognitively challenging. We find that the addition of time pressure increases immersion as predicted. We argue that the level of challenge experienced is an interaction between the level of expertise of the gamer and the cognitive challenge encompassed within the game.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {79–88},
numpages = {10},
keywords = {immersion, challenge, games},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207690,
author = {Schild, Jonas and LaViola, Joseph and Masuch, Maic},
title = {Understanding User Experience in Stereoscopic 3D Games},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207690},
doi = {10.1145/2207676.2207690},
abstract = {Recent advances in digital game technology are making stereoscopic games more popular. Stereoscopic 3D graphics promise a better gaming experience but this potential has not yet been proven empirically. In this paper, we present a comprehensive study that evaluates player experience of three stereoscopic games in comparison with their monoscopic counterparts. We examined 60 participants, each playing one of the three games, using three self-reporting questionnaires and one psychophysiological instrument. Our main results are (1) stereoscopy in games increased experienced immersion, spatial presence, and simulator sickness; (2) the effects strongly differed across the three games and for both genders, indicating more affect on male users and with games involving depth animations; (3) results related to attention and cognitive involvement indicate more direct and less thoughtful interactions with stereoscopic games, pointing towards a more natural experience through stereoscopy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {89–98},
numpages = {10},
keywords = {stereoscopy, games, play, user experience, presence, genre, s3d, simulator sickness., game experience, immersion},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250464,
author = {Ju, Wendy},
title = {Session Details: Eating + Cooking},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250464},
doi = {10.1145/3250464},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207692,
author = {Parker, Andrea and Kantroo, Vasudhara and Lee, Hee Rin and Osornio, Miguel and Sharma, Mansi and Grinter, Rebecca},
title = {Health Promotion as Activism: Building Community Capacity to Effect Social Change},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207692},
doi = {10.1145/2207676.2207692},
abstract = {As HCI researchers have designed tools to promote wellness, disease has often been approached as a general problem. In contrast, public health research argues for an activist approach focused on how certain groups disproportionately experience disease and eliminating these disparities. Taking this activist stance, we examine how technology can reduce health inequalities by disrupting power relationships and helping communities pursue social change. We discuss our tool, Community Mosaic (CM), which allows individuals to share their healthy eating ideas with one another as a means of advocating behavior change. Our results characterize how CM helped facilitate activism (i.e., collective efforts to counter local challenges to healthy living) and shift users' attitudes regarding their role as advocates for health. We contribute to the field of HCI by using our findings to present a set of recommendations for future research focused on designing and evaluating health promotion tools using an activist lens.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {99–108},
numpages = {10},
keywords = {low-income, wellness, collective action, health, activism},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207693,
author = {Narumi, Takuji and Ban, Yuki and Kajinami, Takashi and Tanikawa, Tomohiro and Hirose, Michitaka},
title = {Augmented Perception of Satiety: Controlling Food Consumption by Changing Apparent Size of Food with Augmented Reality},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207693},
doi = {10.1145/2207676.2207693},
abstract = {The main contribution of this paper is to realize a method for modifying perception of satiety and controlling nutritional intake by changing the apparent size of food with augmented reality. As a possible method for decreasing rates of obesity, we focused on controlling food intake implicitly without any effort.We hypothesized that ambiguous perception of satiety can be applied to control our food intake. Recent psychological studies have revealed that the amount of food consumed is influenced by both its actual volume and external factors during eating. Based on this knowledge, we sought to control perception of satiety gained from the same amount of food by changing its apparent size. We also proposed a method for food-volume augmentation using real-time shape deformation. Our results suggest that this augmentation can control the perception of satiety and food intake.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {109–118},
numpages = {10},
keywords = {augmented reality, cross-modal interaction, human food interaction, perception of satiety},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207694,
author = {Hupfeld, Annika and Rodden, Tom},
title = {Laying the Table for HCI: Uncovering Ecologies of Domestic Food Consumption},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207694},
doi = {10.1145/2207676.2207694},
abstract = {Food contributes fundamentally to our well-being: physically, mentally, and socially. Unsurprisingly then, the importance of food to our lives has long been recognized in the social sciences, and more recently, in Human-Computer Interaction. Yet, despite ongoing trends towards the digital augmentation of domestic environments, little consideration has been given to the impact of the material aspects of food consumption in the home. This paper takes an ecological approach to uncovering the role spaces, tabletops, and artefacts play in the social organization of domestic eating practices. Based on our findings of interviews with seven households in England, we discuss implications for those seeking to digitally augment domestic dining.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {119–128},
numpages = {10},
keywords = {tabletop, food, tableware, ubiquitous computing, augmentation, domestic technology, eating},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207695,
author = {Uriu, Daisuke and Namai, Mizuki and Tokuhisa, Satoru and Kashiwagi, Ryo and Inami, Masahiko and Okude, Naohito},
title = {Panavi: Recipe Medium with a Sensors-Embedded Pan for Domestic Users to Master Professional Culinary Arts},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207695},
doi = {10.1145/2207676.2207695},
abstract = {"panavi," a recipe medium, supports cooking experience for domestic users to master professional culinary arts in their kitchens by managing temperature and pan movement properly. Utilizing a sensors-embedded frying pan--providing projected images, LED indications, and vibration--wirelessly connected with a computer system that shows text messages with sounds, the panavi system analyzes sensors' data, recognizes users' conditions, and provides the users with situated instructions. Describing our vision, design process, implementation, and user study that outlines experience of challenging professional cooking, this paper introduces a design framework model of this recipe medium for domestic usage. Throughout revealing the design process--from ideation to the finished research artifact as a whole cooking support system--this research suggests how to design interactive systems responding to human situated actions, for use as daily commodities enriching domestic user experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {129–138},
numpages = {10},
keywords = {research through design, cooking, situated actions, interaction design, ubiquitous computing, kitchen},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250465,
author = {Paulos, Eric},
title = {Session Details: Touch in Context},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250465},
doi = {10.1145/3250465},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207697,
author = {Wang, Rongrong and Quek, Francis and Tatar, Deborah and Teh, Keng Soon and Cheok, Adrian},
title = {Keep in Touch: Channel, Expectation and Experience},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207697},
doi = {10.1145/2207676.2207697},
abstract = {This paper investigates whether and how digitally mediated social touch (remote touch) may influence the sense of connectedness toward a speaker and the emotional experience of what is being communicated. We employ an 'augmented' storytelling methodology where we manipulate the modality of an 'emotive' channel that accompanies the speech, and the contextual expectation of the listener. Comparing a remote upper-arm touch against a similarly timed flashing light, we explore the importance of the touch modality in affect conveyance. Our second manipulation involves two cover stories where the listener is told that the touch or flashing light is triggered either by the storyteller expressively squeezing a touch input device while speaking, or by measured 'high points' in the mental state of the storyteller. Our results show that the story accompanied by communicative touch resulted in a significant increase in the sense of connectedness with the storyteller over the speech-only condition, and a trend toward greater affective conveyance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {139–148},
numpages = {10},
keywords = {connectedness, haptics, multimodality, emotional experience, remote touch, affect, empathy, computer mediated communication},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207698,
author = {Piper, Anne Marie and Weibel, Nadir and Hollan, James},
title = {TAP &amp; PLAY: An End-User Toolkit for Authoring Interactive Pen and Paper Language Activities},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207698},
doi = {10.1145/2207676.2207698},
abstract = {Hybrid paper-digital interfaces are a promising approach for supporting language activities. The familiarity of pen and paper makes it a particularly attractive media for many user groups, including young children. Digital pens enhance interaction with traditional paper content by playing and recording audio and recognizing handwriting and gestures. Currently, generating custom interactive paper documents involves some programming, limiting its use by many user groups (e.g., educators and families) who might especially benefit from application of hybrid paper-digital interfaces in their practices. To address this need, we developed an end-user Toolkit for Authoring Pen and Paper Language Activities (TAP &amp; PLAY). This paper describes the iterative development of the toolkit, its accessibility for novice non-technical users, and use in three different contexts for early language learning. We demonstrate and document the system's usability, generality, and utility for people who want to create and tailor their own custom interactive paper-based language activities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {149–158},
numpages = {10},
keywords = {language activities, learning, children, digital pen, end-user authoring toolkit},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207699,
author = {Kirk, David and Izadi, Shahram and Hilliges, Otmar and Banks, Richard and Taylor, Stuart and Sellen, Abigail},
title = {At Home with Surface Computing?},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207699},
doi = {10.1145/2207676.2207699},
abstract = {This paper describes a field study of an interactive surface deployed in three family homes. The tabletop technology provides a central place where digital content, such as photos, can be easily archived, managed and viewed. The tabletop affords multi-touch input, allowing digital content to be sorted, triaged and interacted with using one or two-handed interactions. A physics-based simulation adds dynamics to digital content, providing users with rich ways of interacting that borrows from the real-world. The field study is one of the first of a surface computer within a domestic environment. Our goal is to uncover people's inter-actions, appropriations, perceptions and experiences with such technologies, exploring the potential barriers to use. Given these devices provide such a revolutionary shift in interaction, will people be able to engage with them in everyday life in the ways we intend? In answering this question, we hope to deepen our understanding of the design of such systems for home and consumer domains.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {159–168},
numpages = {10},
keywords = {physics-simulation, field-study, interactive surfaces and tabletops, home, multi-touch},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207700,
author = {Bartindale, Tom and Sheikh, Alia and Taylor, Nick and Wright, Peter and Olivier, Patrick},
title = {StoryCrate: Tabletop Storyboarding for Live Film Production},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207700},
doi = {10.1145/2207676.2207700},
abstract = {Creating film content for broadcast is a high pressure and complex activity involving multiple experts and highly specialized equipment. Production teams are under continuous pressure to produce ever more creative and groundbreaking content while reducing the budgets and human resources required. While technologies are being developed for digitizing and streamlining sections of the production workflow, a gap remains between creative decisions made on location, and those made during digital editing and post-production. We describe a prototype tangible, tabletop interface to be deployed on a film shoot, which uses a storyboard as a shared data representation to drive team creativity. We define creativity in terms of team production, discuss our implementation and describe a deployment in which the prototype was used by a professional production team during a film shoot. Finally we describe a number of interesting interactions that were observed and consider the implications of our design decisions on the creative process of film making and the benefits of tangible, tabletop collaborative interactive displays in live film production.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {169–178},
numpages = {10},
keywords = {live prototyping, collaborative production, tangible interface, broadcast},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250466,
author = {Kristensson, Per Ola},
title = {Session Details: Curves &amp; Mirages: Gestures &amp; Interaction with Nonplanar Surfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250466},
doi = {10.1145/3250466},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207702,
author = {Sodhi, Rajinder and Benko, Hrvoje and Wilson, Andrew},
title = {LightGuide: Projected Visualizations for Hand Movement Guidance},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207702},
doi = {10.1145/2207676.2207702},
abstract = {LightGuide is a system that explores a new approach to gesture guidance where we project guidance hints directly on a user's body. These projected hints guide the user in completing the desired motion with their body part which is particularly useful for performing movements that require accuracy and proper technique, such as during exercise or physical therapy. Our proof-of-concept implementation consists of a single low-cost depth camera and projector and we present four novel interaction techniques that are focused on guiding a user's hand in mid-air. Our visualizations are designed to incorporate both feedback and feedforward cues to help guide users through a range of movements. We quantify the performance of LightGuide in a user study comparing each of our on-body visualizations to hand animation videos on a computer display in both time and accuracy. Exceeding our expectations, participants performed movements with an average error of 21.6mm, nearly 85% more accurately than when guided by video.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {179–188},
numpages = {10},
keywords = {spatial augmented reality, on-demand interfaces, appropriated surfaces, on-body computing, tracking},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207703,
author = {Voelker, Simon and Sutter, Christine and Wang, Lei and Borchers, Jan},
title = {Understanding Flicking on Curved Surfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207703},
doi = {10.1145/2207676.2207703},
abstract = {Flicking is a common interaction technique to move objects across large interactive surfaces, but little is known about its suitability for use on non-planar, curved surfaces. Flicking consists of two stages: First, visually determining the direction in which to flick the object, then planning and executing the corresponding gesture. Errors in both stages could influence flicking accuracy. We investigated flicking interactions on curved interactive surface to evaluate which type of error influences accuracy. Therefore, we carried out three user studies to analyze how each stage of flicking on a curved surface is influenced. Our main findings are: 1) Flicking gestures are more accurate if horizontal and vertical surface are joined by a continuous curve than if they are separated by an edge or gap. 2) Flicking gestures on curved surfaces are mostly influenced by the motor execution stage of the gesture rather than the visual perception stage. 3) Flicking accuracy decreases as the starting point of the gesture is moved closer to the curve. 4) We conclude with a first mathematical model to estimate the error users will make when flicking across a curve.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {189–198},
numpages = {10},
keywords = {curved surface, touch-input, flicking},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207704,
author = {Benko, Hrvoje and Jota, Ricardo and Wilson, Andrew},
title = {MirageTable: Freehand Interaction on a Projected Augmented Reality Tabletop},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207704},
doi = {10.1145/2207676.2207704},
abstract = {Instrumented with a single depth camera, a stereoscopic projector, and a curved screen, MirageTable is an interactive system designed to merge real and virtual worlds into a single spatially registered experience on top of a table. Our depth camera tracks the user's eyes and performs a real-time capture of both the shape and the appearance of any object placed in front of the camera (including user's body and hands). This real-time capture enables perspective stereoscopic 3D visualizations to a single user that account for deformations caused by physical objects on the table. In addition, the user can interact with virtual objects through physically-realistic freehand actions without any gloves, trackers, or instruments. We illustrate these unique capabilities through three application examples: virtual 3D model creation, interactive gaming with real and virtual objects, and a 3D teleconferencing experience that not only presents a 3D view of a remote person, but also a seamless 3D shared task space. We also evaluated the user's perception of projected 3D objects in our system, which confirmed that the users can correctly perceive such objects even when they are projected over different background colors and geometries (e.g., gaps, drops).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {199–208},
numpages = {10},
keywords = {depth camera, shared task space, spatial augmented reality, projective textures, projector-camera system, 3d digitization, 3d interaction, 3d teleconferencing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207705,
author = {Hennecke, Fabian and Matzke, Wolfgang and Butz, Andreas},
title = {How Screen Transitions Influence Touch and Pointer Interaction across Angled Display Arrangements},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207705},
doi = {10.1145/2207676.2207705},
abstract = {Digital office environments often integrate multiple displays in a variety of arrangements. We investigated the combination of a horizontal and a directly connected vertical display, which together form a digital workspace. In particular, we were interested in the effect of the physical transition (bezel, edge or curve) on dragging. In a study participants performed dragging tasks across both display planes with direct touch as well as a pointing device. Contrary to our expectations, we found no significant effect on task completion time. Only regarding accuracy the curved transition performed better than edge and bezel. Interestingly, the subjective judgment did generally not match the objective results. These findings suggest that we need to rethink our understanding of display continuities in terms of usability as well as user satisfaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {209–212},
numpages = {4},
keywords = {dragging, tabletops, transition, display connection, interactive surfaces},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207706,
author = {Hourcade, Juan Pablo and Bullock-Rest, Natasha},
title = {How Small Can You Go? Analyzing the Effect of Visual Angle in Pointing Tasks},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207706},
doi = {10.1145/2207676.2207706},
abstract = {People are increasingly using wireless mice from across rooms as they use computers as entertainment centers. As a consequence, they often have to point at targets occupying small visual angles. In this note we present the results of a study on pointing performance for targets occupying small visual angles. Our results suggest there is a steep degradation of pointing performance in both accuracy and speed for targets occupying a visual angle below 3 minutes of arc.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {213–216},
numpages = {4},
keywords = {visual angle, accuracy, pointing, efficiency},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250467,
author = {Forte, Andrea},
title = {Session Details: Leveraging the Crowd},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250467},
doi = {10.1145/3250467},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207708,
author = {Zhang, Haoqi and Law, Edith and Miller, Rob and Gajos, Krzysztof and Parkes, David and Horvitz, Eric},
title = {Human Computation Tasks with Global Constraints},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207708},
doi = {10.1145/2207676.2207708},
abstract = {An important class of tasks that are underexplored in current human computation systems are complex tasks with global constraints. One example of such a task is itinerary planning, where solutions consist of a sequence of activities that meet requirements specified by the requester. In this paper, we focus on the crowdsourcing of such plans as a case study of constraint-based human computation tasks and introduce a collaborative planning system called Mobi that illustrates a novel crowdware paradigm. Mobi presents a single interface that enables crowd participants to view the current solution context and make appropriate contributions based on current needs. We conduct experiments that explain how Mobi enables a crowd to effectively and collaboratively resolve global constraints, and discuss how the design principles behind Mobi can more generally facilitate a crowd to tackle problems involving global constraints.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {217–226},
numpages = {10},
keywords = {groupware, collaborative planning, mixed-initiative interaction, human computation, crowdware},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207709,
author = {Willett, Wesley and Heer, Jeffrey and Agrawala, Maneesh},
title = {Strategies for Crowdsourcing Social Data Analysis},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207709},
doi = {10.1145/2207676.2207709},
abstract = {Web-based social data analysis tools that rely on public discussion to produce hypotheses or explanations of the patterns and trends in data, rarely yield high-quality results in practice. Crowdsourcing offers an alternative approach in which an analyst pays workers to generate such explanations. Yet, asking workers with varying skills, backgrounds and motivations to simply "Explain why a chart is interesting" can result in irrelevant, unclear or speculative explanations of variable quality. To address these problems, we contribute seven strategies for improving the quality and diversity of worker-generated explanations. Our experiments show that using (S1) feature-oriented prompts, providing (S2) good examples, and including (S3) reference gathering, (S4) chart reading, and (S5) annotation subtasks increases the quality of responses by 28% for US workers and 196% for non-US workers. Feature-oriented prompts improve explanation quality by 69% to 236% depending on the prompt. We also show that (S6) pre-annotating charts can focus workers' attention on relevant details, and demonstrate that (S7) generating explanations iteratively increases explanation diversity without increasing worker attrition. We used our techniques to generate 910 explanations for 16 datasets, and found that 63% were of high quality. These results demonstrate that paid crowd workers can reliably generate diverse, high-quality explanations that support the analysis of specific datasets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {227–236},
numpages = {10},
keywords = {crowdsourcing, social data analysis, information visualization},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207710,
author = {Bernstein, Michael S. and Teevan, Jaime and Dumais, Susan and Liebling, Daniel and Horvitz, Eric},
title = {Direct Answers for Search Queries in the Long Tail},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207710},
doi = {10.1145/2207676.2207710},
abstract = {Web search engines now offer more than ranked results. Queries on topics like weather, definitions, and movies may return inline results called answers that can resolve a searcher's information need without any additional interaction. Despite the usefulness of answers, they are limited to popular needs because each answer type is manually authored. To extend the reach of answers to thousands of new information needs, we introduce Tail Answers: a large collection of direct answers that are unpopular individually, but together address a large proportion of search traffic. These answers cover long-tail needs such as the average body temperature for a dog, substitutes for molasses, and the keyboard shortcut for a right-click. We introduce a combination of search log mining and paid crowdsourcing techniques to create Tail Answers. A user study with 361 participants suggests that Tail Answers significantly improved users' subjective ratings of search quality and their ability to solve needs without clicking through to a result. Our findings suggest that search engines can be extended to directly respond to a large new class of queries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {237–246},
numpages = {10},
keywords = {crowdsourcing, search user interfaces, query log analysis},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207711,
author = {Fisher, Kristie and Counts, Scott and Kittur, Aniket},
title = {Distributed Sensemaking: Improving Sensemaking by Leveraging the Efforts of Previous Users},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207711},
doi = {10.1145/2207676.2207711},
abstract = {We examine the possibility of distributed sensemaking: improving a user's sensemaking by leveraging previous users' work without those users directly collaborating or even knowing one another. We asked users to engage in sensemaking by organizing and annotating web search results into "knowledge maps," either with or without previous users' maps to work from. We also recorded gaze patterns as users examined others' knowledge maps. Our findings show the conditions under which distributed sensemaking can improve sensemaking quality; that a user's sensemaking process is readily apparent to a subsequent user via a knowledge map; and that the organization of content was more useful to subsequent users than the content itself, especially when those users had differing goals. We discuss the role distributed sensemaking can play in schema induction by helping users make a mental model of an information space and make recommendations for new tool and system development.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {247–256},
numpages = {10},
keywords = {knowledge mapping, collaboration, sensemaking, search},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250468,
author = {Pietriga, Emmanuel},
title = {Session Details: Getting around: Menus, Scrolling, &amp; Advanced Navigation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250468},
doi = {10.1145/3250468},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207713,
author = {Scarr, Joey and Cockburn, Andy and Gutwin, Carl and Bunt, Andrea},
title = {Improving Command Selection with CommandMaps},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207713},
doi = {10.1145/2207676.2207713},
abstract = {Designers of GUI applications typically arrange commands in hierarchical structures, such as menus, due to screen space limitations. However, hierarchical organisations are known to slow down expert users. This paper proposes the use of spatial memory in combination with hierarchy flattening as a means of improving GUI performance. We demonstrate these concepts through the design of a command selection interface, called CommandMaps, and analyse its theoretical performance characteristics. We then describe two studies evaluating CommandMaps against menus and Microsoft's Ribbon interface for both novice and experienced users. Results show that for novice users, there is no significant performance difference between CommandMaps and traditional interfaces -- but for experienced users, CommandMaps are significantly faster than both menus and the Ribbon.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {257–266},
numpages = {10},
keywords = {hierarchies, commands, expertise, spatial memory},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207714,
author = {Cockburn, Andy and Quinn, Philip and Gutwin, Carl and Fitchett, Stephen},
title = {Improving Scrolling Devices with Document Length Dependent Gain},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207714},
doi = {10.1145/2207676.2207714},
abstract = {We describe a method for applying gain to events reported by scrolling input devices such as scroll wheels. By treating document length as an input to our gain functions, the method allows rapid document traversal regardless of document length; it also allows slow and precise scroll control at shorter distances. An initial experiment characterises four diverse scrolling input devices -- a standard 'notched' scroll wheel, a high performance 'inertial' wheel, an isometric scrolling joystick, and a trackpad -- and the results are used to calibrate several gain function parameters. A second experiment validates the method, showing that it allows faster scrolling in long and short documents than current scrolling-device gain methods, and that subjective preferences favour it.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {267–276},
numpages = {10},
keywords = {empirical studies, scrolling, control-display gain},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207715,
author = {Yang, Tao and Ferati, Mexhid and Liu, Yikun and Rohani Ghahari, Romisa and Bolchini, Davide},
title = {Aural Browsing On-the-Go: Listening-Based Back Navigation in Large Web Architectures},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207715},
doi = {10.1145/2207676.2207715},
abstract = {Mobile web navigation requires highly-focused visual attention, which poses problems when it is inconvenient or distracting to continuously look at the screen (e.g., while walking). Aural interfaces support more eyes-free experiences, as users can primarily listen to the content and occasionally look at the device. Yet, designing aural information architectures remains a challenge. Specifically, back navigation is inefficient in the aural setting, as it forces users to listen to each previous page to retrieve the desired content. This paper introduces topic- and list-based back: two navigation strategies to enhance aural browsing. Both are manifest in Green-Savers Mobile (GSM), an aural mobile site. A study (N=29) compared both solutions to traditional back mechanisms. Our findings indicate that topic- and list-based back enable faster access to previous pages, improve the navigation experience and reduce perceived cognitive load. The proposed designs apply to a wide range of content-intensive, ubiquitous web systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {277–286},
numpages = {10},
keywords = {mobile web, info architecture, aural web, back navigation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207716,
author = {Javed, Waqas and Ghani, Sohaib and Elmqvist, Niklas},
title = {Polyzoom: Multiscale and Multifocus Exploration in 2d Visual Spaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207716},
doi = {10.1145/2207676.2207716},
abstract = {The most common techniques for navigating in multiscale visual spaces are pan, zoom, and bird's eye views. However, these techniques are often tedious and cumbersome to use, especially when objects of interest are located far apart. We present the PolyZoom technique where users progressively build hierarchies of focus regions, stacked on each other such that each subsequent level shows a higher magnification. Correlation graphics show the relation between parent and child viewports in the hierarchy. To validate the new technique, we compare it to standard navigation techniques in two user studies, one on multiscale visual search and the other on multifocus interaction. Results show that PolyZoom performs better than current standard techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {287–296},
numpages = {10},
keywords = {maps, multifocus interaction, interaction, comparative visualization, visual exploration, navigation, visual analytics},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250469,
author = {Brown, Barry},
title = {Session Details: Spectators},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250469},
doi = {10.1145/3250469},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207718,
author = {M\"{u}ller, J\"{o}rg and Walter, Robert and Bailly, Gilles and Nischt, Michael and Alt, Florian},
title = {Looking Glass: A Field Study on Noticing Interactivity of a Shop Window},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207718},
doi = {10.1145/2207676.2207718},
abstract = {In this paper we present our findings from a lab and a field study investigating how passers-by notice the interactivity of public displays. We designed an interactive installation that uses visual feedback to the incidental movements of passers-by to communicate its interactivity. The lab study reveals: (1) Mirrored user silhouettes and images are more effective than avatar-like representations. (2) It takes time to notice the interactivity (approx. 1.2s). In the field study, three displays were installed during three weeks in shop windows, and data about 502 interaction sessions were collected. Our observations show: (1) Significantly more passers-by interact when immediately showing the mirrored user image (+90%) or silhouette (+47%) compared to a traditional attract sequence with call-to-action. (2) Passers-by often notice interactivity late and have to walk back to interact (the landing effect). (3) If somebody is already interacting, others begin interaction behind the ones already interacting, forming multiple rows (the honeypot effect). Our findings can be used to design public display applications and shop windows that more effectively communicate interactivity to passers-by.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {297–306},
numpages = {10},
keywords = {interactivity, noticing interactivity, public displays, user representation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207719,
author = {Fischer, Patrick Tobias and Hornecker, Eva},
title = {Urban HCI: Spatial Aspects in the Design of Shared Encounters for Media Facades},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207719},
doi = {10.1145/2207676.2207719},
abstract = {Designing interactive applications for Media Facades is a challenging task. Architectural sized largescale screens can result in unbalanced installations, and meaningful interaction is easily overshadowed by the drastic size of the display. In this paper we reflect on urban technology interventions by analyzing their spatial configuration in relation to the structuring of interaction. We outline basic categories and offer a new terminology to describe these interactive situations designed for the built environment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {307–316},
numpages = {10},
keywords = {media intervention, architecture, urban screens, urban HCI, shared encounter, media facade, social technology},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207720,
author = {Ten Koppel, Maurice and Bailly, Gilles and M\"{u}ller, J\"{o}rg and Walter, Robert},
title = {Chained Displays: Configurations of Public Displays Can Be Used to Influence Actor-, Audience-, and Passer-by Behavior},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207720},
doi = {10.1145/2207676.2207720},
abstract = {Most interactive public displays currently rely on flat screens. This form factor impacts how users (1) notice the public display (2) develop motivation and (3) (socially) interact with the public display. In this paper, we present Chained Displays, a combination of several screens to create different form factors for interactive public displays. We also present a design space based on two complementary concepts, Focus and Nimbus, to describe and compare chained display configurations. Finally, we performed a field study comparing three chained displays: Flat, Concave, and Hexagonal. Results show that Flat triggers the strongest honeypot effect, Hexagonal causes low social learning, and Concave triggers the smallest amount of simultaneously interacting users among other findings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {317–326},
numpages = {10},
keywords = {chained displays, public displays, form factor, field study},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250470,
author = {Lee, Joonhwan},
title = {Session Details: Immateriality as a Design Feature},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250470},
doi = {10.1145/3250470},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207722,
author = {Odom, William and Zimmerman, John and Forlizzi, Jodi and Choi, Hajin and Meier, Stephanie and Park, Angela},
title = {Investigating the Presence, Form and Behavior of Virtual Possessions in the Context of a Teen Bedroom},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207722},
doi = {10.1145/2207676.2207722},
abstract = {Over the past several years, people have acquired more and more virtual possessions. While virtual possessions have become ubiquitous, little work exists to inform designers on how these growing collections should be displayed and how they should behave. We generated four design concepts that changed the form and behavior of these digital things, making them more present within a teen bedroom. We then conducted speed dating sessions to investigate how these new forms and behaviors influence perceptions of value. Sessions revealed how new technologies might better support self-exploration and reflection, as well as how they could complicate identity construction processes. Findings are interpreted to detail opportunities and tensions that can guide future research and practice in this emerging space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {327–336},
numpages = {10},
keywords = {virtual possessions, design methods, home, design research, research through design, speed dating, bedroom, teenagers, design, user enactments},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207723,
author = {Odom, William and Banks, Richard and Kirk, David and Harper, Richard and Lindley, Si\^{a}n and Sellen, Abigail},
title = {Technology Heirlooms? Considerations for Passing down and Inheriting Digital Materials},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207723},
doi = {10.1145/2207676.2207723},
abstract = {Material artifacts are passed down as a way of sustaining relationships and family history. However, new issues are emerging as families are increasingly left with the digital remains of their loved ones. We designed three devices to investigate how digital materials might be passed down, lived with and inherited in the future. We conducted in-home interviews with 8 families using the devices to provoke discussion about how technology might support (or complicate) their existing practices. Sessions revealed families desired to treat their archives in ways not fully supported by technology as well as potential tensions that could emerge. Findings are interpreted to detail design considerations for future work in this emerging space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {337–346},
numpages = {10},
keywords = {memories, technology probes, design, digital inheritance, design research, technology heirlooms},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207724,
author = {Wang, Qi and Ding, Xianghua and Lu, Tun and Gu, Ning},
title = {Digitality and Materiality of New Media: Online TV Watching in China},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207724},
doi = {10.1145/2207676.2207724},
abstract = {This paper examines issues of digitality and materiality of new media, grounded in a study of online TV watching in China. Particularly, by looking at how people make choices and decisions regarding TV watching in everyday life, we highlight material and digital properties of new media TV, and how they support and condition actions and interactions around them. The study illustrates that materiality and digitality are complementary, instead of one substituting the other, and are highly intertwined in the hybrid media environment around which meaningful experiences are conditioned and produced. It also suggests that an analytic distinction between materiality and digitality is fruitful in unpacking the complex relations between media technologies and social experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {347–356},
numpages = {10},
keywords = {online TV, TV, new media TV, new media, digitally, materiality},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207725,
author = {Feinberg, Melanie},
title = {Writing the Experience of Information Retrieval: Digital Collection Design as a Form of Dialogue},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207725},
doi = {10.1145/2207676.2207725},
abstract = {In the context of digital libraries and other online resource collections, the substance of interaction is generated to a large degree through the selection, description, organization, and arrangement of the aggregated items. Within information studies, researchers [such as 32, 6] have shown how individual events of selection and description inevitably form judgments about the collected materials. This paper describes a process in which designers purposefully use the elements of selection, description, organization, and arrangement to "write" a resource collection as a form of rhetorical expression. The design process was implemented in two classroom settings. In the more successful second implementation, the role of the audience in structuring a rhetorical interaction was emphasized, and collection design was conceptualized as designing a dialogue between author and audience. The formalized critique of existing collection designs was a key element in enabling this dialogic orientation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {357–366},
numpages = {10},
keywords = {experience design, rhetoric, digital collections, criticism},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250471,
author = {Tscheligi, Manfred},
title = {Session Details: Privacy + Self Disclosure},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250471},
doi = {10.1145/3250471},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207727,
author = {Barkhuus, Louise},
title = {The Mismeasurement of Privacy: Using Contextual Integrity to Reconsider Privacy in HCI},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207727},
doi = {10.1145/2207676.2207727},
abstract = {Privacy is a widely studied concept in relation to social computing and sensor-based technologies; scores of research papers have investigated people's "privacy preferences" and apparent reluctance to share personal data. In this paper we explore how Ubicomp and HCI studies have approached the notion of privacy, often as a quantifiable concept. Leaning on several theoretical frameworks, but in particular Nissenbaum's notion of contextual integrity, we question the viability of obtaining universal answers in terms of people's "general" privacy practices and apply elements of Nissenbaum's theory to our own data in order to illustrate its relevance. We then suggest restructuring inquiries into information sharing in studies of state-of-the-art technologies and analyze contextually grounded issues using a different, more specific vocabulary. Finally, we provide the first building blocks to such vocabulary.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {367–376},
numpages = {10},
keywords = {user studies, privacy, location-based services, ubiquitous computing, online social networks},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207728,
author = {Klemperer, Peter and Liang, Yuan and Mazurek, Michelle and Sleeper, Manya and Ur, Blase and Bauer, Lujo and Cranor, Lorrie Faith and Gupta, Nitin and Reiter, Michael},
title = {Tag, You Can See It! Using Tags for Access Control in Photo Sharing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207728},
doi = {10.1145/2207676.2207728},
abstract = {Users often have rich and complex photo-sharing preferences, but properly configuring access control can be difficult and time-consuming. In an 18-participant laboratory study, we explore whether the keywords and captions with which users tag their photos can be used to help users more intuitively create and maintain access-control policies. We find that (a) tags created for organizational purposes can be repurposed to create efficient and reasonably accurate access-control rules; (b) users tagging with access control in mind develop coherent strategies that lead to significantly more accurate rules than those associated with organizational tags alone; and (c) participants can understand and actively engage with the concept of tag-based access control.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {377–386},
numpages = {10},
keywords = {privacy, tagging, access control, human factors},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207729,
author = {Gulotta, Rebecca and Faste, Haakon and Mankoff, Jennifer},
title = {Curation, Provocation, and Digital Identity: Risks and Motivations for Sharing Provocative Images Online},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207729},
doi = {10.1145/2207676.2207729},
abstract = {Among the billions of photos that have been contributed to online photo-sharing sites, there are many that are provocative, controversial, and deeply personal. Previous research has examined motivations for sharing images online and has identified several key motivations for doing so: expression, curation of identity, maintaining social connections, and recording experiences. However, few studies have focused on the perceived risks of posting photos online and even fewer have examined the risks associated with provocative, controversial, or deeply personal images. In our work, we used photo-elicitation interviews to explore the motivations for posting these types of images and the perceived risks of doing so. In this paper, we describe our findings from those interviews.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {387–390},
numpages = {4},
keywords = {privacy, flickr, sharing, identity, photos, digital rights},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207730,
author = {Tang, Karen and Hong, Jason and Siewiorek, Dan},
title = {The Implications of Offering More Disclosure Choices for Social Location Sharing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207730},
doi = {10.1145/2207676.2207730},
abstract = {We compared two privacy configuration styles for specifying rules for social sharing one's past locations. Our findings suggest that location-sharing applications (LSAs) which support varying levels of location granularities are associated with sharing rules that are less convoluted, are less likely to be negatively phrased, and can lead to more open sharing; users are also more comfortable with these rules. These findings can help inform LSA privacy designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {391–394},
numpages = {4},
keywords = {location sharing, rules, configuration, privacy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207731,
author = {Sundar, S. Shyam and Oh, Jeeyun and Bellur, Saraswathi and Jia, Haiyan and Kim, Hyang-Sook},
title = {Interactivity as Self-Expression: A Field Experiment with Customization and Blogging},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207731},
doi = {10.1145/2207676.2207731},
abstract = {A paradigmatic quality of interactive interfaces is that they allow users to express themselves, thereby converting message receivers into communication sources. We define this quality as Source Interactivity [26, 29], and test its effects on user experience with a field experiment (N=141) of a portal site featuring cosmetic customization, functional customization and blogging (active versus filter). In demonstrating the psychological influence of source-based interactivity on such outcomes as user engagement, sense of agency, sense of community, intrinsic motivation and attitudes toward the interface, we discuss how designers can use them for creating interactive tools for self-expression.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {395–404},
numpages = {10},
keywords = {customization, user engagement, blogging, interactivity},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250472,
author = {Hanson, Vicki},
title = {Session Details: Supporting Visually Impaired Users},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250472},
doi = {10.1145/3250472},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207733,
author = {Guy, Richard and Truong, Khai},
title = {CrossingGuard: Exploring Information Content in Navigation Aids for Visually Impaired Pedestrians},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207733},
doi = {10.1145/2207676.2207733},
abstract = {Visually impaired pedestrians experience unique challenges when navigating an urban environment because many cues about orientation and traffic patterns are difficult to ascertain without the use of vision. Technological aids such as customized GPS navigation tools offer the chance to augment visually impaired pedestrians' sensory information with a richer depiction of an environment, but care must be taken to balance the need for more information with other demands on the senses. In this paper, we focus on the information needs of visually impaired pedestrians at intersections, which present a specific cause of stress when navigating in unfamiliar locations. We present a navigation application prototype called CrossingGuard that provides rich information to a user such as details about intersection geometry that are not available to visually impaired pedestrians today. A user study comparing content-rich information to a baseline condition shows that content-rich information raises the level of comfort that visually impaired pedestrians feel at unfamiliar intersections. In addition, we discuss the categories of information that are most useful. Finally, we introduce a micro-task approach to gather intersection data via Street View annotations that achieves 85.5% accuracy over the 9 categories of information used by CrossingGuard.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {405–414},
numpages = {10},
keywords = {visually impaired pedestrians, geographic data, wayfinding, navigation aids},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207734,
author = {Yatani, Koji and Banovic, Nikola and Truong, Khai},
title = {SpaceSense: Representing Geographical Information to Visually Impaired People Using Spatial Tactile Feedback},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207734},
doi = {10.1145/2207676.2207734},
abstract = {Learning an environment can be challenging for people with visual impairments. Braille maps allow their users to understand the spatial relationship between a set of places. However, physical Braille maps are often costly, may not always cover an area of interest with sufficient detail, and might not present up-to-date information. We built a handheld system for representing geographical information called SpaceSense, which includes custom spatial tactile feedback hardware-multiple vibration motors attached to different locations on a mobile touch-screen device. It offers high-level information about the distance and direction towards a destination and bookmarked places through vibrotactile feedback to help the user maintain the spatial relationships between these points. SpaceSense also adapts a summarization technique for online user reviews of public and commercial venues. Our user study shows that participants could build and maintain the spatial relationships between places on a map more accurately with SpaceSense compared to a system without spatial tactile feedback. They pointed specifically to having spatial tactile feedback as the contributing factor in successfully building and maintaining their mental map.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {415–424},
numpages = {10},
keywords = {vibrotactile feedback, touch screens, users with visual impairments, handheld devices, geographical information representation, assistive technology},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207735,
author = {Fallah, Navid and Apostolopoulos, Ilias and Bekris, Kostas and Folmer, Eelke},
title = {The User as a Sensor: Navigating Users with Visual Impairments in Indoor Spaces Using Tactile Landmarks},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207735},
doi = {10.1145/2207676.2207735},
abstract = {Indoor navigation systems for users who are visually impaired typically rely upon expensive physical augmentation of the environment or expensive sensing equipment; consequently few systems have been implemented. We present an indoor navigation system called Navatar that allows for localization and navigation by exploiting the physical characteristics of indoor environments, taking advantage of the unique sensing abilities of users with visual impairments, and minimalistic sensing achievable with low cost accelerometers available in smartphones. Particle filters are used to estimate the user's location based on the accelerometer data as well as the user confirming the presence of anticipated tactile landmarks along the provided path. Navatar has a high possibility of large-scale deployment, as it only requires an annotated virtual representation of an indoor environment. A user study with six blind users determines the accuracy of the approach, collects qualitative experiences and identifies areas for improvement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {425–432},
numpages = {8},
keywords = {mobility, indoor navigation, visual impairment},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207736,
author = {Power, Christopher and Freire, Andr\'{e} and Petrie, Helen and Swallow, David},
title = {Guidelines Are Only Half of the Story: Accessibility Problems Encountered by Blind Users on the Web},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207736},
doi = {10.1145/2207676.2207736},
abstract = {This paper describes an empirical study of the problems encountered by 32 blind users on the Web. Task-based user evaluations were undertaken on 16 websites, yielding 1383 instances of user problems. The results showed that only 50.4% of the problems encountered by users were covered by Success Criteria in the Web Content Accessibility Guidelines 2.0 (WCAG 2.0). For user problems that were covered by WCAG 2.0, 16.7% of websites implemented techniques recommended in WCAG 2.0 but the techniques did not solve the problems. These results show that few developers are implementing the current version of WCAG, and even when the guidelines are implemented on websites there is little indication that people with disabilities will encounter fewer problems. The paper closes by discussing the implications of this study for future research and practice. In particular, it discusses the need to move away from a problem-based approach towards a design principle approach for web accessibility.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {433–442},
numpages = {10},
keywords = {web accessibility, user evaluation, blind users, accessibility guidelines},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250473,
author = {Fekete, Jean-Daniel},
title = {Session Details: Text Visualization},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250473},
doi = {10.1145/3250473},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207738,
author = {Chuang, Jason and Ramage, Daniel and Manning, Christopher and Heer, Jeffrey},
title = {Interpretation and Trust: Designing Model-Driven Visualizations for Text Analysis},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207738},
doi = {10.1145/2207676.2207738},
abstract = {Statistical topic models can help analysts discover patterns in large text corpora by identifying recurring sets of words and enabling exploration by topical concepts. However, understanding and validating the output of these models can itself be a challenging analysis task. In this paper, we offer two design considerations - interpretation and trust - for designing visualizations based on data-driven models. Interpretation refers to the facility with which an analyst makes inferences about the data through the lens of a model abstraction. Trust refers to the actual and perceived accuracy of an analyst's inferences. These considerations derive from our experiences developing the Stanford Dissertation Browser, a tool for exploring over 9,000 Ph.D. theses by topical similarity, and a subsequent review of existing literature. We contribute a novel similarity measure for text collections based on a notion of "word-borrowing" that arose from an iterative design process. Based on our experiences and a literature review, we distill a set of design recommendations and describe how they promote interpretable and trustworthy visual analysis tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {443–452},
numpages = {10},
keywords = {design guidelines, statistical models, text, visual analysis},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207739,
author = {Park, Heekyong and Choi, Jinwook},
title = {V-Model: A New Innovative Model to Chronologically Visualize Narrative Clinical Texts},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207739},
doi = {10.1145/2207676.2207739},
abstract = {Visualizing narrative medical events into a timeline can have positive effects on clinical environments. However, the characteristics of natural language and medical environments make this representation more difficult. This paper explains the obstacles and suggests a solution called the V-Model. The V-Model is a new innovative time model that was developed to represent chronological narrative events in a medical domain. Forty medical students participated in evaluating this model. The experimental results show the new model successfully solved the modeling requirements and had better usability compared to conventional timeline models. All the participants assessed the new timeline as very useful in effectively understanding a patient's history.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {453–462},
numpages = {10},
keywords = {visualization, clinical reports, patient history, natural language, timeline},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207740,
author = {Lee, Hyungmin and Lee, Sooyun and Kim, Namwook and Seo, Jinwook},
title = {JigsawMap: Connecting the Past to the Future by Mapping Historical Textual Cadasters},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207740},
doi = {10.1145/2207676.2207740},
abstract = {In this paper, we present an interactive visualization tool, JigsawMap, for visualizing and mapping historical textual cadasters. A cadaster is an official register that records land properties (e.g., location, ownership, value and size) for land valuation and taxation. Such mapping of old and new cadasters can help historians understand the social/economic background of changes in land uses or ownership. With JigsawMap, historians can continue mapping older or newer cadasters. In this way, JigsawMap can connect the past land survey results to today and to the future. We conducted usability studies and long term case studies to evaluate JigsawMap, and received positive responses. As well as summarizing the evaluation results, we also present design guidelines for participatory design projects with historians.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {463–472},
numpages = {10},
keywords = {interactive visualization, jigsawmap, cadaster, graph layout, case study, history},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207741,
author = {Endert, Alex and Fiaux, Patrick and North, Chris},
title = {Semantic Interaction for Visual Text Analytics},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207741},
doi = {10.1145/2207676.2207741},
abstract = {Visual analytics emphasizes sensemaking of large, complex datasets through interactively exploring visualizations generated by statistical models. For example, dimensionality reduction methods use various similarity metrics to visualize textual document collections in a spatial metaphor, where similarities between documents are approximately represented through their relative spatial distances to each other in a 2D layout. This metaphor is designed to mimic analysts' mental models of the document collection and support their analytic processes, such as clustering similar documents together. However, in current methods, users must interact with such visualizations using controls external to the visual metaphor, such as sliders, menus, or text fields, to directly control underlying model parameters that they do not understand and that do not relate to their analytic process occurring within the visual metaphor. In this paper, we present the opportunity for a new design space for visual analytic interaction, called semantic interaction, which seeks to enable analysts to spatially interact with such models directly within the visual metaphor using interactions that derive from their analytic process, such as searching, highlighting, annotating, and repositioning documents. Further, we demonstrate how semantic interactions can be implemented using machine learning techniques in a visual analytic tool, called ForceSPIRE, for interactive analysis of textual data within a spatial visualization. Analysts can express their expert domain knowledge about the documents by simply moving them, which guides the underlying model to improve the overall layout, taking the user's feedback into account.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {473–482},
numpages = {10},
keywords = {visualization, visual analytics, interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250474,
author = {Hoggan, Eve},
title = {Session Details: Brain &amp; Body},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250474},
doi = {10.1145/3250474},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207743,
author = {Sato, Munehiko and Poupyrev, Ivan and Harrison, Chris},
title = {Touch\'{e}: Enhancing Touch Interaction on Humans, Screens, Liquids, and Everyday Objects},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207743},
doi = {10.1145/2207676.2207743},
abstract = {Touch\'{e} proposes a novel Swept Frequency Capacitive Sensing technique that can not only detect a touch event, but also recognize complex configurations of the human hands and body. Such contextual information significantly enhances touch interaction in a broad range of applications, from conventional touchscreens to unique contexts and materials. For example, in our explorations we add touch and gesture sensitivity to the human body and liquids. We demonstrate the rich capabilities of Touch\'{e} with five example setups from different application domains and conduct experimental studies that show gesture classification accuracies of 99% are achievable with our technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {483–492},
numpages = {10},
keywords = {touch, ubiquitous interfaces, gestures, on-body computing, sensors, mobile devices},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207744,
author = {Vi, Chi and Subramanian, Sriram},
title = {Detecting Error-Related Negativity for Interaction Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207744},
doi = {10.1145/2207676.2207744},
abstract = {This paper examines the ability to detect a characteristic brain potential called the Error-Related Negativity (ERN) using off-the-shelf headsets and explores its applicability to HCI. ERN is triggered when a user either makes a mistake or the application behaves differently from their expectation. We first show that ERN can be seen on signals captured by EEG headsets like Emotiv™ when doing a typical multiple choice reaction time (RT) task -- Flanker task. We then present a single-trial online ERN algorithm that works by pre-computing the coefficient matrix of a logistic regression classifier using some data from a multiple choice reaction time task and uses it to classify incoming signals of that task on a single trial of data. We apply it to an interactive selection task that involved users selecting an object under time pressure. Furthermore the study was conducted in a typical office environment with ambient noise. Our results show that online single trial ERN detection is possible using off-the-shelf headsets during tasks that are typical of interactive applications. We then design a Superflick experiment with an integrated module mimicking an ERN detector to evaluate the accuracy of detecting ERN in the context of assisting users in interactive tasks. Based on these results we discuss and present several HCI scenarios for use of ERN.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {493–502},
numpages = {10},
keywords = {brain computer interface, eeg, user interface, flick, electroencephalography, error related negativity},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207745,
author = {Holz, Christian and Grossman, Tovi and Fitzmaurice, George and Agur, Anne},
title = {Implanted User Interfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207745},
doi = {10.1145/2207676.2207745},
abstract = {We investigate implanted user interfaces that small devices provide when implanted underneath human skin. Such devices always stay with the user, making their implanted user interfaces available at all times. We discuss four core challenges of implanted user interfaces: how to sense input through the skin, how to produce output, how to communicate amongst one another and with external infrastructure, and how to remain powered. We investigate these four challenges in a technical evaluation where we surgically implant study devices into a specimen arm. We find that traditional interfaces do work through skin. We then demonstrate how to deploy a prototype device on participants, using artificial skin to simulate implantation. We close with a discussion of medical considerations of implanted user interfaces, risks and limitations, and project into the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {503–512},
numpages = {10},
keywords = {implantables, implanted devices, wearable computing, augmented humans, wireless power, disappearing mobile devices, implanted interfaces, mobile devices},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207746,
author = {Mustafa, Maryam and Lindemann, Lea and Magnor, Marcus},
title = {EEG Analysis of Implicit Human Visual Perception},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207746},
doi = {10.1145/2207676.2207746},
abstract = {Image Based Rendering (IBR) allows interactive scene exploration from images alone. However, despite considerable development in the area, one of the main obstacles to better quality and more realistic visualizations is the occurrence of visually disagreeable artifacts. In this paper we present a methodology to map out the perception of IBR-typical artifacts. This work presents an alternative to traditional image and video quality evaluation methods by using an EEG device to determine the implicit visual processes in the human brain. Our work demonstrates the distinct differences in the perception of different types of visual artifacts and the implications of these differences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {513–516},
numpages = {4},
keywords = {visual processing, eeg, perception, artifacts, hvs},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207747,
author = {Nakamura, Hiromi and Miyashita, Homei},
title = {Development and Evaluation of Interactive System for Synchronizing Electric Taste and Visual Content},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207747},
doi = {10.1145/2207676.2207747},
abstract = {Electric taste is a characteristic taste produced when the tongue is electrically stimulated. We have proposed apparatuses to add electric taste to food and drink. An interactive system could be developed to synchronize video contents using the reversibility and instantaneity of electric taste. However, to do so, the presentation time must be determined based on the different latency for the perception of each sense. We measured the latencies for electric taste and visual stimuli as a basic evaluation for a content presentation system in which electric taste and visual content are synchronized.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {517–520},
numpages = {4},
keywords = {latency difference of several sensations, electric taste, multimodal information system, gustatory presentation system},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250475,
author = {Hoonhout, Jettie},
title = {Session Details: Empathy &amp; Technology: Focus on the End User},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250475},
doi = {10.1145/3250475},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207749,
author = {Lindsay, Stephen and Brittain, Katie and Jackson, Daniel and Ladha, Cassim and Ladha, Karim and Olivier, Patrick},
title = {Empathy, Participatory Design and People with Dementia},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207749},
doi = {10.1145/2207676.2207749},
abstract = {We describe the development, application and evaluation of a design method tailored for working with people with mild to moderate dementia. Our experiences with the approach highlighted areas where designers and participants held radically different views. The tenet of our approach was that to overcome these differences we needed to create an empathic relationship between participants and designers. To achieve this we modified participatory design techniques to foster respectful engagement with participants in the development of a digital aid to facilitate "safe walking". The process begins with broad qualitative scoping and design work then moves to developing personally tailored, individual designs to further exploration of the experiential elements of the domain while reducing the need for the participants to engage in abstract thought. Reflection highlights a number of important areas that demand consideration when undertaking research in this area and, more generally, when performing design work with people with dementia.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {521–530},
numpages = {10},
keywords = {experience, participatory design, dementia, empathy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207750,
author = {Moncur, Wendy and Bikker, Jan and Kasket, Elaine and Troyer, John},
title = {From Death to Final Disposition: Roles of Technology in the Post-Mortem Interval},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207750},
doi = {10.1145/2207676.2207750},
abstract = {In this paper, we describe collaborative processes and stakeholders involved in the period from when a person dies until they are laid to rest: the funeral, final disposition of the body, and (in some circumstances) victim identification. The rich mixture of technologies currently deployed during this brief period are categorized and critically analyzed. We then reflect on the implications of our findings, both for the design of technology that takes the end of life into account, and for the wider HCI community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {531–540},
numpages = {10},
keywords = {end of life, coordination, victim identification, thanatosensitive design, final disposition, collaboration, funerals},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207751,
author = {McCay-Peet, Lori and Lalmas, Mounia and Navalpakkam, Vidhya},
title = {On Saliency, Affect and Focused Attention},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207751},
doi = {10.1145/2207676.2207751},
abstract = {We study how the visual catchiness (saliency) of relevant information impacts user engagement metrics such as focused attention and emotion (affect). Participants completed tasks in one of two conditions, where the task-relevant information either appeared salient or non-salient. Our analysis provides insights into relationships between saliency, focused attention, and affect. Participants reported more distraction in the non-salient condition, and non-salient information was slower to find than salient. Lack-of-saliency led to a negative impact on affect, while saliency maintained positive affect, suggesting its helpfulness. Participants reported that it was easier to focus in the salient condition, although there was no significant improvement in the focused attention scale rating. Finally, this study suggests user interest in the topic is a good predictor of focused attention, which in turn is a good predictor of positive affect. These results suggest that enhancing saliency of user-interested topics seems a good strategy for boosting user engagement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {541–550},
numpages = {10},
keywords = {user interests, user engagement, saliency, positive affect, news entertainment, focused attention},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207752,
author = {Yang, Jiang and Adamic, Lada and Ackerman, Mark and Wen, Zhen and Lin, Ching-Yung},
title = {The Way i Talk to You: Sentiment Expression in an Organizational Context},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207752},
doi = {10.1145/2207676.2207752},
abstract = {Sentiment is a rich and important dimension of social interaction. However, its presence in computer-mediated communication in corporate settings is not well understood. This paper provides a preliminary study of people's expression of sentiment in email conversations in an organizational context. The study reveals that sentiment levels evolve over time during the process of newcomers' socialization, that sentiment varies according to tie-strength with the recipient, and that sentiment patterns can be indicative of one's position in the corporate social network as well as job performance. These findings shed light on the complex and dynamic nature of sentiment patterns, and would inspire further explorations and applications of sentiment analysis in organizations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {551–554},
numpages = {4},
keywords = {organizational science, socializing, social network, computer-mediated-communication (cmc), email, sentiments},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250476,
author = {Pipek, Volkmar},
title = {Session Details: Workplace},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250476},
doi = {10.1145/3250476},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207754,
author = {Mark, Gloria and Voida, Stephen and Cardello, Armand},
title = {"A Pace Not Dictated by Electrons": An Empirical Study of Work without Email},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207754},
doi = {10.1145/2207676.2207754},
abstract = {We report on an empirical study where we cut off email usage for five workdays for 13 information workers in an organization. We employed both quantitative measures such as computer log data and ethnographic methods to compare a baseline condition (normal email usage) with our experimental manipulation (email cutoff). Our results show that without email, people multitasked less and had a longer task focus, as measured by a lower frequency of shifting between windows and a longer duration of time spent working in each computer window. Further, we directly measured stress using wearable heart rate monitors and found that stress, as measured by heart rate variability, was lower without email. Interview data were consistent with our quantitative measures, as participants reported being able to focus more on their tasks. We discuss the implications for managing email better in organizations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {555–564},
numpages = {10},
keywords = {sensors, multitasking, empirical study, interruptions, email},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207755,
author = {Topkara, Mercan and Pan, Shimei and Lai, Jennifer and Dirik, Ahmet and Wood, Steven and Boston, Jeff},
title = {"You've Got Video": Increasing Clickthrough When Sharing Enterprise Video with Email},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207755},
doi = {10.1145/2207676.2207755},
abstract = {In this Note we summarize our research on increasing the information scent of video recordings that are shared via email in a corporate setting. We compare two types of email messages for sharing recordings: the first containing basic information (e.g. title, speaker, abstract) with a link to the video; the second with the same information plus a set of video thumbnails (hyperlinked to the segments they represent), which are automatically created by video summarization technology. We report on the results of two user studies. The first one compares the quality of the set of thumbnails selected by the technology to sets selected by 31 humans. The second study examines the clickthrough rates for both email formats (with and without hyperlinked thumbnails) as well as gathering subjective feedback via survey. Results indicate that the email messages with the thumbnails drove significantly higher clickthrough rates than the messages without, even though people clicked on the main video link more frequently than the thumbnails. Survey responses show that users found the email with the thumbnail set significantly more appealing and novel.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {565–568},
numpages = {4},
keywords = {email overload, link sharing, thumbnail view, video sharing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207756,
author = {Raban, Daphne R. and Danan, Avinoam and Ronen, Inbal and Guy, Ido},
title = {Impression Formation in Corporate People Tagging},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207756},
doi = {10.1145/2207676.2207756},
abstract = {This research explores the relationship between self-presentation and perception by others as manifested explicitly through the use of tags in a people tagging system. The study provides insights relevant for the organizational context since it is based on a system implemented within IBM. We developed a detailed codebook and used it to categorize 9,506 tags assigned to a sample of taggers. Our analysis examines the use of self tags versus social tags (assigned by others) across different categories and sub-categories. While overlap exists, self tags tend to be more factual describing technology expertise, social tags augment the individual tags by adding a personal dimension.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {569–578},
numpages = {10},
keywords = {presentation of self, impression management, human factors, perception of others, experimentation, web 2.0, people tagging, design, social technologies},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250477,
author = {Gulliksen, Jan},
title = {Session Details: Uses of Media &amp; Creation of Web Experiences},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250477},
doi = {10.1145/3250477},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207758,
author = {Malheiros, Miguel and Jennett, Charlene and Patel, Snehalee and Brostoff, Sacha and Sasse, Martina Angela},
title = {Too Close for Comfort: A Study of the Effectiveness and Acceptability of Rich-Media Personalized Advertising},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207758},
doi = {10.1145/2207676.2207758},
abstract = {Online display advertising is predicted to make $29.53 billion this year. Advertisers believe targeted and personalized ads to be more effective, but many users are concerned about their privacy. We conducted a study where 30 participants completed a simulated holiday booking task; each page showing ads with different degrees of personalization. Participants fixated twice as long when ads contained their photo. Participants reported being more likely to notice ads with their photo, holiday destination, and name, but also increasing levels of discomfort with increasing personalization. We conclude that greater personalization in ad content may achieve higher levels of attention, but that the most personalized ads are also the least acceptable. The noticeability benefit in using someone's photo to make them look at an ad may be offset by the privacy cost. As more personal data becomes available to advertisers, it becomes important that these trade-offs are considered.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {579–588},
numpages = {10},
keywords = {targeted advertising, privacy, personalization},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207759,
author = {Leon, Pedro and Ur, Blase and Shay, Richard and Wang, Yang and Balebako, Rebecca and Cranor, Lorrie},
title = {Why Johnny Can't Opt out: A Usability Evaluation of Tools to Limit Online Behavioral Advertising},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207759},
doi = {10.1145/2207676.2207759},
abstract = {We present results of a 45-participant laboratory study investigating the usability of nine tools to limit online behavioral advertising (OBA). We interviewed participants about OBA and recorded their behavior and attitudes as they configured and used a privacy tool, such as a browser plugin that blocks requests to specific URLs, a tool that sets browser cookies indicating a user's preference to opt out of OBA, or the privacy settings built into a web browser. We found serious usability flaws in all tools we tested. Participants found many tools difficult to configure, and tools' default settings were often minimally protective. Ineffective communication, confusing interfaces, and a lack of feedback led many participants to conclude that a tool was blocking OBA when they had not properly configured it to do so. Without being familiar with many advertising companies and tracking technologies, it was difficult for participants to use the tools effectively.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {589–598},
numpages = {10},
keywords = {privacy, online behavioral advertising, usability, cookies},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207760,
author = {Hietanen, Herkko and Salovaara, Antti and Athukorala, Kumaripaba and Liu, Yefeng},
title = {<insert image="">: Helping in the Legal Use of Open Images},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207760},
doi = {10.1145/2207676.2207760},
abstract = {Media creation applications cater poorly to one very common usage: Situations in which the users need media that they do not own and for which they are unwilling to pay. Finding and using externally produced media is currently a cumbersome process. Often, users locate the content using a search engine, copy it into their work, cross their fingers, and hope they do not infringe on any copyrights. While the authors have shared hundreds of millions of images with permissive licenses, the license terms are too complicated for other users to follow. In our studies, we found that even the well-intentioned users still fail to respect copyrights in simple image reuse situations. We therefore introduce an Open Media Retrieval (OMR) model to remedy this problem and supplement it with prototypes that access various legal image sources directly within the creative work flow and provide automatic credits to the original authors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {599–608},
numpages = {10},
keywords = {open content, copyright, open media retrieval, attribution, creative commons},
location = {Austin, Texas, USA},
series = {CHI '12}
}</insert>

@inproceedings{10.1145/2207676.2207761,
author = {Wisniewski, Pamela and Lipford, Heather and Wilson, David},
title = {Fighting for My Space: Coping Mechanisms for Sns Boundary Regulation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207761},
doi = {10.1145/2207676.2207761},
abstract = {Sharing information online via social network sites (SNSs) is at an all-time high, yet research shows that users often exhibit a marked dissatisfaction in using such sites. A compelling explanation for this dichotomy is that users are struggling against their SNS environment in an effort to achieve their preferred levels of privacy for regulating social interactions. Our research investigates users' SNS boundary regulation behavior. This paper presents results from a qualitative interview-based study to identify "coping mechanisms" that users devise outside explicit boundary-regulation interface features in order to manage interpersonal boundaries. Our categorization of such mechanisms provides insight into interaction design issues and opportunities for new SNS features.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {609–618},
numpages = {10},
keywords = {coping, social networking sites, boundary regulation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250478,
author = {Rohs, Michael},
title = {Session Details: Tools for Video + Images},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250478},
doi = {10.1145/3250478},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207763,
author = {Gurevich, Pavel and Lanir, Joel and Cohen, Benjamin and Stone, Ran},
title = {TeleAdvisor: A Versatile Augmented Reality Tool for Remote Assistance},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207763},
doi = {10.1145/2207676.2207763},
abstract = {TeleAdvisor is a novel solution designed to support remote assistance tasks in many real-world scenarios. It consists of a video camera and a small projector mounted at the end of a tele-operated robotic arm. This enables a remote helper to view and interact with the workers' workspace, while controlling the point of view. It also provides the worker with a hands-free transportable device to be placed anywhere in his or her environment. Active tracking of the projection space is used in order to reliably correlate between the camera's view and the projector space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {619–622},
numpages = {4},
keywords = {remote assistance, mobile projector, augmented reality},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207764,
author = {Karrer, Thorsten and Wittenhagen, Moritz and Borchers, Jan},
title = {DragLocks: Handling Temporal Ambiguities in Direct Manipulation Video Navigation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207764},
doi = {10.1145/2207676.2207764},
abstract = {Direct manipulation video navigation (DMVN) systems allow to navigate inside video scenes by spatially manipulating objects in the video. Problems arise when dealing with temporal ambiguities where a time span is projected onto a single point in image space, e.g., when objects stop moving. Existing DMVN systems deal with these cases by either disabling navigation on the paused object or by allowing jumps in the timeline. Both of these workarounds are undesirable as they introduce inconsistency or provoke loss of context. We analyze current practices regarding temporal ambiguities and introduce two new methods to visualize and navigate object pauses. User tests show that the new approaches are better suited for navigation in scenes containing temporal ambiguities and are rated higher in terms of user satisfaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {623–626},
numpages = {4},
keywords = {direct manipulation, accessing pauses, video navigation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207765,
author = {Norris, James and Schn\"{a}delbach, Holger and Qiu, Guoping},
title = {CamBlend: An Object Focused Collaboration Tool},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207765},
doi = {10.1145/2207676.2207765},
abstract = {CamBlend is a new focus-in-context panoramic video collaboration system designed to facilitate the interaction with and around objects in a lightweight, flexible package. As well as the ability to view very high resolution local and remote video that covers a full 180#176; field of view, the system contains a number of tools which facilitate bi-directional pointing between two remote spaces. In the first quasi-naturalistic exploratory study on a focus-in-context video system, we show a number of unique object referencing behaviours, including un-intentional or 'implicit' pointing and a number of scenarios where this was advantageous. Additionally the study highlighted some of the problems inherent in aligning between screen-based and real-world perspectives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {627–636},
numpages = {10},
keywords = {collaboration, focus+context, cscw, interaction analysis},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207766,
author = {Matejka, Justin and Grossman, Tovi and Fitzmaurice, George},
title = {Swift: Reducing the Effects of Latency in Online Video Scrubbing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207766},
doi = {10.1145/2207676.2207766},
abstract = {We first conduct a study using abstracted video content to measure the effects of latency on video scrubbing performance and find that even very small amounts of latency can significantly degrade navigation performance. Based on these results, we present Swift, a technique that supports real-time scrubbing of online videos by overlaying a small, low resolution copy of the video during video scrubbing, and snapping back to the high resolution video when the scrubbing is completed or paused. A second study compares the Swift technique to traditional online video players on a collection of realistic live motion videos and content-specific search tasks which finds the Swift technique reducing completion times by as much as 72% even with a relatively low latency of 500ms. Lastly, we demonstrate that the Swift technique can be easily implemented using modern HTML5 web standards.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {637–646},
numpages = {10},
keywords = {video, video navigation, online streaming},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207767,
author = {Nguyen, Cuong and Niu, Yuzhen and Liu, Feng},
title = {Video Summagator: An Interface for Video Summarization and Navigation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207767},
doi = {10.1145/2207676.2207767},
abstract = {This paper presents Video Summagator (VS), a volume-based interface for video summarization and navigation. VS models a video as a space-time cube and visualizes the video cube using real-time volume rendering techniques. VS empowers a user to interactively manipulate the video cube. We show that VS can quickly summarize both the static and dynamic video content by visualizing the space-time information in 3D. We demonstrate that VS enables a user to quickly look into the video cube, understand the content, and navigate to the content of interest.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {647–650},
numpages = {4},
keywords = {video visualization, summarization, navigation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207768,
author = {Vihavainen, Sami and Mate, Sujeet and Liikkanen, Lassi and Curcio, Igor},
title = {Video as Memorabilia: User Needs for Collaborative Automatic Mobile Video Production},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207768},
doi = {10.1145/2207676.2207768},
abstract = {Digital memorabilia, such as video remixes, can increase the value of attending music events. Remixes can be made using video clips recorded by attendees during the event; however, producing them is a laborious task. In this paper we study the prospects of an automatic video remixing and present the results of a study on users' perceptions and attitudes towards collaborative automatic mobile video production. The three findings are as follows: People assess automatic video remix memorabilia as fairly equal to amateur-made manual ones, even if the manually-created video remixes are better in overall quality; as a remixing actor, a computer can be perceived to be more trustworthy than a human remixer; and, the quality of the video remix and the publication forum of the remix outcome plays a significant role when people are deciding whether or not they need public acknowledgement for their contribution. We conclude by discussing the design implications for collaborative automatic mobile video production.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {651–654},
numpages = {4},
keywords = {crowdsourced media, cscw, memorabilia, live music, mobile video},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250479,
author = {Brush, A.J.},
title = {Session Details: Sustainability &amp; Behavior Change},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250479},
doi = {10.1145/3250479},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207770,
author = {Tomlinson, Bill and Silberman, M. Six and Patterson, Donald and Pan, Yue and Blevis, Eli},
title = {Collapse Informatics: Augmenting the Sustainability &amp; ICT4D Discourse in HCI},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207770},
doi = {10.1145/2207676.2207770},
abstract = {Research in many fields argues that contemporary global industrial civilization will not persist indefinitely in its current form, and may, like many past human societies, eventually collapse. Arguments in environmental studies, anthropology, and other fields indicate that this transformation could begin within the next half-century. While imminent collapse is far from certain, it is prudent to consider now how to develop sociotechnical systems for use in these scenarios. We introduce the notion of collapse informatics---the study, design, and development of sociotechnical systems in the abundant present for use in a future of scarcity---as a complement to ICT4D and mitigation-oriented sustainable HCI. We draw on a variety of literatures to offer a set of relevant concepts and articulate the relationships among them to orient and evaluate collapse informatics work. Observing that collapse informatics poses a unique class of cross-cultural design problems, we sketch the design space of collapse informatics and provide a variety of example projects. We explore points of connection and distinction between collapse informatics and sustainable HCI, ICT4D, and crisis informatics. Finally, we discuss next steps and comment on the potential value of collapse informatics work even in the event that collapse never occurs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {655–664},
numpages = {10},
keywords = {mitigation, sustainable HCI, adaptation, cross-cultural design, ICT4D, sustainability, collapse},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207771,
author = {Pierce, James and Paulos, Eric},
title = {Beyond Energy Monitors: Interaction, Energy, and Emerging Energy Systems},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207771},
doi = {10.1145/2207676.2207771},
abstract = {Motivated by a recent surge of research related to energy and sustainability, this paper presents a review of energy-related work within HCI as well as from literature outside of HCI. Our review of energy-related HCI research identifies a central cluster of work focused on electricity consumption feedback (ECF). Our review of literature outside of HCI highlights a number of emerging energy systems trends of strong relevance to HCI and interaction design, including smart grid, demand response, and distributed generation technologies. We conclude by outlining a range of opportunities for HCI to engage with the experiential, behavioral, social, and cultural aspects of these emerging systems, including highlighting new areas for ECF research that move beyond our field's current focus on energy feedback displays to increase awareness and motivate individual conservation behavior.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {665–674},
numpages = {10},
keywords = {electricity, energy, sustainability, design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207772,
author = {Erickson, Thomas and Podlaseck, Mark and Sahu, Sambit and Dai, Jing D. and Chao, Tian and Naphade, Milind},
title = {The Dubuque Water Portal: Evaluation of the Uptake, Use and Impact of Residential Water Consumption Feedback},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207772},
doi = {10.1145/2207676.2207772},
abstract = {The Dubuque Water Portal is a system aimed at supporting voluntary reductions of water consumption that is intended to be deployed city-wide. It provides each household with fine-grained, near real time feedback on their water consumption, as well as using techniques like social comparison, weekly games, and news and chat to encourage water conservation. This study used logs, a survey and interviews to evaluate a 15-week pilot with 303 households. It describes the Portal's design, and discusses its adoption, use and impacts. The system resulted in a 6.6% decrease in water consumption, and the paper employs qualitative methods to look at the ways in which the Portal was (or wasn't) effective in supporting its users and enabling them to reduce their consumption. The paper concludes with a discussion of design implications for residential feedback systems, and possible engagement models.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {675–684},
numpages = {10},
keywords = {water and energy feedback systems, sustainability, games, smart meters, behavior change, social comparison, water},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207773,
author = {Arroyo, Ernesto and Bonanni, Leonardo and Valkanova, Nina},
title = {Embedded Interaction in a Water Fountain for Motivating Behavior Change in Public Space},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207773},
doi = {10.1145/2207676.2207773},
abstract = {This paper presents an interactive installation for a public space aimed at motivating new behaviors by augmenting the space with subtle and playful audiovisual interaction aesthetically integrated in a shared environment. Designed to complement an existing water fountain with projected light and sound, the embedded installation encouraged people to take a drink, increasing the proportion of people who used the water fountain by 42% to 57% approximately for nine months. Sensors evaluated the impact of multiple interaction modalities on actual water usage. We found that subtle interaction can improve the experience of a space, in particular for those that use it frequently, and lead to sustained behavior change, especially when its modalities are responsive to the level of activity in the space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {685–688},
numpages = {4},
keywords = {augmented public spaces, water, in-the-wild studies, embedded interaction, behavior change, design, persuasion},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207774,
author = {Kehr, Flavius and Hassenzahl, Marc and Laschke, Matthias and Diefenbach, Sarah},
title = {A Transformational Product to Improve Self-Control Strength: The Chocolate Machine},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207774},
doi = {10.1145/2207676.2207774},
abstract = {Lack of self-control is at the heart of many undesirable behaviors, such as overeating, overspending, and even overworking. While the field of Persuasive Technologies searches for ways to change attitudes and behaviors, it often neglects the science of self-control. We present the Chocolate Machine, an exploratory interactive product to train self-control strength based upon Ego Depletion theory. A field study showed the machine to increase perceived self-control over time, while providing a sustained positive experience. This makes the machine transformational, aiming at facilitating behaviors people find worthwhile, but hard to implement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {689–694},
numpages = {6},
keywords = {self-control, experience design, willpower, persuasive technology, transformational product},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250480,
author = {Angeli, Antonello De},
title = {Session Details: Interacting with Robots &amp; Agents},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250480},
doi = {10.1145/3250480},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207776,
author = {Lee, Min Kyung and Kiesler, Sara and Forlizzi, Jodi and Rybski, Paul},
title = {Ripple Effects of an Embedded Social Agent: A Field Study of a Social Robot in the Workplace},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207776},
doi = {10.1145/2207676.2207776},
abstract = {Prior research has investigated the effect of interactive social agents presented on computer screens or embodied in robots. Much of this research has been pursued in labs and brief field studies. Comparatively little is known about social agents embedded in the workplace, where employees have repeated interactions with the agent, alone and with others. We designed a social robot snack delivery service for a workplace, and evaluated the service over four months allowing each employee to use it for two months. We report on how employees responded to the robot and the service over repeated encounters. Employees attached different social roles to the robot beyond a delivery person as they incorporated the robot's visit into their workplace routines. Beyond one-on-one interaction, the robot created a ripple effect in the workplace, triggering new behaviors among employees, including politeness, protection of the robot, mimicry, social comparison, and even jealousy. We discuss the implications of these ripple effects for designing services incorporating social agents.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {695–704},
numpages = {10},
keywords = {organizational technology, field study, longitudinal study, embodiment, human-robot interaction, workplace, social agent, service design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207777,
author = {Andrist, Sean and Pejsa, Tomislav and Mutlu, Bilge and Gleicher, Michael},
title = {Designing Effective Gaze Mechanisms for Virtual Agents},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207777},
doi = {10.1145/2207676.2207777},
abstract = {Virtual agents hold great promise in human-computer interaction with their ability to afford embodied interaction using nonverbal human communicative cues. Gaze cues are particularly important to achieve significant high-level outcomes such as improved learning and feelings of rapport. Our goal is to explore how agents might achieve such outcomes through seemingly subtle changes in gaze behavior and what design variables for gaze might lead to such positive outcomes. Drawing on research in human physiology, we developed a model of gaze behavior to capture these key design variables. In a user study, we investigated how manipulations in these variables might improve affiliation with the agent and learning. The results showed that an agent using affiliative gaze elicited more positive feelings of connection, while an agent using referential gaze improved participants' learning. Our model and findings offer guidelines for the design of effective gaze behaviors for virtual agents.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {705–714},
numpages = {10},
keywords = {learning, virtual agents, gaze, nonverbal behavior, affiliation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250481,
author = {Holmquist, Lars Erik},
title = {Session Details: Hot Moves: Shape-Changing &amp; Thermal Interfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250481},
doi = {10.1145/3250481},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207779,
author = {Halvey, Martin and Wilson, Graham and Brewster, Stephen and Hughes, Stephen},
title = {"Baby It's Cold Outside": The Influence of Ambient Temperature and Humidity on Thermal Feedback},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207779},
doi = {10.1145/2207676.2207779},
abstract = {Thermal feedback is a new area of research in HCI and, as such, there has been very little investigation of the impact of environmental factors on its use for interaction. To address this shortcoming we conducted an experiment to investigate how ambient temperature and humidity could affect the usability of thermal feedback. If environmental conditions affect perception significantly, then it may not be suitable for mobile interactions. Evaluations were conducted outdoors in varying environmental conditions over a period of 5 months. Results showed that the ambient temperature has a significant impact on people's ability to detect stimuli and also their perception of these stimuli. Humidity has a negligible effect for most humidity values. Despite this, previous thermal feedback design recommendations still hold in varying temperatures and humidities showing that thermal feedback is a useful tool for mobile interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {715–724},
numpages = {10},
keywords = {non-visual feedback, environment, temperature, mobile interaction, ambient, humidity, thermal feedback},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207780,
author = {Sugiura, Yuta and Lee, Calista and Ogata, Masayasu and Withana, Anusha and Makino, Yasutoshi and Sakamoto, Daisuke and Inami, Masahiko and Igarashi, Takeo},
title = {PINOKY: A Ring That Animates Your Plush Toys},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207780},
doi = {10.1145/2207676.2207780},
abstract = {PINOKY is a wireless ring-like device that can be externally attached to any plush toy as an accessory that animates the toy by moving its limbs. A user is thus able to instantly convert any plush toy into a soft robot. The user can control the toy remotely or input the movement desired by moving the plush toy and having the data recorded and played back. Unlike other methods for animating plush toys, PINOKY is non-intrusive, so alterations to the toy are not required. In a user study, 1) the roles of plush toys in the participants' daily lives were examined, 2) how participants played with plush toys without PINOKY was observed, 3) how they played with plush toys with PINOKY was observed, and their reactions to the device were surveyed. On the basis of the results, potential applications were conceptualized to illustrate the utility of PINOKY.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {725–734},
numpages = {10},
keywords = {interactive plush toy, ubiquitous computing, tangible user interface, robots},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207781,
author = {Rasmussen, Majken K. and Pedersen, Esben W. and Petersen, Marianne G. and Hornb\ae{}k, Kasper},
title = {Shape-Changing Interfaces: A Review of the Design Space and Open Research Questions},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207781},
doi = {10.1145/2207676.2207781},
abstract = {Shape change is increasingly used in physical user interfaces, both as input and output. Yet, the progress made and the key research questions for shape-changing interfaces are rarely analyzed systematically. We review a sample of existing work on shape-changing interfaces to address these shortcomings. We identify eight types of shape that are transformed in various ways to serve both functional and hedonic design purposes. Interaction with shape-changing interfaces is simple and rarely merges input and output. Three questions are discussed based on the review: (a) which design purposes may shape-changing interfaces be used for, (b) which parts of the design space are not well understood, and (c) why studying user experience with shape-changing interfaces is important.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {735–744},
numpages = {10},
keywords = {organic user interfaces, shape-changing interfaces, non-visual actuators, actuated interfaces, shape displays},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207782,
author = {Nakagawa, Yusuke and Kamimura, Akiya and Kawaguchi, Yoichiro},
title = {MimicTile: A Variable Stiffness Deformable User Interface for Mobile Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207782},
doi = {10.1145/2207676.2207782},
abstract = {MimicTile is a novel variable stiffness deformable user interface for mobile devices that implements two key features. The first feature is an input interface that accepts a variety of deformation-based gestures, providing a user with several ways of interacting with a small mobile device. The other feature is the ability to provide information to the user through haptic feedback by varying the stiffness of the interface. The features are suitable for enhancing mobile applications. They were implemented using only shape memory alloy (SMA) wires as the actuator. SMA wire is extremely flexible, making it ideal for deformable user interfaces. In MimicTile, SMA wires act as both actuators and external input sensors. The actuator function works by altering stiffness based on user input. This study also discusses ideas for further development of deformable user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {745–748},
numpages = {4},
keywords = {haptic feedback, mobile devices, shape memory alloy, deformable user interfaces, gestures},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207783,
author = {Qi, Jie and Buechley, Leah},
title = {Animating Paper Using Shape Memory Alloys},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207783},
doi = {10.1145/2207676.2207783},
abstract = {Our aim is to make shape memory alloys (SMAs) accessible and visible as creative crafting materials by combining them with paper. In this paper, we begin by presenting mechanisms for actuating paper with SMAs along with a set of design guidelines for achieving dramatic movement. We then describe how we tested the usability and educational potential of one of these mechanisms in a workshop where participants, age 9 to 15, made actuated electronic origami cranes. We found that participants were able to successfully build constructions integrating SMAs and paper, that they enjoyed doing so, and were able to learn skills like circuitry design and soldering over the course of the workshop.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {749–752},
numpages = {4},
keywords = {education, origami, paper craft, paper mechanisms, paper electronics, shape memory alloy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250482,
author = {Czerwinski, Mary},
title = {Session Details: Intimacy &amp; Connection},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250482},
doi = {10.1145/3250482},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207785,
author = {Neustaedter, Carman and Greenberg, Saul},
title = {Intimacy in Long-Distance Relationships over Video Chat},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207785},
doi = {10.1145/2207676.2207785},
abstract = {Many couples live a portion of their lives in a long-distance relationship (LDR). This includes a large number of dating college students as well as couples who are geographically-separated because of situational demands such as work. We conducted interviews with individuals in LDRs to understand how they make use of video chat systems to maintain their relationships. In particular, we have investigated how couples use video to "hang out" together and engage in activities over extended periods of time. Our results show that regardless of the relationship situation, video chat affords a unique opportunity for couples to share presence over distance, which in turn provides intimacy. While beneficial, couples still face challenges in using video chat, including contextual (e.g., location of partners, time zones), technical (e.g., mobility, audio/video quality, networking), and personal (e.g., a lack of physicality needed by most for intimate sexual acts) challenges.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {753–762},
numpages = {10},
keywords = {intimacy, video chat, long-distance relationships},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207786,
author = {Park, Young-Woo and Bae, Seok-Hyung and Nam, Tek-Jin},
title = {How Do Couples Use CheekTouch over Phone Calls?},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207786},
doi = {10.1145/2207676.2207786},
abstract = {In this paper we introduce CheekTouch, an affective audio-tactile communication technique that transmits multi-finger touch gestures applied on a sender's mobile phone to a receiver's cheek in real time during a call. We made a pair of CheekTouch prototypes each with a multi-touch screen and vibrotactile display to enable bidirectional touch delivery. We observed four romantic couples in their twenties using our prototype system in a lab setting over five consecutive days, and analyzed how CheekTouch affected their non-verbal and emotional communication. The results of the user study showed that CheekTouch could effectively support audio-tactile communication in various ways - persuading, conveying status, delivering information, emphasizing emotion/words, calling for attention, and being playful.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {763–766},
numpages = {4},
keywords = {affective communication, multi-finger touch, vibrotactile feedback, remote touch, mobile phone, on-the-cheek interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207787,
author = {Kramer, Adam D.I.},
title = {The Spread of Emotion via Facebook},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207787},
doi = {10.1145/2207676.2207787},
abstract = {In this paper we study large-scale emotional contagion through an examination of Facebook status updates. After a user makes a status update with emotional content, their friends are significantly more likely to make a valence-consistent post. This effect is significant even three days later, and even after controlling for prior emotion expressions by both users and their friends. This indicates not only that emotional contagion is possible via text-only communication and that emotions flow through social networks, but also that emotion spreads via indirect communications media.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {767–770},
numpages = {4},
keywords = {social networks, computer-mediated communication, emotion, emotional contagion, facebook},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207788,
author = {Zhao, Xuan and Schwanda Sosik, Victoria and Cosley, Dan},
title = {It's Complicated: How Romantic Partners Use Facebook},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207788},
doi = {10.1145/2207676.2207788},
abstract = {Romantic partners face issues of relational development including managing information privacy, tension between individual and relational needs, and accountability to existing friends. Prior work suggests that affordances of social media might highlight and shape these tensions; to explore this, we asked 20 people to reflect daily for two weeks on feelings and decisions around their own and others' Facebook use related to their relationships. Most generally, we find that tensions arise when romantic partners must manage multiple relationships simultaneously because Facebook audiences are so present and so varied. People also engage in subtle negotiation around and appropriation of Facebook's features to accomplish both personal and relational goals. By capturing both why people make these decisions and how Facebook's affordances support them, we expect our findings to generalize to many other social media tools and to inform theorizing about how these tools affect relational development.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {771–780},
numpages = {10},
keywords = {self-presentation, social media, interpersonal communication, romantic relationships},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207789,
author = {Odom, William and Sellen, Abi and Harper, Richard and Thereska, Eno},
title = {Lost in Translation: Understanding the Possession of Digital Things in the Cloud},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207789},
doi = {10.1145/2207676.2207789},
abstract = {People are amassing larger and more diverse collections of digital things. The emergence of Cloud computing has enabled people to move their personal files to online places, and create new digital things through online services. However, little is known about how this shift might shape people's orientations toward their digital things. To investigate, we conducted in depth interviews with 13 people comparing and contrasting how they think about their possessions, moving from physical ones, to locally kept digital materials, to the online world. Findings are interpreted to detail design and research opportunities in this emerging space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {781–790},
numpages = {10},
keywords = {possession, cloud computing, interactive systems design, materiality, human-centered architectures},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250483,
author = {Friedman, Batya},
title = {Session Details: HCI4D: Business},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250483},
doi = {10.1145/3250483},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2207791,
author = {Sambasivan, Nithya and Cutrell, Edward},
title = {Understanding Negotiation in Airtime Sharing in Low-Income Microenterprises},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2207791},
doi = {10.1145/2207676.2207791},
abstract = {Shared access to airtime is a prominent mode of connectivity access in the developing world. We seek to understand airtime sharing among low-income microenterprises in India (small, low-capital businesses, such as flower sellers and milkmen), that constitute 90% of the total enterprises in India. We introduce social negotiation as the foundation of airtime sharing. We highlight negotiation mechanisms in the microenterprise, showing how shared resources are used towards personal interests amidst tensions and value conflicts, by adapting, modifying, subverting, and repurposing airtime. We then explore the design space of airtime and bandwidth sharing in low-income communities, including designing for negotiation and improving readability of airtime.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {791–800},
numpages = {10},
keywords = {india, negotiation, bandwidth, ict4d, airtime, sharing, microenterprises, hci4d},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250515,
author = {Neustaedter, Carman},
title = {Session Details: Pen + Touch},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250515},
doi = {10.1145/3250515},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208518,
author = {Xin, Yizhong and Bi, Xiaojun and Ren, Xiangshi},
title = {Natural Use Profiles for the Pen: An Empirical Exploration of Pressure, Tilt, and Azimuth},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208518},
doi = {10.1145/2207676.2208518},
abstract = {Inherent pen input modalities such as tip pressure, tilt and azimuth (PTA) have been extensively used as additional input channels in pen-based interactions. We conducted a study to investigate the natural use profiles of PTA, which describes the features of PTA in the course of normal pen use such as writing and drawing. First, the study reveals the ranges of PTA in normal pen use, which can distinguish pen events accidently occurring in normal drawing and writing from those used for mode switch. The natural use profiles also show that azimuth is least likely to cause false pen mode switching while tip pressure is most likely to cause false pen mode switching. Second, the study reveals correlations among various modalities, indicating that pressure plus azimuth is superior to other pairs for dual-modality control.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {801–804},
numpages = {4},
keywords = {azimuth, pen input, natural use profiles, tip pressure, tilt},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208519,
author = {Hasan, Khalad and Yang, Xing-Dong and Bunt, Andrea and Irani, Pourang},
title = {A-Coord Input: Coordinating Auxiliary Input Streams for Augmenting Contextual Pen-Based Interactions},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208519},
doi = {10.1145/2207676.2208519},
abstract = {The human hand can naturally coordinate multiple finger joints, and simultaneously tilt, press and roll a pen to write or draw. For this reason, digital pens are now embedded with auxiliary input sensors to capture these actions. Prior research on auxiliary input channels has mainly investigated them in isolation of one another. In this work, we explore the coordinated use of two auxiliary channels, a class of interaction techniques we refer to as a-coord input. Through two separate experiments, we explore the design space of a-coord input. In the first study we identify if users can successfully coordinate two auxiliary channels. We found a strong degree of coordination between channels. In a second experiment, we evaluate the effectiveness of a-coord input in a task with multiple steps, such as multi-parameter selection and manipulation. We find that a-coord input facilitates coordination even with a complex, aforethought sequential task. Overall our results indicate that users can control at least two auxiliary input channels in conjunction which can facilitate a number of common tasks can on the pen.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {805–814},
numpages = {10},
keywords = {pen roll, pen pressure, pen-based interaction, pen tilt, dual-channel input},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208520,
author = {Findlater, Leah and Wobbrock, Jacob},
title = {Personalized Input: Improving Ten-Finger Touchscreen Typing through Automatic Adaptation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208520},
doi = {10.1145/2207676.2208520},
abstract = {Although typing on touchscreens is slower than typing on physical keyboards, touchscreens offer a critical potential advantage: they are software-based, and, as such, the keyboard layout and classification models used to interpret key presses can dynamically adapt to suit each user's typing pattern. To explore this potential, we introduce and evaluate two novel personalized keyboard interfaces, both of which adapt their underlying key-press classification models. The first keyboard also visually adapts the location of keys while the second one always maintains a visually stable rectangular layout. A three-session user evaluation showed that the keyboard with the stable rectangular layout significantly improved typing speed compared to a control condition with no personalization. Although no similar benefit was found for the keyboard that also offered visual adaptation, overall subjective response to both new touchscreen keyboards was positive. As personalized keyboards are still an emerging area of research, we also outline a design space that includes dimensions of adaptation and key-press classification features.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {815–824},
numpages = {10},
keywords = {adaptive interfaces, touchscreen text input, personalization},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208521,
author = {Guimbreti\`{e}re, Fran\c{c}ois and Nguyen, Chau},
title = {Bimanual Marking Menu for near Surface Interactions},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208521},
doi = {10.1145/2207676.2208521},
abstract = {We describe a mouseless, near-surface version of the Bimanual Marking Menu system. To activate the menu system, users create a pinch gesture with either their index or middle finger to initiate a left click or right click. Then they mark in the 3D space near the interactive area. We demonstrate how the system can be implemented using a commodity range camera such as the Microsoft Kinect, and report on several designs of the 3D marking system.Like the multi-touch marking menu, our system offers a large number of accessible commands. Since it does not rely on contact points to operate, our system leaves the non-dominant hand available for other multi-touch interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {825–828},
numpages = {4},
keywords = {range camera, bimanual marking menu, near surface interactions},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250516,
author = {Schmidt, Albrecht},
title = {Session Details: Affective Presence},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250516},
doi = {10.1145/3250516},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208523,
author = {Jung, Malte and Chong, Jan and Leifer, Larry},
title = {Group Hedonic Balance and Pair Programming Performance: Affective Interaction Dynamics as Indicators of Performance},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208523},
doi = {10.1145/2207676.2208523},
abstract = {Inspired by research on the role of affect in marital interactions, the authors examined whether affective interaction dynamics occurring within a 5-minute slice can predict pair programming performance. In a laboratory experiment with professional programmers, Group Hedonic Balance, a measure of the balance between positive and negative expressed affect, accounted for up to 35% of the variance in not only subjective but also objective pair programming performance. Implications include a new set of methods to study pair programming interactions and recommendations to improve pair programming performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {829–838},
numpages = {10},
keywords = {affective interaction dynamics, thin slicing, emotion, systematic observation of behavior, team performance, pair programming},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208524,
author = {Xu, Anbang and Biehl, Jacob and Rieffel, Eleanor and Turner, Thea and van Melle, William},
title = {Learning How to Feel Again: Towards Affective Workplace Presence and Communication Technologies},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208524},
doi = {10.1145/2207676.2208524},
abstract = {Affect influences workplace collaboration and thereby impacts a workplace's productivity. Participants in face-to-face interactions have many cues to each other's affect, but work is increasingly carried out via computer-mediated channels that lack many of these cues. Current presence systems enable users to estimate the availability of other users, but not their affective states or communication preferences. This work demonstrates the feasibility of estimating affective state and communication preferences from a stream of presence states that are already being shared in a deployed presence system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {839–848},
numpages = {10},
keywords = {presence, affect computing, affect awareness, workplace communication, myunity, affect},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208525,
author = {McDuff, Daniel and Karlson, Amy and Kapoor, Ashish and Roseway, Asta and Czerwinski, Mary},
title = {AffectAura: An Intelligent System for Emotional Memory},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208525},
doi = {10.1145/2207676.2208525},
abstract = {We present AffectAura, an emotional prosthetic that allows users to reflect on their emotional states over long periods of time. We designed a multimodal sensor set-up for continuous logging of audio, visual, physiological and contextual data, a classification scheme for predicting user affective state and an interface for user reflection. The system continuously predicts a user's valence, arousal and engage-ment, and correlates this with information on events, communications and data interactions. We evaluate the interface through a user study consisting of six users and over 240 hours of data, and demonstrate the utility of such a reflection tool. We show that users could reason forward and backward in time about their emotional experiences using the interface, and found this useful.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {849–858},
numpages = {10},
keywords = {affect, visualization, machine learning},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208526,
author = {Slov\'{a}k, Petr and Janssen, Joris and Fitzpatrick, Geraldine},
title = {Understanding Heart Rate Sharing: Towards Unpacking Physiosocial Space},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208526},
doi = {10.1145/2207676.2208526},
abstract = {Advances in biosensing make it possible to include heart rate monitoring in applications and several studies have suggested that heart rate communication has potential for improving social connectedness. However, it is not known how people understand heart rate feedback, or what issues need to be taken into account when designing technologies including heart rate feedback. To explore this, we created a heart rate communication probe that was used in two qualitative in-lab studies and a two-week field trial in participants' homes. Results show that heart rate feedback is a strong connectedness cue that affects the interaction in various ways, depending on a number of interrelated factors. In particular, we found two distinct categories of effects: heart rate as information and heart rate as connection. We propose two mechanisms that could explain these observations and draw out the implications they have for future use of heartbeat communication to support social connectedness or other aspects of social interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {859–868},
numpages = {10},
keywords = {relationships, physiological signals, social connectedness},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250517,
author = {Feiner, Steve},
title = {Session Details: Games: Community + Communication},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250517},
doi = {10.1145/3250517},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208528,
author = {Waern, Annika and Balan, Elena and Nevelsteen, Kim},
title = {Athletes and Street Acrobats: Designing for Play as a Community Value in Parkour},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208528},
doi = {10.1145/2207676.2208528},
abstract = {Participatory design methods face challenges when designing for a widespread youth community. In such projects, it is not enough to design in collaboration with a few selected individuals; one must also strive to understand the community at a deeper level and incorporate its values and practices into the design solution. We report on our process of designing with, and for, an identified youth group: the Parkour and Freerunning community. We show how the successful design relied not only on employing methods of participatory observation and participatory design, but also on acquiring an understanding of the practice as a "fun community", valuing play over achievement and competition.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {869–878},
numpages = {10},
keywords = {fun, freerunning, youth culture, sports, parkour, location-based service, mobile service, design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208529,
author = {Dabbish, Laura and Kraut, Robert and Patton, Jordan},
title = {Communication and Commitment in an Online Game Team},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208529},
doi = {10.1145/2207676.2208529},
abstract = {Theories about commitment in online settings and empirical evidence from offline environments suggest that greater communication in online groups should lead members to become more committed and participate longer. However, experimental evidence is sparse, in part because of difficulties inducing communication online. Moreover, previous work has not identified the route by which communication leads to increased commitment. In this paper, we investigated whether task versus social communication modeled by a leader versus a peer influenced the amount that group members talked and their willingness to continue participating in the group. We conducted an experiment within ad hoc groups in the online game World of Warcraft. Results suggest that communication early in a group's history causes members to talk more later on and that the early communication increases their commitment through its influence on group atmosphere rather than through increased member participation. Social communication by a peer is especially valuable in increasing commitment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {879–888},
numpages = {10},
keywords = {status, online games, virtual teams, commitment, conversation, communication},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208530,
author = {Van Kleek, Max and Smith, Daniel and Stranders, Ruben and schraefel, m.c.},
title = {Twiage: A Game for Finding Good Advice on Twitter},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208530},
doi = {10.1145/2207676.2208530},
abstract = {Millions of recommendations, opinions and experiences are shared across popular microblogging platforms and services each day. Yet much of this content becomes quickly lost in the stream shortly after being posted. This paper looks at the feasibility of identifying useful content in microblog streams so that it might be archived to facilitate wider access and reference. Towards this goal, we present an experiment with a game-with-a-purpose called Twiage that we designed to determine how well the deluge of content in "raw" microblog streams could be turned into filtered and ranked collections using ratings from players. Experiments with Twiage validate the feasibility of applying human-computation to this problem, finding strong agreement about what constitutes the "most useful" content in our test dataset. Second, we compare the effectiveness of various methods of eliciting such ratings, finding that a "choose-best" interface and Elo rating ranking scheme yield the greatest agreement in the fewest rounds. External validation of resulting top-rated twitter content with a domain expert found that while the top Twiage-ranked "tweets" were among the best of the set, there was a tendency for players to also select what we term "weak spam" - e.g., promotional content disguised as articles or reviews, indicating a need for more stringent content filtering.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {889–898},
numpages = {10},
keywords = {games with a purpose, crowdsourcing, social information filtering, microblogs, human-computation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250518,
author = {Siek, Katie},
title = {Session Details: Healthcare + Technology: Putting Patients First},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250518},
doi = {10.1145/3250518},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208532,
author = {Haque, Md and Kawsar, Ferdaus and Adibuzzaman, Mohammad and Ahamed, Sheikh and Love, Richard and Dowla, Rumana and Roe, David and Hossain, Syed and Selim, Reza},
title = {Findings of E-ESAS: A Mobile Based Symptom Monitoring System for Breast Cancer Patients in Rural Bangladesh},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208532},
doi = {10.1145/2207676.2208532},
abstract = {Breast cancer (BC) patients need traditional treatment as well as long term monitoring through an adaptive feedback-oriented treatment mechanism. Here, we present the findings of our 31-week long field study and deployment of e-ESAS - the first mobile-based remote symptom monitoring system (RSMS) developed for rural BC patients where patients are the prime users rather than just the source of data collection at some point of time. We have also shown how 'motivation' and 'automation' have been integrated in e-ESAS and creating a unique motivation-persuasion-motivation cycle where the motivated patients become proactive change agents by persuading others. Though in its early deployment stages (2 months), e-ESAS demonstrates the potential to positively impact the cancer care by (1) helping the doctors with graphical charts of long symptom history (automation), (2) facilitating timely interventions through alert generation (automation) and (3) improving three way communications (doctor-patient-attendant) for a better decision making process (motivation) and thereby improving the quality of life of BC patients.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {899–908},
numpages = {10},
keywords = {symptom monitoring, mobile computing, breast cancer},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208533,
author = {Hartswood, Mark and Procter, Rob and Taylor, Paul and Blot, Lilian and Anderson, Stuart and Rouncefield, Mark and Slack, Roger},
title = {Problems of Data Mobility and Reuse in the Provision of Computer-Based Training for Screening Mammography},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208533},
doi = {10.1145/2207676.2208533},
abstract = {This paper explores some of the problems encountered in using a data archive to build tools for training radiologists to interpret breast screening images. We detail our experiences of taking images and case notes created as part of the work of breast cancer screening and using them as resources for training. Four instances of the use of the archive in training are described in detail and the problems they reveal are discussed. We formulate some general lessons for the mobility and re-use of rich ensembles of data and artefacts drawn from complex professional settings. We argue for a richer representation of the context from which the data was taken than can be achieved through making selected relations explicit in metadata. We also conclude that facilities for correcting and elaborating data should be available at the point of use, and not separated out as distinct activities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {909–918},
numpages = {10},
keywords = {elearning, data sharing, data re-use, metadata, data mobility, data curation, breast cancer screening},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208534,
author = {Comber, Rob and Weeden, Jack and Hoare, Jennifer and Lindsay, Stephen and Teal, Gemma and Macdonald, Alastair and Methven, Lisa and Moynihan, Paula and Olivier, Patrick},
title = {Supporting Visual Assessment of Food and Nutrient Intake in a Clinical Care Setting},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208534},
doi = {10.1145/2207676.2208534},
abstract = {Monitoring nutritional intake is an important aspect of the care of older people, particularly for those at risk of malnutrition. Current practice for monitoring food intake relies on hand written food charts that have several inadequacies. We describe the design and validation of a tool for computer-assisted visual assessment of patient food and nutrient intake. To estimate food consumption, the application compares the pixels the user rubbed out against predefined graphical masks. Weight of food consumed is calculated as a percentage of pixels rubbed out against pixels in the mask. Results suggest that the application may be a useful tool for the conservative assessment of nutritional intake in hospitals.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {919–922},
numpages = {4},
keywords = {portion estimation, dietary assessment, nutrition},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208535,
author = {Huh, Jina and Patel, Rupa and Pratt, Wanda},
title = {Tackling Dilemmas in Supporting 'the Whole Person' in Online Patient Communities},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208535},
doi = {10.1145/2207676.2208535},
abstract = {Online health communities that engage the patient as a whole person attend to personal and medical needs in a holistic manner. Whether current communities structure interaction between health professionals and patients to address the whole person is an open question. To gain insights into this question, we examined a sample of online patient communities to understand health professionals' involvement in bringing in medical advice into peer-patient conversations. We found the communities fall short in supporting the whole person, because (1) patient expertise and clinical expertise generated by health professionals are shared separately, and (2) patients' quantified data are separate from narrative experiences. Such separation in the design of these systems can lead to limitations in addressing patients' interwoven medical and personal concerns. We discuss dilemmas and design implications for supporting the whole person in online patient communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {923–926},
numpages = {4},
keywords = {collaborative help, the whole person, health, online patient communities},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208536,
author = {Mentis, Helena M. and O'Hara, Kenton and Sellen, Abigail and Trivedi, Rikin},
title = {Interaction Proxemics and Image Use in Neurosurgery},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208536},
doi = {10.1145/2207676.2208536},
abstract = {Within medical settings there is a growing interest in exploring touchless interaction technologies. The primary motivation here is to avoid contact during interaction with data so as to maintain asepsis. However, there is another important property of touchless interaction that has significant implications for their use within such settings -- namely that interaction behaviour is spatially distal from the device being interacted with. To further understand these implications we present fieldwork observations of work practice in neurosurgery theatres. Drawing on the notion of interaction proxemics and the theory of F-formations, our analysis articulates the spatial organization of collaborative work practices and interaction in these settings. From this understanding of spatial practices, we discuss opportunities and difficulties relating to the design of touchless interaction technologies for in surgical settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {927–936},
numpages = {10},
keywords = {touchless interaction, surgery, imaging, proxemics, space, health, gestural},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250519,
author = {Wright, Peter},
title = {Session Details: Critical Perspectives on Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250519},
doi = {10.1145/3250519},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208538,
author = {Gaver, William},
title = {What Should We Expect from Research through Design?},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208538},
doi = {10.1145/2207676.2208538},
abstract = {In this essay, I explore several facets of research through design in order to contribute to discussions about how the approach should develop. The essay has three parts. In the first, I review two influential theories from the Philosophy of Science to help reflect on the nature of design theory, concluding that research through design is likely to produce theories that are provisional, contingent, and aspirational. In the second part, I discuss three possible interpretations for the diversity of approaches to research through design, and suggest that this variation need not be seen as a sign of inadequate standards or a lack of cumulative progress in the field, but may be natural for a generative endeavour. In the final section, I suggest that, rather than aiming to develop increasingly comprehensive theories of design, practice based research might better view theory as annotation of realised design examples, and particularly portfolios of related pieces. Overall, I suggest that the design research community should be wary of impulses towards convergence and standardisation, and instead take pride in its aptitude for exploring and speculating, particularising and diversifying, and - especially - its ability to manifest the results in the form of new, conceptually rich artefacts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {937–946},
numpages = {10},
keywords = {annotation, philosophy of science, theory, portfolios, research through design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208539,
author = {Brynjarsdottir, Hronn and H\r{a}kansson, Maria and Pierce, James and Baumer, Eric and DiSalvo, Carl and Sengers, Phoebe},
title = {Sustainably Unpersuaded: How Persuasion Narrows Our Vision of Sustainability},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208539},
doi = {10.1145/2207676.2208539},
abstract = {In this paper we provide a critical analysis of persuasive sustainability research from 2009-2011. Drawing on critical sociological theory of modernism, we argue that persuasion is based on a limited framing of sustainability, human behavior, and their interrelationship. This makes supporting sustainability easier, but leads to characteristic patterns of breakdown. We then detail problems that emerge from this narrowing of vision, such as how the framing of sustainability as the optimization of a simple metrics places technologies incorrectly as objective arbiters over complex issues of sustainability. We conclude by suggesting alternative approaches to move beyond these problems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {947–956},
numpages = {10},
keywords = {critical reflection, sustainable hci, persuasive sustainability, reflective hci, modernism},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208540,
author = {Pierce, James},
title = {Undesigning Technology: Considering the Negation of Design by Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208540},
doi = {10.1145/2207676.2208540},
abstract = {Motivated by substantive concerns with the limitations and negative effects of technology, this paper inquires into the negation of technology as an explicit and intentional aspect of design research within HCI. Building on theory from areas including philosophy and design theory, this paper articulates a theoretical framework for conceptualizing the intentional negation of technology (i.e., the undesign of technology), ranging from the inhibition of particular uses of technology to the total erasure or foreclosure of technology. The framework is then expanded upon to articulate additional areas of undesigning, including self-inhibition, exclusion, removal, replacement, restoration, and safeguarding. In conclusion a scheme is offered for addressing questions concerning the disciplinary scope of undesign in the context of HCI, along with suggestions for ways that undesigning may be more strongly incorporated within HCI research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {957–966},
numpages = {10},
keywords = {sustainability, design theory, design, undesign},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208541,
author = {Kaptelinin, Victor and Nardi, Bonnie},
title = {Affordances in HCI: Toward a Mediated Action Perspective},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208541},
doi = {10.1145/2207676.2208541},
abstract = {Interpretations of the concept of "affordances" in HCI are becoming increasingly diverse, extending well beyond the original Gibsonian meaning. We discuss some of the key analyses of affordances in HCI research and make three related claims. First, we argue that many current interpretations of the concept are essentially incompatible with Gibson. Second, we hold that the Gibsonian concept of affordances, conceptualized as interaction between animals and their environments, provides some important insights, but is, in the end, of limited relevance to HCI research. Third, we call for adopting a mediated action perspective on affordances as an alternative to Gibson's ecological psychology. We outline a view of technology affordances as possibilities for human action mediated by cultural means conceived as a relational property of a three-way interaction between the person, mediational means, and environment. We conclude with a discussion of prospects for future conceptual and empirical explorations of the meditational perspective in HCI research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {967–976},
numpages = {10},
keywords = {technology affordances, mediated action, affordances, ecological psychology},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250520,
author = {Cao, Xiang},
title = {Session Details: I Am How i Touch: Authenticating Users},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250520},
doi = {10.1145/3250520},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208543,
author = {Sae-Bae, Napa and Ahmed, Kowsar and Isbister, Katherine and Memon, Nasir},
title = {Biometric-Rich Gestures: A Novel Approach to Authentication on Multi-Touch Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208543},
doi = {10.1145/2207676.2208543},
abstract = {In this paper, we present a novel multi-touch gesture-based authentication technique. We take advantage of the multi-touch surface to combine biometric techniques with gestural input. We defined a comprehensive set of five-finger touch gestures, based upon classifying movement characteristics of the center of the palm and fingertips, and tested them in a user study combining biometric data collection with usability questions. Using pattern recognition techniques, we built a classifier to recognize unique biometric gesture characteristics of an individual. We achieved a 90% accuracy rate with single gestures, and saw significant improvement when multiple gestures were performed in sequence. We found user ratings of a gestures desirable characteristics (ease, pleasure, excitement) correlated with a gestures actual biometric recognition rate - that is to say, user ratings aligned well with gestural security, in contrast to typical text-based passwords. Based on these results, we conclude that multi-touch gestures show great promise as an authentication mechanism.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {977–986},
numpages = {10},
keywords = {multi-touch interfaces, multi-touch gestures, behavior-based biometric, authentication, password},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208544,
author = {De Luca, Alexander and Hang, Alina and Brudy, Frederik and Lindner, Christian and Hussmann, Heinrich},
title = {Touch Me Once and i Know It's You! Implicit Authentication Based on Touch Screen Patterns},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208544},
doi = {10.1145/2207676.2208544},
abstract = {Password patterns, as used on current Android phones, and other shape-based authentication schemes are highly usable and memorable. In terms of security, they are rather weak since the shapes are easy to steal and reproduce. In this work, we introduce an implicit authentication approach that enhances password patterns with an additional security layer, transparent to the user. In short, users are not only authenticated by the shape they input but also by the way they perform the input. We conducted two consecutive studies, a lab and a long-term study, using Android applications to collect and log data from user input on a touch screen of standard commercial smartphones. Analyses using dynamic time warping (DTW) provided first proof that it is actually possible to distinguish different users and use this information to increase security of the input while keeping the convenience for the user high.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {987–996},
numpages = {10},
keywords = {implicit authentication, password pattern, security},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208545,
author = {Hayashi, Eiji and Pendleton, Bryan and Ozenc, Fatih and Hong, Jason},
title = {WebTicket: Account Management Using Printable Tokens},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208545},
doi = {10.1145/2207676.2208545},
abstract = {Passwords are the most common authentication scheme today. However, it is difficult for people to memorize strong passwords, such as random sequences of characters. Additionally, passwords do not provide protection against phishing attacks. This paper introduces WebTicket, a low cost, easy-to-use and reliable web account management system that uses "tickets", which are tokens that contain a two-dimensional barcode that can be printed or stored on smartphones. Users can log into accounts by presenting the barcodes to webcams connected to computers. Through two lab studies and one field study consisting of 59 participants in total, we found that WebTicket can provide reliable authentication and phishing resilience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {997–1006},
numpages = {10},
keywords = {password, user authentication, usable security},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250521,
author = {Brumby, Duncan},
title = {Session Details: Visionary Models + Tools},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250521},
doi = {10.1145/3250521},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208547,
author = {Heer, Jeffrey and Stone, Maureen},
title = {Color Naming Models for Color Selection, Image Editing and Palette Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208547},
doi = {10.1145/2207676.2208547},
abstract = {Our ability to reliably name colors provides a link between visual perception and symbolic cognition. In this paper, we investigate how a statistical model of color naming can enable user interfaces to meaningfully mimic this link and support novel interactions. We present a method for constructing a probabilistic model of color naming from a large, unconstrained set of human color name judgments. We describe how the model can be used to map between colors and names and define metrics for color saliency (how reliably a color is named) and color name distance (the similarity between colors based on naming patterns). We then present a series of applications that demonstrate how color naming models can enhance graphical interfaces: a color dictionary &amp; thesaurus, name-based pixel selection methods for image editing, and evaluation aids for color palette design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1007–1016},
numpages = {10},
keywords = {image editing, color names, visualization, color modeling, perception, palette design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208548,
author = {Faste, Haakon and Lin, Honray},
title = {The Untapped Promise of Digital Mind Maps},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208548},
doi = {10.1145/2207676.2208548},
abstract = {Digital mind mapping tools present a fertile area for research on human-computer interaction. We evaluated numerous existing mind mapping software applications, performed ethnographic research with a variety of users, and developed a framework of principles to inform the design of future tools for collaborative knowledge management. Our findings suggest an opportunity to advance digital mind mapping beyond the existing state-of-the-art, particularly in the areas of improving workflow, facilitating collaboration, and supporting information storage and retrieval. We conclude with suggestions for how to improve digital mind mapping systems, specifically with regard to real-time collaborative thinking.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1017–1026},
numpages = {10},
keywords = {mind maps, concept maps, collaborative thinking},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208549,
author = {Kong, Nicholas and Grossman, Tovi and Hartmann, Bj\"{o}rn and Agrawala, Maneesh and Fitzmaurice, George},
title = {Delta: A Tool for Representing and Comparing Workflows},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208549},
doi = {10.1145/2207676.2208549},
abstract = {Tutorials and sample workflows for complicated, feature-rich software packages are widely available online. As a result users must differentiate between workflows to choose the most suitable one for their task. We present Delta, an interactive workflow visualization and comparison tool that helps users identify the tradeoffs between workflows. We conducted an initial study to identify the set of attributes users attend to when comparing workflows, finding that they consider result quality, their knowledge of commands, and the efficiency of the workflow. We then designed Delta to surface these attributes at three granularities: a high-level, clustered view; an intermediate-level list view that contains workflow summaries; and a low-level detail view that allows users to compare two individual workflows. Finally, we conducted an evaluation of Delta on a small corpus of 30 workflows and found that the intermediate list view provided the best information density. We conclude with thoughts on how such a workflow comparison system could be scaled up to larger corpora in the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1027–1036},
numpages = {10},
keywords = {workflow comparison, search interfaces, tutorials, delta},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208550,
author = {Cheema, Salman and Gulwani, Sumit and LaViola, Joseph},
title = {QuickDraw: Improving Drawing Experience for Geometric Diagrams},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208550},
doi = {10.1145/2207676.2208550},
abstract = {We present QuickDraw, a prototype sketch-based drawing tool, that facilitates drawing of precise geometry diagrams that are often drawn by students and academics in several scientific disciplines. Quickdraw can recognize sketched diagrams containing components such as line segments and circles, infer geometric constraints relating recognized components, and use this information to beautify the sketched diagram. Beautification is based on a novel algorithm that iteratively computes various sub-components of the components using an extensible set of deductive rules. We conducted a user study comparing QuickDraw with four state-of-the-art diagramming tools: Microsoft PowerPoint, Cabri II Plus, Geometry Expressions and Geometer's SketchPad. Our study demonstrates a strong interest among participants for the use of sketch-based software for drawing geometric diagrams. We also found that QuickDraw enables users to draw precise diagrams faster than the majority of existing tools in some cases, while having them make fewer corrections.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1037–1064},
numpages = {28},
keywords = {sketch-based interfaces, sketch recognition, sketch beautification, geometry constraint solving},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250522,
author = {Lutters, Wayne},
title = {Session Details: It's a Big Web!},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250522},
doi = {10.1145/3250522},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208552,
author = {Kairam, Sanjay and Brzozowski, Mike and Huffaker, David and Chi, Ed},
title = {Talking in Circles: Selective Sharing in Google+},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208552},
doi = {10.1145/2207676.2208552},
abstract = {Online social networks have become indispensable tools for information sharing, but existing 'all-or-nothing' models for sharing have made it difficult for users to target information to specific parts of their networks. In this paper, we study Google+, which enables users to selectively share content with specific 'Circles' of people. Through a combination of log analysis with surveys and interviews, we investigate how active users organize and select audiences for shared content. We find that these users frequently engaged in selective sharing, creating circles to manage content across particular life facets, ties of varying strength, and interest-based groups. Motivations to share spanned personal and informational reasons, and users frequently weighed ''limiting' factors (e.g. privacy, relevance, and social norms) against the desire to reach a large audience. Our work identifies implications for the design of selective sharing mechanisms in social networks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1065–1074},
numpages = {10},
keywords = {group-based access controls, social media, social networks},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208553,
author = {Bao, Patti and Hecht, Brent and Carton, Samuel and Quaderi, Mahmood and Horn, Michael and Gergle, Darren},
title = {Omnipedia: Bridging the Wikipedia Language Gap},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208553},
doi = {10.1145/2207676.2208553},
abstract = {We present Omnipedia, a system that allows Wikipedia readers to gain insight from up to 25 language editions of Wikipedia simultaneously. Omnipedia highlights the similarities and differences that exist among Wikipedia language editions, and makes salient information that is unique to each language as well as that which is shared more widely. We detail solutions to numerous front-end and algorithmic challenges inherent to providing users with a multilingual Wikipedia experience. These include visualizing content in a language-neutral way and aligning data in the face of diverse information organization strategies. We present a study of Omnipedia that characterizes how people interact with information using a multilingual lens. We found that users actively sought information exclusive to unfamiliar language editions and strategically compared how language editions defined concepts. Finally, we briefly discuss how Omnipedia generalizes to other domains facing language barriers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1075–1084},
numpages = {10},
keywords = {wikipedia, hyperlingual, language barrier, text mining, multilingual, user-generated content},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208554,
author = {Muralidharan, Aditi and Gyongyi, Zoltan and Chi, Ed},
title = {Social Annotations in Web Search},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208554},
doi = {10.1145/2207676.2208554},
abstract = {We ask how to best present social annotations on search results, and attempt to find an answer through mixed-method eye-tracking and interview experiments. Current practice is anchored on the assumption that faces and names draw attention; the same presentation format is used independently of the social connection strength and the search query topic. The key findings of our experiments indicate room for improvement. First, only certain social contacts are useful sources of information, depending on the search topic. Second, faces lose their well-documented power to draw attention when rendered small as part of a social search result annotation. Third, and perhaps most surprisingly, social annotations go largely unnoticed by users in general due to selective, structured visual parsing behaviors specific to search result pages. We conclude by recommending improvements to the design and content of social annotations to make them more noticeable and useful.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1085–1094},
numpages = {10},
keywords = {eye tracking, social search, information seeking},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250523,
author = {Heer, Jeff},
title = {Session Details: Tools &amp; Stats in Evaluation Studies},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250523},
doi = {10.1145/3250523},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208556,
author = {Correll, Michael and Albers, Danielle and Franconeri, Steven and Gleicher, Michael},
title = {Comparing Averages in Time Series Data},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208556},
doi = {10.1145/2207676.2208556},
abstract = {Visualizations often seek to aid viewers in assessing the big picture in the data, that is, to make judgments about aggregate properties of the data. In this paper, we present an empirical study of a representative aggregate judgment task: finding regions of maximum average in a series. We show how a theory of perceptual averaging suggests a visual design other than the typically-used line graph. We describe an experiment that assesses participants' ability to estimate averages and make judgments based on these averages. The experiment confirms that this color encoding significantly outperforms the standard practice. The experiment also provides evidence for a perceptual averaging theory.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1095–1104},
numpages = {10},
keywords = {information visualization, line graphs, colorfields, visualization evaluation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208557,
author = {Kaptein, Maurits and Robertson, Judy},
title = {Rethinking Statistical Analysis Methods for CHI},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208557},
doi = {10.1145/2207676.2208557},
abstract = {CHI researchers typically use a significance testing approach to statistical analysis when testing hypotheses during usability evaluations. However, the appropriateness of this approach is under increasing criticism, with statisticians, economists, and psychologists arguing against the use of routine interpretation of results using "canned" p values. Three problems with current practice - the fallacy of the transposed conditional, a neglect of power, and the reluctance to interpret the size of effects - can lead us to build weak theories based on vaguely specified hypothesis, resulting in empirical studies which produce results that are of limited practical or scientific use. Using publicly available data presented at CHI 2010 [19] as an example we address each of the three concerns and promote consideration of the magnitude and actual importance of effects, as opposed to statistical significance, as the new criteria for evaluating CHI research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1105–1114},
numpages = {10},
keywords = {research methods, bayesian statistics, usability evaluation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208558,
author = {Wallner, G\"{u}nter and Kriglstein, Simone},
title = {A Spatiotemporal Visualization Approach for the Analysis of Gameplay Data},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208558},
doi = {10.1145/2207676.2208558},
abstract = {Contemporary video games are highly complex systems with many interacting variables. To make sure that a game provides a satisfying experience, a meaningful analysis of gameplay data is crucial, particularly because the quality of a game directly relates to the experience a user gains from playing it. Automatic instrumentation techniques are increasingly used to record data during playtests. However, the evaluation of the data requires strong analytical skills and experience. The visualization of such gameplay data is essentially an information visualization problem, where a large number of variables have to be displayed in a comprehensible way in order to be able to make global judgments. This paper presents a visualization tool to assist the analytical process. It visualizes the game space as a set of nodes which players visit over the course of a game and is also suitable to observe time-dependent information, such as player distribution. Our tool is not tailored to a specific type of genre. To show the flexibility of our approach we use two different kinds of games as case studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1115–1124},
numpages = {10},
keywords = {clustering, time-dependent visualization, playtesting, player behavior, gameplay visualization},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250524,
author = {Holz, Christian},
title = {Session Details: Values in Research Practice},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250524},
doi = {10.1145/3250524},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208560,
author = {Borning, Alan and Muller, Michael},
title = {Next Steps for Value Sensitive Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208560},
doi = {10.1145/2207676.2208560},
abstract = {Questions of human values often arise in HCI research and practice. Such questions can be difficult to address well, and a principled approach can clarify issues of both theory and practice. One such approach is Value Sensitive Design (VSD), an established theory and method for addressing issues of values in a systematic and principled fashion in the design of information technology. In this essay, we suggest however that the theory and at times the presentation of VSD overclaims in a number of key respects, with the result of inhibiting its more widespread adoption and appropriation. We address these issues by suggesting four topics for next steps in the evolution of VSD: (1) tempering VSD's position on universal values; (2) contextualizing existing and future lists of values that are presented as heuristics for consideration; (3) strengthening the voice of the participants in publications describing VSD investigations; and (4) making clearer the voice of the researchers. We propose new or altered approaches for VSD that address these issues of theory, voice, and reportage.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1125–1134},
numpages = {10},
keywords = {voice, value sensitive design, feminism, universal values, participatory design, qualitative research, design, collaborative ethnography, culturally-specific values},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208561,
author = {Johnson, Rose and Rogers, Yvonne and van der Linden, Janet and Bianchi-Berthouze, Nadia},
title = {Being in the Thick of In-the-Wild Studies: The Challenges and Insights of Researcher Participation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208561},
doi = {10.1145/2207676.2208561},
abstract = {We describe the insights and challenges offered by researcher participation in in-the-wild studies through the comparison of two prototype evaluations with varying levels of researcher participation. By reflecting on these studies we expose different facets of the researcher's role when interacting with participants in in-the-wild studies. We also demonstrate the value of researcher participation in contributing to the way a researcher understands participant responses: aiding rapport, promoting empathy and stimulating the researcher to reflect on their own assumptions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1135–1144},
numpages = {10},
keywords = {prototyping, in-the-wild, participant observation, ethnography},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208562,
author = {Friedman, Batya and Hendry, David},
title = {The Envisioning Cards: A Toolkit for Catalyzing Humanistic and Technical Imaginations},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208562},
doi = {10.1145/2207676.2208562},
abstract = {We introduce the Envisioning Cards - a versatile toolkit for attending to human values during design processes - and discuss their early use. Drawing on almost twenty years of work in value sensitive design, the Envisioning Cards are built upon a set of four envisioning criteria: stakeholders, time, values, and pervasiveness. Each card contains on one side a title and an evocative image related to the card theme; on the flip side, the card shows the envisioning criterion, elaborates on the theme, and provides a focused design activity. Reports from the field demonstrate use in a range of research and design activities including ideation, co-design, heuristic critique, and more.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1145–1148},
numpages = {4},
keywords = {creativity, time, pervasiveness, values, stakeholders, design method, envisioning cards, value sensitive design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250525,
author = {Hourcade, Juan Pablo},
title = {Session Details: Literacy on the Margin},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250525},
doi = {10.1145/3250525},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208564,
author = {Kumar, Anuj and Reddy, Pooja and Tewari, Anuj and Agrawal, Rajat and Kam, Matthew},
title = {Improving Literacy in Developing Countries Using Speech Recognition-Supported Games on Mobile Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208564},
doi = {10.1145/2207676.2208564},
abstract = {Learning to read in a second language is challenging, but highly rewarding. For low-income children in developing countries, this task can be significantly more challenging because of lack of access to high-quality schooling, but can potentially improve economic prospects at the same time. A synthesis of research findings suggests that practicing recalling and vocalizing words for expressing an intended meaning could improve word reading skills - including reading in a second language - more than silent recognition of what the given words mean. Unfortunately, many language learning software do not support this instructional approach, owing to the technical challenges of incorporating speech recognition support to check that the learner is vocalizing the correct word. In this paper, we present results from a usability test and two subsequent experiments that explore the use of two speech recognition-enabled mobile games to help rural children in India read words with understanding. Through a working speech recognition prototype, we discuss two major contributions of this work: first, we give empirical evidence that shows the extent to which productive training (i.e. vocalizing words) is superior to receptive vocabulary training, and discuss the use of scaffolding hints to ""unpack"" factors in the learner's linguistic knowledge that may impact reading. Second, we discuss what our results suggest for future research in HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1149–1158},
numpages = {10},
keywords = {mobile learning, information and communication technology and development (ictd), developing countries, educational games, literacy, speech recognition},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208565,
author = {Kodagoda, Neesha and Wong, B.L. William and Rooney, Chris and Khan, Nawaz},
title = {Interactive Visualization for Low Literacy Users: From Lessons Learnt to Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208565},
doi = {10.1145/2207676.2208565},
abstract = {This paper aims to address the problems low literacy (LL) users face when searching for information online. The first part of this paper summarizes the problems that LL user's face, and establishes a set of design principles for interfaces suitable for LL users. This is followed by a description of how these design principles are mapped to a novel interface for interactive data retrieval. The interface was realized into a working system and evaluated against a traditional web interface for both high literacy (HL) and LL users. The suitability of the designs was analyzed using performance data, subjective feedback and an observational analysis. The findings from the study suggest that LL users perform better and prefer the proposed designs over a traditional web interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1159–1168},
numpages = {10},
keywords = {design principles, low literacy, visualization, mental models, user interface, high literacy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250526,
author = {Dow, Steven},
title = {Session Details: Participatory Design with Older People},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250526},
doi = {10.1145/3250526},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208567,
author = {Vines, John and Blythe, Mark and Lindsay, Stephen and Dunphy, Paul and Monk, Andrew and Olivier, Patrick},
title = {Questionable Concepts: Critique as Resource for Designing with Eighty Somethings},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208567},
doi = {10.1145/2207676.2208567},
abstract = {This paper reports findings from a series of participatory design workshops with ten people over eighty years old. The focus of the workshops was new banking technologies for the older old. Participants were asked to discuss their current experiences of banking and given packs of concept cards which contained design sketches and brief outlines of concepts for new financial services. The designs on the cards were deliberately provocative and aimed to encourage criticism and debate. Participants wrote and drew on the cards and the workshops were recorded and transcribed. The participants were extremely critical of current banking practices and most of the new concepts we presented to them. Their questions and comments led to a number of insights and further iterations. The paper argues that critique is an essential resource for design, both in terms of identifying problems and iterating ideas.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1169–1178},
numpages = {10},
keywords = {eighty somethings, user study methods, participatory design, banking, ageing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208568,
author = {Uzor, Stephen and Baillie, Lynne and Skelton, Dawn},
title = {Senior Designers: Empowering Seniors to Design Enjoyable Falls Rehabilitation Tools},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208568},
doi = {10.1145/2207676.2208568},
abstract = {Studies have shown that functional strength and balance exercises can reduce the risk of falling in older people if they are done on a regular basis. However, the repetitive nature of these exercises; as well as the use of instructional booklets and videos for rehabilitation may discourage seniors to exercise in the home, thereby rendering such an intervention ineffective. Our work proposed that the use of multimodal games -- co-designed with seniors -- could be a way of making falls rehabilitation more enjoyable; thereby improving adherence to home exercise programmes. In this paper, we first explain the process by which we identified barriers to the users' effective interaction with current home rehabilitation tools. We then go on to describe how we actively involved seniors in the initial design, and improvement of useful, enjoyable games for falls rehabilitation. Our findings suggest that seniors are an integral part of the design process and should be directly involved from the concept stages of the design of tools for their rehabilitation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1179–1188},
numpages = {10},
keywords = {user-centered, falls, rehabilitation, design, games},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208569,
author = {Vines, John and Blythe, Mark and Dunphy, Paul and Vlachokyriakos, Vasillis and Teece, Isaac and Monk, Andrew and Olivier, Patrick},
title = {Cheque Mates: Participatory Design of Digital Payments with Eighty Somethings},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208569},
doi = {10.1145/2207676.2208569},
abstract = {This paper describes a project exploring the design of digital payment services in collaboration with 16 people aged over 80. Many older people find cheques valuable as a means of payment but the UK Payments Council recently proposed their abolition. We describe two designs that simultaneously aimed to preserve and augment the paper cheque as a means of making electronic payments. These were devised during participatory design workshops through critical dialogues with our eighty something participants. Workshop discussions resulted in the creation of a real world cheque system where we issued pre-paid cheques without the involvement of banks. This work informed the development of a digital cheque book based on Anoto digital pen technology. The work illustrates the value of participatory design with 'extraordinary' users, such as the eighty somethings, in HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1189–1198},
numpages = {10},
keywords = {cheques, participatory design, ageing, digital payments},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208570,
author = {Lindsay, Stephen and Jackson, Daniel and Schofield, Guy and Olivier, Patrick},
title = {Engaging Older People Using Participatory Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208570},
doi = {10.1145/2207676.2208570},
abstract = {The use of digital technologies is increasingly proposed in health and social care to address the aging population phenomenon but, in practice, the designers of these technologies are ill equipped to design for older people. We suggest participatory design as an approach to improving the quality of design for older people but, based on previous work and our own experiences, identify four central issues that participatory design approaches need to address. We describe an approach to early engagement in design with older people that address each of these issues and some of our experiences applying the approach in a variety of different design projects. We conclude by discussing some of the issues that have been highlighted when attempting apply this approach in different design contexts and the issues that have been raised when working with partners who are less committed to the idea of engaging with older adults in participatory design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1199–1208},
numpages = {10},
keywords = {older people, participatory design, empowerment},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250527,
author = {Bardzell, Shaowen},
title = {Session Details: Personas &amp; Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250527},
doi = {10.1145/3250527},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208572,
author = {Friess, Erin},
title = {Personas and Decision Making in the Design Process: An Ethnographic Case Study},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208572},
doi = {10.1145/2207676.2208572},
abstract = {Personas have become a well-lauded method to aid designers in keeping the needs of the intended user population at the forefront of the design process. However, few studies have ethnographically observed design teams that use personas, and fewer studies have looked specifically at how designers linguistically invoke personas in their decision-making sessions. This discourse analysis of the decision-making sessions of designers at a top tier design firm reveals that although the designers dedicate much time researching, developing, and refining personas, personas themselves make relatively few appearances in the designers' language during decision-making sessions. This study shows that, for persuasive ends, these designers, who are advocates of personas, routinely use other less precise and more designer-centric linguistic mechanisms in lieu of personas. Despite the scarcity of personas in the decision-making sessions, this ethnographic case study also explores the value of personas for this team even when the personas are not explicitly linguistically invoked.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1209–1218},
numpages = {10},
keywords = {personas, ethnography, discourse analysis, design decision-making, user-centered design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208573,
author = {Matthews, Tara and Judge, Tejinder and Whittaker, Steve},
title = {How Do Designers and User Experience Professionals Actually Perceive and Use Personas?},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208573},
doi = {10.1145/2207676.2208573},
abstract = {Personas are a critical method for orienting design and development teams to user experience. Prior work has noted challenges in justifying them to developers. In contrast, it has been assumed that designers and user experience professionals - whose goal is to focus designs on targeted users - will readily exploit personas. This paper examines that assumption. We present the first study of how experienced user-centered design (UCD) practitioners with prior experience deploying personas, use and perceive personas in industrial software design. We identify limits to the persona approach in the context studied. Practitioners used personas almost exclusively for communication, but not for design. Participants identified four problems with personas, finding them abstract, impersonal, misleading and distracting. Our findings argue for a new approach to persona deployment and construction. Personas cannot replace immersion in actual user data. And rather than focusing on creating engaging personas, it is critical to avoid persona attributes that mislead or distract.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1219–1228},
numpages = {10},
keywords = {design tools, personas, evaluation, user study, methods},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250528,
author = {Li, Yang},
title = {Session Details: Kick It! Interfaces for Feet &amp; Walking},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250528},
doi = {10.1145/3250528},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208575,
author = {Alexander, Jason and Han, Teng and Judd, William and Irani, Pourang and Subramanian, Sriram},
title = {Putting Your Best Foot Forward: Investigating Real-World Mappings for Foot-Based Gestures},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208575},
doi = {10.1145/2207676.2208575},
abstract = {Foot-based gestures have recently received attention as an alternative interaction mechanism in situations where the hands are pre-occupied or unavailable. This paper investigates suitable real-world mappings of foot gestures to invoke commands and interact with virtual workspaces. Our first study identified user preferences for mapping common mobile-device commands to gestures. We distinguish these gestures in terms of discrete and continuous command input. While discrete foot-based input has relatively few parameters to control, continuous input requires careful design considerations on how the user's input can be mapped to a control parameter (e.g. the volume knob of the media player). We investigate this issue further through three user-studies. Our results show that rate-based techniques are significantly faster, more accurate and result if far fewer target crossings compared to displacement-based interaction. We discuss these findings and identify design recommendations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1229–1238},
numpages = {10},
keywords = {foot-based interaction, foot gestures, mobile device interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208576,
author = {Bailly, Gilles and M\"{u}ller, J\"{o}rg and Rohs, Michael and Wigdor, Daniel and Kratz, Sven},
title = {ShoeSense: A New Perspective on Gestural Interaction and Wearable Applications},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208576},
doi = {10.1145/2207676.2208576},
abstract = {When the user is engaged with a real-world task it can be inappropriate or difficult to use a smartphone. To address this concern, we developed ShoeSense, a wearable system consisting in part of a shoe-mounted depth sensor pointing upward at the wearer. ShoeSense recognizes relaxed and discreet as well as large and demonstrative hand gestures. In particular, we designed three gesture sets (Triangle, Radial, and Finger-Count) for this setup, which can be performed without visual attention. The advantages of ShoeSense are illustrated in five scenarios: (1) quickly performing frequent operations without reaching for the phone, (2) discreetly performing operations without disturbing others, (3) enhancing operations on mobile devices, (4) supporting accessibility, and (5) artistic performances. We present a proof-of-concept, wearable implementation based on a depth camera and report on a lab study comparing social acceptability, physical and mental demand, and user preference. A second study demonstrates a 94-99% recognition rate of our recognizers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1239–1248},
numpages = {10},
keywords = {sensor placement, shoe, mobile, gesture set, wearable, gestures},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208577,
author = {Richter, Stephan and Holz, Christian and Baudisch, Patrick},
title = {Bootstrapper: Recognizing Tabletop Users by Their Shoes},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208577},
doi = {10.1145/2207676.2208577},
abstract = {In order to enable personalized functionality, such as to log tabletop activity by user, tabletop systems need to recognize users. DiamondTouch does so reliably, but requires users to stay in assigned seats and cannot recognize users across sessions. We propose a different approach based on distinguishing users' shoes. While users are interacting with the table, our system Bootstrapper observes their shoes using one or more depth cameras mounted to the edge of the table. It then identifies users by matching camera images with a database of known shoe images. When multiple users interact, Bootstrapper associates touches with shoes based on hand orientation. The approach can be implemented using consumer depth cameras because (1) shoes offer large distinct features such as color, (2) shoes naturally align themselves with the ground, giving the system a well-defined perspective and thus reduced ambiguity. We report two simple studies in which Bootstrapper recognized participants from a database of 18 users with 95.8% accuracy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1249–1252},
numpages = {4},
keywords = {touch, indoor tracking, user identification, personalization, microsoft surface, tabletop systems},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250529,
author = {Fiebrink, Rebecca},
title = {Session Details: Music across CHI},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250529},
doi = {10.1145/3250529},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208579,
author = {Ghomi, Emilien and Faure, Guillaume and Huot, St\'{e}phane and Chapuis, Olivier and Beaudouin-Lafon, Michel},
title = {Using Rhythmic Patterns as an Input Method},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208579},
doi = {10.1145/2207676.2208579},
abstract = {While interaction techniques that use the temporal dimension have been used for a long time, such as multiple clicks or spring-loaded widgets, more advanced uses of rhythmic patterns have received little attention in HCI. Using such temporal structures to convey information can be particularly useful in situations where the visual channel is overloaded or even not available. In this paper we introduce Rhythmic Interaction as the use of rhythms for input. We report the results of two experiments that show that (i) rhythmic patterns can be efficiently reproduced by novice users and recognized by computer algorithms, and (ii) rhythmic patterns can be memorized as efficiently as traditional shortcuts when associating them with visual commands. Overall, these results demonstrate the potential of Rhythmic Interaction and open the way to a richer repertoire of interaction techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1253–1262},
numpages = {10},
keywords = {rhythm, morse code, patterns, learning, hotkeys, taping},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208580,
author = {McGookin, David and Brewster, Stephen},
title = {PULSE: The Design and Evaluation of an Auditory Display to Provide a Social Vibe},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208580},
doi = {10.1145/2207676.2208580},
abstract = {We present PULSE, a mobile application designed to allow users to gain a 'vibe', an intrinsic understanding of the people, places and activities around their current location, derived from messages on the Twitter social networking site. We compared two auditory presentations of the vibe. One presented message metadata implicitly through modification of spoken message attributes. The other presented the same metadata, but through additional auditory cues. We compared both techniques in a lab and real world study. Additional auditory cues were found to allow for smaller changes in metadata to be more accurately detected, but were least preferred when PULSE was used in context. Results also showed that PULSE enhanced and shaped user understanding, with audio presentation allowing a closer coupling of digital data to the physical world.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1263–1272},
numpages = {10},
keywords = {twitter, geo-social media, location-based services, auditory display},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208581,
author = {Baur, Dominikus and B\"{u}ttgen, Jennifer and Butz, Andreas},
title = {Listening Factors: A Large-Scale Principal Components Analysis of Long-Term Music Listening Histories},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208581},
doi = {10.1145/2207676.2208581},
abstract = {There are about as many strategies for listening to music as there are music enthusiasts. This makes learning about overarching patterns and similarities difficult. In this paper, we present an empirical analysis of long-term music listening histories from the last.fm web service. It gives insight into the most distinguishing factors in music listening behavior. Our sample contains 310 histories with up to six years duration and 48 associated variables describing various user and music characteristics. Using a principal components analysis, we aggregated these variables into 13 components and found several correlations between them. The analysis especially showed the impact of seasons and a listener's interest in novelty on music choice. Using this information, a sample of a user's listening history or even just demographical data could be used to create personalized interfaces and novel recommendation strategies. We close with derived design considerations for future music interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1273–1276},
numpages = {4},
keywords = {music, listening history, lifelogging, latent factors, pca},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250530,
author = {Harrison, Chris},
title = {Session Details: Space: The Interaction Frontier},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250530},
doi = {10.1145/3250530},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208583,
author = {Spindler, Martin and Martsch, Marcel and Dachselt, Raimund},
title = {Going beyond the Surface: Studying Multi-Layer Interaction above the Tabletop},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208583},
doi = {10.1145/2207676.2208583},
abstract = {Lightweight spatially aware displays (Tangible Magic Lenses) are an effective approach for exploring complex information spaces within a tabletop environment. One way of using the 3D space above a horizontal surface is to divide it into discrete parallel layers stacked upon each other. Horizontal and vertical lens movements are essential tasks for the style of multi-layer interaction associated with it. We conducted a comprehensive user study with 18 participants investigating fundamental issues such as optimal number of layers and their thickness, movement and holding accuracies, and physical boundaries of the interaction volume. Findings include a rather limited overall interaction height (44 cm), a different minimal layer thickness for vertical and horizontal search tasks (1 cm/4 cm), a reasonable maximum number of layers depending on the primary task, and a convenience zone in the middle for horizontal search. Derived from that, design guidelines are also presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1277–1286},
numpages = {10},
keywords = {spatially aware displays, tangible magic lens, user study, above the tabletop, multi-layer interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208584,
author = {Tu, Huawei and Ren, Xiangshi and Zhai, Shumin},
title = {A Comparative Evaluation of Finger and Pen Stroke Gestures},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208584},
doi = {10.1145/2207676.2208584},
abstract = {This paper reports an empirical investigation in which participants produced a set of stroke gestures with varying degrees of complexity and in different target sizes using both the finger and the pen. The recorded gestures were then analyzed according to multiple measures characterizing many aspects of stroke gestures. Our findings were as follows: (1) Finger drawn gestures were quite different to pen drawn gestures in basic measures including size ratio and average speed. Finger drawn gestures tended to be larger and faster than pen drawn gestures. They also differed in shape geometry as measured by, for example, aperture of closed gestures, corner shape distance and intersecting points deviation; (2) Pen drawn gestures and finger drawn gestures were similar in several measures including articulation time, indicative angle difference, axial symmetry and proportional shape distance; (3) There were interaction effects between gesture implement (finger vs. pen) and target gesture size and gesture complexity. Our findings show that half of the features we tested were performed well enough by the finger. This finding suggests that "finger friendly" systems should exploit these features when designing finger interfaces and avoid using the other features in which the finger does not perform as well as the pen.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1287–1296},
numpages = {10},
keywords = {gesture design, touch, gesture recognition, finger gestures, pen gestures},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208585,
author = {Song, Peng and Goh, Wooi Boon and Hutama, William and Fu, Chi-Wing and Liu, Xiaopei},
title = {A Handle Bar Metaphor for Virtual Object Manipulation with Mid-Air Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208585},
doi = {10.1145/2207676.2208585},
abstract = {Commercial 3D scene acquisition systems such as the Microsoft Kinect sensor can reduce the cost barrier of realizing mid-air interaction. However, since it can only sense hand position but not hand orientation robustly, current mid-air interaction methods for 3D virtual object manipulation often require contextual and mode switching to perform translation, rotation, and scaling, thus preventing natural continuous gestural interactions. A novel handle bar metaphor is proposed as an effective visual control metaphor between the user's hand gestures and the corresponding virtual object manipulation operations. It mimics a familiar situation of handling objects that are skewered with a bimanual handle bar. The use of relative 3D motion of the two hands to design the mid-air interaction allows us to provide precise controllability despite the Kinect sensor's low image resolution. A comprehensive repertoire of 3D manipulation operations is proposed to manipulate single objects, perform fast constrained rotation, and pack/align multiple objects along a line. Three user studies were devised to demonstrate the efficacy and intuitiveness of the proposed interaction techniques on different virtual manipulation scenarios.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1297–1306},
numpages = {10},
keywords = {3d manipulation, bimanual gestures, user interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208586,
author = {Lichtschlag, Leonhard and Hess, Thomas and Karrer, Thorsten and Borchers, Jan},
title = {Fly: Studying Recall, Macrostructure Understanding, and User Experience of Canvas Presentations},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208586},
doi = {10.1145/2207676.2208586},
abstract = {Most presentation software uses the slide deck metaphor to create visual presentation support. Recently, canvas presentation tools such as Fly or Prezi have begun to use a zoomable free-form canvas to arrange information instead. While their effect on authoring presentations has been evaluated previously, we studied how they impact the audience. In a quantitative study, we compared audience retention and macrostructure understanding of slide deck vs. canvas presentations. We found both approaches to be equally capable of communicating information to the audience. Canvas presentations, however, were rated by participants to better aid them in staying oriented during a talk. This makes canvas presentation tools a promising slideware alternative.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1307–1310},
numpages = {4},
keywords = {canvas presentations, slideware, zoomable user interfaces},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250531,
author = {Thom-Santelli, Jennifer},
title = {Session Details: The Tools of the Trade},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250531},
doi = {10.1145/3250531},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208588,
author = {Morrison, Alistair and McMillan, Donald and Reeves, Stuart and Sherwood, Scott and Chalmers, Matthew},
title = {A Hybrid Mass Participation Approach to Mobile Software Trials},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208588},
doi = {10.1145/2207676.2208588},
abstract = {User trials of mobile applications have followed a steady march out of the lab, and progressively further ''into the wild', recently involving ''app store'-style releases of software to the general public. Yet from our experiences on these mass participation systems and a survey of the literature, we identify a number of reported difficulties. We propose a hybrid methodology that aims to address these, by combining a global software release with a concurrent local trial. A phone-based game, created to explore the uptake and use of ad hoc peer-to-peer networking, was evaluated using this new hybrid trial method, combining a small-scale local trial (11 users) with a ''mass participation' trial (over 10,000 users). Our hybrid method offers many benefits, allowing locally observed findings to be verified, patterns in globally collected data to be explained and addresses ethical issues raised by the mass participation approach. We note trends in the local trial that did not appear in the larger scale deployment, and which would therefore have led to misleading results were the application trialed using ''traditional' methods alone. Based on this study and previous experience, we provide a set of guidelines to researchers working in this area.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1311–1320},
numpages = {10},
keywords = {manets, mass participation, mobile multiplayer games, ad hoc peer-to-peer networking, user trial methodology},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208589,
author = {Dell, Nicola and Vaidyanathan, Vidya and Medhi, Indrani and Cutrell, Edward and Thies, William},
title = {"Yours is Better!": Participant Response Bias in HCI},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208589},
doi = {10.1145/2207676.2208589},
abstract = {Although HCI researchers and practitioners frequently work with groups of people that differ significantly from themselves, little attention has been paid to the effects these differences have on the evaluation of HCI systems. Via 450 interviews in Bangalore, India, we measure participant response bias due to interviewer demand characteristics and the role of social and demographic factors in influencing that bias. We find that respondents are about 2.5x more likely to prefer a technological artifact they believe to be developed by the interviewer, even when the alternative is identical. When the interviewer is a foreign researcher requiring a translator, the bias towards the interviewer's artifact increases to 5x. In fact, the interviewer's artifact is preferred even when it is degraded to be obviously inferior to the alternative. We conclude that participant response bias should receive more attention within the CHI community, especially when designing for underprivileged populations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1321–1330},
numpages = {10},
keywords = {social status, ictd, demand characteristics, interviewer effects, hci4d, bias, methods, culture},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208590,
author = {Weibel, Nadir and Fouse, Adam and Emmenegger, Colleen and Friedman, Whitney and Hutchins, Edwin and Hollan, James},
title = {Digital Pen and Paper Practices in Observational Research},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208590},
doi = {10.1145/2207676.2208590},
abstract = {Researchers from many disciplines are taking advantage of increasingly inexpensive digital video to capture extensive records of human activity in real-world settings. The ability to record and share such data has created a critical moment in the practice and scope of behavioral research. While recent work is beginning to develop techniques for visualizing and interacting with integrated multimodal information collected during field research, navigating and analyzing these large datasets remains challenging and tools are especially needed to support the early stages of data exploration.In this paper we describe digital pen and paper practices in observational research and their integration with ChronoViz, a tool for annotating, visualizing, and analyzing multimodal data. The goal is to better support researchers both in the field, while collecting data, and later in the lab, during analysis. We document the co-evolution of notetaking practices and system features as 28 participants used the tool during an 18-month deployment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1331–1340},
numpages = {10},
keywords = {video analysis, annotations, digital ethnography, activity visualization, paper-digital notes, interactive navigation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208591,
author = {Huang, Jeff and White, Ryen and Buscher, Georg},
title = {User See, User Point: Gaze and Cursor Alignment in Web Search},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208591},
doi = {10.1145/2207676.2208591},
abstract = {Past studies of user behavior in Web search have correlated eye-gaze and mouse cursor positions, and other lines of research have found cursor interactions to be useful in determining user intent and relevant parts of Web pages. However, cursor interactions are not all the same; different types of cursor behavior patterns exist, such as reading, hesitating, scrolling and clicking, each of which has a different meaning. We conduct a search study with 36 subjects and 32 search tasks to determine when gaze and cursor are aligned, and thus when the cursor position is a good proxy for gaze position. We study the effect of time, behavior patterns, user, and search task on the gaze-cursor alignment, findings which lead us to question the maxim that "gaze is well approximated by cursor." These lessons inform an experiment in which we predict the gaze position with better accuracy than simply using the cursor position, improving the state-of-the-art technique for approximating visual attention with the cursor. Our new technique can help make better use of large-scale cursor data in identifying how users examine Web search pages.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1341–1350},
numpages = {10},
keywords = {eye-tracking, cursor, search examination behavior, gaze},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250532,
author = {Light, Ann},
title = {Session Details: Publics &amp; Civic Virtues},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250532},
doi = {10.1145/3250532},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208593,
author = {Le Dantec, Christopher},
title = {Participation and Publics: Supporting Community Engagement},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208593},
doi = {10.1145/2207676.2208593},
abstract = {CHI researchers are beginning a shift from studying technology use in uncommon or exotic communities to designing and deploying technology interventions into those same settings. This paper picks up on these recent developments and further examines the impact and implication of using a bespoke technology platform within the context of providing shelter and basic social services to homeless mothers and their children. I build on findings from a previous system deployment by describing targeted changes made to the technology, the design impetus for making those changes, and the resulting impact those changes had on the relationship between shelter staff, residents, and the information they shared via the system. By way of the findings reported here, I continue to develop the framing of Deweyan publics as a way to scaffold an environmental approach to technology design in contexts with multiple and diverse stakeholders.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1351–1360},
numpages = {10},
keywords = {longitudinal study, constructed publics, qualitative methods, urban computing, homeless},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208594,
author = {Taylor, Nick and Marshall, Justin and Blum-Ross, Alicia and Mills, John and Rogers, Jon and Egglestone, Paul and Frohlich, David M. and Wright, Peter and Olivier, Patrick},
title = {Viewpoint: Empowering Communities with Situated Voting Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208594},
doi = {10.1145/2207676.2208594},
abstract = {Viewpoint is a public voting device developed to allow residents in a disadvantaged community to make their voices heard through a simple, lightweight interaction. This was intended to open a new channel of communication within the community and increase community members' perception of their own efficacy. Local elected officials and community groups were able to post questions on devices located in public spaces, where residents could vote for one of two responses. Question authors were subsequently required to post a response indicating any actions to be taken. Following a two-month trial, we present our experiences and contribute guidelines for the design of public democracy tools and dimensions impacting their effectiveness, including credibility, efficacy and format.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1361–1370},
numpages = {10},
keywords = {information appliances, voting, civic engagement, community, e-democracy, participation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208595,
author = {Lewis, Sheena and Lewis, Dan A.},
title = {Examining Technology That Supports Community Policing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208595},
doi = {10.1145/2207676.2208595},
abstract = {This paper investigates how citizens use technology to support community policing efforts. To explore the types of conversations that are shared on the community web forum, we conducted a qualitative study. We analyzed 865 forum posts from a community crime web forum from April 2004 to June 2011. We found that residents use the forum to: 1) build relationships by strengthening social ties, 2) discuss ways to take collective action, 3) share information and advice, and 4) regulate the social norms of the neighborhood and the web forum. Results suggest that technologies intended for crime prevention should be designed to support communication and problem-solving discussions amongst residents, as opposed to simply providing information to citizens.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1371–1380},
numpages = {10},
keywords = {community policing, crime prevention technologies, collective action, crime},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250533,
author = {Hornof, Anthony},
title = {Session Details: Promoting Educational Opportunity},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250533},
doi = {10.1145/3250533},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208597,
author = {Ogan, Amy and Walker, Erin and Baker, Ryan S.J.D. and Rebolledo Mendez, Genaro and Jimenez Castro, Maynor and Laurentino, Tania and de Carvalho, Adriana},
title = {Collaboration in Cognitive Tutor Use in Latin America: Field Study and Design Recommendations},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208597},
doi = {10.1145/2207676.2208597},
abstract = {Technology has the promise to transform educational prac-tices worldwide. In particular, cognitive tutoring systems are an example of educational technology that has been ex-tremely effective at improving mathematics learning over traditional classroom instruction. However, studies on the effectiveness of tutor software have been conducted mainly in the United States, Canada, and Western Europe, and little is known about how these systems might be used in other contexts with differing classroom practices and values. To understand this question, we studied the usage of mathematics tutoring software for middle school at sites in three Latin American countries: Brazil, Mexico, and Costa Rica. While cognitive tutors were designed for individual use, we found that students in these classrooms worked collaboratively, engaging in interdependently paced work and conducting work away from their own computer. In this paper we present design recommendations for how cognitive tutors might be incorporated into different classroom practices, and better adapted for student needs in these environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1381–1390},
numpages = {10},
keywords = {cultural adaptation, cognitive tutors, collaborative learning},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208598,
author = {Dearman, David and Truong, Khai},
title = {Evaluating the Implicit Acquisition of Second Language Vocabulary Using a Live Wallpaper},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208598},
doi = {10.1145/2207676.2208598},
abstract = {An essential aspect of learning a second language is the acquisition of vocabulary. However, acquiring vocabulary is often a protracted process that requires repeated and spaced exposure; which can be difficult to accommodate given the busyness of daily living. In this paper, we explore if a learner can implicitly acquire second language vocabulary through her explicit interactions with her mobile phone (e.g., navigating multiple home screens) using an interface we developed called Vocabulary Wallpaper. In addition, we examine if the type of vocabulary this technique exposes to the learner, whether it is contextually relevant or contextually-independent will influence the learner's rate of vocabulary acquisition. The results of our study show participants were able to use Vocabulary Wallpaper to increase the number of second language vocabulary that they can recognize and recall and their rate of vocabulary acquisition was significantly greater when presented with a contextually relevant vocabulary than a contextually-independent vocabulary.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1391–1400},
numpages = {10},
keywords = {computer assisted language learning, microlearning, contextualized vocabulary, vocabulary acquisition, mobile},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250534,
author = {Li, Ian},
title = {Session Details: Interfaces for Health &amp; Well Being},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250534},
doi = {10.1145/3250534},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208600,
author = {Bauer, Jared S. and Consolvo, Sunny and Greenstein, Benjamin and Schooler, Jonathan and Wu, Eric and Watson, Nathaniel F. and Kientz, Julie},
title = {ShutEye: Encouraging Awareness of Healthy Sleep Recommendations with a Mobile, Peripheral Display},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208600},
doi = {10.1145/2207676.2208600},
abstract = {Sleep is a basic physiological process essential for good health. However, 40 million people in the U.S. are diagnosed with sleep disorders, with many more undiagnosed. To help address this problem, we developed an application, ShutEye, which provides a peripheral display on the wall-paper of the user's mobile phone to promote awareness about recommended activities that promote good sleep quality. Based on preferences about the user's desired bed-time and activities' for example - consuming caffeine or performing vigorous exercise - ShutEye displays guidance about when engaging in those activities is likely to affect sleep without requiring any explicit interaction from the user. In this paper, we describe ShutEye and results from a four-week field study with 12 participants. Results indicate that a simple, recommendation-based peripheral display can be a very low-effort but still effective method for improving awareness of healthy sleep habits. We also provide recommendations about designing peripheral displays and extend insights for designing health-based mobile applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1401–1410},
numpages = {10},
keywords = {mobile phone, health, peripheral display, wellbeing, mindfulness, sleep hygiene, sleep},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208601,
author = {Pfeifer Vardoulakis, Laura and Karlson, Amy and Morris, Dan and Smith, Greg and Gatewood, Justin and Tan, Desney},
title = {Using Mobile Phones to Present Medical Information to Hospital Patients},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208601},
doi = {10.1145/2207676.2208601},
abstract = {The awareness that hospital patients have of the people and events surrounding their care has a dramatic impact on satisfaction and clinical outcomes. However, patients are often under-informed about even basic aspects of their care. In this work, we hypothesize that mobile devices - which are increasingly available to patients - can be used as real-time information conduits to improve patient awareness and consequently improve patient care. To better understand the unique affordances that mobile devices offer in the hospital setting, we provided twenty-five patients with mobile phones that presented a dynamic, interactive report on their progress, care plan, and care team throughout their emergency department stay. Through interviews with these patients, their visitors, and hospital staff, we explore the benefits and challenges of using the mobile phone as an information display, finding overall that this is a promising approach to improving patient awareness. Furthermore, we demonstrate that only a small number of technology challenges remain before such a system could be deployed without researcher intervention.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1411–1420},
numpages = {10},
keywords = {patient awareness, health information, mobile phone},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208602,
author = {Doherty, Gavin and Coyle, David and Sharry, John},
title = {Engagement with Online Mental Health Interventions: An Exploratory Clinical Study of a Treatment for Depression},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208602},
doi = {10.1145/2207676.2208602},
abstract = {Online mental health interventions can benefit people experiencing a range of psychological difficulties, but attrition is a major problem in real-world deployments. We discuss strategies to reduce attrition, and present SilverCloud, a platform designed to provide more engaging online experiences. The paper presents the results of a practice-based clinical study in which 45 clients and 6 therapists used an online Cognitive Behavioural Therapy programme for depression. Pre and post-treatment assessments, using the Beck Depression Inventory, indicate a statistically significant improvement in depressive symptoms, with a large effect size, for the moderate-to-severe clinical sub-sample receiving standalone online treatment (n=18). This group was the primary target for the intervention. A high level of engagement was also observed compared to a prior online intervention used within the same service. We discuss strategies for design in this area and consider how the quantitative and qualitative results contribute towards our understanding of engagement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1421–1430},
numpages = {10},
keywords = {cognitive behavioural therapy, mental health, depression, online interventions, engagement, healthcare applications},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208603,
author = {Toscos, Tammy and Connelly, Kay and Rogers, Yvonne},
title = {Best Intentions: Health Monitoring Technology and Children},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208603},
doi = {10.1145/2207676.2208603},
abstract = {In this paper we describe findings from two studies aimed at understanding how health monitoring technology affects the parent-child relationship, examining emotional response and barriers to using this type of technology. We present suggestions for the design of health monitoring technology intended to enhance self-care in children without creating parent-child conflict. Our recommendations integrate the study findings, developmental stage specific concerns, and prior HCI research aimed at children's health.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1431–1440},
numpages = {10},
keywords = {pervasive technology, health monitoring, understanding users, diabetes management, children and parents},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250535,
author = {Dunlop, Mark},
title = {Session Details: Needle in the Haystack},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250535},
doi = {10.1145/3250535},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208605,
author = {Song, Minyoung and Quintana, Chris},
title = {Representing "Too Small to See" as "Too Small to See" with Temporal Representation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208605},
doi = {10.1145/2207676.2208605},
abstract = {Teaching and learning the vast range of the sizes of the objects that are too small to see with human eyes (called imperceptible objects) has been a challenging issue in education. Because representation is the only medium that learners can use to make sense of imperceptible phenomena, learners encounter challenges when trying to understand the range of imperceptible sizes. However, the conventional visual representations that are incorporated in many learning technologies tend to direct learners to overestimate the sizes of imperceptible objects. To address this issue, we designed a multimodal representation called ""temporal-aural-visual representation" (or TAVR) to provide students with an alternative way of perceiving and conceptualizing imperceptible sizes. In prior studies it was noticed that learners constructed more refined mental models of the vast range of imperceptible sizes through the TAVR-enhanced learning activity. In this paper, we introduce a recent study that explored how to best augment the temporal experience of the range of imperceptible sizes with supporting modalities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1441–1450},
numpages = {10},
keywords = {multimedia, multimodal representation, learning technology, educational technology, temporal representation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@dataset{10.1145/review-2207676.2208605_R47948,
author = {Hazeltine, Barrett},
title = {Review ID:R47948 for DOI: 10.1145/2207676.2208605},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2207676.2208605_R47948}
}

@inproceedings{10.1145/2207676.2208606,
author = {Davies, Thomas and Beeharee, Ashweeni},
title = {The Case of the Missed Icon: Change Blindness on Mobile Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208606},
doi = {10.1145/2207676.2208606},
abstract = {Insights into human visual attention have benefited many areas of computing, but perhaps most significantly visualisation and UI design [3]. With the proliferation of mobile devices capable of supporting significantly complex applications on small screens, demands on mobile UI design and the user's visual system are becoming greater. In this paper, we report results from an empirical study of human visual attention, specifically the Change Blindness phenomenon, on handheld mobile devices and its impact on mobile UI design. It is arguable that due to the small size of the screen - unlike a typical computer monitor - a greater visual coverage of the mobile device is possible, and that these phenomena may occur less frequently during the use of the device, or even that they may not occur at all. Our study shows otherwise.We tested for Change Blindness (CB) and Inattentional Blindness (IB) in a single-modal, mobile context and attempted to establish factors in the application interface design that induce and/or reduce their occurrences. The results show that both CB and IB can and do occur while using mobile devices. The results also suggest that the number of separate attendable items on-screen is directly proportional to rates of CB. Newly inserted objects were correctly identified more often than changes applied to existing on-screen objects. These results suggest that it is important for mobile UI designers to take these aspects of visual attention into account when designing mobile applications that attempt to deliver information through visual changes or notifications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1451–1460},
numpages = {10},
keywords = {mobile interface design, change blindness, inattentional blindness, visual attention, mobile interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208607,
author = {Thudt, Alice and Hinrichs, Uta and Carpendale, Sheelagh},
title = {The Bohemian Bookshelf: Supporting Serendipitous Book Discoveries through Information Visualization},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208607},
doi = {10.1145/2207676.2208607},
abstract = {Serendipity, a trigger of exciting yet unexpected discoveries, is an important but comparatively neglected factor in information seeking, research, and ideation. We suggest that serendipity can be facilitated through visualization. To explore this, we introduce the Bohemian Bookshelf, which aims to support serendipitous discoveries in the context of digital book collections. The Bohemian Bookshelf consists of five interlinked visualizations each offering a unique overview of the collection. It aims at encouraging serendipity by (1) offering multiple visual access points to the collection, (2) highlighting adjacencies between books, (3) providing flexible visual pathways for exploring the collection, (4) enticing curiosity through abstract, metaphorical, and visually distinct representations of books, and (5) enabling a playful approach to information exploration. A deployment at a library revealed that visitors embraced this approach of utilizing visualization to support open-ended explorations and serendipitous discoveries. This encourages future explorations into promoting serendipity through information visualization.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1461–1470},
numpages = {10},
keywords = {serendipity, library interfaces, information visualization},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208608,
author = {Piorkowski, David and Fleming, Scott and Scaffidi, Christopher and Bogart, Christopher and Burnett, Margaret and John, Bonnie and Bellamy, Rachel and Swart, Calvin},
title = {Reactive Information Foraging: An Empirical Investigation of Theory-Based Recommender Systems for Programmers},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208608},
doi = {10.1145/2207676.2208608},
abstract = {Information Foraging Theory (IFT) has established itself as an important theory to explain how people seek information, but most work has focused more on the theory itself than on how best to apply it. In this paper, we investigate how to apply a reactive variant of IFT (Reactive IFT) to design IFT-based tools, with a special focus on such tools for ill-structured problems. Toward this end, we designed and implemented a variety of recommender algorithms to empirically investigate how to help people with the ill-structured problem of finding where to look for information while debugging source code. We varied the algorithms based on scent type supported (words alone vs. words + code structure), and based on use of foraging momentum to estimate rapidity of foragers' goal changes. Our empirical results showed that (1) using both words and code structure significantly improved the ability of the algorithms to recommend where software developers should look for information; (2) participants used recommendations to discover new places in the code and also as shortcuts to navigate to known places; and (3) low-momentum recommendations were significantly more useful than high-momentum recommendations, suggesting rapid and numerous goal changes in this type of setting. Overall, our contributions include two new recommendation algorithms, empirical evidence about when and why participants found IFT-based recommendations useful, and implications for the design of tools based on Reactive IFT.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1471–1480},
numpages = {10},
keywords = {software maintenance, debugging, information foraging},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250536,
author = {Paul, Sharoda},
title = {Session Details: Understanding Online Communication},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250536},
doi = {10.1145/3250536},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208610,
author = {Sood, Sara and Antin, Judd and Churchill, Elizabeth},
title = {Profanity Use in Online Communities},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208610},
doi = {10.1145/2207676.2208610},
abstract = {As user-generated Web content increases, the amount of inappropriate and/or objectionable content also grows. Several scholarly communities are addressing how to detect and manage such content: research in computer vision focuses on detection of inappropriate images, natural language processing technology has advanced to recognize insults. However, profanity detection systems remain flawed. Current list-based profanity detection systems have two limitations. First, they are easy to circumvent and easily become stale - that is, they cannot adapt to misspellings, abbreviations, and the fast pace of profane slang evolution. Secondly, they offer a one-size fits all solution; they typically do not accommodate domain, community and context specific needs. However, social settings have their own normative behaviors - what is deemed acceptable in one community may not be in another. In this paper, through analysis of comments from a social news site, we provide evidence that current systems are performing poorly and evaluate the cases on which they fail. We then address community differences regarding creation/tolerance of profanity and suggest a shift to more contextually nuanced profanity detection systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1481–1490},
numpages = {10},
keywords = {online communities, comment threads, user-generated content, community management, profanity, negativity},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208611,
author = {Zilouchian Moghaddam, Roshanak and Bailey, Brian and Fu, Wai-Tat},
title = {Consensus Building in Open Source User Interface Design Discussions},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208611},
doi = {10.1145/2207676.2208611},
abstract = {We report results of a study which examines consensus building in user interface design discussions in open source software communities. Our methodology consisted of conducting interviews with designers and developers from the Drupal and Ubuntu communities (N=17) and analyzing a large corpus of interaction data collected from Drupal. The interviews captured user perspectives on the challenges of reaching consensus, techniques employed for building consensus, and the consequences of not reaching consensus. We analyzed the interaction data to determine how different elements of the content, process, and user relationships in the design discussions affect consensus. Our main result shows that design discussions engaging participants with more experience and prior interaction history are more likely to reach consensus. Based on all of our results, we formulated design implications for promoting consensus in distributed discussions of user interface design issues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1491–1500},
numpages = {10},
keywords = {open source software, consensus, design discussion},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208612,
author = {Jamison-Powell, Sue and Linehan, Conor and Daley, Laura and Garbett, Andrew and Lawson, Shaun},
title = {"I Can't Get No Sleep": Discussing #insomnia on Twitter},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208612},
doi = {10.1145/2207676.2208612},
abstract = {Emerging research has shown that social media services are being used as tools to disclose a range of personal health information. To explore the role of social media in the discussion of mental health issues, and with particular reference to insomnia and sleep disorders, a corpus of 18,901 messages - or Tweets - posted to the microblogging social media service Twitter were analysed using a mixed methods approach. We present a content analysis which revealed that Tweets that contained the word "insomnia" contained significantly more negative health information than a random sample, strongly suggesting that individuals were making disclosures about their sleep disorder. A subsequent thematic analysis then revealed two themes: coping with insomnia, and describing the experience of insomnia. We discuss these themes as well as the implications of our research for those in the interaction design community interested in integrating online social media systems in health interventions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1501–1510},
numpages = {10},
keywords = {insomnia, self-disclosure, microblogging, twitter, health, mental health},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208613,
author = {Ploderer, Bernd and Smith, Wally and Howard, Steve and Pearce, Jon and Borland, Ron},
title = {Introducing the Ambivalent Socialiser},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208613},
doi = {10.1145/2207676.2208613},
abstract = {Social interaction can be a powerful strategy for persuasive technology interventions, yet many users are reluctant to engage with others online because they fear pressure, failure and shame. We introduce the 'ambivalent socialiser', a person who is simultaneously keen but also reluctant to engage with others via social media. Our contribution is to identify four approaches to introducing sociality to ambivalent socialisers: structured socialising, incidental socialising, eavesdropping and trace sensing. We discuss the rationale for these approaches and show how they address recent critiques of persuasive technology. Furthermore, we provide actionable insights for designers of persuasive technology by showing how these approaches can be implemented in a social media application.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1511–1514},
numpages = {4},
keywords = {social networks, ambivalent socialiser, persuasive technology, social support, online participation, smoking cessation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208614,
author = {Wang, Yi-Chia and Kraut, Robert},
title = {Twitter and the Development of an Audience: Those Who Stay on Topic Thrive!},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208614},
doi = {10.1145/2207676.2208614},
abstract = {Although economists have long recognized the importance of a critical mass in growing a community, we know little about how it is achieved. This paper examines how initial topical focus influences communities' ability to attract a critical mass. When starting an online community, organizers need to define its initial scope. Topically narrow communities will probably attract a homogeneous group of interested in its content and compatible with each other. However, they are likely to attract fewer members than a diverse one because they offer only a subset of the topics. This paper reports an empirical analysis of longitudinal data collected from Twitter, where each new Twitter poster is considered the seed of a potential social collection. Users who focus the topics of their early tweets more narrowly ultimately attract more followers with more ties among them. Our results shed light on the development of online social networking structures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1515–1518},
numpages = {4},
keywords = {social networking sites, natural language analysis, critical mass, topical focus, community startup, online communities},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250537,
author = {Bertelsen, Olav W.},
title = {Session Details: Performative Emergency Simulation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250537},
doi = {10.1145/3250537},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208616,
author = {Tolmie, Peter and Benford, Steve and Flintham, Martin and Brundell, Patrick and Adams, Matt and Tandavantij, Nicholas and Row Far, Ju and Giannachi, Gabriella},
title = {"Act Natural": Instructions, Compliance and Accountability in Ambulatory Experiences},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208616},
doi = {10.1145/2207676.2208616},
abstract = {This paper uses a detailed ethnographic study of an ambulatory experience, where participants were invited to explore the perspective of two notorious terrorists, in order to discuss the nature of instruction-giving and, most particularly, the methodical ways in which such instructions are complied with. Four distinct layers of compliance are identified, as are three different kinds of accountability, all of which stand potentially at odds with one another. The paper examines the tensions created by this, tensions that are further aggravated by instructions usually being delivered down a thin channel, with considerable surrounding contextual complexity and little opportunity for repair, and uncovers some core challenges for future design in relation to providing instructions for, and orchestrating a range of possible activities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1519–1528},
numpages = {10},
keywords = {instructions, ambulatory experiences, ethnography},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208617,
author = {Ley, Benedikt and Pipek, Volkmar and Reuter, Christian and Wiedenhoefer, Torben},
title = {Supporting Improvisation Work in Inter-Organizational Crisis Management},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208617},
doi = {10.1145/2207676.2208617},
abstract = {Improvisation is necessary when planned decision-making as the main managerial activity does not fit the conditions the practice provides. In these cases, information technology should not just automate planned and structured decisions, but support improvisational practice. In this contribution we present an empirical study about the improvisation work in scenarios of medium to large power outages in Germany. Our focus is on inter-organizational cooperation practices, thus we examined the cooperation of fire departments, police, public administration, electricity infrastructure operators and citizens. Our empirical material allows to describe reasons and conditions for improvisation. Our resulting recommendations address the support of aggregation and visualization of information, a necessary individualization of information compositions, options for collaborative situation assessment, requirements for informal and formal communication, and accessibility of information resources.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1529–1538},
numpages = {10},
keywords = {improvisation, crisis management, ethnography, collaboration},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250538,
author = {Dontcheva, Mira},
title = {Session Details: Crowdsourcing &amp; Peer Production I},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250538},
doi = {10.1145/3250538},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208619,
author = {Heimerl, Kurtis and Gawalt, Brian and Chen, Kuang and Parikh, Tapan and Hartmann, Bj\"{o}rn},
title = {CommunitySourcing: Engaging Local Crowds to Perform Expert Work via Physical Kiosks},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208619},
doi = {10.1145/2207676.2208619},
abstract = {Online labor markets, such as Amazon's Mechanical Turk, have been used to crowdsource simple, short tasks like image labeling and transcription. However, expert knowledge is often lacking in such markets, making it impossible to complete certain classes of tasks. In this work we introduce an alternative mechanism for crowdsourcing tasks that require specialized knowledge or skill: communitysourcing --- the use of physical kiosks to elicit work from specific populations. We investigate the potential of communitysourcing by designing, implementing and evaluating Umati: the communitysourcing vending machine. Umati allows users to earn credits by performing tasks using a touchscreen attached to the machine. Physical rewards (in this case, snacks) are dispensed through traditional vending mechanics. We evaluated whether communitysourcing can accomplish expert work by using Umati to grade Computer Science exams. We placed Umati in a university Computer Science building, targeting students with grading tasks for snacks. Over one week, 328 unique users (302 of whom were students) completed 7771 tasks (7240 by students). 80% of users had never participated in a crowdsourcing market before. We found that Umati was able to grade exams with 2% higher accuracy (at the same price) or at 33% lower cost (at equivalent accuracy) than traditional single-expert grading. Mechanical Turk workers had no success grading the same exams. These results indicate that communitysourcing can successfully elicit high-quality expert work from specific communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1539–1548},
numpages = {10},
keywords = {ubiquitous computing, kiosks, cscw, crowdsourcing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208620,
author = {Chilana, Parmit K. and Ko, Andrew J. and Wobbrock, Jacob O.},
title = {LemonAid: Selection-Based Crowdsourced Contextual Help for Web Applications},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208620},
doi = {10.1145/2207676.2208620},
abstract = {Web-based technical support such as discussion forums and social networking sites have been successful at ensuring that most technical support questions eventually receive helpful answers. Unfortunately, finding these answers is still quite difficult, since users' textual queries are often incomplete, imprecise, or use different vocabularies to describe the same problem. We present LemonAid, a new approach to help that allows users to find help by instead selecting a label, widget, link, image or other user interface (UI) element that they believe is relevant to their problem. LemonAid uses this selection to retrieve previously asked questions and their corresponding answers. The key insight that makes LemonAid work is that users tend to make similar selections in the interface for similar help needs and different selections for different help needs. Our initial evaluation shows that across a corpus of dozens of tasks and thousands of requests, LemonAid retrieved a result for 90% of help requests based on UI selections and, of those, over half had relevant matches in the top 2 results.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1549–1558},
numpages = {10},
keywords = {software support, contextual help, crowdsourced help},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208621,
author = {Kriplean, Travis and Toomim, Michael and Morgan, Jonathan and Borning, Alan and Ko, Andrew},
title = {Is This What You Meant? Promoting Listening on the Web with Reflect},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208621},
doi = {10.1145/2207676.2208621},
abstract = {A lack of support for active listening undermines discussion and deliberation on the web. We contribute a design frame identifying potential improvements to web discussion were listening more explicitly encouraged in interfaces. We explore these concepts through a novel interface, Reflect, that creates a space next to every comment where others can summarize the points they hear the commenter making. Deployments on Slashdot, Wikimedia's Strategic Planning Initiative, and a local civic effort suggest that interfaces for listening may have traction for general use on the web.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1559–1568},
numpages = {10},
keywords = {discussion, listening, deliberation, grounding, web},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208622,
author = {Tang, Anthony and Boring, Sebastian},
title = {#EpicPlay: Crowd-Sourcing Sports Video Highlights},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208622},
doi = {10.1145/2207676.2208622},
abstract = {During a live sports event, many sports fans use social media as a part of their viewing experience, reporting on their thoughts on the event as it unfolds. In this work, we use this information stream to semantically annotate live broadcast sports games, using these annotations to select video highlights from the game. We demonstrate that this approach can be used to select highlights specific for fans of each team, and that these clips reflect the emotions of a fan during a game. Further, we describe how these clips differ from those seen on nightly sportscasts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1569–1572},
numpages = {4},
keywords = {video annotation, microblogging, twitter, broadcast sports, video summarization, crowd-sourcing, sports},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250484,
author = {Lindley, Si\^{a}n},
title = {Session Details: Pasts + Futures},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250484},
doi = {10.1145/3250484},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208278,
author = {Reeves, Stuart},
title = {Envisioning Ubiquitous Computing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208278},
doi = {10.1145/2207676.2208278},
abstract = {Visions of the future are a common feature of discourse within ubiquitous computing and, more broadly, HCI. 'Envisioning', a characteristic future-oriented technique for design thinking, often features as significant part of our research processes in the field. This paper compares, contrasts and critiques the varied ways in which envisionings have been used within ubiquitous computing and traces their relationships to other, different envisionings, such as those of virtual reality. In unpacking envisioning, it argues primarily that envisioning should be foregrounded as a significant concern and interest within HCI. Foregrounding envisioning's frequent mix of fiction, forecasting and extrapolation, the paper recommends changes in the way we read, interpret and use envisionings through taking into account issues such as context and intended audience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1573–1582},
numpages = {10},
keywords = {scenarios, visions of the future, design fiction, forecasting, fiction, ubiquitous computing, teleology},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208279,
author = {Tanenbaum, Joshua and Tanenbaum, Karen and Wakkary, Ron},
title = {Steampunk as Design Fiction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208279},
doi = {10.1145/2207676.2208279},
abstract = {In this paper we look at the Steampunk movement and consider is relevance as a design strategy for HCI and interaction design. Based on a study of online practices of Steampunk, we consider how, as a design fiction, Steampunk provides an explicit model for how to physically realize an ideological and imagined world through design practice. We contend that the practices of DIY and appropriation that are evident in Steampunk design provide a useful set of design strategies and implications for HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1583–1592},
numpages = {10},
keywords = {design strategies, diy, design fiction, appropriation, steampunk},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208280,
author = {Fernaeus, Ylva and Jonsson, Martin and Tholander, Jakob},
title = {Revisiting the Jacquard Loom: Threads of History and Current Patterns in HCI},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208280},
doi = {10.1145/2207676.2208280},
abstract = {In the recent developments of human computer interaction, one central challenge has been to find and to explore alternatives to the legacy of the desktop computer paradigm for interaction design. To investigate this issue further we have conducted an analysis on a fascinating piece of machinery often referred to as one of the predecessors of the modern day computer, the Jacquard loom. In analysing the Jacquard loom we look at qualities in design and interaction from some different perspectives: how historical tools, crafts, and practices can inform interaction design, the role of physicality, materiality, and full-body interaction in order to rethink some current conceptions of interaction and design of computational devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1593–1602},
numpages = {10},
keywords = {sustainable interaction design, materiality, full body interaction, history of HCI},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250485,
author = {Fallman, Daniel},
title = {Session Details: Mobile Computing &amp; Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250485},
doi = {10.1145/3250485},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208282,
author = {Bentley, Frank and Cramer, Henriette and Hamilton, William and Basapur, Santosh},
title = {Drawing the City: Differing Perceptions of the Urban Environment},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208282},
doi = {10.1145/2207676.2208282},
abstract = {In building location-based services, it is important to present information in ways that fit with how individuals view and navigate the city. We conducted an adaptation of the 1970s Mental Maps study by Stanley Milgram in order to better understand differences in people's views of the city based on their backgrounds and technology use. We correlated data from a demographic questionnaire with the map data from our participants to perform a first-of-its-kind statistical analysis on differences in hand-drawn city maps. We describe our study, findings, and design implications for location-based services.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1603–1606},
numpages = {4},
keywords = {urban informatics, cities, location-based services, mobile apps},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208283,
author = {White, Ryen and Buscher, Georg},
title = {Characterizing Local Interests and Local Knowledge},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208283},
doi = {10.1145/2207676.2208283},
abstract = {When searching for destinations and activities, the interests and knowledge of locals and non-locals may vary. In this paper, we compare and contrast the search-related interests of these two groups, and when they share a common interest (in our case, for restaurants), we analyze the quality of the venues they intend to visit. We find differences in interests depending on local knowledge, and that locals generally select higher-quality venues than non-locals. These findings have implications for search and recommendation systems that can personalize results based on local knowledge and leverage that knowledge to benefit non-locals.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1607–1610},
numpages = {4},
keywords = {local knowledge, local interests, web search},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208284,
author = {Boari, Doug and Fraser, Mike and Stanton Fraser, Danae and Cater, Kirsten},
title = {Augmenting Spatial Skills with Mobile Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208284},
doi = {10.1145/2207676.2208284},
abstract = {Mobile devices are increasingly providing novel ways for users to engage with the spaces around them. However, there are few systematic studies of enhancing spatial ability with mobile devices, and applications such as turn-by-turn navigation systems have even been associated with a decline in spatial skills. In this paper we present a study based on the 1971 Shepard-Metzler mental rotation test but performed on a mobile-phone handset and a tablet PC. Our study extends the original experiment with the incorporation of touch and tilt interaction techniques, in order to determine if these affect the use and acquisition of spatial skills. Results suggest that the task is performed faster, and with no significant difference in accuracy, when participants rely on mental abilities rather than interaction techniques to perform 3D rotations. We also find significant differences between tablet and phone handset platforms under interactive conditions. We conclude that applications on mobile devices could be designed to enhance rather than erode spatial skills, by supporting the use of imagination to align real and virtual content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1611–1620},
numpages = {10},
keywords = {mental rotation, mobile interactions, spatial skills},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208285,
author = {Brown, Barry and Laurier, Eric},
title = {The Normal Natural Troubles of Driving with GPS},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208285},
doi = {10.1145/2207676.2208285},
abstract = {In-car GPS based satellite navigation systems are now a common part of driving, providing turn-by-turn navigation instructions on smartphones, portable units or in-car dashboard navigation systems. This paper uses interactional analysis of video data from fifteen naturalistically recorded journeys with GPS to understand the navigational practices deployed by drivers and passengers. The paper documents five types of 'trouble' where GPS systems cause issues and confusion for drivers around: destinations, routes, maps &amp; sensors, timing and relevance and legality. The paper argues that to design GPS systems better we need to move beyond the notion of a docile driver who follows GPS command blindly, to a better understanding of how drivers, passengers and GPS systems work together. We develop this in discussing how technology might better support 'instructed action'.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1621–1630},
numpages = {10},
keywords = {satnav, video analysis, driving, gps, interaction analysis},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250486,
author = {Shaer, Orit},
title = {Session Details: Future Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250486},
doi = {10.1145/3250486},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208287,
author = {Seitlinger, Paul and Ley, Tobias},
title = {Implicit Imitation in Social Tagging: Familiarity and Semantic Reconstruction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208287},
doi = {10.1145/2207676.2208287},
abstract = {Social Tagging is a recent widespread phenomenon on the Web where people assign labels (tags) to Web resources. It has been hypothesized to support collaborative sensemaking. In this paper, we examine some of the cognitive mechanisms assumed to underlie sensemaking, namely social imitation. In line with the semantic imitation model of Fu et al., we assume that implicit processing can be understood as a semantic reconstruction of gist. Our model contrasts this process with a recall of tags from an explicit verbatim memory trace. We tested this model in an experimental study in which after the search task students had to generate tags themselves. We exposed their answers to a multinomial model derived from Fuzzy Trace Theory to obtain independent parameter estimates for the processes of explicit recall, semantic gist reconstruction and familiarity-based recall. A model that assumes all processes are at play explains the data well. Similar to results of our previous study, we find an influence of search intentions on the two processes. Our results have implications for interface and interaction design of social tagging systems, as well as for tag recommendation in these environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1631–1640},
numpages = {10},
keywords = {multinomial modeling, implicit and explicit processing, memory, social tagging},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208288,
author = {Elias, Micheline and Bezerianos, Anastasia},
title = {Annotating BI Visualization Dashboards: Needs &amp; Challenges},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208288},
doi = {10.1145/2207676.2208288},
abstract = {Annotations have been identified as an important aid in analysis record-keeping and recently data discovery. In this paper we discuss the use of annotations on visualization dashboards, with a special focus on business intelligence (BI) analysis. In-depth interviews with experts lead to new annotation needs for multi-chart visualization systems, on which we based the design of a dashboard prototype that supports data and context aware annotations. We focus particularly on novel annotation aspects, such as multi-target annotations, annotation transparency across charts and data dimension levels, as well as annotation properties such as lifetime and validity. Moreover, our prototype is built on a data layer shared among different data-sources and BI applications, allowing cross application annotations. We discuss challenges in supporting context aware annotations in dashboards and other visualizations, such as dealing with changing annotated data, and provide design solutions. Finally we report reactions and recommendations from a different set of expert users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1641–1650},
numpages = {10},
keywords = {annotation, business intelligence, visualization dashboards},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208289,
author = {Back, Jonathan and Cox, Anna and Brumby, Duncan},
title = {Choosing to Interleave: Human Error and Information Access Cost},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208289},
doi = {10.1145/2207676.2208289},
abstract = {People are prone to making more errors when multitasking. Thus in safety-critical environments, it is often considered safer to perform tasks sequentially. Here we explore how the cost of accessing information affects the way people choose to interleave. An empirical study based on a medical scenario was conducted. Participants had to program infusion pump devices using information from a prescription form. The physical and mental effort involved in accessing information was manipulated. This was achieved by varying the physical distance between the prescription form and the devices. We demonstrate that by increasing information access cost, individuals are less likely to omit a required task step. This is because they adopt a more memory-intensive strategy, which encourages interleaving at natural boundaries, i.e., after completing the programming of one of the pumps. Interleaving during programming can result in task steps being forgotten.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1651–1654},
numpages = {4},
keywords = {human error, information access cost, multitasking},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250487,
author = {Gamberini, Luciano},
title = {Session Details: Visualization + Visual Analysis},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250487},
doi = {10.1145/3250487},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208291,
author = {Ziemkiewicz, Caroline and Gomez, Steven and Laidlaw, David},
title = {Analysis within and between Graphs: Observed User Strategies in Immunobiology Visualization},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208291},
doi = {10.1145/2207676.2208291},
abstract = {We present an analysis of two user strategies in interactive data analysis, based on an observational study of four researchers in the immunology domain. Screen captures, video records, interviews, and verbal protocols are used to analyze common procedures in this type of visual data analysis, as well as how these procedures differ among these users. Our findings present a case where skilled users can approach a similar problem with diverging analysis strategies. In the group we observed, strategies fell within two broad categories: within-graph analysis, in which a user generates a few graph layouts and interacts heavily within them, and between-graph analysis, in which a user generates a series of graphs and switches between them in sequence. Differences in strategies lead to distinct interaction patterns, and are likely to be best supported by different interface designs. We characterize these observed strategies and discuss their implications for scientific visualization design and evaluation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1655–1658},
numpages = {4},
keywords = {immunology, visualization, task analysis},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208292,
author = {Metoyer, Ronald and Lee, Bongshin and Henry Riche, Nathalie and Czerwinski, Mary},
title = {Understanding the Verbal Language and Structure of End-User Descriptions of Data Visualizations},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208292},
doi = {10.1145/2207676.2208292},
abstract = {Tools exist for people to create visualizations with their data; however, they are often designed for programmers or they restrict less technical people to pre-defined templates. This can make creating novel, custom visualizations difficult for the average person. For example, existing tools typically do not support syntax or interaction techniques that are natural to end users. To explore how to support a more natural production of data visualizations by end users, we conducted an exploratory study to illuminate the structure and content of the language employed by end users when describing data visualizations. We present our findings from the study and discuss their design implications for future visualization languages and toolkits.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1659–1662},
numpages = {4},
keywords = {end-user programming, information visualization},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208293,
author = {Dunne, Cody and Henry Riche, Nathalie and Lee, Bongshin and Metoyer, Ronald and Robertson, George},
title = {GraphTrail: Analyzing Large Multivariate, Heterogeneous Networks While Supporting Exploration History},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208293},
doi = {10.1145/2207676.2208293},
abstract = {Exploring large network datasets, such as scientific collaboration networks, is challenging because they often contain a large number of nodes and edges in several types and with multiple attributes. Analyses of such networks are often long and complex, and may require several sessions by multiple users. Therefore, it is often difficult for users to recall their own exploration history or share it with others. We introduce GraphTrail, an interactive visualization for analyzing networks through exploration of node and edge aggregates that captures users' interactions and integrates this history directly in the exploration workspace. To facilitate large network analysis, GraphTrail integrates aggregation with familiar charts, drag-and-drop interaction on a canvas, and a novel pivoting mechanism for transitioning between aggregates. Through a three-month field study with a team of archeologists and a qualitative lab study with ten users, we demonstrate the effectiveness of our design and the benefits of integrated exploration history, including analysis comprehension, insight discovery, and exploration recall.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1663–1672},
numpages = {10},
keywords = {data aggregation, visual analytics, network visualization, analytic provenance, exploration history},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208294,
author = {Fisher, Danyel and Popov, Igor and Drucker, Steven and schraefel, m.c.},
title = {Trust Me, i'm Partially Right: Incremental Visualization Lets Analysts Explore Large Datasets Faster},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208294},
doi = {10.1145/2207676.2208294},
abstract = {Queries over large scale (petabyte) data bases often mean waiting overnight for a result to come back. Scale costs time. Such time also means that potential avenues of exploration are ignored because the costs are perceived to be too high to run or even propose them. With sampleAction we have explored whether interaction techniques to present query results running over only incremental samples can be presented as sufficiently trustworthy for analysts both to make closer to real time decisions about their queries and to be more exploratory in their questions of the data. Our work with three teams of analysts suggests that we can indeed accelerate and open up the query process with such incremental visualizations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1673–1682},
numpages = {10},
keywords = {large data, online aggregation, exploratory data analysis, incremental visualizations},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250488,
author = {Izadi, Shahram},
title = {Session Details: Outside the Box},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250488},
doi = {10.1145/3250488},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208296,
author = {Harrison, Chris and Horstman, John and Hsieh, Gary and Hudson, Scott},
title = {Unlocking the Expressivity of Point Lights},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208296},
doi = {10.1145/2207676.2208296},
abstract = {Small point lights (e.g., LEDs) are used as indicators in a wide variety of devices today, from digital watches and toasters, to washing machines and desktop computers. Although exceedingly simple in their output - varying light intensity over time - their design space can be rich. Unfortunately, a survey of contemporary uses revealed that the vocabulary of lighting expression in popular use today is small, fairly unimaginative, and generally ambiguous in meaning. In this paper, we work through a structured design process that points the way towards a much richer set of expressive forms and more effective communication for this very simple medium. In this process, we make use of five different data gathering and evaluation components to leverage the knowledge, opinions and expertise of people outside our team. Our work starts by considering what information is typically conveyed in this medium. We go on to consider potential expressive forms -- how information might be conveyed. We iteratively refine and expand these sets, concluding with ideas gathered from a panel of designers. Our final step was to make use of thousands of human judgments, gathered in a crowd-sourced fashion (265 participants), to measure the suitability of different expressive forms for conveying different information content. This results in a set of recommended light behaviors that mobile devices, such as smartphones, could readily employ.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1683–1692},
numpages = {10},
keywords = {light behavior, notification, expressive, indicator lights, led},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208297,
author = {Baur, Dominikus and Boring, Sebastian and Feiner, Steven},
title = {Virtual Projection: Exploring Optical Projection as a Metaphor for Multi-Device Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208297},
doi = {10.1145/2207676.2208297},
abstract = {Handheld optical projectors provide a simple way to overcome the limited screen real-estate on mobile devices. We present virtual projection (VP), an interaction metaphor inspired by how we intuitively control the position, size, and orientation of a handheld optical projector's image. VP is based on tracking a handheld device without an optical projector and allows selecting a target display on which to position, scale, and orient an item in a single gesture. By relaxing the optical projection metaphor, we can deviate from modeling perspective projection, for example, to constrain scale or orientation, create multiple copies, or offset the image. VP also supports dynamic filtering based on the projection frustum, creating overview and detail applications, and selecting portions of a larger display for zooming and panning. We show exemplary use cases implemented using our optical feature-tracking framework and present the results of a user study demonstrating the effectiveness of VP in complex interactions with large displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1693–1702},
numpages = {10},
keywords = {interaction technique, mobile device, handheld projection},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208298,
author = {Andrews, Daniel and Baber, Chris and Efremov, Sergey and Komarov, Mikhail},
title = {Creating and Using Interactive Narratives: Reading and Writing Branching Comics},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208298},
doi = {10.1145/2207676.2208298},
abstract = {In this paper we describe the design and development of a multi-touch surface and software that challenges current approaches to the production and consumption of comics. Authorship of the comics involves drawing the 'top level' of the story directly onto paper and projecting lower-level narrative elements, such as objects, characters, dialogue, descriptions and/or events onto the paper via a multi-touch interface. In terms of the impact this has upon the experience of reading and writing, the implementation of paper is intended to facilitate the creation of high-level overviews of stories, while the touch surface allows users to generate branches through the addition of artifacts in accordance with certain theories about interactive narratives. This provides the opportunity to participate in the reading and authoring of both traditional, paper-based texts and interactive, digital scenarios. Prototype comics are used to demonstrate this approach to reading and writing top-level and low-level narratives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1703–1712},
numpages = {10},
keywords = {authoring, comics, interactive narratives, multi-touch table, participation, reading},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208299,
author = {Hayashi, Eiji and Rau, Martina and Neo, Zhe Han and Tan, Nastasha and Ramasubramanian, Sriram and Paulos, Eric},
title = {TimeBlocks: Mom, Can I Have Another Block of Time},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208299},
doi = {10.1145/2207676.2208299},
abstract = {Time is a difficult concept for parents to communicate with young children. We developed TimeBlocks, a novel tangible, playful object to facilitate communication about concepts of time with young children. TimeBlocks consists of a set of cubic blocks that function as a physical progress bar. Parents and children can physically manipulate the blocks to represent the concept of time. We evaluated TimeBlocks through a field study in which six families tried TimeBlocks for four days at their homes. The results indicate that TimeBlocks played a useful role in facilitating the often challenging task of time-related communication between parents and children. We also report on a range of observed insightful novel uses of TimeBlocks in our study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1713–1716},
numpages = {4},
keywords = {tangible interface, interaction design for children},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250489,
author = {Haller, Michael},
title = {Session Details: Sensing + Sensible Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250489},
doi = {10.1145/3250489},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208301,
author = {Williamson, John and Murray-Smith, Roderick},
title = {Rewarding the Original: Explorations in Joint User-Sensor Motion Spaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208301},
doi = {10.1145/2207676.2208301},
abstract = {This paper presents a systematic and general technique for establishing a set of motions suitable for use with sensor systems, by drawing performable and measurable motions directly from users. It uses reinforcement which rewards originality to induce users to explore the space of motions they can perform. A decomposition of movements into motion primitives is constructed, among which a meaningful originality metric can be defined. Because the originality measure is defined in terms of the sensed input, the resulting space contains only movements which can both be performed and sensed. We show how this can be used to evaluate the relative performance of different joint user-sensor systems, providing objective analyses of gesture lexicons with regard to the technical limitations of sensors and humans. In particular, we show how the space of motions varies across the arm for a body-mounted inertial sensor.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1717–1726},
numpages = {10},
keywords = {inertial, reinforcement, novelty, motion, gesture, originality},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208302,
author = {Kazi, Rubaiat Habib and Igarashi, Takeo and Zhao, Shengdong and Davis, Richard},
title = {Vignette: Interactive Texture Design and Manipulation with Freeform Gestures for Pen-and-Ink Illustration},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208302},
doi = {10.1145/2207676.2208302},
abstract = {Vignette is an interactive system that facilitates texture creation in pen-and-ink illustrations. Unlike existing systems, Vignette preserves illustrators' workflow and style: users draw a fraction of a texture and use gestures to automatically fill regions with the texture. We currently support both 1D and 2D synthesis with stitching. Our system also has interactive refinement and editing capabilities to provide a higher level texture control, which helps artists achieve their desired vision. A user study with professional artists shows that Vignette makes the process of illustration more enjoyable and that first time users can create rich textures from scratch within minutes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1727–1736},
numpages = {10},
keywords = {sketch based interaction, pen-and-ink illustration, texture design and manipulation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208303,
author = {Fothergill, Simon and Mentis, Helena and Kohli, Pushmeet and Nowozin, Sebastian},
title = {Instructing People for Training Gestural Interactive Systems},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208303},
doi = {10.1145/2207676.2208303},
abstract = {Entertainment and gaming systems such as the Wii and XBox Kinect have brought touchless, body-movement based interfaces to the masses. Systems like these enable the estimation of movements of various body parts from raw inertial motion or depth sensor data. However, the interface developer is still left with the challenging task of creating a system that recognizes these movements as embodying meaning. The machine learning approach for tackling this problem requires the collection of data sets that contain the relevant body movements and their associated semantic labels. These data sets directly impact the accuracy and performance of the gesture recognition system and should ideally contain all natural variations of the movements associated with a gesture. This paper addresses the problem of collecting such gesture datasets. In particular, we investigate the question of what is the most appropriate semiotic modality of instructions for conveying to human subjects the movements the system developer needs them to perform. The results of our qualitative and quantitative analysis indicate that the choice of modality has a significant impact on the performance of the learnt gesture recognition system; particularly in terms of correctness and coverage.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1737–1746},
numpages = {10},
keywords = {machine learning, natural gesture recognition, data collection, instructing movement},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208304,
author = {Kratz, Louis and Morris, Daniel and Saponas, T. Scott},
title = {Making Gestural Input from Arm-Worn Inertial Sensors More Practical},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208304},
doi = {10.1145/2207676.2208304},
abstract = {Gestural input can greatly improve computing experiences away from the desktop, and has the potential to provide always-available access to computing. Specifically, accelerometers and gyroscopes worn on the arm (e.g., in a wristwatch) can sense arm gestures, enabling natural input in untethered scenarios. Two core components of any gesture recognition system are detecting when a gesture is occurring and classifying which gesture a person has performed. In previous work, accurate detection has required significant computation, and high-accuracy classification has come at the cost of training the system on a per-user basis. In this note, we present a gesture detection method whose computational complexity does not depend on the duration of the gesture, and describe a novel method for recognizing gestures with only a single example from a new user.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1747–1750},
numpages = {4},
keywords = {gesture recognition, hidden markov models},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208305,
author = {Woo, Jong-bum and Lim, Youn-kyung},
title = {Clipoid: An Augmentable Short-Distance Wireless Toolkit for 'accidentally Smart Home' Environments},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208305},
doi = {10.1145/2207676.2208305},
abstract = {Unlike lab environments, the existing environment is not built for smart applications, but rather should be "upgraded" to support new technologies. The result of this process is called the "accidentally smart home". We developed Clipoid, an augmentable wireless technology toolkit for supporting the development of an "accidentally smart home" environment. We observed the real user context (static, moving) with Clipoid. We present a guideline for developing an augmentation toolkit, and identify human needs of close proximity physical interaction and multiple users-public platforms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1751–1754},
numpages = {4},
keywords = {accidentally smart home, ubiquitous computing, augmentation toolkit, short-distance wireless connection},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250490,
author = {Dabbish, Laura},
title = {Session Details: Time + Task: Managing Work Life},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250490},
doi = {10.1145/3250490},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208307,
author = {Dugan, Casey and Geyer, Werner and Muller, Michael and Valente, Abel N. and James, Katherine and Levy, Steve and Cheng, Li-Te and Daly, Elizabeth and Brownholtz, Beth},
title = {"I'd Never Get out of This !?$%# Office": Redesigning Time Management for the Enterprise},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208307},
doi = {10.1145/2207676.2208307},
abstract = {In this paper, we propose to improve time management in the enterprise by providing users interactive visualizations of how they are spending their time. Through an interview study (n=21) in a multi-national corporation, we were able to determine the data available for visualizations and the value of a number of general visualizations of employees' calendar data. We develop implications for design in improving personal time management.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1755–1764},
numpages = {10},
keywords = {calendar, visualization, social software, enterprise, time management, persuasive design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208308,
author = {Birnholtz, Jeremy and Bi, Nanyi and Fussell, Susan},
title = {Do You See That I See? Effects of Perceived Visibility on Awareness Checking Behavior},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208308},
doi = {10.1145/2207676.2208308},
abstract = {Informal interactions are a key element of group work, and many theoretical frameworks and systems have been developed to understand and support these conversations in distributed workgroups. In particular, systems used in several recent experiments provided information about others' current activities so that their availability for conversation could be assessed, and interruptions could be timed strategically. One issue with these experimental systems, though, is that many do not notify the observed party that these observations are taking place. There is reason to believe that such notification could be valuable to users, and that it could alter observers' behavior. Moreover, factors such as the perceived urgency of the interruption could affect willingness to violate social norms in gathering information. We report on an experiment assessing the impact of perceived visibility and task urgency on awareness checking behavior. Results suggest that people check more often when they believe their partners do not know they are checking, and more often when the task is time-constrained than when it is not.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1765–1774},
numpages = {10},
keywords = {CMC, interaction, attention, CSCW, awareness},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250491,
author = {Chang, Remco},
title = {Session Details: Search Interfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250491},
doi = {10.1145/3250491},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208310,
author = {Guy, Ido and Ur, Sigalit and Ronen, Inbal and Weber, Sara and Oral, Tolga},
title = {Best Faces Forward: A Large-Scale Study of People Search in the Enterprise},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208310},
doi = {10.1145/2207676.2208310},
abstract = {This paper presents Faces, an application built to enable effective people search in the enterprise. We take advantage of the popularity Faces has gained within a globally distributed enterprise to provide an extensive analysis of how and why people search is used within the organization. Our study is primarily based on an analysis of the Faces query log over a period of more than four months, with over a million queries and tens of thousands of users. The analysis results are presented across four dimensions: queries, users, clicks, and actions, and lay the foundation for further advancement and research on the topic.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1775–1784},
numpages = {10},
keywords = {people search, enterprise search, large scale},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208311,
author = {Bateman, Scott and Teevan, Jaime and White, Ryen W.},
title = {The Search Dashboard: How Reflection and Comparison Impact Search Behavior},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208311},
doi = {10.1145/2207676.2208311},
abstract = {Most searchers do not know how to use Web search engines as effectively as possible. This is due, in part, to search engines not providing feedback about how search behavior can be improved. Because feedback is an essential part of learning, we created the Search Dashboard, which provides an interface for reflection on personal search behavior. The Dashboard aggregates and presents an individual's search history and provides comparisons with that of archetypal expert profiles. Via a five-week study of 90 Search Dash-board users, we find that users are able to change aspects of their behavior to be more in line with that of the presented expert searchers. We also find that reflection can be beneficial, even without comparison, by changing participants' views about their own search skills, what is possible with search, and what aspects of their behavior may influence search success. Our findings demonstrate a new way for search engines to help users modify their search behavior for positive outcomes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1785–1794},
numpages = {10},
keywords = {web search, search expertise, social feedback, reflection},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208312,
author = {Yuan, Xiaojun and White, Ryen},
title = {Building the Trail Best Traveled: Effects of Domain Knowledge on Web Search Trailblazing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208312},
doi = {10.1145/2207676.2208312},
abstract = {Web users can help guide others through complex tasks in unfamiliar domains by creating ordered sequences of queries and Web pages, an activity we call trailblazing. The trails generated from this process can be surfaced by search engines to help users engaged in these tasks. However, if search engines are going to have people generate trails they need to understand whether there is value in using domain experts for trailblazing (or whether novices are sufficient). In this paper, we describe the findings of a user study of trailblazing in the medical domain, comparing domain novices and experts. We observed differences in how people in each of the groups blazed trails and the value of the trails they generated; experts were more efficient and generated better-quality trails. Although there has been significant research on contrasting novice and expert search behaviors, to our knowledge there is no work (at least in the search domain) on establishing whether artifacts created by domain experts (trails in our case) are more valuable than those created by novices. The answer to this question is important for system designers who want to learn whether investing in domain expertise is worthwhile.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1795–1804},
numpages = {10},
keywords = {search trails, trailblazing, domain knowledge, search behavior, search systems},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250492,
author = {Moffatt, Karyn},
title = {Session Details: Music},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250492},
doi = {10.1145/3250492},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208314,
author = {Ahmed, Ahmed and Benford, Steve and Crabtree, Andy},
title = {Digging in the Crates: An Ethnographic Study of DJS' Work},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208314},
doi = {10.1145/2207676.2208314},
abstract = {An ethnographic study uncovers the work of nightclub DJs, which extends far beyond the act of mixing tracks to also encompass collecting music, preparing for performances, and promotion and networking. We reveal how DJs value vinyl and digital formats in different ways, acquire music through 'crate digging', prepare physical and digital crates of music before gigs, and how these underpin improvised selections during their performances. We document how DJs interact with promoters, venues, dancers and other DJs, revealing an etiquette that governs how they select and share music, and manage an ongoing tension between revealing and hiding metadata so as to maintain a competitive edge. We raise implications for technologies to support DJs, while also shedding light on previous studies of music consumption and sharing in other settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1805–1814},
numpages = {10},
keywords = {metadata, sharing, ethnography, performance, djs, music},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208315,
author = {Swift, Benjamin},
title = {Becoming-Sound: Affect and Assemblage in Improvisational Digital Music Making},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208315},
doi = {10.1145/2207676.2208315},
abstract = {The concepts of affect and assemblage proposed by thinkers such as Gilles Deleuze and Brian Massumi can help us to understand the interaction between users and artefacts in interactive systems, particularly in the context of computer-supported improvisation and creativity. In this paper I provide an introduction to affect and assemblage theory for HCI practitioners. I then use a case study of Viscotheque, an iOS-based interface for group musical collaboration, to demonstrate the application of affective analysis in making sense of improvisational group music making.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1815–1824},
numpages = {10},
keywords = {affect, assemblage, improvisation, music making},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208316,
author = {Garcia, J\'{e}r\'{e}mie and Tsandilas, Theophanis and Agon, Carlos and Mackay, Wendy},
title = {Interactive Paper Substrates to Support Musical Creation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208316},
doi = {10.1145/2207676.2208316},
abstract = {We present paper substrates, interactive paper components that support the creation and manipulation of complex musical data. Substrates take different forms, from whole pages to movable strips, and contain or control typed data representations. We conducted participatory design sessions with five professional musicians with extensive experience with music creation tools. All generated innovative uses of paper substrates, manipulating their data, linking multiple representation layers and creating modular, reusable paper elements. The substrates reflect the structure of their computer-based data, but in a much more flexible and adaptable form. We use their prototypes to provide concrete examples of substrates, identify their roles, properties and functions. Finally, we explore their physical and interaction design with an interactive prototype.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1825–1828},
numpages = {4},
keywords = {computer-aided composition, tangible user interfaces, interactive paper, musical creation, participatory design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208317,
author = {Heller, Florian and Borchers, Jan},
title = {DiskPlay: In-Track Navigation on Turntables},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208317},
doi = {10.1145/2207676.2208317},
abstract = {Although digital media playback and storage have several advantages, many DJs still prefer using vinyl records on turntables due to their direct manipulation and haptic qualities. The physical structure of a traditional vinyl record provides important cues for in-track navigation, such as track length or location of loud and soft passages. Digital vinyl systems use a timecode record to combine the advantages of digital playback with the handling DJs are used to. These records contain a special audio signal that is processed by a computer and mapped to information such as playback speed, direction, and absolute position in a track. However, due to their generic nature, timecode records cannot provide visual information to navigate inside individual tracks. Using top-projection, DiskPlay augments a white timecode record with individual visual cues of the medium, such as cue points or track start and end. In our observational study with four professional DJs, participants valued the co-location of visual feedback with the control vinyl on the turntable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1829–1832},
numpages = {4},
keywords = {visualization, tangible interface, augemented reality, music, dj, turntable, digital vinyl system},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250493,
author = {Ullmer, Brygg},
title = {Session Details: ICT4D},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250493},
doi = {10.1145/3250493},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208319,
author = {Densmore, Melissa},
title = {Claim Mobile: When to Fail a Technology},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208319},
doi = {10.1145/2207676.2208319},
abstract = {This paper looks back at the deployment of Claim Mobile, a smartphone-based data collection application developed for a non-governmental organization (NGO) in Southwest Uganda. This NGO subsidizes health facilities by paying for medical services on the basis of claims submitted after the patient consultation, targeting treatment of 99,000 clients between 2006-2011. I successfully tested Claim Mobile in Summer 2008, processing 35 claims over two weeks, and then discontinued it six months later, when it became apparent that integration and scale-up of the technology would be problematic for the NGO. In addition, many issues we hoped to address through technology had been addressed through program management changes instead. I find that a) the context motivating the technology changed over time, b) simpler solutions can be as effective as new technologies, and c) prioritizing the needs of the NGO required abandoning the deployment of Claim Mobile. Thus this paper presents the value of learning from failure in the process of designing for users in developing regions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1833–1842},
numpages = {10},
keywords = {sms, ictd, braided communications, mobile phone, failure, hci4d},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208320,
author = {Gupta, Aakar and Thies, William and Cutrell, Edward and Balakrishnan, Ravin},
title = {MClerk: Enabling Mobile Crowdsourcing in Developing Regions},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208320},
doi = {10.1145/2207676.2208320},
abstract = {Global crowdsourcing platforms could offer new employment opportunities to low-income workers in developing countries. However, the impact to date has been limited because poor communities usually lack access to computers and the Internet.This paper presents mClerk, a new platform for mobile crowdsourcing in developing regions. mClerk sends and receives tasks via SMS, making it accessible to anyone with a low-end mobile phone. However, mClerk is not limited to text: it leverages a little-known protocol to send small images via ordinary SMS, enabling novel distribution of graphical tasks. Via a 5-week deployment in semi-urban India, we demonstrate that mClerk is effective for digitizing local-language documents. Usage of mClerk spread virally from 10 users to 239 users, who digitized over 25,000 words during the study. We discuss the social ecosystem surrounding this usage, and evaluate the potential of mobile crowdsourcing to both deliver and derive value from users in developing regions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1843–1852},
numpages = {10},
keywords = {ictd, digitization, mobile crowdsourcing, microtasks},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250494,
author = {Kane, Shaun},
title = {Session Details: Movement-Based Gameplay},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250494},
doi = {10.1145/3250494},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208322,
author = {Mueller, Florian and Vetere, Frank and Gibbs, Martin and Edge, Darren and Agamanolis, Stefan and Sheridan, Jennifer and Heer, Jeffrey},
title = {Balancing Exertion Experiences},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208322},
doi = {10.1145/2207676.2208322},
abstract = {Exercising with others, such as jogging in pairs, can be socially engaging. However, if exercise partners have different fitness levels then the activity can be too strenuous for one and not challenging enough for the other, compromising engagement and health benefits. Our system, Jogging over a Distance, uses heart rate data and spatialized sound to create an equitable, balanced experience between joggers of different fitness levels who are geographically distributed. We extend this prior work by analyzing the experience of 32 joggers to detail how specific design features facilitated, and hindered, an engaging and balanced exertion experience. With this knowledge, we derive four dimensions that describe a design space for balancing exertion experiences: Measurement, Adjustment, Presentation and Control. We also present six design tactics for creating balanced exertion experiences described by these dimensions. By aiding designers in supporting participants of different physical abilities, we hope to increase participation and engagement with physical activity and facilitate the many benefits it brings about.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1853–1862},
numpages = {10},
keywords = {handicap, heart rate scaling, sport, whole-body interaction, jogging, running, exergame, dynamic difficulty adjustment, exertion interface, dynamic game balancing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208323,
author = {Gao, Yue and Mandryk, Regan},
title = {The Acute Cognitive Benefits of Casual Exergame Play},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208323},
doi = {10.1145/2207676.2208323},
abstract = {Acute cognitive benefits, such as temporary improvements in concentration, can result from as few as ten minutes of exercise; however, most people do not take exercise breaks throughout the day. To motivate people to receive the cognitive benefits of exercising in short bursts multiple times per day, we designed an engaging casual exergame. To determine whether there are cognitive benefits after playing our game, we conducted two studies to compare playing ten minutes of our casual exergame to a sedentary version of the game or exercise on a treadmill. We found acute cognitive benefits of the casual exergame over the sedentary version (but not treadmill exercise), demonstrated by significantly improved performance on two cognitive tests that require focus and concentration. Significant improvements were also found in participants' affective states after playing the casual exergame. Finally, our casual exergame produces similar exertion levels to treadmill exercise, but is perceived as more fun.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1863–1872},
numpages = {10},
keywords = {cognitive benefits, casual game, exergame, exercise, affect},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208324,
author = {Gerling, Kathrin and Livingston, Ian and Nacke, Lennart and Mandryk, Regan},
title = {Full-Body Motion-Based Game Interaction for Older Adults},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208324},
doi = {10.1145/2207676.2208324},
abstract = {Older adults in nursing homes often lead sedentary lifestyles, which reduces their life expectancy. Full-body motion-control games provide an opportunity for these adults to remain active and engaged; these games are not designed with age-related impairments in mind, which prevents the games from being leveraged to increase the activity levels of older adults. In this paper, we present two studies aimed at developing game design guidelines for full-body motion controls for older adults experiencing age-related changes and impairments. Our studies also demonstrate how full-body motion-control games can accommodate a variety of user abilities, have a positive effect on mood and, by extension, the emotional well-being of older adults. Based on our studies, we present seven guidelines for the design of full-body interaction in games. The guidelines are designed to foster safe physical activity among older adults, thereby increasing their quality of life.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1873–1882},
numpages = {10},
keywords = {design, games, entertainment, older adults},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250495,
author = {Skov, Mikael B.},
title = {Session Details: Beyond Paper},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250495},
doi = {10.1145/3250495},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208326,
author = {Zyto, Sacha and Karger, David and Ackerman, Mark and Mahajan, Sanjoy},
title = {Successful Classroom Deployment of a Social Document Annotation System},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208326},
doi = {10.1145/2207676.2208326},
abstract = {NB is an in-place collaborative document annotation website targeting students reading lecture notes and draft textbooks. Serving as a discussion forum in the document margins, NB lets users ask and answer questions about their reading material as they are reading. NB users can read and annotate documents using their web browsers, without any special plug-ins. We describe the NB system and its evaluation in real class environment, where students used it to submit their reading assignments, ask questions and get or provide feedback. We show that this tool can be and has been successfully incorporated into a number of different classes at different institutions. To understand how and why, we focus on a particularly successful class deployment where the instructor adapted his teaching style to take students' comment into account. We analyze the annotation practices that were observed - including the way geographic locality was exploited in ways unavailable in traditional forums - and discuss general design implications for online annotation tools in academia.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1883–1892},
numpages = {10},
keywords = {e-learning, annotation, collaboration, hypertext, forum},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208327,
author = {Hinckley, Ken and Bi, Xiaojun and Pahud, Michel and Buxton, Bill},
title = {Informal Information Gathering Techniques for Active Reading},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208327},
doi = {10.1145/2207676.2208327},
abstract = {GatherReader is a prototype e-reader with both pen and multi-touch input that illustrates several interesting design trade-offs to fluidly interleave content consumption behaviors (reading and flipping through pages) with information gathering and informal organization activities geared to active reading tasks. These choices include (1) relaxed precision for casual specification of scope; (2) multiple object collection via a visual clipboard; (3) flexible workflow via deferred action; and (4) complementary use of pen+touch. Our design affords active reading by limiting the transaction costs for secondary subtasks, while keeping users in the flow of the primary task of reading itself.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1893–1896},
numpages = {4},
keywords = {informal interaction, touch, pen, tablets, active reading},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208328,
author = {Heinrichs, Felix and Schreiber, Daniel and Huber, Jochen and M\"{u}hlh\"{a}user, Max},
title = {Toward a Theory of Interaction in Mobile Paper-Digital Ensembles},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208328},
doi = {10.1145/2207676.2208328},
abstract = {Although smartphones and tablets become increasingly popular, pen and paper continues to play an important role in mobile practices, such as note taking or creative discussions. Applications designed to combine the benefits of both worlds in a mobile paper-digital ensemble require a theoretical understanding of interaction, to inform the design of adequate interaction techniques. To fill this void, we propose a theory based on the results of a stimulus driven exploratory study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1897–1900},
numpages = {4},
keywords = {theory, pen and paper interaction, mobile, digital pen, anoto},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250496,
author = {Russell, Daniel M.},
title = {Session Details: Sensory Interaction Modalities},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250496},
doi = {10.1145/3250496},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208330,
author = {Cohn, Gabe and Morris, Daniel and Patel, Shwetak and Tan, Desney},
title = {Humantenna: Using the Body as an Antenna for Real-Time Whole-Body Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208330},
doi = {10.1145/2207676.2208330},
abstract = {Computer vision and inertial measurement have made it possible for people to interact with computers using whole-body gestures. Although there has been rapid growth in the uses and applications of these systems, their ubiquity has been limited by the high cost of heavily instrumenting either the environment or the user. In this paper, we use the human body as an antenna for sensing whole-body gestures. Such an approach requires no instrumentation to the environment, and only minimal instrumentation to the user, and thus enables truly mobile applications. We show robust gesture recognition with an average accuracy of 93% across 12 whole-body gestures, and promising results for robust location classification within a building. In addition, we demonstrate a real-time interactive system which allows a user to interact with a computer using whole-body gestures},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1901–1910},
numpages = {10},
keywords = {electrical noise, body as antenna, whole-body gestures},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208331,
author = {Gupta, Sidhant and Morris, Daniel and Patel, Shwetak and Tan, Desney},
title = {SoundWave: Using the Doppler Effect to Sense Gestures},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208331},
doi = {10.1145/2207676.2208331},
abstract = {Gesture is becoming an increasingly popular means of interacting with computers. However, it is still relatively costly to deploy robust gesture recognition sensors in existing mobile platforms. We present SoundWave, a technique that leverages the speaker and microphone already embedded in most commodity devices to sense in-air gestures around the device. To do this, we generate an inaudible tone, which gets frequency-shifted when it reflects off moving objects like the hand. We measure this shift with the microphone to infer various gestures. In this note, we describe the phenomena and detection algorithm, demonstrate a variety of gestures, and present an informal evaluation on the robustness of this approach across different devices and people.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1911–1914},
numpages = {4},
keywords = {doppler, in-air gesture sensing, interaction technique},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208332,
author = {Rofouei, Mahsan and Wilson, Andrew and Brush, A.J. and Tansley, Stewart},
title = {Your Phone or Mine? Fusing Body, Touch and Device Sensing for Multi-User Device-Display Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208332},
doi = {10.1145/2207676.2208332},
abstract = {Determining who is interacting with a multi-user interactive touch display is challenging. We describe a technique for associating multi-touch interactions to individual users and their accelerometer-equipped mobile devices. Real-time device accelerometer data and depth camera-based body tracking are compared to associate each phone with a particular user, while body tracking and touch contacts positions are compared to associate a touch contact with a specific user. It is then possible to associate touch contacts with devices, allowing for more seamless device-display multi-user interactions. We detail the technique and present a user study to validate and demonstrate a content exchange application using this approach.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1915–1918},
numpages = {4},
keywords = {sensor fusion, accelerometers, multi-touch, depth camera},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208333,
author = {Junuzovic, Sasa and Inkpen, Kori and Blank, Tom and Gupta, Anoop},
title = {IllumiShare: Sharing Any Surface},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208333},
doi = {10.1145/2207676.2208333},
abstract = {Task and reference spaces are important communication channels for remote collaboration. However, all existing systems for sharing these spaces have an inherent weakness: they cannot share arbitrary physical and digital objects on arbitrary surfaces. We present IllumiShare, a new cost-effective, light-weight device that solves this issue. It both shares physical and digital objects on arbitrary surfaces and provides rich referential awareness. To evaluate IllumiShare, we studied pairs of children playing remotely. They used IllumiShare to share the task-reference space and Skype Video to share the person space. The study results show that IllumiShare shared the play space in a natural and seamless way. We also found that children preferred having both spaces compared to having only one. Moreover, we found that removing the task-reference space caused stronger negative disruptions to the play task and engagement level than removing the person space. Similarly, we found that adding the task-reference space resulted in stronger positive disruptions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1919–1928},
numpages = {10},
keywords = {children, surface sharing, reference spaces, task, video, telepresence, video echo cancellation, remote play, person},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208334,
author = {Rudeck, Frederik and Baudisch, Patrick},
title = {Rock-Paper-Fibers: Bringing Physical Affordance to Mobile Touch Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208334},
doi = {10.1145/2207676.2208334},
abstract = {We explore how to bring physical affordance to mobile touch devices. We present Rock-Paper-Fibers, a device that is functionally equivalent to a touchpad, yet that users can reshape so as to best match the interaction at hand. For efficiency, users interact bimanually: one hand reshapes the device and the other hand operates the resulting widget.We present a prototype that achieves deformability using a bundle of optical fibers, demonstrate an audio player and a simple video game each featuring multiple widgets. We demonstrate how to support applications that require responsiveness by adding mechanical wedges and clamps.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1929–1932},
numpages = {4},
keywords = {gesture, mobile, malleable, reconfigurable, input device, wearable, optical fiber, ubicomp, tangible},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208335,
author = {Butler, D. Alex and Izadi, Shahram and Hilliges, Otmar and Molyneaux, David and Hodges, Steve and Kim, David},
title = {Shake'n'sense: Reducing Interference for Overlapping Structured Light Depth Cameras},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208335},
doi = {10.1145/2207676.2208335},
abstract = {We present a novel yet simple technique that mitigates the interference caused when multiple structured light depth cameras point at the same part of a scene. The technique is particularly useful for Kinect, where the structured light source is not modulated. Our technique requires only mechanical augmentation of the Kinect, without any need to modify the internal electronics, firmware or associated host software. It is therefore simple to replicate. We show qualitative and quantitative results highlighting the improvements made to interfering Kinect depth signals. The camera frame rate is not compromised, which is a problem in approaches that modulate the structured light source. Our technique is non-destructive and does not impact depth values or geometry. We discuss uses for our technique, in particular within instrumented rooms that require simultaneous use of multiple overlapping fixed Kinect cameras to support whole room interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1933–1936},
numpages = {4},
keywords = {depth camera, kinect, structured light, reducing interference, motion blur, instrumented rooms},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250497,
author = {Gajos, Krzysztof},
title = {Session Details: Old Mouse, New Tricks: Desktop Interfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250497},
doi = {10.1145/3250497},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208337,
author = {Hoarau, Rapha\"{e}l and Conversy, St\'{e}phane},
title = {Augmenting the Scope of Interactions with Implicit and Explicit Graphical Structures},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208337},
doi = {10.1145/2207676.2208337},
abstract = {When using interactive graphical tools, users often have to manage a structure, i.e. the arrangement of and relations between the parts or elements of the content. However, interaction with structures may be complex and not well integrated with interaction with the content. Based on contextual inquiries and past work, we have identified a number of requirements for the interaction with graphical structures. We have designed and explored two interactive tools that rely on implicit and explicit structures: ManySpector, an inspector for multiple objects that help visualize and interact with used values; and links that users can draw between object properties to provide a dependency. The interactions with the tools augment the scope of interactions to multiple objects. A study showed that users understood the interactions and could use them to perform complex graphical tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1937–1946},
numpages = {10},
keywords = {instrumental interaction, graphical interaction design, exploratory design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208338,
author = {Evans, Abigail and Wobbrock, Jacob},
title = {Taming Wild Behavior: The Input Observer for Obtaining Text Entry and Mouse Pointing Measures from Everyday Computer Use},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208338},
doi = {10.1145/2207676.2208338},
abstract = {We present the Input Observer, a tool that can run quietly in the background of users' computers and measure their text entry and mouse pointing performance from everyday use. In lab studies, participants are presented with prescribed tasks, enabling easy identification of speeds and errors. In everyday use, no such prescriptions exist. We devised novel algorithms to segment text entry and mouse pointing input streams into "trials". We are the first to measure errors for unprescribed text entry and mouse pointing. To measure errors, we utilize web search engines, adaptive offline dictionaries, an Automation API, and crowdsourcing. Capturing errors allows us to employ Crossman's (1957) speed-accuracy normalization when calculating Fitts' law throughputs. To validate the Input Observer, we compared its measures from 12 participants over a week of computer use to the same participants' results from a lab study. Overall, in the lab and field, average text entry speeds were 74.47 WPM and 80.59 WPM, respectively. Average uncorrected error rates were near zero, at 0.12% and 0.28%. For mouse pointing, average movement times were 971 ms and 870 ms. Average pointing error rates were 4.42% and 4.66%. Average throughputs were 3.48 bits/s and 3.45 bits/s. Device makers, researchers, and assistive technology specialists may benefit from measures of everyday use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1947–1956},
numpages = {10},
keywords = {mouse pointing, human performance, text entry, fitts' law, field studies, in the wild, everyday},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208339,
author = {Appert, Caroline and Chapuis, Olivier and Pietriga, Emmanuel},
title = {Dwell-and-Spring: Undo for Direct Manipulation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208339},
doi = {10.1145/2207676.2208339},
abstract = {In graphical user interfaces, direct manipulation consists in incremental actions that should be reversible. Typical examples include manipulating geometrical shapes in a vector graphics editor, navigating a document using a scrollbar, or moving and resizing windows on the desktop. As in many such cases, there will not be any mechanism to undo them, requiring users to manually revert to the previous state using a similar sequence of direct manipulation actions. The associated motor and cognitive costs can be high. We argue that proper and consistent mechanisms to support undo in this context are lacking, and present Dwell-and-Spring, an interaction technique that uses the metaphor of springs to enable users to undo direct manipulations. A spring widget pops up whenever the user dwells during a press-drag-release interaction, giving her the opportunity to either cancel the current manipulation or undo the last one. The technique is generic and can easily be implemented on top of existing applications to complement the traditional undo command. Empirical evaluation shows that users quickly adopt it as soon as they discover it.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1957–1966},
numpages = {10},
keywords = {spring, direct manipulation, canceling, undo, dwell},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250498,
author = {Morris, Meredith Ringel},
title = {Session Details: Social Support &amp; Collaboration},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250498},
doi = {10.1145/3250498},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208341,
author = {Voida, Amy and Harmon, Ellie and Al-Ani, Ban},
title = {Bridging between Organizations and the Public: Volunteer Coordinators' Uneasy Relationship with Social Computing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208341},
doi = {10.1145/2207676.2208341},
abstract = {We present the results of a qualitative study of the use of social computing technologies by volunteer coordinators at nonprofit organizations. The work of volunteer coordinators is bridge-building work - bringing together numerous public constituencies as well as constituencies within their organizations. One might expect this class of work to be well supported by social software, some of which has been found to enable bridging social capital. However, we find that, in many ways, this class of technology fails to adequately support volunteer coordinators' bridge-building work. We discuss a number of strategies for bridge-building via social computing technologies, numerous challenges faced by volunteer coordinators in their use of these technologies, and opportunities for designing social software to better support bridge-building between organizations and the public.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1967–1976},
numpages = {10},
keywords = {volunteer coordination, nonprofit, npo, social computing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208342,
author = {Dombrowski, Lynn and Voida, Amy and Hayes, Gillian R. and Mazmanian, Melissa},
title = {The Labor Practices of Service Mediation: A Study of the Work Practices of Food Assistance Outreach},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208342},
doi = {10.1145/2207676.2208342},
abstract = {In this paper, we present the results of a study of the work practices of food assistance outreach workers. We introduce the construct of service mediation, which includes the technical, social, and knowledge labor practices involved in enabling access to and use of an e-government service. We explore the service mediation activities of outreach, technological assistance, providing knowledge, and ongoing engagement. These activities bring to light how successful service relationships involve fostering a process, bridging relationships, and providing broader scaffolding. The results of our research highlight the role service mediation plays in the use of services and service technologies in information-rich organizations. This research extends previous conceptualizations of mediation by documenting how mediators support broader service processes for their clients, transform potential beneficiaries into clients, and engage in long term assistance. Therefore, this work moves beyond prior conceptualizations of mediation that concentrate solely on enabling access and use of specific technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1977–1986},
numpages = {10},
keywords = {service mediation, e-government, service systems, food insecurity},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208343,
author = {Boujarwah, Fatima and Abowd, Gregory and Arriaga, Rosa},
title = {Socially Computed Scripts to Support Social Problem Solving Skills},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208343},
doi = {10.1145/2207676.2208343},
abstract = {The social world that most of us navigate effortlessly can prove to be a perplexing and disconcerting place for individuals with autism. Interactive tools to teach social skills that are personalized to the individual's needs show promise, but it is challenging to author them. We describe the design, development, and preliminary evaluation of an approach to using human computation that enables the creation of models of complex and interesting social scenarios, possible obstacles that may arise in those scenarios, and potential solutions to those obstacles. Our preliminary evaluation of the models confirms that these models have the potential to help an author create a social skills instructional module.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1987–1996},
numpages = {10},
keywords = {human computation, crowdsourcing, design, autism, social scripts, evaluation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208344,
author = {Judge, Tejinder and Matthews, Tara and Whittaker, Steve},
title = {Comparing Collaboration and Individual Personas for the Design and Evaluation of Collaboration Software},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208344},
doi = {10.1145/2207676.2208344},
abstract = {Collaboration personas are a tool that can be used to design for groups. Prior work posits that collaboration personas can improve tool adoption by helping designers create collaboration tools that are better targeted to the goals, needs, and interactions between members of collaborative groups. We present a comparative study of design and user experience practitioners who used both collaboration personas and individual personas. Participants conducted a cognitive walkthrough and provided redesign suggestions for a collaboration tool. Our results show that the focus of the cognitive walkthrough and redesign task differed, with collaboration personas showing more group focus. Collaboration personas led to a more complete discussion, as indicated by a greater amount of time spent on the task compared to individual personas. Despite prior experience and training with individual personas, collaboration personas were preferred and better supported the task, since they focused on groups of people and their interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1997–2000},
numpages = {4},
keywords = {personas, user study, evaluation, methods, collaboration personas, design tools},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208345,
author = {Kashiwabara, Tadakazu and Osawa, Hirotaka and Shinozawa, Kazuhiko and Imai, Michita},
title = {TEROOS: A Wearable Avatar to Enhance Joint Activities},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208345},
doi = {10.1145/2207676.2208345},
abstract = {This paper proposes a wearable avatar named TEROOS, which is mounted on a person's shoulder. TEROOS allows the users who wear it and control it to share a vision remotely. Moreover, the avatar has an anthropomorphic face that enables the user who controls it to communicate with people co-located with the user who wears it. We have a field test by using TEROOS and observed that the wearable avatar innovatively assisted the users to communicate during their joint activities such as route navigating and buying goods at a shop. The user controlling TEROOS could give the user wearing it appropriate route instructions on the basis of the situation around TEROOS. In addition, both users could easily identify objects that they discussed. Moreover, shop staff members communicated with the user controlling TEROOS and behaved as they normally would when the user asked questions about the goods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2001–2004},
numpages = {4},
keywords = {avatar communication, shared vision, field test, social response, wearable avatar},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250499,
author = {Leahu, Lucian},
title = {Session Details: Culture, Playfulness, &amp; Creativity},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250499},
doi = {10.1145/3250499},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208347,
author = {Benford, Steve and Greenhalgh, Chris and Giannachi, Gabriella and Walker, Brendan and Marshall, Joe and Rodden, Tom},
title = {Uncomfortable Interactions},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208347},
doi = {10.1145/2207676.2208347},
abstract = {We argue for deliberately and systematically creating uncomfortable interactions as part of powerful cultural experiences. We identify the potential benefits of uncomfortable interactions under the general headings of entertainment, enlightenment and sociality. We then review artworks and performances that have employed discomfort, including two complementary examples from the worlds of entertainment and performance. From this, we articulate a suite of tactics for designing four primary forms of discomfort referred to as visceral, cultural, control and intimate. We discuss how moments of discomfort need to be embedded into an overall experience which requires a further consideration of the dramatic acts of exposition, rising action, climax, falling action, and d\'{e}nouement. Finally, we discuss an ethical framework for uncomfortable interactions which leads us to revisit key issues of consent, withdrawal, privacy and risk.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2005–2014},
numpages = {10},
keywords = {rides, visceral, pain, culture, ethics, voyeurism, performance, discomfort, suffering, entertainment, live art, control},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208348,
author = {Ferreira, Pedro and H\"{o}\"{o}k, Kristina},
title = {Appreciating Plei-Plei around Mobiles: Playfulness in Rah Island},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208348},
doi = {10.1145/2207676.2208348},
abstract = {We set out to explore and understand the ways in which mobiles made their way into an environment--Rah Island in Vanuatu--for the first time. We were struck by their playful use, especially given the very limited infrastructure and inexpensive devices that were available. Based on our findings, we discuss tensions between playfulness and utility, in particular relating to socio-economic benefits, and conclude that playfulness in these settings needs to be taken as seriously as in any other setting. Additionally, we formulated three challenges when designing for play in similar settings: (1) engage intimately with the materials of inexpensive ICT; (2) revisit design recommendations for playfulness to ensure that they can travel/translate into other cultures; and (3) alleviate existing tensions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2015–2024},
numpages = {10},
keywords = {ICT4D, playfulness, third wave hci},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250500,
author = {Rosson, Mary Beth},
title = {Session Details: I Did That! Being in Control},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250500},
doi = {10.1145/3250500},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208350,
author = {Coyle, David and Moore, James and Kristensson, Per Ola and Fletcher, Paul and Blackwell, Alan},
title = {I Did That!  Measuring Users' Experience of Agency in Their Own Actions},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208350},
doi = {10.1145/2207676.2208350},
abstract = {Cognitive neuroscience defines the sense of agency as the experience of controlling one's own actions and, through this control, affecting the external world. We believe that the sense of personal agency is a key factor in how people experience interactions with technology. This paper draws on theoretical perspectives in cognitive neuroscience and describes two implicit methods through which personal agency can be empirically investigated. We report two experiments applying these methods to HCI problems. One shows that a new input modality - skin-based interaction - can substantially increase users' sense of agency. The second demonstrates that variations in the parameters of assistance techniques such as predictive mouse acceleration can have a significant impact on users' sense of agency. The methods presented provide designers with new ways of evaluating and refining empowering interaction techniques and interfaces, in which users experience an instinctive sense of control and ownership over their actions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2025–2034},
numpages = {10},
keywords = {personal agency,  evaluation methods,  cognitive science,  implicit measures,  experience of agency},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208351,
author = {Nobarany, Syavash and Oram, Louise and Rajendran, Vasanth Kumar and Chen, Chi-Hsiang and McGrenere, Joanna and Munzner, Tamara},
title = {The Design Space of Opinion Measurement Interfaces: Exploring Recall Support for Rating and Ranking},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208351},
doi = {10.1145/2207676.2208351},
abstract = {Rating interfaces are widely used on the Internet to elicit people's opinions. Little is known, however, about the effectiveness of these interfaces and their design space is relatively unexplored. We provide a taxonomy for the design space by identifying two axes: Measurement Scale for absolute rating vs. relative ranking, and Recall Support for the amount of information provided about previously recorded opinions. We present an exploration of the design space through iterative prototyping of three alternative interfaces and their evaluation. Among many findings, the study showed that users do take advantage of recall support in interfaces, preferring those that provide it. Moreover, we found that designing ranking systems is challenging; there may be a mismatch between a ranking interface that forces people to specify a total ordering for a set of items, and their mental model that some items are not directly comparable to each other.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2035–2044},
numpages = {10},
keywords = {attitude, opinion, ranking, review, rating},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208352,
author = {Sahami Shirazi, Alireza and Moghadam, Peyman and Ketabdar, Hamed and Schmidt, Albrecht},
title = {Assessing the Vulnerability of Magnetic Gestural Authentication to Video-Based Shoulder Surfing Attacks},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208352},
doi = {10.1145/2207676.2208352},
abstract = {Secure user authentication on mobile phones is crucial, as they store highly sensitive information. Common approaches to authenticate a user on a mobile phone are based either on entering a PIN, a password, or drawing a pattern. However, these authentication methods are vulnerable to the shoulder surfing attack. The risk of this attack has increased since means for recording high-resolution videos are cheaply and widely accessible. If the attacker can videotape the authentication process, PINs, passwords, and patterns do not even provide the most basic level of security. In this project, we assessed the vulnerability of a magnetic gestural authentication method to the video-based shoulder surfing attack. We chose a scenario that is favourable to the attack-er. In a real world environment, we videotaped the interactions of four users performing magnetic signatures on a phone, in the presence of HD cameras from four different angles. We then recruited 22 participants and asked them to watch the videos and try to forge the signatures. The results revealed that with a certain threshold, i.e, th=1.67, none of the forging attacks was successful, whereas at this level all eligible login attempts were successfully recognized. The qualitative feedback also indicated that users found the magnetic gestural signature authentication method to be more secure than PIN-based and 2D signature methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2045–2048},
numpages = {4},
keywords = {magnet, signature, mobile phone, authentication},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250501,
author = {Butz, Andreas},
title = {Session Details: Teaching with Games},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250501},
doi = {10.1145/3250501},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208354,
author = {Alankus, Gazihan and Kelleher, Caitlin},
title = {Reducing Compensatory Motions in Video Games for Stroke Rehabilitation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208354},
doi = {10.1145/2207676.2208354},
abstract = {Stroke is the leading cause of long-term disability among adults in industrialized nations; approximately 80% of people who survive a stroke experience motor disabilities. Recovery requires hundreds of daily repetitions of therapeutic exercises, often without therapist supervision. When performing therapy alone, people with limited motion often compensate for the lack of motion in one joint by moving another one. This compensation can impede the recovery progress and create new health problems. In this work we contribute (1) a methodology to reliably sense compensatory torso motion in the context of shoulder exercises done by persons with stroke and (2) the design and experimental evaluation of operant-conditioning-based strategies for games that aim to reduce compensatory torso motion. Our results show that these strategies significantly reduce compensatory motions compared to alternatives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2049–2058},
numpages = {10},
keywords = {stroke rehabilitation, design, compensation, video games},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208355,
author = {Horn, Michael and Atrash Leong, Zeina and Block, Florian and Diamond, Judy and Evans, E. Margaret and Phillips, Brenda and Shen, Chia},
title = {Of BATs and APEs: An Interactive Tabletop Game for Natural History Museums},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208355},
doi = {10.1145/2207676.2208355},
abstract = {In this paper we describe visitor interaction with an interactive tabletop exhibit on evolution that we designed for use in natural history museums. We video recorded 30 families using the exhibit at the Harvard Museum of Natural History. We also observed an additional 50 social groups interacting with the exhibit without video recording. The goal of this research is to explore ways to develop "successful" interactive tabletop exhibits for museums. To determine criteria for success in this context, we borrow the concept of Active Prolonged Engagement (APE) from the science museum literature. Research on APE sets a high standard for visitor engagement and learning, and it offers a number of useful concepts and measures for research on interactive surfaces in the wild. In this paper we adapt and expand on these measures and apply them to our tabletop exhibit. Our results show that visitor groups collaborated effectively and engaged in focused, on-topic discussion for prolonged periods of time. To understand these results, we analyze visitor conversation at the exhibit. Our analysis suggests that social practices of game play contributed substantially to visitor collaboration and engagement with the exhibit.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2059–2068},
numpages = {10},
keywords = {interactive surfaces, design, learning, multi-touch tabletops, museums, evolution, games},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208356,
author = {Linder, Jason and Ju, Wendy},
title = {Playable Character: Extending Digital Games into the Real World},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208356},
doi = {10.1145/2207676.2208356},
abstract = {This paper describes a series of research probe games developed to investigate how real-world activity could be incorporated into digital game systems. These culminated in the design of our final game, Forest, which was conceived for the San Francisco non-profit Friends of the Urban Forest (FUF), who have been planting and caring for the city's street trees for 30 years. By incorporating real-world actions and behaviors into digital games, we can create experiences that both enhance our understanding of the world around us and provide incentive structures towards our personal, community, or societal goals.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2069–2078},
numpages = {10},
keywords = {location-based, design, forest, social games, games},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208357,
author = {Bonsignore, Elizabeth and Kraus, Kari and Visconti, Amanda and Hansen, Derek and Fraistat, Ann and Druin, Allison},
title = {Game Design for Promoting Counterfactual Thinking},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208357},
doi = {10.1145/2207676.2208357},
abstract = {We describe the first iteration of an Alternate Reality Game (ARG) designed to lead players into a newly enfranchised relationship with history and engage them in scientific thinking and information literacy practices. We found that the points at which the game's mythology blurred the lines between fact and fiction prompted middle school students to move beyond rote memorization of content. Instead, they began to question, analyze, and make hypotheses about the data presented. However, striking a meaningful balance between "true" history and imagined events poses new design challenges. We present a formative typology of counterfactual design patterns that can help designers, educators, and players locate interesting fault lines in reality that facilitate the expansion of ARG mythologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2079–2082},
numpages = {4},
keywords = {counterfactual thinking, children, alternate reality games},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208358,
author = {Dong, Tao and Dontcheva, Mira and Joseph, Diana and Karahalios, Karrie and Newman, Mark and Ackerman, Mark},
title = {Discovery-Based Games for Learning Software},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208358},
doi = {10.1145/2207676.2208358},
abstract = {We propose using discovery-based learning games to teach people how to use complex software. Specifically, we developed Jigsaw, a learning game that asks players to solve virtual jigsaw puzzles using tools in Adobe Photoshop. We conducted an eleven-person lab study of the prototype, and found the game to be an effective learning medium that can complement demonstration-based tutorials. Not only did the participants learn about new tools and techniques while actively solving the puzzles in Jigsaw, but they also recalled techniques that they had learned previously but had forgotten.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2083–2086},
numpages = {4},
keywords = {software training, learning games, discovery learning},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250502,
author = {Forlizzi, Jodi},
title = {Session Details: Health + Design},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250502},
doi = {10.1145/3250502},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208360,
author = {Bonner, Matthew and Wang, Lan and Mynatt, Elizabeth D.},
title = {Activity-Based Interaction: Designing with Child Life Specialists in a Children's Hospital},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208360},
doi = {10.1145/2207676.2208360},
abstract = {Child Life Specialists (CLS's) are medical professionals who use activities to educate, comfort, entertain and distract children in hospitals. Adapting to a shifting cast of children, context and mediating activities requires CLS's to be experts at a kind of articulation work. This expertise means CLS's are well equipped to help technologists introduce child-facing interventions to the hospital. We conducted participatory design activities with 9 CLS's to develop two mobile systems to explore how CLS-child interactions are shaped by activities. We observed 18 child-CLS pairs using these systems in a hospital setting. By analyzing these encounters, we describe a continuum for classifying activities as either Co-Present or Collaborative. We then introduce a framework, Activity-Based Interaction, to describe structural components of activities that impact their position on this continuum. These concepts suggest new approaches to designing mediating technologies for adults and children.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2087–2096},
numpages = {10},
keywords = {participatory design, mobile computing, hospital, children, collaboration, child life specialist, articulation work},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208361,
author = {Park, Sun Young and Chen, Yunan},
title = {Adaptation as Design: Learning from an EMR Deployment Study},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208361},
doi = {10.1145/2207676.2208361},
abstract = {We conducted an observational study in an Emergency Department (ED) to examine the adaptation process after deploying an Electronic Medical Records (EMR) system. We investigated how EMR was adapted to the complex clinical work environment and how doctors and nurses engaged in the adaptation process. In this paper, we present three cases in which ED clinicians designed workarounds in order to adapt to the new work practice. Our findings reveal a rich picture of ED clinicians' active reinterpretation and modification of their work practice through their engagement with the system-in-use and its organizational and physical context. These findings call for the adaptation period in designing a socio-technical system in healthcare settings to be critically considered as an active end-user design process, a negotiating process, and a re-routinized process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2097–2106},
numpages = {10},
keywords = {electronic medical record (emr), implementations, clinical practices, adaptation, design, workaround},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250503,
author = {Law, Effie},
title = {Session Details: Usability Methods},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250503},
doi = {10.1145/3250503},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208363,
author = {Petrie, Helen and Power, Christopher},
title = {What Do Users Really Care about? A Comparison of Usability Problems Found by Users and Experts on Highly Interactive Websites},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208363},
doi = {10.1145/2207676.2208363},
abstract = {Expert evaluation methods, such as heuristic evaluation, are still popular in spite of numerous criticisms of their effectiveness. This paper investigates the usability problems found in the evaluation of six highly interactive websites by 30 users in a task-based evaluation and 14 experts using three different expert evaluation methods. A grounded theory approach was taken to categorize 935 usability problems from the evaluation. Four major categories emerged: Physical presentation, Content, Information Architecture and Interactivity. Each major category had between 5 and 16 sub-categories. The categories and sub-categories were then analysed for whether they were found by users only, experts only or both users and experts. This allowed us to develop an evidence-based set of 21 heuristics to assist in the development and evaluation of interactive websites.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2107–2116},
numpages = {10},
keywords = {usability problems, expert evaluation, heuristic evaluation, user evaluation, heuristics},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208364,
author = {Bruun, Anders and Stage, Jan},
title = {The Effect of Task Assignments and Instruction Types on Remote Asynchronous Usability Testing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208364},
doi = {10.1145/2207676.2208364},
abstract = {Remote asynchronous usability testing involves users directly in reporting usability problems. Most studies of this approach employ predefined tasks to ensure that users experience specific aspects of the system, whereas other studies use no task assignments. Yet the effect of using predefined tasks is still to be uncovered. There is also limited research on instructions for users in identifying usability problems. This paper reports from a comparative study of the effect of task assignments and instruction types on the problems identified in remote asynchronous usability testing of a website for information retrieval, involving 53 prospective users. The results show that users solving predefined tasks identified significantly more usability problems with a significantly higher level of agreement than those working on their own authentic tasks. Moreover, users that were instructed by means of examples of usability problems identified significantly more usability problems than those who received a conceptual definition of usability problems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2117–2126},
numpages = {10},
keywords = {remote testing, task assignments, empirical study, instruction types, asynchronous testing, usability testing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208365,
author = {F\o{}lstad, Asbj\o{}rn and Law, Effie and Hornb\ae{}k, Kasper},
title = {Analysis in Practical Usability Evaluation: A Survey Study},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208365},
doi = {10.1145/2207676.2208365},
abstract = {Analysis is a key part of conducting usability evaluations, yet rarely systematically studied. Thus, we lack direction on how to do research on supporting practitioners' analysis and lose an opportunity for practitioners to learn from each other. We have surveyed 155 usability practitioners on the analysis in their latest usability evaluation. Analysis is typically flexible and light-weight. At the same time, practitioners see a need to strengthen reliability in evaluation. Redesign is closely integrated with analysis; more than half of the respondents provide visual redesign suggestions in their evaluation deliverables. Analysis support from academic research, including tools, forms and structured formats, does not seem to have direct impact on analysis practice. We provide six recommendations for future research to better support analysis.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2127–2136},
numpages = {10},
keywords = {questionnaire survey, analysis, usability evaluation method, state-of-the-practice},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208366,
author = {Babaian, Tamara and Lucas, Wendy and Oja, Mari-Klara},
title = {Evaluating the Collaborative Critique Method},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208366},
doi = {10.1145/2207676.2208366},
abstract = {We introduce a new usability walkthrough method called Collaborative Critique (CC), which is inspired by the human-computer collaboration paradigm of system-user interaction. This method applies a "collaboration lens" to assessing the system's behavior and its impact on the user's efforts in the context of the task being performed. We present findings from a laboratory evaluation of the CC method with usability practitioners, in which the results of the CC walkthrough were compared to a benchmark set of problems collected via user testing with two experimental Enterprise Resource Planning (ERP) system tasks. The development of this new usability evaluation method was driven by the need for an approach that assesses the adequacy of the system's support for reducing the user's cognitive and physical effort in the context of the interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2137–2164},
numpages = {28},
keywords = {erp, complex systems, usability inspection methods, human-computer collaboration},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250504,
author = {Patel, Shwetak},
title = {Session Details: Dimensions of Sensory Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250504},
doi = {10.1145/3250504},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208368,
author = {Moeller, Jon and Kerne, Andruid},
title = {ZeroTouch: An Optical Multi-Touch and Free-Air Interaction Architecture},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208368},
doi = {10.1145/2207676.2208368},
abstract = {ZeroTouch (ZT) is a unique optical sensing technique and architecture that allows precision sensing of hands, fingers, and other objects within a constrained 2-dimensional plane. ZeroTouch provides tracking at 80 Hz, and up to 30 concurrent touch points. Integration with LCDs is trivial. While designed for multi-touch sensing, ZT enables other new modalities, such as pen+touch and free-air interaction. In this paper, we contextualize ZT innovations with a review of other flat-panel sensing technologies. We present the modular sensing architecture behind ZT, and examine early diverse uses of ZT sensing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2165–2174},
numpages = {10},
keywords = {zerotouch, multi-touch, sensing, interaction, free-air},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208369,
author = {Kim, Seokhwan and Cao, Xiang and Zhang, Haimo and Tan, Desney},
title = {Enabling Concurrent Dual Views on Common LCD Screens},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208369},
doi = {10.1145/2207676.2208369},
abstract = {Researchers have explored a variety of technologies that enable a single display to simultaneously present different content when viewed from different angles or by different people. These displays provide new functionalities such as personalized views for multiple users, privacy protection, and stereoscopic 3D displays. However, current multi-view displays rely on special hardware, thus significantly limiting their availability to consumers and adoption in everyday scenarios. In this paper, we present a pure software solution (i.e. with no hardware modification) that allows us to present two independent views concurrently on the most widely used and affordable type of LCD screen, namely Twisted Nematic (TN). We achieve this by exploiting a technical limitation of the technology which causes these LCDs to show varying brightness and color depending on the viewing angle. We describe our technical solution as well as demonstrate example applications in everyday scenarios.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2175–2184},
numpages = {10},
keywords = {dual-view display, twisted nematic., LCD},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208370,
author = {Marshall, Mark and Carter, Thomas and Alexander, Jason and Subramanian, Sriram},
title = {Ultra-Tangibles: Creating Movable Tangible Objects on Interactive Tables},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208370},
doi = {10.1145/2207676.2208370},
abstract = {Tangible objects placed on interactive surfaces allow users to employ a physical object to manipulate digital content. However, creating the reverse effect - having digital content manipulate a tangible object placed on the surface - is a more challenging task. We present a new approach to this problem, using ultrasound-based air pressure waves to move multiple tangible objects, independently, around an interactive surface. We describe the technical background, design, implementation, and test cases for such a system. We conclude by discussing practical uses of our system, Ultra-Tangibles, in the creation of new tangible user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2185–2188},
numpages = {4},
keywords = {feedback, user interface device, actuated tabletops, tangible interface, ultrasound},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208371,
author = {Chan, Liwei and M\"{u}ller, Stefanie and Roudaut, Anne and Baudisch, Patrick},
title = {CapStones and ZebraWidgets: Sensing Stacks of Building Blocks, Dials and Sliders on Capacitive Touch Screens},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208371},
doi = {10.1145/2207676.2208371},
abstract = {Recent research proposes augmenting capacitive touch pads with tangible objects, enabling a new generation of mobile applications enhanced with tangible objects, such as game pieces and tangible controllers. In this paper, we extend the concept to capacitive tangibles consisting of multiple parts, such as stackable gaming pieces and tangible widgets with moving parts. We achieve this using a system of wires and connectors inside each block that causes the capacitance of the bottom-most block to reflect the entire assembly. We demonstrate three types of tangibles, called CapStones, Zebra Dials and Zebra Sliders that work with current consumer hardware and investigate what designs may become possible as touchscreen hardware evolves.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2189–2192},
numpages = {4},
keywords = {tangible interface, capacitive sensing, multi-component},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208372,
author = {Solovey, Erin and Schermerhorn, Paul and Scheutz, Matthias and Sassaroli, Angelo and Fantini, Sergio and Jacob, Robert},
title = {Brainput: Enhancing Interactive Systems with Streaming Fnirs Brain Input},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208372},
doi = {10.1145/2207676.2208372},
abstract = {This paper describes the Brainput system, which learns to identify brain activity patterns occurring during multitasking. It provides a continuous, supplemental input stream to an interactive human-robot system, which uses this information to modify its behavior to better support multitasking. This paper demonstrates that we can use non-invasive methods to detect signals coming from the brain that users naturally and effortlessly generate while using a computer system. If used with care, this additional information can lead to systems that respond appropriately to changes in the user's state. Our experimental study shows that Brainput significantly improves several performance metrics, as well as the subjective NASA-Task Load Index scores in a dual-task human-robot activity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2193–2202},
numpages = {10},
keywords = {near-infrared spectroscopy, fnirs, human-robot interaction, multitasking, brain computer interface},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250505,
author = {Hinckley, Ken},
title = {Session Details: Phone Fun: Extending Mobile Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250505},
doi = {10.1145/3250505},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208374,
author = {Cheng, Lung-Pan and Hsiao, Fang-I and Liu, Yen-Ting and Chen, Mike Y.},
title = {IRotate: Automatic Screen Rotation Based on Face Orientation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208374},
doi = {10.1145/2207676.2208374},
abstract = {We present iRotate, an approach to automatically rotate screens on mobile devices to match users' face orientation. Current approaches to automatic screen rotation are based on gravity and device orientation. Our survey of 513 users shows that 42% currently experience auto-rotation that leads to incorrect viewing orientation several times a week or more, and 24% find the problem to be very serious to extremely serious. iRotate augments gravity-based approach, and uses front cameras on mobile devices to detect users' faces and rotates screens accordingly. It requires no explicit user input and supports different user postures and device orientations. We have implemented a iRotate that works in real-time on iPhone and iPad, and we assess the accuracy and limitations of iRotate through a 20- participant feasibility study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2203–2210},
numpages = {8},
keywords = {face detection, auto rotation, device orientation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208375,
author = {Joshi, Neel and Kar, Abhishek and Cohen, Michael},
title = {Looking at You: Fused Gyro and Face Tracking for Viewing Large Imagery on Mobile Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208375},
doi = {10.1145/2207676.2208375},
abstract = {We present a touch-free interface for viewing large imagery on mobile devices. In particular, we focus on viewing paradigms for 360 degree panoramas, parallax image sequences, and long multi-perspective panoramas. We describe a sensor fusion methodology that combines face tracking using a front-facing camera with gyroscope data to produce a robust signal that defines the viewer's 3D position relative to the display. The gyroscopic data provides both low-latency feedback and allows extrapolation of the face position beyond the the field-of-view of the front-facing camera. We also demonstrate a hybrid position and rate control that uses the viewer's 3D position to drive exploration of very large image spaces. We report on the efficacy of the hybrid control vs. position only control through a user study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2211–2220},
numpages = {10},
keywords = {mobile device, sensors, navigation, viewing large imagery},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208376,
author = {Jain, Mohit and Balakrishnan, Ravin},
title = {User Learning and Performance with Bezel Menus},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208376},
doi = {10.1145/2207676.2208376},
abstract = {Touchscreen phones tend to require constant visual attention, thus not allowing eyes-free interaction. For users with visual impairment, or when occupied with another task that requires a user's visual attention, these phones can be difficult to use. Recently, marks initiating from the bezel, the physical touch-insensitive frame surrounding a touchscreen display, have been proposed as a method for eyes-free interaction. Due to the physical form factor of the mobile device, it is possible to access different parts of the bezel eyes-free. In this paper, we first studied the performance of different bezel menu layouts. Based on the results, we designed a bezel-based text entry application to gain insights into how bezel menus perform in a real-world application. From a longitudinal study, we found that the participants achieved 9.2 words per minute in situations requiring minimal visual attention to the screen. After only one hour of practice, the participants transitioned from novice to expert users. This shows that bezel menus can be adopted for realistic applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2221–2230},
numpages = {10},
keywords = {bezel menu, touchscreen phones, text entry, eyes-free interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208377,
author = {Dearman, David and Guy, Richard and Truong, Khai},
title = {Determining the Orientation of Proximate Mobile Devices Using Their Back Facing Camera},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208377},
doi = {10.1145/2207676.2208377},
abstract = {Proximate mobile devices that are aware of their orientation relative to one another can support novel and natural forms of interaction. In this paper, we present a method to determine the relative orientation of proximate mobile devices using only the backside camera. We implemented this method as a service called Orienteer, which provides mobile device with the orientation of other proximate mobile devices. We demonstrate that orientation information can be used to enable novel and natural interactions by developing two applications that allow the user to push content in the direction of another device to share it and point the device toward another to filter content based on the device's owner. An informal evaluation revealed that interactions built upon orientation information can be natural and compelling to users, but developers and designers need to carefully consider how orientation should be applied effectively.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2231–2234},
numpages = {4},
keywords = {backside camera, proximate, mobile devices, orientation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208378,
author = {Schwarz, Julia and Klionsky, David and Harrison, Chris and Dietz, Paul and Wilson, Andrew},
title = {Phone as a Pixel: Enabling Ad-Hoc, Large-Scale Displays Using Mobile Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208378},
doi = {10.1145/2207676.2208378},
abstract = {We present Phone as a Pixel: a scalable, synchronization-free, platform-independent system for creating large, ad-hoc displays from a collection of smaller devices. In contrast to most tiled-display systems, the only requirement for participation is for devices to have an internet connection and a web browser. Thus, most smartphones, tablets, laptops and similar devices can be used. Phone as a Pixel uses a color-transition encoding scheme to identify and locate displays. This approach has several advantages: devices can be arbitrarily arranged (i.e., not in a grid) and infrastructure consists of a single conventional camera. Further, additional devices can join at any time without re-calibration. These are desirable properties to enable collective displays in contexts like sporting events, concerts and political rallies. In this paper we describe our system, show results from proof-of-concept setups, and quantify the performance of our approach on hundreds of displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2235–2238},
numpages = {4},
keywords = {computer vision, ubiquitous computing, crowd-computer interaction, devices, distributed screens},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208380,
author = {Fitchett, Stephen and Cockburn, Andy},
title = {AccessRank: Predicting What Users Will Do Next},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208380},
doi = {10.1145/2207676.2208380},
abstract = {We introduce AccessRank, an algorithm that predicts revisitations and reuse in many contexts, such as file accesses, website visits, window switches, and command lines. AccessRank uses many sources of input to generate its predictions, including recency, frequency, temporal clustering, and time of day. Simulations based on log records of real user interaction across a diverse range of applications show that AccessRank more accurately predicts upcoming accesses than other algorithms. The prediction lists generated by AccessRank are also shown to be more stable than other algorithms that have good predictive capability, which can be important for usability when items are presented in lists as users can rely on their spatial memory for target location. Finally, we present examples of how real world applications might use AccessRank.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2239–2242},
numpages = {4},
keywords = {list stability, revisitation, prediction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250506,
author = {Fogarty, James},
title = {Session Details: Check This out: Recommender Systems},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250506},
doi = {10.1145/3250506},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208381,
author = {Nowak, Michael and Nass, Clifford},
title = {Effects of Behavior Monitoring and Perceived System Benefit in Online Recommender Systems},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208381},
doi = {10.1145/2207676.2208381},
abstract = {Behavior monitoring is an important part of many recommender systems; however, its effects on users' perceptions of such systems are not well understood. We describe a 2x2 factorial experiment that manipulates a simulated recommender system's monitoring of user behavior (monitoring: present vs. absent) and whom the system is perceived to benefit (benefit: corporate vs. consumer). We find that attitudes toward being monitored are moderated by perceptions about system intentions. We propose an explanatory mechanism and highlight the value of understanding the subjective experience of interacting with recommender systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2243–2246},
numpages = {4},
keywords = {monitoring, human-computer interaction, recommender systems},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208382,
author = {Yarosh, Svetlana and Matthews, Tara and Zhou, Michelle},
title = {Asking the Right Person: Supporting Expertise Selection in the Enterprise},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208382},
doi = {10.1145/2207676.2208382},
abstract = {Expertise selection is the process of choosing an expert from a list of recommended people. This is an important and nuanced step in expertise location that has not received a great deal of attention. Through a lab-based, controlled investigation with 35 enterprise workers, we found that presenting additional information about each recommended person in a search result list led the participants to make quicker and better-informed selections. These results focus attention on a currently understudied aspect of expertise location--expertise selection--that could greatly improve the usefulness of supporting systems. We also asked participants to rate the type of information that might be most useful for expertise selection on a paper prototype containing 36 types of potentially helpful information. We identified sixteen types of this information that may be most useful for various expertise selection tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2247–2256},
numpages = {10},
keywords = {expertise location, expertise recommender systems, office, expertise selection},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208383,
author = {Zhu, Haiyi and Huberman, Bernardo and Luon, Yarun},
title = {To Switch or Not to Switch: Understanding Social Influence in Online Choices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208383},
doi = {10.1145/2207676.2208383},
abstract = {We designed and ran an experiment to measure social influence in online recommender systems, specifically how often people's choices are changed by others' recommendations when facing different levels of confirmation and conformity pressures. In our experiment participants were first asked to provide their preferences between pairs of items. They were then asked to make second choices about the same pairs with knowledge of others' preferences. Our results show that others people's opinions significantly sway people's own choices. The influence is stronger when people are required to make their second decision sometime later (22.4%) than immediately (14.1%). Moreover, people seem to be most likely to reverse their choices when facing a moderate, as opposed to large, number of opposing opinions. Finally, the time people spend making the first decision significantly predicts whether they will reverse their decisions later on, while demographics such as age and gender do not. These results have implications for consumer behavior research as well as online marketing strategies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2257–2266},
numpages = {10},
keywords = {recommender systems, online choices, social influence},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250507,
author = {Adar, Eytan},
title = {Session Details: See Hear Speak: Redesigning I/O for Effectiveness},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250507},
doi = {10.1145/3250507},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208385,
author = {Lazar, Jonathan and Feng, Jinjuan and Brooks, Tim and Melamed, Genna and Wentz, Brian and Holman, Jon and Olalere, Abiodun and Ekedebe, Nnanna},
title = {The SoundsRight CAPTCHA: An Improved Approach to Audio Human Interaction Proofs for Blind Users},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208385},
doi = {10.1145/2207676.2208385},
abstract = {In this paper we describe the development of a new audio CAPTCHA called the SoundsRight CAPTCHA, and the evaluation of the CAPTCHA with 20 blind users. Blind users cannot use visual CAPTCHAs, and it has been documented in the research literature that the existing audio CAPTCHAs have task success rates below 50% for blind users. The SoundsRight audio CAPTCHA presents a real-time audio-based challenge in which the user is asked to identify a specific sound (for example the sound of a bell or a piano) each time it occurs in a series of 10 sounds that are played through the computer's audio system. Evaluation results from three rounds of usability testing document that the task success rate was higher than 90% for blind users. Discussion, limitations, and suggestions for future research are also presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2267–2276},
numpages = {10},
keywords = {audio CAPTCHA, web accessibility, human interaction proof, blind users, security, accessibility, evaluation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208386,
author = {Kumar, Anuj and Paek, Tim and Lee, Bongshin},
title = {Voice Typing: A New Speech Interaction Model for Dictation on Touchscreen Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208386},
doi = {10.1145/2207676.2208386},
abstract = {Dictation using speech recognition could potentially serve as an efficient input method for touchscreen devices. However, dictation systems today follow a mentally disruptive speech interaction model: users must first formulate utterances and then produce them, as they would with a voice recorder. Because utterances do not get transcribed until users have finished speaking, the entire output appears and users must break their train of thought to verify and correct it. In this paper, we introduce Voice Typing, a new speech interaction model where users' utterances are transcribed as they produce them to enable real-time error identification. For fast correction, users leverage a marking menu using touch gestures. Voice Typing aspires to create an experience akin to having a secretary type for you, while you monitor and correct the text. In a user study where participants composed emails using both Voice Typing and traditional dictation, they not only reported lower cognitive demand for Voice Typing but also exhibited 29% relative reduction of user corrections. Overall, they also preferred Voice Typing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2277–2286},
numpages = {10},
keywords = {speech user interfaces, multimodal, speech recognition, error correction, dictation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208387,
author = {Vinot, Jean-Luc and Athenes, Sylvie},
title = {Legible, Are You Sure? An Experimentation-Based Typographical Design in Safety-Critical Context},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208387},
doi = {10.1145/2207676.2208387},
abstract = {Designing Safety-critical interfaces entails proving the safety and operational usability of each component. Largely taken for granted in everyday interface design, the typographical component, through its legibility and aesthetics, weighs heavily on the ubiquitous reading task at the heart of most visualizations and interactions. In this paper, we present a research project whose goal is the creation of a new typeface to display textual information on future aircraft interfaces. After an initial task analysis leading to the definition of specific needs, requirements and design principles, the design constantly evolves from an iterative cycle of design and experimentation. We present three experiments (laboratory and cockpit) used mainly to validate initial choices and fine-tune font properties. Results confirm the importance of rigorously testing the typographical component as a part of text output evaluation in interactive systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2287–2296},
numpages = {10},
keywords = {safety-critical, experimentation, aircraft, evaluation, legibility, readability, design, typography, cockpit},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208388,
author = {Flatla, David and Gutwin, Carl},
title = {SSMRecolor: Improving Recoloring Tools with Situation-Specific Models of Color Differentiation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208388},
doi = {10.1145/2207676.2208388},
abstract = {Color is commonly used to convey information in digital environments, but colors can be difficult to distinguish for many users -- either because of a congenital color vision deficiency (CVD), or because of situation-induced CVDs such as wearing colored glasses or working in sunlight. Tools intended to improve color differentiability (recoloring tools) exist, but these all use abstract models of only a few types of congenital CVD; if the user's color problems have a different cause, existing recolorers can perform poorly. We have developed a recoloring tool (SSMRecolor) based on the idea of situation-specific modeling -- in which we build a performance-based model of a particular user in their specific environment, and use that model to drive the recoloring process. SSMRecolor covers a much wider range of CVDs, including acquired and situational deficiencies. We evaluated SSMRecolor and two existing tools in a controlled study of people's color-matching performance in several environmental conditions. The study included participants with and without congenital CVD. Our results show both accuracy and response time in color-matching tasks were significantly better with SSMRecolor. This work demonstrates the value of a situation-specific approach to recoloring, and shows that this technique can substantially improve the usability of color displays for users of all types.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2297–2306},
numpages = {10},
keywords = {color vision deficiency, color, accessibility, recoloring},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250508,
author = {Hartmann, Bjoern},
title = {Session Details: Triple t: Touch, Tables, Tablets},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250508},
doi = {10.1145/3250508},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208390,
author = {Vogel, Daniel and Casiez, G\'{e}ry},
title = {Hand Occlusion on a Multi-Touch Tabletop},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208390},
doi = {10.1145/2207676.2208390},
abstract = {We examine the shape of hand and forearm occlusion on a multi-touch table for different touch contact types and tasks. Individuals have characteristic occlusion shapes, but with commonalities across tasks, postures, and handedness. Based on this, we create templates for designers to justify occlusion-related decisions and we propose geometric models capturing the shape of occlusion. A model using diffused illumination captures performed well when augmented with a forearm rectangle, as did a modified circle and rectangle model with ellipse "fingers" suitable when only X-Y contact positions are available. Finally, we describe the corpus of detailed multi-touch input data we generated which is available to the community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2307–2316},
numpages = {10},
keywords = {finger, multi-touch, tabletop, hand, tablet, occlusion},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208391,
author = {Wagner, Julie and Huot, St\'{e}phane and Mackay, Wendy},
title = {BiTouch and BiPad: Designing Bimanual Interaction for Hand-Held Tablets},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208391},
doi = {10.1145/2207676.2208391},
abstract = {Despite the demonstrated benefits of bimanual interaction, most tablets use just one hand for interaction, to free the other for support. In a preliminary study, we identified five holds that permit simultaneous support and interaction, and noted that users frequently change position to combat fatigue. We then designed the BiTouch design space, which introduces a support function in the kinematic chain model for interacting with hand-held tablets, and developed BiPad, a toolkit for creating bimanual tablet interaction with the thumb or the fingers of the supporting hand. We ran a controlled experiment to explore how tablet orientation and hand position affect three novel techniques: bimanual taps, gestures and chords. Bimanual taps outperformed our one-handed control condition in both landscape and portrait orientations; bimanual chords and gestures in portrait mode only; and thumbs outperformed fingers, but were more tiring and less stable. Together, BiTouch and BiPad offer new opportunities for designing bimanual interaction on hand-held tablets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2317–2326},
numpages = {10},
keywords = {bipad, bimanual interaction, multi-touch tablets, hand-held tablets, bitouch design space},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208392,
author = {Zhang, Hong and Yang, Xing-Dong and Ens, Barrett and Liang, Hai-Ning and Boulanger, Pierre and Irani, Pourang},
title = {See Me, See You: A Lightweight Method for Discriminating User Touches on Tabletop Displays},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208392},
doi = {10.1145/2207676.2208392},
abstract = {Tabletop systems provide a versatile space for collaboration, yet, in many cases, are limited by the inability to differentiate the interactions of simultaneous users. We present See Me, See You, a lightweight approach for discriminating user touches on a vision-based tabletop. We contribute a valuable characterization of finger orientation distributions of tabletop users. We exploit this biometric trait with a machine learning approach to allow the system to predict the correct position of users as they touch the surface. We achieve accuracies as high as 98% in simple situations and above 92% in more challenging conditions, such as two-handed tasks. We show high acceptance from users, who can self-correct prediction errors without significant costs. See Me, See You is a viable solution for providing simple yet effective support for multi-user application features on tabletops.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2327–2336},
numpages = {10},
keywords = {multi-user application, tabletop interaction, touch discrimination, position aware system},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250509,
author = {Borning, Alan},
title = {Session Details: Defying Environmental Behavior Changes},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250509},
doi = {10.1145/3250509},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208394,
author = {Thieme, Anja and Comber, Rob and Miebach, Julia and Weeden, Jack and Kraemer, Nicole and Lawson, Shaun and Olivier, Patrick},
title = {"We've Bin Watching You": Designing for Reflection and Social Persuasion to Promote Sustainable Lifestyles},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208394},
doi = {10.1145/2207676.2208394},
abstract = {BinCam is a social persuasive system to motivate reflection and behavioral change in the food waste and recycling habits of young adults. The system replaces an existing kitchen refuse bin and automatically logs disposed of items through digital images captured by a smart phone installed on the underside of the bin lid. Captured images are uploaded to a BinCam application on Facebook where they can be explored by all users of the BinCam system. Engagement with BinCam is designed to fit into the existing structure of users' everyday life, with the intention that reflection on waste and recycling becomes a playful and shared group activity. Results of a user study reveal an increase in both users' awareness of, and reflection about, their waste management and their motivation to improve their waste-related skills. With BinCam, we also explore informational and normative social influences as a source of change (e.g., socially evoked feelings of 'guilt' for non-recycling or food disposal), which has to date been underexplored in persuasive HCI. Design implications for reflection and social persuasion are proposed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2337–2346},
numpages = {10},
keywords = {social networks, behavioral change, sustainable HCI, reflection, social persuasion, persuasive, technology},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208395,
author = {Kjeldskov, Jesper and Skov, Mikael B. and Paay, Jeni and Pathmanathan, Rahuvaran},
title = {Using Mobile Phones to Support Sustainability: A Field Study of Residential Electricity Consumption},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208395},
doi = {10.1145/2207676.2208395},
abstract = {Recent focus on sustainability has made consumers more aware of our joint responsibility for conserving energy resources such as electricity. However, reducing electricity use can be difficult with only a meter and a monthly or annual electricity bill. With the emergence of new power meters units, information on electricity consumption is now available digitally and wirelessly. This enables the design and deployment of a new class of persuasive systems giving consumers insight into their use of energy resources and means for reducing it. In this paper, we explore the design and use of one such system, Power Advisor, promoting electricity conservation through tailored information on a mobile phone or tablet. The use of the system in 10 households was studied over 7 weeks. Findings provide insight into peoples awareness of electricity consumption in their home and how this may be influenced through design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2347–2356},
numpages = {10},
keywords = {sustainability, electricity consumption, households},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208396,
author = {Foster, Derek and Lawson, Shaun and Wardman, Jamie and Blythe, Mark and Linehan, Conor},
title = {"Watts in It for Me?": Design Implications for Implementing Effective Energy Interventions in Organisations},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208396},
doi = {10.1145/2207676.2208396},
abstract = {The design of technological interventions to motivate behaviour-based reductions in end-user energy consumption has recently been identified as a priority for the HCI community. Previous interventions have produced promising results, but have typically focused on domestic energy consumption. By contrast, this paper focuses on the workplace context, which presents very different opportunities and challenges. For instance, financial consequences, which have proved successful as motivations in the domestic environment, are not present in the workplace in the context of employees. We describe the outcome of a sequence of workshops that focussed on understanding employee perceptions of energy use in the workplace, with the locus of activity on energy intervention design. Using a grounded theory analysis, we produced a framework of key themes detailing user perceptions and energy intervention design considerations. Our findings provide a framework of considerations for the design of successful workplace energy interventions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2357–2366},
numpages = {10},
keywords = {energy, behaviour change, organisations, hci, sustainability},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208397,
author = {Froehlich, Jon and Findlater, Leah and Ostergren, Marilyn and Ramanathan, Solai and Peterson, Josh and Wragg, Inness and Larson, Eric and Fu, Fabia and Bai, Mazhengmin and Patel, Shwetak and Landay, James A.},
title = {The Design and Evaluation of Prototype Eco-Feedback Displays for Fixture-Level Water Usage Data},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208397},
doi = {10.1145/2207676.2208397},
abstract = {Few means currently exist for home occupants to learn about their water consumption: e.g., where water use occurs, whether such use is excessive and what steps can be taken to conserve. Emerging water sensing systems, however, can provide detailed usage data at the level of individual water fixtures (i.e., disaggregated usage data). In this paper, we perform formative evaluations of two sets of novel eco-feedback displays that take advantage of this disaggregated data. The first display set isolates and examines specific elements of an eco-feedback design space such as data and time granularity. Displays in the second set act as design probes to elicit reactions about competition, privacy, and integration into domestic space. The displays were evaluated via an online survey of 651 North American respondents and in-home, semi-structured interviews with 10 families (20 adults). Our findings are relevant not only to the design of future water eco-feedback systems but also for other types of consumption (e.g., electricity and gas).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2367–2376},
numpages = {10},
keywords = {sustainability, eco-feedback, water, iterative design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250510,
author = {DiSalvo, Carl},
title = {Session Details: Learning with Children},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250510},
doi = {10.1145/3250510},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208399,
author = {Frauenberger, Christopher and Good, Judith and Keay-Bright, Wendy and Pain, Helen},
title = {Interpreting Input from Children: A Designerly Approach},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208399},
doi = {10.1145/2207676.2208399},
abstract = {Involving children in the design process of interactive technology can greatly enhance its likelihood of successful adoption. However, children's input and ideas require careful interpretation to reach viable designs and technical specifications, which poses a significant challenge to an adult design research team. In this paper we discuss our approach to managing the complexity of combining concepts and ideas that were generated through participatory design work with the practical, technical, ethical and theoretical constraints of developing a technologically enhanced learning environment for children with and without Autism Spectrum Conditions. We found that the nature of this design problem did not lend itself to be rationally reduced to produce a single solution, but required an understanding of interpretive and speculative approaches for us to be able to cope with the complexity of requirements. We describe a workshop in which members of the design team used such approaches to develop a design brief that is faithful to the children's input. By making this process transparent, we aim to contribute to the methodology of using such designerly approaches in combination with participatory and human-centred methods to develop interactive technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2377–2386},
numpages = {10},
keywords = {children, autism, participatory design, design research},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208400,
author = {Inkpen, Kori and Du, Honglu and Roseway, Asta and Hoff, Aaron and Johns, Paul},
title = {Video Kids: Augmenting Close Friendships with Asynchronous Video Conversations in Videopal},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208400},
doi = {10.1145/2207676.2208400},
abstract = {Consumer-based synchronous video communication is on the rise and is viewed as a valuable medium to support long distance relationships. We were interested in the potential of asynchronous video to augment children's close friendships and what types of activities they would engage in using video. We explored both of these concepts through a 9-week field study with a group of six 9-10 year old girls. We see children as potential media trendsetters when it comes to video communication given their comfort with video and desire for rich social interactions. The results from this study were striking. Despite having frequent face-to-face interactions, the girls used our asynchronous video communication tool extensively to augment their existing relationships. Not only were they able to have rich conversations using asynchronous video, they also demonstrated a strong desire to share more than just a "talking head". The results from this work point to the need for video mediated communication to move beyond conversations, to the sharing of rich experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2387–2396},
numpages = {10},
keywords = {video-mediated communication, telepresence, children, cmc, asynchronous video},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208401,
author = {Kano, Akiyo and Read, Janet},
title = {Interchangeability of Computer and Paper Based Questionnaires in Gathering Computer Experience Data from Young Children},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208401},
doi = {10.1145/2207676.2208401},
abstract = {The study compares self-reported computer experience (CE) obtained from children in computer-assisted and paper-and-pencil self-administered questionnaires. Twenty primary school children aged between 8 and 9 years completed a set of CE questions in both forms of administration in a Latin-square order. Findings show that young children can use both methods, and that they are able to answer a computer-based questionnaire just as consistently as a paper-based questionnaire.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2397–2400},
numpages = {4},
keywords = {children, computer experience, questionnaires},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250511,
author = {Latulipe, Celine},
title = {Session Details: Morphing &amp; Tracking &amp; Stacking: 3D Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250511},
doi = {10.1145/3250511},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208403,
author = {Follmer, Sean and Ishii, Hiroshi},
title = {KidCAD: Digitally Remixing Toys through Tangible Tools},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208403},
doi = {10.1145/2207676.2208403},
abstract = {Children have great facility in the physical world, and can skillfully model in clay and draw expressive illustrations. Traditional digital modeling tools have focused on mouse, keyboard and stylus input. These tools may be complicated and difficult for young users to easily and quickly create exciting designs. We seek to bring physical interaction to digital modeling, to allow users to use existing physical objects as tangible building blocks for new designs. We introduce KidCAD a digital clay interface for children to remix toys. KidCAD allows children to imprint 2.5D shapes from physical objects into their digital models by deforming a malleable gel input device, deForm. Users can mashup existing objects, edit and sculpt or draw new designs on a 2.5D canvas using physical objects, hands and tools as well as 2D touch gestures. We report on a preliminary user study with 13 children, ages 7 to 10, which provides feedback for our design and helps guide future work in tangible modeling for children.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2401–2410},
numpages = {10},
keywords = {tangible sculpting tools, children's design tools, digital clay},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208404,
author = {Takeuchi, Yuichiro and Perlin, Ken},
title = {ClayVision: The (Elastic) Image of the City},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208404},
doi = {10.1145/2207676.2208404},
abstract = {In this paper we describe ClayVision, a new quasi-immersive urban navigation system that rethinks the design conventions of existing Augmented Reality (AR) applications, by aggressively incorporating knowledge from non-Computer Science fields - namely Information Design and Urban Planning. Instead of the prevailing approach of pasting "information bubbles" onto the existing urban scenery, ClayVision communicates through real-time 3D transformations of city elements. In other words, the system dynamically probes and reassembles the city into a better-designed copy of the original, that is both easier to navigate and tailored to suit the user's needs and preferences. We provide extensive discussions that cover the technical details of the system, the types of city-morphing operations that can be effectively applied, and what people's experiences will be in the newly "elastic" city.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2411–2420},
numpages = {10},
keywords = {urban planning, information design, computer vision, augmented reality, urban navigation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208405,
author = {Hilliges, Otmar and Kim, David and Izadi, Shahram and Weiss, Malte and Wilson, Andrew},
title = {HoloDesk: Direct 3d Interactions with a Situated See-through Display},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208405},
doi = {10.1145/2207676.2208405},
abstract = {HoloDesk is an interactive system combining an optical see through display and Kinect camera to create the illusion that users are directly interacting with 3D graphics. A virtual image of a 3D scene is rendered through a half silvered mirror and spatially aligned with the real-world for the viewer. Users easily reach into an interaction volume displaying the virtual image. This allows the user to literally get their hands into the virtual display and to directly interact with an spatially aligned 3D virtual world, without the need for any specialized head-worn hardware or input device. We introduce a new technique for interpreting raw Kinect data to approximate and track rigid (e.g., books, cups) and non-rigid (e.g., hands, paper) physical objects and support a variety of physics-inspired interactions between virtual and real. In particular the algorithm models natural human grasping of virtual objects with more fidelity than previously demonstrated. A qualitative study highlights rich emergent 3D interactions, using hands and real-world objects. The implementation of HoloDesk is described in full, and example application scenarios explored. Finally, HoloDesk is quantitatively evaluated in a 3D target acquisition task, comparing the system with indirect and glasses-based variants.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2421–2430},
numpages = {10},
keywords = {see-through display, augmented reality (ar), natural human grasping, kinect, 3d physics interactions},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208406,
author = {Girouard, Audrey and Tarun, Aneesh and Vertegaal, Roel},
title = {DisplayStacks: Interaction Techniques for Stacks of Flexible Thin-Film Displays},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208406},
doi = {10.1145/2207676.2208406},
abstract = {Stacking physical documents is one of the main forms of spatio-temporal organization of information. We present DisplayStacks, a system that enables physical stacking of digital documents via piles of flexible E Ink displays. With a conductive dot pattern sensor attached to the flexible display, we dynamically track the position and orientation of these displays in relation to one another. We introduce mechanisms for interacting with these physical stacks for access and manipulation of information using asymmetric bi-manual interactions, such as providing contextual overviews. Initial user experiences indicate a preference for linear overlaps as a stacking configuration.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2431–2440},
numpages = {10},
keywords = {e ink, flexible displays, stacks, organic user interfaces},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250512,
author = {Cramer, Henriette},
title = {Session Details: Social Computing: Business &amp; Beyond},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250512},
doi = {10.1145/3250512},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208408,
author = {Brecht, Franziska and Eckhardt, Andreas and Berger, Christian and Guenther, Oliver},
title = {Corporate Career Presences on Social Network Sites: An Analysis of Hedonic and Utilitarian Value},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208408},
doi = {10.1145/2207676.2208408},
abstract = {Due to the shortage of skilled workforce and the increasing usage of social network sites, companies increasingly apply social network sites to attract potential applicants. This paper explores how corporate career presences on network sites should be realized in order to attract potential applicants. Therefore, we tested the impact of seven individual characteristics (namely Appointments, Daily Working Routine, Jobs, Corporate News, Entertainment, Media Format, and Features) of these corporate career presences that we extracted by a comprehensive pre-study on users' perceived hedonic and utilitarian value of these presences on social network sites. Based on an online survey with 470 participants, the results reveal a highly significant impact of five characteristics that corporate career presences provide both a hedonic as well as a utilitarian value to the user.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2441–2450},
numpages = {10},
keywords = {website characteristics, technology acceptance, structural equation modeling, social network sites, hedonic and utilitarian information systems, employer branding},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208409,
author = {Diakopoulos, Nicholas and De Choudhury, Munmun and Naaman, Mor},
title = {Finding and Assessing Social Media Information Sources in the Context of Journalism},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208409},
doi = {10.1145/2207676.2208409},
abstract = {Social media is already a fixture for reporting for many journalists, especially around breaking news events where non-professionals may already be on the scene to share an eyewitness report, photo, or video of the event. At the same time, the huge amount of content posted in conjunction with such events serves as a challenge to finding interesting and trustworthy sources in the din of the stream. In this paper we develop and investigate new methods for filtering and assessing the verity of sources found through social media by journalists. We take a human centered design approach to developing a system, SRSR ("Seriously Rapid Source Review"), informed by journalistic practices and knowledge of information production in events. We then used the system, together with a realistic reporting scenario, to evaluate the filtering and visual cue features that we developed. Our evaluation offers insights into social media information sourcing practices and challenges, and highlights the role technology can play in the solution.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2451–2460},
numpages = {10},
keywords = {news events, computational journalism, social media},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208410,
author = {Liao, Q. Vera and Wagner, Claudia and Pirolli, Peter and Fu, Wai-Tat},
title = {Understanding Experts' and Novices' Expertise Judgment of Twitter Users},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208410},
doi = {10.1145/2207676.2208410},
abstract = {Judging topical expertise of micro-blogger is one of the key challenges for information seekers when deciding which information sources to follow. However, it is unclear how useful different types of information are for people to make expertise judgments and to what extent their background knowledge influences their judgments. This study explored differences between experts and novices in inferring expertise of Twitter users. In three conditions, participants rated the level of expertise of users after seeing (1) only the tweets, (2) only the contextual information including short biographical and user list information, and (3) both tweets and contextual information. Results indicated that, in general, contextual information provides more useful information for making expertise judgment of Twitter users than tweets. While the addition of tweets seems to make little difference, or even add nuances to novices' expertise judgment, experts' judgments were improved when both content and contextual information were presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2461–2464},
numpages = {4},
keywords = {expertise judgment, twitter, recommendation system},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250513,
author = {Thomas, John},
title = {Session Details: Programming, Performance, &amp; Sense Making},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250513},
doi = {10.1145/3250513},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208412,
author = {Gomez, Steven and Laidlaw, David},
title = {Modeling Task Performance for a Crowd of Users from Interaction Histories},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208412},
doi = {10.1145/2207676.2208412},
abstract = {We present TOME, a novel framework that helps developers quantitatively evaluate user interfaces and design iterations by using histories from crowds of end users. TOME collects user-interaction histories via an interface instrumentation library as end users complete tasks; these histories are compiled using the Keystroke-Level Model (KLM) into task completion-time predictions using CogTool. With many histories, TOME can model prevailing strategies for tasks without needing an HCI specialist to describe users' interaction steps. An unimplemented design change can be evaluated by perturbing a TOME task model in CogTool to reflect the change, giving a new performance prediction. We found that predictions for quick (5-60s) query tasks in an instrumented brain-map interface averaged within 10% of measured expert times. Finally, we modified a TOME model to predict closely the speed-up yielded by a proposed interaction before implementing it.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2465–2468},
numpages = {4},
keywords = {user interfaces, klm, histories, performance modeling},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208413,
author = {Bogart, Christopher and Burnett, Margaret and Douglass, Scott and Adams, Hannah and White, Rachel},
title = {Designing a Debugging Interaction Language for Cognitive Modelers: An Initial Case Study in Natural Programming Plus},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208413},
doi = {10.1145/2207676.2208413},
abstract = {In this paper, we investigate how a debugging environment should support a population doing work at the core of HCI research: cognitive modelers. In conducting this investigation, we extended the Natural Programming methodology (a user-centered design method for HCI researchers of programming environments), to add an explicit method for mapping the outcomes of NP's empirical investigations to a language design. This provided us with a concrete way to make the design leap from empirical assessment of users' needs to a language. The contributions of our work are therefore: (1) empirical evidence about the content and sequence of cognitive modelers' information needs when debugging, (2) a new, empirically derived, design specification for a debugging interaction language for cognitive modelers, and (3) an initial case study of our "Natural Programming Plus" methodology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2469–2478},
numpages = {10},
keywords = {natural programming, cognitive model, end-user software engineering, evaluation abstraction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208414,
author = {Teo, Leong-Hwee and John, Bonnie and Blackmon, Marilyn},
title = {CogTool-Explorer: A Model of Goal-Directed User Exploration That Considers Information Layout},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208414},
doi = {10.1145/2207676.2208414},
abstract = {CogTool-Explorer 1.2 (CTE1.2) predicts novice exploration behavior and how it varies with different user-interface (UI) layouts. CTE1.2 improves upon previous models of information foraging by adding a model of hierarchical visual search to guide foraging behavior. Built within CogTool so it is easy to represent UI layouts, run the model, and present results, CTE1.2's vision is to assess many design ideas at the storyboard stage before implementation and without the cost of running human participants. This paper evaluates CTE1.2 predictions against observed human behavior on 108 tasks (36 tasks on 3 distinct website layouts). CTE1.2's predictions accounted for 63-82% of the variance in the percentage of participants succeeding on each task, the number of clicks to success, and the percentage of participants succeeding without error. We demonstrate how these predictions can be used to identify areas of the UI in need of redesign.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2479–2488},
numpages = {10},
keywords = {ACT-R, CogTool, human performance modeling, information foraging},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208415,
author = {Swearngin, Amanda and Cohen, Myra and John, Bonnie and Bellamy, Rachel},
title = {Easing the Generation of Predictive Human Performance Models from Legacy Systems},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208415},
doi = {10.1145/2207676.2208415},
abstract = {With the rise of tools for predictive human performance modeling in HCI comes a need to model legacy applications. Models of legacy systems are used to compare products to competitors, or new proposed design ideas to the existing version of an application. We present CogTool-Helper, an exemplar of a tool that results from joining this HCI need to research in automatic GUI testing from the Software Engineering testing community. CogTool-Helper uses automatic UI-model extraction and test case generation to automatically create CogTool storyboards and models and infer methods to accomplish tasks beyond what the UI designer has specified. A design walkthrough with experienced CogTool users reveal that CogTool-Helper resonates with a "pain point" of real-world modeling and provide suggestions for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2489–2498},
numpages = {10},
keywords = {automatic gui testing, predictive human performance modeling},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250514,
author = {Bardzell, Jeffrey},
title = {Session Details: Design Theory &amp; Practice},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250514},
doi = {10.1145/3250514},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208417,
author = {Tholander, Jakob and Normark, Maria and Rossitto, Chiara},
title = {Understanding Agency in Interaction Design Materials},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208417},
doi = {10.1145/2207676.2208417},
abstract = {We draw on the concept of agency in order to understand the process of how design materials 'talk back' to designers. In so doing, we illustrate the various levels at which agency can emerge in the context of intensive short-time prototyping sessions. In HCI, it is often assumed that the designer is the agent that acts intentionally in the design process. Contrary to this, recent notions of agency provide a way of analysing the performative role of design materials as intra-actions between components within a given phenomenon, rather than as meanings merely ascribed by actions of designers. The notion of agency puts focus on the emerging properties of materials and how they actively contribute to the way that design activity unfolds. The analyses showed how interaction design is to a large extent driven by emergent characteristics of available materials. The results have implications for understanding material interactions and materiality in interaction design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2499–2508},
numpages = {10},
keywords = {materiality, agency, material interactions, interaction design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208418,
author = {Denef, Sebastian and Keyson, David},
title = {Talking about Implications for Design in Pattern Language},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208418},
doi = {10.1145/2207676.2208418},
abstract = {In this paper we present our approach to capture and share knowledge from field studies using pattern language and thereby inform the design of ubiquitous computing. In our case, we studied frontline firefighting by observing the existing practice, by developing empathy through participation and by introducing new technology as triggering artifacts. Applying grounded theory, we distilled our findings into pattern language describing core aspects of this practice and their interaction. In a workshop, we introduced the pattern language to developers who had no previous knowledge of this practice and, in follow-up interviews, confronted them with new technology proposals for firefighters. Our study shows that pattern language, while not to be confused with an immutable description of the status quo or a direct path from contextual analysis to design, supports a reflective discussion of novel technology and the fit with and potential impact on existing practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2509–2518},
numpages = {10},
keywords = {firefighting, ethnography, design, ubiquitous computing, pattern language},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208419,
author = {San pedro, Jose and Suryanarayan, Poonam},
title = {Your Opinion Counts! Leveraging Social Comments for Analyzing Aesthetic Perception of Photographs.},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208419},
doi = {10.1145/2207676.2208419},
abstract = {This paper presents a novel method for estimating the main factors that influence aesthetic perception of photographs. This goal is achieved by automatically leveraging comments written by professional and knowledgeable photographers in specialized community websites. The statistical analysis of the resulting data shows the importance of multiple visual attributes in aesthetic perception, and their interaction effects with different photography categories. This technique can be applied in personalization and ranking of search results, and has the potential to reveal relevant factors in other domains.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2519–2522},
numpages = {4},
keywords = {user comments, sentiment analysis, photography, community knowledge, factorial analysis, aesthetic value},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250539,
author = {Lyons, Kent},
title = {Session Details: Interactions beyond the Desktop},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250539},
doi = {10.1145/3250539},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208638,
author = {Zhang, Haimo and Cao, Xiang and Zhao, Shengdong},
title = {Beyond Stereo: An Exploration of Unconventional Binocular Presentation for Novel Visual Experience},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208638},
doi = {10.1145/2207676.2208638},
abstract = {Human stereo vision processes the two different images seen by the two eyes to generate depth sensation. While current stereoscopic display technologies look at how to faithfully simulate the stereo viewing experience, we took a look out of this scope, to explore how we may present binocular image pairs that differ in other ways to create novel visual experience. This paper presents several interesting techniques we explored, and discusses their potential applications according to an informal user study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2523–2526},
numpages = {4},
keywords = {special effect, binocular visualization, stereo},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208639,
author = {Casiez, G\'{e}ry and Roussel, Nicolas and Vogel, Daniel},
title = {1 € Filter: A Simple Speed-Based Low-Pass Filter for Noisy Input in Interactive Systems},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208639},
doi = {10.1145/2207676.2208639},
abstract = {The 1 € filter ("one Euro filter") is a simple algorithm to filter noisy signals for high precision and responsiveness. It uses a first order low-pass filter with an adaptive cutoff frequency: at low speeds, a low cutoff stabilizes the signal by reducing jitter, but as speed increases, the cutoff is increased to reduce lag. The algorithm is easy to implement, uses very few resources, and with two easily understood parameters, it is easy to tune. In a comparison with other filters, the 1 € filter has less lag using a reference amount of jitter reduction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2527–2530},
numpages = {4},
keywords = {jitter, responsiveness, noise, signal, filtering, precision, lag},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208640,
author = {Kim, Kibum and Bolton, John and Girouard, Audrey and Cooperstock, Jeremy and Vertegaal, Roel},
title = {TeleHuman: Effects of 3d Perspective on Gaze and Pose Estimation with a Life-Size Cylindrical Telepresence Pod},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208640},
doi = {10.1145/2207676.2208640},
abstract = {In this paper, we present TeleHuman, a cylindrical 3D display portal for life-size human telepresence. The TeleHuman 3D videoconferencing system supports 360 degree motion parallax as the viewer moves around the cylinder and optionally, stereoscopic 3D display of the remote person. We evaluated the effect of perspective cues on the conveyance of nonverbal cues in two experiments using a one-way telecommunication version of the system. The first experiment focused on how well the system preserves gaze and hand pointing cues. The second experiment evaluated how well the system conveys 3D body postural information. We compared 3 perspective conditions: a conventional 2D view, a 2D view with 360 degree motion parallax, and a stereoscopic view with 360 degree motion parallax. Results suggest the combined presence of motion parallax and stereoscopic cues significantly improved the accuracy with which participants were able to assess gaze and hand pointing cues, and to instruct others on 3D body poses. The inclusion of motion parallax and stereoscopic cues also led to significant increases in the sense of social presence and telepresence reported by participants.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2531–2540},
numpages = {10},
keywords = {cylindrical display, telepresence, 3d video, organic user interfaces, videoconference, motion parallax},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208641,
author = {Karnik, Abhijit and Mayol-Cuevas, Walterio and Subramanian, Sriram},
title = {MUSTARD: A Multi User See through AR Display},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208641},
doi = {10.1145/2207676.2208641},
abstract = {We present MUSTARD, a multi-user dynamic random hole see-through display, capable of delivering viewer dependent information for objects behind a glass cabinet. Multiple viewers are allowed to observe both the physical object(s) being augmented and their location dependent annotations at the same time. The system consists of two liquid-crystal (LC) panels within which physical objects can be placed. The back LC panel serves as a dynamic mask while the front panel serves as the data. We first describe the principle of MUSTARD and then examine various functions that can be used to minimize crosstalk between multiple viewer positions. We compare different conflict management strategies using PSNR and the quality mean opinion score of HDR-VDP2. Finally, through a user-study we show that users can clearly identify images and objects even when the images are shown with strong conflicting regions; demonstrating that our system works even in the most extreme of circumstances.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2541–2550},
numpages = {10},
keywords = {multi-view, multi-user, see-through, augmented reality, random hole display},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208642,
author = {Oyekoya, Oyewole and Steptoe, William and Steed, Anthony},
title = {SphereAvatar: A Situated Display to Represent a Remote Collaborator},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208642},
doi = {10.1145/2207676.2208642},
abstract = {An emerging form of telecollaboration utilizes situated or mobile displays at a physical destination to virtually represent remote visitors. An example is a personal telepresence robot, which acts as a physical proxy for a remote visitor, and uses cameras and microphones to capture its surroundings, which are transmitted back to the visitor. We propose the use of spherical displays to represent telepresent visitors at a destination. We suggest that the use of such 360 degree displays in a telepresence system has two key advantages: it is possible to understand the identity of the visitor from any viewpoint; and with suitable graphical representation, it is possible to tell where the visitor is looking from any viewpoint. In this paper, we investigate how to optimally represent a visitor as an avatar on a spherical display by evaluating how varying representations are able to accurately convey head gaze.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2551–2560},
numpages = {10},
keywords = {remote collaboration, mixed reality, avatars, telerobotics, telepresence, spherical displays},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250540,
author = {R\"{a}ih\"{a}, Kari-Jouko},
title = {Session Details: Right Where i Am: UX in Complex Environments},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250540},
doi = {10.1145/3250540},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208644,
author = {Amini, Shahriyar and Brush, A.J. and Krumm, John and Teevan, Jaime and Karlson, Amy},
title = {Trajectory-Aware Mobile Search},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208644},
doi = {10.1145/2207676.2208644},
abstract = {Most location-aware mobile applications only make use of the user's current location, but there is an opportunity for them to infer the user's future locations. We present Trajectory-Aware Search (TAS), a mobile local search application that predicts the user's destination in real-time based on location data from the current trip and shows search results near the predicted location. TAS demonstrates the feasibility of destination prediction in an interactive mobile application. Our user study of TAS shows using predicted destinations to help select search results positively augments the local search experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2561–2564},
numpages = {4},
keywords = {location prediction, mobile local search, mobile systems},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208645,
author = {Mulloni, Alessandro and Seichter, Hartmut and D\"{u}nser, Andreas and Baudisch, Patrick and Schmalstieg, Dieter},
title = {360° Panoramic Overviews for Location-Based Services},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208645},
doi = {10.1145/2207676.2208645},
abstract = {We investigate 360° panoramas as overviews to support users in the task of locating objects in the surrounding environment. Panoramas are typically visualized as rectangular photographs, but this does not provide clear cues for physical directions in the environment. In this paper, we conduct a series of studies with three different shapes: Frontal, Top-Down and Bird's Eye; the last two shapes are chosen because they provide a clearer representation of the spatial mapping between panorama and environment. Our results show that good readability of the panorama is most important and that a clear representation of the spatial mapping plays a secondary role. This paper is the first to provide understanding on how users exploit 360° panoramic over-views to locate objects in the surrounding environment and how different design factors can affect user performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2565–2568},
numpages = {4},
keywords = {visualization, location-based service, magic lens, panorama},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208646,
author = {H\"{u}hn, Arief Ernst and Khan, Vassilis-Javed and Lucero, Andr\'{e}s and Ketelaar, Paul},
title = {On the Use of Virtual Environments for the Evaluation of Location-Based Applications},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208646},
doi = {10.1145/2207676.2208646},
abstract = {User experience (UX) research on pervasive technologies faces considerable challenges regarding today's mobile context-sensitive applications: evaluative field studies lack control, whereas lab studies miss the interaction with a dynamic context. This dilemma has inspired researchers to use virtual environments (VEs) to acquire control while offering the user a rich contextual experience. Although promising, these studies are mainly concerned with usability and the technical realization of their setup. Furthermore, previous setups leave room for improvement regarding the user's immersive experience. This paper contributes to this line of research by presenting a UX case study on mobile advertising with a novel CAVE-smartphone interface. We conducted two experiments in which we evaluated the intrusiveness of a mobile location-based advertising app in a virtual supermarket. The results confirm our hypothesis that context-congruent ads lessen the experienced intrusiveness thereby demonstrating that our setup is capable of generating preliminary meaningful results with regards to UX. Furthermore, we share insights in conducting these studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2569–2578},
numpages = {10},
keywords = {mixed reality, location-based services, user experience evaluation, pervasive computing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208647,
author = {Boonsuk, Wutthigrai and Gilbert, Stephen and Kelly, Jonathan},
title = {The Impact of Three Interfaces for 360-Degree Video on Spatial Cognition},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208647},
doi = {10.1145/2207676.2208647},
abstract = {In this paper, we describe an experiment designed to evaluate the effectiveness of three interfaces for surveillance or remote control using live 360-degree video feeds from a person or vehicle in the field. Video feeds are simulated using a game engine. While locating targets within a 3D terrain using a 2D 360-degree interface, participants indicated perceived egocentric directions to targets and later placed targets on an overhead view of the terrain. Interfaces were compared based on target finding and map placement performance. Results suggest 1) non-seamless interfaces with visual boundaries facilitate spatial understanding, 2) correct perception of self-to-object relationships is not correlated with understanding object-to-object relationships within the environment, and 3) increased video game experience corresponds with better spatial understanding of an environment observed in 360-degrees. This work can assist researchers of panoramic video systems in evaluating the optimal interface for observation and teleoperation of remote systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2579–2588},
numpages = {10},
keywords = {spatial cognition, 360-degree view, virtual navigation, panorama},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250541,
author = {Kientz, Julie},
title = {Session Details: Health &amp; Children},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250541},
doi = {10.1145/3250541},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208649,
author = {Escobedo, Lizbeth and Nguyen, David H. and Boyd, LouAnne and Hirano, Sen and Rangel, Alejandro and Garcia-Rosas, Daniel and Tentori, Monica and Hayes, Gillian},
title = {MOSOCO: A Mobile Assistive Tool to Support Children with Autism Practicing Social Skills in Real-Life Situations},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208649},
doi = {10.1145/2207676.2208649},
abstract = {MOSOCO is a mobile assistive application that uses augmented reality and the visual supports of a validated curriculum, the Social Compass, to help children with autism practice social skills in real-life situations. In this paper, we present the results of a seven-week deployment study of MOSOCO in a public school in Southern California with both students with autism and neurotypical students. The results of our study demonstrate that MOSOCO facilitates practicing and learning social skills, increases both quantity and quality of social interactions, reduces social and behavioral missteps, and enables the integration of children with autism in social groups of neurotypical children. The findings from this study reveal emergent practices of the uses of mobile assistive technologies in real-life situations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2589–2598},
numpages = {10},
keywords = {mobile applications, child-computer interaction, social skills, assistive technology, augmented reality, autism},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208650,
author = {Benton, Laura and Johnson, Hilary and Ashwin, Emma and Brosnan, Mark and Grawemeyer, Beate},
title = {Developing IDEAS: Supporting Children with Autism within a Participatory Design Team},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208650},
doi = {10.1145/2207676.2208650},
abstract = {IDEAS (Interface Design Experience for the Autistic Spectrum) is a method for involving children with Autism Spectrum Disorders (ASD) in the technology design process. This paper extends the IDEAS method to enable use with a design team, providing specific added support for communication and collaboration difficulties that may arise. A study to trial this extended method was conducted with two design teams, each involving three children with ASD, in a series of six, weekly design sessions focused on designing a math game. The findings from this study reveal that the children were able to successfully participate in the sessions and collaborate with other children. The findings also highlight the positive experience that involvement in such a process can offer this population.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2599–2608},
numpages = {10},
keywords = {educational games, autism, participatory design, children},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208651,
author = {Hourcade, Juan Pablo and Driessnack, Martha and Huebner, Kelsey E.},
title = {Supporting Face-to-Face Communication between Clinicians and Children with Chronic Headaches through a Zoomable Multi-Touch App},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208651},
doi = {10.1145/2207676.2208651},
abstract = {Chronic headaches are one of the top five health problems for young children in the United States, negatively affecting their quality of life and learning opportunities. A clear understanding of children's headache characteristics is crucial for delivering appropriate treatment. However, current data collection methods were designed for adults often resulting in insufficient information. In this paper we present a novel method to help children communicate with health care providers and researchers about their headaches. It augments an existing child-centric method called Draw-and-Tell Conversation, which has already been shown to provide more actionable information from children than standard data collection methods. It does so by enabling children to draw their symptoms on a zoomable drawing application, giving them the ability to provide more details and context than on paper. We present a study conducted with nineteen children aged 7 to 12 suggesting that children provided more information about their headaches when using the zoomable drawing application than when drawing on paper. This study provides a rare example of a mobile device used to enhance face-to-face interactions and contributes evidence of a specific benefit of zoomable user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2609–2618},
numpages = {10},
keywords = {communication, mobile devices, draw, pain, tablets, headaches, zoomable user interfaces, children},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208652,
author = {Hernandez, Hamilton A. and Graham, T.C. Nicholas and Fehlings, Darcy and Switzer, Lauren and Ye, Zi and Bellay, Quentin and Hamza, Md Ameer and Savery, Cheryl and Stach, Tadeusz},
title = {Design of an Exergaming Station for Children with Cerebral Palsy},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208652},
doi = {10.1145/2207676.2208652},
abstract = {We report on the design of a novel station supporting the play of exercise video games (exergames) by children with cerebral palsy (CP). The station combines a physical platform allowing children with CP to provide pedaling input into a game, a standard Xbox 360 controller, and algorithms for interpreting the cycling input to improve smoothness and accuracy of gameplay. The station was designed through an iterative and incremental participatory design process involving medical professionals, game designers, computer scientists, kinesiologists, physical therapists, and eight children with CP. It has been tested through observation of its use, through gathering opinions from the children, and through small experimental studies. With our initial design, only three of eight children were capable of playing a cycling-based game; with the final design, seven of eight could cycle effectively, and six reached energy expenditure levels recommended by the American College of Sports Medicine while pedaling unassisted.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2619–2628},
numpages = {10},
keywords = {exergaming station, exergame, accessibility, exertion interface, video game design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250542,
author = {Wulf, Volker},
title = {Session Details: Comfortable Aging},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250542},
doi = {10.1145/3250542},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208654,
author = {Wallace, Jayne and Thieme, Anja and Wood, Gavin and Schofield, Guy and Olivier, Patrick},
title = {Enabling Self, Intimacy and a Sense of Home in Dementia: An Enquiry into Design in a Hospital Setting},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208654},
doi = {10.1145/2207676.2208654},
abstract = {Design and digital technologies to support a sense of self and human relationships for people living with dementia are both urgently needed. We present an enquiry into design for dementia facilitated by a public art commission for an adult mental health unit in a hospital in the UK. The interactive art piece was informed by the notion of personhood in dementia that foregrounds the person's social being and interpersonal relationships as sites where self is maintained and constructed. How clients, clients' family members and staff used the piece is reported and insights related to the notions of home, intimacy, possessions and self are presented. The art piece served as window on both dementia and the institution leading to a number of insights and implications for design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2629–2638},
numpages = {10},
keywords = {dementia, design. , self, dignity, empathy, home, intimacy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208655,
author = {M\"{u}ller, Claudia and Neufeldt, Cornelius and Randall, David and Wulf, Volker},
title = {ICT-Development in Residential Care Settings: Sensitizing Design to the Life Circumstances of the Residents of a Care Home},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208655},
doi = {10.1145/2207676.2208655},
abstract = {In this paper we wish to contribute to the recent ICT-design for and reflection of the application field of residential care homes. In doing so, the contribution of the paper is twofold: we wish to highlight some aspects of the every-day life of institutionalized elderly people - trust, sociality, and memory - which not only provoke reflection on design ideas but also on the socio-technical nexus in which design for the elderly has to take place. This domain, we suggest, is one where the 'parachuting in' of technology is unlikely to prove successful, for reasons we examine below. Further, we suggest that design for and with the elderly carries with it some specific problems. We illustrate our methodological reflections by means of an ongoing empirical research project which aims at the development of a large-screen display for a residential care home.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2639–2648},
numpages = {10},
keywords = {methodology, residential care, action research, design, elderly people, large-screen display},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208656,
author = {Brehmer, Matthew and McGrenere, Joanna and Tang, Charlotte and Jacova, Claudia},
title = {Investigating Interruptions in the Context of Computerised Cognitive Testing for Older Adults},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208656},
doi = {10.1145/2207676.2208656},
abstract = {Interruptions in the home pose a threat to the validity of self-administered computerised cognitive testing. We report the findings of a laboratory experiment investigating the effects of increased interruption workload demand on older adults' computerised cognitive test performance. Related work has reported interruptions having a range of inhibitory and facilitatory effects on primary task performance. Cognitive ageing literature suggests that increased interruption workload demand should have greater detrimental effects on older adults' performance, when compared to younger adults. With 36 participants from 3 age groups (20-54, 55-69, 70+), we found divergent effects of increased interruption demand on two primary tasks. Results suggest that older and younger adults experience interruptions differently, but at no age is test performance compromised by demanding interruptions. This finding is reassuring with respect to the success of a self-administered computerised cognitive assessment test, and is likely to be useful for other applications used by older adults.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2649–2658},
numpages = {10},
keywords = {interruptions, computerised cognitive assessment, task resumption, older adults, experiment},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250543,
author = {Bailey, Brian},
title = {Session Details: Touch Text Entry},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250543},
doi = {10.1145/3250543},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208658,
author = {Henze, Niels and Rukzio, Enrico and Boll, Susanne},
title = {Observational and Experimental Investigation of Typing Behaviour Using Virtual Keyboards for Mobile Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208658},
doi = {10.1145/2207676.2208658},
abstract = {With the rise of current smartphones, virtual keyboards for touchscreens became the dominant mobile text entry technique. We developed a typing game that records how users touch on the standard Android keyboard to investigate users' typing behaviour. 47,770,625 keystrokes from 72,945 installations have been collected by publishing the game. By visualizing the touch distribution we identified a systematic skew and derived a function that compensates this skew by shifting touch events. By updating the game we conduct an experiment that investigates the effect of shifting touch events, changing the keys' labels, and visualizing the touched position. Results based on 6,603,659 keystrokes and 13,013 installations show that visualizing the touched positions using a simple dot decreases the error rate of the Android keyboard by 18.3% but also decreases the speed by 5.2% with no positive effect on learnability. The Android keyboard outperforms the control condition but the constructed shift function further improves the performance by 2.2% and decreases the error rate by 9.1%. We argue that the shift function can improve existing keyboards at no costs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2659–2668},
numpages = {10},
keywords = {virtual keyboard, touchscreen, public study, mobile phone},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208659,
author = {Dunlop, Mark and Levine, John},
title = {Multidimensional Pareto Optimization of Touchscreen Keyboards for Speed, Familiarity and Improved Spell Checking},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208659},
doi = {10.1145/2207676.2208659},
abstract = {This paper presents a new optimization technique for keyboard layouts based on Pareto front optimization. We used this multifactorial technique to create two new touchscreen phone keyboard layouts based on three design metrics: minimizing finger travel distance in order to maximize text entry speed, a new metric to maximize the quality of spell correction by reducing tap ambiguity, and maximizing familiarity through a similarity function with the standard Qwerty layout. The paper describes the optimization process and resulting layouts for a standard trapezoid shaped keyboard and a more rectangular layout. Fitts' law modelling shows a predicted 11% improvement in entry speed without taking into account the significantly improved error correction potential and the subsequent effect on speed. In initial user tests typing speed dropped from approx. 21 wpm with Qwerty to 13 wpm (64%) on first use of our layout but recovered to 18 wpm (85%) within four short trial sessions, and was still improving. NASA TLX forms showed no significant difference on load between Qwerty and our new layout use in the fourth session. Together we believe this shows the new layouts are faster and can be quickly adopted by users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2669–2678},
numpages = {10},
keywords = {text entry studies, mobile text entry, pareto front optimization, touch-screen keyboard design},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208660,
author = {Findlater, Leah and Lee, Ben and Wobbrock, Jacob},
title = {Beyond QWERTY: Augmenting Touch Screen Keyboards with Multi-Touch Gestures for Non-Alphanumeric Input},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208660},
doi = {10.1145/2207676.2208660},
abstract = {Although many techniques have been proposed to improve text input on touch screens, the vast majority of this research ignores non-alphanumeric input (i.e., punctuation, symbols, and modifiers). To support this input, widely adopted commercial touch-screen interfaces require mode switches to alternate keyboard layouts for most punctuation and symbols. Our approach is to augment existing ten-finger QWERTY keyboards with multi-touch gestural input that can exist as a complement to the moded-keyboard approach. To inform our design, we conducted a study to elicit user-defined gestures from 20 participants. The final gesture set includes both multi-touch and single-touch gestures for commonly used non-alphanumeric text input. We implemented and conducted a preliminary evaluation of a touch-screen keyboard augmented with this technique. Findings show that using gestures for non-alphanumeric input is no slower than using keys, and that users strongly prefer gestures to a moded-keyboard interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2679–2682},
numpages = {4},
keywords = {text input, gestures, touch-screen},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208661,
author = {Nicolau, Hugo and Jorge, Joaquim},
title = {Touch Typing Using Thumbs: Understanding the Effect of Mobility and Hand Posture},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208661},
doi = {10.1145/2207676.2208661},
abstract = {Mobile touch devices have become increasingly popular, yet typing on virtual keyboards whilst walking is still an overwhelming task. In this paper we analyze; firstly, the negative effect of walking on text-input performance, particularly the users' main difficulties and error patterns. We focused our research on thumb typing, since this is a commonly used technique to interact with touch interfaces. Secondly, we analyze how these effects can be compensated by two-hand interaction and increasing target size. We asked 22 participants to input text under three mobility conditions (seated, slow walking, and normal walking) and three hand conditions (one-hand/portrait, two-hand/portrait, and two-hand/landscape). Results show that independently of hand condition, mobility significantly decreased input quality, leading to specific error patterns. Moreover, it was shown that target size can compensate the negative effect of walking, while two-hand interaction does not provide additional stability or input accuracy. We finish with implications for future designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2683–2686},
numpages = {4},
keywords = {mobile, hand posture, walk, thumb, text-entry},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208662,
author = {Goel, Mayank and Findlater, Leah and Wobbrock, Jacob},
title = {WalkType: Using Accelerometer Data to Accomodate Situational Impairments in Mobile Touch Screen Text Entry},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208662},
doi = {10.1145/2207676.2208662},
abstract = {The lack of tactile feedback on touch screens makes typing difficult, a challenge exacerbated when situational impairments like walking vibration and divided attention arise in mobile settings. We introduce WalkType, an adaptive text entry system that leverages the mobile device's built-in tri-axis accelerometer to compensate for extraneous movement while walking. WalkType's classification model uses the displacement and acceleration of the device, and inference about the user's footsteps. Additionally, WalkType models finger-touch location and finger distance traveled on the screen, features that increase overall accuracy regardless of movement. The final model was built on typing data collected from 16 participants. In a study comparing WalkType to a control condition, WalkType reduced uncorrected errors by 45.2% and increased typing speed by 12.9% for walking participants.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2687–2696},
numpages = {10},
keywords = {situational impairments, virtual keyboard, touch screen, walking, mobile, text entry, adaptive},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250544,
author = {Elmqvist, Niklas},
title = {Session Details: Programming &amp; Debugging},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250544},
doi = {10.1145/3250544},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208664,
author = {Oney, Stephen and Brandt, Joel},
title = {Codelets: Linking Interactive Documentation and Example Code in the Editor},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208664},
doi = {10.1145/2207676.2208664},
abstract = {Programmers frequently use instructive code examples found on the Web to overcome cognitive barriers while programming. These examples couple the concrete functionality of code with rich contextual information about how the code works. However, using these examples necessitates understanding, configuring, and integrating the code, all of which typically take place after the example enters the user's code and has been removed from its original instructive context. In short, a user's interaction with an example continues well after the code is pasted. This paper investigates whether treating examples as "first-class" objects in the code editor - rather than simply as strings of text - will allow programmers to use examples more effectively. We explore this through the creation and evaluation of Codelets. A Codelet is presented inline with the user's code, and consists of a block of example code and an interactive helper widget that assists the user in understanding and integrating the example. The Codelet persists throughout the example's lifecycle, remaining accessible even after configuration and integration is done. A comparative laboratory study with 20 participants found that programmers were able to complete tasks involving examples an average of 43% faster when using Codelets than when using a standard Web browser.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2697–2706},
numpages = {10},
keywords = {structured editing, programming, example, documentation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208665,
author = {Xie, Jing and Lipford, Heather and Chu, Bei-Tseng},
title = {Evaluating Interactive Support for Secure Programming},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208665},
doi = {10.1145/2207676.2208665},
abstract = {Implementing secure code is an important and oft-overlooked non-functional requirement. Secure programming errors are a subset of program errors that result in many common privacy and security breaches in commercial software. We are seeking to provide interactive support for secure programming in the development environment. In this paper, we have evaluated our prototype tool, ASIDE, which provides real-time warnings and code generation to reduce secure programming errors introduced by programmers. We evaluate the potential use and effectiveness of ASIDE on both novice and professional developers in two comparison user studies. Our results demonstrate that the interactive support can help address this important non-functional requirement, and suggest guidelines for such tools to support programmers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2707–2716},
numpages = {10},
keywords = {software developers, software security, secure programming},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208666,
author = {Banovic, Nikola and Chevalier, Fanny and Grossman, Tovi and Fitzmaurice, George},
title = {Triggering Triggers and Burying Barriers to Customizing Software},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208666},
doi = {10.1145/2207676.2208666},
abstract = {General-purpose software applications are usually not tailored for a specific user with specific tasks, strategies or preferences. In order to achieve optimal performance with such applications, users typically need to transition to an alternative efficient behavior. Often, features of such alternative behaviors are not initially accessible and first need to be customized. However, few research works formally study and empirically measure what drives a user to customize. In this paper, we describe the challenges involved in empirically studying customization behaviors, and propose a methodology for formally measuring the impact of potential customization factors. We then demonstrate this methodology by studying the impact of different customization factors on customization behaviors. Our results show that increasing exposure and awareness of customization features, and adding social influence can significantly affect the user's customization behavior.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2717–2726},
numpages = {10},
keywords = {adaptable interfaces, customization, mixed-initiative, adaptive interfaces, personalization},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250545,
author = {Wakkary, Ron},
title = {Session Details: Organizing the Recovery},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250545},
doi = {10.1145/3250545},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208668,
author = {Muller, Michael and Chua, Sacha},
title = {Brainstorming for Japan: Rapid Distributed Global Collaboration for Disaster Response},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208668},
doi = {10.1145/2207676.2208668},
abstract = {Tragic events struck northern Japan in March-April 2011. This note presents a case study of rapid distributed brainstorming for disaster response, involving 275 contributors from 23 countries within a three-day period, conducted among the staff in a multinational company. Factors that appear to have contributed to the success of this brainstorming include: Social media that could be easily appropriated; and employee familiarity with large-scale brainstorming. The formation of this "flash-community" joins other CHI reports to point toward a new genre of rapid large-scale responses to disasters through social media.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2727–2730},
numpages = {4},
keywords = {social media, online community, virtual team, emergency management, disaster response},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250546,
author = {Shami, Sadat},
title = {Session Details: Tweet, Tweet, Tweet!},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250546},
doi = {10.1145/3250546},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208670,
author = {Gilbert, Eric},
title = {Designing Social Translucence over Social Networks},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208670},
doi = {10.1145/2207676.2208670},
abstract = {Social translucence is a landmark theory in social computing. Modeled on physical life, it guides designers toward elegant social technologies. However, we argue that it breaks down over modern social network sites because social networks resist its physical metaphors. In this paper, we build theory relating social translucence to social network structure. To explore this idea, we built a tool called Link Different. Link Different addresses a structural awareness problem by letting users know how many of their Twitter followers already a saw link via someone else they follow. During two months on the web, nearly 150K people used the site a total of 1.3M times. Its widespread, viral use suggests that people want social translucence, but network structure gets in the way. We conclude the paper by illustrating new design problems that lie at the intersection of social translucence and other unexplored network structures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2731–2740},
numpages = {10},
keywords = {design, cmc, social networks, social translucence, twitter},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208671,
author = {Archambault, Anne and Grudin, Jonathan},
title = {A Longitudinal Study of Facebook, LinkedIn, &amp; Twitter Use},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208671},
doi = {10.1145/2207676.2208671},
abstract = {We conducted four annual comprehensive surveys of social networking at Microsoft between 2008 and 2011. We are interested in how employees use these tools and whether they consider then useful for organizational communication and information-gathering. Our study is longitudinal and based on random sampling. Between 2008 and 2011, social networking went from being a niche activity to being very widely and heavily used. Growth in use and acceptance was not uniform, with differences based on gender, age and level (individual contributor vs. manager). Behaviors and concerns changed, with some showing signs of leveling off.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2741–2750},
numpages = {10},
keywords = {facebook, enterprise, twitter, social networking, linkedin},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208672,
author = {Hu, Mengdie and Liu, Shixia and Wei, Furu and Wu, Yingcai and Stasko, John and Ma, Kwan-Liu},
title = {Breaking News on Twitter},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208672},
doi = {10.1145/2207676.2208672},
abstract = {After the news of Osama Bin Laden's death leaked through Twitter, many people wondered if Twitter would fundamentally change the way we produce, spread, and consume news. In this paper we provide an in-depth analysis of how the news broke and spread on Twitter. We confirm the claim that Twitter broke the news first, and find evidence that Twitter had convinced a large number of its audience before mainstream media confirmed the news. We also discover that attention on Twitter was highly concentrated on a small number of "opinion leaders" and identify three groups of opinion leaders who played key roles in spreading the news: individuals affiliated with media played a large part in breaking the news, mass media brought the news to a wider audience and provided eager Twitter users with content on external sites, and celebrities helped to spread the news and stimulate conversation. Our findings suggest Twitter has great potential as a news medium.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2751–2754},
numpages = {4},
keywords = {opinion leaders, twitter, social media, breaking news},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208673,
author = {Golbeck, Jennifer},
title = {The Twitter Mute Button: A Web Filtering Challenge},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208673},
doi = {10.1145/2207676.2208673},
abstract = {The microblogging service Twitter has become an important, and sometimes primary, source of information for many users. As a forum for sharing news and discussing events, it can provide instant access to the latest updates, but this is not always welcome. In the case of television shows or live sporting events, for example, tweets about them may reveal spoilers to users in different time zones or who are delaying their viewing until later. More broadly, because Twitter is a broadcast medium, users may often want to temporarily or permanently hide content about a very specific given topic.In this paper, we describe the unique challenges to HCI, social computing, and computational linguistics posed by the task of building an interface that blocks all tweets about a specific event or topic. We illustrate some of the challenges through a pilot experiment run for three major television events: the 2009 NFC Championship football game, the 2010 mid-season finale of the show Glee, and the 2010 season premiere of the show 24. While simple techniques achieve very high recall (&gt;98%), spoilers still make it through the filter and precision is extremely poor. We conclude with a description of challenges to the community in implementing this new and increasingly important feature.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2755–2758},
numpages = {4},
keywords = {filtering, computational linguistics, twitter},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250547,
author = {Baillie, Lynne},
title = {Session Details: Me &amp; My Mobile},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250547},
doi = {10.1145/3250547},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208675,
author = {Licoppe, Christian and Inada, Yoriko},
title = { 'Timid Encounters': A Case Study in the Use of Proximity-Based Mobile Technologies},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208675},
doi = {10.1145/2207676.2208675},
abstract = {We report a comparative ethnographic study of a proximity-based mobile 'video game' (Dragon Quest 9) in Japan: the Nintendo DS game terminals may 'recognize' one another and allow players to exchange game resources when they are close to one another. Because different communication infrastructures are available, situations of encounter are shown to be potentially seamful and to support multi-layered participation frames. Our observations show a variety of encounter formats, among whom 'timid' encounters are the most characteristic of the kind of sociality which may develop in urban public places turned into proximity-sensitive 'hybrid ecologies' The normative order which governs such encounters is marked by a tension between the minimality expected of encounters with strangers in urban spaces, and the concern for identification and focused interaction that derives from being engaged in proximal digital communication. These empirical observations and framework of analysis offer insights for the design and the understanding of proximity-based mobile technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2759–2768},
numpages = {10},
keywords = {proximity, encounters, public space, hybrid ecology, gaming, mobility, locative media},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208676,
author = {Tossell, Chad and Kortum, Philip and Rahmati, Ahmad and Shepard, Clayton and Zhong, Lin},
title = {Characterizing Web Use on Smartphones},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208676},
doi = {10.1145/2207676.2208676},
abstract = {The current paper establishes empirical patterns associated with mobile internet use on smartphones and explores user differences in these behaviors. We apply a naturalistic and longitudinal logs-based approach to collect real usage data from 24 iPhone users in the wild. These data are used to describe smartphone usage and analyze revisitation patterns of web browsers, native applications, and physical locations where phones are used. Among our findings are that web page revisitation through browsers occurred very infrequently (approximately 25% of URLs are revisited by each user), bookmarks were used sparingly, physical traversing patterns mirrored virtual (internet) traversing patterns and users systematically differed in their web use. We characterize these differences and suggest ways to support users with enhanced design of smartphone technologies and content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2769–2778},
numpages = {10},
keywords = {web browsing, mobile web, revisitation, user differences, smartphone},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208677,
author = {Olsson, Thomas and Salo, Markus},
title = {Narratives of Satisfying and Unsatisfying Experiences of Current Mobile Augmented Reality Applications},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208677},
doi = {10.1145/2207676.2208677},
abstract = {Over the last few years, mobile applications demonstrating Augmented Reality (AR) - such as Layar, Junaio and Google Goggles - have been introduced to consumers. We conducted an online survey to explore the user experience (UX) of early stage mobile AR applications available in the market in spring 2011, covering both location-based AR browsers and image recognition AR applications for object-based interaction. We identify various types of experiences such applications have evoked by qualitatively analyzing 84 users' narratives of their most satisfying and unsatisfying experiences. The results highlight, for example, experiences of awareness of surroundings, empowerment, positive surprise, amazement and fascination from the novelty value, as well as some examples of immersion and social connectivity. The analysis indicates that the applications have not yet reached their potential in evoking a multifaceted user experience that is characteristic especially to AR. This work helps in understanding the experiential design potential in mobile AR and points out UX issues to further focus on in design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2779–2788},
numpages = {10},
keywords = {online survey, location-based service, user experience, user narration, end-user application, object-based interaction, mixed reality, evaluation, mobile augmented reality},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208678,
author = {Yi, Bo and Cao, Xiang and Fjeld, Morten and Zhao, Shengdong},
title = {Exploring User Motivations for Eyes-Free Interaction on Mobile Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208678},
doi = {10.1145/2207676.2208678},
abstract = {While there is increasing interest in creating eyes-free interaction technologies, a solid analysis of why users need or desire eyes-free interaction has yet to be presented. To gain a better understanding of such user motivations, we conducted an exploratory study with four focus groups, and suggest a classification of motivations for eyes-free interaction under four categories (environmental, social, device features, and personal). Exploring and analyzing these categories, we present early insights pointing to design implications for future eyes-free interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2789–2792},
numpages = {4},
keywords = {user motivation, eyes-free, mobile devices},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250548,
author = {Tolmie, Peter},
title = {Session Details: Understanding Gamers},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250548},
doi = {10.1145/3250548},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208680,
author = {Merritt, Tim and McGee, Kevin},
title = {Protecting Artificial Team-Mates: More Seems like Less},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208680},
doi = {10.1145/2207676.2208680},
abstract = {Previous research on conversational, competitive, and cooperative systems suggests that people respond differently to humans and AI agents in terms of perception and evaluation of observed team-mate behavior. However, there has not been research examining the relationship between participants' protective behavior toward human/AI team-mates and their beliefs about their behavior. A study was conducted in which 32 participants played two sessions of a cooperative game, once with a "presumed" human and once with an AI team-mate; players could "draw fire" from a common enemy by "yelling" at it. Overwhelmingly, players claimed they "drew fire" on behalf of the presumed human more than for the AI team-mate; logged data indicates the opposite. The main contribution of this paper is to provide evidence of the mismatch in player beliefs about their actions and actual behavior with humans or agents and provides possible explanations for the differences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2793–2802},
numpages = {10},
keywords = {casa, cscp, team-mate},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208681,
author = {Yee, Nick and Ducheneaut, Nicolas and Nelson, Les},
title = {Online Gaming Motivations Scale: Development and Validation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208681},
doi = {10.1145/2207676.2208681},
abstract = {Understanding gaming motivations is important given the growing trend of incorporating game-based mechanisms in non-gaming applications. In this paper, we describe the development and validation of an online gaming motivations scale based on a 3-factor model. Data from 2,071 US participants and 645 Hong Kong and Taiwan participants is used to provide a cross-cultural validation of the developed scale. Analysis of actual in-game behavioral metrics is also provided to demonstrate predictive validity of the scale.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2803–2806},
numpages = {4},
keywords = {online games, cross-cultural, scale development, player motivations, taxonomy, scale validation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208682,
author = {Terada, Kazunori and Yamada, Seiji and Ito, Akira},
title = {Experimental Investigation of Human Adaptation to Change in Agent's Strategy through a Competitive Two-Player Game},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208682},
doi = {10.1145/2207676.2208682},
abstract = {We conducted an experimental investigation on human adaptation to change in an agent's strategy through a competitive two-player game. Modeling the process of human adaptation to agents is important for designing intelligent interface agents and adaptive user interfaces that learn a user's preferences and behavior strategy. However, few studies on human adaptation to such an agent have been done. We propose a human adaptation model for a two-player game. We prepared an on-line experimental system in which a participant and an agent play a repeated penny-matching game with a bonus round. We then conducted experiments in which different opponent agents (human or robot) change their strategy during the game. The experimental results indicated that, as expected, there is an adaptation phase when a human is confronted with a change in the opponent agent's strategy, and adaptation is faster when a human is competing with robot than with another human.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2807–2810},
numpages = {4},
keywords = {human-agent interaction, intentional stance, two player game, appearance, human adaptation to an agent},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208683,
author = {Yee, Nick and Ducheneaut, Nicolas and Shiao, Han-Tai and Nelson, Les},
title = {Through the Azerothian Looking Glass: Mapping in-Game Preferences to Real World Demographics},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208683},
doi = {10.1145/2207676.2208683},
abstract = {Examining how in-game behavior preferences map onto real world demographics provides important empirically-derived insights into how to match game-based mechanisms to target demographic segments. Using behavioral and demographic data from 1,037 World of Warcraft players, we use multiple regressions to provide this mapping. Given current interest in "gamifying" applications, we believe these findings are relevant for both gaming and non-gaming research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2811–2814},
numpages = {4},
keywords = {in-game behaviors, player demographics, gamification},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250549,
author = {Hsieh, Gary},
title = {Session Details: Better Together},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250549},
doi = {10.1145/3250549},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208685,
author = {Muller, Michael and Ehrlich, Kate and Matthews, Tara and Perer, Adam and Ronen, Inbal and Guy, Ido},
title = {Diversity among Enterprise Online Communities: Collaborating, Teaming, and Innovating through Social Media},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208685},
doi = {10.1145/2207676.2208685},
abstract = {There is a growing body of research into the adoption and use of social software in enterprises. However, less is known about how groups, such as communities, use and appropriate these technologies, and the implications for community structures. In a study of 188 very active online enterprise communities, we found systematic differences in size, demographics and participation, aligned with differences in community types. Different types of communities differed in their appropriation of social software tools to create and use shared resources, and build relationships. We propose implications for design of community support features, services for potential community members, and organizations looking to derive value from online groups.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2815–2824},
numpages = {10},
keywords = {online communities, communities, communities of practice, teams, virtual teams, idea labs},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208686,
author = {Woelfer, Jill Palzkill and Hendry, David G.},
title = {Homeless Young People on Social Network Sites},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208686},
doi = {10.1145/2207676.2208686},
abstract = {This paper reports on the use of social network sites (MySpace and Facebook) by homeless young people, an extraordinary user population, made so in part by its vulnerability. Twenty-three participants of diverse ethnicities, 11 women and 12 men (mean age, 21.7 years), were interviewed in same-sex discussion groups of four participants each. The interviews consisted of questions about the uses, benefits, and harms of social network sites and how people present themselves online. Qualitative analysis of the discussion group transcripts shows how young people explore their identities, cultivate and exploit social ties, experience interpersonal tensions, manage incompatible audiences, and respond to shifting affiliations and transitions. From this analysis, implications for social intervention and technical design are presented, focused on maintaining ties with pro-social family and friends and with maintaining separation between communication spheres of incompatible audiences. This work contributes to the growing literature on vital, deeply human experiences that have become associated with social network sites.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2825–2834},
numpages = {10},
keywords = {vulnerability, social network sites, social and technical design, myspace, homeless young people, facebook},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208687,
author = {Draxler, Sebastian and Stevens, Gunnar and Stein, Martin and Boden, Alexander and Randall, David},
title = {Supporting the Social Context of Technology Appropriation: On a Synthesis of Sharing Tools and Tool Knowledge},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208687},
doi = {10.1145/2207676.2208687},
abstract = {There is an increasing spread of flexible software applications that can be modified by adding components (sometimes called plug-ins or add-ons). A popular example in the software development domain is Eclipse, a flexible development environment that can be extended with literally thousands of different plug-ins. However, searching, installing and configuring new plug-ins requires complex overhead work that is only weakly addressed by existing support mechanisms. Recent research has highlighted the related practices of learning about new plug-ins and tailoring software tools as being highly cooperative, situated, socially embedded, and often connected to particular work situations. Based on an empirical study in small software enterprises, we develop an understanding of appropriation as a social and collaborative activity. We then suggest design principles for appropriation support that are grounded in the practices we have found in the field, and present a prototypical implementation of the concept that extends existing mechanisms of sharing tools and tool-knowledge.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2835–2844},
numpages = {10},
keywords = {learning, help giving, workplace learning, tailorability, appropriation, ad-hoc, software development, peer-to-peer},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250550,
author = {Dearman, David},
title = {Session Details: Bigger is Better: Large &amp; Multiple Display Environments},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250550},
doi = {10.1145/3250550},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208689,
author = {Bardram, Jakob and Gueddana, Sofiane and Houben, Steven and Nielsen, S\o{}ren},
title = {ReticularSpaces: Activity-Based Computing Support for Physically Distributed and Collaborative Smart Spaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208689},
doi = {10.1145/2207676.2208689},
abstract = {Smart spaces research focuses on technology for multiple displays and devices for collocated participants. In most approaches, however, users have to cope with heterogeneous interfaces and information organization, as well as a lack of support for collaboration with mobile and remote users outside the smart space. In this paper, we present ReticularSpaces; a multi-display smart space system built on the principles of activity-based computing. The focus of ReticularSpaces is to support: (i) unified interaction with applications and documents through ReticularUI, a novel distributed user interfaces design; (ii) management of the complexity of tasks between users and displays; (iii) mobile users in a local, remote or 'nomadic' settings; and (iv) collaboration among local and remote users. We describe the motivation, design, and architecture of ReticularSpaces, and report from a preliminary feasibility study. The study shows that participants found ReticularSpaces useful and effective, but at the same time reveals new areas for research on smart environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2845–2854},
numpages = {10},
keywords = {smart spaces, multiple display environments, collaboration, nomadic computing, distributed user interfaces},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208690,
author = {Seifried, Thomas and Rendl, Christian and Haller, Michael and Scott, Stacey},
title = {Regional Undo/Redo Techniques for Large Interactive Surfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208690},
doi = {10.1145/2207676.2208690},
abstract = {When multiple users are simultaneously sharing a workspace, it is not always clear what should happen when a user invokes an undo action. In this paper we explore different user interfaces for undo/redo for co-located collaborative workspaces, such as large interactive whiteboards. A preliminary study revealed that users expect neither a global nor personal undo, but rather a regional undo. We propose and evaluate three automatic regional undo/redo techniques (clustering, workspace, field of view) designed for a large interactive whiteboard. The results of the evaluation showed that an undo technique based on users' field of view was most preferred, while the content-based clustering technique produced most errors. We conclude with potential improvements to the developed techniques, and propose a set of design recommendations for implementing regional undo/redo on large interactive surfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2855–2864},
numpages = {10},
keywords = {interactive whiteboard, interactive surfaces, multi-user input, undo, large displays, co-located collaboration},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208691,
author = {Jansen, Yvonne and Dragicevic, Pierre and Fekete, Jean-Daniel},
title = {Tangible Remote Controllers for Wall-Size Displays},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208691},
doi = {10.1145/2207676.2208691},
abstract = {We explore the use of customizable tangible remote controllers for interacting with wall-size displays. Such controllers are especially suited to visual exploration tasks where users need to move to see details of complex visualizations. In addition, we conducted a controlled user study suggesting that tangibles make it easier for users to focus on the visual display while they interact. We explain how to build such controllers using off-the-shelf touch tablets and describe a sample application that supports multiple dynamic queries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2865–2874},
numpages = {10},
keywords = {wall-size displays, tangible user interfaces, visual exploration},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250551,
author = {Benko, Hrvoje},
title = {Session Details: What a Lovely Gesture},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250551},
doi = {10.1145/3250551},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208693,
author = {L\"{u}, Hao and Li, Yang},
title = {Gesture Coder: A Tool for Programming Multi-Touch Gestures by Demonstration},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208693},
doi = {10.1145/2207676.2208693},
abstract = {Multi-touch gestures have become popular on a wide range of touchscreen devices, but the programming of these gestures remains an art. It is time-consuming and error-prone for a developer to handle the complicated touch state transitions that result from multiple fingers and their simultaneous movements. In this paper, we present Gesture Coder, which by learning from a few examples given by the developer automatically generates code that recognizes multi-touch gestures, tracks their state changes and invokes corresponding application actions. Developers can easily test the generated code in Gesture Coder, refine it by adding more examples, and once they are satisfied with its performance integrate the code into their applications. We evaluated our learning algorithm exhaustively with various conditions over a large set of noisy data. Our results show that it is sufficient for rapid prototyping and can be improved with higher quality and more training data. We also evaluated Gesture Coder's usability through a within-subject study in which we asked participants to implement a set of multi-touch interactions with and without Gesture Coder. The results show overwhelmingly that Gesture Coder significantly lowers the threshold of programming multi-touch gestures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2875–2884},
numpages = {10},
keywords = {programming by demonstration, eclipse plug-in., state machines, multi-touch gestures, decision trees},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208694,
author = {Kin, Kenrick and Hartmann, Bj\"{o}rn and DeRose, Tony and Agrawala, Maneesh},
title = {Proton: Multitouch Gestures as Regular Expressions},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208694},
doi = {10.1145/2207676.2208694},
abstract = {Current multitouch frameworks require application developers to write recognition code for custom gestures; this code is split across multiple event-handling callbacks. As the number of custom gestures grows it becomes increasingly difficult to 1) know if new gestures will conflict with existing gestures, and 2) know how to extend existing code to reliably recognize the complete gesture set. Proton is a novel framework that addresses both of these problems. Using Proton, the application developer declaratively specifies each gesture as a regular expression over a stream of touch events. Proton statically analyzes the set of gestures to report conflicts, and it automatically creates gesture recognizers for the entire set. To simplify the creation of complex multitouch gestures, Proton introduces gesture tablature, a graphical notation that concisely describes the sequencing of multiple interleaved touch actions over time. Proton contributes a graphical editor for authoring tablatures and automatically compiles tablatures into regular expressions. We present the architecture and implementation of Proton, along with three proof-of-concept applications. These applications demonstrate the expressiveness of the framework and show how Proton simplifies gesture definition and conflict resolution.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2885–2894},
numpages = {10},
keywords = {regular expressions, multitouch, UI framework, conflict detection, gesture tablature editor},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208695,
author = {Ouyang, Tom and Li, Yang},
title = {Bootstrapping Personal Gesture Shortcuts with the Wisdom of the Crowd and Handwriting Recognition},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208695},
doi = {10.1145/2207676.2208695},
abstract = {Personal user-defined gesture shortcuts have shown great potential for accessing the ever-growing amount of data and computing power on touchscreen mobile devices. However, their lack of scalability is a major challenge for their wide adoption. In this paper, we present Gesture Marks, a novel approach to touch-gesture interaction that allows a user to access applications and websites using gestures without having to define them first. It offers two distinctive solutions to address the problem of scalability. First, it leverages the "wisdom of the crowd", a continually evolving library of gesture shortcuts that are collected from the user population, to infer the meaning of gestures that a user never defined himself. Second, it combines an extensible template-based gesture recognizer with a specialized handwriting recognizer to even better address handwriting-based gestures, which are a common form of gesture shortcut. These approaches effectively bootstrap a user's personal gesture library, alleviating the need to define most gestures manually. Our work was motivated and validated via a series of user studies, and the findings from these studies add to the body of knowledge on gesture-based interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2895–2904},
numpages = {10},
keywords = {gesture-based interaction, search, mobile computing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250552,
author = {Poole, Erika},
title = {Session Details: Crowdsourcing &amp; Peer Production II},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250552},
doi = {10.1145/3250552},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208697,
author = {Wohn, Donghee and Velasquez, Alcides and Bjornrud, Tor and Lampe, Cliff},
title = {Habit as an Explanation of Participation in an Online Peer-Production Community},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208697},
doi = {10.1145/2207676.2208697},
abstract = {User activities in peer-production communities have mainly been examined under the assumption that individuals are rational individuals who are always cognizant of what they are doing and why. We argue that not all use is the same; while some behaviors are governed by conscious motivations, others may be a habitual response that is developed out of routine. We take a more granular approach to explaining what people are doing in online communities and how motivations and habits explain their use of specific features. In the context of the peer-production community Everything2 we employ both server log data and self-report, finding that habit is a non-conscious-driven behavior that is more associated with less cognitively-demanding tasks than content production.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2905–2914},
numpages = {10},
keywords = {motivations, online community, habit, computer supported collaborative work},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208698,
author = {Masli, Mikhil and Terveen, Loren},
title = {Evaluating Compliance-without-Pressure Techniques for Increasing Participation in Online Communities},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208698},
doi = {10.1145/2207676.2208698},
abstract = {Social psychology offers several theories of potential use for designing techniques to increase user contributions to online communities. Some of these techniques follow the "compliance without pressure" approach, where users are led to comply with a request without being subjected to any obvious external pressure. We evaluated two such techniques -- foot-in-the-door and low-ball -- in the context of Cyclopath, a geographic wiki. We found that while both techniques succeeded, low-ball elicited more work than foot-in-the-door. We discuss design and research implications of applying these (and other such techniques) in online communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2915–2924},
numpages = {10},
keywords = {online communities, compliance, social production, low-ball, increasing participation, foot-in-the-door},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208699,
author = {Antin, Judd and Shaw, Aaron},
title = {Social Desirability Bias and Self-Reports of Motivation: A Study of Amazon Mechanical Turk in the US and India},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208699},
doi = {10.1145/2207676.2208699},
abstract = {In this study we extend research on online collaboration by examining motivation to do work on the crowdsoucing service Amazon Mechanical Turk (MTurk). We address a challenge to many existing studies of motivation in online contexts: they are based on survey self-reports, which are susceptible to effects such as social desirability bias. In addition we investigate a second challenge to the extant research on motivation in the context of MTurk: a failure to examine potential differences between MTurk workers (Turkers) from different parts of the world, especially those from the US and India, MTurk's two largest worker groups. Using a survey technique called the list experiment, we observe distinct profiles of motivation and patterns of social desirability effects among Turkers in the US and India. Among US Turkers, we find that social desirability encourages over-reporting of each of four motivating factors we examined. The over-reporting was particularly large in the case of money as a motivator. In contrast, among Turkers in India we find a more complex pattern of social desirability effects, with workers under-reporting "killing time" and "fun" as motivations, and drastically over-reporting "sense of purpose." We conclude by discussing these results and proposing implications for future research and design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2925–2934},
numpages = {10},
keywords = {motivation, social desirability, amazon mechanical turk, crowdsourcing, distributed work},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208700,
author = {Hu, Chang and Resnik, Philip and Kronrod, Yakov and Bederson, Benjamin},
title = {Deploying Monotrans Widgets in the Wild},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208700},
doi = {10.1145/2207676.2208700},
abstract = {In this paper, we report our experience deploying the MonoTrans Widgets system in a public setting. Our work follows a line of crowd-sourced monolingual translation systems, and it is the first attempt to deploy such a system "in the wild". The results are promising, but we also found out that simultaneously drawing from multiple crowds with different expertise and sizes poses unique problems in the design of such crowd-sourcing systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2935–2938},
numpages = {4},
keywords = {human computation, monolingual, machine translation, translation interface, translation, wisdom of crowds, distributed human computation, crowd-sourcing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208701,
author = {Sarkar, Chandan and Wohn, Donghee and Lampe, Cliff and DeMaagd, Kurt},
title = {A Quantitative Explanation of Governance in an Online Peer-Production Community},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208701},
doi = {10.1145/2207676.2208701},
abstract = {In this paper, we examine how user ratings of content produced for an online community are taken into account by administrators when they decide whether to delete content. Incorporating about 10 years of server data from the online peer-production community Everything2, we looked at how specific features of voting predicted deletion of posts. We found that not all types of voting are the same: negative voting of users was the strongest factor explaining deletion of a Write-up. Receiving a positive vote from a member with higher status decreases the chances of deletion, while receiving a positive vote from a user with neutral status has a very little effect on the deletion of content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2939–2942},
numpages = {4},
keywords = {content editors, user voting, feedback, online community, decision-making, online governance, moderation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250553,
author = {Cox, Anna},
title = {Session Details: Usability &amp; User Research},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250553},
doi = {10.1145/3250553},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208703,
author = {Holland, Corey and Komogortsev, Oleg and Tamir, Dan},
title = {Identifying Usability Issues via Algorithmic Detection of Excessive Visual Search},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208703},
doi = {10.1145/2207676.2208703},
abstract = {Automated detection of excessive visual search (ES) experienced by a user during software use presents the potential for substantial improvement in the efficiency of supervised usability analysis. This paper presents an objective evaluation of several methods for the automated segmentation and classification of ES intervals from an eye movement recording, a technique that can be utilized to aid in the identification of usability problems during software usability testing. Techniques considered for automated segmentation of the eye movement recording into unique intervals include mouse/keyboard events and eye movement scanpaths. ES is identified by a number of eye movement metrics, including: fixation count, saccade amplitude, convex hull area, scanpath inflections, scanpath length, and scanpath duration. The ES intervals identified by each algorithm are compared to those produced by manual classification to verify the accuracy, precision, and performance of each algorithm. The results indicate that automated classification can be successfully employed to substantially reduce the amount of recorded data reviewed by HCI experts during usability testing, with relatively little loss in accuracy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2943–2952},
numpages = {10},
keywords = {usability testing., usability, human-computer interaction, visual search, eye tracking},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208704,
author = {Jianu, Radu and Laidlaw, David},
title = {An Evaluation of How Small User Interface Changes Can Improve Scientists' Analytic Strategies},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208704},
doi = {10.1145/2207676.2208704},
abstract = {Subtle changes in analysis system interfaces can be used purposely to alter users' analytic behaviors. In a controlled study subjects completed three analyses at one-week intervals using an analysis support system. Control subjects used one interface in all sessions. Test subjects used modified versions in the last two sessions: a first set of changes aimed at increasing subjects' use of the system and their consideration of alternative hypotheses; a second set of changes aimed at increasing the amount of evidence collected. Results show that in the second session test subjects used the interface 39% more and switched between hypotheses 19% more than in the first session. They then collected 26% more evidence in the third than in the second session. These increases differ significantly (p&lt;0.05) from near constant control rates. We hypothesize that this approach can be used in many real applications to guide analysts unobtrusively towards improved analytic strategies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2953–2962},
numpages = {10},
keywords = {analytic biases, visual analytics, persuasive technology},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208705,
author = {Navalpakkam, Vidhya and Churchill, Elizabeth},
title = {Mouse Tracking: Measuring and Predicting Users' Experience of Web-Based Content},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208705},
doi = {10.1145/2207676.2208705},
abstract = {Previous studies have used mouse tracking as a tool to measure usability of webpages, user attention and search relevance. In this paper, we go beyond measurement of user behavior to prediction of the resulting user experience from mouse patterns alone. Specifically, we identify mouse markers that can predict user frustration and reading struggles at reasonably high accuracy. We believe that mouse-based prediction of user experience is an important advance, and could potentially offer a scalable way to infer user experience on the web. In addition, we demonstrate that mouse tracking could be used for applications such as evaluating content layout and content noticeability; we apply this in particular to advertisements. More generally, it could be used to infer user attention in complex webpages containing images, text and varied content, including how attention patterns vary with page layout and user distraction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2963–2972},
numpages = {10},
keywords = {mouse tracking, content effectiveness, web pages, attention, user experience, frustration, distractiprediction, reading online, measurement, distraction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208706,
author = {Liu, Can and Huot, Stephane and Diehl, Jonathan and Mackay, Wendy and Beaudouin-Lafon, Michel},
title = {Evaluating the Benefits of Real-Time Feedback in Mobile Augmented Reality with Hand-Held Devices},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208706},
doi = {10.1145/2207676.2208706},
abstract = {Augmented Reality (AR) has been proved useful to guide operational tasks in professional domains by reducing the shift of attention between instructions and physical objects. Modern smartphones make it possible to use such techniques in everyday tasks, but raise new challenges for the usability of AR in this context: small screen, occlusion, operation "through a lens". We address these problems by adding real-time feedback to the AR overlay. We conducted a controlled experiment comparing AR with and without feedback, and with standard textual and graphical instructions. Results show significant benefits for mobile AR with feedback and reveals some problems with the other techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2973–2976},
numpages = {4},
keywords = {real-time feedback, hand-held devices, augmented reality},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208707,
author = {Bergman, Ofer and Whittaker, Steve and Sanderson, Mark and Nachmias, Rafi and Ramamoorthy, Anand},
title = {How Do We Find Personal Files? The Effect of OS, Presentation &amp; Depth on File Navigation},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208707},
doi = {10.1145/2207676.2208707},
abstract = {Folder navigation is the main way that computer users retrieve their personal files. However we know surprisingly little about navigation, particularly about how it is affected by the operating system used, the interface presentation and the folder structure. To investigate this, we asked 289 participants to retrieve 1,109 of their own active files. We analyzed the 4,948 resulting retrieval steps, i.e. moves through the hierarchical folder tree. Results show: (a) significant differences in overall retrieval time between PC and Mac that arise from different organizational strategies rather than interface design; (b) the default Windows presentation is suboptimal - if changed, retrieval time could be reduced substantially and (c) contrary to our expectations, folder depth did not affect step duration. We discuss possible reasons for these results and suggest directions for future research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2977–2980},
numpages = {4},
keywords = {personal information management, navigation, files},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250554,
author = {Duchowski, Andrew},
title = {Session Details: Do You See What Eye See},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250554},
doi = {10.1145/3250554},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208709,
author = {Stellmach, Sophie and Dachselt, Raimund},
title = {Look &amp; Touch: Gaze-Supported Target Acquisition},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208709},
doi = {10.1145/2207676.2208709},
abstract = {While eye tracking has a high potential for fast selection tasks, it is often regarded as error-prone and unnatural, especially for gaze-only interaction. To improve on that, we propose gaze-supported interaction as a more natural and effective way combining a user's gaze with touch input from a handheld device. In particular, we contribute a set of novel and practical gaze-supported selection techniques for distant displays. Designed according to the principle gaze suggests, touch confirms they include an enhanced gaze-directed cursor, local zoom lenses and more elaborated techniques utilizing manual fine positioning of the cursor via touch. In a comprehensive user study with 24 participants, we investigated the potential of these techniques for different target sizes and distances. All novel techniques outperformed a simple gaze-directed cursor and showed individual advantages. In particular those techniques using touch for fine cursor adjustments (MAGIC touch) and for cycling through a list of possible close-to-gaze targets (MAGIC tab) demonstrated a high overall performance and usability.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2981–2990},
numpages = {10},
keywords = {target acquisition, gaze-supported interaction, selection, gaze input, mobile touch interaction},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208710,
author = {Vitak, Sarah A. and Ingram, John E. and Duchowski, Andrew T. and Ellis, Steven and Gramopadhye, Anand K.},
title = {Gaze-Augmented Think-Aloud as an Aid to Learning},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208710},
doi = {10.1145/2207676.2208710},
abstract = {The use of recorded eye movements, or scanpaths, has been demonstrated as an effective visualization for feed-forward visual search training, instruction, and stimulated retrospective think-aloud usability testing. In this paper we show that creation of a scripted or recorded video of an expert's think-aloud session augmented by an animation of their scanpaths can result in an effective aid for learners of visual search. Because the creation of such a video is relatively easy, the benefits-to-cost ratio may potentially be substantial, especially in settings where learned visual scanning strategies are indicators of expertise. We suggest that two such examples are examinations of Chest X-Rays and histological slides. Results are presented where straightforward construction of an instruction video provides measurable benefit to novice as well as experienced learners in the latter context.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2991–3000},
numpages = {10},
keywords = {visual search, eye tracking, histology},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208711,
author = {R\"{a}ih\"{a}, Kari-Jouko and Ovaska, Saila},
title = {An Exploratory Study of Eye Typing Fundamentals: Dwell Time, Text Entry Rate, Errors, and Workload},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208711},
doi = {10.1145/2207676.2208711},
abstract = {Although eye typing (typing on an on-screen keyboard via one's eyes as they are tracked by an eye tracker) has been studied for more than three decades now, we still know relatively little about it from the users' point of view. Standard metrics such as words per minute and keystrokes per character yield information only about the effectiveness of the technology and the interaction techniques developed for eye typing. We conducted an extensive study with almost five hours of eye typing per participant and report on extended qualitative and quantitative analysis of the relationship of dwell time, text entry rate, errors made, and workload experienced by the participants. The analysis method is comprehensive and stresses the need to consider different metrics in unison. The results highlight the importance of catering for individual differences and lead to suggestions for improvements in the interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3001–3010},
numpages = {10},
keywords = {extended study, eye tracking, eye typing, workload, error analysis, adjustable dwell time},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208712,
author = {Bulling, Andreas and Alt, Florian and Schmidt, Albrecht},
title = {Increasing the Security of Gaze-Based Cued-Recall Graphical Passwords Using Saliency Masks},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208712},
doi = {10.1145/2207676.2208712},
abstract = {With computers being used ever more ubiquitously in situations where privacy is important, secure user authentication is a central requirement. Gaze-based graphical passwords are a particularly promising means for shoulder-surfing-resistant authentication, but selecting secure passwords remains challenging. In this paper, we present a novel gaze-based authentication scheme that makes use of cued-recall graphical passwords on a single image. In order to increase password security, our approach uses a computational model of visual attention to mask those areas of the image that are most likely to attract visual attention. We create a realistic threat model for attacks that may occur in public settings, such as filming the user's interaction while drawing money from an ATM. Based on a 12-participant user study, we show that our approach is significantly more secure than a standard image-based authentication and gaze-based 4-digit PIN entry.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3011–3020},
numpages = {10},
keywords = {cued-recall graphical passwords, gaze-based, user authentication, eye tracking, saliency masks},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250555,
author = {Parker, Andrea Grimes},
title = {Session Details: Home &amp; Family},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250555},
doi = {10.1145/3250555},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208714,
author = {Chetty, Marshini and Banks, Richard and Brush, A.J. and Donner, Jonathan and Grinter, Rebecca},
title = {You're Capped: Understanding the Effects of Bandwidth Caps on Broadband Use in the Home},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208714},
doi = {10.1145/2207676.2208714},
abstract = {Bandwidth caps, a limit on the amount of data users can upload and download in a month, are common globally for both home and mobile Internet access. With caps, each bit of data consumed comes at a cost against a monthly quota or a running tab. Yet, relatively little work has considered the implications of this usage-based pricing model on the user experience. In this paper, we present results from a qualitative study of households living with bandwidth caps. Our findings suggest home users grapple with three uncertainties regarding their bandwidth usage: invisible balances, mysterious processes, and multiple users. We discuss how these uncertainties impact their usage and describe the potential for better tools to help monitor and manage data caps. We conclude that as a community we need to cater for users under Internet cost constraints.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3021–3030},
numpages = {10},
keywords = {data cap, usage-based pricing, internet, bandwidth, metered use, bandwidth cap, usage-based billing, pricing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208715,
author = {Chin, Jessie and Fu, Wai-Tat},
title = {Age Differences in Exploratory Learning from a Health Information Website},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208715},
doi = {10.1145/2207676.2208715},
abstract = {An empirical study was conducted to investigate how older and younger users learned by performing exploratory search of health information using an interface that recommended relevant links based on browsing histories. While older and younger users gained both factual and structural knowledge about the health topics, significant age differences were observed. Our results showed that processing of recommended and regular Web links imposed distinct demands on cognitive abilities, which at least partially explained the observed age differences in the search process. The use of recommended links was positively associated with general knowledge, while the use of regular Web links was positively associated with processing capacity. Results also showed that the recommended links benefited both younger and older adults by broadening the exploration of information, which led to better learning. Implications on designs of health information interfaces that facilitate exploratory search and learning for different age groups were discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3031–3040},
numpages = {10},
keywords = {recommended links, knowledge structure, learning, exploratory search, aging},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208716,
author = {Yardi, Sarita and Bruckman, Amy},
title = {Income, Race, and Class: Exploring Socioeconomic Differences in Family Technology Use},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208716},
doi = {10.1145/2207676.2208716},
abstract = {Minorities are the fastest growing demographic in the U.S. and the poverty level in the U.S. is the highest it has been in 50 years. We interviewed middle to upper class, suburban, white American parents and low-income, urban, African-American parents to understand how each group incorporates technology into their lives. Participants had teens in their homes and devices like computers and cell phones played a powerful and preeminent role in family life. Our results show that socioeconomic differences both reflect and reinforce technology use at home. Specifically, low socioeconomic status families share devices more often and low socioeconomic status teens have more responsibility and independence in their technology use. We argue that that as low socioeconomic status families become the majority demographic, the CHI community needs to better understand how to design for these groups.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3041–3050},
numpages = {10},
keywords = {families, parents, class, race, income, socioeconomic status., social computing, african american, teens},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250556,
author = {Hutchinson, Hilary},
title = {Session Details: Designing for Learners' Complex Needs},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250556},
doi = {10.1145/3250556},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208718,
author = {Tabard, Aur\'{e}lien and Hincapi\'{e} Ramos, Juan David and Bardram, Jakob},
title = {The ELabBench in the Wild: Supporting Exploration in a Molecular Biology Lab},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208718},
doi = {10.1145/2207676.2208718},
abstract = {In this paper we present a field trial of the eLabBench, a digital tabletop-based laboratory bench designed to support the exploratory practices of molecular biologists in the laboratory. The eLabBench supports the organization of personal information, capture of experimental work for later access, and the use of a variety of computational resources directly at the lab bench. We deployed the eLabBench in a biology laboratory for 16 weeks, and invited seven molecular biologists to run experiments on it. We report on how they used the bench and how it fitted within their larger experimental process. The main impact of the eLabBench lies in the changes it sparked off in preparing, running, and documenting lab experiments. By supporting computation at the bench and management of physical objects in the office, the eLabBench blurred the separation between office and laboratory work. Based on our observations, we discuss how interactive systems for laboratories such as the eLabBench can support a more exploratory or design-oriented way of 'doing' science.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3051–3060},
numpages = {10},
keywords = {laboratory, research practices, field study, biology, life-sciences, tabletop, design, digital bench, elabbench, experiment},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208719,
author = {Kuhn, Alex and McNally, Brenna and Schmoll, Shannon and Cahill, Clara and Lo, Wan-Tzu and Quintana, Chris and Delen, Ibrahim},
title = {How Students Find, Evaluate and Utilize Peer-Collected Annotated Multimedia Data in Science Inquiry with Zydeco},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208719},
doi = {10.1145/2207676.2208719},
abstract = {Scientific inquiry can be more authentic and meaningful to students when using personal and peer-collected data. The challenges of organizing and evaluating a potentially large amount of data can be overcome through the use of annotations (title, tags, and audio notes). We created Zydeco, a multi-component system that students use to collect annotated multimedia data from a museum (using a smartphone app), and then create a scientific explanation with their personal and peers' data (using a tablet app). We ran a classroom study with 54 students (ages 11-13) investigating how students searched for, evaluated, and used annotated data to construct a scientific explanation. We found that tags supported data interpretation, while title searching and panning through the unfiltered data set supported finding and using data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3061–3070},
numpages = {10},
keywords = {children and technology, learner-centered design, mobile computing, science inquiry, tagging},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208720,
author = {Schneider, Bertrand and Strait, Megan and Muller, Laurence and Elfenbein, Sarah and Shaer, Orit and Shen, Chia},
title = {Phylo-Genie: Engaging Students in Collaborative 'tree-Thinking' through Tabletop Techniques},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208720},
doi = {10.1145/2207676.2208720},
abstract = {Phylogenetic trees are representations of evolutionary relationships amongst species. Interviews of instructors and students have revealed that novice biologists have difficulty understanding phylogenetics. Moreover, misinterpretations of phylogenetics are common among college-level students. In this paper we present Phylo-Genie, a tabletop interface for fostering collaborative learning of phylogenetics. We conducted an experimental study with 56 participants, comparing students' conceptual learning and engagement using Phylo-Genie as: 1) a multi-touch tabletop interface and 2) a pen and paper activity. Our findings show that the tabletop implementation fosters collaborative learning by engaging users in the activity. We also shed light on the way in which our design principles facilitated engagement and collaborative learning in a tabletop environment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3071–3080},
numpages = {10},
keywords = {bioinformatics, tabletop, multi-touch interaction, collaborative learning, education, tangible user interface},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250557,
author = {Gilbert, Eric},
title = {Session Details: Groups @ Work},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250557},
doi = {10.1145/3250557},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208722,
author = {Cataldo, Marcelo and Ehrlich, Kate},
title = {The Impact of Communication Structure on New Product Development Outcomes},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208722},
doi = {10.1145/2207676.2208722},
abstract = {New product development teams face important challenges to their performance due to the novelty of the work and the need to rapidly develop shared knowledge and goals. However, little is known about the relationship between the structural properties of communication and performance in these teams. This study examined the effect of communication structure, specifically hierarchical and small-world structures on the delivery performance and quality outcomes of a large-scale new product development project. Our longitudinal analyses revealed that structuring communication patterns in a hierarchical manner significantly improves delivery performance. However, hierarchical communication has a detrimental effect on quality while small-world communication structures improved the quality outcomes of development teams. We discuss the implications of these results for collaborative tools that support communication tradeoffs},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3081–3090},
numpages = {10},
keywords = {new product development, communication, small-world networks, social network analysis, hierarchy},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208723,
author = {Rae, Irene and Takayama, Leila and Mutlu, Bilge},
title = {One of the Gang: Supporting in-Group Behavior for Embodied Mediated Communication},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208723},
doi = {10.1145/2207676.2208723},
abstract = {As an emerging technology that enables geographically distributed work teams, mobile remote presence (MRP) systems present new opportunities for supporting effective team building and collaboration. MRP systems are physically embodied mobile videoconferencing systems that remote co-workers control. These systems allow remote users, pilots, to actively initiate conversations and to navigate throughout the local environment. To investigate ways of encouraging team-like behavior among local and remote co-workers, we conducted a 2 (visual framing: decoration vs. no decoration) x 2 (verbal framing: interdependent vs. independent performance scoring) between-participants study (n=40). We hypothesized that verbally framing the situation as interdependent and visually framing the MRP system to create a sense of self-extension would enhance group cohesion between the local and the pilot. We found that the interdependent framing was successful in producing more in-group oriented behaviors and, contrary to our predictions, visual framing of the MRP system weakened team cohesion.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3091–3100},
numpages = {10},
keywords = {remote presence, in-group behavior, embodied mediated communication},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208724,
author = {Voida, Amy and Bos, Nathan and Olson, Judith and Olson, Gary and Dunning, Lauren},
title = {Cross-Cutting Faultlines of Location and Shared Identity in the Intergroup Cooperation of Partially Distributed Groups},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208724},
doi = {10.1145/2207676.2208724},
abstract = {This paper reports the results of a study comparing the relative influence of location and shared identity in partially distributed work. Using an experimental task called Shape Factory, groups of eight participants were configured such that in the baseline 'strangers' condition only the location-based faultline was present while in the experimental 'intergroup' condition, participants from two different shared identity groups engaged in distributed collaboration, creating an additional, cross-cutting faultline. The results showed that participants in the intergroup condition, with both location-based and shared identity faultlines, performed at a higher level than participants in the strangers condition, with only the location-based faultline. In the intergroup condition, the performance effects of location and shared identity were roughly equal and did not affect each other differentially in combination.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3101–3110},
numpages = {10},
keywords = {shared identity, partially distributed work, faultline, intergroup cooperation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208725,
author = {Tang, John and Marlow, Jennifer and Hoff, Aaron and Roseway, Asta and Inkpen, Kori and Zhao, Chen and Cao, Xiang},
title = {Time Travel Proxy: Using Lightweight Video Recordings to Create Asynchronous, Interactive Meetings},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208725},
doi = {10.1145/2207676.2208725},
abstract = {Time Travel Proxy (TTP) enables participating in meetings that you cannot attend in real time, either because of time conflicts or global time zone differences. TTP uses lightweight video recordings to pre-record your contributions to a meeting, which are played on a tablet that serves as a proxy for you during the meeting. Reactions and responses in the meeting are also captured in video to give you feedback of what happened at the meeting. A working prototype of TTP was deployed and studied within four developer teams in their daily stand-up meetings. The study found that the affordances of video helped integrate the time traveler into the social context of the meeting, although the current prototype was better at enabling the time traveler to contribute to the meeting than it was in conveying the meeting experience back to the time traveler.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3111–3120},
numpages = {10},
keywords = {asynchronous collaboration, telepresence, video, meetings.},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250558,
author = {Horn, Mike},
title = {Session Details: Use the Force},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250558},
doi = {10.1145/3250558},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208727,
author = {Lee, Bhoram and Lee, Hyunjeong and Lim, Soo-Chul and Lee, Hyungkew and Han, Seungju and Park, Joonah},
title = {Evaluation of Human Tangential Force Input Performance},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208727},
doi = {10.1145/2207676.2208727},
abstract = {While interacting with mobile devices, users may press against touch screens and also exert tangential force to the display in a sliding manner. We seek to guide UI design based on the tangential force applied by a user to the surface of a hand-held device. A prototype of an interface using tangential force input was implemented utilizing a force sensitive layer and an elastic layer and used for the user experiment. We investigated user controllability to reach and maintain target force levels and considered the effects of hand pose and direction of force input. Our results imply no significant difference in performance when applying force holding the device in one hand and in two hands. We also observed that users have more physical and perceived loads when applying tangential force in the left-right direction compared to the up-down direction. Based on the experimental results, we discuss considerations for user interface applications of tangential-force-based interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3121–3130},
numpages = {10},
keywords = {mobile interaction, input devices, force-based interface},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208728,
author = {Pielot, Martin and Poppinga, Benjamin and Heuten, Wilko and Boll, Susanne},
title = {PocketNavigator: Studying Tactile Navigation Systems in-Situ},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208728},
doi = {10.1145/2207676.2208728},
abstract = {In this paper, we report about a large-scale in-situ study of tactile feedback for pedestrian navigation systems. Recent advances in smartphone technology have enabled a number of interaction techniques for smartphone that use tactile feedback to deliver navigation information. The aim is to enable eyes-free usage and avoid distracting the user from the environment. Field studies where participants had to fulfill given navigation tasks, have found these techniques to be efficient and beneficial in terms of distraction. But it is not yet clear whether these findings will replicate in in-situ usage. We, therefore, developed a Google Maps-like navigation application that incorporates interaction techniques proposed in previous work. The application was published for free on the Android Market and so people were able to use it as a navigation system in their everyday life. The data collected through anonymous monitoring suggests that tactile feedback is successfully adopted in one third of all trips and has positive effects on the user's level of distraction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3131–3140},
numpages = {10},
keywords = {tactile &amp; haptic uis, handheld devices and mobile computing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208729,
author = {Lee, Jaedong and Kim, Youngsun and Kim, Gerard},
title = {Funneling and Saltation Effects for Tactile Interaction with Virtual Objects},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208729},
doi = {10.1145/2207676.2208729},
abstract = {Funneling and saltation are two major illusory feedback techniques for vibration-based tactile feedback. They are often put into practice e.g. to reduce the number of vibrators to be worn on the body and thereby build a less cumbersome feedback device. Recently, these techniques have been found to be applicable to eliciting "out of the body" experiences as well (e.g. through user-held external objects). This paper examines the possibility of applying this phenomenon to interacting with virtual objects. Two usability experiments were run to test the effects of funneling and saltation respectively for perceiving tactile sensation from a virtual object in an augmented reality setting. Experimental results have shown solid evidences for phantom sensations from virtual objects with funneling, but mixed results for saltation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3141–3148},
numpages = {8},
keywords = {saltation, phantom sensation, funneling, illusory feedback, vibro-tactile feedback},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208730,
author = {Harrison, Chris and Hudson, Scott},
title = {Using Shear as a Supplemental Two-Dimensional Input Channel for Rich Touchscreen Interaction},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208730},
doi = {10.1145/2207676.2208730},
abstract = {Touch input is constrained, typically only providing finger X/Y coordinates. To access and switch between different functions, valuable screen real estate must be allocated to buttons and menus, or users must perform special actions, such as touch-and-hold, double tap, or multi-finger chords. Even still, this only adds a few bits of additional information, leaving touch interaction unwieldy for many tasks. In this work, we suggest using a largely unutilized touch input dimension: shear (force tangential to a screen's surface). Similar to pressure, shear can be used in concert with conventional finger positional input. However, unlike pressure, shear provides a rich, analog 2D input space, which has many powerful uses. We put forward five classes of advanced interaction that considerably expands the envelope of interaction possible on touchscreens.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3149–3152},
numpages = {4},
keywords = {finger interaction, touchscreens, handheld mobile devices, tangential force, fat fingers},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208731,
author = {Badshah, Akash and Gupta, Sidhant and Morris, Daniel and Patel, Shwetak and Tan, Desney},
title = {GyroTab: A Handheld Device That Provides Reactive Torque Feedback},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208731},
doi = {10.1145/2207676.2208731},
abstract = {Haptic devices that provide robust and realistic force feedback are generally grounded to counterweight the applied force, prohibiting their use in mobile devices. Many ungrounded force-feedback devices rely on the gyro effect to produce torques on the human body, but their active control systems render them extremely bulky for implementation in small mobile devices. We present GyroTab, a relatively flat handheld system that utilizes the gyro effect to provide torque feedback. GyroTab relies on the user to produce an input torque and provides feedback by opposing that torque, making its feedback reactive to the user's motion. We describe the implementation of GyroTab, discuss the kinds of feedback it generates, and explore some of the psychophysical results we obtained from a study with the device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3153–3156},
numpages = {4},
keywords = {gyroscopic feedback, haptics},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250559,
author = {Chapuis, Olivier},
title = {Session Details: Human Performance Gives Us Fitts'},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250559},
doi = {10.1145/3250559},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208733,
author = {Gajos, Krzysztof and Reinecke, Katharina and Herrmann, Charles},
title = {Accurate Measurements of Pointing Performance from in Situ Observations},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208733},
doi = {10.1145/2207676.2208733},
abstract = {We present a method for obtaining lab-quality measurements of pointing performance from unobtrusive observations of natural in situ interactions. Specifically, we have developed a set of user-independent classifiers for discriminating between deliberate, targeted mouse pointer movements and those movements that were affected by any extraneous factors. To develop and validate these classifiers, we developed logging software to unobtrusively record pointer trajectories as participants naturally interacted with their computers over the course of several weeks. Each participant also performed a set of pointing tasks in a formal study set-up. For each movement, we computed a set of measures capturing nuances of the trajectory and the speed, acceleration, and jerk profiles. Treating the observations from the formal study as positive examples of deliberate, targeted movements and the in situ observations as unlabeled data with an unknown mix of deliberate and distracted interactions, we used a recent advance in machine learning to develop the classifiers. Our results show that, on four distinct metrics, the data collected in-situ and filtered with our classifiers closely matches the results obtained from the formal experiment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3157–3166},
numpages = {10},
keywords = {in situ studies, pointing, machine learning, motor performance},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208734,
author = {Dixon, Morgan and Fogarty, James and Wobbrock, Jacob},
title = {A General-Purpose Target-Aware Pointing Enhancement Using Pixel-Level Analysis of Graphical Interfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208734},
doi = {10.1145/2207676.2208734},
abstract = {We present a general-purpose implementation of a target aware pointing technique, functional across an entire desktop and independent of application implementations. Specifically, we implement Grossman and Balakrishnan's Bubble Cursor, the fastest general pointing facilitation technique in the literature. Our implementation obtains the necessary knowledge of interface targets using a combination of pixel-level analysis and social annotation. We discuss the most novel aspects of our implementation, including methods for interactive creation and correction of pixel-level prototypes of interface elements and methods for interactive annotation of how the cursor should select identified elements. We also report on limitations of the Bubble Cursor unearthed by examining our implementation in the complexity of real-world interfaces. We therefore contribute important progress toward real-world deployment of an important family of techniques and shed light on the gap between understanding techniques in controlled settings versus behavior with real-world interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3167–3176},
numpages = {10},
keywords = {real-world interfaces, prefab, target-aware pointing, social annotation, pixel-based reverse engineering, bubble cursor},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208735,
author = {Yem, Vibol and Kuzuoka, Hideaki and Yamashita, Naomi and Shibusawa, Ryota and Yano, Hiroaki and Yamashita, Jun},
title = {Assisting Hand Skill Transfer of Tracheal Intubation Using Outer-Covering Haptic Display},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208735},
doi = {10.1145/2207676.2208735},
abstract = {Various systems for hand tool skill training have been developed in the domain of haptic displays. These systems typically present force to a learner's palm by directly actuating the tool. However, this approach is sometimes ineffective because learners have difficulty sensing the haptic feedback from the tool when they are holding it tightly. Thus, we propose a different approach (OCHD) that effectively guides the learner's hand by presenting force to the back of his/her hand as if an instructor is holding it. A preliminary experiment showed that OCHD effectively guides users with less actuator drive force than cases where the tool is directly actuated.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3177–3180},
numpages = {4},
keywords = {haptic display, hand skill training, tracheal intubation},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208736,
author = {Hutchings, Dugald},
title = {An Investigation of Fitts' Law in a Multiple-Display Environment},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208736},
doi = {10.1145/2207676.2208736},
abstract = {We describe the design and analysis of a Fitts' law experiment, conducted in a multiple-display environment (MDE), in which the physical gap between displays and the proximity of targets to the gap systematically varied. Participants achieved decreasing throughput values (a combined measure of movement time and accuracy in a target acquisition task) under increasing gap sizes. Participants likewise performed relatively poorly in tasks involving monitor crossing over all gap conditions, especially so when motion either originates or terminates very close to the gap. Both results could be considered surprising since in either case, the amount of mouse movement needed to successfully execute the task does not change based on physical gap size or a target's proximity to the edge. Fitts' law may underestimate the difficulty of movement tasks in MDEs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3181–3184},
numpages = {4},
keywords = {multiple-display environment, fitts' law, throughput},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208737,
author = {Zhang, Xinyong and Zha, Hongbin and Feng, Wenxin},
title = {Extending Fitts' Law to Account for the Effects of Movement Direction on 2d Pointing},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208737},
doi = {10.1145/2207676.2208737},
abstract = {Fitts' law is the most widely applied model in the field of HCI. However, this model and its existing extensions are still limited for 2D pointing task especially when the effects of movement direction (Θ) remain in the task. In this paper, we employ the concept of projection to account for the effects of target width (W) and height (H) on movement time so that we seamlessly integrate the four factors, i.e. Θ, amplitude (A), W and H, into the new extension of Fitts' law, which can uncover not only the periodicity of the asymmetrical impacts of W and H with the variation of Θ but also their interrelation. Carrying out two experiments, we verify that the vertical projection of W and the horizontal projection of H in the line of movement direction can be viewed as the determinants of movement time. Finally, we offer recommendations for 2D pointing experiments and discuss the implications for interface designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3185–3194},
numpages = {10},
keywords = {fitts' law, movement direction, two-dimensional pointing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3250560,
author = {Hurst, Amy},
title = {Session Details: With a Little Help from My Friends},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250560},
doi = {10.1145/3250560},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208739,
author = {Lampe, Cliff and Vitak, Jessica and Gray, Rebecca and Ellison, Nicole},
title = {Perceptions of Facebook's Value as an Information Source},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208739},
doi = {10.1145/2207676.2208739},
abstract = {Facebook has become an increasingly important tool for people engaging in a range of communication behaviors, including requesting help from their social network to address information needs. Through a study of 614 staff members at a large university, we show how social capital, network characteristics, and use of Facebook are related to how useful individuals find Facebook to be for informational purposes and their propensity to seek different types of information on the site. We find that bridging social capital and engagement with one's network through directed communication behaviors are important predictors of these dimensions of information seeking; furthermore, a number of demographic and usage behavior differences exist between those who choose to engage in information-seeking behaviors on Facebook and those who do not. Finally, when predicting information-seeking behaviors, we identify a significant interaction between users' perceptions of Facebook as appropriate for purposes beyond the purely social and their engagement with their network.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3195–3204},
numpages = {10},
keywords = {social network sites, facebook, information-seeking, social capital},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208740,
author = {Chang, Kerry Shih-Ping and Myers, Brad A.},
title = {WebCrystal: Understanding and Reusing Examples in Web Authoring},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208740},
doi = {10.1145/2207676.2208740},
abstract = {Examples have been widely used in the area of web design to help web authors create web pages. However, without actually understanding how an example is constructed, people often have trouble extracting the elements they want and incorporating them into their own design. This paper introduces WebCrystal, a web development tool that helps users understand how a web page is built. WebCrystal contributes novel interaction techniques that let the user quickly access HTML and CSS information by selecting questions regarding how a selected element is designed. It provides answers using a textual description and a customized code snippet that can be copied-and-pasted to recreate the desired properties. WebCrystal also supports combining the styles and structures from multiple elements into the generated code snippet, and provides visualizations on the web page itself to explain layout relationships. Our user study shows that WebCrystal helped both novice and experienced developers complete more tasks successfully using significantly less time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3205–3214},
numpages = {10},
keywords = {examples, web authoring},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/2207676.2208741,
author = {Lee, Uichin and Kang, Hyanghong and Yi, Eunhee and Yi, Mun and Kantola, Jussi},
title = {Understanding Mobile Q&amp;A Usage: An Exploratory Study},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208741},
doi = {10.1145/2207676.2208741},
abstract = {Recently questioning and answering (Q&amp;A) communities that facilitate knowledge sharing among people have been introduced to the mobile environments such as Naver Mobile Q&amp;A and ChaCha. These mobile Q&amp;A services are very different from traditional Q&amp;A sites in that questions/answers are short in length and are exchanged via mobile devices (e.g., SMS or mobile Internet). While traditional Q&amp;A sites have been well investigated, so far little is known about the mobile Q&amp;A usage. To understand mobile Q&amp;A usage, we analyzed 2.4 million question/answer pairs spanning a 14 month period from Naver Mobile Q&amp;A and performed a complementary survey study of 555 active mobile Q&amp;A users. We find that mobile Q&amp;A is deeply wired into users' everyday life activities - its usage is largely dependent on users' spatial, temporal, and social contexts; the key factors of mobile Q&amp;A usage are accessibility/convenience of mobile Q&amp;A, promptness of receiving answers, and users' satisficing behavior of information seeking (i.e., minimizing efforts and settling with good enough information). We also observe that users tend to seek more factual information attributed to everyday life activities than they do on traditional Q&amp;A sites and that they exhibit unique interaction patterns such as repeating and refining questions as coping strategies in seeking information needs. Our main findings reported in the paper have significant implications on the design of mobile Q&amp;A systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3215–3224},
numpages = {10},
keywords = {online community, ubiquitous computing, mobile q&amp;a system},
location = {Austin, Texas, USA},
series = {CHI '12}
}

