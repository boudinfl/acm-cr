@inproceedings{10.1145/365024.365027,
author = {Accot, Johnny and Zhai, Shumin},
title = {Scale Effects in Steering Law Tasks},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365027},
doi = {10.1145/365024.365027},
abstract = {Interaction tasks on a computer screen can technically be scaled to a much larger or much smaller sized input control area by adjusting the input device's control gain or the control-display (C-D) ratio. However, human performance as a function of movement scale is not a well concluded topic. This study introduces a new task paradigm to study the scale effect in the framework of the steering law. The results confirmed a U-shaped performance-scale function and rejected straight-line or no-effect hypotheses in the literature. We found a significant scale effect in path steering performance, although its impact was less than that of the steering law's index of difficulty.  We analyzed the scale effects in two plausible causes: movement joints shift and motor precision limitation. The theoretical implications of the scale effects to the validity of the steering law, and the practical implications of input device size and zooming functions are discussed in the paper.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {limb, finger, C-D ratio, input device, steering law, wrist, device size, motor control, arm, hand, joints, elbow, movement scale, control gain},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365028,
author = {MacKenzie, I. Scott and Kauppinen, Tatu and Silfverberg, Miika},
title = {Accuracy Measures for Evaluating Computer Pointing Devices},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365028},
doi = {10.1145/365024.365028},
abstract = {In view of the difficulties in evaluating computer pointing devices across different tasks within dynamic and complex systems, new performance measures are needed. This paper proposes seven new accuracy measures to elicit (sometimes subtle) differences among devices in precision pointing tasks. The measures are target re-entry, task axis crossing, movement direction change, orthogonal direction change, movement variability, movement error, and movement offset. Unlike movement time, error rate, and throughput, which are based on a single measurement per trial, the new measures capture aspects of movement behaviour during a trial. The theoretical basis and computational techniques for the measures are described, with examples given. An evaluation with four pointing devices was conducted to validate the measures. A causal relationship to pointing device efficiency (viz. throughput) was found, as was an ability to discriminate among devices in situations where differences did not otherwise appear. Implications for pointing device research are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {9–16},
numpages = {8},
keywords = {performance measurement, performance evaluation, computer pointing devices, cursor positioning tasks},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365030,
author = {Olsen, Dan R. and Nielsen, Travis},
title = {Laser Pointer Interaction},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365030},
doi = {10.1145/365024.365030},
abstract = {Group meetings and other non-desk situations require that people be able to interact at a distance from a display surface. This paper describes a technique using a laser pointer and a camera to accomplish just such interactions. Calibration techniques are given to synchronize the display and camera coordinates. A series of interactive techniques are described for navigation and entry of numbers, times, dates, text, enumerations and lists of items. The issues of hand jitter, detection error, slow sampling and latency are discussed in each of the interactive techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {17–22},
numpages = {6},
keywords = {group interaction, camera-based interaction, laser pointer interaction},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365031,
author = {Back, Maribeth and Cohen, Jonathan and Gold, Rich and Harrison, Steve and Minneman, Scott},
title = {Listen Reader: An Electronically Augmented Paper-Based Book},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365031},
doi = {10.1145/365024.365031},
abstract = {While predictions abound that electronic books will supplant traditional paper-based books, many people bemoan the coming loss of the book as cultural artifact. In this project we deliberately keep the affordances of paper books while adding electronic augmentation. The Listen Reader combines the look and feel of a real book - a beautiful binding, paper pages and printed images and text - with the rich, evocative quality of a movie soundtrack. The book's multi-layered interactive soundtrack consists of music and sound effects. Electric field sensors located in the book binding sense the proximity of the reader's hands and control audio parameters, while RFID tags embedded in each page allow fast, robust page identification.Three different Listen Readers were built as part of a six-month museum exhibit, with more than 350,000 visitors. This paper discusses design, implementation, and lessons learned through the iterative design process, observation, and visitor interviews.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {23–29},
numpages = {7},
keywords = {exhibits, augmented reality, gestural input, embedded tags, smart documents, sound design, electronic books, multimodal i/o, augmented books, new genres, interactive museum, page detection, audio books, interactive books, RFID tags, interactive audio},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365032,
author = {Craven, Mike and Taylor, Ian and Drozd, Adam and Purbrick, Jim and Greenhalgh, Chris and Benford, Steve and Fraser, Mike and Bowers, John and J\"{a}\"{a}-Aro, Kai-Mikael and Lintermann, Bernd and Hoch, Michael},
title = {Exploiting Interactivity, Influence, Space and Time to Explore Non-Linear Drama in Virtual Worlds},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365032},
doi = {10.1145/365024.365032},
abstract = {We present four contrasting interfaces to allow multiple viewers to explore 3D recordings of dramas in on-line virtual worlds. The first is an on-line promenade performance to an audience of avatars. The second is a form of immersive cinema, with multiple simultaneous viewpoints. The third is a tabletop projection surface that allows viewers to select detailed views from a bird's-eye overview. The fourth is a linear television broadcast created by a director or editor. A comparison of these examples shows how a viewing audience can exploit four general resources - interactivity, influence, space, and time - to make sense of complex, non-linear virtual drama. These resources provide interaction designers with a general framework for defining the relationship between the audience and  the 3D content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {30–37},
numpages = {8},
keywords = {enterainment applications, virtual reality},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365033,
author = {Koleva, Boriana and Taylor, Ian and Benford, Steve and Fraser, Mike and Greenhalgh, Chris and Schn\"{a}delbach, Holger and vom Lehn, Dirk and Heath, Christian and Row-Farr, Ju and Adams, Matt},
title = {Orchestrating a Mixed Reality Performance},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365033},
doi = {10.1145/365024.365033},
abstract = {A study of a professional touring mixed reality performance called Desert Rain yields insights into how performers orchestrate players' engagement in an interactive experience. Six players at a time journey through an extended physical and virtual set. Each sees a virtual world projected onto a screen made from a fine water spray. This acts as a traversable interface, supporting the illusion that performers physically pass between real and virtual worlds. Live and video-based observations of Desert Rain, coupled with interviews with players and the production team, have revealed how the performers create conditions for the willing suspension of disbelief, and how they monitor and intervene in the players experience without breaking their engagement. This involves carefully timed  performances and “off-face” and “virtual” interventions. In turn, these are supported by the ability to monitor players' physical and virtual activity through asymmetric interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {38–45},
numpages = {8},
keywords = {mixed reality, performance, traversable interfaces},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365034,
author = {Millett, Lynette I. and Friedman, Batya and Felten, Edward},
title = {Cookies and Web Browser Design: Toward Realizing Informed Consent Online},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365034},
doi = {10.1145/365024.365034},
abstract = {We first provide criteria for assessing informed consent online. Then we examine how cookie technology and Web browser designs have responded to concerns about informed consent. Specifically, we document relevant design changes in Netscape Navigator and Internet Explorer over a 5-year period, starting in 1995. Our retrospective analyses leads us to conclude that while cookie technology has improved over time regarding informed consent, some startling problems remain. We specify six of these problems and offer design remedies. This work fits within the emerging field of Value-Sensitive Design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {46–52},
numpages = {7},
keywords = {computer ethics, online interactions, social computing, e-commerce, human-computer interaction, locus of control, Web browsers, privacy, social impact, ethics, personalization, informed consent, Internet Explorer, Netscape Navigator, World Wide Web, security, e-business, tracking, cookies, human values, interface design, Value-Sensitive Design},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365035,
author = {Ivory, Melody Y. and Sinha, Rashmi R. and Hearst, Marti A.},
title = {Empirically Validated Web Page Design Metrics},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365035},
doi = {10.1145/365024.365035},
abstract = {A quantitative analysis of a large collection of expert-rated web sites reveals that page-level metrics can accurately predict if a site will be highly rated.  The analysis also provides empirical evidence that important metrics, including page composition, page formatting, and overall page characteristics, differ among web site categories such as education, community, living, and finance. These results provide an empirical foundation for web site design guidelines and also suggest which metrics can be most important for evaluation via user studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {53–60},
numpages = {8},
keywords = {Web site design, World Wide Web, automated usability evaluation, empirical studies},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365037,
author = {Fogg, B. J. and Marshall, Jonathan and Laraki, Othman and Osipovich, Alex and Varma, Chris and Fang, Nicholas and Paul, Jyoti and Rangnekar, Akshay and Shon, John and Swani, Preeti and Treinen, Marissa},
title = {What Makes Web Sites Credible? A Report on a Large Quantitative Study},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365037},
doi = {10.1145/365024.365037},
abstract = {The credibility of web sites is becoming an increasingly important area to understand. To expand knowledge in this domain, we conducted an online study that investigated how different elements of Web sites affect people's perception of credibility. Over 1400 people participated in this study, both from the U.S. and Europe, evaluating 51 different Web site elements. The data showed which elements boost and which elements hurt perceptions of Web credibility. Through analysis we found these elements fell into one of seven factors. In order of impact, the five types of elements that increased credibility perceptions were “real-world feel”, “ease of use”, “expertise”, “trustworthiness”, and “tailoring”. The two types of elements that hurt credibility were “commercial implications&amp;rdquo ;and “amateurism”. This  large-scale study lays the groundwork for further research into the elements that affect Web credibility. The results also suggest implications for designing credible Web sites.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {61–68},
numpages = {8},
keywords = {expertise, captology, online research, credibility, trustworthiness, usability, Web design, World Wide Web},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365038,
author = {Doherty, Eamon and Cockton, Gilbert and Bloor, Chris and Benigno, Dennis},
title = {Improving the Performance of the Cyberlink Mental Interface with “Yes / No Program”},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365038},
doi = {10.1145/365024.365038},
abstract = {We summarise the results of the first studies to investigate the Cyberlink brain body interface as an assistive technology. Three phases of studies and a contextual inquiry were performed with a range of users.  A focus group was formed from brain-injured users with locked-in syndrome who have no other method of communication or control of a computer than the Cyberlink. Versions of a Yes/No program were then created to allow communication and have achieved some success with the focus group.  The purpose of this paper is to discuss how this program has been improved and what steps need to be taken to create communication programs for persons with severe motor impairment.  As a result of our experiences, we have been able to develop a set of design guidelines for brain-body  interface operated Yes/No programs.  These are presented and justified on the basis of our experiences.  We also raise some general issues for assistive technologies of this nature.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {69–76},
numpages = {8},
keywords = {ody interface, locked in syndrome, cyberlink, assistive technology, mental interface},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365047,
author = {Tsukahara, Wataru and Ward, Nigel},
title = {Responding to Subtle, Fleeting Changes in the User's Internal State},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365047},
doi = {10.1145/365024.365047},
abstract = {In human-to-human interaction, people sometimes are able to pick up and respond sensitively to the other's internal state as it shifts moment by moment over the course of an exchange. To find out whether such an ability is worthwhile for computer human interfaces, we built a semi-automated tutoring-type spoken dialog system. The system inferred information about the user's scare{ephemeral emotions}, such as confidence, confusion, pleasure, and dependency, from the prosody of his utterances and the context. It used this information to select the most appropriate acknowledgement form at each moment. In doing so the system was following some of the basic social conventions for real-time interaction. Users rated the system with this ability more highly than a version without.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {77–84},
numpages = {8},
keywords = {prosody, responsive, real-time, social interaction, Japanese, ephemeral emotions, acknowledgements, feedback, spoken dialog, tutoring, non-verbal},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365051,
author = {Duh, Henry Been-Lirn and Parker, Donald E. and Furness, Thomas A.},
title = {An “Independent Visual Background” Reduced Balance Disturbance Envoked by Visual Scene Motion: Implication for Alleviating Simulator Sickness},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365051},
doi = {10.1145/365024.365051},
abstract = {Simulator sickness (SS) / virtual environment (VE) sickness is expected to become increasingly troublesome as VE technology evolves [20]. Procedures to alleviate SS / VE sickness have been of limited value [12]. This paper investigated a possible procedure to reduce SS and VE sickness. Postural disturbance was evoked by visual scene motion at different frequencies. Differences in disturbance were examined as a function of simultaneous exposure to an “independent visual background” (IVB). Eight subjects were tested at two scene motion frequencies and three different IVB conditions using a within-subjects design. An expected statistically significant interaction between IVB condition and frequency was observed. For low frequency scene movements, subjects exhibited less balance  disturbance when the IVB was presented. We suggest that an IVB may alleviate disturbance when conflicting visual and inertial cues are likely to result in simulator or VE sickness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {85–89},
numpages = {5},
keywords = {virtual reality, self-motion perception, virtual environments, cybersickness, simulator sickness},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365054,
author = {Muller, Michael J.},
title = {Layered Participatory Analysis: New Developments in the CARD Technique},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365054},
doi = {10.1145/365024.365054},
abstract = {CARD (Collaborative Analysis of Requirements and Design) is an influential technique for participatory design and participatory analysis that is in use on three continents.  This paper reviews three case studies that document the development of a layered CARD approach, which distinguishes among the following: (1) observable, formal components, (2) skill and craft, and (3) interpretative description.  The layered approach simplifies the CARD materials, and moves the deliberately informal technique toward a more principled analysis.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {90–97},
numpages = {8},
keywords = {work analysis, participatory analysis, CARD, participatory design, PANDA},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365056,
author = {Philips, Brian H. and Rahman, Moin and J\"{a}rvinen, Jari},
title = {Building a Human Factors “Knowledge Shelf” as a Collaborative Information Tool for Designers},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365056},
doi = {10.1145/365024.365056},
abstract = {Human factors professionals have long been challenged with finding an effective way of communicating critical human factors design information to product designers. The authors have created a tool called a “Knowledge Shelf” for providing human factors information to designers in a very easy to use manner. The Knowledge Shelf is an interactive virtual library of information on human factors methodologies and data relevant to the specific product development needs of designers. Available through the Motorola Intranet, the Knowledge Shelf is designed to make human factors design information easily accessible. Providing these types of information to designers positively impacts the product development process, by facilitating more user-centered design practices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {98–103},
numpages = {6},
keywords = {product development, information sharing, engineering, knowledge shelf, industrial design, collaborative work},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365060,
author = {Yeo, Alvin W.},
title = {Global-Software Development Lifecycle: An Exploratory Study},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365060},
doi = {10.1145/365024.365060},
abstract = {This study was conducted to explore the efficacy of the global-software development lifecycle (global-SDLC), which comprises design, implementation and usability evaluation phase. A spreadsheet was adapted using the global-SDLC process to accommodate a number of cultures. The design and implementation phases were efficacious. However, in the usability evaluation phase, the usability evaluation techniques were only efficacious when participants, who were experienced computer users and participants who were familiar with the experimenter, were employed. Explanations, from cultural literature such as Hofstede, are presented and implications of these findings on the usability evaluation phase and the global-SDLC are also described.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {104–111},
numpages = {8},
keywords = {usability evaluation, Hoftede's cultural dimensions, localisation, global-software development, internationalisation},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365061,
author = {Gray, Wayne D. and Fu, Wai-Tat},
title = {Ignoring Perfect Knowledge In-the-World for Imperfect Knowledge in-the-Head},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365061},
doi = {10.1145/365024.365061},
abstract = {Memory can be internal or external - knowledge in-the-world or knowledge in-the-head. Making needed information available in an interface may seem the perfect alternative to relying on imperfect memory. However, the rational analysis framework (Anderson, 1990) suggests that least-effort tradeoffs may lead to imperfect performance even when perfect knowledge in-the-world is readily available. The implications of rational analysis for interactive behavior are investigated in two experiments. In experiment 1 we varied the perceptual-motor effort of accessing knowledge in-the-world as well as the cognitive effort of retrieving items from memory. In experiment 2 we replicated one of the experiment 1 conditions to collect eye movement data. The results suggest that milliseconds matter. Least-effort tradeoffs are adopted even when the absolute difference in effort between a perceptual-motor versus a memory strategy is small, and even when adopting a memory strategy results in a higher error rate and lower performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {112–119},
numpages = {8},
keywords = {direct-manipulation interfaces, interface design, rational analysis, satisficing, errors, eye movements, eye tracking, interactive bahavior, cognitive least-effort},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365064,
author = {Salvucci, Dario D.},
title = {Predicting the Effects of In-Car Interfaces on Driver Behavior Using a Cognitive Architecture},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365064},
doi = {10.1145/365024.365064},
abstract = {When designing and evaluating in-car user interfaces for drivers, it is essential to determine what effects these interfaces may have on driver behavior and performance. This paper describes a novel approach to predicting effects of in-car interfaces by modeling behavior in a cognitive architecture. A cognitive architecture is a theoretical frame-work for building computational models of cognition and performance. The proposed approach centers on integrating a user model for the interface with an existing driver model that accounts for basic aspects of driver behavior (e.g., steering and speed control). By running the integrated model and having it interact with the interface while driving, we can generate a priori predictions of the effects of interface use on driver performance. The paper illustrates the approach by comparing four representative dialing interfaces for an in-car, hands-free cellular phone. It also presents an empirical study that validates several of the qualitative and quantitative predictions of the model.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {120–127},
numpages = {8},
keywords = {driving, in-car interfaces, ACT-R, cognitive models, cognitive architectures, cellular phones},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365069,
author = {Kieras, David and Meyer, David and Ballas, James},
title = {Towards Demystification of Direct Manipulation: Cognitive Modeling Charts the Gulf of Execution},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365069},
doi = {10.1145/365024.365069},
abstract = {Direct manipulation involves a large number of interacting psychological mechanisms that make the performance of a given interface hard to predict on intuitive or informal grounds. This paper applies cognitive modeling to explain the subtle effects produced by using a keypad versus a touchscreen in a performance-critical laboratory task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {128–135},
numpages = {8},
keywords = {direct manipulation, cognitive modeling},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365073,
author = {Smith, Marc A. and Fiore, Andrew T.},
title = {Visualization Components for Persistent Conversations},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365073},
doi = {10.1145/365024.365073},
abstract = {An appropriately designed interface to persistent, threaded conversations could reinforce socially beneficial behavior by prominently featuring how frequently and to what degree each user exhibits such behaviors. Based on the data generated by the Netscan data-mining project [9], we have developed a set of tools for illustrating the structure of discussion threads like those found in Usenet newsgroups and the patterns of participation within the discussions. We describe the benefits and challenges of integrating these tools into a multi-faceted dashboard for navigating and reading discussions in social cyberspaces like Usenet and related interaction media. Visualizations of the structure of online discussions have applications for research into the sociology of online groups as well as possible interface designs for their members.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {136–143},
numpages = {8},
keywords = {newsgroup, social cyberspaces, asynchronous threaded discussions, persistent conversation, Usenet, visualization},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365077,
author = {Mamykina, Lena and Mynatt, Elizabeth and Terry, Michael A.},
title = {Time Aura: Interfaces for Pacing},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365077},
doi = {10.1145/365024.365077},
abstract = {Historically one of the visions for human-computer symbiosis has been to augment human intelligence and extend people's cognitive abilities. In this paper, we present two visually-based systems to enhance a person's ability to flexibly control their pace while engaged in a cognitively demanding activity. In these investigations, we explore pacing interfaces that minimize the cognitive demands for assessing a current pace, provide ambient cues that can be quickly interpreted without incurring significant interruption from the current task, and place knowledge in the world to flexibly support different pacing strategies. Evaluation of our pacing interfaces shows that technology can successfully support pacing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {144–151},
numpages = {8},
keywords = {visual interaces, pacing, ubiquitous computing},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365078,
author = {Chao, Dennis},
title = {Doom as an Interface for Process Management},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365078},
doi = {10.1145/365024.365078},
abstract = {This paper explores a novel interface to a system administration task. Instead of creating an interface de novo for the task, the author modified a popular computer game, Doom, to perform useful work. The game was chosen for its appeal to the target audience of system administrators. The implementation described is not a mature application, but it illustrates important points about user interfaces and our relationship with computers. The applications relies on a computer game vernacular rather than the simulations of physical reality found in typical navigable virtual environments. Using a computer game vocabulary may broaden an application's audience by providing sn intuitive environment for children and non-technical users. In addition, the application highlights the adversarial relationships that exist in a computer and suggests a new resource allocation scheme.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {152–157},
numpages = {6},
keywords = {video games, visualization, cyberspace, first-person shooter, 3D user interfaces, games, Doom, metaphors, vernacular, Post-Modernism, operating systems},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365090,
author = {Gong, Li and Lai, Jennifer},
title = {Shall We Mix Synthetic Speech and Human Speech? Impact on Users' Performance, Perception, and Attitude},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365090},
doi = {10.1145/365024.365090},
abstract = {Because it is impractical to record human voice for ever-changing dynamic content such as email messages and news, many commercial speech applications use human speech for fixed prompts and synthetic speech (TTS) for the dynamic content. However, this mixing approach may not be optimal from a consistency perspective. A 2-condition between-group experiment (N = 24) was conducted to compare two versions of a virtual-assistant interface (mixing human voice and TTS vs. TTS-only). Users interacted with the virtual assistant to manage some email and calendar tasks. Their task performance, self-perception of task performance, and attitudinal responses were measured. Users interacting with the TTS-only interface performed the task significantly better, while users interacting with the mixed-voices interface thought they did better and had more positive attitudinal responses. Explanations and design implications are suggested.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {158–165},
numpages = {8},
keywords = {consistency, virtual assistant, telephone-based solution, speech applications, email and calendar},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365092,
author = {Baldis, Jessica J.},
title = {Effects of Spatial Audio on Memory, Comprehension, and Preference during Desktop Conferences},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365092},
doi = {10.1145/365024.365092},
abstract = {An experiment was conducted to determine the effect of spatial audio on memory, focal assurance, perceived comprehension and listener preferences during desktop conferences. Nineteen participants listened to six, pre-recorded, desktop conferences. Each conference was presented using either non-spatial audio, co-located spatial audio, or scaled spatial audio, and during half of the conferences, static visual representations of the conferees were present. In the co-located condition, each conferees voice originated from directly above their image on the screen, and in the scaled spatial audio condition, the spatial separation between conferee voices was increased beyond the visual separation. Results showed that spatial audio improved all measures, increasing memory, focal assurance, and perceived comprehension. In addition, participants preferred spatial audio to non-spatial audio. No strong differences were found in the visual conditions, or between the co-located spatial condition and the scaled spatial conditions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {166–173},
numpages = {8},
keywords = {audio, sound, comprehension, communication, spatial, user preference, focal assurance, memory, 3D, perception},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365094,
author = {Nelson, Les and Bly, Sara and Sokoler, Tomas},
title = {Quiet Calls: Talking Silently on Mobile Phones},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365094},
doi = {10.1145/365024.365094},
abstract = {Quiet Calls is a technology allowing mobile telephone users to respond to telephone conversations without talking aloud. QC-Hold, a Quiet Calls prototype, combines three buttons for responding to calls with a PDA/mobile phone unit to silently send pre-recorded audio directly into the phone. This permits a mixed-mode communication where callers in public settings use a quiet means of communication, and other callers experience a voice telephone call. An evaluation of QC-Hold shows that it is easily used and suggests ways in which Quiet Calls offers a new form of communication, extending the choices offered by synchronous phone calling and asynchronous voicemail.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {174–181},
numpages = {8},
keywords = {interaction design, telecommunication, mobile computing, computer mediated communication, hand-held devices},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365096,
author = {Stifelman, Lisa and Arons, Barry and Schmandt, Chris},
title = {The Audio Notebook: Paper and Pen Interaction with Structured Speech},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365096},
doi = {10.1145/365024.365096},
abstract = {This paper addresses the problem that a listener experiences when attempting to capture information presented during a lecture, meeting, or interview. Listeners must divide their attention between the talker and their notetaking activity. We propose a new device-the Audio Notebook-for taking notes and interacting with a speech recording. The Audio Notebook is a combination of a digital audio recorder and paper notebook, all in one device. Audio recordings are structured using two techniques: user structuring based on notetaking activity, and acoustic structuring based on a talker's changes in pitch, pausing, and energy. A field study showed that the interaction techniques enabled a range of usage styles, from detailed review to high speed skimming. The study motivated the addition of  phrase detection and topic suggestions to improve access to the audio recordings. Through these audio interaction techniques, the Audio Notebook defines a new approach for navigation in the audio domain.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {182–189},
numpages = {8},
keywords = {speech as data, speech interfaces, user structuring, acoustic structuring, audio, paper, speech, pen interaction},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365097,
author = {Rodden, Kerry and Basalaj, Wojciech and Sinclair, David and Wood, Kenneth},
title = {Does Organisation by Similarity Assist Image Browsing?},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365097},
doi = {10.1145/365024.365097},
abstract = {In current systems for browsing image collections, users are presented with sets of thumbnail images arranged in some default order on the screen. We are investigating whether it benefits users to have sets of thumbnails arranged according to their mutual similarity, so images that are alike are placed together. There are, of course, many possible definitions of “similarity”: so far we have explored measurements based on low-level visual features, and on the textual captions assigned to the images. Here we describe two experiments, both involving designers as the participants, examining whether similarity-based arrangements of the candidate images are helpful for a picture selection task. Firstly, the two types of similarity-based arrangement were informally compared.  Then, an  arrangement based on visual similarity was more formally compared with a control of a random arrangement. We believe this work should be of interest to anyone designing a system that involves presenting sets of images to users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {190–197},
numpages = {8},
keywords = {information visualisation, evaluation, image retrieval},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365098,
author = {Woodruff, Allison and Faulring, Andrew and Rosenholtz, Ruth and Morrsion, Julie and Pirolli, Peter},
title = {Using Thumbnails to Search the Web},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365098},
doi = {10.1145/365024.365098},
abstract = {We introduce a technique for creating novel, textually-enhanced thumbnails of Web pages. These thumbnails combine the advantages of image thumbnails and text summaries to provide consistent performance on a variety of tasks. We conducted a study in which participants used three different types of summaries (enhanced thumbnails, plain thumbnails, and text summaries) to search Web pages to find several different types of information. Participants took an average of 67, 86, and 95 seconds to find the answer with enhanced thumbnails, plain thumbnails, and text summaries, respectively. We found a strong effect of question category. For some questions, text outperformed plain thumbnails, while for other questions, plain thumbnails outperformed text. Enhanced thumbnails (which combine the features of text summaries and plain thumbnails) were more consistent than either text summaries or plain thumbnails, having for all categories the best performance or performance that was statistically indistinguishable from the best.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {198–205},
numpages = {8},
keywords = {thumbnails, Web search task},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365100,
author = {Lai, Jennifer and Cheng, Karen and Green, Paul and Tsimhoni, Omer},
title = {On the Road and on the Web? Comprehension of Synthetic and Human Speech While Driving},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365100},
doi = {10.1145/365024.365100},
abstract = {In this study 24 participants drove a simulator while listening to three types of messages in both synthesized speech and recorded human speech. The messages consisted of short navigation messages, medium length (approximately 100 words) email messages, and longer news stories (approximately 200 words). After each message the participant was presented with a series of multiple choice questions to measure comprehension of the message. Driving performance was recorded. Findings show that for the low driving workload conditions in the study, (cruise control, predictable two-lane road with no intersections, invariant lead car) driving performance was not affected by listening to messages. This was true for both the synthesized speech and natural speech. Comprehension of messages in synthetic speech was significantly lower than for recorded human speech for all message types.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {206–212},
numpages = {7},
keywords = {comprehension, driving simulator, driving performance, text-to-speech, speech synthesis},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365102,
author = {Buyukkokten, Orkut and Garcia-Molina, Hector and Paepcke, Andreas},
title = {Accordion Summarization for End-Game Browsing on PDAs and Cellular Phones},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365102},
doi = {10.1145/365024.365102},
abstract = {We demonstrate a new browsing technique for devices with small displays such as PDAs or cellular phones. We concentrate on end-game browsing, where the user is close to or on the target page. We make browsing more efficient and easier by Accordion Summarization. In this technique the Web page is first represented as a short summary. The user can then drill down to discover relevant parts of the page. If desired, keywords can be highlighted and exposed automatically. We discuss our techniques, architecture, interface facilities, and the result of user evaluations. We measured a 57% improvement in browsing speed and 75% reduction in input effort.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {213–220},
numpages = {8},
keywords = {WWW (World-Wide Web), WAP, WML, HTML, PDA (Personal Digital Assistant)},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365105,
author = {Tang, John C. and Yankelovich, Nicole and Begole, James and Van Kleek, Max and Li, Francis and Bhalodia, Janak},
title = {ConNexus to Awarenex: Extending Awareness to Mobile Users},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365105},
doi = {10.1145/365024.365105},
abstract = {We explored the use of awareness information to facilitate communication by developing a series of prototypes. The ConNexus prototype integrates awareness information, instant messaging, and other communication channels in an interface that runs on a desktop computer. The Awarenex prototype extends that functionality to wireless handheld devices, such as a Palm. A speech interface also enables callers to make use of the awareness information over the telephone. While the prototypes offer similar functionality, the interfaces reflect the different design affordances and use context of each platform. We discuss the design implications of providing awareness information on devices with varying interface and network characteristics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {221–228},
numpages = {8},
keywords = {awareness, computer-mediated communication, instant messaging, mobile devices, wireless handhelds, CSCW},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365107,
author = {Bhavnani, Suresh K. and Reif, Frederick and John, Bonnie E.},
title = {Beyond Command Knowledge: Identifying and Teaching Strategic Knowledge for Using Complex Computer Applications},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365107},
doi = {10.1145/365024.365107},
abstract = {Despite experience, many users do not make efficient use of complex computer applications. We argue that this is caused by a lack of strategic knowledge that is difficult to acquire just by knowing how to use commands. To address this problem, we present efficient and general strategies for using computer applications, and identify the components of strategic knowledge required to use them. We propose a framework for teaching strategic knowledge, and show how we implemented it in a course for freshman students. In a controlled study, we compared our approach to the traditional approach of just teaching commands. The results show that efficient and general strategies can in fact be taught to students of diverse backgrounds in a limited time without harming command knowledge. The experiment also pinpointed those strategies that can be automatically learned just from learning commands, and those that require more practice than we provided. These results are important to universities and companies that wish to foster more efficient use of complex computer applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {229–236},
numpages = {8},
keywords = {strategies, instruction, GOMS, training},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365109,
author = {Rosson, Mary Beth and Seals, Cheryl D.},
title = {Teachers as Simulation Programmers: Minimalist Learning and Reuse},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365109},
doi = {10.1145/365024.365109},
abstract = {Five public school teachers were observed during two self-study sessions where they learned to use Visual AgenTalk (VAT). The first session emphasized the basic visual programming skills, while the second introduced ways to reuse existing simulations. Two versions of the reuse tutorial were developed, one offering a concrete example world for reuse, and the second an abstract world. During their learning and reuse sessions, the teachers thought out loud as they worked, enabling a detailed analysis of their goals, reactions, problems, and successes. After each session, the teachers also completed user reaction questionnaires. Although all teachers succeeded in learning the basics of VAT, they varied considerably in their reuse of the example simulations. It appears that the simplified components of the abstract world supported reuse to a greater degree than those of the concrete example world.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {237–244},
numpages = {8},
keywords = {simulations, visual programming, teacher education},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365111,
author = {Corbett, Albert T. and Anderson, John R.},
title = {Locus of Feedback Control in Computer-Based Tutoring: Impact on Learning Rate, Achievement and Attitudes},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365111},
doi = {10.1145/365024.365111},
abstract = {The advent of second-generation intelligent computer tutors raises an important instructional design question: when should tutorial advice be presented in problem solving? This paper examines four feedback conditions in the ACT Programming Tutor. Three versions offer the student different levels of control over error feedback and correction: (a) immediate feedback and immediate error correction; (b) immediate error flagging and student control of error correction; (c) feedback on demand and student control of error correction. A fourth, No-tutor condition offers no stepby-step problem solving support. The immediate feedback group with greatest tutor control of problem solving yielded the most efficient learning. These students completed the tutor problems fastest, and the three tutor-supported groups performed equivalently on tests. Questionnaires revealed little student preference among the four conditions. These results suggest that students will need explicit guidance to benefit from learning opportunities that arise when they have greater control over tutorial assistance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {245–252},
numpages = {8},
keywords = {intelligent tutoring systems, student modeling, feedback in problem solving, instructional interface design},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365112,
author = {Patten, James and Ishii, Hiroshi and Hines, Jim and Pangaro, Gian},
title = {Sensetable: A Wireless Object Tracking Platform for Tangible User Interfaces},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365112},
doi = {10.1145/365024.365112},
abstract = {In this paper we present a system that electromagnetically tracks the positions and orientations of multiple wireless objects on a tabletop display surface. The system offers two types of improvements over existing tracking approaches such as computer vision. First, the system tracks objects quickly and accurately without susceptibility to occlusion or changes in lighting conditions. Second, the tracked objects have state that can be modified by attaching physical dials and modifiers. The system can detect these changes in real-time.We present several new interaction techniques developed in the context of this system. Finally, we present two applications of the system: chemistry and system dynamics simulation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {253–260},
numpages = {8},
keywords = {tangible user interface, two-handed manipulation, object tracking, augmented reality, system dynamics, interactive surface},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365114,
author = {Schkolne, Steven and Pruett, Michael and Schr\"{o}der, Peter},
title = {Surface Drawing: Creating Organic 3D Shapes with the Hand and Tangible Tools},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365114},
doi = {10.1145/365024.365114},
abstract = {Surface Drawing is a system for creating organic 3D shapes in a manner which supports the needs and interests of artists. This medium facilitates the early stages of creative design which many 3D modeling programs neglect. Much like traditional media such as line drawing and painting, Surface Drawing lets users construct shapes through repeated marking. In our case, the hand is used to mark 3D space in a semi-immersive virtual environment. The interface is completed with tangible tools to edit and manipulate models. We introduce the use of tongs to move and scale 3D shapes and demonstrate a magnet tool which is comfortably held without restricting hand motion. We evaluated our system through collaboration with artists and designers, exhibition before hundreds of users, our own extensive exploration of the medium, and an informal user study. Response was especially positive from users with an artistic background.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {261–268},
numpages = {8},
keywords = {hand-based interface, artistic shape creation, 3D modeling, design prototyping, repeated marking, fine art, semi-immersive environment, tangible user interface},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365115,
author = {Rekimoto, Jun and Ullmer, Brygg and Oba, Haruo},
title = {DataTiles: A Modular Platform for Mixed Physical and Graphical Interactions},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365115},
doi = {10.1145/365024.365115},
abstract = {The DataTiles system integrates the benefits of two major interaction paradigms: graphical and physical user interfaces.  Tagged transparent tiles are used as modular construction units.  These tiles are augmented by dynamic graphical information when they are placed on a sensor-enhanced flat panel display.  They can be used independently or can be combined into more complex configurations, similar to the way language can express complex concepts through a sequence of simple words. In this paper, we discuss our design principles for mixing physical and graphical interface techniques, and describe the system architecture and example applications of the DataTiles system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {269–276},
numpages = {8},
keywords = {visual language, tangible user interfaces, graphical user interfaces, radio-frequency identification tags, interaction techniques},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365116,
author = {Dumais, Susan and Cutrell, Edward and Chen, Hao},
title = {Optimizing Search by Showing Results in Context},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365116},
doi = {10.1145/365024.365116},
abstract = {We developed and evaluated seven interfaces for integrating semantic category information with Web search results. List interfaces were based on the familiar ranked-listing of search results, sometimes augmented with a category name for each result. Category interfaces also showed page titles and/or category names, but re-organized the search results so that items in the same category were grouped together visually. Our user studies show that all Category interfaces were more effective than List interfaces even when lists were augmented with category names for each result. The best category performance was obtained when both category names and individual page titles were presented. Either alone is better than a list presentation, but both together provide the most effective means for allowing users to quickly examining search results. These results provide a better understanding of the perceptual and cognitive factors underlying the advantage of category groupings and provide some practical guidance to Web search interface designers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {277–284},
numpages = {8},
keywords = {World Wide Web, usability, text categorization, user interface, focus-in-context, user study, search},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365117,
author = {Brush, A. J. Bernheim and Bargeron, David and Gupta, Anoop and Cadiz, J. J.},
title = {Robust Annotation Positioning in Digital Documents},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365117},
doi = {10.1145/365024.365117},
abstract = {Increasingly, documents exist primarily in digital form. System designers have recently focused on making it easier to read digital documents, with annotation as an important new feature. But supporting annotation well is difficult because digital documents are frequently modified, making it challenging to correctly reposition annotations in modified versions. Few systems have addressed this issue, and even fewer have approached the problem from the users' point of view. This paper reports the results of two studies examining user expectations for robust annotation positioning in modified documents. We explore how users react to lost annotations, the relationship between types of document modifications and user expectations, and whether users pay attention to text surrounding their  annotations. Our results could contribute substantially to effective digital document annotation systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {285–292},
numpages = {8},
keywords = {documents, annotation system design, annotation, robust, digital},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365118,
author = {Hornb\ae{}k, Kasper and Fr\o{}kj\ae{}r, Erik},
title = {Reading of Electronic Documents: The Usability of Linear, Fisheye, and Overview+detail Interfaces},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365118},
doi = {10.1145/365024.365118},
abstract = {Reading of electronic documents is becoming increasingly important as more information is disseminated electronically. We present an experiment that compares the usability of a linear, a fisheye, and an overview+detail interface for electronic documents. Using these interfaces, 20 subjects wrote essays and answered questions about scientific documents. Essays written using the overview+detail interface received higher grades, while subjects using the fisheye interface read documents faster. However, subjects used more time to answer questions with the overview+detail interface. All but one subject preferred the overview+detail interface. The most common interface in practical use, the linear interface, is found to be inferior to the fisheye and overview+detail interfaces regarding most aspects of usability. We recommend using overview+detail interfaces for electronic documents, while fisheye interfaces mainly should be considered for time-critical tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {293–300},
numpages = {8},
keywords = {user study, electronic documents, reading activity, information retrieval, information visualization, usability},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365119,
author = {Vertegaal, Roel and Slagter, Robert and van der Veer, Gerrit and Nijholt, Anton},
title = {Eye Gaze Patterns in Conversations: There is More to Conversational Agents than Meets the Eyes},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365119},
doi = {10.1145/365024.365119},
abstract = {In multi-agent, multi-user environments, users as well as agents should have a means of establishing who is talking to whom. In this paper, we present an experiment aimed at evaluating whether gaze directional cues of users could be used for this purpose. Using an eye tracker, we measured subject gaze at the faces of conversational partners during four-person conversations. Results indicate that when someone is listening or speaking to individuals, there is indeed a high probability that the person looked at is the person listened (p=88%) or spoken to (p=77%). We conclude that gaze is an excellent predictor of conversational attention in multiparty conversations. As such, it may form a reliable source of input for conversational systems that need to establish whom the user is speaking or listening to. We implemented our findings in FRED, a multi-agent conversational system that uses eye input to gauge which agent the user is listening or speaking to.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {301–308},
numpages = {8},
keywords = {attentive agents, multiparty communication, conversational attention, attention-based interfaces, tracking, gaze},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365121,
author = {Garau, Maia and Slater, Mel and Bee, Simon and Sasse, Martina Angela},
title = {The Impact of Eye Gaze on Communication Using Humanoid Avatars},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365121},
doi = {10.1145/365024.365121},
abstract = {In this paper we describe an experiment designed to investigate the importance of eye gaze in humanoid avatar's representing people engaged in conversation. We compare responses to dyadic conversations in four mediated conditions: video, audio-only, and two avatar conditions. The avatar conditions differed only in their treatment of eye gaze. In the random-gaze condition the avatars head and eye animations were unrelated to conversational flow. In the informed-gaze condition, they were related to turn-taking during the conversation. The head animations were tracked and the eye animations were inferred from the audio stream. Our comparative analysis of 100 post-experiment questionnaires showed that the random-gaze avatar did not improve on audio-only communication. The informed-gaze  avatar significantly outperformed the random-gaze model and also outperformed audio-only on several response measures. We conclude that an avatar whose gaze behaviour is related to the conversation provides a marked improvement on an avatar that merely exhibits liveliness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {309–316},
numpages = {8},
keywords = {avatars, computer-mediated communication (CMC), mediated communication, collaborative virtual enviroments (CVEs), nonverbal behaviours, gaze},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365124,
author = {Hahn, Jungpil},
title = {The Dynamics of Mass Online Marketplaces: A Case Study of an Online Auction},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365124},
doi = {10.1145/365024.365124},
abstract = {The Internet has dramatically changed how people sell and buy goods. In recent years we have seen the emergence of electronic marketplaces that leverage information technology to create more efficient markets such as online auctions to bring together buyers and sellers with greater effectiveness at a massive scale. Despite the growing interest and importance of such marketplaces, our understanding of how the design of the marketplace affects buyer and seller behavior at the individual level and the market effectiveness at the aggregate level is still quite limited. This paper presents a detailed case study of a currently operational massive scale online auction marketplace. The main focus is to gain initial insights into the effects of the design of the marketplace. The results of the study point to several important considerations and implications not only for the design of online marketplaces but also for the design of large-scale websites where effective locating of information is key to user success.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {317–324},
numpages = {8},
keywords = {market navigation, information overload, online market design, market technostructure, item display, massive scale online auctions, electronic marketplaces},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.383749,
author = {Hindus, Debby and Mainwaring, Scott D. and Leduc, Nicole and Hagstr\"{o}m, Anna Elizabeth and Bayley, Oliver},
title = {Casablanca: Designing Social Communication Devices for the Home},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.383749},
doi = {10.1145/365024.383749},
abstract = {The Casablanca project explored how media space concepts could be incorporated into households and family life. This effort included prototypes built for the researchers' own home use, field studies of households, and consumer testing of design concepts. A number of previously unreported consumer preferences and concerns were uncovered and incorporated into several original prototypes, most notably ScanBoard and the Intentional Presence Lamp. Casablanca also resulted in conclusions about designing household social communication devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {325–332},
numpages = {8},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365126,
author = {Mynatt, Elizabeth D. and Rowan, Jim and Craighill, Sarah and Jacobs, Annie},
title = {Digital Family Portraits: Supporting Peace of Mind for Extended Family Members},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365126},
doi = {10.1145/365024.365126},
abstract = {A growing social problem in the U.S., and elsewhere, is supporting older adults who want to continue living independently, as opposed to moving to an institutional care setting. One key part of this complex problem is providing awareness of senior adults day-to-day activities, promoting peace of mind for extended family members. In this paper, we introduce the concept of a digital family portrait that provides qualitative visualizations of a family members daily life. Leveraging a familiar household object, the picture frame, our design populates the frame with iconic imagery summarizing 28 days. In a final implementation, the digital family portrait would gather information from sensors in the home.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {333–340},
numpages = {8},
keywords = {home, ubiquitous computing, light-weight interaction, awareness, aging, visualization},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365130,
author = {Svensson, Martin and H\"{o}\"{o}k, Kristina and Laaksolahti, Jarmo and Waern, Annika},
title = {Social Navigation of Food Recipes},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365130},
doi = {10.1145/365024.365130},
abstract = {The term Social Navigation captures every-day behaviour used to find information, people, and places - namely through watching, following, and talking to people. We discuss how to design information spaces to allow for social navigation. We applied our ideas in a recipe recommendation system. In a follow-up user study, subjects state that social navigation adds value to the service: it provides for social affordance, and it helps turning a space into a social place. The study also reveals some unresolved design issues, such as the snowball effect where more and more users follow each other down the wrong path, and privacy issues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {341–348},
numpages = {8},
keywords = {online shopping, awareness, social navigation, recommender system, privacy},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365298,
author = {Wang, Jingtao and Zhai, Shumin and Su, Hui},
title = {Chinese Input with Keyboard and Eye-Tracking: An Anatomical Study},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365298},
doi = {10.1145/365024.365298},
abstract = {Chinese input presents unique challenges to the field of human computer interaction. This study provides an anatomical analysis of today's standard Chinese input process, which is based on pinyin, a phonetic spelling system in Roman characters. Through a combination of human performance modeling and experimentation, our study decomposed the Chinese input process into sub-tasks and found that choice reaction time and numeric keying, two component resulted from the large number of homophones in Chinese, were the major usability bottlenecks. Choice reaction alone took 36% of the total input time in our experiment. Numeric keying for multiple candidates selection tends to take the user's attention away from the computer visual screen. We designed and implemented the EASE (Eye Assisted  Selection and Entry) system to help maintaining  complete touch-typing experience without diverting visual (spacebar) and implicit eye-tracking to replace the numeric keystrokes. Our experiment showed that such a system could indeed work, even with today's imperfecteye-tracking technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {349–356},
numpages = {8},
keywords = {Chinese text input, performance modeling, multi-modal interface, gaze, eye-tracking, gaze-tracking, pinyin input},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365299,
author = {Isokoski, Poika},
title = {Model for Unistroke Writing Time},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365299},
doi = {10.1145/365024.365299},
abstract = {Unistrokes are a viable form of text input in pen-based user interfaces. However, they are a very heterogeneous group of gestures the only common feature being that all are drawn with a single stroke. Several unistroke alphabets have been proposed including the original Unistrokes, Graffiti, Allegro, T-Cube and MDITIM. Comparing these methods usually requires a lengthy study with many writers and even then the results are biased by the earlier handwriting experience that the writers have. Therefore, a simple descriptive model for predicting the writing time for an expert user on any given unistroke alphabet thus enabling sounder argumentation on the properties of different writing methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {357–364},
numpages = {8},
keywords = {pen input, modeling of motor performance, handwriting},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365300,
author = {James, Christina L. and Reischel, Kelly M.},
title = {Text Input for Mobile Devices: Comparing Model Prediction to Actual Performance},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365300},
doi = {10.1145/365024.365300},
abstract = {A study was conducted to obtain performance data for entering text on a mobile phone in order to compare it to performance predictions based on two different mathematical models. Speed data was obtained for two text input methods, T9 Text Input and Multi-tap. While the direction of the results was the same for both the performance data and both model predicitons (with predictive text entry being faster than Multi-tap text entry), the results for all three differed in magnitude. Suggestions for this discrepancy are provided. In addition, in order to help shape future models, additional results are presented for both input methods to show how both accuracy and speed performance varies based on user experience and text subject matter.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {365–371},
numpages = {7},
keywords = {performance modeling, text entry, mobile phones, mobile systems, keypad input},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365301,
author = {Carroll, John M. and Rosson, Mary Beth},
title = {Better Home Shopping or New Democracy? Evaluating Community Network Outcomes},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365301},
doi = {10.1145/365024.365301},
abstract = {This is a perspective paper on community networks - socio-technical infrastructures supporting villages, towns, and neighborhoods. Community networking is well-established, world wide, and addresses critical societal issues, such as the “crisis of community” and the sociality of the Internet. However, community network projects have not emphasized evaluation. Relatively little is known about the economic, social, and psychological consequences of community networks for the individuals, groups, and communities served. Evaluating community networks is a momentous mutual opportunity for the development of CHI evaluation methodologies and for bringing technical CHI expertise to bear on societal issues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {372–379},
numpages = {8},
keywords = {community networks, evaluation, social impact},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365302,
author = {Bers, Marina U. and Gonzalez-Heydrich, Joseph and DeMaso, David Ray},
title = {Identity Construction Environments: Supporting a Virtual Therapeutic Community of Pediatric Patients Undergoing Dialysis},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365302},
doi = {10.1145/365024.365302},
abstract = {We describe a five-month pilot project conducted in the dialysis unit at Boston's Children's Hospital. Pediatric patients with renal disease used the Zora graphical multi-user environment while facing hemodialysis. Zora is an identity construciton environment specifically designed to help young people explore issues of identity, while engaging in a participatory virtual community. This paper presents the experience and evaluates the feasibility and safety of using Zora in a hospital setting. It describes how Zora facilitated explorations of identity and mutual patient support and interaction. Finally it also presents design recommendations for future interventions of this kind. More generally, this paper explores the potential of technology specifically designed with therapeutic  purposes to help patients cope with their illness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {380–387},
numpages = {8},
keywords = {therapy, identity, pediatric patients, virtual communities, dialysis, multi-user virtual environment, storytelling},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365303,
author = {Danesh, Arman and Inkpen, Kori and Lau, Felix and Shu, Keith and Booth, Kellogg},
title = {GeneyTM: Designing a Collaborative Activity for the PalmTM Handheld Computer},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365303},
doi = {10.1145/365024.365303},
abstract = {This paper describes a project to explore issues surrouding the development of a collaborative handheld educational application for children. A user-centered, iterative design process was used to develop GeneyTM, a collaborative problem solving application to help children explore genetic concepts using PalmTM handheld computers. The design methodology utilized mock-ups of representative tasks and scenarios, pre-design meetings with targets users, prototype development, and feedback sessions with target users. The results of this work identify an effective way of utilizing handheld computers for collaborative learning and provide important insights into the design of handheld applications for children. This work also illustrates the necessity of user-centered design when new user  groups are targeted, especially when novel user interface paradigms are employed that go beyond current windows-based interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {388–395},
numpages = {8},
keywords = {education, CSCL, user-centered design, genetics, children, handheld computing, CSCW, PDAs},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365304,
author = {Bickmore, Timothy and Cassell, Justine},
title = {Relational Agents: A Model and Implementation of Building User Trust},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365304},
doi = {10.1145/365024.365304},
abstract = {Building trust with users is crucial in a wide range of applications, such as financial transactions, and some minimal degree of trust is required in all applications to even initiate and maintain an interaction with a user. Humans use a variety of relational conversational strategies, including small talk, to establish trusting relationships with each other. We argue that such strategies can also be used by interface agents, and that embodied conversational agents are ideally suited for this task given the myriad cues available to them for signaling trustworthiness. We describe a model of social dialogue, an implementation in an embodied conversation agent, and an experiment in which social dialogue was demonstrated to have an effect on trust, for users with a disposition to be  extroverts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {396–403},
numpages = {8},
keywords = {natural language, small talk, embodied conversational agent, personality, social interface, trust},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365305,
author = {Aberg, Johan and Shahmehri, Nahid},
title = {An Empirical Study of Human Web Assistants: Implications for User Support in Web Information Systems},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365305},
doi = {10.1145/365024.365305},
abstract = {User support is an important element in reaching the goal of universal usability for Web information systems. Recent developments indicate that human involvement in user support is a step towards this goal. However, most such efforts are currently being pursued on a purely intuitive basis. This, empirical findings about the role of human assistants are important. In this paper we present the findings from a field study of a general user support model for Web information systems. We show that integrating human assistance into Web systems is a way to provide efficient user support. Further, this integration makes a Web site more fun to use and increases the user's trust in the site. The support also improves the site atmosphere. Our findings are summarised as recommendations and design  guidelines for decision-makers and developers Web systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {404–411},
numpages = {8},
keywords = {universal usability, user support, efficiency, field study, attitude, design guidelines, Web information systems},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365306,
author = {Couper, Mick P. and Tourangeau, Roger and Steiger, Darby M.},
title = {Social Presence in Web Surveys},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365306},
doi = {10.1145/365024.365306},
abstract = {Social interface theory has widespread influence in the field of human-computer interaction. The basic thesis is that humanizing cues in a computer interface can engender responses from users similar to human-human interaction. In contrast, the survey interviewing literature suggests that computer administration of surveys on highly sensitive topics reduces or eliminates social desirability effect, even when such humanizing features as voice are used.In attempting to reconcile these apparently contradictory findings, we varied features of the interface in a Web survey (n=3047). In one treatment, we presented an image of 1) a male researcher, 2) a female researcher, or 3) the study logo at several points. In another, we varied the extent of personal feedback provided. We  find little support for the soical interface hypothesis. We describe our study and discuss possible reasons for the contradictory evidence on social interfaces},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {412–417},
numpages = {6},
keywords = {social desirability, social interfaces, Web surveys},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365307,
author = {Tan, Desney S. and Robertson, George G. and Czerwinski, Mary},
title = {Exploring 3D Navigation: Combining Speed-Coupled Flying with Orbiting},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365307},
doi = {10.1145/365024.365307},
abstract = {We present a task-based taxonomy of navigation techniques for 3D virtual environments, used to categorize existing techniques, drive exploration of the design space, and inspire new techniques. We briefly discuss several new techniques, and describe in detail one new techniques, Speed-coupled Flying with Orbiting. This technique couples control of movement speed to camera height and tilt, allowing users to seamlessly transition between local environment-views and global overviews. Users can also orbit specific objects for inspection. Results from two competitive user studies suggest users performed better with Speed-coupled Flying with Orbiting over alternatives, with performance also enhanced by a large display.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {418–425},
numpages = {8},
keywords = {egocentric navigation, interaction techniques, 3D virtual environments, user studies},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365308,
author = {Mason, Andrea H. and Walji, Masuma A. and Lee, Elaine J. and MacKenzie, Christine L.},
title = {Reaching Movements to Augmented and Graphic Objects in Virtual Environments},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365308},
doi = {10.1145/365024.365308},
abstract = {This work explores how the availability of visual and haptic feedback affects and kinematics of reaching performance in a tabletop virtual environment. Eight subjects performed reach-to-grasp movements toward target objects of various sites in conitions where visual and haptic feedback were either present or absent. It was found that movement time was slower when visual feedback of the moving limb was not available. Further MT varied systematically with target size when haptic feedback was available (i.e. augmented targets), and thus followed Fitts' law. However, movement times were constant regardless of target size when haptic feedback was removed. In depth analysis of the reaching kinematics revealed that subjects spent longer decelerating toward smaller targets in conditions where  haptic feedback was available. In contrast, deceleration time was constant when haptic feedback was absent. These results suggest that visual feedback about the moving limb and veridical haptic feedback about object contract are extremely important for humans to effectively work in virtual environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {426–433},
numpages = {8},
keywords = {sensory manipulation, human performance, interaction, Fitts' law, sensory information, kinematic data, empirical data, haptic feedback, augmented reality, object manipulation, visual feedback},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365309,
author = {Cockburn, Andy and McKenzie, Bruce},
title = {3D or Not 3D? Evaluating the Effect of the Third Dimension in a Document Management System},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365309},
doi = {10.1145/365024.365309},
abstract = {Several recent research systems have provided interactive three-dimensional (3D) visualisations for supporting everyday work such as file and document management. But what improvements do these 3D interfaces offer over their traditional 2D counterparts? This paper describes the comparative evaluation of two document management systems that differ only in the number of dimensions used for displaying and interacting with the data. The 3D system is heavily based on Robertson et al.'s Data Mountain, which supports users in storing, organising and retrieving “thumbnail” representations of documents such as bookmarked Web-pages. Results show that our subjects were faster at storing and retrieving pages in the display when using the 2D interface, but not significantly so. As expected,  retrieval times significantly increased as the number of thumbnails increased. Despite the lack of significant differences between the 2D and 3D interfaces, subjective assessments showed a significant preference for the 3D interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {434–441},
numpages = {8},
keywords = {spatial memory, document management, information visualisation, 3D user interfaces},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365310,
author = {Liu, Qiong and Rui, Yong and Gupta, Anoop and Cadiz, J. J.},
title = {Automating Camera Management for Lecture Room Environments},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365310},
doi = {10.1145/365024.365310},
abstract = {Given rapid improvements in network infrastructure and streaming-media technologies, a large number of corporations and universities are recording lectures and making them available online for anytime, anywhere access. However, producing high-quality lecture videos is still labor intensive and expensive. Fortunately, recent technology advances are making it feasible to build automated camera management systems to capture lectures. In this paper we report on our design, implementation and study of such a system. Compared to previous work-which has tended to be technology centric-we started with interviews with professional video producers and used their knowledge and expertise to create video production rules. We then targeted technology components that allowed us to implement a  substantial portion of these rules, including the design of a virtual video director. The system's performance was compared to that of a human operator via a user study. Results suggest that our system's quality in close to that of a human-controlled system. In fact most remote audience members could not tell if the video was produced by a computer or a person.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {442–449},
numpages = {8},
keywords = {virtual video director, sound source localization, automated camera management, video production rules, speaker tracking},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365311,
author = {Rui, Yong and Gupta, Anoop and Cadiz, J. J.},
title = {Viewing Meeting Captured by an Omni-Directional Camera},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365311},
doi = {10.1145/365024.365311},
abstract = {One vision of future technology is the ability to easily and inexpensively capture any group meeting that occurs, store it, and make it available for people to view anytime and anywhere on the network. One barrier to achieving this vision has been the design of low-cost camera systems that can capture important aspects of the meeting without needing a human camera operator. A promising solution that has emerged recently is omni-directional cameras that can capture a 360-degree video of the entire meeting.The panoramic capability provided by these cameras raises both new opportunities and new issues for the interfaces provided for post-meeting viewers — for example, do we show all meeting participants all the time or do we just show the person who is speaking, how much  control do we provide to the end-user in selecting the view, and will providing this control distract them from their task. These are not just user interface issues, they also raise tradeoffs for the client-server systems used to deliver such content. They impact how much data needs to be stored on the disk, what computation can be done on the server vs. the client, and how much bandwidth is needed. We report on a rototype system built using an omni-directional camera and results from user studies of interface preferences expressed by viewers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {450–457},
numpages = {8},
keywords = {on-demand meeting watching, omni-directional camera systems},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365312,
author = {Grudin, Jonathan},
title = {Partitioning Digital Worlds: Focal and Peripheral Awareness in Multiple Monitor Use},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365312},
doi = {10.1145/365024.365312},
abstract = {Software today does not help us partition our digital worlds effectively. We must organize them ourselves. This field study of users of multiple monitors examines how people with a lot of display space arrange information. Second monitors are generally used for secondary activities related to principal tasks, for peripheral awareness of information that is not the main focus, and for easy access to resources. A second monitor improves efficiency in ways that are difficult to measure yet can have substantial subjective benefit. The study concludes with illustrations of shortcomings of today's systems and applications: the way we work could be improved at relatively low cost.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {458–465},
numpages = {8},
keywords = {displays, multiple monitors, awareness},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365316,
author = {Borovoy, Rick and Silverman, Brian and Gorton, Tim and Notowidigdo, Matt and Knep, Brian and Resnick, Mitchel and Klann, Jeff},
title = {Folk Computing: Revisiting Oral Tradition as a Scaffold for Co-Present Communities},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365316},
doi = {10.1145/365024.365316},
abstract = {In this paper, we introduce Folk Computing: an approach for using technology to support co-present community building inspired by the concept of folklore. We also introduce a new technology, called “i-balls,” whose design helped fashion this approach. The design of the i-ball environment is explained in terms of our effort to simultaneously preserve what works about folklore while also using technology to expand its power as a medium for community building.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {466–473},
numpages = {8},
keywords = {community, groupware, social computing, PDA, folklore, mobile computing, ubiquitous computing, face-to-face, handheld, education},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365317,
author = {Ellis, Jason B. and Bruckman, Amy S.},
title = {Designing Palaver Tree Online: Supporting Social Roles in a Community of Oral History},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365317},
doi = {10.1145/365024.365317},
abstract = {As a more diverse population of users moves online, understanding how to help those groups work together and leverage their diverse skills poses a significant challenge for human-computer interaction. This paper presents a case study of the design of an online community that supports kids interviewing elders to build up a shared database of oral history. Two pilot studies with existing technology are presented, and a software design based on those studies is described, along with future work. This work shows the value of prototyping with existing technology in order to uncover user needs in an onine environment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {474–481},
numpages = {8},
keywords = {user-centered design, online community, children, CSCL},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365322,
author = {Stanton, Danae and Bayon, Victor and Neale, Helen and Ghali, Ahmed and Benford, Steve and Cobb, Sue and Ingram, Rob and O'Malley, Claire and Wilson, John and Pridmore, Tony},
title = {Classroom Collaboration in the Design of Tangible Interfaces for Storytelling},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365322},
doi = {10.1145/365024.365322},
abstract = {We describe the design of tangible interfaces to the KidPad collaborative drawing tool. Our aims are to support the re-enactment of stories to audiences, and integration within real classroom environments. A six-month iterative design process, working with children and teachers in school, has produced the “magic carpet”, an interface that uses pressure mats and video-tracked and barcoded physical props to navigate a story in KidPad. Reflecting on this process, we propose four guidelines for the design of tangible interfaces for the classroom. (1) Use physical size and shysical props to encourage collaboration. (2) Be aware of how different interfaces emphasize different actions. (3) Be aware that superficial changes to the design can produce very different physical interactions. (4) Focus on open low-tech technologies rather than (over) polished products.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {482–489},
numpages = {8},
keywords = {storytelling, children, tangibles, participatory design},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365325,
author = {Chi, Ed H. and Pirolli, Peter and Chen, Kim and Pitkow, James},
title = {Using Information Scent to Model User Information Needs and Actions and the Web},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365325},
doi = {10.1145/365024.365325},
abstract = {On the Web, users typically forage for information by navigating from page to page along Web links. Their surfing patterns or actions are guided by their information needs. Researchers need tools to explore the complex interactions between user needs, user actions, and the structures and contents of the Web. In this paper, we describe two computational methods for understanding the relationship between user needs and user actions. First, for a particular pattern of surfing, we seek to infer the associated information need. Second, given an information need, and some pages as starting pints, we attempt to predict the expected surfing patterns. The algorithms use a concept called “information scent”, which is the subjective sense of value and cost of accessing a page based on perceptual cues. We present an empirical evaluation of these two algorithms, and show their effectiveness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {490–497},
numpages = {8},
keywords = {information foraging, information scent, World Wide Web, data mining, usability, information retrieval},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365331,
author = {Card, Stuart K. and Pirolli, Peter and Van Der Wege, Mija and Morrison, Julie B. and Reeder, Robert W. and Schraedley, Pamela K. and Boshart, Jenea},
title = {Information Scent as a Driver of Web Behavior Graphs: Results of a Protocol Analysis Method for Web Usability},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365331},
doi = {10.1145/365024.365331},
abstract = {The purpose of this paper is to introduce a replicable WWW protocol analysis methodology illustrated by application to data collected in the laboratory. The methodology uses instrumentation to obtain detailed recordings of user actions with a browser, caches Web pages encoutered, and videotapes talk-aloud protocols. We apply the current form of the method to the analysis of eight Web protocols, visualizing the structure of the interaction and showing the strong effect of information scent in determining the path followed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {498–505},
numpages = {8},
keywords = {Web usability, information scent, Weblogger, web-eyemapper, Web behavior graph, protocol analysis, information foraging},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365337,
author = {Pirolli, Peter and Card, Stuart K. and Van Der Wege, Mija M.},
title = {Visual Information Foraging in a Focus + Context Visualization},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365337},
doi = {10.1145/365024.365337},
abstract = {Eye tracking studies of the Hyperbolic Tree browser [10] suggest that visual search in focus+context displays is highly affected by information scent (i.e., local cues, such as text summaries, used to assess and navigate toward distal information sources). When users detected a strong information scent, they were able to reach their goal faster with the Hyperbolic Tree browser than with a conventional browser. When users detected a weak scent or no scent, users exhibited less efficient search of areas with a high density of visual items. In order to interpret these results we present an integration of the CODE Theory of Visual Attention (CTVA) with information foraging theory. Development of the CTVA-foraging theory could lead to deeper analysis of interaction with visual displays of  content, such as the World Wide Web or information visualizations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {506–513},
numpages = {8},
keywords = {visual attention, CODE theory of visual attention, information visualization, information scent, information foraging, hyperbolic tree, visual search, focus+context},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365339,
author = {Greenberg, Saul and Rounding, Michael},
title = {The Notification Collage: Posting Information to Public and Personal Displays},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365339},
doi = {10.1145/365024.365339},
abstract = {The Notification Collage (NC) is a groupware system where distributed and co-located colleagues comprising a small community post media elements onto a real-time collaborative surface that all members can see. Akin to collages of information found on public bulletin boards, NC randomly places incoming elements onto this surface. People can post assorted media: live video from desktop cameras; editable sticky notes; activity indicator; slide shows displaying a series of digital photos, snapshots of a person's digitial desktop, and Web page thumbnails. User experiences show that NC becomes a rich resource for awareness and collaboration. Community members indicate their presence to others by posting live video. They regularly act on this information by engaging in text and video   conversations. Because all people can overhear conversations, these become active opportunities to join in. People also post items they believe will be interesting to others, such as desktop snapshots and vacation photos. Finally, people use NC somewhat differently when it is displayed on a large public screen than when it appears on a personal computer.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {514–521},
numpages = {8},
keywords = {messaging, media spaces, informal interaction, awareness},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365349,
author = {Shoemaker, Garth B. D. and Inkpen, Kori M.},
title = {Single Display Privacyware: Augmenting Public Displays with Private Information},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365349},
doi = {10.1145/365024.365349},
abstract = {The research area of Single Display Groupware (SDG) confronts the standard model of computing interaction, one user working on one computer, by investigating how the best support groups of users interacting with a shared display. One problem that has arisen in SDG research concerns access to private information. Previously, private information could not be displayed on a shared display, it could only be accessed on external devices, such as private monitors or Personal Digital Assistants (PDAs). This paper discusses Single Display Privacyware (SDP), an interaction technique that allows private information to be shown within the context of a shared display. A description of the hardware and software components of our prototype SDP system is given, as are the results of a user study  performed to investigate users interacting in the environment. Conclusions concerning future research in the area of SDP are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {522–529},
numpages = {8},
keywords = {single display privacyware (SDP), awareness, privacy, single display groupware, CSCW, collaboration},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/365024.365352,
author = {Jancke, Gavin and Venolia, Gina Danielle and Grudin, Jonathan and Cadiz, J. J. and Gupta, Anoop},
title = {Linking Public Spaces: Technical and Social Issues},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365352},
doi = {10.1145/365024.365352},
abstract = {Three public spaces frequency used by members of a single organization who are distributed across different floors of two buildings were linked by constantly-running video and audio connections. We discuss the design of the system, including issues in providing low-latency, full-duplex audio-video connectivity, ways to increase possibilities for interaction while addressing privacy concerns, and the introduction of the system to the community. We report on responses to the system and lessions learned, including unexpected issues, such as creative decorations of the spaces and assertions by a vocal minority of employees about the private nature of “public space.”},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {530–537},
numpages = {8},
keywords = {privacy, informal communication, videoconferencing},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

