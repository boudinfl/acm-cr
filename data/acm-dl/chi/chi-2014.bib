@inproceedings{10.1145/3250911,
author = {De Angeli, Antonella},
title = {Session Details: Visualization and Aesthetics},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250911},
doi = {10.1145/3250911},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557152,
author = {\v{S}imbelis, Vygandas and Lundstr\"{o}m, Anders and H\"{o}\"{o}k, Kristina and Solsona, Jordi and Lewandowski, Vincent},
title = {Metaphone: Machine Aesthetics Meets Interaction Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557152},
doi = {10.1145/2556288.2557152},
abstract = {Through our art project, Metaphone, we explored a particular form of aesthetics referred to in the arts tradition as machine aesthetics. The Metaphone machine collects the participant's bio-data, Galvanic Skin Response (GSR) and Heart Rate (HR), creating a process of movement, painting and sound. The machine behaves in machine-like, aesthetically evocative ways: a shaft on two large wheels rotates on the floor, carrying paint that is dripped onto a large sheet of aquarelle paper on the floor according to bio-sensor data. A soundscape rhythmically follows the bio-sensor data, but also has its own machine-like sounds. Six commentators were invited to interact with the machine. They reported a strangely relaxing atmosphere induced by the machine. Based on these experiences we discuss how different art styles can help to describe aesthetics in interaction design generally, and how machine aesthetics in particular can be used to create interesting, sustained, stylistically coherent interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {affective computing, media arts, interaction design, machine aesthetics, bodily interaction, interactive arts},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557052,
author = {Reinecke, Katharina and Gajos, Krzysztof Z.},
title = {Quantifying Visual Preferences around the World},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557052},
doi = {10.1145/2556288.2557052},
abstract = {Website aesthetics have been recognized as an influential moderator of people's behavior and perception. However, what users perceive as "good design" is subject to individual preferences, questioning the feasibility of universal design guidelines. To better understand how people's visual preferences differ, we collected 2.4 million ratings of the visual appeal of websites from nearly 40 thousand participants of diverse backgrounds. We address several gaps in the knowledge about design preferences of previously understudied groups. Among other findings, our results show that the level of colorfulness and visual complexity at which visual appeal is highest strongly varies: Females, for example, liked colorful websites more than males. A high education level generally lowers this preference for colorfulness. Russians preferred a lower visual complexity, and Macedonians liked highly colorful designs more than any other country in our dataset. We contribute a computational model and estimates of peak appeal that can be used to support rapid evaluations of website design prototypes for specific target groups.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {modeling, personalization, website aesthetics, adaptation, colorfulness, complexity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557419,
author = {Sonderegger, Andreas and Uebelbacher, Andreas and Pugliese, Manuela and Sauer, Juergen},
title = {The Influence of Aesthetics in Usability Testing: The Case of Dual-Domain Products},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557419},
doi = {10.1145/2556288.2557419},
abstract = {An experimental study examined whether the effects of aesthetic appeal on usability test outcomes are moderated by usage domain. The aesthetic appeal of a cell phone was experimentally manipulated in both home- and work-based usage domains. The two usage domains were modeled in a usability laboratory. 60 participants completed a series of typical cell phone user tasks. Dependent measures such as performance, perceived usability, and emotion were taken. The results showed that aesthetic appeal had a positive effect on perceived usability but a negative effect on performance. The effects of aesthetic appeal on usability test outcomes were not moderated by usage domain. The results of this study imply that it may be sufficient to test dual-domain products in only one of their usage domains.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {21–30},
numpages = {10},
keywords = {product aesthetics, usage domain, usability test, user performance, perceived usability},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557241,
author = {Kong, Nicholas and Hearst, Marti A. and Agrawala, Maneesh},
title = {Extracting References between Text and Charts via Crowdsourcing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557241},
doi = {10.1145/2556288.2557241},
abstract = {News articles, reports, blog posts and academic papers often include graphical charts that serve to visually reinforce arguments presented in the text. To help readers better understand the relation between the text and the chart, we present a crowdsourcing pipeline to extract the references between them. Specifically, we give crowd workers paragraph-chart pairs and ask them to select text phrases as well as the corresponding visual marks in the chart. We then apply automated clustering and merging techniques to unify the references generated by multiple workers into a single set. Comparing the crowdsourced references to a set of gold standard references using a distance measure based on the F1 score, we find that the average distance between the raw set of references produced by a single worker and the gold standard is 0.54 (out of a max of 1.0). When we apply clustering and merging techniques the average distance between the unified set of references and the gold standard reduces to 0.39; an improvement of 27%. We conclude with an interactive document viewing application that uses the extracted references; readers can select phrases in the text and the system highlights the related marks in the chart.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {31–40},
numpages = {10},
keywords = {crowdsourcing, visualization, interactive documents},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250912,
author = {Chen, Yunan},
title = {Session Details: Stress},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250912},
doi = {10.1145/3250912},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557361,
author = {Mark, Gloria and Wang, Yiran and Niiya, Melissa},
title = {Stress and Multitasking in Everyday College Life: An Empirical Study of Online Activity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557361},
doi = {10.1145/2556288.2557361},
abstract = {While HCI has focused on multitasking with information workers, we report on multitasking among Millennials who grew up with digital media - focusing on college students. We logged computer activity and used biosensors to measure stress of 48 students for 7 days for all waking hours, in their in situ environments. We found a significant positive relationship with stress and daily time spent on computers. Stress is positively associated with the amount of multitasking. Conversely, stress is negatively associated with Facebook and social media use. Heavy multitaskers use significantly more social media and report lower positive affect than light multitaskers. Night habits affect multitasking the following day: late-nighters show longer duration of computer use and those ending their activities earlier in the day multitask less. Our study shows that college students multitask at double the frequency compared to studies of information workers. These results can inform designs for stress management of college students.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {41–50},
numpages = {10},
keywords = {computer logging, in situ study, millennial generation, multitasking, biosensors, stress, social media},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557165,
author = {Hernandez, Javier and Paredes, Pablo and Roseway, Asta and Czerwinski, Mary},
title = {Under Pressure: Sensing Stress of Computer Users},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557165},
doi = {10.1145/2556288.2557165},
abstract = {Recognizing when computer users are stressed can help reduce their frustration and prevent a large variety of negative health conditions associated with chronic stress. However, measuring stress non-invasively and continuously at work remains an open challenge. This work explores the possibility of using a pressure-sensitive keyboard and a capacitive mouse to discriminate between stressful and relaxed conditions in a laboratory study. During a 30 minute session, 24 participants performed several computerized tasks consisting of expressive writing, text transcription, and mouse clicking. During the stressful conditions, the large majority of the participants showed significantly increased typing pressure (&gt;79% of the participants) and more contact with the surface of the mouse (75% of the participants). We discuss the potential implications of this work and provide recommendations for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {51–60},
numpages = {10},
keywords = {stress measurement, capacitive mouse, affective computing, pressure-sensitive keyboard},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557243,
author = {Sun, David and Paredes, Pablo and Canny, John},
title = {MouStress: Detecting Stress from Mouse Motion},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557243},
doi = {10.1145/2556288.2557243},
abstract = {Stress causes and exacerbates many physiological and mental health problems. Routine and unobtrusive monitoring of stress would enable a variety of treatments, from break-taking to calming exercises. It may also be a valuable tool for assessing effects (frustration, difficulty) of using interfaces or applications. Custom sensing hardware is a poor option, because of the need to buy/wear/use it continuously, even before stress-related problems are evident. Here we explore stress measurement from common computer mouse operations. We use a simple model of arm-hand dynamics that captures muscle stiffness during mouse movement. We show that the within-subject mouse-derived stress measure is quite strong, even compared to concurrent physiological sensor measurements. While our study used fixed mouse tasks, the stress signal was still strong even when averaged across widely varying task geometries. We argue that mouse sensing "in the wild" may be feasible, by analyzing frequently-performed operations of particular geometries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {61–70},
numpages = {10},
keywords = {mouse interaction, stress modeling, affective interfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557038,
author = {Tan, Chiew Seng Sean and Sch\"{o}ning, Johannes and Luyten, Kris and Coninx, Karin},
title = {Investigating the Effects of Using Biofeedback as Visual Stress Indicator during Video-Mediated Collaboration},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557038},
doi = {10.1145/2556288.2557038},
abstract = {During remote video-mediated assistance, instructors often guide workers through problems and instruct them to perform unfamiliar or complex operations. However, the workers' performance might deteriorate due to stress. We argue that informing biofeedback to the instructor, can improve communication and lead to lower stress. This paper presents a thorough investigation on mental workload and stress perceived by twenty participants, paired up in an instructor-worker scenario, performing remote video-mediated tasks. The interface conditions differ in task, facial and biofeedback communication. Two self-report measures are used to assess mental workload and stress. Results show that pairs reported lower mental workload and stress when instructors are using the biofeedback as compared to using interfaces with facial view. Significant correlations were found on task performance with reducing stress (i.e. increased task engagement and decreased worry) for instructors and declining mental workload (i.e. increased performance) for workers. Our findings provide insights to advance video-mediated interfaces for remote collaborative work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {71–80},
numpages = {10},
keywords = {biofeedback, video-mediated collaboration, stress, cscw},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250913,
author = {McGookin, David},
title = {Session Details: Social Local Mobile},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250913},
doi = {10.1145/3250913},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557102,
author = {Kobsa, Alfred and Knijnenburg, Bart P. and Livshits, Benjamin},
title = {Let's Do It at My Place Instead? Attitudinal and Behavioral Study of Privacy in Client-Side Personalization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557102},
doi = {10.1145/2556288.2557102},
abstract = {Many users welcome personalized services, but are reluctant to provide the information about themselves that personalization requires. Performing personalization exclusively at the client side (e.g., on one's smartphone) may conceptually increase privacy, because no data is sent to a remote provider. But does client-side personalization (CSP) also increase users' perception of privacy?We developed a causal model of privacy attitudes and behavior in personalization, and validated it in an experiment that contrasted CSP with personalization at three remote providers: Amazon, a fictitious company, and the "Cloud". Participants gave roughly the same amount of personal data and tracking permissions in all four conditions. A structural equation modeling analysis reveals the reasons: CSP raises the fewest privacy concerns, but does not lead in terms of perceived protection nor in resulting self-anticipated satisfaction and thus privacy-related behavior. Encouragingly, we found that adding certain security features to CSP is likely to raise its perceived protection significantly. Our model predicts that CSP will then also sharply improve on all other privacy measures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {81–90},
numpages = {10},
keywords = {personalization, privacy, attitudes, structural equation modeling (sem), behaviors, client-side},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557400,
author = {Tan, Joshua and Nguyen, Khanh and Theodorides, Michael and Negr\'{o}n-Arroyo, Heidi and Thompson, Christopher and Egelman, Serge and Wagner, David},
title = {The Effect of Developer-Specified Explanations for Permission Requests on Smartphone User Behavior},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557400},
doi = {10.1145/2556288.2557400},
abstract = {In Apple's iOS 6, when an app requires access to a protected resource (e.g., location or photos), the user is prompted with a permission request that she can allow or deny. These permission request dialogs include space for developers to optionally include strings of text to explain to the user why access to the resource is needed. We examine how app developers are using this mechanism and the effect that it has on user behavior. Through an online survey of 772 smartphone users, we show that permission requests that include explanations are significantly more likely to be approved. At the same time, our analysis of 4,400 iOS apps shows that the adoption rate of this feature by developers is relatively small: around 19% of permission requests include developer-specified explanations. Finally, we surveyed 30 iOS developers to better understand why they do or do not use this feature.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {91–100},
numpages = {10},
keywords = {privacy, usability, access control, smartphones},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2557400_R50249,
author = {Edwards, John S.},
title = {Review ID:R50249 for DOI: 10.1145/2556288.2557400},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557400_R50249}
}

@inproceedings{10.1145/2556288.2557121,
author = {Patil, Sameer and Schlegel, Roman and Kapadia, Apu and Lee, Adam J.},
title = {Reflection or Action? How Feedback and Control Affect Location Sharing Decisions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557121},
doi = {10.1145/2556288.2557121},
abstract = {Owing to the ever-expanding size of social and professional networks, it is becoming cumbersome for individuals to configure information disclosure settings. We used location sharing systems to unpack the nature of discrepancies between a person's disclosure settings and contextual choices. We conducted an experience sampling study (N = 35) to examine various factors contributing to such divergence. We found that immediate feedback about disclosures without any ability to control the disclosures evoked feelings of oversharing. Moreover, deviation from specified settings did not always signal privacy violation; it was just as likely that settings prevented information disclosure considered permissible in situ. We suggest making feedback more actionable or delaying it sufficiently to avoid a knee-jerk reaction. Our findings also make the case for proactive techniques for detecting potential mismatches and recommending adjustments to disclosure settings, as well as selective control when sharing location with socially distant recipients and visiting atypical locations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {101–110},
numpages = {10},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557347,
author = {Zhang, Bo and Wu, Mu and Kang, Hyunjin and Go, Eun and Sundar, S. Shyam},
title = {Effects of Security Warnings and Instant Gratification Cues on Attitudes toward Mobile Websites},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557347},
doi = {10.1145/2556288.2557347},
abstract = {In order to address the increased privacy and security concerns raised by mobile communications, designers of mobile applications and websites have come up with a variety of warnings and appeals. While some interstitials warn about potential risk to personal information due to an untrusted security certificate, others attempt to take users' minds away from privacy concerns by making tempting, time-sensitive offers. How effective are they? We conducted an online experiment (N = 220) to find out. Our data show that both these strategies raise red flags for users - appeals to instant gratification make users more leery of the site and warnings make them perceive greater threat to personal data. Yet, users tend to reveal more information about their social media accounts when warned about an insecure site. This is probably because users process these interstitials based on cognitive heuristics triggered by them. These findings hold important implications for the design of cues in mobile interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {111–114},
numpages = {4},
keywords = {online privacy, security, information disclosure, trust, mobile interface},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557417,
author = {Shami, N. Sadat and Nichols, Jeffrey and Chen, Jilin},
title = {Social Media Participation and Performance at Work: A Longitudinal Study},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557417},
doi = {10.1145/2556288.2557417},
abstract = {The use of social media at work is gaining traction, and there is evidence to suggest that various benefits accrue from its use. Yet the relationship between using social media at work and employee performance is not clear. Through a study of 75,747 employees of a large global company over the course of 3 years, we find that some social media usage (number of forum posts, forum post length, and status update length) was positively associated with performance ratings. This study is one of the first to show the relationship among different forms of social media use and employee performance ratings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {115–118},
numpages = {4},
keywords = {social software, work, performance, social media},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250914,
author = {Rouncefield, Mark},
title = {Session Details: Coordination and Collaboration},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250914},
doi = {10.1145/3250914},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557388,
author = {Schuler, Richard P. and Grandhi, Sukeshini A. and Mayer, Julia M. and Ricken, Stephen T. and Jones, Quentin},
title = {The Doing of Doing Stuff: Understanding the Coordination of Social Group-Activities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557388},
doi = {10.1145/2556288.2557388},
abstract = {This paper explores how the adoption of mobile and social computing technologies has impacted upon the way in which we coordinate social group-activities. We present a diary study of 36 individuals that provides an overview of how group coordination is currently performed as well as the challenges people face. Our findings highlight that people primarily use open-channel communication tools (e.g., text messaging, phone calls, email) to coordinate because the alternatives are seen as either disrupting or curbing to the natural conversational processes. Yet the use of open-channel tools often results in conversational overload and a significant disparity of work between coordinating individuals. This in turn often leads to a sense of frustration and confusion about coordination details. We discuss how the findings argue for a significant shift in our thinking about the design of coordination support systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {119–128},
numpages = {10},
keywords = {common ground, social group-activity, coordination theory, mobile coordination, communication, qualitative research, language action theory, diary study, conversation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557229,
author = {Goyal, Nitesh and Leshed, Gilly and Cosley, Dan and Fussell, Susan R.},
title = {Effects of Implicit Sharing in Collaborative Analysis},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557229},
doi = {10.1145/2556288.2557229},
abstract = {When crime analysts collaborate to solve crime cases, they need to share insights in order to connect the clues, identify a pattern, and attribute the crime to the right culprit. We designed a collaborative analysis tool to explore the value of implicitly sharing insights and notes, without requiring analysts to explicitly push information or request it from each other. In an experiment, pairs of remote individuals played the role of crime analysts solving a set of serial killer crimes with both partners having some, but not all, relevant clues. When implicit sharing of notes was available, participants remembered more clues related to detecting the serial killer, and they perceived the tool as more useful compared to when implicit sharing was not available.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {129–138},
numpages = {10},
keywords = {implicit sharing, collaborative analysis, sensemaking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557158,
author = {Andr\'{e}, Paul and Kraut, Robert E. and Kittur, Aniket},
title = {Effects of Simultaneous and Sequential Work Structures on Distributed Collaborative Interdependent Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557158},
doi = {10.1145/2556288.2557158},
abstract = {Distributed online groups have great potential for generating interdependent and complex products like encyclopedia articles or product design. However, coordinating multiple group members to work together effectively while minimizing process losses remains an open challenge. We conducted an experiment comparing the effectiveness of two coordination strategies (simultaneous vs. sequential work) on a complex creative task as the number of group members increased. Our results indicate that, contrary to prior work, a sequential work structure was more effective than a simultaneous work structure as the size of the group increased. A mediation analysis suggests that social processes such as territoriality partially accounts for these results. A follow up experiment giving workers specific roles mitigated the detrimental effects of the simultaneous work structure. These results have implications for small group theory and crowdsourcing research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {139–148},
numpages = {10},
keywords = {group size, interdependence, small groups, coordination},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557126,
author = {Woodruff, Allison},
title = {Necessary, Unpleasant, and Disempowering: Reputation Management in the Internet Age},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557126},
doi = {10.1145/2556288.2557126},
abstract = {In this paper, we report on a qualitative study of how users manage their reputation online. We focus particularly on people who are bothered by content online about themselves and how they manage reputation damage and repair. We describe how users view reputation management chores as necessary but unpleasant, and how they feel disempowered to repair their online reputation. Participants were unable to identify feasible repair mechanisms and ultimately failed to resolve their problems. Given the current state of dysfunction indicated by our findings, we advocate for increased HCI research attention to this area.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {149–158},
numpages = {10},
keywords = {reputation management, privacy, online reputation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250915,
author = {Li, Yang},
title = {Session Details: Watches and Small Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250915},
doi = {10.1145/3250915},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556955,
author = {Chen, Xiang 'Anthony' and Grossman, Tovi and Wigdor, Daniel J. and Fitzmaurice, George},
title = {Duet: Exploring Joint Interactions on a Smart Phone and a Smart Watch},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556955},
doi = {10.1145/2556288.2556955},
abstract = {The emergence of smart devices (e.g., smart watches and smart eyewear) is redefining mobile interaction from the solo performance of a smart phone, to a symphony of multiple devices. In this paper, we present Duet -- an interactive system that explores a design space of interactions between a smart phone and a smart watch. Based on the devices' spatial configurations, Duet coordinates their motion and touch input, and extends their visual and tactile output to one another. This transforms the watch into an active element that enhances a wide range of phone-based interactive tasks, and enables a new class of multi-device gestures and sensing techniques. A technical evaluation shows the accuracy of these gestures and sensing techniques, and a subjective study on Duet provides insights, observations, and guidance for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {159–168},
numpages = {10},
keywords = {joint interaction, duet, smart phone, smart watch.},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2556955_R50153,
author = {UBEDA, JOSE CARLOS MORENO},
title = {Review ID:R50153 for DOI: 10.1145/2556288.2556955},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2556955_R50153}
}

@inproceedings{10.1145/2556288.2557138,
author = {Oakley, Ian and Lee, Doyoung},
title = {Interaction on the Edge: Offset Sensing for Small Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557138},
doi = {10.1145/2556288.2557138},
abstract = {The touch screen interaction paradigm, currently dominant in mobile devices, begins to fail when very small systems are considered. Specifically, "fat fingers", a term referring to the fact that users' extremities physically obstruct their view of screen content and feedback, become particularly problematic. This paper presents a novel solution for this issue based on sensing touches to the perpendicular edges of a device featuring a front-mounted screen. The use of such offset contact points ensures that both a user's fingers and the device screen remain clearly in view throughout a targeting operation. The configuration also supports a range of novel interaction scenarios based on the touch, grip and grasp patterns it affords. To explore the viability of this concept, this paper describes EdgeTouch, a small (6 cm) hardware prototype instantiating this multi-touch functionality. User studies characterizing targeting performance, typical user grasps and exploring input affordances are presented. The results show that targets of 7.5-22.5 degrees in angular size are acquired in 1.25-1.75 seconds and with accuracy rates of 3%-18%, promising results considering the small form factor of the device. Furthermore, grasps made with between two and five fingers are robustly identifiable. Finally, we characterize the types of input users envisage performing with EdgeTouch, and report occurrence rates for key interactions such as taps, holds, strokes and multi-touch and compound input. The paper concludes with a discussion of the interaction scenarios enabled by offset sensing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {169–178},
numpages = {10},
keywords = {mobile devices, touch, edge-of-device input, pointing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557239,
author = {Weigel, Martin and Mehta, Vikram and Steimle, J\"{u}rgen},
title = {More than Touch: Understanding How People Use Skin as an Input Surface for Mobile Computing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557239},
doi = {10.1145/2556288.2557239},
abstract = {This paper contributes results from an empirical study of on-skin input, an emerging technique for controlling mobile devices. Skin is fundamentally different from off-body touch surfaces, opening up a new and largely unexplored interaction space. We investigate characteristics of the various skin-specific input modalities, analyze what kinds of gestures are performed on skin, and study what are preferred input locations. Our main findings show that (1) users intuitively leverage the properties of skin for a wide range of more expressive commands than on conventional touch surfaces; (2) established multi-touch gestures can be transferred to on-skin input; (3) physically uncomfortable modalities are deliberately used for irreversible commands and expressing negative emotions; and (4) the forearm and the hand are the most preferred locations on the upper limb for on-skin input. We detail on users' mental models and contribute a first consolidated set of on-skin gestures. Our findings provide guidance for developers of future sensors as well as for designers of future applications of on-skin input.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {179–188},
numpages = {10},
keywords = {touch input, deformable surface, skin gestures, on-skin input, mobile computing, elicitation study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557258,
author = {Huang, Da-Yuan and Tsai, Ming-Chang and Tung, Ying-Chao and Tsai, Min-Lun and Yeh, Yen-Ting and Chan, Liwei and Hung, Yi-Ping and Chen, Mike Y.},
title = {TouchSense: Expanding Touchscreen Input Vocabulary Using Different Areas of Users' Finger Pads},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557258},
abstract = {We present TouchSense, which provides additional touchscreen input vocabulary by distinguishing the areas of users' finger pads contacting the touchscreen. It requires minimal touch input area and minimal movement, making it especially ideal for wearable devices such as smart watches and smart glasses. For example, users of a calculator application on a smart watch could tap normally to enter numbers, and tap with the right side of their fingers to enter the operators (e.g. , -, =). Results from two human-factor studies showed that users could tap a touchscreen with five or more distinct areas of their finger pads. Also, they were able to tap with more distinct areas closer to their fingertips. We developed a TouchSense smart watch prototype using inertial measurement sensors, and developed two example applications: a calculator and a text editor. We also collected user feedback via an explorative study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {189–192},
numpages = {4}
}

@inproceedings{10.1145/2556288.2557017,
author = {Xiao, Robert and Laput, Gierad and Harrison, Chris},
title = {Expanding the Input Expressivity of Smartwatches with Mechanical Pan, Twist, Tilt and Click},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557017},
doi = {10.1145/2556288.2557017},
abstract = {Smartwatches promise to bring enhanced convenience to common communication, creation and information retrieval tasks. Due to their prominent placement on the wrist, they must be small and otherwise unobtrusive, which limits the sophistication of interactions we can perform. This problem is particularly acute if the smartwatch relies on a touchscreen for input, as the display is small and our fingers are relatively large. In this work, we propose a complementary input approach: using the watch face as a multi-degree-of-freedom, mechanical interface. We developed a proof of concept smartwatch that supports continuous 2D panning and twist, as well as binary tilt and click. To illustrate the potential of our approach, we developed a series of example applications, many of which are cumbersome -- or even impossible -- on today's smartwatch devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {193–196},
numpages = {4},
keywords = {on-body interfaces, wearable computing, buttons, watch, touchscreens, smart clothing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250916,
author = {Hancock, Mark},
title = {Session Details: The Third Dimension},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250916},
doi = {10.1145/3250916},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557125,
author = {\v{C}opi\v{c} Pucihar, Klen and Coulton, Paul and Alexander, Jason},
title = {The Use of Surrounding Visual Context in Handheld AR: Device vs. User Perspective Rendering},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557125},
doi = {10.1145/2556288.2557125},
abstract = {The magic lens paradigm, a commonly used descriptor for handheld Augmented Reality (AR), presents the user with dual views: the augmented view (magic lens) that appears on the device, and the real view of the surroundings (what the user can see around the perimeter of the device). The augmented view is typically implemented by rendering the video captured by the rear-facing camera directly onto the device's screen. This results in dual perspectives - the real world being captured from the device's perspective rather than the user's perspective (what an observer would see looking through a transparent glass pane). These differences manifest themselves in misaligned and/or incorrectly scaled transparency resulting in the dual-view problem.This paper presents two user studies comparing (a) device-perspective and (b) fixed Point-of-View (POV) user-perspective magic lenses to analyze the effect of the dual-view problem on the use of the surrounding visual context. The results confirm that the dual-view problem, a result of dual perspective, has a significant effect on the use of information from the surrounding visual context. The study also highlights that magnification and not the dual-view problem is the key factor explaining the correlation between magic lens size and the increased intensity of the magic lens type effect. From the results, we derive design guidelines for future magic lenses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {197–206},
numpages = {10},
keywords = {ar, magic lens, dual views, dual-view, user-perspective},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557283,
author = {Schild, Jonas and LaViola, Joseph J. and Masuch, Maic},
title = {Altering Gameplay Behavior Using Stereoscopic 3D Vision-Based Video Game Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557283},
doi = {10.1145/2556288.2557283},
abstract = {We explore the potential of stereoscopic 3D (S3D) vision in offering distinct gameplay using an S3D-specific game called Deepress3D. Our game utilizes established S3D design principles for optimizing GUI design, visual comfort and game mechanics which rely on depth perception in time-pressured spatial conflicts. The game collects detailed S3D player metrics and allows players to choose between different, evenly matched strategies. We conducted a between subjects study comparing S3D and monoscopic versions of Deepress3D that examined player behavior and performance and measured user-reported data on presence, simulator sickness, and game experience. Confirming previous results, stereo users reported higher spatial presence. More importantly, for the first time, our game metrics indicate that S3D vision can measurably change player behavior depending on actual game content and level design, without necessarily affecting performance or emotional experience. These findings indicate the potential for optimizing applications for stereo users distinguishing them as a distinct group in HCI research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {207–216},
numpages = {10},
keywords = {game design, gameplay metrics, spatial presence, player behavior, simulator sickness, stereoscopic 3d, user experience},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557089,
author = {Mauderer, Michael and Conte, Simone and Nacenta, Miguel A. and Vishwanath, Dhanraj},
title = {Depth Perception with Gaze-Contingent Depth of Field},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557089},
doi = {10.1145/2556288.2557089},
abstract = {Blur in images can create the sensation of depth because it emulates an optical property of the eye; namely, the limited depth of field created by the eye's lens. When the human eye looks at an object, this object appears sharp on the retina, but objects at different distances appear blurred. Advances in gaze-tracking technologies enable us to reproduce dynamic depth of field in regular displays, providing an alternative way of conveying depth. In this paper we investigate gaze-contingent depth of field as a method to produce realistic 3D images, and analyze how effectively people can use it to perceive depth. We found that GC DOF increases subjective perceived realism and depth and can contribute to the perception of ordinal depth and distance between objects, but it is limited in its accuracy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {217–226},
numpages = {10},
keywords = {depth perception, depth-of-field, eye tracking, three-dimensional graphics and realism, gaze-contingent display, blur, depth cues},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557134,
author = {Valkov, Dimitar and Giesler, Alexander and Hinrichs, Klaus H.},
title = {Imperceptible Depth Shifts for Touch Interaction with Stereoscopic Objects},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557134},
doi = {10.1145/2556288.2557134},
abstract = {While touch technology has proven its usability for 2D interaction and has already become a standard input modality for many devices, the challenges to exploit its applicability with stereoscopically rendered content have barely been studied. In this paper we exploit the properties of the visual perception to allow users to touch stereoscopically displayed objects when the input is constrained to a 2D surface. Therefore, we have extended and generalized recent evaluations on the user's ability to discriminate small induced object shifts while reaching out to touch a virtual object, and we propose a practical interaction technique, the attracting shift technique, suitable for numerous application scenarios where shallow depth interaction is sufficient. In addition, our results indicate that slight object shifts during touch interaction make the virtual scene appear perceptually more stable compared to a static scene. As a consequence, applications have to manipulate the virtual objects to make them appear static for the user.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {227–236},
numpages = {10},
keywords = {experimentation, human factors},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250917,
author = {Subramanian, Sriram},
title = {Session Details: Audio Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250917},
doi = {10.1145/3250917},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557206,
author = {Adams, Alexander Travis and Gonzalez, Berto and Latulipe, Celine},
title = {SonicExplorer: Fluid Exploration of Audio Parameters},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557206},
doi = {10.1145/2556288.2557206},
abstract = {In digital music production, the phrase "in the box" refers to the increasing replacement of extraneous hardware devices with compatible software components. As controls move from hard to soft, we have seen an increase in usability issues for musicians and sound engineers dealing with a large number of temporal inputs and both continuous and discrete controls. We present the SonicExplorer application, which we developed to give users a new interface for exploring and manipulating audio. SonicExplorer leverages users' spatial and color perception to enhance exploration by visualizing the parameter space and providing implicit memory cues. The application also leverages bimanual input to aid in fluid exploration of multidimensional audio parameter spaces, and to minimize the need for switching between parameters.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {237–246},
numpages = {10},
keywords = {spatial memory cues, parameter exploration, color memory cues, audio, bimanual interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557000,
author = {M\"{u}ller, J\"{o}rg and Geier, Matthias and Dicke, Christina and Spors, Sascha},
title = {The BoomRoom: Mid-Air Direct Interaction with Virtual Sound Sources},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557000},
doi = {10.1145/2556288.2557000},
abstract = {In this paper we present a system that allows to "touch", grab and manipulate sounds in mid-air. Further, arbitrary objects can seem to emit sound. We use spatial sound reproduction for sound rendering and computer vision for tracking. Using our approach, sounds can be heard from anywhere in the room and always appear to originate from the same (possibly moving) position, regardless of the listener's position. We demonstrate that direct "touch" interaction with sound is an interesting alternative to indirect interaction mediated through controllers or visual interfaces. We show that sound localization is surprisingly accurate (11.5 cm), even in the presence of distractors. We propose to leverage the ventriloquist effect to further increase localization accuracy. Finally, we demonstrate how affordances of real objects can create synergies of auditory and visual feedback. As an application of the system, we built a spatial music mixing room.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {247–256},
numpages = {10},
keywords = {mid-air, spatial sound reproduction, gestural interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557253,
author = {Bryan, Nicholas J. and Mysore, Gautham J. and Wang, Ge},
title = {ISSE: An Interactive Source Separation Editor},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557253},
doi = {10.1145/2556288.2557253},
abstract = {Traditional audio editing tools do not facilitate the task of separating a single mixture recording (e.g. pop song) into its respective sources (e.g. drums, vocal, etc.). Such ability, however, would be very useful for a wide variety of audio applications such as music remixing, audio denoising, and audio-based forensics. To address this issue, we present ISSE - an interactive source separation editor. ISSE is a new open-source, freely available, and cross-platform audio editing tool that enables a user to perform source separation by painting on time-frequency visualizations of sound, resulting in an interactive machine learning system. The system brings to life our previously proposed interaction paradigm and separation algorithm that learns from user-feedback to perform separation. For evaluation, we conducted user studies and compared results between inexperienced and expert users. For a variety of real-world tasks, we found that inexperienced users can achieve good separation quality with minimal instruction and expert users can achieve state-of-the-art separation quality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {257–266},
numpages = {10},
keywords = {source separation, audio interface, intelligent user interface, interactive machine learning},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557168,
author = {Marentakis, Georgios and Liepins, Rudolfs},
title = {Evaluation of Hear-through Sound Localization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557168},
doi = {10.1145/2556288.2557168},
abstract = {Listening and interacting with audio commonly relies on using earphones which limit the ability of users to perceive their auditory environment. Earphone sets that integrate miniature microphones on their exterior can, however, be used to hear-through the auditory environment. We present an evaluation study in which sound localization when wearing such a hear-through system is compared to normal earphones, open headphones and unblocked ears. Although localization performance is improved compared to open headphones, we find that it is compromised in comparison to listening without earphones because confusions of sound direction increase and localization judgment distributions are more dispersed and show a weaker correlation to the test directions. The implications of the results to human computer interaction and possible improvements to hear-through system design are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {267–270},
numpages = {4},
keywords = {hear-through systems, auditory augmented reality},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/3250918,
author = {Hazas, Mike},
title = {Session Details: Sustainability and Everyday Practices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250918},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1}
}

@inproceedings{10.1145/2556288.2557318,
author = {Normark, Maria and Tholander, Jakob},
title = {Performativity in Sustainable Interaction: The Case of Seasonal Grocery Shopping in Ecofriends},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557318},
doi = {10.1145/2556288.2557318},
abstract = {The EcoFriends application was developed as an attempt to support grocery shopping adjusted to vegetables? seasonality through a performative approach to interaction and interactive applications. The design aimed at critical reflection and inspiration among users, rather than achieving a certain kind of persuasion. This guided the practical design to be modelled around open-endedness and social voices to challenge ideas and points of view. We argue that research addressing design for interactions about value-laden concepts such as sustainable action need to find ways of supporting various knowledge discourses, by distinguishing between performative and representational technologies. The approach allowed us to identify a number of design challenges regarding interactive technology and interaction design in relation to aspects of knowledge and truth, trust, negotiation and responsibility.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {271–280},
numpages = {10},
keywords = {sustainable interaction, mobile interaction, performative design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250919,
author = {de Paula, Rogerio},
title = {Session Details: Studying Online Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250919},
doi = {10.1145/3250919},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557213,
author = {Zhu, Haiyi and Kraut, Robert E. and Kittur, Aniket},
title = {The Impact of Membership Overlap on the Survival of Online Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557213},
abstract = {If the people belong to multiple online communities, their joint membership can influence the survival of each of the communities to which they belong. Communities with many joint memberships may struggle to get enough of their members' time and attention, but find it easy to import best practices from other communities. In this paper, we study the effects of membership overlap on the survival of online communities. By analyzing the historical data of 5673 Wikia communities, we find that higher levels of membership overlap are positively associated with higher survival rates of online communities. Furthermore, we find that it is beneficial for young communities to have shared members who play a central role in other mature communities. Our contributions are two-fold. Theoretically, by examining the impact of membership overlap on the survival of online communities we identified an important mechanism underlying the success of online communities. Practically, our findings may guide community creators on how to effectively manage their members, and tool designers on how to support this task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {281–290},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557201,
author = {Matthews, Tara and Chen, Jilin and Whittaker, Steve and Pal, Aditya and Zhu, Haiyi and Badenes, Hernan and Smith, Barton},
title = {Goals and Perceived Success of Online Enterprise Communities: What is Important to Leaders &amp; Members?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557201},
doi = {10.1145/2556288.2557201},
abstract = {Online communities are successful only if they achieve their goals, but there has been little direct study of goals. We analyze novel data characterizing the goals of enterprise online communities, assessing the importance of goals for leaders, how goals influence member perceptions of community value, and how goals relate to success measures proposed in the literature. We find that most communities have multiple goals and common goals are learning, reuse of resources, collaboration, networking, influencing change, and innovation. Leaders and members agree that all of these goals are important, but their perceptions of success on goals do not align with each other, or with commonly used behavioral success measures. We conclude that simple behavioral measures and leader perceptions are not good success metrics, and propose alternatives based on specific goals members and leaders judge most important.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {291–300},
numpages = {10},
keywords = {metrics, goals, workplace, online communities, enterprise},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557348,
author = {Zhu, Haiyi and Chen, Jilin and Matthews, Tara and Pal, Aditya and Badenes, Hernan and Kraut, Robert E.},
title = {Selecting an Effective Niche: An Ecological View of the Success of Online Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557348},
doi = {10.1145/2556288.2557348},
abstract = {Online communities serve various important functions, but many fail to thrive. Research on community success has traditionally focused on internal factors. In contrast, we take an ecological view to understand how the success of a community is influenced by other communities. We measured a community's relationship with other communities - its "niche" - through four dimensions: topic overlap, shared members, content linking, and shared offline organizational affiliation. We used a mixed-method approach, combining the quantitative analysis of 9495 online enterprise communities and interviews with community members. Our results show that too little or too much overlap in topic with other communities causes a community's activity to suffer. We also show that this main result is moderated in predictable ways by whether the community shares members with, links to content in, or shares an organizational affiliation with other communities. These findings provide new insight on community success, guiding online community designers on how to effectively position their community in relation to others.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {301–310},
numpages = {10},
keywords = {online communities, workplace, success, topic overlap},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557313,
author = {Halfaker, Aaron and Geiger, R. Stuart and Terveen, Loren G.},
title = {Snuggle: Designing for Efficient Socialization and Ideological Critique},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557313},
doi = {10.1145/2556288.2557313},
abstract = {Wikipedia, the encyclopedia "anyone can edit", has become increasingly less so. Recent academic research and popular discourse illustrates the often aggressive ways newcomers are treated by veteran Wikipedians. These are complex sociotechnical issues, bound up in infrastructures based on problematic ideologies. In response, we worked with a coalition of Wikipedians to design, develop, and deploy Snuggle, a new user interface that served two critical functions: making the work of newcomer socialization more effective, and bringing visibility to instances in which Wikipedians? current practice of gatekeeping socialization breaks down. Snuggle supports positive socialization by helping mentors quickly find newcomers whose good-faith mistakes were reverted as damage. Snuggle also supports ideological critique and reflection by bringing visibility to the consequences of viewing newcomers through a lens of suspiciousness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {311–320},
numpages = {10},
keywords = {critique, activism, algorithms, design, wikipedia},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250920,
author = {Moscovich, Tomer},
title = {Session Details: Image and Animation Authoring},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250920},
doi = {10.1145/3250920},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557062,
author = {Nakajima, Makoto and Sakamoto, Daisuke and Igarashi, Takeo},
title = {Offline Painted Media for Digital Animation Authoring},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557062},
doi = {10.1145/2556288.2557062},
abstract = {We present an animation creation workflow for integrating offline physical, painted media into the digital authoring of Flash-style animations. Generally, animators create animations with standardized digital authoring software. However, the results tend to lack the individualism or atmosphere of physical media. In contrast, illustrators have skills in painting physical media but have limited experience in animation. To incorporate their skills, we present a workflow that integrates the offline painting and digital animation creation processes in a labor-saving manner. First, a user makes a rough sketch of the visual elements and defines their movements using our digital authoring software with a sketch interface. Then these images are exported to printed pages, and users can paint using offline physical media. Finally, the work is scanned and imported back into the digital content, forming a composite animation that combines digital and physical media. We present an implementation of this system to demonstrate its workflow. We also discuss the advantages of using physical media in digital animations through design evaluations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {321–330},
numpages = {10},
keywords = {workflow, animation authoring, offline painted media, creativity support tool},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557411,
author = {Mangano, Nicolas and LaToza, Thomas D. and Petre, Marian and van der Hoek, Andr\'{e}},
title = {Supporting Informal Design with Interactive Whiteboards},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557411},
doi = {10.1145/2556288.2557411},
abstract = {Whiteboards serve an important role in supporting informal design, providing a fluid and flexible medium for collaborative design. Interactive whiteboards offer the potential for enhanced support for manipulating content, managing sketches, and distributed work, but little is known about how this support affects the practice of informal design. To understand the opportunities and challenges, we first conducted a literature review, identifying 14 behaviors that occur during informal design. We then designed an interactive whiteboard system to support all of these behaviors and deployed the system to three groups of designers. Through usage logs and interviews, we examined the effects of interactivity on whiteboard use across a wide spectrum of design behaviors, identifying ways in which interactive whiteboards support the practices used in physical whiteboards and where they enable designers to work more effectively.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {331–340},
numpages = {10},
keywords = {informal design, design, sketching, interactive whiteboard},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557327,
author = {Benjamin, William and Chandrasegaran, Senthil and Ramanujan, Devarajan and Elmqvist, Niklas and Vishwanathan, SVN and Ramani, Karthik},
title = {Juxtapoze: Supporting Serendipity and Creative Expression in Clipart Compositions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557327},
doi = {10.1145/2556288.2557327},
abstract = {Juxtapoze is a clipart composition workflow that supports creative expression and serendipitous discoveries in the shape domain. We achieve creative expression by supporting a workflow of searching, editing, and composing: the user queries the shape database using strokes, selects the desired search result, and finally modifies the selected image before composing it into the overall drawing. Serendipitous discovery of shapes is facilitated by allowing multiple exploration channels, such as doodles, shape filtering, and relaxed search. Results from a qualitative evaluation show that Juxtapoze makes the process of creating image compositions enjoyable and supports creative expression and serendipity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {341–350},
numpages = {10},
keywords = {sketching, creative expression, shape search, clipart composition, serendipity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556987,
author = {Kazi, Rubaiat Habib and Chevalier, Fanny and Grossman, Tovi and Zhao, Shengdong and Fitzmaurice, George},
title = {Draco: Bringing Life to Illustrations with Kinetic Textures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556987},
doi = {10.1145/2556288.2556987},
abstract = {We present Draco, a sketch-based interface that allows artists and casual users alike to add a rich set of animation effects to their drawings, seemingly bringing illustrations to life. While previous systems have introduced sketch-based animations for individual objects, our contribution is a unified framework of motion controls that allows users to seamlessly add coordinated motions to object collections. We propose a framework built around kinetic textures, which provide continuous animation effects while preserving the unique timeless nature of still illustrations. This enables many dynamic effects difficult or not possible with previous sketch-based tools, such as a school of fish swimming, tree leaves blowing in the wind, or water rippling in a pond. We describe our implementation and illustrate the repertoire of animation effects it supports. A user study with professional animators and casual users demonstrates the variety of animations, applications and creative possibilities our tool provides.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {351–360},
numpages = {10},
keywords = {direct manipulation, sketching, kinetic textures, animation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250921,
author = {Gutwin, Carl},
title = {Session Details: Studying and Designing Gameplay},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250921},
doi = {10.1145/3250921},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557317,
author = {Kriglstein, Simone and Wallner, G\"{u}nter and Pohl, Margit},
title = {A User Study of Different Gameplay Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557317},
doi = {10.1145/2556288.2557317},
abstract = {With the rising interest in multiplayer gaming, gameplay statistics have become an increasingly important aspect of the overall game experience for many players. As a part of this trend, visualizations have gained great popularity among players, in particular heatmaps since they allow them to reenact the course of a game and to develop new strategies. In this paper we report results of a user study conducted with 29 players (i) to investigate how players use heatmaps and two further graphical representations that use clustering algorithms to interpret gameplay and (ii) to assess the three representations in regard to time efficiency, correctness, suitability, and player preference. Our results show that heatmaps were mainly used to detect hot spots while the cluster representations proved useful to compare variables, allowing the players to uncover relationships between them and in turn allowing a deeper insight into the gameplay data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {361–370},
numpages = {10},
keywords = {heatmap, visualization, clustering, evaluation, games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557345,
author = {Cairns, Paul and Li, Jing and Wang, Wendy and Nordin, A. Imran},
title = {The Influence of Controllers on Immersion in Mobile Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557345},
doi = {10.1145/2556288.2557345},
abstract = {The controls for digital games understandably have an important part in building up the gaming experiences that people have. Whilst there is substantial work on innovative controllers for consoles, like the XBox Kinect, relatively little has been done to understand the effect of the different control mechanisms that can be used to play games on mobile devices like smartphones. A well-defined framework of naturalness has emerged as potentially useful concept in area of game controllers. This paper reports two experiments that look at how the naturalness of the game controls influences the experience of immersion in mobile games. It seems that where there is an a prior natural mapping, this will improve immersion in the game but in the absence of a prior mapping, naturalness alone is not sufficient to account for immersion. This opens up the need for a more thorough investigation of this area.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {371–380},
numpages = {10},
keywords = {immersion, mobile games, natural mappings, gaming experience, controllers},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557326,
author = {Tan, Chek Tien and Leong, Tuck Wah and Shen, Songjia},
title = {Combining Think-Aloud and Physiological Data to Understand Video Game Experiences},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557326},
doi = {10.1145/2556288.2557326},
abstract = {Think-aloud protocols are commonly used to evaluate player experiences of video games but suffer from a lack of objectivity and timeliness. On the other hand, quantitative captures of physiological data are effective; providing detailed, unbiased and continuous responses of players, but lack contexts for interpretation. This paper documents how both approaches could be used together in practice by comparing video-cued retrospective think-aloud data and physiological data collected during a video gameplay experiment. We observed that many interesting physiological responses did not feature in participants' think-aloud data, and conversely, reports of interesting experiences were sometimes not observed in the collected physiological data. Through learnings from our experiment, we present some of the challenges when combining these approaches and offer some guidelines as to how qualitative and quantitative data can be used together to gain deeper insights into player experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {381–390},
numpages = {10},
keywords = {psychophysiology, game user research, think-aloud},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557104,
author = {Goh, Wooi Boon and Chen, Ming and Trinh, Cuong Hong and Tan, Jacquelyn and Shou, Wei},
title = {The MOY Framework for Collaborative Play Design in Integrated Shared and Private Interactive Spaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557104},
doi = {10.1145/2556288.2557104},
abstract = {A novel Mine-Ours-Yours (MOY) interaction design framework is proposed for designing collaborative play activities in environments that combine both private and shared interactive spaces. A collaborative game designed on a system that integrates multiple mobile devices with an interactive tabletop was presented to demonstrate the implementation of the proposed MOY framework. Observations from field trials involving two groups of children were used to summarize the collaborative behaviors that are likely to be observed under the different interaction design configurations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {391–400},
numpages = {10},
keywords = {collaborative play, cooperative design patterns, interaction design, multi-touch interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250922,
author = {Oakley, Ian},
title = {Session Details: Force Input and Haptic Feedback},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250922},
doi = {10.1145/3250922},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557260,
author = {McLachlan, Ross and Boland, Daniel and Brewster, Stephen},
title = {Transient and Transitional States: Pressure as an Auxiliary Input Modality for Bimanual Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557260},
doi = {10.1145/2556288.2557260},
abstract = {A novel investigation of pressure input is presented where it is characterised as a transient modality, one that has a natural inverse, bounce-back and a state that only persists during interaction. Three empirical studies are described that evaluate pressure for use as a non-dominant hand input modality, where the ability to target and maintain pressure while simultaneously performing a dominant-hand targeting task is investigated. Pressure accuracy was high (93%) and the impact on dominant-hand targeting was low. Mean pressure accuracy when selecting targets by releasing pressure was also high (89%) as was selecting targets by applying pressure from a non-zero starting point (94.4%). The ability to accurately maintain pressure over time was better with larger target pressures. Example applications and design guidelines are presented that enable designers to exploit the transient properties of pressure input in interaction design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {401–410},
numpages = {10},
keywords = {pressure input, transience, bimanual interaction, non-dominant hand},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557252,
author = {Hachisu, Taku and Fukumoto, Masaaki},
title = {VacuumTouch: Attractive Force Feedback Interface for Haptic Interactive Surface Using Air Suction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557252},
doi = {10.1145/2556288.2557252},
abstract = {We present VacuumTouch, a novel haptic interface architecture for touch screens that provides attractive force feedback to the user's finger. VacuumTouch consists of an air pump and solenoid air valves that connect to the surface of the touch screen and suck the air above the surface where the user's finger makes contact. VacuumTouch does not require the user to hold or attach additional devices to provide the attractive force, which allows for easy interaction with the surface. This paper introduces the implementation of the VacuumTouch architecture and some applications for enhancement of the graphical user interface, namely a suction button, a suction slider, and a suction dial. The quantitative evaluation was conducted with the suction dial and showed that the attractive force provided by VacuumTouch improved the performance of the dial menu interface and its potential effects. At the end of this paper, we discuss the current prototype's advantages and limitations, as well as possible improvements and potential capabilities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {411–420},
numpages = {10},
keywords = {interactive surface, haptic interface, air suction, vacuumtouch, attractive force},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557019,
author = {Pedersen, Esben Warming and Hornb\ae{}k, Kasper},
title = {Expressive Touch: Studying Tapping Force on Tabletops},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557019},
doi = {10.1145/2556288.2557019},
abstract = {This paper investigates users' ability to perform force-sensitive tapping and explores its potential as an input modality in touch-based systems. We study force-sensitive tapping using Expressive Touch, a tabletop interface that infers tapping force from the sound waves created by the users' finger upon impact. The first part of the paper describes the implementation details of Expressive Touch and shows how existing tabletop interfaces can be augmented to reliably detect tapping force across the entire surface. The second part of the paper reports on the results of three studies of force-sensitive tapping. First, we use a classic psychophysic task to gain insights into participants' perception of tapping force (Study 1). Results show that although participants tap with different absolute tapping forces, they have a similar perception of relative tapping force. Second, we investigate participants' ability to control tapping force (Study 2) and find that users can produce two force levels with 99% accuracy. For six levels of force, accuracy drops to 58%. Third, we investigate the usability of force tapping by studying participants' reactions to seven force-sensitive touch applications (Study 3).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {421–430},
numpages = {10},
keywords = {expressive touch, force, touch, tapping, tabletop computing, acoustic sensing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557146,
author = {Rendl, Christian and Greindl, Patrick and Probst, Kathrin and Behrens, Martin and Haller, Michael},
title = {Presstures: Exploring Pressure-Sensitive Multi-Touch Gestures on Trackpads},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557146},
doi = {10.1145/2556288.2557146},
abstract = {In this paper, we present Presstures, an extension to current multi-touch operations that enriches common multi-finger gestures with pressure information. By using the initially applied pressure level for implicit mode switching, a gesture can be enhanced with different functionalities to enlarge the interaction space for multi-touch. To evaluate the feasibility of our concept, we conducted an experiment, which indicates good human sensorimotor skills for performing multi-touch gestures with a few number of pressure levels and without any additional feedback. Based on the experimental results, we discuss implications for the design of pressure-sensitive multi-touch gestures, and propose application scenarios that make optimal use of our concept.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {431–434},
numpages = {4},
keywords = {pressure, pressure gestures, multi-touch gestures, force},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557040,
author = {Kangas, Jari and Akkil, Deepak and Rantala, Jussi and Isokoski, Poika and Majaranta, P\"{a}ivi and Raisamo, Roope},
title = {Gaze Gestures and Haptic Feedback in Mobile Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557040},
doi = {10.1145/2556288.2557040},
abstract = {Anticipating the emergence of gaze tracking capable mobile devices, we are investigating the use of gaze as an input modality in handheld mobile devices. We conducted a study of combining gaze gestures with vibrotactile feedback. Gaze gestures were used as an input method in a mobile device and vibrotactile feedback as a new alternative way to give confirmation of interaction events. Our results show that vibrotactile feedback significantly improved the use of gaze gestures. The tasks were completed faster and rated easier and more comfortable when vibrotactile feedback was provided.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {435–438},
numpages = {4},
keywords = {haptic feedback, gaze interaction, gaze tracking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250923,
author = {Tscheligi, Manfred},
title = {Session Details: Hackerspaces, Making and Breaking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250923},
doi = {10.1145/3250923},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557132,
author = {Lindtner, Silvia and Hertz, Garnet D. and Dourish, Paul},
title = {Emerging Sites of HCI Innovation: Hackerspaces, Hardware Startups &amp; Incubators},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557132},
doi = {10.1145/2556288.2557132},
abstract = {In this paper, we discuss how a flourishing scene of DIY makers is turning visions of tangible and ubiquitous computing into products. Drawing on long-term multi-sited ethnographic research and active participation in DIY making, we provide insights into the social, material, and economic processes that undergird this transition from prototypes to products. The contribution of this paper is three-fold. First, we show how DIY maker practice is illustrative of a broader "return to" and interest in physical materials. This has implications for HCI research that investigates questions of materiality. Second, we shed light on how hackerspaces and hardware start-ups are experimenting with new models of manufacturing and entrepreneurship. We argue that we have to take seriously these maker practices, not just as hobbyist or leisure practice, but as a professionalizing field functioning in parallel to research and industry labs. Finally, we end with reflections on the role of HCI researchers and designers as DIY making emerges as a site of HCI innovation. We argue that HCI is positioned to provide critical reflection, paired with a sensibility for materials, tools and design methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {439–448},
numpages = {10},
keywords = {iot, manufacturing, china, materiality, make, hackerspace, making cultures, critical making, diy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557332,
author = {Jackson, Steven J. and Kang, Laewoo},
title = {Breakdown, Obsolescence and Reuse: HCI and the Art of Repair},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557332},
doi = {10.1145/2556288.2557332},
abstract = {This paper describes an integrated program of theoretical, ethnographic, and building work meant to explore post-humanist alternatives to questions around HCI creativity and design. We review recent theories in the humanities, social sciences, and HCI that argue for different ways of framing the relationship between human agents and the object world around them. We then describe a program of ethnographic work with artists who feature found and broken technologies as central methods and topics of work. Finally, we describe an installation and self-study project of our own, 'Scale,' that extends these lines of analysis through collaborative acts of building with broken and discarded technologies. We argue that such integrated programs of work offer one useful model for leveraging the theoretical, ethnographic and material dimensions of HCI work; and that the distinct 'propensities' of found and broken objects can challenge and extend HCI notions of creativity and design itself.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {449–458},
numpages = {10},
keywords = {repair, ethnography, design, art, agency},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557338,
author = {Hudson, Scott E.},
title = {Printing Teddy Bears: A Technique for 3D Printing of Soft Interactive Objects},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557338},
doi = {10.1145/2556288.2557338},
abstract = {This paper considers the design, construction, and example use of a new type of 3D printer which fabricates three-dimensional objects from soft fibers (wool and wool blend yarn). This printer allows the substantial advantages of additive manufacturing techniques (including rapid turn-around prototyping of physical objects and support for high levels of customization and configuration) to be employed with a new class of material. This material is a form of loose felt formed when fibers from an incoming feed of yarn are entangled with the fibers in layers below it. The resulting objects recreate the geometric forms specified in the solid models which specify them, but are soft and flexible -- somewhat reminiscent in character to hand knitted materials. This extends 3D printing from typically hard and precise forms into a new set of forms which embody a different aesthetic of soft and imprecise objects, and provides a new capability for researchers to explore the use of this class of materials in interactive devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {459–468},
numpages = {10},
keywords = {additive manufacturing, computational crafts, interactive devices, soft materials},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557267,
author = {Murer, Martin and Jacobsson, Mattias and Skillgate, Siri and Sundstr\"{o}m, Petra},
title = {Taking Things Apart: Reaching Common Ground and Shared Material Understanding},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557267},
doi = {10.1145/2556288.2557267},
abstract = {In this note we discuss and argue about how taking things apart and disassembling can be meaningful practices in explorative design projects. In particular, we report on an explorative design exercise about taking apart an unfamiliar device. Relating to this design situation, we provide accounts for how collaborative hands-on experience can support reaching common ground and acquiring shared material understanding in an interdisciplinary design team through establishing a material brief. In the end we reflect and discuss how this may complement our practices regarding materials and interaction design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {469–472},
numpages = {4},
keywords = {material, disassembling, exploration, artifacts},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557221,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Toombs, Austin},
title = {"now That's Definitely a Proper Hack": Self-Made Tools in Hackerspaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557221},
doi = {10.1145/2556288.2557221},
abstract = {Cultures of making - that is, social practices of hacking, DIY, tinkering, repair, and craft - continue to rise in prominence, and design researchers have taken note, because of their implications for sustainability, democratization, and alternative models of innovation, design, participation, and education. We contribute to this agenda by exploring our findings on self-made tools, which we encountered in a 9-month ethnographic study of a hackerspace. Self-made tools embody issues raised in two discourses that are of interest in design research on making: tools and adhocism. In this paper, we explore ways that tools and adhocism interface with each other, using our findings as a material to think with. We find that this juxtaposition of concepts helps explain a highly generative creative practice - tool-making - within the hackerspace we studied.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {473–476},
numpages = {4},
keywords = {hackerspaces, ad hoc, design, hci, tools, maker culture, hackers},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250924,
author = {Busse, Daniela},
title = {Session Details: Activity Recognition},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250924},
doi = {10.1145/3250924},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557220,
author = {Min, Jun-Ki and Doryab, Afsaneh and Wiese, Jason and Amini, Shahriyar and Zimmerman, John and Hong, Jason I.},
title = {Toss 'n' Turn: Smartphone as Sleep and Sleep Quality Detector},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557220},
doi = {10.1145/2556288.2557220},
abstract = {The rapid adoption of smartphones along with a growing habit for using these devices as alarm clocks presents an opportunity to use this device as a sleep detector. This adds value to UbiComp and personal informatics in terms of user context and new performance data to collect and visualize, and it benefits healthcare as sleep is correlated with many health issues. To assess this opportunity, we collected one month of phone sensor and sleep diary entries from 27 people who have a variety of sleep contexts. We used this data to construct models that detect sleep and wake states, daily sleep quality, and global sleep quality. Our system classifies sleep state with 93.06% accuracy, daily sleep quality with 83.97% accuracy, and overall sleep quality with 81.48% accuracy. Individual models performed better than generally trained models, where the individual models require 3 days of ground truth data and 3 weeks of ground truth data to perform well on detecting sleep and sleep quality, respectively. Finally, the features of noise and movement were useful to infer sleep quality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {477–486},
numpages = {10},
keywords = {sleep, smartphone, machine learning, sensors},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557383,
author = {Fritz, Thomas and Huang, Elaine M. and Murphy, Gail C. and Zimmermann, Thomas},
title = {Persuasive Technology in the Real World: A Study of Long-Term Use of Activity Sensing Devices for Fitness},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557383},
doi = {10.1145/2556288.2557383},
abstract = {Persuasive technology to motivate healthy behavior is a growing area of research within HCI and ubiquitous computing. The emergence of commercial wearable devices for tracking health- and fitness-related activities arguably represents the first widespread adoption of dedicated ubiquitous persuasive technology. The recent ubiquity of commercial systems allows us to learn about their value and use in truly "in the wild" contexts and understand how practices evolve over long-term, naturalistic use. We present a study with 30 participants who had adopted wearable activity-tracking devices of their own volition and had continued to use them for between 3 and 54 months. The findings, which both support and contrast with those of previous research, paint a picture of the evolving benefits and practices surrounding these emerging technologies over long periods of use. They also serve as the basis for design implications for personal informatics technologies for long-term health and fitness support.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {487–496},
numpages = {10},
keywords = {persuasive technology, behavior change, personal informatics, health, activity monitoring, wearable sensing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557147,
author = {Y\"{u}r\"{u}ten, Onur and Zhang, Jiyong and Pu, Pearl H.Z.},
title = {Predictors of Life Satisfaction Based on Daily Activities from Mobile Sensor Data},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557147},
doi = {10.1145/2556288.2557147},
abstract = {In recent years much research work has been dedicated to detecting user activity patterns from sensor data such as location, movement and proximity. However, how daily activities are correlated to people's happiness (such as their satisfaction from work and social lives) is not well explored. In this work, we propose an approach to investigate the relationship between users' daily activity patterns and their life satisfaction level. From a well-known longitudinal dataset collected by mobile devices, we extract various activity features through location and proximity information, and compute the entropies of these data to capture the regularities of the behavioral patterns of the participants. We then perform component analysis and structural equation modeling to identify key behavior contributors to self-reported satisfaction scores. Our results show that our analytical procedure can identify meaningful assumptions of causality between activities and satisfaction. Particularly, keeping regularity in daily activities can significantly improve the life satisfaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {497–500},
numpages = {4},
keywords = {handheld devices and mobile computing, ubiquitous computing/smart environments, analysis methods},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250925,
author = {Schoenebeck, Sarita Yardi},
title = {Session Details: Managing Income},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250925},
doi = {10.1145/3250925},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556961,
author = {Vines, John and Dunphy, Paul and Monk, Andrew},
title = {Pay or Delay: The Role of Technology When Managing a Low Income},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556961},
doi = {10.1145/2556288.2556961},
abstract = {This paper reports on a qualitative study of 38 low-income individuals living in the North East of England. The participants' experiences of money, banking and the role digital technology plays in their financial practices were identified through semi-structured interviews in people's homes and group workshops. A grounded theory analysis of these data characterises how technology both helped and hindered participants to keep close control of their finances. These findings suggest design opportunities for future digital banking technologies that extend the already sophisticated practices of individuals managing a low income, focusing on: delaying, prioritising, planning, watching, and hiding monetary transactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {501–510},
numpages = {10},
keywords = {low income, banking technologies, financial inclusion, qualitative study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557358,
author = {Smith-Clarke, Christopher and Mashhadi, Afra and Capra, Licia},
title = {Poverty on the Cheap: Estimating Poverty Maps Using Aggregated Mobile Communication Networks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557358},
doi = {10.1145/2556288.2557358},
abstract = {Governments and other organisations often rely on data collected by household surveys and censuses to identify areas in most need of regeneration and development projects. However, due to the high cost associated with the data collection process, many developing countries conduct such surveys very infrequently and include only a rather small sample of the population, thus failing to accurately capture the current socio-economic status of the country's population. In this paper, we address this problem by means of a methodology that relies on an alternative source of data from which to derive up to date poverty indicators, at a very fine level of spatio-temporal granularity. Taking two developing countries as examples, we show how to analyse the aggregated call detail records of mobile phone subscribers and extract features that are strongly correlated with poverty indexes currently derived from census data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {511–520},
numpages = {10},
keywords = {ict4d, socio-economics, call detail records, data4d},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556975,
author = {Kaye, Joseph Jofish and McCuistion, Mary and Gulotta, Rebecca and Shamma, David A.},
title = {Money Talks: Tracking Personal Finances},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556975},
doi = {10.1145/2556288.2556975},
abstract = {How do people keep track of their money? In this paper we present a preliminary scoping study of how 14 individuals in the San Francisco Bay Area earn, save, spend and understand money and their personal and family finances. We describe the practices we developed for exploring the sensitive topic of money, and then discuss three sets of findings. The first is the emotional component of the relationship people have with their finances. Second, we discuss the tools and processes people used to keep track of their financial situation. Finally we discuss how people account for the unknown and unpredictable nature of the future through their financial decisions. We conclude by discussing the future of studies of money and finance in HCI, and reflect on the opportunities for improving tools to aid people in managing and planning their finances.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {521–530},
numpages = {10},
keywords = {finance, interviews, banking, money},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557123,
author = {Dillahunt, Tawanna R.},
title = {Fostering Social Capital in Economically Distressed Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557123},
doi = {10.1145/2556288.2557123},
abstract = {Past Information and Communication Technology (ICT) literature suggests that engaging in meaningful activities with ICTs may be related to socio-economic security, social inclusion, empowerment, and increased social capital. However, we identify a pervasive lack of understanding in existing literature, which raises an important research question: how can we build social capital where little social capital exists? We conducted a preliminary study to explore whether and if so, how, individuals in an economically distressed population with limited social capital use technologies to increase social capital and achieve socio-economic security. We contribute details about barriers affecting social capital (e.g., difficulties finding and making the right connections and an overall lack of trust within communities). We also suggest ways in which ICTs can assist populations that could benefit most from increased social capital and economic security.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {531–540},
numpages = {10},
keywords = {economic mobility, sustainability, social capital, ict4d},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250926,
author = {Isenberg, Petra},
title = {Session Details: Designing and Understanding Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250926},
doi = {10.1145/3250926},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557408,
author = {Setlur, Vidya and Mackinlay, Jock D.},
title = {Automatic Generation of Semantic Icon Encodings for Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557408},
doi = {10.1145/2556288.2557408},
abstract = {Authors use icon encodings to indicate the semantics of categorical information in visualizations. The default icon libraries found in visualization tools often do not match the semantics of the data. Users often manually search for or create icons that are more semantically meaningful. This process can hinder the flow of visual analysis, especially when the amount of data is large, leading to a suboptimal user experience. We propose a technique for automatically generating semantically relevant icon encodings for categorical dimensions of data points. The algorithm employs natural language processing in order to find relevant imagery from the Internet. We evaluate our approach on Mechanical Turk by generating large libraries of icons using Tableau Public workbooks that represent real analytical effort by people out in the world. Our results show that the automatic algorithm does nearly as well as the manually created icons, and particularly has higher user satisfaction for larger cardinalities of data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {541–550},
numpages = {10},
keywords = {visualization, natural language processing (nlp), image retrieval., icon encodings},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557200,
author = {Albers, Danielle and Correll, Michael and Gleicher, Michael},
title = {Task-Driven Evaluation of Aggregation in Time Series Visualization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557200},
doi = {10.1145/2556288.2557200},
abstract = {Many visualization tasks require the viewer to make judgments about aggregate properties of data. Recent work has shown that viewers can perform such tasks effectively, for example to efficiently compare the maximums or means over ranges of data. However, this work also shows that such effectiveness depends on the designs of the displays. In this paper, we explore this relationship between aggregation task and visualization design to provide guidance on matching tasks with designs. We combine prior results from perceptual science and graphical perception to suggest a set of design variables that influence performance on various aggregate comparison tasks. We describe how choices in these variables can lead to designs that are matched to particular tasks. We use these variables to assess a set of eight different designs, predicting how they will support a set of six aggregate time series comparison tasks. A crowd-sourced evaluation confirms these predictions. These results not only provide evidence for how the specific visualizations support various tasks, but also suggest using the identified design variables as a tool for designing visualizations well suited for various types of tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {551–560},
numpages = {10},
keywords = {perceptual study, visualization design, time series visualization, information visualization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557195,
author = {Glueck, Michael and Khan, Azam and Wigdor, Daniel J.},
title = {Dive in! Enabling Progressive Loading for Real-Time Navigation of Data Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557195},
doi = {10.1145/2556288.2557195},
abstract = {We introduce Splash, a framework reducing development overhead for both data curators and visualization developers of client-server visualization systems. Splash streamlines the process of creating a multiple level-of-detail version of the data and facilitates progressive data download, thereby enabling real-time, on-demand navigation with existing visualization toolkits. As a result, system responsiveness is increased and the user experience is improved. We demonstrate the benefit of progressive loading for user interaction on slower networks. Additionally, case study evaluations of Splash with real-world data curators suggest that Splash supports iterative refinement of visualizations and promotes the use of exploratory data analysis.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {561–570},
numpages = {10},
keywords = {data visualization, client-server, real-time interaction, progressive-loading},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557131,
author = {Ferreira, Nivan and Fisher, Danyel and Konig, Arnd Christian},
title = {Sample-Oriented Task-Driven Visualizations: Allowing Users to Make Better, More Confident Decisions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557131},
abstract = {We often use datasets that reflect samples, but many visualization tools treat data as full populations. Uncertain visualizations are good at representing data distributions emerging from samples, but are more limited in allowing users to carry out decision tasks. This is because tasks that are simple on a traditional chart (e.g. "compare two bars") become a complex probabilistic task on a chart with uncertainty. We present guidelines for creating visual annotations for solving tasks with uncertainty, and an implementation that addresses five core tasks on a bar chart. A preliminary user study shows promising results: that users have a justified confidence in their answers with our system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {571–580},
numpages = {10}
}

@inproceedings{10.1145/3250927,
author = {Muller, Michael},
title = {Session Details: Crowdfunding and Crowd Storage},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250927},
doi = {10.1145/3250927},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557110,
author = {Greenberg, Michael D. and Gerber, Elizabeth M.},
title = {Learning to Fail: Experiencing Public Failure Online through Crowdfunding},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557110},
doi = {10.1145/2556288.2557110},
abstract = {Online crowdfunding platforms like Kickstarter are gaining attention among novice creatives as an effective platform for funding their ventures and engaging in creative work with others. However, a focus on financial success of crowdfunding has obscured the fact that over 58% of crowdfunding projects fail to achieve their funding goals. This population of failed creatives however, gives us an audience to study public creative failure in an online environment. We draw inspiration from work in organizational behavior on failure, and work in Human Computer Interaction (HCI) on online behavior, to study online public failure. Using a mixed-methods approach with data scraped from Kickstarter and interview data with failed crowdfunding project creators, we answer the following question: What do project creators on crowdfunding platforms learn and change through the process of failing? We find that creators who relaunch their projects succeed 43% of the time, and that most individuals find failure to be a positive experience. We conclude the paper with a series of design implications for future creative platforms where public failure is part of the creative process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {581–590},
numpages = {10},
keywords = {feedback, failure, crowdsourcing, crowdfunding},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557045,
author = {Xu, Anbang and Yang, Xiao and Rao, Huaming and Fu, Wai-Tat and Huang, Shih-Wen and Bailey, Brian P.},
title = {Show Me the Money! An Analysis of Project Updates during Crowdfunding Campaigns},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557045},
doi = {10.1145/2556288.2557045},
abstract = {Hundreds of thousands of crowdfunding campaigns have been launched, but more than half of them have failed. To better understand the factors affecting campaign outcomes, this paper targets the content and usage patterns of project updates -- communications intended to keep potential funders aware of a campaign's progress. We analyzed the content and usage patterns of a large corpus of project updates on Kickstarter, one of the largest crowdfunding platforms. Using semantic analysis techniques, we derived a taxonomy of the types of project updates created during campaigns, and found discrepancies between the design intent of a project update and the various uses in practice (e.g. social promotion). The analysis also showed that specific uses of updates had stronger associations with campaign success than the project's description. Design implications were formulated from the results to help designers better support various uses of updates in crowdfunding campaigns.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {591–600},
numpages = {10},
keywords = {crowdsouring, updates, crowdfunding},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557159,
author = {Bigham, Jeffrey P. and Lasecki, Walter S.},
title = {Crowd Storage: Storing Information on Existing Memories},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557159},
doi = {10.1145/2556288.2557159},
abstract = {This paper introduces the concept of crowd storage, the idea that digital files can be stored and retrieved later from the memories of people in the crowd. Similar to human memory, crowd storage is ephemeral, which means that storage is temporary and the quality of the stored information degrades over time. Crowd storage may be preferred over storing information directly in the cloud, or when it is desirable for information to degrade inline with normal human memories. To explore and validate this idea, we created WeStore, a system that stores and then later retrieves digital files in the existing memories of crowd workers. WeStore does not store information directly, but rather encrypts the files using details of the existing memories elicited from individuals within the crowd as cryptographic keys. The fidelity of the retrieved information is tied to how well the crowd remembers the details of the memories they provided. We demonstrate that crowd storage is feasible using an existing crowd marketplace (Amazon Mechanical Turk), explore design considerations important for building systems that use crowd storage, and outline ideas for future research in this area.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {601–604},
numpages = {4},
keywords = {memory, crowdsourcing, storage},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250928,
author = {Takeuchi, Yuichiro},
title = {Session Details: Novel Approaches to Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250928},
doi = {10.1145/3250928},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557250,
author = {Hazzard, Adrian and Benford, Steve and Burnett, Gary},
title = {Walk This Way: Musically Guided Walking Experiences},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557250},
doi = {10.1145/2556288.2557250},
abstract = {Musical soundtracks will be important features of future locative experiences from tours to games. We present a study designed to uncover potential relationships between higher-level musical structures such as harmony, melody, timbre, dynamic intensity and punctuation and users' spatial experiences. We observed twenty-two participants exploring an open field while listening to four contrasting musical compositions, and then interviewed them afterwards. We report their different approaches to interpreting the music, strategies for mapping zones, choice of stopping destinations, and their awareness and appreciation of the music. Our discussion of these findings in relation to the literature leads us to propose six initial principles to guide the composition of mobile and locative soundtracks, and also to articulate a three-layer framework of global, regional and local attachment to help guide the attachment of musical features to different regions within a locative experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {605–614},
numpages = {10},
keywords = {attachment, location based experiences, design, conceptual metaphors, music composition},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557021,
author = {Heller, Florian and Kr\"{a}mer, Aaron and Borchers, Jan},
title = {Simplifying Orientation Measurement for Mobile Audio Augmented Reality Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557021},
doi = {10.1145/2556288.2557021},
abstract = {Audio augmented reality systems overlay the physical world with a virtual audio space. Today's smartphones provide enough processing power to create the impression of virtual sound sources being located in the real world. To achieve this, information about the user's location and orientation is necessary which requires additional hardware. In a real-world installation, however, we observed that instead of turning their head to localize sounds, users tend to turn their entire body. Therefore, we suggest to simply measure orientation of the user's body - or even just the mobile device she is holding - to generate the spatial audio.To verify this approach, we present two studies: Our first study in examines the user's head, body, and mobile device orientation when moving through an audio augmented reality system in a lab setting. Our second study analyzes the user experience in a real-world installation when using head, body, or device orientation to control the audio spatialization. We found that when navigating close to sound sources head tracking is necessary, but that it can potentially be replaced by device tracking in larger or more explorative usage scenarios. These findings help reduce the technical complexity of mobile audio augmented reality systems (MAARS), and enable their wider dissemination as mobile software-only apps.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {615–624},
numpages = {10},
keywords = {binaural rendering, mobile devices, audio augmented reality, presence, spatial audio, orientation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557259,
author = {Fosh, Lesley and Benford, Steve and Reeves, Stuart and Koleva, Boriana},
title = {Gifting Personal Interpretations in Galleries},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557259},
doi = {10.1145/2556288.2557259},
abstract = {The designers of mobile guides for museums and galleries face three major challenges: fostering rich interpretation, delivering deep personalization, and enabling a coherent social visit. We propose an approach to tackling all three simultaneously by inviting visitors to design an interpretation that is specifically tailored for a friend or loved one that they then experience together. We describe a trial of this approach at a contemporary art gallery, revealing how visitors designed personal and sometimes provocative experiences for people they knew well. We reveal how pairs of visitors negotiated these experiences together, showing how our approach could deliver intense experiences for both, but also required them to manage social risk. By interpreting our findings through the lens of 'gift giving' we shed new light on ongoing explorations of interpretation, personalization and social visiting within HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {625–634},
numpages = {10},
keywords = {museums, personalization, collaboration, visiting, interpretation, galleries, mobile guides, gifting},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557270,
author = {Wein, Leonard},
title = {Visual Recognition in Museum Guide Apps: Do Visitors Want It?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557270},
doi = {10.1145/2556288.2557270},
abstract = {In this paper, visual recognition (VisRec) is evaluated as a method to access background information on artworks in mobile museum guide applications (apps) by means of a field experiment. While museums and previous research have explored technical aspects, it is unclear whether visitors actually want to use VisRec. A prototype featuring VisRec, QR codes and number codes was developed and assessed with a usability study in two museums (N=89). The prototype confirms the efficacy of the recently introduced ORB-algorithm for VisRec. Compared to previous literature, the results highlight the context-dependency of perceived usability and variability in the importance of usability factors. The results reveal a clear preference for VisRec among participants (53%); only 14% preferred QR codes. Ease of use, enjoyability and distance are identified as the main factors. This provides strong evidence to further explore the potential of VisRec to improve visitors' museum experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {635–638},
numpages = {4},
keywords = {museum guide, mobile applications, visual recognition, usability test, access methods},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556994,
author = {Robinson, Simon and Pearson, Jennifer S. and Jones, Matt},
title = {A Billion Signposts: Repurposing Barcodes for Indoor Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556994},
doi = {10.1145/2556288.2556994},
abstract = {Barcodes are all around us--on books, groceries and other products--but these everyday markers are typically used for a single focused purpose. In this paper we explore the concept of "piggybacking" on ubiquitous markers to facilitate indoor navigation. Our initial probe--BookMark--allows library visitors to scan any nearby book to provide a custom map to the location of a desired item. In contrast to previous indoor navigation systems, our approach repurposes existing markers on physical items that are already in the navigation space, meaning that no additional infrastructure is required. We evaluated the BookMark probe in a large university library, showing its potential with real library users. In addition, we illustrate how the general technique shows further potential in other similar barcode-rich environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {639–642},
numpages = {4},
keywords = {piggybacking, indoor navigation, reuse, libraries, barcodes},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250929,
author = {Kjeldskov, Jesper},
title = {Session Details: Interfaces for Care and Support},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250929},
doi = {10.1145/3250929},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557103,
author = {Matthews, Mark and Gay, Geri and Doherty, Gavin},
title = {Taking Part: Role-Play in the Design of Therapeutic Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557103},
doi = {10.1145/2556288.2557103},
abstract = {Gaining an understanding of user needs is a central component of HCI design approaches such as user-centred design and participatory design. In some settings, such as mental health care, access to end-users is often constrained. This is a particular difficulty given that the experience of those with mental illness can be difficult for researchers to understand, and is further complicated by its associated stigma. In addition, the therapeutic setting is outside the common experience of most people and protected from outside intrusion. Although role-play has been used in varied ways in HCI, rarely has it been defined with sufficient clarity to enable others to deploy it in a nuanced manner. We argue that role-play is particularly suited for use in mental healthcare settings and, when used judiciously, can address some of the difficulties associated with working in this setting. This paper details a range of role-play formats appropriated from therapeutic role-play, drawing upon the HCI and mental health literature, therapist input and our experience of using role-play for a number of purposes at different stages of the development process. We consider how and why role-play can be used to generate empathy, gain understanding of therapy, provide feedback on designs before clinical use and help train therapists in using technology in the treatment room.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {643–652},
numpages = {10},
keywords = {role-play, mental health, healthcare, design, therapy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557297,
author = {Adams, Phil and Baumer, Eric PS and Gay, Geri},
title = {Staccato Social Support in Mobile Health Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557297},
doi = {10.1145/2556288.2557297},
abstract = {Social support plays an important role in health systems. While significant work has explored the role of social support in CMC environments, less analysis has considered social support in mobile health systems. This paper describes socially supportive messages in VERA, a mobile application for sharing health decisions and behaviors. The short and bursty interactions in social awareness streams [36] afford a particular style of social support, for which we offer the label staccato social support. Results indicate that, in comparison to previous work, staccato social support is characterized by a greater prevalence of esteem support, which builds respect and confidence. We further note the presence of 'following up', a positive behavior that contributes to supportive interactions, likely via social pressure and accountability [7,38]. These findings suggest design recommendations to developers of mobile social support systems and contribute to understanding technologically mediated social support for health.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {653–662},
numpages = {10},
keywords = {social support, mobile health, user experience},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557194,
author = {Jacobs, Maia L. and Clawson, James and Mynatt, Elizabeth D.},
title = {My Journey Compass: A Preliminary Investigation of a Mobile Tool for Cancer Patients},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557194},
doi = {10.1145/2556288.2557194},
abstract = {Health information management for cancer care is a challenging and personal process that changes over time based on one's needs, goals, and health status. While technologies supporting health information management appear promising, we do not fully understand how health information tools fit into patients? daily lives. To better understand the opportunities and usage barriers of these tools, we designed and deployed a mobile, tablet-based health management aid: My Journey Compass. After one month of use, we interviewed twelve breast cancer patients to investigate their initial patterns of adoption, adaptation, use and non-use. We found that developing a tool that was customizable, mobile, and integrated into the patients' healthcare system resulted in a set of surprising uses by breast cancer patients for a wide variety of tasks. Our study demonstrates the potential for health management tools to improve the cancer care experience and for HCI research to influence existing healthcare systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {663–672},
numpages = {10},
keywords = {breast cancer, mobile health, cancer navigation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557333,
author = {Threatt, Anthony L. and Merino, Jessica and Green, Keith Evan and Walker, Ian and Brooks, Johnell O. and Healy, Stan},
title = {An Assistive Robotic Table for Older and Post-Stroke Adults: Results from Participatory Design and Evaluation Activities with Clinical Staff},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557333},
abstract = {An inevitable new frontier for the CHI community is the development of complex, larger-scale, cyber-physical artifacts where advancements in design, computing and robotics converge. Presented here is a design exemplar: the Assistive, Robotic Table (ART), the key component of our envisioned home suite of networked, robotic furnishings for hospitals and homes, promoting wellbeing and independent living. We begin with the motivations for ART, and present our iterative, five-phase, participatory design-and-evaluation process involving clinicians at a rehabilitation hospital, focusing here on the final usability study. From our wide-ranging design-research activities, which may be characterized as research through design, we found ART to be promising but also challenging. As a design exemplar, ART offers invaluable lessons to the CHI community as it comes to design larger-scale, cyber-physical artifacts cultivating interactions across people and their surroundings that define places of social, cultural and psychological significance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {673–682},
numpages = {10}
}

@inproceedings{10.1145/3250930,
author = {Satchell, Christina},
title = {Session Details: Research through Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250930},
doi = {10.1145/3250930},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556960,
author = {Vines, John and Denman-Cleaver, Tess and Dunphy, Paul and Wright, Peter and Olivier, Patrick},
title = {Experience Design Theatre: Exploring the Role of Live Theatre in Scaffolding Design Dialogues},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556960},
doi = {10.1145/2556288.2556960},
abstract = {While theatre has been used in HCI as a tool for engaging participants in design processes, the specific benefits of using live theatre over other communicative mediums, remains underexplored. In this paper we introduce Experience Design Theatre (EDT) as an approach to undertaking experience-centered design with multiple parties in the early stages of design. EDT was motivated by a need to involve several diverse groups of people in the design of a digitally coordinated care service - NetCarers. We used live theatre as a way to engage small groups of participants in dialogues around the design of NetCarers, to qualify their contributions in a refined performance, and to communicate their concerns and aspirations to domain experts. We highlight key benefits to using live theatre in experience-centered design and offer insights for researchers undertaking similar work in the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {683–692},
numpages = {10},
keywords = {ageing, care, intergenerational, theatre, experience-centered design, older people},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557222,
author = {Seok, Jin-min and Woo, Jong-bum and Lim, Youn-kyung},
title = {Non-Finito Products: A New Design Space of User Creativity for Personal User Experience},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557222},
doi = {10.1145/2556288.2557222},
abstract = {Conventional wisdom says that to be successful, an idea must be concrete, complete, and certain. However, what if unfinished ideas work? This CHI paper proposes a new design space we call non-finito products for the HCI community. This new design space is about intentionally unfinished products and how they foster new creations by end-users as they are actually used to help people solve their own problems. The central idea comes from the background of the growing complexity associated with IT advancement and from the new way of dealing with it, with the assistance of user creativity in the actual use of the products. This paper begins with the exploration of non-finito products as a new design space for the end-user's creativity in the personal user experience. We then defined and proposed non-finito products. We discussed three case studies that will help to understand the design space of non-finito products, and we framed the new design space by revealing the beneficial contexts and values. Finally, we suggested the implications of designing non-finito products. We believe that non-finito products will open a new design space in HCI, prompt a new means of replacing value-destroying complexity with value-creating version, and help to make a product better fit to user experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {693–702},
numpages = {10},
keywords = {design perspective, unfinished product, user creativity, non-finito product, user experience},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557098,
author = {Blythe, Mark},
title = {Research through Design Fiction: Narrative in Real and Imaginary Abstracts},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557098},
doi = {10.1145/2556288.2557098},
abstract = {This paper reflects on the uses of prototypes in "Research through Design" and considers "Design Fiction" as a technique for exploring the potential value of new design work. It begins with an analysis of Research through Design abstracts in the ACM digital library and identifies an emerging language and structure of papers in this emerging field. The abstracts: frame a problem space, introduce a study, often involving the deployment of a prototype, and conclude with considerations, reflections and discussion. This format is then pastiched in a series of design fictions written for a project investigating new and emerging forms of reproduction in Art. The fictions take the form of "imaginary abstracts" which summarize findings of papers that have not been written about prototypes that do not exist. It is argued that framing concept designs as fictional studies can provide a space for research focused critique and development.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {703–712},
numpages = {10},
keywords = {prototypes, research through design, design fiction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557261,
author = {Dachtera, Juri and Randall, Dave and Wulf, Volker},
title = {Research on Research: Design Research at the Margins: Academia, Industry and End-Users},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557261},
doi = {10.1145/2556288.2557261},
abstract = {Design research processes often take place in publicly funded projects. Besides designers and users, public funding increasingly requires industry partners to participate in such projects. We present empirical insights from a joint research project in order to assess the claims connected with such funding structures and to report on challenges for design research within them. We identify three themes of conflict between academic and industry partners and elaborate on the sources of them. The presentation of our results builds on the distinction between 'academia' and 'industry', which is frequently applied by political funding agencies. The analysis of the respective stakeholders' actual interests, however, will prove such a dichotomy to be misleading and simplistic.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {713–722},
numpages = {10},
keywords = {joint research, mode2-research, design research},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250931,
author = {Irani, Pourang},
title = {Session Details: Pointing and Cursors},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250931},
doi = {10.1145/3250931},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556997,
author = {Gilliot, J\'{e}r\'{e}mie and Casiez, G\'{e}ry and Roussel, Nicolas},
title = {Impact of Form Factors and Input Conditions on Absolute Indirect-Touch Pointing Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556997},
doi = {10.1145/2556288.2556997},
abstract = {Absolute indirect interaction maps the absolute position of a device's end-effector to the absolute position of a remote on-screen object.Despite its long-time use with graphics tablets and growing use in research prototypes, little is known on the influence of form factors and input conditions on pointing performance with such a mapping. The input and display can have different sizes and aspect ratios, for example. The on-screen targets can vary in size. Users can look solely at the display or at the input device as well. They can also hold the input device in certain cases, or let it rest on a table. This paper reports on two experiments designed to investigate the influence of all these factors on absolute indirect-touch pointing performance. We also provide design guidelines for interaction in these situations based on the observed impacting factors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {723–732},
numpages = {10},
keywords = {form factors, absolute pointing, performance, indirect touch, input conditions},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557410,
author = {Mott, Martez E. and Wobbrock, Jacob O.},
title = {Beating the Bubble: Using Kinematic Triggering in the Bubble Lens for Acquiring Small, Dense Targets},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557410},
doi = {10.1145/2556288.2557410},
abstract = {We present the Bubble Lens, a new target acquisition technique that remedies the limitations of the Bubble Cursor to increase the speed and accuracy of acquiring small, dense targets--precisely those targets for which the Bubble Cursor degenerates to a point cursor. When targets are large and sparse, the Bubble Lens behaves like the Bubble Cursor. But when targets are small and dense, the Bubble Lens automatically magnifies nearby targets, making them larger in both visual- and motor-space. Importantly, magnification is not governed by an explicit user-invoked mode-switch. Rather, magnification is activated through kinematic triggering, a technique that continuously examines an unfolding velocity profile to automatically trigger mode changes based on observed features. In a first study, we found the Bubble Cursor performed poorly when targets had an effective size smaller than 10 pixels. Using this threshold for the Bubble Lens in a second study, we found that the Bubble Lens significantly outperformed the Bubble Cursor, decreasing movement time by 10.2% and error rates by 37.9%, making the Bubble Lens the fastest current pointing technique.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {733–742},
numpages = {10},
keywords = {bubble cursor, magnification, pointing techniques, zooming, pointing facilitation, lensing, mouse pointing, target acquisition, kinematics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557406,
author = {Pasqual, Phillip T. and Wobbrock, Jacob O.},
title = {Mouse Pointing Endpoint Prediction Using Kinematic Template Matching},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557406},
doi = {10.1145/2556288.2557406},
abstract = {We present a new method of predicting the endpoints of mouse movements. While prior approaches to endpoint prediction have relied upon normative kinematic laws, regression, or control theory, our approach is straightforward but kinematically rich. Our key insight is to regard the unfolding velocity profile of a pointing movement as a 2-D stroke gesture and to use template matching to predict the endpoint based on prior observed movements. We call our technique kinematic template matching (KTM), which is simple to implement, user-adaptable, and kinematically expressive. In a study of 17 able-bodied participants evaluated over movement amplitudes ranging from 100-800 pixels, we found KTM to predict endpoints that were within 83 pixels of the true endpoint at 50% of the way through the movement, within 48 pixels at 75%, and within 39 pixels at 90%, using 1000 templates per participant. These accuracies make KTM as successful an approach to endpoint prediction as any prior technique, while being easier to implement and understand than most.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {743–752},
numpages = {10},
keywords = {target prediction, mouse pointing, endpoint prediction, kinematics, template matching},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557095,
author = {Su, Xiaojun and Au, Oscar Kin-Chung and Lau, Rynson W.H.},
title = {The Implicit Fan Cursor: A Velocity Dependent Area Cursor},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557095},
doi = {10.1145/2556288.2557095},
abstract = {We present the Implicit Fan Cursor (IFC) - a novel target pointing technique using a cursor with a fan-shape activation area. The IFC couples the cursor's activation area with its velocity, i.e., the speed and direction of the mouse motion, behaving like a 2D spotlight cursor at low speed and a circular area cursor at high speed. Thus, it enables the user to precisely acquire distant targets at low speed and easily acquire nearest targets at high speed, without explicit mode switching. This technique minimizes cursor movement, while taking into consideration of the precision of cursor movement at different speeds. It also ensures that only one target is captured at any time. The results of our controlled experiments show that the IFC outperforms the point cursor and the area cursor techniques, particularly in terms of cursor moving distance, and that its performance can be accurately modeled using the Fitts' law.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {753–762},
numpages = {10},
keywords = {area cursor, velocity-aware pointing, fitts' law, implicit fan cursor},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250932,
author = {Yarosh, Svetlana},
title = {Session Details: Always Connected: Email and Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250932},
doi = {10.1145/3250932},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557381,
author = {Mazmanian, Melissa and Erickson, Ingrid},
title = {The Product of Availability: Understanding the Economic Underpinnings of Constant Connectivity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557381},
doi = {10.1145/2556288.2557381},
abstract = {Constant connectivity and total availability to clients is the rule rather than the exception in many contemporary workplaces. Enabled by developments in information and communication technologies (ICTs), total availability of employees is possible and presumed. Scholars have explored how new technological affordances, cultural shifts, individual personality traits, and/or the development of social expectations that reinforce norms of constant connectivity have led to this state of affairs. We argue that a key factor has been overlooked in current scholarship about stress, intensive work, and constant connectivity. That is, current economic conditions are creating a marketplace in which firms increasing sell the availability of their employees as part of the services offered by the firm. In this paper we use qualitative data to illustrate how total availability is an integral aspect of the 'product' offered by professional service firms and is becoming increasingly prevalent in other service industries. We conclude with a discussion of how the HCI community might address this situation as a design challenge. Drawing on the work of Goffman and Perlow, we suggest that designers attend to the ways in which organizations might maintain front stage impressions of total availability while collectively managing individual time to restrict total availability behind the scenes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {763–772},
numpages = {10},
keywords = {mobile technology, economic constraints, time and temporality, markets of availability, service work, knowledge work},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556983,
author = {Schoenebeck, Sarita Yardi},
title = {Giving up Twitter for Lent: How and Why We Take Breaks from Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556983},
doi = {10.1145/2556288.2556983},
abstract = {Social media use is widespread, but many people worry about overuse. This paper explores how and why people take breaks from social media. Using a mixed methods approach, we pair data from users who tweeted about giving up Twitter for Lent with an interview study of social media users. We find that 64% of users who proclaim that they are giving up Twitter for Lent successfully do so. Among those who fail, 31% acknowledge their failure; the other 69% simply return. We observe hedging patterns (e.g. "I thought about giving up Twitter for Lent but"?) that surfaced uncertainty about social media behavior. Interview participants were concerned about the tradeoffs of spending time on social media versus doing other things and of spending time on social media rather than in "real life." We discuss gaps in related theory that might help reduce users' anxieties and open design problems related to designing systems and services that can help users manage their own social media use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {773–782},
numpages = {10},
keywords = {willpower, Twitter, media refusal, internet, social media, breaks, self-control},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557182,
author = {Rector, Kyle and Hailpern, Joshua},
title = {MinEMail: SMS Alert System for Managing Critical Emails},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557182},
abstract = {Email is the primary method of digital communication for most people, but the overwhelming quantity has led to a poverty of attention. Existing manual and automatic solutions that aim to save important emails from falling through the cracks have begun to address this problem, but may increase user workload, sacrifice efficiency, or fail to identify high value communications. In response, we developed MinEMail, an alert system that uses a text message (SMS) to remind and notify users of critical emails that may have been missed or forgotten. MinEMail provides an alert infrastructure as well as accurately labeling and predicting which emails are critical, and when and how they need to be addressed. To motivate our system, we also present an up-front study with 777 participants that aims to understand the state and limitations of email and SMS in enterprise. We conduct an experience sampling study of over 3000 emails in order to construct MinEMail's predictive models. Finally, we present the results from a 15 user ecologically valid real-world deployment of MinEMail in enterprise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {783–792},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557013,
author = {Grevet, Catherine and Choi, David and Kumar, Debra and Gilbert, Eric},
title = {Overload is Overloaded: Email in the Age of Gmail},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557013},
doi = {10.1145/2556288.2557013},
abstract = {The term email overload has two definitions: receiving a large volume of incoming email, and having emails of different status types (to do, to read, etc). Whittaker and Sidner proposed the latter definition in 1996, noticing that email inboxes were far more complex than simply containing incoming messages. Sixteen years after Whittaker and Sidner, we replicate and extend their work with a qualitative analysis of Google's Gmail. We find that email overload, both in terms of volume and of status, is still a problem today. Our contributions are 1) updating the state of email overload, 2) extending our understanding of overload in the context of Gmail and 3) comparing personal with work email accounts: while work email tends to be status overloaded, personal email is also type overloaded. These comparisons between work and personal email suggest new avenues for email research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {793–802},
numpages = {10},
keywords = {qualitative study, email overload, organization, work and personal email, management strategies},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250933,
author = {Wakkary, Ron},
title = {Session Details: Smart Homes and Sustainability},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250933},
doi = {10.1145/3250933},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557420,
author = {Ur, Blase and McManus, Elyse and Pak Yong Ho, Melwyn and Littman, Michael L.},
title = {Practical Trigger-Action Programming in the Smart Home},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557420},
doi = {10.1145/2556288.2557420},
abstract = {We investigate the practicality of letting average users customize smart-home devices using trigger-action ("if, then") programming. We find trigger-action programming can express most desired behaviors submitted by participants in an online study. We identify a class of triggers requiring machine learning that has received little attention. We evaluate the uniqueness of the 67,169 trigger-action programs shared on IFTTT.com, finding that real users have written a large number of unique trigger-action interactions. Finally, we conduct a 226-participant usability test of trigger-action programming, finding that inexperienced users can quickly learn to create programs containing multiple triggers or actions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {803–812},
numpages = {10},
keywords = {internet of things, smart home, end-user programming, home automation, condition-action programming},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557167,
author = {Costanza, Enrico and Fischer, Joel E. and Colley, James A. and Rodden, Tom and Ramchurn, Sarvapali D. and Jennings, Nicholas R.},
title = {Doing the Laundry with Agents: A Field Trial of a Future Smart Energy System in the Home},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557167},
doi = {10.1145/2556288.2557167},
abstract = {Future energy systems that rely on renewable energy may bring about a radical shift in how we use energy in our homes. We developed and prototyped a future scenario with highly variable, real-time electricity prices due to a grid that mainly relies on renewables. We designed and deployed an agent-based interactive system that enables users to effectively operate the washing machine in this scenario. The system is used to book timeslots of washing machine use so that the agent can help to minimize the cost of a wash by charging a battery at times when electricity is cheap. We carried out a deployment in 10 households in order to uncover the socio-technical challenges around integrating new technologies into everyday routines. The findings reveal tensions that arise when deploying a rationalistic system to manage contingently and socially organized domestic practices. We discuss the trade-offs between utility and convenience inherent in smart grid applications; and illustrate how certain design choices position applications along this spectrum.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {813–822},
numpages = {10},
keywords = {demand response, energy, real-time pricing, smart grid, autonomous agents, field trial},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557380,
author = {Yang, Rayoung and Newman, Mark W. and Forlizzi, Jodi},
title = {Making Sustainability Sustainable: Challenges in the Design of Eco-Interaction Technologies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557380},
doi = {10.1145/2556288.2557380},
abstract = {The smart home is here. One area where smart home devices promise to deliver great benefits is in the control of home heating, ventilation, and cooling (HVAC) systems. In this paper, we seek to inform the design of future heating and cooling systems by investigating users' experiences with the Nest Learning Thermostat, a commercially available smart home device. We conducted a qualitative study where we compared people's interactions with conventional thermostats with interactions with the Nest. A key finding was that the Nest impacted users' pattern of HVAC control, but only for a while, and caused new problems in unrealized energy savings. In leveraging these findings, we create a set of design implications for Eco-Interaction, the design of features and human-system interactions with the goal of saving energy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {823–832},
numpages = {10},
keywords = {eco-interaction, sustainability, smart home, thermostat},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250934,
author = {Wang, Hao-Chuan},
title = {Session Details: Multilingual Communication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250934},
doi = {10.1145/3250934},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557203,
author = {Hale, Scott A.},
title = {Global Connectivity and Multilinguals in the Twitter Network},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557203},
doi = {10.1145/2556288.2557203},
abstract = {This article analyzes the global connectivity of the Twitter retweet and mentions network and the role of multilingual users engaging with content in multiple languages. The network is heavily structured by language with most mentions and retweets directed to users writing in the same language. Users writing in multiple languages are more active, authoring more tweets than monolingual users. These multilingual users play an important bridging role in the global connectivity of the network. The mean level of insularity from speakers in each language does not correlate straightforwardly with the size of the user base as predicted by previous research. Finally, the English language does play more of a bridging role than other languages, but the role played collectively by multilingual users across different languages is the largest bridging force in the network.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {833–842},
numpages = {10},
keywords = {cross-language, social media, micro-blogs, social network analysis, information diffusion, multilingual, information discovery},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557303,
author = {Gao, Ge and Yamashita, Naomi and Hautasaari, Ari MJ and Echenique, Andy and Fussell, Susan R.},
title = {Effects of Public vs. Private Automated Transcripts on Multiparty Communication between Native and Non-Native English Speakers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557303},
doi = {10.1145/2556288.2557303},
abstract = {Real-time transcripts generated by automated speech recognition (ASR) technologies have the potential to facilitate communication between native speakers (NS) and non-native speakers (NNS). Previous studies of ASR have focused on how transcripts aid NNS speech comprehension. In this study, we examine whether transcripts benefit multiparty real-time conversation between NS and NNS. We hypothesized that ASR transcripts would be more beneficial when the transcripts were publicly shared by all group members as opposed to when they were seen only by the NNS. To test our hypothesis, we conducted a lab experiment in which 14 groups of native and non-native speakers engaged in a story-telling task. Half of the groups received private transcripts that were available only to the NNS; the other half received publicly shared transcripts that were available to all group members. NS spoke more clearly, and both NS and NNS rated the quality of communication higher, when transcripts were publicly shared. These findings inform the design of future tools to support multilingual group communication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {843–852},
numpages = {10},
keywords = {multilingual communication, automated speech recognition, real-time transcripts},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557256,
author = {Kovacs, Geza and Miller, Robert C.},
title = {Smart Subtitles for Vocabulary Learning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557256},
doi = {10.1145/2556288.2557256},
abstract = {Language learners often use subtitled videos to help them learn. However, standard subtitles are geared more towards comprehension than vocabulary learning, as translations are nonliteral and are provided only for phrases, not vocabulary. This paper presents Smart Subtitles, which are interactive subtitles tailored towards vocabulary learning. Smart Subtitles can be automatically generated from common video sources such as subtitled DVDs. They provide features such as vocabulary definitions on hover, and dialog-based video navigation. In our pilot study with intermediate learners studying Chinese, participants correctly defined over twice as many new words in a post-viewing vocabulary test when they used Smart Subtitles, compared to dual Chinese-English subtitles. Learners spent the same amount of time watching clips with each tool, and enjoyed viewing videos with Smart Subtitles as much as with dual subtitles. Learners understood videos equally well using either tool, as indicated by self-assessments and independent evaluations of their summaries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {853–862},
numpages = {10},
keywords = {language learning, interactive videos, subtitles},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557209,
author = {Li, Na and Rosson, Mary Beth},
title = {Using Annotations in Online Group Chats},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557209},
doi = {10.1145/2556288.2557209},
abstract = {Annotating documents has long been a widely used strategy for distilling important contents and externalizing related thoughts and ideas in context. No one has studied the activity of annotating dynamic texts, such as online chat, although online conversation is an important communication media for global companies. In this paper, we investigate Instant Annotation (IA), a real-time annotation-enhanced chat tool. We contrast the use of the enhanced chat tool to a standard chat tool for multilingual groups doing a brainstorming and decision-making task. Results show that group satisfaction and perceived control of the conversation are enhanced for the participants who used IA. We also report new patterns of annotation use and discuss design implications for group chat tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {863–866},
numpages = {4},
keywords = {design, conversation control, instant annotation, evaluation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250935,
author = {Adar, Eytan},
title = {Session Details: Interactive Visualization and Visual Elements},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250935},
doi = {10.1145/3250935},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557010,
author = {Bach, Benjamin and Pietriga, Emmanuel and Fekete, Jean-Daniel},
title = {Visualizing Dynamic Networks with Matrix Cubes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557010},
abstract = {Designing visualizations of dynamic networks is challenging, both because the data sets tend to be complex and because the tasks associated with them are often cognitively demand- ing. We introduce the Matrix Cube, a novel visual representation and navigation model for dynamic networks, inspired by the way people comprehend and manipulate physical cubes. Users can change their perspective on the data by rotating or decomposing the 3D cube. These manipulations can produce a range of different 2D visualizations that emphasize specific aspects of the dynamic network suited to particular analysis tasks. We describe Matrix Cubes and the interactions that can be performed on them in the Cubix system. We then show how two domain experts, an astronomer and a neurologist, used Cubix to explore and report on their own network data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {877–886},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557379,
author = {Perin, Charles and Vuillemot, Romain and Fekete, Jean-Daniel},
title = {A Table! Improving Temporal Navigation in Soccer Ranking Tables},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557379},
doi = {10.1145/2556288.2557379},
abstract = {This article introduces A Table!, an enhanced soccer ranking table providing temporal navigation by combining two novel interaction techniques. Ranking tables order soccer teams represented as rows, according to values of columns containing attributes e.g., accumulated points, or number of scored goals. Because they represent a snapshot of a championship at a time t, tables are regularly updated with new results. Such updates usually change the rows order, which makes the tracking of a specified team over time difficult. We observed that the tables available on the web do not support tracking such changes very well, are generally hard to read, and lack interactions. This contrasts with the extensive use of comments on temporal trends found in soccer analysts articles. To better support such analyzes, the two interactive techniques presented allow exploration of time, and are designed to preserve users' flow: DRAG-CELL is based on direct manipulation of values to browse ranks; VIZ-RANK uses a transient line chart of team ranks to visually explore a championship. An on-line evaluation with 143 participants shows that each technique efficiently supports a set of important temporal tasks not supported by current ranking tables. This paves the way for introducing efficient advanced visual exploration techniques to millions of soccer enthusiasts who use tables everyday.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {887–896},
numpages = {10},
keywords = {soccer, ranking tables, visualization, temporal navigation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557231,
author = {Rzeszotarski, Jeffrey M. and Kittur, Aniket},
title = {Kinetica: Naturalistic Multi-Touch Data Visualization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557231},
doi = {10.1145/2556288.2557231},
abstract = {Over the last several years there has been an explosion of powerful, affordable, multi-touch devices. This provides an outstanding opportunity for novel data visualization techniques that leverage new interaction methods and minimize their barriers to entry. In this paper we describe an approach for multivariate data visualization that uses physics-based affordances that are easy to intuit, constraints that are easy to apply and visualize, and a consistent view as data is manipulated in order to promote data exploration and interrogation. We provide a framework for exploring this problem space, and an example proof of concept system called Kinetica. We describe the results of a user study that suggest users of Kinetica were able to explore multiple dimensions of data at once, identify outliers, and discover trends with minimal training.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {897–906},
numpages = {10},
keywords = {multivariate data, visualization, physics, multi-touch},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557224,
author = {Hong, Sungsoo (Ray) and Kim, Yea-Seul and Yoon, Jong-Chul and Aragon, Cecilia R.},
title = {Traffigram: Distortion for Clarification via Isochronal Cartography},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557224},
doi = {10.1145/2556288.2557224},
abstract = {Most geographic maps visually represent physical distance; however, travel time can in some cases be more important than distance because it directly indicates availability. The technique of creating maps from temporal data is known as isochronal cartography, and is a form of distortion for clarification. In an isochronal map, congestion expands areas, while ideal travel conditions make the map shrink in comparison to the actual distance scale of a traditional map. Although there have been many applications of this technique, detailed user studies of its efficacy remain scarce, and there are conflicting views on its practical value. To attempt to settle this issue, we utilized a user-centered design process to determine which features of isochronal cartography might be most usable in practice. We developed an interactive cartographic visualization system, Traffigram, that features a novel combination of efficient isochronal map algorithms and an interface designed to give map users a quick and seamless experience while preserving geospatial integrity and aesthetics. We validated our design choices with multiple usability studies. We present our results and discuss implications for design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {907–916},
numpages = {10},
keywords = {time-space map, isochrones, geographic visualization, map user interface, information visualization, map usage},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250936,
author = {Nacke, Lennart},
title = {Session Details: Understanding and Designing Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250936},
doi = {10.1145/3250936},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557341,
author = {Smith, Gillian},
title = {Understanding Procedural Content Generation: A Design-Centric Analysis of the Role of PCG in Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557341},
doi = {10.1145/2556288.2557341},
abstract = {Games that use procedural content generation (PCG) do so in a wide variety of ways and for different reasons. One of the most common reasons cited by PCG system creators and game designers is improving replayability by providing a means for automatically creating near-infinite amounts of content, the player can come back and replay the game and refine her strategies over a long period. However, this notion of replayability is both overly broad and incomplete as a motivation. This paper contributes an analytical framework and associated common vocabulary for understanding the role of PCG in games from a design standpoint, with an aim of unpacking some of the broad justifications for PCG use in games, and bringing together technical concerns in designing PCG systems with design concerns related to creating engaging playable experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {917–926},
numpages = {10},
keywords = {game ai, mda framework, game design, procedural content generation, game design theory.},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557078,
author = {Mekler, Elisa D. and Bopp, Julia Ayumi and Tuch, Alexandre N. and Opwis, Klaus},
title = {A Systematic Review of Quantitative Studies on the Enjoyment of Digital Entertainment Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557078},
doi = {10.1145/2556288.2557078},
abstract = {Enjoyment has been identified as a central component of the player experience (PX), but various, overlapping concepts within PX make it difficult to develop valid measures and a common understanding of game enjoyment. We conducted a systematic review of 87 quantitative studies, analyzing different operationalizations and measures of game enjoyment, its determinants, and how these were related to other components of PX, such as flow, presence and immersion. Results suggest that game enjoyment describes the positive cognitive and affective appraisal of the game experience, and may in part be associated with the support of player needs and values. Further, we outline that enjoyment is distinct from flow in that it may occur independently of challenge and cognitive involvement, and argue that enjoyment may be understood as the valence of the player experience. We conclude with a discussion of methodological challenges and point out opportunities for future research on game enjoyment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {927–936},
numpages = {10},
keywords = {flow, player experience, enjoyment, digital games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557308,
author = {Vicencio-Moreira, Rodrigo and Mandryk, Regan L. and Gutwin, Carl and Bateman, Scott},
title = {The Effectiveness (or Lack Thereof) of Aim-Assist Techniques in First-Person Shooter Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557308},
doi = {10.1145/2556288.2557308},
abstract = {Aim-assistance techniques have been shown to work for player balancing in 2D environments, but little information exists about how well these techniques will work in a 3D FPS game. We carried out three studies of the performance of five different aim assists in an Unreal-based game world. The assists worked well in a target-range scenario (study 1), but their performance was reduced when game elements were introduced in a walkthrough map (study 2). We systematically examined the relationships between realistic game elements and assist performance (study 3). These studies show that two techniques -- bullet magnetism and area cursor -- worked well in a wide variety of situations. Other techniques that worked well were too perceptible, and some previously-successful techniques did not work well in any game-like scenario. Our studies are the first to provide empirical evidence of the performance of aim assist techniques in 3D environments, and the first to identify the complexities in using these techniques in real FPS games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {937–946},
numpages = {10},
keywords = {aim assistance, game balancing, first-person shooter games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557245,
author = {Bonsignore, Elizabeth and Moulder, Vicki and Neustaedter, Carman and Hansen, Derek and Kraus, Kari and Druin, Allison},
title = {Design Tactics for Authentic Interactive Fiction: Insights from Alternate Reality Game Designers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557245},
doi = {10.1145/2556288.2557245},
abstract = {This paper presents insights from designers of Alternate Reality Games (ARGs) regarding the design tactics they employ to integrate participatory storytelling and "authentic fiction" into the transmedia experiences they create. Our approach was motivated by recent efforts in HCI to more closely align the development of interaction design theory to the craft knowledge and experiences of designers themselves. The resulting insights enhance our understanding of design approaches that a diverse group of ARG producers follow to create interactive, participatory narratives. We outline narrative-specific themes to support designers who craft similar interactive experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {947–950},
numpages = {4},
keywords = {transmedia, narrative design, alternate reality games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557107,
author = {Silpasuwanchai, Chaklam and Ren, Xiangshi},
title = {Jump and Shoot! Prioritizing Primary and Alternative Body Gestures for Intense Gameplay},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557107},
doi = {10.1145/2556288.2557107},
abstract = {Motion gestures enable natural and intuitive input in video games. However, game gestures designed by developers may not always be the optimal gestures for players. A key challenge in designing appropriate game gestures lies in the interaction-intensive nature of video games, i.e., several actions/commands may need to be executed concurrently using different body parts. This study analyzes user preferences in game gestures, with the aim of accommodating high interactivity during gameplay. Two user-elicitation studies were conducted: first, to determine user preferences, participants were asked to define gestures for common game actions/commands; second, to develop effective combined-gestures, participants were asked to define possible game gestures using each body part (one and two hands, one and two legs, head, eyes, and torso). Our study presents a set of suitable and alternative body parts for common game actions/commands. We also present some simultaneously applied game gestures that assist interaction in highly interactive game situations (e.g., selecting a weapon with the feet while shooting with the hand). Interesting design implications are further discussed, e.g., transferability between hand and leg gestures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {951–954},
numpages = {4},
keywords = {motion gestures, user-defined approach, concurrent gestures, games, interactivity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250937,
author = {Reinecke, Katharina},
title = {Session Details: Personal Values and Preferences},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250937},
doi = {10.1145/3250937},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557398,
author = {Gou, Liang and Zhou, Michelle X. and Yang, Huahai},
title = {KnowMe and ShareMe: Understanding Automatically Discovered Personality Traits from Social Media and User Sharing Preferences},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557398},
doi = {10.1145/2556288.2557398},
abstract = {There is much recent work on using the digital footprints left by people on social media to predict personal traits and gain a deeper understanding of individuals. Due to the veracity of social media, imperfections in prediction algorithms, and the sensitive nature of one's personal traits, much research is still needed to better understand the effectiveness of this line of work, including users' preferences of sharing their computationally derived traits. In this paper, we report a two- part study involving 256 participants, which (1) examines the feasibility and effectiveness of automatically deriving three types of personality traits from Twitter, including Big 5 personality, basic human values, and fundamental needs, and (2) investigates users' opinions of using and sharing these traits. Our findings show there is a potential feasibility of automatically deriving one's personality traits from social media with various factors impacting the accuracy of models. The results also indicate over 61.5% users are willing to share their derived traits in the workplace and that a number of factors significantly influence their sharing preferences. Since our findings demonstrate the feasibility of automatically inferring a user's personal traits from social media, we discuss their implications for designing a new generation of privacy-preserving, hyper-personalized systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {955–964},
numpages = {10},
keywords = {social media, fundamental needs, personality traits, privacy, basic values, big 5 personality},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557403,
author = {Bakhshi, Saeideh and Shamma, David A. and Gilbert, Eric},
title = {Faces Engage Us: Photos with Faces Attract More Likes and Comments on Instagram},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557403},
doi = {10.1145/2556288.2557403},
abstract = {Photos are becoming prominent means of communication online. Despite photos' pervasive presence in social media and online world, we know little about how people interact and engage with their content. Understanding how photo content might signify engagement, can impact both science and design, influencing production and distribution. One common type of photo content that is shared on social media, is the photos of people. From studies of offline behavior, we know that human faces are powerful channels of non-verbal communication. In this paper, we study this behavioral phenomena online. We ask how presence of a face, it's age and gender might impact social engagement on the photo. We use a corpus of 1 million Instagram images and organize our study around two social engagement feedback factors, likes and comments. Our results show that photos with faces are 38% more likely to receive likes and 32% more likely to receive comments, even after controlling for social network reach and activity. We find, however, that the number of faces, their age and gender do not have an effect. This work presents the first results on how photos with human faces relate to engagement on large scale image sharing communities. In addition to contributing to the research around online user behavior, our findings offer a new line of future work using visual analysis.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {965–974},
numpages = {10},
keywords = {image, photo, demographics, instagram, engagement, content, image sharing community, social media, mobile, faces, gender, age, face detection},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557247,
author = {Kim, Auk and Gweon, Gahgene},
title = {Photo Sharing of the Subject, by the Owner, for the Viewer: Examining the Subject's Preference},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557247},
doi = {10.1145/2556288.2557247},
abstract = {Photo sharing activities on social networking sites concern not only the person sharing the information (owner) and the person receiving the information (viewer) but also the person who is in the photo (subject). In our exploratory lab study, we asked 29 participants about their comfort level in allowing a photo owner to share a picture containing both the participant (subject) and the owner. Our results show that the photo subject feels more comfortable in sharing a photo when i) the "closeness between the subject and the owner (SO closeness)" is higher, and ii) the "closeness between the subject and the viewer (SV closeness)" is higher. In addition, we observed that both SV and SO closeness are important in determining the subject's picture sharing preference level.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {975–978},
numpages = {4},
keywords = {closeness, information sharing preference},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557285,
author = {Figueiredo, Flavio and Almeida, Jussara M. and Benevenuto, Fabr\'{\i}cio and Gummadi, Krishna P.},
title = {Does Content Determine Information Popularity in Social Media? A Case Study of Youtube Videos' Content and Their Popularity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557285},
abstract = {We here investigate what drives the popularity of information on social media platforms. Focusing on YouTube, we seek to understand the extent to which content by itself determines a video's popularity. Using mechanical turk as experimental platform, we asked users to evaluate pairs of videos, and compared users' relative perception of the videos' content against their relative popularity reported by YouTube. We found that in most evaluations users could not reach consensus on which video had better content as their perceptions tend to be very subjective. Nevertheless, when consensus was reached, the video with preferred content almost always achieved greater popularity on YouTube, highlighting the importance of content in driving information popularity on social media.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {979–982},
numpages = {4}
}

@inproceedings{10.1145/2556288.2556995,
author = {Hsieh, Gary and Chen, Jilin and Mahmud, Jalal U. and Nichols, Jeffrey},
title = {You Read What You Value: Understanding Personal Values and Reading Interests},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556995},
doi = {10.1145/2556288.2556995},
abstract = {This paper presents an experiment on the relationship between personal values and reading interests of online articles. Results suggest that individuals' values can predict their topical interests. For example, holding stronger universalism values predict interests towards environmental articles, whereas holding stronger achievement values predict interest towards work-related articles. Findings demonstrate the possibility of targeting based on individuals' personal values, but also highlight certain challenges and limitations when applying this approach for online content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {983–986},
numpages = {4},
keywords = {personal values, twitter, content targeting, reading interest},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557179,
author = {O'Kane, Aisling Ann and Rogers, Yvonne and Blandford, Ann E.},
title = {Gaining Empathy for Non-Routine Mobile Device Use through Autoethnography},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557179},
doi = {10.1145/2556288.2557179},
abstract = {In this paper, we report on autoethnography as a method to access non-routine usage of mobile devices, such as during business trips, vacations, etc. Autoethnography, a self-study method with the researcher as participant, was employed for the evaluation of a wrist blood pressure monitor used by people with conditions such as hypertension. The findings from the study were surprising, especially with respect to the environmental and social impact on the use of the technology. Although the autoethnographic method can be disruptive for the researcher, it enables them to understand and empathize with the experiences mobile device users can face in difficult to access contexts. This method allows HCI researchers to better understand user experiences with mobile devices, including mobile medical technology, especially during non-routine times that can be difficult to study in-situ with traditional user studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {987–990},
numpages = {4},
keywords = {empathy, mobile, context, healthcare., autoethnography},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250938,
author = {O'Malley, Claire},
title = {Session Details: Enabling Interactive Performances},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250938},
doi = {10.1145/3250938},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557251,
author = {Silang Maranan, Diego and Fdili Alaoui, Sarah and Schiphorst, Thecla and Pasquier, Philippe and Subyen, Pattarawut and Bartram, Lyn},
title = {Designing for Movement: Evaluating Computational Models Using LMA Effort Qualities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557251},
abstract = {While single-accelerometers are a common consumer embedded sensors, their use in representing movement data as an intelligent resource remains scarce. Accelerometers have been used in movement recognition systems, but rarely to assess expressive qualities of movement. We present a prototype of wearable system for the real-time detection and classification of movement quality using acceleration data. The system applies Laban Movement Analysis (LMA) to recognize Laban Effort qualities from acceleration input using a Machine Learning software that generates classifications in real time. Existing LMA-recognition systems rely on motion capture data and video data, and can only be deployed in controlled settings. Our single-accelerometer system is portable and can be used under a wide range of environmental conditions. We evaluate the performance of the system, present two applications using the system in the digital arts and discuss future directions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {991–1000},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557050,
author = {Unander-Scharin, Carl and Unander-Scharin, \r{A}sa and H\"{o}\"{o}k, Kristina},
title = {The Vocal Chorder: Empowering Opera Singers with a Large Interactive Instrument},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557050},
doi = {10.1145/2556288.2557050},
abstract = {With The Vocal Chorder, a large interactive instrument to create accompaniment, opera singers can get more power over the performance. The device allows performers to interactively accompany themselves through pushing, leaning on and bending steel wires. The design was guided by the unique needs of the solo-singer, explored through autobiographical design and material explorations, some on stage, and later tested by other singers. We discuss how designing for opera and for the stage requires extraordinary durability and how opera performances can change with a bodily-oriented instrument such as The Vocal Chorder. Through a designerly exploration, we arrived at a device that offered (1) a tool for singers to take control over the rhythmical pace and overall artistic and aesthetic outcome of their performances, (2) an enriched sense of embodiment between their voice and the overall performance; and (3) a means to empower opera singers on stage.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1001–1010},
numpages = {10},
keywords = {empowerment, interactive instruments, opera, autobiographical design, embodiment, appropriation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557187,
author = {H\"{a}kkil\"{a}, Jonna R. and Posti, Maaret and Schneegass, Stefan and Alt, Florian and Gultekin, Kunter and Schmidt, Albrecht},
title = {Let Me Catch This! Experiencing Interactive 3D Cinema through Collecting Content with a Mobile Phone},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557187},
doi = {10.1145/2556288.2557187},
abstract = {The entertainment industry is going through a transformation, and technology development is affecting how we can enjoy and interact with the entertainment media content in new ways. In our work, we explore how to enable interaction with content in the context of 3D cinemas. This allows viewers to use their mobile phone to retrieve, for example, information on the artist of the soundtrack currently playing or a discount coupon on the watch the main actor is wearing. We are particularly interested in the user experience of the interactive 3D cinema concept, and how different interactive elements and interaction techniques are perceived. We report on the development of a prototype application utilizing smart phones and on an evaluation in a cinema context with 20 participants. Results emphasize that designing for interactive cinema experiences should drive for holistic and positive user experiences. Interactive content should be tied together with the actual video content, but integrated into contexts where it does not conflict with the immersive experience with the movie.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1011–1020},
numpages = {10},
keywords = {3d, user studies, user experience, mobile phone interaction, interactive cinema},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557049,
author = {Swift, Ben and Sorensen, Andrew and Martin, Michael and Gardner, Henry},
title = {Coding Livecoding},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557049},
doi = {10.1145/2556288.2557049},
abstract = {Livecoding is an artistic programming practice in which an artist's low-level interaction can be observed with sufficiently high fidelity to allow for transcription and analysis. This paper presents the first reported "coding" of livecoding videos. From an identified corpus of videos available on the web, we coded performances of two different livecoding artists, recording both the (textual) programming edit events and the musical effect of these edits. Our analysis includes a novel, transition-matrix visualisation of the textual and musical dimensions of this data to create a "performer fingerprint". We show how detailed transcriptions of livecoding videos can be made which, we hope, will provide a foundation for further research into describing and understanding livecoding.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1021–1024},
numpages = {4},
keywords = {end-user programming, creativity support tools},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557226,
author = {Martin, Charles and Gardner, Henry and Swift, Ben},
title = {Exploring Percussive Gesture on IPads with Ensemble Metatone},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557226},
doi = {10.1145/2556288.2557226},
abstract = {Percussionists are unique among western classical instrumentalists in that their artistic practice is defined by an approach to interaction rather than their instruments. While percussionists are accustomed to exploring non-traditional objects to create music, these objects have yet to encompass touch-screen computing devices to any great extent. The proliferation and popularity of these devices now presents an opportunity to explore their use in combining computer-generated sound together with percussive interaction in a musical ensemble.This paper examines Ensemble Metatone, a group formed to explore the "infiltration" of iPad-based musical instruments into a free-improvisation percussion ensemble. We discuss the design approach for two different iPad percussion instruments and the methodology for exploring them with the group over a series of rehearsals and performances. Qualitative analysis of discussions throughout this process shows that the musicians developed a vocabulary of gestures and musical interactions to make musical sense of these new instruments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1025–1028},
numpages = {4},
keywords = {multitouch, user experience, percussion, gesture, expression, music},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250939,
author = {Chen, Nicholas},
title = {Session Details: Battery Life and Energy Harvesting},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250939},
doi = {10.1145/3250939},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557271,
author = {Athukorala, Kumaripaba and Lagerspetz, Eemil and von K\"{u}gelgen, Maria and Jylh\"{a}, Antti and Oliner, Adam J. and Tarkoma, Sasu and Jacucci, Giulio},
title = {How Carat Affects User Behavior: Implications for Mobile Battery Awareness Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557271},
doi = {10.1145/2556288.2557271},
abstract = {Mobile devices have limited battery life, and numerous battery management applications are available that aim to improve it. This paper examines a large-scale mobile battery awareness application, called Carat, to see how it changes user behavior with long-term use. We conducted a survey of current Carat Android users and analyzed their interaction logs. The results show that long-term Carat users save more battery, charge their devices less often, learn to manage their battery with less help from Carat, have a better understanding of how Carat works, and may enjoy competing against other users. Based on these findings, we propose a set of guidelines for mobile battery awareness applications: battery awareness applications should make the reasoning behind their recommendations understandable to the user, be tailored to retain long-term users, take the audience into account when formulating feedback, and distinguish third-party and system applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1029–1038},
numpages = {10},
keywords = {energy awareness, user retention, user behavior, smartphone},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557225,
author = {Ryokai, Kimiko and Su, Peiqi and Kim, Eungchan and Rollins, Bob},
title = {EnergyBugs: Energy Harvesting Wearables for Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557225},
doi = {10.1145/2556288.2557225},
abstract = {EnergyBugs are energy harvesting wearables with features that invite children to move their bodies to generate tiny, yet usable amounts of electricity. EnergyBugs not only convert children's kinetic energy into usable electrical energy, but also let children power a specially designed LED lamp with the energy the children have personally harvested. EnergyBugs therefore turn the electrical energy into a tangible object that children can manipulate and think with. Two studies of EnergyBugs with 34 elementary school children have revealed that children carefully observed and negotiated the use of personally harvested energy with their classmates, as well as developed emotional connections to energy. In particular, moving their own bodies to generate energy led the children to more actively ask questions about energy from new perspectives. We report our iterative design process and discuss the implications of our results for HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1039–1048},
numpages = {10},
keywords = {tangible uis, wearable, human-powered microgeneration, kinetic energy, children, energy harvesting},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557041,
author = {Mikkonen, Jussi and Gowrishankar, Ramyah and Oksanen, Miia and Raittinen, Harri and Kolinummi, Arto},
title = {OJAS: Open Source Bi-Directional Inductive Power Link},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557041},
doi = {10.1145/2556288.2557041},
abstract = {We present the design, development and evaluation of a bi-directional inductive power transfer circuit for prototyping purposes in the watt-range. Our device does not require any configuration and is intended for the development of wearable and tangible systems. Our approach allows a bi-directional power flow without any change in the circuit, such that the same circuit can be used for charging and discharging a battery. The contribution of this work is an enabling technology for researchers and practitioners in the fields of Wearable Electronics, Ubiquitous Computing and Human-Computer Interaction interested in exploring new interactions powered by watt-range inductive links. It enables smaller battery sizes, and therefore lighter devices, as the power can be distributed in a way that has not been feasible before. We discuss the motivations, technical details and the workshop evaluating our inductive approach.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1049–1058},
numpages = {10},
keywords = {prototyping, wearable electronics, smart garments, bi-directional inductive power},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557135,
author = {Kihm, Jaeyeon and Guimbreti\`{e}re, Fran\c{c}ois V. and Karl, Julia and Manohar, Rajit},
title = {Using Asymmetric Cores to Reduce Power Consumption for Interactive Devices with Bi-Stable Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557135},
doi = {10.1145/2556288.2557135},
abstract = {Low power "helper" cores have been increasingly included on application processors to accomplish low intensity tasks such as music playing and motion sensing with minimum energy consumption. Recently, Guimbreti\`{e}re et al. [1] demonstrated that such helper cores can also be used to execute simple user interface tasks. We revisit this approach by implementing a similar system on an off-the-shelf application processor (TI OMAP4). Our study shows that in the case of high event rate interactions (pen inking and virtual keyboard), significant battery life gains (\texttimes{}1.7 and \texttimes{}2.3 respectively) can be achieved with the helper core executing the interface. Having the helper core only dis-patch input events incurs a 18% penalty relative to the maximum savings rate, but allows for simplified deployment since it merely requires a change in toolkit infrastructure.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1059–1062},
numpages = {4},
keywords = {user interface system, asymmetric architecture, energy efficiency, bi-stable display, pen interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250940,
author = {Izadi, Shahram},
title = {Session Details: Mid-Air Gestures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250940},
doi = {10.1145/3250940},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557130,
author = {Hincapi\'{e}-Ramos, Juan David and Guo, Xiang and Moghadasian, Paymahn and Irani, Pourang},
title = {Consumed Endurance: A Metric to Quantify Arm Fatigue of Mid-Air Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557130},
doi = {10.1145/2556288.2557130},
abstract = {Mid-air interactions are prone to fatigue and lead to a feeling of heaviness in the upper limbs, a condition casually termed as the gorilla-arm effect. Designers have often associated limitations of their mid-air interactions with arm fatigue, but do not possess a quantitative method to assess and therefore mitigate it. In this paper we propose a novel metric, Consumed Endurance (CE), derived from the biomechanical structure of the upper arm and aimed at characterizing the gorilla-arm effect. We present a method to capture CE in a non-intrusive manner using an off-the-shelf camera-based skeleton tracking system, and demonstrate that CE correlates strongly with the Borg CR10 scale of perceived exertion. We show how designers can use CE as a complementary metric for evaluating existing and designing novel mid-air interactions, including tasks with repetitive input such as mid-air text-entry. Finally, we propose a series of guidelines for the design of fatigue-efficient mid-air interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1063–1072},
numpages = {10},
keywords = {seato mid-air keyboard, consumed endurance, endurance, gorilla-arm, mid-air interactions, mid-air text-entry},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556964,
author = {Markussen, Anders and Jakobsen, Mikkel R\o{}nne and Hornb\ae{}k, Kasper},
title = {Vulture: A Mid-Air Word-Gesture Keyboard},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556964},
doi = {10.1145/2556288.2556964},
abstract = {Word-gesture keyboards enable fast text entry by letting users draw the shape of a word on the input surface. Such keyboards have been used extensively for touch devices, but not in mid-air, even though their fluent gestural input seems well suited for this modality. We present Vulture, a word-gesture keyboard for mid-air operation. Vulture adapts touch based word-gesture algorithms to work in mid-air, projects users' movement onto the display, and uses pinch as a word delimiter. A first 10-session study suggests text-entry rates of 20.6 Words Per Minute (WPM) and finds hand-movement speed to be the primary predictor of WPM. A second study shows that with training on a few phrases, participants do 28.1 WPM, 59% of the text-entry rate of direct touch input. Participants' recall of trained gestures in mid-air was low, suggesting that visual feedback is important but also limits performance. Based on data from the studies, we discuss improvements to Vulture and some alternative designs for mid-air text entry.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1073–1082},
numpages = {10},
keywords = {text entry, in-air interaction, shape writing, word-gesture keyboard, freehand interaction, mid-air interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557151,
author = {Wacharamanotham, Chat and Todi, Kashyap and Pye, Marty and Borchers, Jan},
title = {Understanding Finger Input above Desktop Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557151},
doi = {10.1145/2556288.2557151},
abstract = {Using the space above desktop input devices adds a rich new input channel to desktop interaction. Input in this elevated layer has been previously used to modify the granularity of a 2D slider, navigate layers of a 3D body scan above a multitouch table and access vertically stacked menus. However, designing these interactions is challenging because the lack of haptic and direct visual feedback easily leads to input errors. For bare finger input, the user's fingers needs to reliably enter and stay inside the interactive layer, and engagement techniques such as midair clicking have to be disambiguated from leaving the layer. These issues have been addressed for interactions in which users operate other devices in midair, but there is little guidance for the design of bare finger input in this space.In this paper, we present the results of two user studies that inform the design of finger input above desktop devices. Our studies show that 2 cm is the minimum thickness of the above-surface volume that users can reliably remain within. We found that when accessing midair layers, users do not automatically move to the same height. To address this, we introduce a technique that dynamically determines the height at which the layer is placed, depending on the velocity profile of the user's initial finger movement into midair. Finally, we propose a technique that reliably distinguishes clicking from homing movements, based on the user's hand shape. We structure the presentation of our findings using Buxton's three-state input model, adding additional states and transitions for above-surface interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1083–1092},
numpages = {10},
keywords = {midair, height, thickness, near-surface, finger input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557122,
author = {Kulshreshth, Arun and LaViola, Joseph J.},
title = {Exploring the Usefulness of Finger-Based 3D Gesture Menu Selection},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557122},
doi = {10.1145/2556288.2557122},
abstract = {Counting using one's fingers is a potentially intuitive way to enumerate a list of items and lends itself naturally to gesture-based menu systems. In this paper, we present the results of the first comprehensive study on Finger-Count menus to investigate its usefulness as a viable option for 3D menu selection tasks. Our study compares 3D gesture-based finger counting (Finger Count menus) with two gesture-based menu selection techniques (Hand-n-Hold, Thumbs-Up), derived from existing motion-controlled video game menu selection strategies, as well as 3D Marking menus. We examined selection time, selection accuracy and user preference for all techniques. We also examined the impact of different spatial layouts for menu items and different menu depths. Our results indicate that Finger-Count menus are significantly faster than the other menu techniques we tested and are the most liked by participants. Additionally, we found that while Finger-Count menus and 3D Marking menus have similar selection accuracy, Finger-Count menus are almost twice as fast compared to 3D Marking menus.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1093–1102},
numpages = {10},
keywords = {selection, video games, gesture recognition, 3d marking menu, 3d interaction, user study, finger-count menu, menu selection, thumbs-up menu, hand-n-hold menu, depth camera},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250941,
author = {Cao, Xiang},
title = {Session Details: Touch and Stylus Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250941},
doi = {10.1145/3250941},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557037,
author = {Ng, Albert and Annett, Michelle and Dietz, Paul and Gupta, Anoop and Bischof, Walter F.},
title = {In the Blink of an Eye: Investigating Latency Perception during Stylus Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557037},
doi = {10.1145/2556288.2557037},
abstract = {While pen computing has become increasingly more popular, device responsiveness, or latency, still plagues such interaction. Although there have been advances in digitizer technology over the last few years, commercial end-to-end latencies are unfortunately similar to those found with touchscreens, i.e., 65 - 120 milliseconds. We report on a prototype stylus-enabled device, the High Performance Stylus System (HPSS), designed to display latencies as low as one millisecond while users ink or perform dragging tasks.To understand the role of latency while inking with a stylus, psychophysical just-noticeable difference experiments were conducted using the HPSS. While participants performed dragging and scribbling tasks, very low levels of latency could be discriminated, i.e., ~1 versus 2 milliseconds while dragging and ~7 versus 40 milliseconds while scribbling. The HPSS and our experimentation have provided further motivation for the implementation of latency saving measures in pen-based hardware and software systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1103–1112},
numpages = {10},
keywords = {pen computing, psychophysics, stylus, latency, pen, perception},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557028,
author = {Spindler, Martin and Schuessler, Martin and Martsch, Marcel and Dachselt, Raimund},
title = {Pinch-Drag-Flick vs. Spatial Input: Rethinking Zoom &amp; Pan on Mobile Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557028},
doi = {10.1145/2556288.2557028},
abstract = {The multi-touch-based pinch to zoom, drag and flick to pan metaphor has gained wide popularity on mobile displays, where it is the paradigm of choice for navigating 2D documents. But is finger-based navigation really the gold standard' In this paper, we present a comprehensive user study with 40 participants, in which we systematically compared the Pinch-Drag-Flick approach with a technique that relies on spatial manipulation, such as lifting a display up/down to zoom. While we solely considered known techniques, we put considerable effort in implementing both input strategies on popular consumer hardware (iPhone, iPad). Our results show that spatial manipulation can significantly outperform traditional Pinch-Drag-Flick. Given the carefully optimized prototypes, we are confident to have found strong arguments that future generations of mobile devices could rely much more on spatial interaction principles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1113–1122},
numpages = {10},
keywords = {spatial input, spatially aware displays, mobile displays, user study, multi-touch input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557302,
author = {Ren, Yi and Li, Yang and Lank, Edward},
title = {InkAnchor: Enhancing Informal Ink-Based Note Taking on Touchscreen Mobile Phones},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557302},
doi = {10.1145/2556288.2557302},
abstract = {Although touchscreen mobile phones are widely used for recording informal text notes (e.g., grocery lists, reminders and directions), the lack of efficient mechanisms for combining informal graphical content with text is a persistent challenge. In this paper, we present InkAnchor, a digital ink editor that allows users to easily create ink-based notes by finger drawing and writing on a mobile phone touchscreen. InkAnchor incorporates flexible anchoring, focus-plus-context input, content chunking, and lightweight editing mechanisms to support the capture of informal notes and annotations. We describe the design and evaluation of InkAnchor through a series of user studies, which revealed that the integrated support enabled by InkAnchor is a significant improvement over current mobile note taking applications on a range of mobile note-taking tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1123–1132},
numpages = {10},
keywords = {mobile interaction, multi-scale sketching, multi-touch, note taking, digital ink, drawing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557033,
author = {Wilson, Graham and Carter, Thomas and Subramanian, Sriram and Brewster, Stephen A.},
title = {Perception of Ultrasonic Haptic Feedback on the Hand: Localisation and Apparent Motion},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557033},
doi = {10.1145/2556288.2557033},
abstract = {Ultrasonic haptic feedback is a promising means of providing tactile sensations in mid-air without encumbering the user with an actuator. However, controlled and rigorous HCI research is needed to understand the basic characteristics of perception of this new feedback medium, and so how best to utilise ultrasonic haptics in an interface. This paper describes two experiments conducted into two fundamental aspects of ultrasonic haptic perception: 1) localisation of a static point and 2) the perception of motion. Understanding these would provide insight into 1) the spatial resolution of an ultrasonic interface and 2) what forms of feedback give the most convincing illusion of movement. Results show an average localisation error of 8.5mm, with higher error along the longitudinal axis. Convincing sensations of motion were produced when travelling longer distances, using longer stimulus durations and stimulating multiple points along the trajectory. Guidelines for feedback design are given.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1133–1142},
numpages = {10},
keywords = {perception, haptic feedback, ultrasound, localisation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250942,
author = {Zimmerman, John},
title = {Session Details: Quantified Self},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250942},
doi = {10.1145/3250942},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557372,
author = {Choe, Eun Kyoung and Lee, Nicole B. and Lee, Bongshin and Pratt, Wanda and Kientz, Julie A.},
title = {Understanding Quantified-Selfers' Practices in Collecting and Exploring Personal Data},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557372},
doi = {10.1145/2556288.2557372},
abstract = {Researchers have studied how people use self-tracking technologies and discovered a long list of barriers including lack of time and motivation as well as difficulty in data integration and interpretation. Despite the barriers, an increasing number of Quantified-Selfers diligently track many kinds of data about themselves, and some of them share their best practices and mistakes through Meetup talks, blogging, and conferences. In this work, we aim to gain insights from these "extreme users," who have used existing technologies and built their own workarounds to overcome different barriers. We conducted a qualitative and quantitative analysis of 52 video recordings of Quantified Self Meetup talks to understand what they did, how they did it, and what they learned. We highlight several common pitfalls to self-tracking, including tracking too many things, not tracking triggers and context, and insufficient scientific rigor. We identify future research efforts that could help make progress toward addressing these pitfalls. We also discuss how our findings can have broad implications in designing and developing self-tracking technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1143–1152},
numpages = {10},
keywords = {self-tracking, personal analytics, health, self-monitoring, per-sonal informatics, self-experimentation., quantified self},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557223,
author = {Jang, Amy and MacLean, Diana L. and Heer, Jeffrey},
title = {BodyDiagrams: Improving Communication of Pain Symptoms through Drawing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557223},
doi = {10.1145/2556288.2557223},
abstract = {Thousands of people use the Internet to discuss pain symptoms. While communication between patients and physicians involves both verbal and physical interactions, online discussions of symptoms typically comprise text only. We present BodyDiagrams, an online interface for expressing symptoms via drawings and text. BodyDiagrams augment textual descriptions with pain diagrams drawn over a reference body and annotated with severity and temporal metadata. The resulting diagrams can easily be shared to solicit feedback and advice. We also conduct a two-phase user study to assess BodyDiagrams' communicative efficacy. In the first phase, users describe pain symptoms using BodyDiagrams and a text-only interface; in the second phase, medical professionals evaluate these descriptions. We find that patients are significantly more confident that their BodyDiagrams will be correctly interpreted, while medical professionals rated BodyDiagrams as significantly more informative than text descriptions. Both groups indicated a preference for using diagrams to communicate physical symptoms in the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1153–1162},
numpages = {10},
keywords = {symptom communication, drawing, pain diagrams, health},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557039,
author = {Rooksby, John and Rost, Mattias and Morrison, Alistair and Chalmers, Matthew},
title = {Personal Tracking as Lived Informatics},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557039},
doi = {10.1145/2556288.2557039},
abstract = {This paper characterises the use of activity trackers as "lived informatics". This characterisation is contrasted with other discussions of personal informatics and the quantified self. The paper reports an interview study with activity tracker users. The study found: people do not logically organise, but interweave various activity trackers, sometimes with ostensibly the same functionality; that tracking is often social and collaborative rather than personal; that there are different styles of tracking, including goal driven tracking and documentary tracking; and that tracking information is often used and interpreted with reference to daily or short term goals and decision making. We suggest there will be difficulties in personal informatics if we ignore the way that personal tracking is enmeshed with everyday life and people's outlook on their future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1163–1172},
numpages = {10},
keywords = {data, activity tracking, qualitative methods},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250943,
author = {Huang, Elaine},
title = {Session Details: Sustainability Perspectives},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250943},
doi = {10.1145/3250943},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556968,
author = {Bates, Oliver and Hazas, Mike and Friday, Adrian and Morley, Janine and Clear, Adrian K.},
title = {Towards an Holistic View of the Energy and Environmental Impacts of Domestic Media and IT},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556968},
doi = {10.1145/2556288.2556968},
abstract = {To date, research in sustainable HCI has dealt with eco-feedback, usage and recycling of appliances within the home, and longevity of portable electronics such as mobile phones. However, there seems to be less awareness of the energy and greenhouse emissions impacts of domestic consumer electronics and information technology. Such awareness is needed to inform HCI sustainability researchers on how best to prioritise efforts around digital media and IT. Grounded in inventories, interview and plug energy data from 33 undergraduate student participants, our findings provide the context for assessing approaches to reducing the energy and carbon emissions of media and IT in the home. In the paper, we use the findings to discuss and inform more fruitful directions that sustainable HCI research might take, and we quantify how various strategies might have modified the energy and emissions impacts for our participants.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1173–1182},
numpages = {10},
keywords = {life cycle assessment, sustainability, home energy, embodied emissions},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557374,
author = {Brereton, Margot and Roe, Paul and Schroeter, Ronald and Lee Hong, Anita},
title = {Beyond Ethnography: Engagement and Reciprocity as Foundations for Design Research out Here},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557374},
doi = {10.1145/2556288.2557374},
abstract = {This paper explores an emerging paradigm for HCI design research based primarily upon engagement, reciprocity and doing. Much HCI research begins with an investigatory and analytic ethnographic approach before translating to design. Design may come much later in the process and may never benefit the community that is researched. However in many settings it is difficult for researchers to access the privileged ethnographer position of observer and investigator. Moreover rapid ethnographic research often does not seem the best or most appropriate course of action. We draw upon a project working with a remote Australian Aboriginal community to illustrate an alternative approach in Indigenous research, where the notion of reciprocity is first and foremost. We argue that this can lead to sustainable designs, valid research and profound innovation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1183–1186},
numpages = {4},
keywords = {ict4d, participatory action research, postcolonial hci},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250944,
author = {Gajos, Krzysztof},
title = {Session Details: Navigating Video},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250944},
doi = {10.1145/3250944},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557106,
author = {Al-Hajri, Abir and Miller, Gregor and Fong, Matthew and Fels, Sidney S.},
title = {Visualization of Personal History for Video Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557106},
doi = {10.1145/2556288.2557106},
abstract = {We present an investigation of two different visualizations of video history: Video Timeline and Video Tiles. Video Timeline extends the commonly employed list-based visualization for navigation history by applying size to indicate heuristics and occupying the full screen with a two-sided timeline. Video Tiles visualizes history items in a grid-based layout by following pre-defined templates based on items' heuristics and ordering, utilizing screen space more effectively at the expense of a clearer temporal location. The visualizations are compared against the state-of-the-art method (a filmstrip-based visualization), with ten participants tasked with sharing their previously-seen affective intervals. Our study shows that our visualizations are perceived as intuitive and both outperform and are strongly preferred to the current method. Based on these results, Video Timeline and Video Tiles provide an effective addition to video viewers to help manage the growing quantity of video. They provide users with insight into their navigation patterns, allowing them to quickly find previously-seen intervals, leading to efficient clip sharing, simpler authoring and video summarization.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1187–1196},
numpages = {10},
keywords = {video, navigation, history, visualization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557382,
author = {Hunter, Seth E. and Maes, Pattie and Tang, Anthony and Inkpen, Kori M. and Hessey, Susan M.},
title = {WaaZam! Supporting Creative Play at a Distance in Customized Video Environments},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557382},
doi = {10.1145/2556288.2557382},
abstract = {We present the design, and evaluation of WaaZam, a video mediated communication system designed to support creative play in customized environments. Users can interact together in virtual environments composed of digital assets layered in 3D space. The goal of the project is to support creative play and increase social engagement during video sessions of geographically separated families. We try to understand the value of customization for individual families with children ages 6-12. We present interviews with creativity experts, a pilot study and a formal evaluation of families playing together in four conditions: separate windows, merged windows, digital play sets, and customized digital environments. We found that playing in the same video space enables new activities and increases social engagement for families. Customization allows families to modify scenes for their needs and support more creative play activities that embody the imagination of the child.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1197–1206},
numpages = {10},
keywords = {family play, composited video, shared experiences at a distance, play at a distance, video mediated communication, remote play, customized video environments},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557304,
author = {Freeman, Dustin and Santosa, Stephanie and Chevalier, Fanny and Balakrishnan, Ravin and Singh, Karan},
title = {LACES: Live Authoring through Compositing and Editing of Streaming Video},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557304},
doi = {10.1145/2556288.2557304},
abstract = {Video authoring activity typically consists of three phases: planning (pre-production), capture (production) and processing (post-production). The status quo is that these phases occur separately, and the latter two have a significant amount of "slack time", where the camera operator is watching the scene unfold during capture, and the editor is re-watching and navigating through recorded footage during post-production. While this process is well suited to creating polished or professional video, video clips produced by casual video makers as seen in online forums could benefit from some editing without the overhead of current authoring tools. We introduce LACES, a tablet-based system enabling simple video manipulations in the midst of filming. Seamless in-situ integration of video capture and manipulation forms a novel workflow, allowing greater spontaneity and exploration of video creation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1207–1216},
numpages = {10},
keywords = {compositing, video editing, video production},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557249,
author = {Craggs, Barnaby and Kilgallon Scott, Myles and Alexander, Jason},
title = {ThumbReels: Query Sensitive Web Video Previews Based on Temporal, Crowdsourced, Semantic Tagging},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557249},
doi = {10.1145/2556288.2557249},
abstract = {During online search, the user's expectations often differ from those of the author. This is known as the "intention gap" and is particularly problematic when searching for and discriminating between online video content. An author uses description and meta-data tags to label their content, but often cannot predict alternate interpretations or appropriations of their work. To address this intention gap, we present ThumbReels, a concept for query-sensitive video previews generated from crowdsourced, temporally defined semantic tagging. Further, we supply an open-source tool that supports on-the-fly temporal tagging of videos, whose output can be used for later search queries. A first user study validates the tool and concept. We then present a second study that shows participants found ThumbReels to better represent search terms than contemporary preview techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1217–1220},
numpages = {4},
keywords = {metadata, thumbnails, crowdsourcing, video summarisation, video surrogates, thumbreels, video},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557082,
author = {Nicholson, James and Huber, Mark and Jackson, Daniel and Olivier, Patrick},
title = {Panopticon as an ELearning Support Search Tool},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557082},
doi = {10.1145/2556288.2557082},
abstract = {We present an evaluation of Panopticon, a video surrogate system, as an online eLearning support search tool for finding information within video lectures. A comparison was made with a standard video player (YouTube) in two scenarios with two classes of users: revision students and independent learners. Results showed that users of Panopticon were significantly faster at finding information within the lecture videos than users of the YouTube player. It was also found that videos predominantly featuring a talking lecturer took longest to navigate, presenting design implications for lectures to be uploaded to open eLearning platforms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1221–1224},
numpages = {4},
keywords = {elearning, video browsing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250945,
author = {Irani, Lilly},
title = {Session Details: Crowds and Creativity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250945},
doi = {10.1145/3250945},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557378,
author = {Yu, Lixiu and Kittur, Aniket and Kraut, Robert E.},
title = {Searching for Analogical Ideas with Crowds},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557378},
doi = {10.1145/2556288.2557378},
abstract = {Seeking solutions from one domain to solve problems in another is an effective process of innovation. This process of analogy searching is difficult for both humans and machines. In this paper, we present a novel approach for re-presenting a problem in terms of its abstract structure, and then allowing people to use this structural representation to find analogies. We propose a crowdsourcing process that helps people navigate a large dataset to find analogies. Through two experiments, we show the benefits of using abstract structural representations to search for ideas that are analogous to a source problem, and that these analogies result in better solutions than alternative approaches. This work provides a useful method for finding analogies, and can streamline innovation for both novices and professional designers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1225–1234},
numpages = {10},
keywords = {analogy searching, schema, crowdsourcing, creativity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557394,
author = {Zhao, Zhenpeng and Badam, Sriram Karthik and Chandrasegaran, Senthil and Park, Deok Gun and Elmqvist, Niklas L.E. and Kisselburgh, Lorraine and Ramani, Karthik},
title = {SkWiki: A Multimedia Sketching System for Collaborative Creativity},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557394},
doi = {10.1145/2556288.2557394},
abstract = {We present skWiki, a web application framework for collaborative creativity in digital multimedia projects, including text, hand-drawn sketches, and photographs. skWiki overcomes common drawbacks of existing wiki software by providing a rich viewer/editor architecture for all media types that is integrated into the web browser itself, thus avoiding dependence on client-side editors. Instead of files, skWiki uses the concept of paths as trajectories of persistent state over time. This model has intrinsic support for collaborative editing, including cloning, branching, and merging paths edited by multiple contributors. We demonstrate skWiki's utility using a qualitative, sketching-based user study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1235–1244},
numpages = {10},
keywords = {creativity, wikis, collaborative editing, sketching},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557371,
author = {Yu, Lixiu and Kittur, Aniket and Kraut, Robert E.},
title = {Distributed Analogical Idea Generation: Inventing with Crowds},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557371},
doi = {10.1145/2556288.2557371},
abstract = {Harnessing crowds can be a powerful mechanism for increasing innovation. However, current approaches to crowd innovation rely on large numbers of contributors generating ideas independently in an unstructured way. We introduce a new approach called distributed analogical idea generation, which aims to make idea generation more effective and less reliant on chance. Drawing from the literature in cognitive science on analogy and schema induction, our approach decomposes the creative process in a structured way amenable to using crowds. In three experiments we show that distributed analogical idea generation leads to better ideas than example-based approaches, and investigate the conditions under which crowds generate good schemas and ideas. Our results have implications for improving creativity and building systems for distributed crowd innovation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1245–1254},
numpages = {10},
keywords = {crowdsourcing, innovation, schema, analogy, creativity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557375,
author = {Chilton, Lydia B. and Kim, Juho and Andr\'{e}, Paul and Cordeiro, Felicia and Landay, James A. and Weld, Daniel S. and Dow, Steven P. and Miller, Robert C. and Zhang, Haoqi},
title = {Frenzy: Collaborative Data Organization for Creating Conference Sessions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557375},
doi = {10.1145/2556288.2557375},
abstract = {Organizing conference sessions around themes improves the experience for attendees. However, the session creation process can be difficult and time-consuming due to the amount of expertise and effort required to consider alternative paper groupings. We present a collaborative web application called Frenzy to draw on the efforts and knowledge of an entire program committee. Frenzy comprises (a) interfaces to support large numbers of experts working collectively to create sessions, and (b) a two-stage process that decomposes the session-creation problem into meta-data elicitation and global constraint satisfaction. Meta-data elicitation involves a large group of experts working simultaneously, while global constraint satisfaction involves a smaller group that uses the meta-data to form sessions.We evaluated Frenzy with 48 people during a deployment at the CSCW 2014 program committee meeting. The session making process was much faster than the traditional process, taking 88 minutes instead of a full day. We found that meta-data elicitation was useful for session creation. Moreover, the sessions created by Frenzy were the basis of the CSCW 2014 schedule.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1255–1264},
numpages = {10},
keywords = {communitysourcing, crowdsourcing, groupware},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250946,
author = {Golbeck, Jennifer},
title = {Session Details: Interacting with the Web},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250946},
doi = {10.1145/3250946},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557036,
author = {Benson, Edward and Karger, David R.},
title = {End-Users Publishing Structured Information on the Web: An Observational Study of What, Why, and How},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557036},
doi = {10.1145/2556288.2557036},
abstract = {End-users are accustomed to filtering and browsing styled collections of data on professional web sites, but they have few ways to create and publish such information architectures for themselves. This paper presents a full-lifecycle analysis of the Exhibit framework - an end-user tool which provides such functionality - to understand the needs, capabilities, and practices of this class of users. We include interviews, as well as analysis of over 1,800 visualizations and 200,000 web interactions with these visualizations. Our analysis reveals important findings about this user population which generalize to the task of providing better end-user structured content publication tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1265–1274},
numpages = {10},
keywords = {web content editing, web design, faceted browsing, information architectures},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557265,
author = {Seckler, Mirjam and Heinz, Silvia and Bargas-Avila, Javier A. and Opwis, Klaus and Tuch, Alexandre N.},
title = {Designing Usable Web Forms: Empirical Evaluation of Web Form Improvement Guidelines},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557265},
doi = {10.1145/2556288.2557265},
abstract = {This study reports a controlled eye tracking experiment (N = 65) that shows the combined effectiveness of 20 guidelines to improve interactive online forms when applied to forms found on real company websites. Results indicate that improved web forms lead to faster completion times, fewer form submission trials, and fewer eye movements. Data from subjective questionnaires and interviews further show increased user satisfaction. Overall, our findings highlight the importance for web designers to improve their web forms using UX guidelines.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1275–1284},
numpages = {10},
keywords = {form guidelines, form evaluation, world wide web, internet, web forms, form interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557149,
author = {Chiravirakul, Pawitra and Payne, Stephen J.},
title = {Choice Overload in Search Engine Use?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557149},
doi = {10.1145/2556288.2557149},
abstract = {Search engines typically return so many results that choosing from the list might be predicted to suffer from the effects of "choice overload". Preliminary work has reported just such an effect [12]. In this paper a series of three experiments was conducted to investigate the choice overload effect in search engine use. Participants were given search tasks and presented with either six or twenty-four returns to choose from. The results revealed that the choice behaviour was strongly influenced by the ranking of returns, and that choice satisfaction was affected by the number of options and the decision time. The main results, from the third experiment, showed that large sets of options yielded a positive effect on participants' satisfaction when they made a decision without time limit. When time was more strongly constrained, choices from small sets led to relatively higher satisfaction. Our studies show how user satisfaction with found information can be affected by processing strategies that are influenced by search engine design features.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1285–1294},
numpages = {10},
keywords = {choice satisfaction, search engines, decision behaviour},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250947,
author = {Blythe, Mark},
title = {Session Details: Music, Dance, and Television},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250947},
doi = {10.1145/3250947},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557298,
author = {Hoare, Michaela and Benford, Steve and Jones, Rachel and Milic-Frayling, Natasa},
title = {Coming in from the Margins: Amateur Musicians in the Online Age},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557298},
doi = {10.1145/2556288.2557298},
abstract = {HCI is increasingly interested in amateurism, but the wider literature suggests that the amateur is a complex and distinctive phenomenon. An interview study reveals the nature of the amateur in the digital age. Even though operating non-professionally at a micro-scale, amateur musicians employ a plethora of online services to sustain local fanbases, reach out to new fans, collaborate internationally, and actively promote both digital and material products. Our findings lead to recommendations for event-oriented promotion tools; community-oriented analytics; tangible and embedded products; and limited-edition digital experiences. We conclude that HCI needs to recognise the amateur as an important class of user, one who is serious about their leisure, and who is also distinct from the professional as from the novice and hobbyist.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1295–1304},
numpages = {10},
keywords = {music, community, distribution, sharing, amateur, social media, promotion, craft, diy, tangible},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557369,
author = {Barkhuus, Louise and Engstr\"{o}m, Arvid and Zoric, Goranka},
title = {Watching the Footwork: Second Screen Interaction at a Dance and Music Performance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557369},
doi = {10.1145/2556288.2557369},
abstract = {Interactive mobile technologies have become part of audience experiences of live performances in terms of both general media sharing and specific (sometimes official) extra content. At the same time, high bandwidth affords streaming of live events to mobile devices. We take advantage of these technologies in our high resolution, panoramic image video stream and study a scenario of audience members viewing the very same live event they are watching on a tablet. The video stream on the tablet is navigational and enables audience members to pan and zoom in the real-time video feed. We studied audience interaction and impressions in three performances of a dance and music show and found distinct uses of the second screen video stream. We emphasize that despite initial reluctance, the observed utilization of the technology opened up for new potential practices. Our study shows how working with perceived conflict in technology can still open up design space for interactive technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1305–1314},
numpages = {10},
keywords = {second screen interaction, mobile entertainment, interactive television},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557048,
author = {Hamilton, William A. and Garretson, Oliver and Kerne, Andruid},
title = {Streaming on Twitch: Fostering Participatory Communities of Play within Live Mixed Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557048},
abstract = {Previously, video streaming sites were at the fringes of online social media. In the past two years, live streams of video games, on sites such as Twitch.tv, have become very popular. Live streams serve as meeting grounds for player communities. The Twitch streaming medium combines broadcast video with open IRC chat channels. In conjunction with gameplay, viewer participation and community building gain emphasis. Twitch streams range in size and nature, from intimate communities with fifty viewers, to massive broadcasts with tens of thousands. In this paper, we present an ethnographic investigation of the live streaming of video games on Twitch.We find that Twitch streams act as virtual third places, in which informal communities emerge, socialize, and participate. Over time, stream communities form around shared identities drawn from streams? contents and participants? shared experiences. We describe processes through which stream communities form, the motivations of members, and emergent issues in the medium. Finally, we draw from our findings to derive implications for design of live mixed-media environments to support participatory online communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1315–1324},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557315,
author = {Juhlin, Oskar and Engstr\"{o}m, Arvid and \"{O}nnevall, Elin},
title = {Long Tail TV Revisited: From Ordinary Camera Phone Use to pro-Am Video Production},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557315},
doi = {10.1145/2556288.2557315},
abstract = {Pro-Am live video producers broadcast events on a regular basis. They are here selected for an ethnographic study since their continuous content generation can teach us something of what it takes for amateurs, who currently struggle with mastering the video medium, to become proficient producers. We learn from media theory that Pro-Ams are distinguished from professionals in terms of inherent skills and identities, and have therefore focused on these characteristics. We add to this research by showing on-going challenges that the former face in their production, i.e. how their learning practices, such as learning through instructions, are situated and related to particular settings. Learning and development of skills were done as organizations, rather than as individuals. Furthermore, the recurrent nature of both events and broadcasts appears to be an important condition for establishing the terms needed to carry out a production, and to learn the skills of a producer. This understanding may explain in part why accounts in previous research, of single users struggling with the affordances of live video, point to such difficulties in mastering the medium. The findings guide design to better support activities contiguous with the set-up of the production, rather than the broadcast per se.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1325–1334},
numpages = {10},
keywords = {learning, media studies, organization theory, video, ethnography, mimicking, live video, negotiation, identity, user-generated content, pro-am, camera phones},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250948,
author = {schraefel, m.c.},
title = {Session Details: Social Media and Health},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250948},
doi = {10.1145/3250948},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557139,
author = {Culotta, Aron},
title = {Estimating County Health Statistics with Twitter},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557139},
doi = {10.1145/2556288.2557139},
abstract = {Understanding the relationships among environment, behavior, and health is a core concern of public health researchers. While a number of recent studies have investigated the use of social media to track infectious diseases such as influenza, little work has been done to determine if other health concerns can be inferred. In this paper, we present a large-scale study of 27 health-related statistics, including obesity, health insurance coverage, access to healthy foods, and teen birth rates. We perform a linguistic analysis of the Twitter activity in the top 100 most populous counties in the U.S., and find a significant correlation with 6 of the 27 health statistics. When compared to traditional models based on demographic variables alone, we find that augmenting models with Twitter-derived information improves predictive accuracy for 20 of 27 statistics, suggesting that this new methodology can complement existing approaches.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1335–1344},
numpages = {10},
keywords = {social media, public health, natural language processing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557145,
author = {Murnane, Elizabeth L. and Counts, Scott},
title = {Unraveling Abstinence and Relapse: Smoking Cessation Reflected in Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557145},
doi = {10.1145/2556288.2557145},
abstract = {Analysis of smokers' posts and behaviors on Twitter reveals factors impacting abstinence and relapse during cessation attempts. Combining automatic and crowdsourced techniques, we detect users trying to quit smoking and analyze tweet and network data from a sample of 653 individuals over a two-year window of quitting. Guided by theory and practice, we derive behavioral, social, and emotional measures to compare users who abstain and relapse. We also examine the cessation process, demonstrating that Twitter can help chronicle how some people go about quitting. Among other results, we show that those who fail in their smoking cessation are far heavier posters and use relatively less positive language, while those who succeed are more social in both network ties and in directed communication. We conclude with insights on how intelligent intervention systems can harness these signals to provide tailored behavior change support.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1345–1354},
numpages = {10},
keywords = {cessation, health, behavior, twitter, social media, smoking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557293,
author = {Huh, Jina and Pratt, Wanda},
title = {Weaving Clinical Expertise in Online Health Communities},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557293},
doi = {10.1145/2556288.2557293},
abstract = {Many patients visit online health communities to receive support. In face-to-face support groups, health professionals facilitate peer-patients exchanging experience while adding their clinical expertise when necessary. However, the large scale of online health communities makes it challenging for such health professional moderators' involvement to happen. To address this challenge of delivering clinical expertise to where patients need them, we explore the idea of semi-automatically providing clinical expertise in online health communities. We interviewed 14 clinicians showing them example peer-patient conversation threads. From the interviews, we examined the ideal practice of clinicians providing expertise to patients. The clinicians continuously assessed when peer-patients were providing appropriate support, what kinds of clinical help they could give online, and when to defer to patients' healthcare providers. The findings inform requirements for building a semi-automated system delivering clinical expertise in online health communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1355–1364},
numpages = {10},
keywords = {support group, moderator, online health communities, health informatics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557214,
author = {De Choudhury, Munmun and Morris, Meredith Ringel and White, Ryen W.},
title = {Seeking and Sharing Health Information Online: Comparing Search Engines and Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557214},
doi = {10.1145/2556288.2557214},
abstract = {Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1365–1376},
numpages = {12},
keywords = {health, search engine, social search, social media, twitter},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250949,
author = {Weibel, Nadir},
title = {Session Details: On and above the Surface},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250949},
doi = {10.1145/3250949},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557336,
author = {Kim, David and Izadi, Shahram and Dostal, Jakub and Rhemann, Christoph and Keskin, Cem and Zach, Christopher and Shotton, Jamie and Large, Timothy and Bathiche, Steven and Nie\ss{}ner, Matthias and Butler, D. Alex and Fanello, Sean and Pradeep, Vivek},
title = {RetroDepth: 3D Silhouette Sensing for High-Precision Input on and above Physical Surfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557336},
doi = {10.1145/2556288.2557336},
abstract = {We present RetroDepth, a new vision-based system for accurately sensing the 3D silhouettes of hands, styluses, and other objects, as they interact on and above physical surfaces. Our setup is simple, cheap, and easily reproducible, comprising of two infrared cameras, diffuse infrared LEDs, and any off-the-shelf retro-reflective material. The retro-reflector aids image segmentation, creating a strong contrast between the surface and any object in proximity. A new highly efficient stereo matching algorithm precisely estimates the 3D contours of interacting objects and the retro-reflective surfaces. A novel pipeline enables 3D finger, hand and object tracking, as well as gesture recognition, purely using these 3D contours. We demonstrate high-precision sensing, allowing robust disambiguation between a finger or stylus touching, pressing or interacting above the surface. This allows many interactive scenarios that seamlessly mix together freehand 3D interactions with touch, pressure and stylus input. As shown, these rich modalities of input are enabled on and above any retro-reflective surface, including custom "physical widgets" fabricated by users. We compare our system with Kinect and Leap Motion, and conclude with limitations and future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1377–1386},
numpages = {10},
keywords = {depth sensing, stylus, vision-based uis, contour classification, 3D contours, 3D input, stereo matching, touch, nui},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557120,
author = {Goel, Mayank and Lee, Brendan and Islam Aumi, Md. Tanvir and Patel, Shwetak and Borriello, Gaetano and Hibino, Stacie and Begole, Bo},
title = {SurfaceLink: Using Inertial and Acoustic Sensing to Enable Multi-Device Interaction on a Surface},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557120},
doi = {10.1145/2556288.2557120},
abstract = {We present SurfaceLink, a system where users can make natural surface gestures to control association and information transfer among a set of devices that are placed on a mutually shared surface (e.g., a table). SurfaceLink uses a combination of on-device accelerometers, vibration motors, speakers and microphones (and, optionally, an off-device contact microphone for greater sensitivity) to sense gestures performed on the shared surface. In a controlled evaluation with 10 participants, SurfaceLink detected the presence of devices on the same surface with 97.7% accuracy, their relative arrangement with 89.4% accuracy, and various single- and multi-touch surface gestures with an average accuracy of 90.3%. A usability analysis showed that SurfaceLink has advantages over current multi-device interaction techniques in a number of situations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1387–1396},
numpages = {10},
keywords = {surface interaction, inertial sensing, mobile phones, multi-device interaction, acoustic sensing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557276,
author = {Pan, Ye and Steptoe, William and Steed, Anthony},
title = {Comparing Flat and Spherical Displays in a Trust Scenario in Avatar-Mediated Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557276},
doi = {10.1145/2556288.2557276},
abstract = {We report on two experiments that investigate the influence of display type and viewing angle on how people place their trust during avatar-mediated interaction. By monitoring advice seeking behavior, our first experiment demonstrates that if participants observe an avatar at an oblique viewing angle on a flat display, they are less able to discriminate between expert and non-expert advice than if they observe the avatar face-on. We then introduce a novel spherical display and a ray-traced rendering technique that can display an avatar that can be seen correctly from any viewing direction. We expect that a spherical display has advantages over a flat display because it better supports non-verbal cues, particularly gaze direction, since it presents a clear and undistorted viewing aspect at all angles. Our second experiment compares the spherical display to a flat display. Whilst participants can discriminate expert advice regardless of display, a negative bias towards the flat screen emerges at oblique viewing angles. This result emphasizes the ability of the spherical display to be viewed qualitatively similarly from all angles. Together the experiments demonstrate how trust can be altered depending on how one views the avatar.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1397–1406},
numpages = {10},
keywords = {avatars, telecommunication, mixed reality, spherical displays, trust},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557173,
author = {Gong, Nan-Wei and Steimle, J\"{u}rgen and Olberding, Simon and Hodges, Steve and Gillian, Nicholas Edward and Kawahara, Yoshihiro and Paradiso, Joseph A.},
title = {PrintSense: A Versatile Sensing Technique to Support Multimodal Flexible Surface Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557173},
doi = {10.1145/2556288.2557173},
abstract = {We present a multimodal on-surface and near-surface sensing technique for planar, curved and flexible surfaces. Our technique leverages temporal multiplexing of signals coming from a universal interdigitated electrode design, which is printed as a single conductive layer on a flexible substrate. It supports sensing of touch and proximity input, and moreover is capable of capturing several levels of pressure and flexing. We leverage recent developments in conductive inkjet printing as a way to prototype electrode patterns, and combine this with our hardware module for supporting the full range of sensing methods. As the technique is low-cost and easy to implement, it is particularly well-suited for prototyping touch- and hover-based user interfaces, including curved and deformable ones.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1407–1410},
numpages = {4},
keywords = {flexible sensor, touch input, conductive inkjet printed electronics", multimodal input, "interactive surface},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557316,
author = {Jota, Ricardo and Lopes, Pedro and Wigdor, Daniel and Jorge, Joaquim},
title = {Let's Kick It: How to Stop Wasting the Bottom Third of Your Large Screen Display},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557316},
doi = {10.1145/2556288.2557316},
abstract = {Large-scale touch surfaces have been widely studied in literature and adopted for public installations such as interactive billboards. However, current designs do not take into consideration that touching the interactive surface at different heights is not the same; for body-height displays, the bottom portion of the screen is within easier reach of the foot than the hand. We explore the design space of foot input on vertical surfaces, and propose three distinct interaction modalities: hand, foot tapping, and foot gesturing. Our design exploration pays particular attention to areas of the touch surface that were previously overlooked: out of hand's reach and close to the floor. We instantiate our design space with a working prototype of an interactive surface, in which we are able to distinguish between finger and foot tapping and extend the input area beyond the bottom of the display to support foot gestures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1411–1414},
numpages = {4},
keywords = {kick, foot interaction, large-scale display, floor input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250950,
author = {Butz, Andreas},
title = {Session Details: Interactive Whiteboards and Public Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250950},
doi = {10.1145/3250950},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557001,
author = {M\"{u}ller, J\"{o}rg and Eberle, Dieter and Tollmar, Konrad},
title = {Communiplay: A Field Study of a Public Display Mediaspace},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557001},
doi = {10.1145/2556288.2557001},
abstract = {We present Communiplay, a public display media space. People passing by see their own contour mirrored on a public display and can start to play with virtual objects. At the same time, they see others playing at remote displays within the same virtual space. We are interested whether people would use such a public display media space, and if so, how and why. We evaluate Communiplay in a field study in six connected locations and find a remote honey-pot effect, i.e. people interacting at one location attract people at other locations. The conversion rate (percentage of passers-by starting to interact) rose by +136% when people saw others playing at remote locations. We also provide the first quantification of the (local) honey-pot effect (in our case it raised the conversion rate by +604% when people saw others playing at the same location). We conclude that the integration of multiple public displays into a media space is a promising direction for public displays and can make them more attractive and valuable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1415–1424},
numpages = {10},
keywords = {public displays, media space, in-the-wild study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556970,
author = {Fortin, Claude and Neustaedter, Carman and Hennessy, Kate},
title = {Posting for Community and Culture: Considerations for the Design of Interactive Digital Bulletin Boards},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556970},
doi = {10.1145/2556288.2556970},
abstract = {The next decade is likely to see a shift in digital public displays moving from non-interactive to interactive content. This will likely create a need for digital bulletin boards and for a better understanding of how such displays should be designed to encourage community members to interact with them. Our study addresses this by exploring community bulletin boards as a ubiquitous type of participatory non-digital display "in the wild". Our results highlight how they are used for content of local and contextual relevance, and how cultures of participation, personalization, location, the tangible character of architecture, access, control and flexibility might affect community members' level of engagement with them. Our analysis suggests entry points as design considerations intrinsically linked to the users' sense of agency within a delineated space. Overlaps with related work are identified throughout to provide further validation of previous findings in this area of research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1425–1434},
numpages = {10},
keywords = {urban computing, entry points, digital bulletin boards, observation, large public displays, cultures of participation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557186,
author = {Greis, Miriam and Alt, Florian and Henze, Niels and Memarovic, Nemanja},
title = {I Can Wait a Minute: Uncovering the Optimal Delay Time for Pre-Moderated User-Generated Content on Public Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557186},
doi = {10.1145/2556288.2557186},
abstract = {Public displays have advanced from isolated and non interactive "ad" displays which show images and videos to displays that are networked, interactive, and open to a wide variety of content and applications. Prior work has shown large potential of user-generated content on public displays. However, one of the problems with user-generated content on public displays is moderation as content may be explicit or troublesome for a particular location. In this work we explore the expectations of users with regard to content moderation on public displays. An online survey revealed that people not only think that display content should be moderated but also that a delay of up to 10 minutes is acceptable if display content is moderated. In a subsequent in the wild deployment we compared different moderation delays. We found that a moderation delay significantly decreases the number of user-generated posts while at the same time there is no significant effect on users' decision to repeatedly post on the display.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1435–1438},
numpages = {4},
keywords = {content moderation, public displays, twitter},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250951,
author = {Ju, Wendy},
title = {Session Details: Human-Robot Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250951},
doi = {10.1145/3250951},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557057,
author = {Saupp\'{e}, Allison and Mutlu, Bilge},
title = {Design Patterns for Exploring and Prototyping Human-Robot Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557057},
doi = {10.1145/2556288.2557057},
abstract = {Robotic products are envisioned to offer rich interactions in a range of environments. While their specific roles will vary across applications, these products will draw on fundamental building blocks of interaction, such as greeting people, narrating information, providing instructions, and asking and answering questions. In this paper, we explore how such building blocks might serve as interaction design patterns that enable design exploration and prototyping for human-robot interaction. To construct a pattern library, we observed human interactions across different scenarios and identified seven patterns, such as question-answer pairs. We then designed and implemented Interaction Blocks, a visual authoring environment that enabled prototyping of robot interactions using these patterns. Design sessions with designers and developers demonstrated the promise of using a pattern language for designing robot interactions, confirmed the usability of our authoring environment, and provided insights into future research on tools for human-robot interaction design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1439–1448},
numpages = {10},
keywords = {prototyping, design patterns, design exploration, human-robot interaction, authoring environment, design sessions, interaction design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557180,
author = {Pereira, Andr\'{e} and Prada, Rui and Paiva, Ana},
title = {Improving Social Presence in Human-Agent Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557180},
doi = {10.1145/2556288.2557180},
abstract = {Humans have a tendency to consider media devices as social beings. Social agents and artificial opponents can be examined as one instance of this effect. With today's technology it is already possible to create artificial agents that are perceived as socially present. In this paper, we start by identifying the factors that influence perceptions of social presence in human-agent interactions. By taking these factors into account and by following previously defined guidelines for building socially present artificial opponents, a case study was created in which a social robot plays the Risk board game against three human players. An experiment was performed to ascertain whether the agent created in this case study is perceived as socially present. The experiment suggested that by following the guidelines for creating socially present artificial board game opponents, the perceived social presence of users towards the artificial agent improves.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1449–1458},
numpages = {10},
keywords = {board games, human-robot interaction (hri), artificial opponents, social presence},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557274,
author = {Lohse, Manja and Rothuis, Reinier and Gallego-P\'{e}rez, Jorge and Karreman, Daphne E. and Evers, Vanessa},
title = {Robot Gestures Make Difficult Tasks Easier: The Impact of Gestures on Perceived Workload and Task Performance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557274},
doi = {10.1145/2556288.2557274},
abstract = {Gestures are important non-verbal signals in human communication. Research with virtual agents and robots has started to add to the scientific knowledge about gestures but many questions with respect to the use of gestures in human-computer interaction are still open. This paper investigates the influence of robot gestures on the users' perceived workload and task performance (i.e. information recall) in a direction-giving task. We conducted a 2 x 2 (robot gestures vs. no robot gestures x easy vs. difficult task) experiment. The results indicate that robot gestures increased user performance and decreased perceived workload in the difficult task but not in the easy task. Thus, robot gestures are a promising means to improve human-robot interaction particularly in challenging tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1459–1466},
numpages = {8},
keywords = {perceived workload, gestures, task performance, human-robot interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557174,
author = {Bidwell, Jonathan and Holloway, Alexandra and Davidoff, Scott},
title = {Measuring Operator Anticipatory Inputs in Response to Time-Delay for Teleoperated Human-Robot Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557174},
doi = {10.1145/2556288.2557174},
abstract = {Many tasks call for efficient user interaction under time delay-controlling space instruments, piloting remote aircraft and operating search and rescue robots. In this paper we identify an underexplored design opportunity for building robotic teleoperation user interfaces following an evaluation of operator performance during a time-delayed robotic arm block-stacking task in twenty-two participants. More delay resulted in greater operator hesitation and a decreased ratio of active to inactive input. This ratio can serve as a useful proxy for measuring an operator's ability to anticipate the outcome of their control inputs before receiving delayed visual feedback. High anticipatory input ratio (AIR) scores indicate times when robot operators enter commands before waiting for visual feedback. Low AIR scores highlight when operators must wait for visual feedback before continuing. We used this measurement to help us identify particular sub-tasks where operators would likely benefit from additional support.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1467–1470},
numpages = {4},
keywords = {teleoperation, metric, human-robot interface, time delay},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557395,
author = {Lee, Hee Rin and \v{S}abanovic, Selma and Stolterman, Erik},
title = {Stay on the Boundary: Artifact Analysis Exploring Researcher and User Framing of Robot Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557395},
doi = {10.1145/2556288.2557395},
abstract = {In recent years, HCI researchers have increased their focus on studying the power relationships between researchers and users, and developing methodologies for eliciting design ideas that are sensitive to existing epistemic hierarchies in technology design. The differential value given to expert versus lay knowledge is a central factor in these debates. We apply Artifact Analysis, developed to help designers handle the complexity of digital artifacts, as a method to explore how experts and non-experts understand and frame robots, a technology characterized by significant complexity. Our results show that both non-expert users and expert researchers have knowledge that is significant to future robot development, but they focus on different aspects of the technology - users address mediated and interaction complexity while researchers focus on internal and external complexity. We also found that robots function as boundary objects between experts and users, and suggest that one task designers can perform is to "stay on the boundary" and mediate between the different ways in which experts and non-experts frame emerging technology to develop designs that benefit from insights from both user and researcher perspectives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1471–1474},
numpages = {4},
keywords = {boundary objects, artifact analysis, epistemic hierarchy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250952,
author = {Cranor, Lorrie},
title = {Session Details: Emergency Response},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250952},
doi = {10.1145/3250952},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557002,
author = {Al-Akkad, Amro and Ramirez, Leonardo and Boden, Alexander and Randall, Dave and Zimmermann, Andreas},
title = {Help Beacons: Design and Evaluation of an Ad-Hoc Lightweight s.o.s. System for Smartphones},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557002},
doi = {10.1145/2556288.2557002},
abstract = {We present the design and evaluation of a lightweight mobile S.O.S. system that facilitates ad-hoc communication between first responders and victims in emergency situations. Our approach leverages established protocols and standards in unforeseen ways to provide a platform supporting the creation of short-lived communication links. The system comprises two mobile applications: one victim application that allows the broadcasting of distress signals by a novel use of Wi-Fi SSIDs; and a responder application that allows first responders to discover and trace the people broadcasting the signals. The main difference of our system with other platforms enabling communication in crisis situations is that our system is independent from existing network infrastructure and runs on off-the-shelf, commercially available smartphones. We describe the results of our evaluation process in the context of both a design evaluation during a real-world emergency response exercise and of two user workshops in preparation for an upcoming large-scale exercise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1485–1494},
numpages = {10},
keywords = {ad-hoc communication, mobile computing, smartphones, emergency response},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557140,
author = {Leavitt, Alex and Clark, Joshua A.},
title = {Upvoting Hurricane Sandy: Event-Based News Production Processes on a Social News Site},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557140},
doi = {10.1145/2556288.2557140},
abstract = {This paper uses the case of Hurricane Sandy and reddit's topical community (subreddit) /r/sandy to examine the production and curation of news content around events on a social news site. Through qualitative analysis, we provide a coded topology of produced content and describe how types of networked gatekeeping impact the framing of a crisis situation. This study also examines, through quantitative modeling, what kind of information becomes negotiated and voted as relevant. We suggest that highly scored content shared in a social news setting focused more on human-interest media and perspective-based citizen journalism than professional news reports. We conclude by discussing how the mechanisms of social news sites conflict with the social norms and culture of reddit to produce differing expectations around news.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1495–1504},
numpages = {10},
keywords = {news framing, news production, crisis communication, reddit, social news site, mixed methods, networked gatekeeping},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557227,
author = {Hughes, Amanda L. and St. Denis, Lise A. A. and Palen, Leysia and Anderson, Kenneth M.},
title = {Online Public Communications by Police &amp; Fire Services during the 2012 Hurricane Sandy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557227},
doi = {10.1145/2556288.2557227},
abstract = {Social media and other online communication tools are a subject of great interest in mass emergency response. Members of the public are turning to these solutions to seek and offer emergency information. Emergency responders are working to determine what social media policies should be in terms of their "public information" functions. We report on the online communications from all the coastal fire and police departments within a 100 mile radius of Hurricane Sandy's US landfall. Across four types of online communication media, we collected data from 840 fire and police departments. Findings indicate that few departments used these online channels in their Sandy response efforts, and that communications differed between fire and police departments and across media type. However, among the highly engaged departments, there is evidence that they bend and adapt policies about what constitutes appropriate public communication in the face of emergency demands; therefore, we propose that flexibility is important in considering future emergency online communication policy. We conclude with design recommendations for making online communication media more "listenable" for both emergency managers and members of the public.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1505–1514},
numpages = {10},
keywords = {disaster, risk communication, crisis informatics, microblogging, social media, social computing, emergency},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557188,
author = {Betz, Matthias and Wulf, Volker},
title = {EmergencyMessenger: A Text Based Communication Concept for Indoor Firefighting},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557188},
doi = {10.1145/2556288.2557188},
abstract = {Finding and rescuing missing or injured people or fighting fire inside burning buildings is a central challenge for fire brigades. To ensure the safety of indoor work, monitoring the operations of firefighting units is crucial. As in most countries, firefighters in Germany utilize radio sets to establish voice communication between indoor operating units and the supervisory structure outside. Based on findings from a long term ethnographic study in cooperation with different German fire brigades over a time span of more than 5 years we analyzed the advantages and disadvantages of the current voice over radio communication tactics and techniques. We designed and evaluated a complementary text based communication device the EMERGENCY-MESSENGER to support the time critical work of indoor units working under harsh conditions, wearing Self-Contained-Breathing-Apparatus (SCBA). We conducted 13 full scale training missions including extensive debriefings to design and evaluate the communication concept and the corresponding device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1515–1524},
numpages = {10},
keywords = {monitoring, security, firefighting, messaging, safety, autonomy, text, cooperation, indoor, communication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251008,
author = {Bigham, Jeffrey},
title = {Session Details: Sensemaking and Information in Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251008},
doi = {10.1145/3251008},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556959,
author = {Hailpern, Joshua M. and Huberman, Bernardo A.},
title = {Odin: Contextual Document Opinions on the Go},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556959},
doi = {10.1145/2556288.2556959},
abstract = {Information overload is a systemic problem for knowledge workers in enterprise. For a long time, information was scarce and therefore valuable. While, the explosion of digital information has made information plentiful, time to read and process that content is now scarce. This problem is only exacerbated by our increased mobility, and the expectation to be "on top" of the continuous barrage of documents while on the go. Knowledge workers in enterprise need solutions that are designed with quick methods for finding what to read in a large collection of documents (e.g. financial reports, legal documents, news), and ways of presenting it within small visual real estate. Unlike reviews, document collections are long, more varied, and context is extremely important. In response, we present Odin, a mobile web-based window onto a user's document corpus. Rather than performing corpus summarization, Odin users can quickly find opinions and documents that are Aligned or Divergent from the corpus' consensus, or those that are the most Relevant given the overall corpus' of opinions. Odin presents this information through a simple and intuitive mobile interface. To the authors' knowledge, this is the first UI/system (and support algorithm) to allow mobile users to place documents and their opinions in context through alignment rather than raw word count or sentiment. Positive results from two evaluations are also presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1525–1534},
numpages = {10},
keywords = {opinions, divergence, alignment, mobile, interaction, economics of attention, consensus, interface},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557083,
author = {D\"{o}rk, Marian and Comber, Rob and Dade-Robertson, Martyn},
title = {Monadic Exploration: Seeing the Whole through Its Parts},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557083},
doi = {10.1145/2556288.2557083},
abstract = {Monadic exploration is a new approach to interacting with relational information spaces that challenges the distinction between the whole and its parts. Building on the work of sociologists Gabriel Tarde and Bruno Latour we turn to the concept of the monad as a useful lens on online communities and collections that expands the possibility for creating meaning in their navigation. While existing interfaces tend to emphasize either the structure of the whole or details of a part, monadic exploration brings these opposing perspectives closer together in continuous movements between partially overlapping points of view. We present a visualization that reflects a given node's relative position within a network using radial displacements and visual folding. To investigate the potential of monadic exploration we report on an iterative design process of a web-based visualization of a highly cross-referenced book and its six-month deployment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1535–1544},
numpages = {10},
keywords = {information visualization, exploratory search, network visualization, philosophy, theory, information seeking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557192,
author = {Yue, Zhen and Litt, Eden and Cai, Carrie J. and Stern, Jeff and Baxter, Kathy K. and Guan, Zhiwei and Sharma, Nikhil and Zhang, Guangqiang (George)},
title = {Photographing Information Needs: The Role of Photos in Experience Sampling Method-Style Research},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557192},
doi = {10.1145/2556288.2557192},
abstract = {The Experience Sampling Method (ESM) enables researchers to capture information about participants' experiences in the moment. Adding an end-of-day retrospective survey also allows participants to elaborate on those experiences. Although the use of photos in retrospective interviews and surveys for memory elicitation is well known, little research has investigated the use of photos in ESM studies. As smartphone adoption increases facilitating ESM studies and making photo sharing easier, researchers need to continuously evaluate the method and investigate the role of photos in such studies. We conducted a large-scale ESM and retrospective survey study via Android smartphones with more than 1,000 US participants, and analyzed participants' photo submissions, including how photo use correlated with participants' data quality and what, if any, value photos added for researchers. Our study sheds light on the role of photos in ESM and retrospective studies that researchers can reference when constructing future study designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1545–1554},
numpages = {10},
keywords = {retrospective study method, information need, experience sampling method, photo-elicitation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557284,
author = {Vigo, Markel and Jay, Caroline and Stevens, Robert},
title = {Design Insights for the next Wave Ontology Authoring Tools},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557284},
doi = {10.1145/2556288.2557284},
abstract = {Ontologies have been employed across scientific and business domains for some time, and the proliferation of linked data means the number and range of potential authors is set to increase significantly. Ontologies using the Web Ontology Language (OWL) are complex artefacts, however: the authoring process requires not only knowledge of the application domain, but also skills in programming and logics. To date, there has been no systematic attempt to understand the effectiveness of existing tools, or explore what users really require to build successful ontologies. Here we address this shortfall, presenting insights from an interview study with 15 ontology authors. We identify the problems reported by authors, and the strategies they employ to solve them. We map the data to a set of design recommendations, which describe how tools of the future can support ontology authoring. A key challenge is dealing with information overload: improving the user's ability to navigate, populate and debug large ontologies will revolutionise the engineering process, and open ontology authoring up to a new generation of users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1555–1558},
numpages = {4},
keywords = {ontologies, authoring tools, semantic web},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557337,
author = {Sun, Maoyuan and Bradel, Lauren and North, Chris L. and Ramakrishnan, Naren},
title = {The Role of Interactive Biclusters in Sensemaking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557337},
doi = {10.1145/2556288.2557337},
abstract = {Visual exploration of relationships within large, textual datasets is an important aid for human sensemaking. By understanding computed, structural relationships between entities of different types (e.g., people and locations), users can leverage domain expertise and intuition to determine the importance and relevance of these relationships for tasks, such as intelligence analysis. Biclusters are a potentially desirable method to facilitate this, because they reveal coordinated relationships that can represent meaningful relationships. Bixplorer, a visual analytics prototype, supports interactive exploration of textual datasets in a spatial workspace with biclusters. In this paper, we present results of a study that analyzes how users interact with biclusters to solve an intelligence analysis problem using Bixplorer. We found that biclusters played four principal roles in the analytical process: an effective starting point for analysis, a revealer of two levels of connections, an indicator of potentially important entities, and a useful label for clusters of organized information.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1559–1562},
numpages = {4},
keywords = {visual interaction, intelligence analysis, biclustering},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251009,
author = {Zhao, Shengdong},
title = {Session Details: Presentation Technologies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251009},
doi = {10.1145/3251009},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557161,
author = {Li, Xiang and Rekimoto, Jun},
title = {SmartVoice: A Presentation Support System for Overcoming the Language Barrier},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557161},
doi = {10.1145/2556288.2557161},
abstract = {In most cases, speeches or presentations at an international event are required to be given in a common language (e.g. English). However, for people who are not proficient in that common language, delivering presentations fluently is very difficult. Simultaneous translation seems to be a solution, but besides its high cost, simultaneous translation undermines the nature of the presentation by substituting the real voice of the lecturer as well as his/her emotions. In this paper, we propose "SmartVoice", a presentation support system, which aims to overcome language barriers. By tracking the lip motion of the lecturer, SmartVoice controls the playback of the narration, which is a sound data prepared in advance or created automatically using a voice synthesizer. SmartVoice also controls the intonation of the sound based on the position and shape of the lecturer's mouth. As the lecturer can talk at his/her own pace with the voice automatically following, it appears as if he/she talks in his/her own voice. In our user evaluation, we confirmed that audiences find it difficult to distinguish between the narration generated by SmartVoice and that by a real voice. We also discuss the possibility of applying SmartVoice to fields other than multi-language presentation support, such as Automated Dialogue Replacement and language study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1563–1570},
numpages = {8},
keywords = {user interface, facial actions, presentation support, language barrier, face tracking, lip sync},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557286,
author = {Trinh, Ha and Yatani, Koji and Edge, Darren},
title = {PitchPerfect: Integrated Rehearsal Environment for Structured Presentation Preparation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557286},
doi = {10.1145/2556288.2557286},
abstract = {Rehearsal is a critical component of preparing to give an oral presentation, yet it is frequently abbreviated, performed in ways that are inefficient or ineffective, or simply omitted. We conducted an exploratory study to understand the relationship between the theory and practice of presentation rehearsal, classifying our qualitative results into five themes to motivate more structured rehearsal support deeply integrated in slide presentation software. In a within-subject study (N=12) comparing against participants' existing rehearsal practices, we found that our resulting PitchPerfect system significantly improved overall presentation quality and content coverage as well as provided greater support for content mastery, time management, and confidence building.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1571–1580},
numpages = {10},
keywords = {presentation rehearsal, slideware, powerpoint},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557254,
author = {Chi, Pei-Yu and Lee, Bongshin and Drucker, Steven M.},
title = {DemoWiz: Re-Performing Software Demonstrations for a Live Presentation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557254},
doi = {10.1145/2556288.2557254},
abstract = {Showing a live software demonstration during a talk can be engaging, but it is often not easy: presenters may struggle with (or worry about) unexpected software crashes and encounter issues such as mismatched screen resolutions or faulty network connectivity. Furthermore, it can be difficult to recall the steps to show while talking and operating the system all at the same time. An alternative is to present with pre-recorded screencast videos. It is, however, challenging to precisely match the narration to the video when using existing video players. We introduce DemoWiz, a video presentation system that provides an increased awareness of upcoming actions through glanceable visualizations. DemoWiz supports better control of timing by overlaying visual cues and enabling lightweight editing. A user study shows that our design significantly improves the presenters' perceived ease of narration and timing compared to a system without visualizations that was similar to a standard playback control. Furthermore, nine (out of ten) participants preferred DemoWiz over the standard playback control with the last expressing no preference.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1581–1590},
numpages = {10},
keywords = {software demo, video, demo, demonstration, presentation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557389,
author = {Pschetz, Larissa and Yatani, Koji and Edge, Darren},
title = {TurningPoint: Narrative-Driven Presentation Planning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557389},
doi = {10.1145/2556288.2557389},
abstract = {Once upon a time, people told stories unencumbered by slides. What modern presentations gain through visual slide support, however, is often at the expense of storytelling. We present TurningPoint, a probe to investigate the potential use of narrative-driven talk planning in slideware. Our study of TurningPoint reveals a delicate balance between narrative templates focusing author attention in ways that save time, and fixating attention in ways that limit experimentation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1591–1594},
numpages = {4},
keywords = {storytelling, narrative templates, slide presentations},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251010,
author = {Huh, Jina},
title = {Session Details: Personal Health and Wellbeing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251010},
doi = {10.1145/3251010},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557236,
author = {Joshi, Anirudha and Rane, Mandar and Roy, Debjani and Emmadi, Nagraj and Srinivasan, Padma and Kumarasamy, N. and Pujari, Sanjay and Solomon, Davidson and Rodrigues, Rashmi and Saple, D.G. and Sen, Kamalika and Veldeman, Els and Rutten, Romain},
title = {Supporting Treatment of People Living with HIV / AIDS in Resource Limited Settings with IVRs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557236},
abstract = {We developed an interactive voice response (IVR) system called TAMA (Treatment Advice by Mobile Alerts) that provides treatment support to people living with HIV / AIDS (PLHA) in developing countries, who are on antiret-roviral therapy (ART). We deployed TAMA with 54 PLHA in 5 HIV clinics in India for a period of 12 weeks. During the study, we gathered feedback about TAMA's design and usage. Additionally, we conducted detailed qualitative interviews and analysed usage logs. We found that TAMA was usable and viable in the real life settings of PLHA and it had many desirable effects on their treatment adherence. We developed insights that inform the design of TAMA and some of these can be generalised to design of other long-term, frequent-use IVR applications for users in developing countries in the healthcare domain and beyond.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1595–1604},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557119,
author = {Brown, Deana and Ayo, Victoria and Grinter, Rebecca E.},
title = {Reflection through Design: Immigrant Women's Self-Reflection on Managing Health and Wellness},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557119},
doi = {10.1145/2556288.2557119},
abstract = {Women comprise nearly half of the immigrant population worldwide and are susceptible to a wider range of health challenges compared to immigrant men. We present the findings of four participatory design sessions with immigrant women from the Caribbean to identify health and wellness challenges they faced and to conceptualize technologies to help them manage these issues. Stress, dietary challenges (specifically obesity), mental health, and domestic abuse, as identified by the women, form the focal themes for the design sessions. Their design approaches emphasized rebuilding the support structure, reducing stressors through entertainment and relaxation and encouraging positive gradational lifestyle changes. In conceiving health and wellness technologies for immigrant women, our work highlights opportunities for HCI to consider the role of others (and who benefits) and to reflect on the role of design and the underlying values and themes designs encompass. Finally, we emphasize how the technologies conceived by these women support rather than replace social solutions to the health and wellness challenges faced by these and other immigrant women.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1605–1614},
numpages = {10},
keywords = {participatory design, culture, immigrant women, health and wellness, caribbean},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557077,
author = {Haimson, Oliver L. and Brubaker, Jed R. and Hayes, Gillian R.},
title = {DDFSeeks Same: Sexual Health-Related Language in Online Personal Ads for Men Who Have Sex with Men},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557077},
doi = {10.1145/2556288.2557077},
abstract = {The HIV/AIDS crisis of the 1980s fundamentally changed sexual practices of men who have sex with men (MSM) in the U.S., including increased usage of sexual health-related (SHR) language in personal advertisements. Analyzing online personal ads from Craigslist, we found a substantial increase in SHR language, from ~23% in 1988 to over 53% today, echoing continuing concern about rising HIV rates. We argue that SHR language in Craigslist ads can be used as a sensor to provide insight into HIV epidemiology as well as discourse among particular communities. We show a positive significant relationship between prevalence rate of HIV in an ad's location and use of SHR language in that location. Analysis highlights the opportunity for SHR information found in Craigslist personal ads to serve as a data source for HIV prevention research. More broadly, we argue for mining large-scale user-generated content to inform HCI design of health and other systems, and explore use of such data to examine temporal changes in language to facilitate improved user-interface design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1615–1624},
numpages = {10},
keywords = {hiv/aids, craigslist, computational linguistics, health informatics, personal ads, digital identity, lgbt, online dating},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557108,
author = {Vlahovic, Tatiana A. and Wang, Yi-Chia and Kraut, Robert E. and Levine, John M.},
title = {Support Matching and Satisfaction in an Online Breast Cancer Support Community},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557108},
doi = {10.1145/2556288.2557108},
abstract = {Research suggests that online health support benefits chronically ill users. Their satisfaction might be an indicator that they perceive group interactions as beneficial and a precursor to group commitment. We examined whether receiving emotional and informational support is satisfying in its own right, or whether satisfaction depends on matches between what users sought and what they received. Two studies collected judgments in a breast cancer support community of support users sought, support they received, and their expressed satisfaction. While receiving emotional or informational support in general positively predicted satisfaction, users expressed less satisfaction when they sought informational support but received emotional support. There was also a tendency for users to express more satisfaction when they sought and received informational support. On the other hand, users were equally satisfied with emotional and informational support after seeking emotional support. Implications for membership commitment and interventions in online support groups are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1625–1634},
numpages = {10},
keywords = {support groups, social support, computer-mediated communication, health informatics, breast cancer},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251011,
author = {Harrison, Steve},
title = {Session Details: Design Theory},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251011},
doi = {10.1145/3251011},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557342,
author = {Dalsgaard, Peter and Dindler, Christian},
title = {Between Theory and Practice: Bridging Concepts in HCI Research},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557342},
doi = {10.1145/2556288.2557342},
abstract = {We present the notion of "bridging concepts" as a particular form of intermediary knowledge in HCI research, residing between theory and practice. We argue that bridging concepts address the challenge of facilitating exchange between theory and practice in HCI, and we compare it to other intermediary forms of knowledge such as strong concepts and conceptual constructs. We propose that bridging concepts have three defining constituents: a theoretical foundation, a set of design articulations and a range of exemplars that demonstrate the scope and potential of their application. These constituents specify how bridging concepts, as a form of knowledge, are accountable to both theory and practice. We present an analysis of the concept of "peepholes" as an example of a bridging concept aimed at spurring user curiosity and engagement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1635–1644},
numpages = {10},
keywords = {analytical frameworks, engagement, interaction design theory, experience-oriented design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557264,
author = {Gray, Colin M.},
title = {Evolution of Design Competence in UX Practice},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557264},
abstract = {There has been increasing interest in the adoption of UX within corporate environments, and what competencies translate into effective UX design. This paper addresses the space between pedagogy and UX practice through the lens of competence, with the goal of understanding how students are initiated into the practice community, how their perception of competence shifts over time, and what factors influence this shift. A 12-week longitudinal data collection, including surveys and interviews, documents this shift, with participants beginning internships and full-time positions in UX. Students and early professionals were asked to assess their level of competence and factors that influenced competence. A co-construction of identity between the designer and their environment is proposed, with a variety of factors relating to tool and representational knowledge, complexity, and corporate culture influencing perceptions of competence in UX over time. Opportunities for future research, particularly in building an understanding of competency in UX based on this preliminary framing of early UX practice are addressed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1645–1654},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557216,
author = {Darlow, Adam and Goldin, Gideon and Sloman, Steven},
title = {Causal Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557216},
doi = {10.1145/2556288.2557216},
abstract = {In this paper we present two design guidelines, causal order and continuity, to be used as rules of thumb for designing intuitive interactions based on principles of causal reasoning. We propose that designing interactions to behave like real-world systems of cause and effect makes them more intuitive. Using these basic principles avoids the limitations inherent to specific metaphors. In three experiments, participants solved puzzles using variations of a novel graphical interface. Participants using interfaces that were consistent with the causal guidelines consistently solved the puzzle faster than participants using inconsistent interfaces. We also discuss common interactions already consistent with the causal guidelines as well as areas where the guidelines are likely to apply successfully. The causal order guidelines provide specific utility while also demonstrating how principles of causal psychology can be applied to help interface designers better convey the functionality of their interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1655–1664},
numpages = {10},
keywords = {graphical interfaces, design guidelines, psychology, gui, causal reasoning, interaction design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557080,
author = {Nielsen, Lene and Storgaard Hansen, Kira},
title = {Personas is Applicable: A Study on the Use of Personas in Denmark},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557080},
doi = {10.1145/2556288.2557080},
abstract = {The persona method is gaining widespread use and support. Many researchers have reported from single cases and novel domains how they have used the method. Few have conducted literature studies in order to identify and discuss the different understandings of the method. Fewer still have reported on ethnographic studies of practice. This paper falls within the last category, reporting on a study on how practitioners in Denmark use the method, and their perceptions of benefits and challenges when using the method. Finally, different casts of personas obtained from the involved companies are analyzed. The findings are compared to reported studies of practice. Contrary to the existing findings the study reports that the method is well integrated into existing practices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1665–1674},
numpages = {10},
keywords = {practice-study, application, personas, scenarios},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251012,
author = {Lyons, Kent},
title = {Session Details: Novel Keyboards},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251012},
doi = {10.1145/3251012},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557362,
author = {Zhang, Haimo and Li, Yang},
title = {GestKeyboard: Enabling Gesture-Based Interaction on Ordinary Physical Keyboard},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557362},
doi = {10.1145/2556288.2557362},
abstract = {Stroke gestures are intuitive and efficient but often require gesture-capable input hardware such as a touchscreen. In this paper, we present GestKeyboard, a novel technique for gesturing over an ordinary, unmodified physical keyboard that remains the major input modality for existing desktop and laptop computers. We discuss an exploratory study for understanding the design space of gesturing on a physical keyboard and our algorithms for detecting gestures in a modeless way, without interfering with the keyboard's major functionality such as text entry and shortcuts activation. We explored various features for detecting gestures from a keyboard event stream. Our experiment based on the data collected from 10 participants indicated it is feasible to reliably detect gestures from normal keyboard use, 95% detection accuracy within a maximum latency of 200ms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1675–1684},
numpages = {10},
keywords = {modeless interaction, physical keyboard, gesture detection},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557263,
author = {L\"{u}, Hao and Fogarty, James A. and Li, Yang},
title = {Gesture Script: Recognizing Gestures and Their Structure Using Rendering Scripts and Interactively Trained Parts},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557263},
doi = {10.1145/2556288.2557263},
abstract = {Gesture-based interactions have become an essential part of the modern user interface. However, it remains challenging for developers to create gestures for their applications. This paper studies unistroke gestures, an important category of gestures defined by their single-stroke trajectories. We present Gesture Script, a tool for creating unistroke gesture recognizers. Gesture Script enhances example-based learning with interactive declarative guidance through rendering scripts and interactively trained parts. The structural information from the rendering scripts allows Gesture Script to synthesize gesture variations and generate a more accurate recognizer that also automatically extracts gesture attributes needed by applications. The results of our study with developers show that Gesture Script preserves the threshold of familiar example based gesture tools, while raising the ceiling of the recognizers created in such tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1685–1694},
numpages = {10},
keywords = {gesture recognition, interactive machine learning},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557030,
author = {Taylor, Stuart and Keskin, Cem and Hilliges, Otmar and Izadi, Shahram and Helmes, John},
title = {Type-Hover-Swipe in 96 Bytes: A Motion Sensing Mechanical Keyboard},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557030},
doi = {10.1145/2556288.2557030},
abstract = {We present a new type of augmented mechanical keyboard, capable of sensing rich and expressive motion gestures performed both on and directly above the device. Our hardware comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed between the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest based classifier to robustly recognize a large set of motion gestures on and directly above the keyboard. Our technique achieves a mean per-frame classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training cross-validation. We detail our hardware and gesture recognition algorithm, provide performance and accuracy numbers, and demonstrate a large set of gestures designed to be performed with our device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1695–1704},
numpages = {10},
keywords = {keyboard, input devices, gesture recognition},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557269,
author = {Nicolau, Hugo and Montague, Kyle and Guerreiro, Tiago and Guerreiro, Jo\~{a}o and Hanson, Vicki L.},
title = {B#: Chord-Based Correction for Multitouch Braille Input},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557269},
doi = {10.1145/2556288.2557269},
abstract = {Braille has paved its way into mobile touchscreen devices, providing faster text input for blind people. This advantage comes at the cost of accuracy, as chord typing over a flat surface has proven to be highly error prone. A misplaced finger on the screen translates into a different or unrecognized character. However, the chord itself gathers information that can be leveraged to improve input performance. We present B#, a novel correction system for multitouch Braille input that uses chords as the atomic unit of information rather than characters. Experimental results on data collected from 11 blind people revealed that B# is effective in correcting errors at character-level, thus providing opportunities for instant corrections of unrecognized chords; and at word-level, where it outperforms a popular spellchecker by providing correct suggestions for 72% of incorrect words (against 38%). We finish with implications for designing chord-based correction system and avenues for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1705–1708},
numpages = {4},
keywords = {mobile, error correction, chord, touchscreen, braille},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557024,
author = {Leiva, Luis A. and Sanchis-Trilles, Germ\'{a}n},
title = {Representatively Memorable: Sampling the Right Phrase Set to Get the Text Entry Experiment Right},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557024},
doi = {10.1145/2556288.2557024},
abstract = {In text entry experiments, memorability is a desired property of the phrases used as stimuli. Unfortunately, to date there is no automated method to achieve this effect. As a result, researchers have to use either manually curated English-only phrase sets or sampling procedures that do not guarantee phrases being memorable. In response to this need, we present a novel sampling method based on two core ideas: a multiple regression model over language-independent features, and the statistical analysis of the corpus from which phrases will be drawn. Our results show that researchers can finally use a method to successfully curate their own stimuli targeting potentially any language or domain. The source code as well as our phrase sets are publicly available.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1709–1712},
numpages = {4},
keywords = {text entry, representativeness, memorability, sampling},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251013,
author = {Hornbaek, Kasper},
title = {Session Details: DIY and Hacking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251013},
doi = {10.1145/3251013},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557391,
author = {Qi, Jie and Buechley, Leah},
title = {Sketching in Circuits: Designing and Building Electronics on Paper},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557391},
doi = {10.1145/2556288.2557391},
abstract = {The field of new methods and techniques for building electronics is quickly growing - from research in new materials for circuit building, to modular toolkits, and more recently to untoolkits, which aim to incorporate more off-the-shelf parts. However, the standard mediums for circuit design and construction remain the breadboard, protoboard, and printed circuit board (PCB). As an alternative, we introduce a method in which circuits are hand-made on ordinary paper substrates, connected with conductive foil tape and off-the-shelf circuit components with the aim of supporting the durability, scalability, and accessibility needs of novice and expert circuit builders alike. We also used electrified notebooks to investigate how the circuit design and build process would be affected by the constraints and affordances of the bound book. Our ideas and techniques were evaluated through a series of workshops, through which we found our methods supported a wide variety of approaches and results - both technical and expressive - to electronics design and construction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1713–1722},
numpages = {10},
keywords = {toolkits, circuit prototyping, sketchbooks, paper computing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557309,
author = {Mellis, David A. and Buechley, Leah},
title = {Do-It-Yourself Cellphones: An Investigation into the Possibilities and Limits of High-Tech Diy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557309},
doi = {10.1145/2556288.2557309},
abstract = {This paper describes our do-it-yourself cellphone and our use of it to investigate the possibilities and limits of high-tech DIY practice. We describe our autobiographical approach -- making the phone and using it in our daily lives -- and our work disseminating the cellphone in workshops and online. This informs a discussion of the implications of technology for DIY practice. We suggest an understanding of DIY as an individual's ability to combine existing technologies into a desired product, enabled and limited by ecosystems of industrial actors and individuals. We distinguish different pathways into high-tech DIY practice, consider the relationship between prototyping and production, and discuss the effect of technology on DIY's relevance and tools, and on notions of transparency. We conclude by reflecting on the relationship between DIY and empowerment: the extent to which making devices gives people control over the technology in their lives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1723–1732},
numpages = {10},
keywords = {microcontrollers, toolkits, diy, prototyping, digital fabrication, electronics, cellphone},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557046,
author = {Ishiguro, Yoshio and Poupyrev, Ivan},
title = {3D Printed Interactive Speakers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557046},
doi = {10.1145/2556288.2557046},
abstract = {We propose technology for designing and manufacturing interactive 3D printed speakers. With the proposed technology, sound reproduction can easily be integrated into vari-ous objects at the design stage and little assembly is required. The speaker can take the shape of anything from an abstract spiral to a rubber duck, opening new opportunities in product design. Furthermore, both audible sound and inaudible ultrasound can be produced with the same design, allowing for identifying and tracking 3D printed objects in space using common integrated microphones. The design of 3D printed speakers is based on electrostatic loudspeaker technology first explored in the early 1930s but not broadly applied until now. These speakers are simpler than common electromagnetic speakers, while allowing for sound reproduction at 60 dB levels with arbitrary directivity ranging from focused to omnidirectional. Our research of 3D printed speakers contributes to the growing body of work exploring functional 3D printing in interactive applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1733–1742},
numpages = {10},
keywords = {ultrasonic, 3d printing, speakers, audio, tracking, rapid prototyping, additive manufacturing, tangible},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557150,
author = {Hodges, Steve and Villar, Nicolas and Chen, Nicholas and Chugh, Tushar and Qi, Jie and Nowacka, Diana and Kawahara, Yoshihiro},
title = {Circuit Stickers: Peel-and-Stick Construction of Interactive Electronic Prototypes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557150},
doi = {10.1145/2556288.2557150},
abstract = {We present a novel approach to the construction of electronic prototypes which can support a variety of interactive devices. Our technique, which we call circuit stickers, involves adhering physical interface elements such as LEDs, sounders, buttons and sensors onto a cheap and easy-to-make substrate which provides electrical connectivity. This assembly may include control electronics and a battery for standalone operation, or it can be interfaced to a microcontroller or PC. In this paper we illustrate different points in the design space and demonstrate the technical feasibility of our approach. We have found circuit stickers to be versatile and low-cost, supporting quick and easy construction of physically flexible interactive prototypes. Building extra copies of a device is straightforward. We believe this technology has potential for design exploration, research proto-typing, education and for hobbyist projects.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1743–1746},
numpages = {4},
keywords = {silver ink, rapid prototyping, physical computing, conductive inkjet, solderless electronics, tangible interfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251014,
author = {Brumby, Duncan},
title = {Session Details: User Models and Prediction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251014},
doi = {10.1145/3251014},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557355,
author = {Nicosia, Max and Oulasvirta, Antti and Kristensson, Per Ola},
title = {Modeling the Perception of User Performance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557355},
doi = {10.1145/2556288.2557355},
abstract = {This paper studies how users perceive their own performance in two alternative user interfaces. We extend methodology from psychophysics to the study of interactive performance and conduct two experiments in order to create a model of users' perception of their own performance. In our studies, two interfaces are sequentially used in a pointing task, and users are asked to rate in which interface their performance was higher. We first differentiate the effects of objective performance (speed and accuracy) versus interface qualities (distance between elements and width of elements) on perceived performance. We then derive a model that predicts the amount of change required in an interface for users to reliably detect a difference. The model is useful as a heuristic for predicting if a new interface design is better enough for users to reliably appreciate the obtained gain in user performance. We validate the model via a separate user study, and conclude by discussing how to apply our findings to design problems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1747–1756},
numpages = {10},
keywords = {psychophysics, perception of user performance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557191,
author = {Zade, Himanshu and Adimoolam, Santosh Arvind and Gollapudi, Sai and Dey, Anind K. and Choppella, Venkatesh},
title = {Edit Distance modulo Bisimulation: A Quantitative Measure to Study Evolution of User Models},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557191},
doi = {10.1145/2556288.2557191},
abstract = {When a user learns to use a new device, her understanding of it evolves. A progressive comparison of the evolving user models towards the device target model, for analysing learning, involves determining the behavioral proximity between them. To quantify the gap between a user model and a target model, we introduce an edit distance metric for measuring their behavioral proximity using a bisimulation-based equivalence relation. We define edit distance to be the minimum number of edges and states with incident edges required to be deleted from and/or added to a user model to make it bisimilar to the target model. We propose an algorithm to compute edit distance between two models and employ the heuristic procedure on experimental data for computing edit distance between target and user models. The data is organised into two experiments depending on the device the user interacted with: (a) a simple device resembling a vending machine and (b) a close to real-world vehicle transmission model. The results validate our proposed metric as edit distance converges with progressive user learning, increases for erroneous learning, and remains unchanged indicating no learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1757–1766},
numpages = {10},
keywords = {learning, behavioral proximity., finite state machines},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557422,
author = {Trafton, J. Gregory and Ratwani, Raj M.},
title = {The Law of Unintended Consequences: The Case of External Subgoal Support},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557422},
doi = {10.1145/2556288.2557422},
abstract = {Many interfaces have been designed to prevent or reduce errors. These interfaces may, in fact, reduce the error rate of specific error classes, but may also have unintended consequences. In this paper, we show a series of studies where a better interface did not reduce the number of errors but instead shifted errors from one error class (omissions) to another error class (perseverations). We also show that having access to progress tracking (a progress bar) does not reduce the number of errors. We propose and demonstrate a solution -- a predictive error system -- that reduces errors based on the error class, not on the type of interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1767–1776},
numpages = {10},
keywords = {error prediction, progress tracking, computer human interaction, interface subgoal support},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2556990,
author = {Nancel, Mathieu and Cockburn, Andy},
title = {Causality: A Conceptual Model of Interaction History},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556990},
abstract = {Simple history systems such as Undo and Redo permit retrieval of earlier or later interaction states, but advanced systems allow powerful capabilities to reuse or reapply combinations of commands, states, or data across interaction contexts. Whether simple or powerful, designing interaction history mechanisms is challenging. We begin by reviewing existing history systems and models, observing a lack of tools to assist designers and researchers in specifying, contemplating, combining, and communicating the behaviour of history systems. To resolve this problem, we present CAUSALITY, a conceptual model of interaction history that clarifies the possibilities for temporal interactions. The model includes components for the work artifact (such as the text and formatting of a Word document), the system context (such as the settings and parameters of the user interface), the linear timeline (the commands executed in real time), and the branching chronology (a structure of executed commands and their impact on the artifact and/or context, which may be navigable by the user). We then describe and exemplify how this model can be used to encapsulate existing user interfaces and reveal limitations in their behaviour, and we also show in a conceptual evaluation how the model stimulates the design of new and innovative opportunities for interacting in time.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1777–1786},
numpages = {10}
}

@inbook{10.1145/3251015,
author = {Kientz, Julie},
title = {Session Details: Engage and Educate Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251015},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1}
}

@inproceedings{10.1145/2556288.2557280,
author = {Hyde, Jennifer and Kiesler, Sara and Hodgins, Jessica K. and Carter, Elizabeth J.},
title = {Conversing with Children: Cartoon and Video People Elicit Similar Conversational Behaviors},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557280},
doi = {10.1145/2556288.2557280},
abstract = {Interactive animated characters have the potential to engage and educate children, but there is little research on children's interactions with animated characters and real people. We conducted an experiment with 69 children between the ages of 4 and 10 years to investigate how they might engage in conversation differently if their interactive partner appeared as a cartoon character or as a person. A subset of the participants interacted with characters that displayed exaggerated and damped facial motion. The children completed two conversations with an adult confederate who appeared once as herself through video and once as a cartoon character. We measured how much the children spoke and compared their gaze and gesture patterns. We asked them to rate their conversations and indicate their preferred partner. There was no difference in children's conversation behavior with the cartoon character and the person on video, even among those who preferred the person and when the cartoon exhibited altered motion. These results suggest that children will interact with animated characters as they would another person.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1787–1796},
numpages = {10},
keywords = {animated character, children, avatar, facial motion, conversation, behavior, agent},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557128,
author = {Hashish, Yasmeen and Bunt, Andrea and Young, James E.},
title = {Involving Children in Content Control: A Collaborative and Education-Oriented Content Filtering Approach},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557128},
doi = {10.1145/2556288.2557128},
abstract = {We present an approach to content control where parents and children collaboratively configure restrictions and filters, an approach that focuses on education rather than simple rule setting. We conducted an initial exploratory qualitative study with results highlighting the importance that parents place on avoiding inappropriate content. Building on these findings, we designed an initial prototype which allows parents and children to work together to select appropriate applications, providing an opportunity for parents to educate their children on what is appropriate. A second qualitative study with parents and children in the six to eight year-old age group revealed a favorable response to this approach. Our results suggest that parents felt that this approach helped facilitate discussions with their children and made the education more enjoyable and approachable, and that children may have also learned from the interaction. In addition, the approach provided some parents with insights into their children's interests and understanding of their notions of appropriate and inappropriate content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1797–1806},
numpages = {10},
keywords = {parental control strategies, collaborative content filtering, children and technology},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557205,
author = {Tewari, Anuj and Canny, John},
title = {What Did Spot Hide? A Question-Answering Game for Preschool Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557205},
doi = {10.1145/2556288.2557205},
abstract = {Early literacy is critical to child development, and determines a child's later educational and life opportunities. Moreover, preschool children are incessantly inquisitive, and will readily engage in question answering and asking activities if given the opportunity. We argue here that question asking/answering technologies can play a major role in early literacy. We describe the design and evaluation of a conversational agent called Spot, with the goal of engaging children in a 20-questions game. Towards this goal, we conducted a feasibility study to determine if children's questions are "on-topic" and suitable for ASR/dialogue systems. We evaluated Spot's performance at conducting a game of 20-questions against that of a human partner.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1807–1816},
numpages = {10},
keywords = {games, conversational agents, question-answering, preschool literacy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557402,
author = {Hamidi, Foad and Baljko, Melanie},
title = {Rafigh: A Living Media Interface for Speech Intervention},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557402},
doi = {10.1145/2556288.2557402},
abstract = {Digital games can engage children in therapeutic and learning activities. Incorporating living media in these designs can create feelings of empathy and caring in users. We present, Rafigh, a living media interface designed to motivate children with speech disorders to use their speech to care for a living mushroom colony. The mushrooms' growth is used to communicate how much speech is used during interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1817–1820},
numpages = {4},
keywords = {embedded computing, speech intervention, living media interfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557031,
author = {Gossen, Tatiana and H\"{o}bel, Juliane and N\"{u}rnberger, Andreas},
title = {A Comparative Study about Children's and Adults' Perception of Targeted Web Search Engines},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557031},
doi = {10.1145/2556288.2557031},
abstract = {In this paper we describe an eye-tracking study where we compare children's and adults' search behavior and perception of search interface elements on search engine results pages (SERPs) during an informational and a navigational search with Google and a search engine for children. Our first results indicate that children employ an exhaustive scanning strategy combined with cued visual jumps. Then they navigate to the next result page and only then modify their query. Adults only scan the first three results, following the F-shaped strategy, and immediately reformulate the query. Children pay less attention to textual summaries and more to thumbnails than adults do. Children take notice of a navigational menu with categories while adults do not.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1821–1824},
numpages = {4},
keywords = {search engine, children, eye-tracker, user study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251016,
author = {Dragicevic, Pierre},
title = {Session Details: Studying Visualization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251016},
doi = {10.1145/3251016},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557112,
author = {Alper, Basak E. and Henry Riche, Nathalie and Hollerer, Tobias},
title = {Structuring the Space: A Study on Enriching Node-Link Diagrams with Visual References},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557112},
abstract = {Exploring large visualizations that do not fit in the screen raises orientation and navigation challenges. Structuring the space with additional visual references such as grids or contour lines provide spatial landmarks that may help viewers form a mental model of the space. However, previous studies report mixed results regarding their utility. While some evidence showed that grid and other visual embellishments improve memorability, experiments with contour lines suggest otherwise. In this work, we describe an evaluation framework to capture the impact of introducing visual references in node-link diagrams. We present the results of three controlled experiments that deepen our understanding on enriching large visualization spaces with visual structures. In particular, we provide the first tangible evidence that contour lines have significant benefits when navigating large node-link diagrams.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1825–1834},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557141,
author = {Carenini, Giuseppe and Conati, Cristina and Hoque, Enamul and Steichen, Ben and Toker, Dereck and Enns, James},
title = {Highlighting Interventions and User Differences: Informing Adaptive Information Visualization Support},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557141},
doi = {10.1145/2556288.2557141},
abstract = {There is increasing evidence that the effectiveness of information visualization techniques can be impacted by the particular needs and abilities of each user. This suggests that it is important to investigate information visualization systems that can dynamically adapt to each user. In this paper, we address the question of how to adapt. In particular, we present a study to evaluate a variety of visual prompts, called "interventions", that can be performed on a visualization to help users process it. Our results show that some of the tested interventions perform better than a condition in which no intervention is provided, both in terms of task performance as well as subjective user ratings. We also discuss findings on how intervention effectiveness is influenced by individual differences and task complexity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1835–1844},
numpages = {10},
keywords = {adaptive information visualization, user characteristics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251017,
author = {Edge, Darren},
title = {Session Details: Exploring Exergames},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251017},
doi = {10.1145/3251017},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557385,
author = {Sheinin, Mike and Gutwin, Carl},
title = {Exertion in the Small: Improving Differentiation and Expressiveness in Sports Games with Physical Controls},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557385},
doi = {10.1145/2556288.2557385},
abstract = {Many sports video games contain elements such as running or throwing that are based on real-world physical activities, but the translation of these activities to game controllers means that the original physicality is lost. This results in games where players have limited opportunity to improve their physical skills, where there is little differentiation in people's physical abilities, and where skills do not change over the course of a game. To explore ways of adding these elements back into sports games, we developed two games with small-scale physical controls for running and throwing -- one game was a simple running race, and one was a team-based handball-style game called Jelly Polo. In two studies (three track-and-field tournaments for the running game, and a four-week league for Jelly Polo), we observed the effects of physical controls on gameplay. Our studies showed that the physical controls enabled substantial individual differences in running and passing skill, allowed people to increase their expertise over time, and led to fatigue-based changes in performance during a game. Physical controls increased the games' challenge, complexity, and unpredictability, and dramatically improved player interest, expressiveness, and enjoyment. Our work shows that game designers should consider the idea of "exertion in the small" as a way to improve play experience in games based on physical activities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1845–1854},
numpages = {10},
keywords = {physical controls, sports video games, exertion games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557246,
author = {Chen, Frank X. and King, Abby C. and Hekler, Eric B.},
title = {"healthifying" Exergames: Improving Health Outcomes through Intentional Priming},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557246},
doi = {10.1145/2556288.2557246},
abstract = {Exergames, video game systems that require exertion and interaction, have been rising in popularity in the past years. However, research on popular exergames shows mixed health benefits, potentially due to minimal energy expenditure and decreasing use over time. This paper presents a 2x2 experimental study (N = 44), using a popular exergame, where we vary the framing of intention (i.e., "Gameplay" or "Exercise") and feedback (i.e., "Health" or "No health") to explore their single and interactive impacts on perceived exertion, objectively measured energy expenditure, affect, and duration of usage in a single session. Our study showed that participants primed with exercise used the system significantly longer than those primed with game play (M = 49.2 ±2.0 min versus M = 39.3 ±2.0 min). We discuss our results and possible design implications based on our single-session experiment. We conclude with a discussion on the potential impact of focusing on "healthifying" exergames -highlighting an exergames" dual purpose as both a game and exercise - as opposed to gamifying health behaviors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1855–1864},
numpages = {10},
keywords = {priming, persuasive technology, exergaming, fitness},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557091,
author = {Park, Taiwoo and Lee, Uichin and MacKenzie, Scott and Moon, Miri and Hwang, Inseok and Song, Junehwa},
title = {Human Factors of Speed-Based Exergame Controllers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557091},
doi = {10.1145/2556288.2557091},
abstract = {Exergame controllers are intended to add fun to monotonous exercise. However, studies on exergame controllers mostly focus on designing new controllers and exploring specific application domains without analyzing human factors, such as performance, comfort, and effort. In this paper, we examine the characteristics of a speed-based exergame controller that bear on human factors related to body movement and exercise. Users performed tasks such as changing and maintaining exercise speed for avatar control while their performance was measured. The exergame controller follows Fitts' law, but requires longer movement time than a gamepad and Wiimote. As well, resistance force and target speed affect performance. User experience data confirm that the comfort and mental effort are adequate as practical game controllers. The paper concludes with discussion on applying our findings to practical exergame design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1865–1874},
numpages = {10},
keywords = {exergame, speed-based control, game controller},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557329,
author = {Zaczynski, Monica and Whitehead, Anthony D.},
title = {Establishing Design Guidelines in Interactive Exercise Gaming: Preliminary Data from Two Posing Studies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557329},
doi = {10.1145/2556288.2557329},
abstract = {Interactive gaming has demonstrated promise as a low-cost, at-home training and fitness instruction alternative. Gaming systems offer convenience and the ability to provide enhanced reporting and progress data if body measurement information is collected effectively. However, commercially available systems today are designed primarily for entertainment and as a result, the quality of instruction delivery and level of involvement may not meet the needs of a user performing a disciplined activity.This paper will look at adapting for occlusion and lack of visibility; learning and orientation; and providing feedback in an effort to determine if there is an ideal visual demonstration delivery that maximizes pose understanding and user self-efficacy, determine whether supplementary modalities are important for instruction, and determine if there is an ideal feedback delivery that promotes pose comprehension, confidence and motivation. This information can provide a guideline for designing clear and supportive, interactive training systems that can engage users, prevent injury and help maintain fitness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1875–1884},
numpages = {10},
keywords = {panning, visual delivery, design guidelines, wii balance board, haptic feedback, feedback, yoga, usability, low-paced exercise training},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251018,
author = {Kelliher, Aisling},
title = {Session Details: Narratives and Storytelling},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251018},
doi = {10.1145/3251018},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557034,
author = {Wood, Gavin and Vines, John and Balaam, Madeline and Taylor, Nick and Smith, Thomas and Crivellaro, Clara and Mensah, Juliana and Limon, Helen and Challis, John and Anderson, Linda and Clarke, Adam and Wright, Peter C.},
title = {The Department of Hidden Stories: Playful Digital Storytelling for Children in a Public Library},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557034},
doi = {10.1145/2556288.2557034},
abstract = {We detail the design of the Department of Hidden Stories (DoHS), a mobile-based game to support playful digital storytelling among primary school children in public libraries. Through a process of iterative design in collaboration with library staff and children's writers we designed DoHS to support the potential for playful storytelling through interactions with books. A deployment of DoHS with two classes of 8 to 10 years olds as part of their regular library visits revealed insights related to how to balance the expectations of a child-at-play and the requirement to further develop their creative reading and writing skills. Based on our experiences we recommend that designers create playful digitally based activities that encourage children to explore libraries and experience new interactions with physical books.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1885–1894},
numpages = {10},
keywords = {play, children's library, augmenting books, storytelling},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557296,
author = {Andrews, Daniel and Baber, Chris},
title = {Visualizing Interactive Narratives: Employing a Branching Comic to Tell a Story and Show Its Readings},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557296},
doi = {10.1145/2556288.2557296},
abstract = {This paper describes the design and evaluation of a branching comic to compare how readers recall a visual narrative when presented as an interactive, digital program, or as a linear sequence on paper. The layout of the comic is used to visualize this data as heat maps and explore patterns of users' recollections. We describe the theoretical justification for this based upon previous work in narrative visualizations, interactive stories and comics. Having tested the comic with school boys aged 11-12; we saw patterns in the data that complement other research in both interactive stories and visualizations. We argue that the heat maps helped identify these patterns, which have implications for future designs and analyses of interactive visual and/or narrative media.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1895–1904},
numpages = {10},
keywords = {interactive stories, narrative visualization, branching comics, story comprehension},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557339,
author = {Huang, Jin and Yu, Chun and Wang, Yuntao and Zhao, Yuhang and Liu, Siqi and Mo, Chou and Liu, Jie and Zhang, Lie and Shi, Yuanchun},
title = {FOCUS: Enhancing Children's Engagement in Reading by Using Contextual BCI Training Sessions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557339},
abstract = {Reading is an important aspect of a child's development. Reading outcome is heavily dependent on the level of engagement while reading. In this paper, we present FOCUS, an EEG-augmented reading system which monitors a child's engagement level in real time, and provides contextual BCI training sessions to improve a child's reading engagement. A laboratory experiment was conducted to assess the validity of the system. Results showed that FOCUS could significantly improve engagement in terms of both EEG-based measurement and teachers' subjective measure on the reading outcome.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1905–1908},
numpages = {4}
}

@inproceedings{10.1145/2556288.2557154,
author = {Wang, Chen and Geelhoed, Erik N. and Stenton, Phil P. and Cesar, Pablo},
title = {Sensing a Live Audience},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557154},
doi = {10.1145/2556288.2557154},
abstract = {Psychophysiological measurement has the potential to play an important role in audience research. Currently, such research is still in its infancy and it usually involves collecting data in the laboratory, where during each experimental session one individual watches a video recording of a performance. We extend the experimental paradigm by simultaneously measuring Galvanic Skin Response (GSR) of a group of participants during a live performance. GSR data were synchronized with video footage of performers and audience. In conjunction with questionnaire data, this enabled us to identify a strongly correlated main group of participants, describe the nature of their theatre experience and map out a minute-by-minute unfolding of the performance in terms of psycho-physiological engagement. The benefits of our approach are twofold. It provides a robust and accurate mechanism for assessing a performance. Moreover, our infrastructure can enable, in the future, real-time feedback from remote audiences for online performances.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1909–1912},
numpages = {4},
keywords = {audience engagement, galvanic skin response.},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251019,
author = {Hanson, Vicki},
title = {Session Details: Designing for Older Adults and Demographic Change},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251019},
doi = {10.1145/3251019},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557124,
author = {Haddad, Shathel and McGrenere, Joanna and Jacova, Claudia},
title = {Interface Design for Older Adults with Varying Cultural Attitudes toward Uncertainty},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557124},
doi = {10.1145/2556288.2557124},
abstract = {This work reports on the design and evaluation of culturally appropriate technology for older adults. Our design context was Cognitive Testing on a Computer (C-TOC): a self-administered computerized test under development, intended to screen older adults for cognitive impairments. Using theory triangulation of cultural attitudes toward uncertainty, we designed two interfaces (one minimal and one rich) for one C-TOC subtest and hypothesized they would be culturally appropriate for older adult Caucasians and East Asians respectively. We ran an experiment with 36 participants to investigate cultural differences in performance, preference and anxiety. We found that Caucasians preferred the interface with minimal elements (i.e. those essential for the primary task) or had no preference. By contrast, East Asians preferred the rich interface augmented with security and learning support and felt less anxious with it than the minimal.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1913–1922},
numpages = {10},
keywords = {older adults, experiment, uncertainty avoidance, cultural design, computerized cognitive assessment},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557300,
author = {Meurer, Johanna and Stein, Martin and Randall, David and Rohde, Markus and Wulf, Volker},
title = {Social Dependency and Mobile Autonomy: Supporting Older Adults' Mobility with Ridesharing Ict},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557300},
doi = {10.1145/2556288.2557300},
abstract = {Alternative mobility modes for older adults are increasingly important for economic, ecological and social reasons. A promising option is ridesharing, defined as use of the same vehicle by two or more people traveling to a common destination. In particular, mobile computer supported ridesharing provides a promising way to enlarge older adults' mobility choices in addition to private driving and public transportation options. In order to understand the opportunities and obstacles of ridesharing from the point of view of elderly people, we conducted an interview study in order to examining ridesharing experiences. It turns out that "mobile independence" and "decisional autonomy" are key issues for mobile wellbeing. This partially conflicts with common ridesharing concepts. Hence, we further analyze older adults' strategies dealing with these conflicts and show that these strategies offer departure points for the design ridesharing solutions, which are better suited to the demands of older adults.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1923–1932},
numpages = {10},
keywords = {design, dynamic ridesharing, social experiences, elderly, ethnography},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557084,
author = {Arreola, Ingrid and Morris, Zan and Francisco, Matthew and Connelly, Kay and Caine, Kelly and White, Ginger},
title = {From Checking on to Checking in: Designing for Low Socio-Economic Status Older Adults},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557084},
doi = {10.1145/2556288.2557084},
abstract = {In this paper we describe the design evolution of a novel technology that collects and displays presence information to be used in the homes of older adults. The first two iterations, the Ambient Plant and Presence Clock, were designed for higher socio-economic status (SES) older adults, whereas the Check-In Tree was designed for low SES older adults. We describe how feedback from older adult participants drove our design decisions, and give an in-depth account of how the Check-In Tree evolved from concept to a final design ready for in situ deployment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1933–1936},
numpages = {4},
keywords = {peer production, aging in place, caregivers, older adults},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557314,
author = {Vaisutis, Kate and Brereton, Margot and Robertson, Toni and Vetere, Frank and Durick, Jeannette and Nansen, Bjorn and Buys, Laurie},
title = {Invisible Connections: Investigating Older People's Emotions and Social Relations around Objects},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557314},
doi = {10.1145/2556288.2557314},
abstract = {The advent of the Internet of Things creates an interest in how people might interrelate through and with networks of internet enabled objects. With an emphasis on fostering social connection and physical activity among older people, this preliminary study investigated objects that people over the age of 65 years viewed as significant to them. We conducted contextual interviews in people's homes about their significant objects in order to understand the role of the objects in their lives, the extent to which they fostered emotional and social connections and physical activity, and how they might be augmented through internet connection.Discussion of significant objects generated considerable emotion in the participants. We identified objects of comfort and routine, objects that exhibited status, those that fostered independence and connection, and those that symbolized relationships with loved ones. These findings lead us to consider implications for the design of interconnected objects.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1937–1940},
numpages = {4},
keywords = {ageing, tangible interaction, social relations, socio-material relations, objects, internet of things},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251020,
author = {Parker, Andrea},
title = {Session Details: Critical Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251020},
doi = {10.1145/3251020},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557055,
author = {Feinberg, Melanie and Carter, Daniel and Bullard, Julia},
title = {Always Somewhere, Never There: Using Critical Design to Understand Database Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557055},
doi = {10.1145/2556288.2557055},
abstract = {Structured databases achieve effective searching and sorting by enacting sharply delineated category boundaries around their contents. While this enables precise retrieval, it also distorts identities that exist between category lines. A choice between Single and Married, for example, blurs distinctions within the Single group: single, perhaps, merely because same-sex marriage is not legal in one's locality. Sociologists Susan Leigh Star and Geoffrey Bowker describe such residual states as inevitable byproducts of information systems. To minimize residuality, traditional practice for descriptive metadata seeks to demarcate clear and objective classes. In this study, we use critical design to question this position by creating information collections that foreground the residual, instead of diminishing it. We then interrogate our design experiments with solicited critical responses from invited experts and student designers. Inspired by the anthropologist Tim Ingold, we argue that our experiments illuminate a form of interacting with databases characterized by notions of wayfaring, or inhabiting a space, as opposed to notions of transport, or reaching a known destination. We suggest that the form of coherence that shapes a wayfaring database is enacted through its flow, or fluid integration between structure and content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1941–1950},
numpages = {10},
keywords = {classification, collections, metadata, criticism, design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557137,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Stolterman, Erik},
title = {Reading Critical Designs: Supporting Reasoned Interpretations of Critical Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557137},
doi = {10.1145/2556288.2557137},
abstract = {Critical Design has emerged as an important concept in HCI research and practice. Yet researchers have noted that its uptake has been limited by certain lacks of intellectual infrastructure theories, methodologies, canons and exemplars, and a community of practice. We argue that one way to create this infrastructure is to cultivate a community adept at reading that is, critically interpreting and making reasoned judgments about critical designs. We propose an approach to developing close readings of critical designs, which are both evidence-based and carefully reasoned. The approach highlights analytical units of analysis, the relevance of design languages and social norms, and the analytical contemplation of critical aspects of a design. It is intended to be relatively easy to learn, to try out, and to teach, in the hopes of inviting more members of the HCI community to engage in this practice. We exemplify the approach with readings of two critical designs and reflect on different ways that a design might serve a critical purpose or offer a critical argument about design, society, and the future.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1951–1960},
numpages = {10},
keywords = {criticism, art, interpretation, critical design, design theory},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557178,
author = {Odom, William T. and Sellen, Abigail J. and Banks, Richard and Kirk, David S. and Regan, Tim and Selby, Mark and Forlizzi, Jodi L. and Zimmerman, John},
title = {Designing for Slowness, Anticipation and Re-Visitation: A Long Term Field Study of the Photobox},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557178},
doi = {10.1145/2556288.2557178},
abstract = {We describe the design, implementation and deployment of Photobox, a domestic technology that prints four or five randomly selected photos from the owner's Flickr collection at random intervals each month. We deployed Photobox in three homes for fourteen months, to explore how the slow pace at which it operates could support experiences of anticipation and re-visitation of the past. Findings reveal changes in attitude toward the device, from frustration to eventual acceptance. Participants drew on the photos to reflect on past life events and reactions indicated a renewed interest for their Flickr collection. Photobox also provoked reflection on technology in and around the home. These findings suggest several opportunities, such as designing for anticipation, better supporting reflection on the past, and, more generally, expanding the slow technology research program within the HCI community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1961–1970},
numpages = {10},
keywords = {home, slow technology, design, interaction design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557357,
author = {Sas, Corina and Whittaker, Steve and Dow, Steven and Forlizzi, Jodi and Zimmerman, John},
title = {Generating Implications for Design through Design Research},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557357},
doi = {10.1145/2556288.2557357},
abstract = {A central tenet of HCI is that technology should be user-centric, with designs being based around social science findings about users. Nevertheless a repeated but critical challenge in design is translating empirical findings into actionable ideas that inform design, or generating implications for design. Despite various design methods aiming to bridge this gap, knowledge informing design is still seen as problematic. However there has been little empirical exploration into what design researchers understand by such design knowledge, the functions and principles behind their creation. We report on interviews with twelve expert HCI design researchers probing the roles and types of design implications, and the process of generating and evaluating them. We synthesize different types of design implications into a framework to guide their generation. Our findings identify a broader range than previously described, additional sources and heuristics supporting their development as well some important evaluation criteria. We discuss the value of these findings for interaction design research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1971–1980},
numpages = {10},
keywords = {implications for design, design research, design knowledge},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251021,
author = {Vogel, Daniel},
title = {Session Details: Understanding and Modeling Touch},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251021},
doi = {10.1145/3251021},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557312,
author = {Ng, Alexander and Brewster, Stephen A. and Williamson, John H.},
title = {Investigating the Effects of Encumbrance on One- and Two- Handed Interactions with Mobile Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557312},
doi = {10.1145/2556288.2557312},
abstract = {In this paper, we investigate the effects of encumbrance (carrying typical objects such as shopping bags during interaction) and walking on target acquisition on a touchscreen mobile phone. Users often hold objects and use mobile devices at the same time and we examined the impact encumbrance has on one- and two- handed interactions. Three common input postures were evaluated: two-handed index finger, one-handed preferred thumb and two-handed both thumbs, to assess the effects on performance of carrying a bag in each hand while walking. The results showed a significant decrease in targeting performance when users were encumbered. For example, input accuracy dropped to 48.1% for targeting with the index finger when encumbered, while targeting error using the preferred thumb to input was 4.2mm, an increase of 40% compared to unencumbered input. We also introduce a new method to evaluate the user's preferred walking speed when interacting - PWS&amp;I, and suggest future studies should use this to get a more accurate measure of the user's input performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1981–1990},
numpages = {10},
keywords = {one- and two- handed input, target acquisition, mobile interactions, encumbrance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557354,
author = {Bergstrom-Lehtovirta, Joanna and Oulasvirta, Antti},
title = {Modeling the Functional Area of the Thumb on Mobile Touchscreen Surfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557354},
abstract = {We present a predictive model for the functional area of the thumb on a touchscreen surface: the area of the interface reachable by the thumb of the hand that is holding the device. We derive a quadratic formula by analyzing the kinematics of the gripping hand. Model fit is high for the thumb-motion trajectories of 20 participants. The model predicts the functional area for a given 1) surface size, 2) hand size, and 3) position of the index finger on the back of the device. Designers can use this model to ensure that a user interface is suitable for interaction with the thumb. The model can also be used inversely - that is, to infer the grips assumed by a given user interface layout.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1991–2000},
numpages = {10}
}

@inbook{10.1145/2556288.2557088,
author = {Tsandilas, Theophanis and Appert, Caroline and Bezerianos, Anastasia and Bonnet, David},
title = {Coordination of Tilt and Touch in One- and Two-Handed Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557088},
abstract = {Our goal is to enhance navigation in mobile interfaces with quick command gestures that do not make use of explicit mode-switching actions. TilTouch gestures extend the vocabulary of navigation interfaces by combining motion tilt with directional touch. We consider sixteen directional TilTouch gestures that rely on tilt and touch movements along the four main compass directions. An experiment explores their effectiveness for both one-handed and two-handed use. Results identify the best combinations of TilTouch gestures in terms of performance, motor coordination, and user preferences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2001–2004},
numpages = {4}
}

@inproceedings{10.1145/2556288.2557148,
author = {Mohd Noor, Mohammad Faizuddin and Ramsay, Andrew and Hughes, Stephen and Rogers, Simon and Williamson, John and Murray-Smith, Roderick},
title = {28 Frames Later: Predicting Screen Touches from Back-of-Device Grip Changes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557148},
doi = {10.1145/2556288.2557148},
abstract = {We demonstrate that front-of-screen targeting on mobile phones can be predicted from back-of-device grip manipulations. Using simple, low-resolution capacitive touch sensors placed around a standard phone, we outline a machine learning approach to modelling the grip modulation and inferring front-of-screen touch targets. We experimentally demonstrate that grip is a remarkably good predictor of touch, and we can predict touch position 200ms before contact with an accuracy of 18mm.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2005–2008},
numpages = {4},
keywords = {touch, machine learning, back-of-device, capacitive},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557056,
author = {Schwarz, Julia and Xiao, Robert and Mankoff, Jennifer and Hudson, Scott E. and Harrison, Chris},
title = {Probabilistic Palm Rejection Using Spatiotemporal Touch Features and Iterative Classification},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557056},
doi = {10.1145/2556288.2557056},
abstract = {Tablet computers are often called upon to emulate classical pen-and-paper input. However, touchscreens typically lack the means to distinguish between legitimate stylus and finger touches and touches with the palm or other parts of the hand. This forces users to rest their palms elsewhere or hover above the screen, resulting in ergonomic and usability problems. We present a probabilistic touch filtering approach that uses the temporal evolution of touch contacts to reject palms. Our system improves upon previous approaches, reducing accidental palm inputs to 0.016 per pen stroke, while correctly passing 98% of stylus inputs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2009–2012},
numpages = {4},
keywords = {tablet computing, touchscreen, pen and stylus input, touch interaction, palm rejection},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557399,
author = {Nguyen, Quan and Kipp, Michael},
title = {Orientation Matters: Efficiency of Translation-Rotation Multitouch Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557399},
doi = {10.1145/2556288.2557399},
abstract = {The translation and rotation of objects with two fingers is a well explored multitouch technique. However, there are some unsolved questions regarding the optimal conditions under which this technique functions best. Does it matter in which direction the movement is oriented? Does parallel or sequential performance of the two operations work best? This study attempts to answer this question using a typical Fitts' Law setup but with varying translation-rotation orientation combinations. The results show that right-oriented movements were faster and easier than left-oriented ones. Movement combinations which went in different directions (translation right, rotation left, and vice versa) were found more tiresome and resulted in more strategy switches compared to equi-directional combinations. Our findings can inform positioning decisions in interaction design and contribute to theoretical adjustments to Fitts' Law.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2013–2016},
numpages = {4},
keywords = {multitouch interaction techniques, 2d translation and rotation, fitts law},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251022,
author = {Stuerzlinger, Wolfgang},
title = {Session Details: 3D Interaction: Modeling and Prototyping},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251022},
doi = {10.1145/3251022},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557218,
author = {Gupta, Ankit and Agrawala, Maneesh and Curless, Brian and Cohen, Michael},
title = {MotionMontage: A System to Annotate and Combine Motion Takes for 3D Animations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557218},
doi = {10.1145/2556288.2557218},
abstract = {We present MotionMontage, a system for recording multiple motion takes of a rigid virtual object and compositing them together into a montage. Our system incorporates a Kinect-based performance capture setup that allows animators to create 3D animations by tracking the motion of a rigid physical object and mapping it in realtime onto a virtual object. The animator then temporally annotates the best parts of each take. MotionMontage merges the annotated motions into a single composite montage using a combination of dynamic time warping and optimization of a Semi-Markov Conditional Random Field. Our system also supports the creation of layered animations in which multiple objects are moving at the same time. To aid the animator in coordinating the motions of the objects we provide spatial markers which indicate the positions of previously recorded objects at user-specified points in time. We perform a user study to evaluate the perceived quality of the montages created with our system and find that viewers (including both the original animators and new viewers) generally prefer the animation montage to any individual take.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2017–2026},
numpages = {10},
keywords = {depth camera, animation, active visual feedback, montage},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557009,
author = {Chen, Hsiang-Ting and Grossman, Tovi and Wei, Li-Yi and Schmidt, Ryan M. and Hartmann, Bj\"{o}rn and Fitzmaurice, George and Agrawala, Maneesh},
title = {History Assisted View Authoring for 3D Models},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557009},
doi = {10.1145/2556288.2557009},
abstract = {3D modelers often wish to showcase their models for sharing or review purposes. This may consist of generating static viewpoints of the model or authoring animated fly-throughs. Manually creating such views is often tedious and few automatic methods are designed to interactively assist the modelers with the view authoring process. We present a view authoring assistance system that supports the creation of informative view points, view paths, and view surfaces, allowing modelers to author the interactive navigation experience of a model. The key concept of our implementation is to analyze the model's workflow history, to infer important regions of the model and representative viewpoints of those areas. An evaluation indicated that the viewpoints generated by our algorithm are comparable to those manually selected by the modeler. In addition, participants of a user study found our system easy to use and effective for authoring viewpoint summaries.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2027–2036},
numpages = {10},
keywords = {3D model, editing history, viewpoint authoring},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557183,
author = {Broy, Nora and Schneegass, Stefan and Alt, Florian and Schmidt, Albrecht},
title = {FrameBox and MirrorBox: Tools and Guidelines to Support Designers in Prototyping Interfaces for 3D Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557183},
doi = {10.1145/2556288.2557183},
abstract = {In this paper, we identify design guidelines for stereoscopic 3D (S3D) user interfaces (UIs) and present the MirrorBox and the FrameBox, two UI prototyping tools for S3D displays. As auto-stereoscopy becomes available for the mass market we believe the design of S3D UIs for devices, for example, mobile phones, public displays, or car dashboards, will rapidly gain importance. A benefit of such UIs is that they can group and structure information in a way that makes them easily perceivable for the user. For example, important information can be shown in front of less important information. This paper identifies core requirements for designing S3D UIs and derives concrete guidelines. The requirements also serve as a basis for two depth layout tools we built with the aim to overcome limitations of traditional prototyping when sketching S3D UIs. We evaluated the tools with usability experts and compared them to traditional paper prototyping.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2037–2046},
numpages = {10},
keywords = {prototyping, stereoscopic 3d, user interfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557242,
author = {Ortega, Micha\"{e}l and Vincent, Thomas},
title = {Direct Drawing on 3D Shapes with Automated Camera Control},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557242},
doi = {10.1145/2556288.2557242},
abstract = {We present ACCD, an interaction technique that allows direct drawing of long curves on 3D shapes with a tablet display over both multiple depth layers and multiple viewpoints. ACCD reduces the number of explicit viewpoint manipulations by combining self-occlusion management and automated camera control. As such it enables drawing on occluded faces but also around a 3D shape while keeping a constant drawing precision. Our experimental results indicates the efficacy of ACCD over conventional techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2047–2050},
numpages = {4},
keywords = {3d painting, 3d interaction technique, camera controls},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556966,
author = {Joshi, Neel S. and Morris, Dan and Cohen, Michael F.},
title = {Interactively Stylizing Camera Motion},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556966},
doi = {10.1145/2556288.2556966},
abstract = {Movie directors and cinematographers impart style onto video using techniques that are learned through years of experience: camera movement, framing, color, lighting, etc. Without this experience and expensive equipment, it is very difficult to control stylistic aspects of a video. We introduce a novel approach for post-hoc editing of one specific aspect of cinematography -- camera motion style -- via an equalizer-like set of controls that manipulates the power spectra of a video's apparent motion path. We explore free manipulation of apparent camera motion as well as the transfer of motion styles from an example video to a new video to create a wide range of stylistic variations. We report on a user study confirming the ability of non-expert users to create motion styles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2051–2054},
numpages = {4},
keywords = {camera motion editing, video stylization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251023,
author = {Steimle, J\"{u}rgen},
title = {Session Details: The Eyes Have It},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251023},
doi = {10.1145/3251023},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557129,
author = {Crnovrsanin, Tarik and Wang, Yang and Ma, Kwan-Liu},
title = {Stimulating a Blink: Reduction of Eye Fatigue with Visual Stimulus},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557129},
doi = {10.1145/2556288.2557129},
abstract = {Computers make incredible amounts of information available at our fingertips. As computers become integral parts of our lives, we spend more time staring at computer monitor than ever before, sometimes with negative effects. One major concern is the increasing number of people suffering from Computer Vision Syndrome (CVS). CVS is caused by extensive use of computers, and its symptoms include eye fatigue, frequent headaches, dry eyes, and blurred vision. It is possible to partially alleviate CVS if we can remind users to blink more often. We present a prototype system that uses a camera to monitor a user's blink rate, and when the user has not blinked in a while, the system triggers a blink stimulus. We investigated four different types of eye-blink stimulus: screen blurring, screen flashing, border flashing, and pop-up notifications. Users also rated each stimulus type in terms of effectiveness, intrusiveness, and satisfaction. Results from our user studies show that our stimuli are effective in increasing user blink rate with screen blurring being the best.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2055–2064},
numpages = {10},
keywords = {cvs, blink detection, user study, blink stimulus},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557025,
author = {Walber, Tina Caroline and Scherp, Ansgar and Staab, Steffen},
title = {Smart Photo Selection: Interpret Gaze as Personal Interest},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557025},
doi = {10.1145/2556288.2557025},
abstract = {Manually selecting subsets of photos from large collections in order to present them to friends or colleagues or to print them as photo books can be a tedious task. Today, fully automatic approaches are at hand for supporting users. They make use of pixel information extracted from the images, analyze contextual information such as capture time and focal aperture, or use both to determine a proper subset of photos. However, these approaches miss the most important factor in the photo selection process: the user. The goal of our approach is to consider individual interests. By recording and analyzing gaze information from the user's viewing photo collections, we obtain information on user's interests and use this information in the creation of personal photo selections. In a controlled experiment with 33 participants, we show that the selections can be significantly improved over a baseline approach by up to 22% when taking individual viewing behavior into account. We also obtained significantly better results for photos taken at an event participants were involved in compared with photos from another event.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2065–2074},
numpages = {10},
keywords = {photo selection, eye tracking, usage-based image selection},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557086,
author = {Jiang, Xianta and Atkins, M. Stella and Tien, Geoffrey and Bednarik, Roman and Zheng, Bin},
title = {Pupil Responses during Discrete Goal-Directed Movements},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557086},
doi = {10.1145/2556288.2557086},
abstract = {Pupil size is known to correlate with the changes of cognitive task workloads, but how the pupil responds to requirements of basic goal-directed motor tasks involved in human-machine interactions is not yet clear. This work conducted a user study to investigate the pupil dilations during aiming in a tele-operation setting, with the purpose of better understanding how the changes in task requirements are reflected by the changes of pupil size. The task requirements, managed by Fitts' index of difficulty (ID), i.e. the size and distance apart of the targets, were varied between tasks, and pupil responses to different task IDs were recorded. The results showed that pupil diameter can be employed as an indicator of task requirements in goal-directed movements-higher task difficulty evoked higher valley to peak pupil dilation, and the peak pupil dilation occurred after a longer delay. These findings contribute to the foundation for developing methods to objectively evaluate interactive task requirements using pupil parameters during goal-directed movements in HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2075–2084},
numpages = {10},
keywords = {goal-directed movement, movement-evoked pupillary response, fitts' law, pupil diameter},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557279,
author = {May, Jon and Gamble, Tim},
title = {Collocating Interface Objects: Zooming into Maps},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557279},
doi = {10.1145/2556288.2557279},
abstract = {May, Dean and Barnard (2003) used a theoretically based model to argue that objects in a wide range of interfaces should be collocated following screen changes such as a zoom-in to detail. Many existing online maps do not follow this principle, but move a clicked point to the centre of the subsequent display, leaving the user looking at an unrelated location. This paper presents three experiments showing that collocating the point clicked on a map so that the detailed location appears in the place previously occupied by the overview location makes the map easier to use, reducing eye movements and interaction duration. We discuss the benefit of basing design principles on theoretical models so that they can be applied to novel situations, and so designers can infer when to use and not use them.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2085–2094},
numpages = {10},
keywords = {collocation, zooming, cinematography, eye-tracking, cognitive models, maps},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251024,
author = {Tatar, Deborah},
title = {Session Details: Learning and Education},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251024},
doi = {10.1145/3251024},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557207,
author = {Kizilcec, Ren\'{e} F. and Papadopoulos, Kathryn and Sritanyaratana, Lalida},
title = {Showing Face in Video Instruction: Effects on Information Retention, Visual Attention, and Affect},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557207},
doi = {10.1145/2556288.2557207},
abstract = {The amount of online educational content is rapidly increasing, particularly in the form of video lectures. The goal is to design video instruction to facilitate an experience that maximizes learning and satisfaction. A widely used but understudied design element in video instruction is the overlay of a small video of the instructor over lecture slides. We conducted an experiment with eye-tracking and recall tests to investigate how adding the instructor's face to video instruction affects information retention, visual attention, and affect. Participants strongly preferred instruction with the face and perceived it as more educational. They spent about 41% of time looking at the face and switched between the face and slide every 3.7 seconds. Consistent with prior work, no significant difference in short- and medium-term recall ability was found. Including the face in video instruction is encouraged based on learners' positive affective response. More fine-grained analytics combining eye-tracking with detailed learning assessment could shed light on the mechanisms by which the face aids or hinders learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2095–2102},
numpages = {8},
keywords = {eye-tracking, multimedia learning, audiovisual instruction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557162,
author = {Lui, Michelle and Kuhn, Alex C. and Acosta, Alisa and Quintana, Chris and Slotta, James D.},
title = {Supporting Learners in Collecting and Exploring Data from Immersive Simulations in Collective Inquiry},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557162},
doi = {10.1145/2556288.2557162},
abstract = {Digitally augmented physical spaces (e.g., smart classrooms) offer opportunities to engage students in novel and potentially transformative learning experiences. This paper presents an immersive rainforest simulation and collective inquiry activity where students collect observational data from the environment and explore their peers' data through large visualization displays and personal mobile devices. Two iterations of the design were tested, which resulted in higher quality student explanations constructed. Images were found to be an important source of evidence for the explanations, more so than text-only evidence. We also found that patterns of collective ideas influenced student performance, and that visualizations, as ambient or plenary displays, supported both teacher and students in reviewing patterns of collected data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2103–2112},
numpages = {10},
keywords = {smart classroom, mobile computing, multi-device environments, visualizations, digitally augmented physical spaces, science inquiry, large displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557387,
author = {Mentis, Helena M. and Chellali, Amine and Schwaitzberg, Steven},
title = {Learning to See the Body: Supporting Instructional Practices in Laparoscopic Surgical Procedures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557387},
doi = {10.1145/2556288.2557387},
abstract = {Learning the practices and the performance of physically manipulating instruments in minimally invasive surgeries is an impetus for the development of surgical training simulators. However, an often-overlooked aspect of surgical training is learning how to see the body through the various imaging mechanisms. With this study, we address the ways in which surgeons demonstrate and instruct residents in seeing the body during minimally invasive surgical procedures. Drawing on observations and analysis of video recordings of minimally invasive surgical operations, we examine how particular anatomy and movement within the body to see and conceptualize that anatomy are made visible by the instructive practices of the surgeon. We use these findings to discuss further directions for minimally invasive surgical training through mechanisms for making the body visible during situated surgical training and surgical training simulation systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2113–2122},
numpages = {10},
keywords = {surgery, training, gestures, vision, movement},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557294,
author = {Shelley, Tia and Lyons, Leilah and Moher, Tom and Dasgupta, Chandan and Lopez Silva, Brenda and Silva, Alexandra},
title = {Information-Building Applications: Designing for Data Exploration and Analysis by Elementary School Students},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557294},
doi = {10.1145/2556288.2557294},
abstract = {The propagation of Inquiry Based Learning has lead to many more elementary students interacting with authentic scientific tools and practices. However, the more problematic realities of scientific data collection, such as noise and large data sets, are often deliberately hidden from students. Students will need to confront these realities and be able to make skillful data scoping decisions in order to make sense of ever more prevalent large datasets. We dub software designed to support these activities Information-Building Applications (IBAs). This paper presents the design considerations that went into building an exemplar IBA, PhotoMAT (Photo Management and Analysis Tool), a brief user study to show how the solutions enacted by following these principles are taken up by actual students, and a discussion of how the design considerations identified by our work might be applied to another IBA.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2123–2132},
numpages = {10},
keywords = {learner centered design, k-12 science education, information-building applications},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250953,
author = {Inkpen, Kori},
title = {Session Details: Telepresence and Connecting over Video},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250953},
doi = {10.1145/3250953},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557169,
author = {Nakanishi, Hideyuki and Tanaka, Kazuaki and Wada, Yuya},
title = {Remote Handshaking: Touch Enhances Video-Mediated Social Telepresence},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557169},
doi = {10.1145/2556288.2557169},
abstract = {Since past studies on haptic and visual communication have tended to be isolated from each other, it has remained unclear whether a touch channel can still enrich mediated communication where video and audio channels are already available. To clarify this, we analyzed remote handshaking in which a robot hand that was attached just under a videoconferencing terminal's display moved according to the opening and closing motion of a conversation partner's hand. Combining touch and video channels raises a question as to whether the partner's action of touching a haptic device should be visible to the user. If it can be invisible, the action may be unnecessary, and a unilaterally controlled device may be enough to establish an effective touch channel. Our analysis revealed that the feeling of being close to the partner can be enhanced by mutual touch in which the partner's action needs to occur but should be invisible.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2143–2152},
numpages = {10},
keywords = {social interaction, video-mediated communication, social telepresence, haptic devices, videoconferencing, social touch, humanoid robots},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557047,
author = {Rae, Irene and Mutlu, Bilge and Takayama, Leila},
title = {Bodies in Motion: Mobility, Presence, and Task Awareness in Telepresence},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557047},
doi = {10.1145/2556288.2557047},
abstract = {Robotic telepresence systems - videoconferencing systems that allow a remote user to drive around in another location - provide an alternative to video-mediated communications as a way of interacting over distances. These systems, which are seeing increasing use in business and medical settings, are unique in their ability to grant the remote user the ability to maneuver in a distant location. While this mobility promises increased feelings of "being there" for remote users and thus greater support for task collaboration, whether these promises are borne out, providing benefits in task performance, is unknown. To better understand the role that mobility plays in shaping the remote user's sense of presence and its potential benefits, we conducted a two-by-two (system mobility: stationary vs. mobile; task demands for mobility: low vs. high) controlled laboratory experiment. We asked participants (N=40) to collaborate in a construction task with a confederate via a robotic telepresence system. Our results showed that mobility significantly increased the remote user's feelings of presence, particularly in tasks with high mobility requirements, but decreased task performance. Our findings highlight the positive effects of mobility on feelings of "being there," while illustrating the need to design support for effective use of mobility in high-mobility tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2153–2162},
numpages = {10},
keywords = {robotic telepresence, remote collaboration, presence, mobility, task awareness, robot-mediated communication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557198,
author = {Procyk, Jason and Neustaedter, Carman and Pang, Carolyn and Tang, Anthony and Judge, Tejinder K.},
title = {Exploring Video Streaming in Public Settings: Shared Geocaching over Distance Using Mobile Video Chat},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557198},
doi = {10.1145/2556288.2557198},
abstract = {Our research explores the use of mobile video chat in public spaces by people participating in parallel experiences, where both a local and remote person are doing the same activity together at the same time. We prototyped a wearable video chat experience and had pairs of friends and family members participate in 'shared geocaching' over distance. Our results show that video streaming works best for navigation tasks but is more challenging to use for fine-grained searching tasks. Video streaming also creates a very intimate experience with a remote partner, but this can lead to distraction from the 'real world' and even safety concerns. Overall, privacy concerns with streaming from a public space were not typically an issue; however, people tended to rely on assumptions of what were acceptable. The implications are that designers should consider appropriate feedback, user disembodiment, and asymmetry when designing for parallel experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2163–2172},
numpages = {10},
keywords = {shared experiences, video communication, geocaching},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557320,
author = {Pan, Ye and Steed, Anthony},
title = {A Gaze-Preserving Situated Multiview Telepresence System},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557320},
doi = {10.1145/2556288.2557320},
abstract = {Gaze, attention, and eye contact are important aspects of face to face communication, but some subtleties can be lost in videoconferencing because participants look at a single planar image of the remote user. We propose a low-cost cylindrical videoconferencing system that preserves gaze direction by providing perspective-correct images for multiple viewpoints around a conference table. We accomplish this by using an array of cameras to capture a remote person, and an array of projectors to present the camera images onto a cylindrical screen. The cylindrical screen reflects each image to a narrow viewing zone. The use of such a situated display allows participants to see the remote person from multiple viewing directions. We compare our system to three alternative display configurations. We demonstrate the effectiveness of our system by showing it allows multiple participants to simultaneously tell where the remote person is placing their gaze.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2173–2176},
numpages = {4},
keywords = {gaze, non-planar displays, camera arrays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557117,
author = {Cohen, Maayan and Dillman, Kody R. and MacLeod, Haley and Hunter, Seth and Tang, Anthony},
title = {OneSpace: Shared Visual Scenes for Active Freeplay},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557117},
doi = {10.1145/2556288.2557117},
abstract = {Children engage in free play for emotional, physical and social development; researchers have explored supporting free play between physically remote playmates using videoconferencing tools. We show that the configuration of the video conferencing setup affects play. Specifically, we show that a shared visual scene configuration promotes fundamentally active forms of engaged, co-operative play.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2177–2180},
numpages = {4},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250954,
author = {Munson, Sean},
title = {Session Details: Exergame Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250954},
doi = {10.1145/3250954},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557257,
author = {Garner, Jayden and Wood, Gavin and Pijnappel, Sebastiaan and Murer, Martin and Mueller, Florian},
title = {I-Dentity: Innominate Movement Representation as Engaging Game Element},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557257},
doi = {10.1145/2556288.2557257},
abstract = {Movement-based digital games typically make it clear whose movement representation belongs to which player. In contrast, we argue that selectively concealing whose movement controls which representation can facilitate engaging play experiences. We call this "innominate movement representation" and explore this opportunity through our game "i-dentity", where players have to guess who makes everyone's controller light up based on his/her movements. Our work reveals five dimensions for the design of innominate movement representation: concealing the association between movement and representation; number of represented movements; number of players with representations; location of representation in relation to the body and technical attributes of representation. We also present five strategies for how innominate representation can be embedded into a play experience. With our work we hope to expand the range of digital movement games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2181–2190},
numpages = {10},
keywords = {social play, ambiguity, game design, engagement, entertainment, digital play, movement representation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557163,
author = {Mueller, Florian and Isbister, Katherine},
title = {Movement-Based Game Guidelines},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557163},
doi = {10.1145/2556288.2557163},
abstract = {Movement-based digital games are becoming increasingly popular, yet there is limited comprehensive guidance on how to design these games. We present a set of guidelines for movement-based game design that has emerged from our research-based game development practice. These guidelines have been examined and refined by 14 movement-based game design experts with experience in the academic, independent and commercial game development domains. We contextualize the guidelines using current findings about movement-based game and interaction design, taken from both published research papers and game design venues. Our primary contribution is a body of generative intermediate-level knowledge in the design research tradition that is readily accessible and actionable for the design of future movement-based games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2191–2200},
numpages = {10},
keywords = {whole-body interaction, digital games, play, movement-based games, exertion},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2556963,
author = {Gerling, Kathrin Maria and Miller, Matthew and Mandryk, Regan L. and Birk, Max Valentin and Smeddinck, Jan David},
title = {Effects of Balancing for Physical Abilities on Player Performance, Experience and Self-Esteem in Exergames},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556963},
abstract = {Game balancing can help players with different skill levels play multiplayer games together; however, little is known about how the balancing approach affects performance, experience, and self-esteem'especially when differences in player strength result from given abilities, rather than learned skill. We explore three balancing approaches in a dance game and show that the explicit approach commonly used in commercial games reduces self-esteem and feelings of relatedness in dyads, whereas hidden balancing improves self-esteem and reduces score differential without affecting game outcome. We apply our results in a second study with dyads where one player had a mobility disability and used a wheelchair. By making motion-based games accessible for people with different physical abilities, and by enabling people with mobility disabilities to compete on a par with able-bodied peers, we show how to provide empowering experiences through enjoyable games that have the potential to increase physical activity and self-esteem.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2201–2210},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557272,
author = {Mueller, Florian and Gibbs, Martin R. and Vetere, Frank and Edge, Darren},
title = {Supporting the Creative Game Design Process with Exertion Cards},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557272},
doi = {10.1145/2556288.2557272},
abstract = {Advances in sensing technologies have led to research into exertion games that support physically effortful experiences. Despite the existence of theoretical frameworks that can be used to analyze such exertion experiences, there are few tools to support the hands-on practice of exertion game design. To address this, we present a set of design cards based on the "Exertion Framework", grounded in our experience of creating exertion games for over a decade. We present results demonstrating the value and utility of these Exertion Cards based on our studies of their use in three workshops held over seven sessions with 134 design students and experts. We also articulate lessons learned from transforming a theoretical framework into a design tool that aims to support designers in their practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2211–2220},
numpages = {10},
keywords = {exertion interface, game design, whole-body interaction, creative process, design cards, workshops, exergame},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250955,
author = {Nebeling, Michael},
title = {Session Details: Designing and Modeling GUIs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250955},
doi = {10.1145/3250955},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557349,
author = {Meng, Xiaojun and Zhao, Shengdong and Huang, Yongfeng and Zhang, Zhongyuan and Eagan, James and Subramanian, Ramanathan},
title = {WADE: Simplified GUI Add-on Development for Third-Party Software},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557349},
doi = {10.1145/2556288.2557349},
abstract = {We present the WADE Integrated Development Environment (IDE), which simplifies interface and functionality modification of existing third-party software without access to source code. WADE clones the Graphical User Interface (GUI) of a host program through dynamic-link library (DLL) injection, enabling modifications to (1) the GUI in a WYSIWYG fashion and (2) software functionality. We compare WADE with an alternative state-of-the-art runtime toolkit overloading approach in a user-study, whose results demonstrate that WADE significantly simplifies the task of GUI-based add-on development.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2221–2230},
numpages = {10},
keywords = {IDE, WADE, add-on integration, wysiwyg, GUI},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556979,
author = {Dixon, Morgan and Laput, Gierad and Fogarty, James},
title = {Pixel-Based Methods for Widget State and Style in a Runtime Implementation of Sliding Widgets},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556979},
doi = {10.1145/2556288.2556979},
abstract = {Pixel-based methods offer unique potential for modifying existing interfaces independent of their underlying implementation. Prior work has demonstrated a variety of modifications to existing interfaces, including accessibility enhancements, interface language translation, testing frameworks, and interaction techniques. But pixel-based methods have also been limited in their understanding of the interface and therefore the complexity of modifications they can support. This work examines deeper pixel-level understanding of widgets and the resulting capabilities of pixel-based runtime enhancements. Specifically, we present three new sets of methods: methods for pixel-based modeling of widgets in multiple states, methods for managing the combinatorial complexity that arises in creating a multitude of runtime enhancements, and methods for styling runtime enhancements to preserve consistency with the design of an existing interface. We validate our methods through an implementation of Moscovich et al.'s Sliding Widgets, a novel runtime enhancement that could not have been implemented with prior pixel-based methods.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2231–2240},
numpages = {10},
keywords = {prefab, pixel-based runtime modification, hybrid touch and mouse interaction, sliding widgets, real-world interfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556976,
author = {Scarr, Joey and Cockburn, Andy and Gutwin, Carl and Bunt, Andrea and Cechanowicz, Jared E.},
title = {The Usability of CommandMaps in Realistic Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556976},
doi = {10.1145/2556288.2556976},
abstract = {CommandMaps are a promising interface technique that flattens command hierarchies and exploits human spatial memory to provide rapid access to commands. CommandMaps have performed favorably in constrained cued-selection studies, but have not yet been tested in the context of real tasks. In this paper we present two real-world implementations of CommandMaps: one for Microsoft Word and one for an image editing program called Pinta. We use these as our experimental platforms in two experiments. In the first, we show that CommandMaps demonstrate performance and subjective advantages in a realistic task. In the second, we observe naturalistic use of CommandMaps over the course of a week, and gather qualitative data from interviews, questionnaires, and conversations. Our results provide substantial insight into users' reactions to CommandMaps, showing that they are positively received by users and allowing us to provide concrete recommendations to designers regarding when and how they should be implemented in real applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2241–2250},
numpages = {10},
keywords = {commandmaps, real tasks, spatial memory, hierarchies},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556972,
author = {Hong, Kyung Wha and St. Amant, Robert},
title = {Novice Use of a Predictive Human Performance Modeling Tool to Produce UI Recommendations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556972},
doi = {10.1145/2556288.2556972},
abstract = {This note describes two studies of the use of a performance modeling tool, CogTool, for making recommendations to improve a user interface. The first study replicates findings by Bonnie John [7]: the rates at which novice modelers made correct recommendations (88.1%) and supported them (68.2%) are close to the values in John's study (91.7% and 75.1%, respectively). A follow-on study of novice modelers on the same task without CogTool produced sig-nificantly lower values. CogTool improves the UI design recommendations made by novices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2251–2254},
numpages = {4},
keywords = {usability analysis, cogtool, interface design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557288,
author = {Balata, Jan and Cmolik, Ladislav and Mikovec, Zdenek},
title = {On the Selection of 2D Objects Using External Labeling},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557288},
doi = {10.1145/2556288.2557288},
abstract = {We present an external labeling laid over small and/or overlapping 2D objects as an efficient representation for their selection. The approximation of objects with points allows us to transform the labeling problem to graph layout problem, which we solve by means of force-based algorithm. The input parameters allow us to influence the resulting layout of label boxes (e.g. to adapt their distance for imprecise input devices). In a study with 15 participants two implementations of our algorithm were compared against labeling method, where all label boxes share the same offset from corresponding objects. The results of the study show that implementation using a special functionality (temporary freezing of the label box position recalculation) was 14% faster with a comparable accuracy. The subjective evaluation revealed that the implementation with temporary freezing is perceived as most comfortable, fastest and most accurate. The implementation without temporary freezing showed much higher error rate and cannot be recommended.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2255–2258},
numpages = {4},
keywords = {user study, object selection, visualization, external labeling},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250956,
author = {Wolters, Maria},
title = {Session Details: Health and Everyday Life},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250956},
doi = {10.1145/3250956},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557210,
author = {Lee, Matthew L. and Dey, Anind K.},
title = {Real-Time Feedback for Improving Medication Taking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557210},
doi = {10.1145/2556288.2557210},
abstract = {Medication taking is a self-regulatory process that requires individuals to self-monitor their medication taking behaviors, but this can be difficult because medication taking is such a mundane, unremarkable behavior. Ubiquitous sensing systems have the potential to sense everyday behaviors and provide the objective feedback necessary for self-regulation of medication taking. We describe an unobtrusive sensing system consisting of a sensor-augmented pillbox and an ambient display that provides near real-time visual feedback about how well medications are being taken. In contrast to other systems that focus on reminding before medication taking, our approach uses feedback after medication taking to allow the individual to develop their own routines through self-regulation. We evaluated this system in the homes of older adults in a 10-month deployment. Feedback helped improve the consistency of medication-taking behaviors as well as increased ratings of self-efficacy. However, the improved performance did not persist after the feedback display was removed, because individuals had integrated the feedback display into their routines to support their self-awareness, identify mistakes, guide the timing of medication taking, and provide a sense of security that they are taking their medications well. Finally, we reflect on design considerations for feedback systems to support the process of self-regulation of everyday behaviors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2259–2268},
numpages = {10},
keywords = {medication adherence, ambient display, self-regulation, feedback, self-efficacy, sensors, behavior change},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2557210_R50745,
author = {Olagunju, Amos O},
title = {Review ID:R50745 for DOI: 10.1145/2556288.2557210},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557210_R50745}
}

@inproceedings{10.1145/2556288.2557079,
author = {Stawarz, Katarzyna and Cox, Anna L. and Blandford, Ann},
title = {Don't Forget Your Pill! Designing Effective Medication Reminder Apps That Support Users' Daily Routines},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557079},
doi = {10.1145/2556288.2557079},
abstract = {Despite the fact that a third of all cases of unintentional medication non-adherence are caused by simple forgetfulness, the majority of interventions neglect this issue. Even though patients have access to smartphone applications ("apps") designed to help them remember medication, neither their quality nor effectiveness has been evaluated yet. We report the findings of a functionality review of 229 medication reminder apps and a thematic analysis of their 1,012 user reviews. Our research highlights the gap between the theory and practice: while the literature shows that many medication regimens are habitual in nature and the presence of daily routines supports remembering, existing apps rely on timer-based reminders. To address this disparity, we present design requirements for building medication reminders that support the routine aspect of medication-taking and its individual nature, and demonstrate how they could be implemented to move from passive alerts to a smarter memory and routine assistant.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2269–2278},
numpages = {10},
keywords = {forgetfulness, medication reminders, habits, smartphone apps, routines},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557386,
author = {Suh, Hyewon and Porter, John R. and Hiniker, Alexis and Kientz, Julie A.},
title = {@BabySteps: Design and Evaluation of a System for Using Twitter for Tracking Children's Developmental Milestones},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557386},
doi = {10.1145/2556288.2557386},
abstract = {The tracking of developmental milestones in young children is an important public health goal for ensuring early detection and treatment for developmental delay. While numerous paper-based and web-based solutions are available for tracking milestones, many busy parents often forget to enter information on a regular basis. To help address this need, we have developed an interactive system called @BabySteps for allowing parents who use Twitter to track and respond to tweets about developmental milestones using a special hashtag syntax. Parent responses are parsed automatically and written into a central database that can be accessed via the web. We deployed @BabySteps with 14 parents over a 3-week period and found that parents were able to learn how to use the system to track their children's progress, with some using it to communicate with other parents. The study helped to identify a number of ways to improve the approach, including simplifying the hashtag syntax, allowing for private responses via direct messaging, and improving the social component. We provide a discussion of lessons learned and suggestions for the design of interactive public health systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2279–2288},
numpages = {10},
keywords = {memories, microblogging, health, public health, children, data capture, parents, twitter, social media},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557334,
author = {Nguyen, Linh Chi and Do, Ellen Yi-Luen and Chia, Audrey and Wang, Yuan and Duh, Henry Been-Lirn},
title = {DoDo Game, a Color Vision Deficiency Screening Test for Young Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557334},
doi = {10.1145/2556288.2557334},
abstract = {This paper presents 'DoDo's Catching Adventure,' a new color vision deficient screening test for young children. Early detection of color blindness among children is useful for parents and teachers to better understand children's needs, to overcome difficulties in learning, and for life and career planning. Unfortunately, current color screening tests are not designed for young children; most require more advanced verbal or cognitive skills. DoDo game has taken a new approach by embedding game elements into a color vision screening test. A user study conducted at Singapore National Eye Centre on twenty-eight children, identified fourteen as Red-Green deficient subjects as did by Ishihara screening test, showed that DoDo was adequately effective in identifying Red-Green color vision deficiency and comparable to two current gold standard colorblind tests, Ishihara and D15.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2289–2292},
numpages = {4},
keywords = {color deficiency test, digital game, children game},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557065,
author = {Cairns, Paul and Pandab, Pratyush and Power, Christopher},
title = {The Influence of Emotion on Number Entry Errors},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557065},
doi = {10.1145/2556288.2557065},
abstract = {Given the proliferation of devices like infusion pumps in hospitals, number entry and in particular number entry error is an emerging important concern in HCI. There are clearly design features that could greatly improve accuracy in entering numbers but the context of the task could also play an important role. In particular, the emotional state of a person is known to strongly influence their response to a difficult situation and hence the errors that they make. In this paper, we consider the impact of the emotional state of the user on the accuracy with which people enter numbers. Our experiment shows that participants who are in a more positive emotional state are more accurate. The effect is small but could be very important when considering the potentially highly-charged emotional contexts where many healthcare devices are used.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2293–2296},
numpages = {4},
keywords = {affect, number entry, healthcare, human error},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250957,
author = {Oulasvirta, Antti},
title = {Session Details: Text Entry and Evaluation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250957},
doi = {10.1145/3250957},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557414,
author = {Bi, Xiaojun and Ouyang, Tom and Zhai, Shumin},
title = {Both Complete and Correct? Multi-Objective Optimization of Touchscreen Keyboard},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557414},
doi = {10.1145/2556288.2557414},
abstract = {Correcting erroneous input (i.e., correction) and completing a word based on partial input (i.e., completion) are two important "smart" capabilities of a modern intelligent touchscreen keyboard. However little is known whether these two capabilities are conflicting or compatible with each other in the keyboard parameter tuning. Applying computational optimization methods, this work explores the optimality issues related to them. The work demonstrates that it is possible to simultaneously optimize a keyboard algorithm for both correction and completion. The keyboard simultaneously optimized for both introduces no compromise to correction and only a slight compromise to completion when compared to the keyboards exclusively optimized for one objective. Our research also demonstrates the effectiveness of the proposed optimization method in keyboard algorithm design, which is based on the Pareto multi-objective optimization and the Metropolis algorithm. For the development and test datasets used in our experiments, computational optimization improved the correction accuracy rate by 8.3% and completion power by 17.7%.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2297–2306},
numpages = {10},
keywords = {text input, optimization, smart touch screen keyboard, correction, keyboard algorithm, intelligent user interfaces, mobile, completion},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557412,
author = {Weir, Daryl and Pohl, Henning and Rogers, Simon and Vertanen, Keith and Kristensson, Per Ola},
title = {Uncertain Text Entry on Mobile Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557412},
doi = {10.1145/2556288.2557412},
abstract = {Users often struggle to enter text accurately on touchscreen keyboards. To address this, we present a flexible decoder for touchscreen text entry that combines probabilistic touch models with a language model. We investigate two different touch models. The first touch model is based on a Gaussian Process regression approach and implicitly models the inherent uncertainty of the touching process. The second touch model allows users to explicitly control the uncertainty via touch pressure. Using the first model we show that the character error rate can be reduced by up to 7% over a baseline method, and by up to 1.3% over a leading commercial keyboard. Using the second model we demonstrate that providing users with control over input certainty reduces the amount of text users have to correct manually and increases the text entry rate.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2307–2316},
numpages = {10},
keywords = {mobile text entry, keyboard error correction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250958,
author = {Kr\"{u}ger, Antonio},
title = {Session Details: Emotions and Mobiles},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250958},
doi = {10.1145/3250958},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557295,
author = {Meschtscherjakov, Alexander and Wilfinger, David and Tscheligi, Manfred},
title = {Mobile Attachment Causes and Consequences for Emotional Bonding with Mobile Phones},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557295},
doi = {10.1145/2556288.2557295},
abstract = {This paper addresses the phenomenon of emotional attachments to mobile phones. We introduce the term "mobile attachment" and define it as a bond between a person's self and a mobile phone that varies in strength. Based on a critical reflection of interdisciplinary literature, a conceptual mobile attachment model is developed. Within this model causes, consequences and influencing factors of mobile attachment are exposed and elaborated. We argue that mobile attachment emerges when the mobile phone becomes part of the user's self concept. The link between the user and their mobile phone may be fostered when it empowers, enriches, or gratifies the user's self. Attachment causes lead to "design space determinants" that enable user experience designers to design for mobile attachment. Attachment consequences may be operationalized for user experience evaluation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2317–2326},
numpages = {10},
keywords = {user experience, mobile phones, emotional attachment},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557366,
author = {Lee, Uichin and Lee, Joonwon and Ko, Minsam and Lee, Changhun and Kim, Yuhwan and Yang, Subin and Yatani, Koji and Gweon, Gahgene and Chung, Kyong-Mee and Song, Junehwa},
title = {Hooked on Smartphones: An Exploratory Study on Smartphone Overuse among College Students},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557366},
doi = {10.1145/2556288.2557366},
abstract = {The negative aspects of smartphone overuse on young adults, such as sleep deprivation and attention deficits, are being increasingly recognized recently. This emerging issue motivated us to analyze the usage patterns related to smartphone overuse. We investigate smartphone usage for 95 college students using surveys, logged data, and interviews. We first divide the participants into risk and non-risk groups based on self-reported rating scale for smartphone overuse. We then analyze the usage data to identify between-group usage differences, which ranged from the overall usage patterns to app-specific usage patterns. Compared with the non-risk group, our results show that the risk group has longer usage time per day and different diurnal usage patterns. Also, the risk group users are more susceptible to push notifications, and tend to consume more online content. We characterize the overall relationship between usage features and smartphone overuse using analytic modeling and provide detailed illustrations of problematic usage behaviors based on interview data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2327–2336},
numpages = {10},
keywords = {smartphone overuse, measurement},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557067,
author = {Schaub, Florian and Seifert, Julian and Honold, Frank and M\"{u}ller, Michael and Rukzio, Enrico and Weber, Michael},
title = {Broken Display = Broken Interface': The Impact of Display Damage on Smartphone Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557067},
doi = {10.1145/2556288.2557067},
abstract = {This paper is the first to assess the impact of touchscreen damage on smartphone interaction. We gathered a dataset consisting of 95 closeup images of damaged smartphones and extensive information about a device's usage history, damage severity, and impact on use. 88% of our participants continued to use their damaged smartphone for at least three months; 32% plan to use it for another year or more, mainly due to high repair and replacement costs. From the dataset, we identified three categories of damaged smartphone displays. Reading and text input were most affected. Further interviews (n=11) revealed that users adapt to damage with diverse coping strategies, closely tailored to specific interaction issues. In total, we identified 23 different strategies. Based on our results, we proposed guidelines for interaction design in order to provide a positive user experience when display damage occurs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2337–2346},
numpages = {10},
keywords = {smartphone, broken display, user experience, display damage, mobile interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250959,
author = {Patil, Sameer},
title = {Session Details: Privacy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250959},
doi = {10.1145/3250959},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557421,
author = {Shklovski, Irina and Mainwaring, Scott D. and Sk\'{u}lad\'{o}ttir, Halla Hrund and Borgthorsson, H\"{o}skuldur},
title = {Leakiness and Creepiness in App Space: Perceptions of Privacy and Mobile App Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557421},
doi = {10.1145/2556288.2557421},
abstract = {Mobile devices are playing an increasingly intimate role in everyday life. However, users can be surprised when informed of the data collection and distribution activities of apps they install. We report on two studies of smartphone users in western European countries, in which users were confronted with app behaviors and their reactions assessed. Users felt their personal space had been violated in "creepy" ways. Using Altman's notions of personal space and territoriality, and Nissenbaum's theory of contextual integrity, we account for these emotional reactions and suggest that they point to important underlying issues, even when users continue using apps they find creepy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2347–2356},
numpages = {10},
keywords = {data privacy, bodily integrity, learned helplessness, creepiness, mobile devices},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557287,
author = {Davies, Nigel and Langheinrich, Marc and Clinch, Sarah and Elhart, Ivan and Friday, Adrian and Kubitza, Thomas and Surajbali, Bholanathsingh},
title = {Personalisation and Privacy in Future Pervasive Display Networks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557287},
doi = {10.1145/2556288.2557287},
abstract = {There is increasing interest in using digital signage to deliver highly personalised content. However, display personalization presents a number of architectural design challenges in particular, how best to provide personalisation without unduly compromising viewers' privacy. While previous research has focused on understanding specific elements of the overall vision, our work presents details of the first significant attempt at a system that integrates future pervasive display networks and mobile devices to support display personalisation. We describe a series of usage models and design goals for display personalisation and then present Tacita, a system that supports these models and goals. Our architecture includes mobile, display and cloud-based elements and provides comprehensive personalisation features while preventing the creation of user profiles within the display infrastructure, thus helping to preserve users' privacy. An initial evaluation of our prototype implementation of the architecture is also included and demonstrates the viability of the Tacita approach.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2357–2366},
numpages = {10},
keywords = {digital signage, architecture, privacy, personalisation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557413,
author = {Wang, Yang and Leon, Pedro Giovanni and Acquisti, Alessandro and Cranor, Lorrie Faith and Forget, Alain and Sadeh, Norman},
title = {A Field Trial of Privacy Nudges for Facebook},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557413},
doi = {10.1145/2556288.2557413},
abstract = {Anecdotal evidence and scholarly research have shown that Internet users may regret some of their online disclosures. To help individuals avoid such regrets, we designed two modifications to the Facebook web interface that nudge users to consider the content and audience of their online disclosures more carefully. We implemented and evaluated these two nudges in a 6-week field trial with 28 Facebook users. We analyzed participants' interactions with the nudges, the content of their posts, and opinions collected through surveys. We found that reminders about the audience of posts can prevent unintended disclosures without major burden; however, introducing a time delay before publishing users' posts can be perceived as both beneficial and annoying. On balance, some participants found the nudges helpful while others found them unnecessary or overly intrusive. We discuss implications and challenges for designing and evaluating systems to assist users with online disclosures.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2367–2376},
numpages = {10},
keywords = {regret, online disclosure, facebook, behavioral bias, social media, soft-paternalism, privacy, nudge},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557352,
author = {Denning, Tamara and Dehlawi, Zakariya and Kohno, Tadayoshi},
title = {In Situ with Bystanders of Augmented Reality Glasses: Perspectives on Recording and Privacy-Mediating Technologies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557352},
abstract = {Augmented reality (AR) devices are poised to enter the market. It is unclear how the properties of these devices will affect individuals' privacy. In this study, we investigate the privacy perspectives of individuals when they are bystanders around AR devices. We conducted 12 field sessions in caf\'{e}s and interviewed 31 bystanders regarding their reactions to a co-located AR device. Participants were predominantly split between having indifferent and negative reactions to the device. Participants who expressed that AR devices change the bystander experience attributed this difference to subtleness, ease of recording, and the technology's lack of prevalence. Additionally, participants surfaced a variety of factors that make recording more or less acceptable, including what they are doing when the recording is being taken. Participants expressed interest in being asked permission before being recorded and in recording-blocking devices. We use the interview results to guide an exploration of design directions for privacy-mediating technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2377–2386},
numpages = {10}
}

@inproceedings{10.1145/3250960,
author = {Comber, Rob},
title = {Session Details: Issues That Matter},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250960},
doi = {10.1145/3250960},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557022,
author = {Moran, Stuart and Pantidi, Nadia and Rodden, Tom and Chamberlain, Alan and Griffiths, Chloe and Zilli, Davide and Merrett, Geoff and Rogers, Alex},
title = {Listening to the Forest and Its Curators: Lessons Learnt from a Bioacoustic Smartphone Application Deployment},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557022},
doi = {10.1145/2556288.2557022},
abstract = {Our natural environment is complex and sensitive, and is home to a number of species on the verge of extinction. Surveying is one approach to their preservation, and can be supported by technology. This paper presents the deployment of a smartphone-based citizen science biodiversity application. Our findings from interviews with members of the biodiversity community revealed a tension between the technology and their established working practices. From our experience, we present a series of general guidelines for those designing citizen science apps.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2387–2396},
numpages = {10},
keywords = {community practices, tension, bioacoustics, participatory sensing, tradition, citizen science, biodiversity, mobile},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557359,
author = {DiSalvo, Carl and Lukens, Jonathan and Lodato, Thomas and Jenkins, Tom and Kim, Tanyoung},
title = {Making Public Things: How HCI Design Can Express Matters of Concern},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557359},
doi = {10.1145/2556288.2557359},
abstract = {Science studies scholar Bruno Latour suggests that contemporary democracy is shifting from "matters of fact"to "matters of concern": contentious conditions entwined with everyday life. What is the role of human-computer interaction (HCI) design in this shift' In this paper we draw from five design projects to explore how design can express matters of concern by communicating the factors and consequences of issues. In the process, we consider the role of design in contributing to the formation of publics and discuss an emerging orientation to publics in HCI design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2397–2406},
numpages = {10},
keywords = {publics, matters of concern, public design, design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557193,
author = {Pater, Jessica Annette and Nadji, Yacin and Mynatt, Elizabeth D. and Bruckman, Amy S.},
title = {Just Awful Enough: The Functional Dysfunction of the Something Awful Forums},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557193},
doi = {10.1145/2556288.2557193},
abstract = {The Something Awful Forums (SAF) is an online community comprised of a loosely connected federation of forums, united in a distinctive brand of humor with a focus on the quality of member contributions. In this case study we find that the site has sustained success while deviating from common conventions and norms of online communities. Humor and the quality of content contributed by SAF members foster practices that seem counterintuitive to the development of a stable and thriving community. In this case study we show how design decisions are contextual and inter-dependent and together these heuristics create a different kind of online third place that challenges common practices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2407–2410},
numpages = {4},
keywords = {case study, third place, design, online community},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250961,
author = {Kelley, Patrick Gage},
title = {Session Details: Understanding and Using Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250961},
doi = {10.1145/3250961},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557273,
author = {Linder, Rhema and Snodgrass, Clair and Kerne, Andruid},
title = {Everyday Ideation: All of My Ideas Are on Pinterest},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557273},
doi = {10.1145/2556288.2557273},
abstract = {We develop new understanding of how people engage in digital curation. We interview twenty users of Pinterest, a social curation platform. We find that through collecting, organizing, and sharing image bookmarks, users engage in processes of everyday ideation. That is, they use digital found objects as creative resources to develop ideas for shaping their lives. Curators assemble information into new contexts, forming and sharing ideas with practical and emotional value. We investigate cognitive and social aspects of creativity that affect the digital curation practices of everyday ideation. We derive implications for the design of curation environments that support information-based ideation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2411–2420},
numpages = {10},
keywords = {curation, pinterest, everyday design, information-based ideation, creativity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557363,
author = {Wisniewski, Pamela and Xu, Heng and Chen, Yunan},
title = {Understanding User Adaptation Strategies for the Launching of Facebook Timeline},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557363},
doi = {10.1145/2556288.2557363},
abstract = {This paper applies coping theory to understand user adaptation strategies to major interface changes on Social Networking Sites (SNSs). Specifically, we qualitatively examine 1,149 user comments posted to the Facebook's official Timeline blog in order to get a large and unobtrusive sample of real Facebook users' perceptions about the launch of Timeline. Our data suggests a high level of stress associated with the transition to the new interface introduced by Timeline. We also found evidence which suggests that increasing users' perceptions of control over major interface changes may help facilitate user adaptation to these changes. This study offers valuable insights to SNSs for mitigating user stress and facilitating successful adaptation during major interface changes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2421–2430},
numpages = {10},
keywords = {facebook timeline, privacy, user adaptation, stress, coping, change},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557291,
author = {Zhao, Xuan and Lindley, Si\^{a}n E.},
title = {Curation through Use: Understanding the Personal Value of Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557291},
doi = {10.1145/2556288.2557291},
abstract = {Content generation on social network sites has been considered mainly from the perspective of individuals interacting with social network contacts. Yet research has also pointed to the potential for social media to become a meaningful personal archive over time. The aim of this paper is to consider how social media, over time and across sites, forms part of the wider digital archiving space for individuals. Our findings, from a qualitative study of 14 social media users, highlight how although some sites are more associated with 'keepable' social media than others, even those are not seen as archives in the usual sense of the word. We show how this perception is bound up with five contradictions, which center on social media as curated, as a reliable repository of meaningful content, as readily encountered and as having the potential to present content as a compelling narrative. We conclude by highlighting opportunities for design relating to curation through use and what this implies for personal digital archives, which are known to present difficulties in terms of curation and re-finding.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2431–2440},
numpages = {10},
keywords = {archive, exhibition, personal information management},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557070,
author = {Schirra, Steven and Sun, Huan and Bentley, Frank},
title = {Together Alone: Motivations for Live-Tweeting a Television Series},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557070},
doi = {10.1145/2556288.2557070},
abstract = {In this paper, we explore motivations for live-tweeting across a season of a television show. Using the third season of Downton Abbey as a case study, we followed 2,234 live-tweeters from the show's premiere episode to its finale, finding that nearly a third of users returned each week to tweet. Semi-structured interviews with 11 diverse live-tweeters revealed that the decision to live-tweet is dependent upon a variety of personal considerations and social conventions forming around this emerging TV viewing practice. This includes the desire to feel connected to a larger community that is interested in the show. Participants actively sought to protect the user experience of others by following good live-tweeting "etiquette", including limiting their number of posts and censoring content that might spoil the show for others. Over time, live-tweeting helped users build and maintain a network of fellow Downton Abbey viewers with shared interests.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2441–2450},
numpages = {10},
keywords = {live-tweeting, social television, user research, second screen, annotation, twitter},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250962,
author = {Furniss, Dominic},
title = {Session Details: Working Together},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250962},
doi = {10.1145/3250962},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557305,
author = {Christensen, Lars Rune and Bjorn, Pernille},
title = {Documentscape: Intertextuality, Sequentiality, &amp; Autonomy at Work},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557305},
doi = {10.1145/2556288.2557305},
abstract = {On the basis of an ethnographic field study, this article introduces the concept of documentscape to the analysis of document-centric work practices. The concept of documentscape refers to the entire ensemble of documents in their mutual intertextual interlocking. Providing empirical data from a global software development case, we show how hierarchical structures and sequentiality across the interlocked documents are critical to how actors make sense of the work of others and what to do next in a geographically distributed setting. Furthermore, we found that while each document is created as part of a quasi-sequential order, this characteristic does not make the document, as a single entity, into a stable object. Instead, we found that the documents were malleable and dynamic while suspended in intertextual structures. Our concept of documentscape points to how the hierarchical structure, sequentiality, and authorless nature of documents serve as a constitutive platform for the development of iterative and emergent work practices, making it possible for highly distributed actors to collaborate with limited communication, as the documentscape serves as a vehicle of coordination.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2451–2460},
numpages = {10},
keywords = {documentscape, global software development, "documents, global interaction"},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557042,
author = {Massey, Charlotte and Lennig, Thomas and Whittaker, Steve},
title = {Cloudy Forecast: An Exploration of the Factors Underlying Shared Repository Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557042},
doi = {10.1145/2556288.2557042},
abstract = {Many teams are now adopting shared repositories for their work. Such adoption is paradoxical, however, as past research has repeatedly shown major co-organizational barriers; teams cannot agree a common organizational scheme, making it difficult to retrieve information organized by others. Another barrier is email competition; email provides a reliable alternative for distributing files that are then personally organized. To address this paradox, we explored how 27 participants actively using shared repositories overcome these barriers in a qualitative study. We found teams addressed co-organization using 4 strategies. First they create ContentMaps that provide explicit structure to organize shared information. Participants also co-organize using implicit strategies based on task structure, expertise, and tool affordances. Greater shared repository use also leads to a changed role for email. Versioning problems mean email is not used for distributing attachments, instead for task management. We present technical implications suggesting how new tools might be better integrated with email facilitating these continued email uses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2461–2470},
numpages = {10},
keywords = {co-organization, email competition, contentmaps, shared repositories, versioning},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557072,
author = {Forte, Andrea and Andalibi, Nazanin and Park, Thomas and Willever-Farr, Heather},
title = {Designing Information Savvy Societies: An Introduction to Assessability},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557072},
doi = {10.1145/2556288.2557072},
abstract = {This paper provides first steps toward an empirically grounded design vocabulary for assessable design as an HCI response to the global need for better information literacy skills. We present a framework for synthesizing literatures called the Interdisciplinary Literacy Framework and use it to highlight gaps in our understanding of information literacy that HCI as a field is particularly well suited to fill. We report on two studies that lay a foundation for developing guidelines for assessable information system design. The first is a study of Wikipedians', librarians', and laypersons' information assessment practices from which we derive two important features of assessable designs: information provenance and stewardship. The second is an experimental study in which we operationalize these concepts in designs and test them using Amazon Mechanical Turk (MTurk).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2471–2480},
numpages = {10},
keywords = {wikipedia, information literacy, credibility, assessability},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250963,
author = {Chevalier, Fanny},
title = {Session Details: Programming and Development Tools},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250963},
doi = {10.1145/3250963},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557409,
author = {Lieber, Tom and Brandt, Joel R. and Miller, Rob C.},
title = {Addressing Misconceptions about Code with Always-on Programming Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557409},
doi = {10.1145/2556288.2557409},
abstract = {We present Theseus, an IDE extension that visualizes run-time behavior within a JavaScript code editor. By displaying real-time information about how code actually behaves during execution, Theseus proactively addresses misconceptions by drawing attention to similarities and differences between the programmer's idea of what code does and what it actually does. To understand how programmers would respond to this kind of an always-on visualization, we ran a lab study with graduate students, and interviewed 9 professional programmers who were asked to use Theseus in their day-to-day work. We found that users quickly adopted strategies that are unique to always-on, real-time visualizations, and used the additional information to guide their navigation through their code.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2481–2490},
numpages = {10},
keywords = {debugging, programming, code understanding},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556998,
author = {Fast, Ethan and Steffee, Daniel and Wang, Lucy and Brandt, Joel R. and Bernstein, Michael S.},
title = {Emergent, Crowd-Scale Programming Practice in the IDE},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556998},
doi = {10.1145/2556288.2556998},
abstract = {While emergent behaviors are uncodified across many domains such as programming and writing, interfaces need explicit rules to support users. We hypothesize that by codifying emergent programming behavior, software engineering interfaces can support a far broader set of developer needs. To explore this idea, we built Codex, a knowledge base that records common practice for the Ruby programming language by indexing over three million lines of popular code. Codex enables new data-driven interfaces for programming systems: statistical linting, identifying code that is unlikely to occur in practice and may constitute a bug; pattern annotation, automatically discovering common programming idioms and annotating them with metadata using expert crowdsourcing; and library generation, constructing a utility package that encapsulates and reflects emergent software practice. We evaluate these applications to find Codex captures a broad swatch of programming practice, statistical linting detects problematic code snippets, and pattern annotation discovers nontrivial idioms such as basic HTTP authentication and database migration templates. Our work suggests that operationalizing practice-driven knowledge in structured domains such as programming can enable a new class of user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2491–2500},
numpages = {10},
keywords = {data mining, programming tools},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557350,
author = {Atachiants, Roman and Gregg, David and Jarvis, Kim and Doherty, Gavin},
title = {Design Considerations for Parallel Performance Tools},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557350},
doi = {10.1145/2556288.2557350},
abstract = {In recent years there has been a shift in microprocessor manufacture from building single-core processors towards providing multiple cores on the same chip. This shift has meant that a much wider population of developers are faced with the task of developing parallel software: a difficult, time consuming and expensive process. With the aim of identifying issues, emerging practices and design opportunities for support, we present in this paper a qualitative study in which we interviewed a range of software developers, in both industry and academia. We then perform a systematic analysis of the data and identify several cross-cutting themes. These analysis themes include the practical relevance of the probe effect, the significance of orchestration models in development and the mismatch between currently available tools and developers' needs. We also identify an important characteristic of parallel programming, where the process of optimisation goes hand in hand with the process of debugging, as opposed to clearer distinctions which may be made in traditional programming. We conclude with reflection on how the study can inform the design of software tools to support developers in the endeavour of parallel programming.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2501–2510},
numpages = {10},
keywords = {visualisation, multi-core, parallel programing, qualitative study, many-core},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557073,
author = {Henley, Austin Z. and Fleming, Scott D.},
title = {The Patchworks Code Editor: Toward Faster Navigation with Less Code Arranging and Fewer Navigation Mistakes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557073},
doi = {10.1145/2556288.2557073},
abstract = {Increasingly, people are faced with navigating large information spaces, and making such navigation efficient is of paramount concern. In this paper, we focus on the problems programmers face in navigating large code bases, and propose a novel code editor, Patchworks, that addresses the problems. In particular, Patchworks leverages two new interface idioms - the patch grid and the ribbon - to help programmers navigate more quickly, make fewer navigation errors, and spend less time arranging their code. To validate Patchworks, we conducted a user study that compared Patchworks to two existing code editors: the traditional file-based editor, Eclipse, and the newer canvas-based editor, Code Bubbles. Our results showed (1) that programmers using Patchworks were able to navigate significantly faster than with Eclipse (and comparably with Code Bubbles), (2) that programmers using Patchworks made significantly fewer navigation errors than with Code Bubbles or Eclipse, and (3) that programmers using Patchworks spent significantly less time arranging their code than with Code Bubbles (and comparably with Eclipse).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2511–2520},
numpages = {10},
keywords = {navigation, code editor, integrated development environment (ide), user study},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250964,
author = {Zhou, Xiaomu},
title = {Session Details: Interactive Technologies for Rehabilitation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250964},
doi = {10.1145/3250964},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557353,
author = {Ayoade, Mobolaji and Baillie, Lynne},
title = {A Novel Knee Rehabilitation System for the Home},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557353},
doi = {10.1145/2556288.2557353},
abstract = {In this paper, we describe the design and evaluation of an interactive home-based rehabilitation visualisation system used by a wide variety of ages (users in our studies were aged from 47-89) to undertake rehabilitation in the home following knee replacement surgery. We present the rehabilitation visualization system and the results of a randomized controlled study in which we investigated the usability and feasibility of the system in the home. We found that our users were able to use the system successfully for their rehabilitation with improved rehabilitation outcomes after 6 weeks when compared to the current rehabilitation care. Finally we highlight the lessons learned which will benefit prospective designers of home rehabilitation technology in ensuring successful home evaluations in clinical rehabilitation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2521–2530},
numpages = {10},
keywords = {home knee rehabilitation, usability, user design, visualizations, inertial sensors},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557278,
author = {Mazilu, Sinziana and Blanke, Ulf and Hardegger, Michael and Tr\"{o}ster, Gerhard and Gazit, Eran and Hausdorff, Jeffrey M.},
title = {GaitAssist: A Daily-Life Support and Training System for Parkinson's Disease Patients with Freezing of Gait},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557278},
doi = {10.1145/2556288.2557278},
abstract = {Patients with Parkinson's disease often experience freezing of gait, which bears a high risk of falling, a prevalent cause for morbidity and mortality. In this work we present GaitAssist, a wearable system for freezing of gait support in daily life. The system provides real-time auditory cueing after the onset of freezing episodes. Furthermore, GaitAssist implements training exercises to learn how to handle freezing situations. GaitAssist is the result of a design process where we considered the input of engineers, clinicians and 18 Parkinson's disease patients, in order to find an optimal trade-off between system wearability and performance. We tested the final system in a user study with 5 additional patients. They reported a reduction in the freezing of gait duration as a result of the auditory stimulation provided, and that they feel the system enhanced their confidence during walking.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2531–2540},
numpages = {10},
keywords = {on-body sensors, gait impairment, wearable support, freezing of gait, user-centered},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557416,
author = {Huang, Kevin and Sparto, Patrick J. and Kiesler, Sara and Smailagic, Asim and Mankoff, Jennifer and Siewiorek, Dan},
title = {A Technology Probe of Wearable In-Home Computer-Assisted Physical Therapy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557416},
doi = {10.1145/2556288.2557416},
abstract = {Physical therapists could make better treatment decisions if they had accurate patient home exercise data but today this information is only available from patient self-report. A more accurate source of data could be gained from wearable computing designed for physical therapy exercise support. Existing systems have been tested in the lab but we have little information about issues they may face in home settings. We designed a technology probe, SenseCap, and deployed it for seven days in ten physical therapy patients' homes. SenseCap is a wearable physical therapy support system that gathers patient exercise compliance and performance data and summarizes the data in charts on an iPad Dashboard for physical therapists to view when patients return to the clinic. In this paper, we present the results of our deployment, show in-home patient exercise data gathered by the probe, and make design recommendations based on patient and physical therapist responses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2541–2550},
numpages = {10},
keywords = {rehabilitation, technology probe, ubiquitous computing, wearable, exercise, mobile, ipod, physical therapy, quantifying},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557092,
author = {McNaney, Roisin and Vines, John and Roggen, Daniel and Balaam, Madeline and Zhang, Pengfei and Poliakov, Ivan and Olivier, Patrick},
title = {Exploring the Acceptability of Google Glass as an Everyday Assistive Device for People with Parkinson's},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557092},
doi = {10.1145/2556288.2557092},
abstract = {We describe a qualitative study investigating the acceptability of the Google Glass eyewear computer to people with Parkinson's disease (PD). We held a workshop with 5 PD patients and 2 carers exploring perceptions of Glass. This was followed by 5-day field trials of Glass with 4 PD patients, where participants wore the device during everyday activities at home and in public. We report generally positive responses to Glass as a device to instil confidence and safety for this potentially vulnerable group. We also raise concerns related to the potential for Glass to reaffirm dependency on others and stigmatise wearers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2551–2554},
numpages = {4},
keywords = {field trial, parkinson's disease, google glass, qualitative},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2556981,
author = {Zhang, Qiao and Gollakota, Shyamnath and Taskar, Ben and Rao, Raj P.N.},
title = {Non-Intrusive Tongue Machine Interface},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556981},
abstract = {There has been recent interest in designing systems that use the tongue as an input interface. Prior work however either require surgical procedures or in-mouth sensor placements. In this paper, we introduce TongueSee, a non-intrusive tongue machine interface that can recognize a rich set of tongue gestures using electromyography (EMG) signals from the surface of the skin. We demonstrate the feasibility and robustness of TongueSee with experimental studies to classify six tongue gestures across eight participants. TongueSee achieves a classification accuracy of 94.17% and a false positive probability of 0.000358 per second using three-protrusion preamble design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2555–2558},
numpages = {4}
}

@inproceedings{10.1145/3250965,
author = {Karnik, Abhijit},
title = {Session Details: Shape-Changing Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250965},
doi = {10.1145/3250965},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557360,
author = {Gr\"{o}nvall, Erik and Kinch, Sofie and Petersen, Marianne Graves and Rasmussen, Majken K.},
title = {Causing Commotion with a Shape-Changing Bench: Experiencing Shape-Changing Interfaces in Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557360},
doi = {10.1145/2556288.2557360},
abstract = {In this paper we describe results from testing coMotion, a shape-changing bench, in three different contexts: a concert hall foyer, an airport departure hall and a shopping mall. We have gathered insights from more than 120 people, with regard to how users experience and make sense of the bench's shape changing capability. The paper applies McCarthy and Wright's six different sense making processes (anticipating, connecting, interpreting, reflecting, appropriating and recounting) as an instrument to analyse people's experience with shape-changing furniture in the wild. The paper also introduces exploring as a seventh sense making process. Based on this analysis, the paper points to three relevant aspects when designing shape-changing artefacts for the wild, namely: 1) Affordance of shape-changing interfaces, 2) Transitions between background and foreground and 3) Interpreting physically dynamic objects.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2559–2568},
numpages = {10},
keywords = {sense-making, interactive furniture, in situ, user experience, design, shape-changing interface},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557340,
author = {Ramakers, Raf and Sch\"{o}ning, Johannes and Luyten, Kris},
title = {Paddle: Highly Deformable Mobile Devices with Physical Controls},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557340},
doi = {10.1145/2556288.2557340},
abstract = {We present the concept of highly deformable mobile devices that can be transformed into various special-purpose controls in order to bring physical controls to mobile devices. Physical controls have the advantage of exploiting people's innate abilities for manipulating physical objects in the real world. We designed and implemented a prototype, called Paddle, to demonstrate our concept. Additionally, we explore the interaction techniques enabled by this concept and conduct an in-depth study to evaluate our transformable physical controls. Our findings show that these physical controls provide several benefits over traditional touch interaction techniques commonly used on mobile devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2569–2578},
numpages = {10},
keywords = {deformable interfaces, tangible interfaces, mobile devices},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557018,
author = {Pedersen, Esben W. and Subramanian, Sriram and Hornb\ae{}k, Kasper},
title = {Is My Phone Alive? A Large-Scale Study of Shape Change in Handheld Devices Using Videos},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557018},
doi = {10.1145/2556288.2557018},
abstract = {Shape-changing handheld devices are emerging as research prototypes, but it is unclear how users perceive them and which experiences they engender. The little data we have on user experience is from single prototypes, only covering a small part of the possibilities in shape change. We produce 51 videos of a shape-changing handheld device by systematically varying seven parameters of shape change. In a crowd-sourced study, 187 participants watched the videos and described their experiences using rating scales and free text. We find significant and large differences among parameters of shape change. Shapes that have previously been used for notifications were rated the least urgent; the degree of shape change was found to impact experience more than type of shape change. The experience of shape change was surprisingly complex: hedonic quality were inversely related to urgency, and some shapes were perceived as ugly, yet useful. We discuss how to advance models of shape change and improve research on the experience of shape change.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2579–2588},
numpages = {10},
keywords = {actuated interfaces, shape displays, organic user interfaces, shape-changing interfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557164,
author = {Dimitriadis, Panteleimon and Alexander, Jason},
title = {Evaluating the Effectiveness of Physical Shape-Change for in-Pocket Mobile Device Notifications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557164},
doi = {10.1145/2556288.2557164},
abstract = {Audio and vibrotactile output are the standard mechanisms mobile devices use to attract their owner's attention. Yet in busy and noisy environments, or when the user is physically active, these channels sometimes fail. Recent work has explored the use of physical shape-change as an additional method for conveying notifications when the device is in-hand or viewable. However, we do not yet understand the effectiveness of physical shape-change as a method for communicating in-pocket notifications. This paper presents three robustly implemented, mobile-device sized shape-changing devices, and two user studies to evaluate their effectiveness at conveying notifications. The studies reveal that (1) different types and configurations of shape-change convey different levels of urgency and; (2) fast pulsing shape-changing notifications are missed less often and recognised more quickly than the standard slower vibration pulse rates of a mobile device.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2589–2592},
numpages = {4},
keywords = {mobile devices, shape-change, notifications},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557006,
author = {Roudaut, Anne and Reed, Rebecca and Hao, Tianbo and Subramanian, Sriram},
title = {Changibles: Analyzing and Designing Shape Changing Constructive Assembly},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557006},
doi = {10.1145/2556288.2557006},
abstract = {Advances in shape changing assemblies have been made in reconfiguration algorithms, hardware designs and interaction techniques. However no tools exist for guiding designers in building those modular devices and especially for choosing the shape of the units. The task becomes even more complex when the units themselves can change their shapes to animate the entire assembly. In this paper, we contribute with the first analysis tool which helps the designer to both choose the right subset of forms for the units and to create an assembly with maximum accuracy from the set of given objects. We introduce the concept of Changibles that are interactive wireless units that can reshape themselves and be attached together to create an animated assembly. We present a use case to demonstrate the use of our tool, with an instantiation of six Changibles that are used to construct a pulsing heart assembly.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2593–2596},
numpages = {4},
keywords = {modular robot., actuated display, shape changing object, constructive assembly},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250966,
author = {Wigdor, Daniel},
title = {Session Details: Touch Input},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250966},
doi = {10.1145/3250966},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557234,
author = {Heo, Seongkook and Gu, Jiseong and Lee, Geehyuk},
title = {Expanding Touch Input Vocabulary by Using Consecutive Distant Taps},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557234},
doi = {10.1145/2556288.2557234},
abstract = {In recent years, touch screens have emerged and matured as the main input interface for mobile and tablet computers calling for extended touch input possibilities. In this paper, we explore the use of consecutive distant taps to expand the touch screen input vocabulary. We analyzed time intervals and distances between consecutive taps during common applications on a tablet and verified that consecutive distant taps can be used conflict-free with existing touch gestures. We designed the two interaction techniques Ta-tap and Ta-Ta-tap that utilize consecutive distant taps. Ta-tap uses two consecutive distant taps to invoke alternative touch operations for multi-touch emulation, whereas Ta-Ta-tap uses a series of consecutive distant taps to define a spatial gesture. We verified the feasibility of both interaction techniques through a series of experiments and a user study. The high recognition rate of Ta-tap and Ta-Ta-tap gestures, the few conflicts with existing gestures, and the positive feedback from the participants assert the potential of consecutive distant taps as a new design space to enrich touch screen interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2597–2606},
numpages = {10},
keywords = {consecutive distant taps, command shortcut, touch screen, ta-tap, ta-ta-tap},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557096,
author = {Au, Oscar Kin-Chung and Su, Xiaojun and Lau, Rynson W.H.},
title = {LinearDragger: A Linear Selector for One-Finger Target Acquisition},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557096},
doi = {10.1145/2556288.2557096},
abstract = {Touch input is increasingly popular nowadays, especially for mobile devices such as smartphones and tablet computers. However, the human finger has considerably large fingertip size and finger input is imprecise. As such, acquiring small targets on a touch screen is still a challenging task. In this paper, we present the LinearDragger, a new and integrated one-finger target acquisition technique for small and clustered targets. The proposed method has three advantages. First, it allows users to select targets in dense clustered groups easily with a single touch-drag-release operation. Second, it maps the 2D selection problem into a more precise 1D selection problem, which is independent of the target distribution. Third, it avoids finger occlusion and does not create visual distraction. As a result, it is particularly suitable for applications with dense targets and rich visual elements. Results of our controlled experiments show that when selecting small targets, LinearDragger takes about 70% and 30% less selection time than target acquisition without using any techniques and with the state-of-the-art target acquisition technique that involves a single touch operation, respectively, while maintaining a reasonable error rate.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2607–2616},
numpages = {10},
keywords = {touch input, target acquisition, dense target selection},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557136,
author = {Gutwin, Carl and Cockburn, Andy and Scarr, Joey and Malacria, Sylvain and Olson, Scott C.},
title = {Faster Command Selection on Tablets with FastTap},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557136},
doi = {10.1145/2556288.2557136},
abstract = {Touch-based tablet UIs provide few shortcut mechanisms for rapid command selection; as a result, command selection on tablets often requires slow traversal of menus. We developed a new selection technique for multi-touch tablets, called FastTap, that uses thumb-and-finger touches to show and choose from a spatially-stable grid-based overlay interface. FastTap allows novices to view and inspect the full interface, but once item locations are known, FastTap allows people to select commands with a single quick thumb-and-finger tap. The interface helps users develop expertise, since the motor actions carried out as a novice rehearse the expert behavior. A controlled study showed that FastTap was significantly faster (by 33% per selection overall) than marking menus, both for novices and experts, and without reduction in accuracy or subjective preference. Our work introduces a new and efficient selection mechanism that supports rapid command execution on touch tablets, for both novices and experts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2617–2626},
numpages = {10},
keywords = {expertise, command selection, tablet uis},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557397,
author = {Luo, Yuexing and Vogel, Daniel},
title = {Crossing-Based Selection with Direct Touch Input},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557397},
doi = {10.1145/2556288.2557397},
abstract = {Fundamental performance results for crossing-based selec-tion tasks with direct touch input are presented. A close adaptation of Accot and Zhai's indirect stylus crossing ex-periment reveals similar trends for direct touch input: touch crossing task time is faster or equivalent to touch pointing; continuous selection of large orthogonal crossing targets is most effective; and continuous selection of small collinear targets is least effective. Unlike indirect stylus and mouse crossing, not every kind of direct touch pointing perfor-mance is modeled accurately with standard Fitts' law. Instead, Fitts' law, used previously for touch pointing with small targets, is used to more accurately model discrete touch crossing with a directionally constrained target. In addition, visual touch feedback is shown to have a strong effect on absolute accuracy. Our work empirically validates touch crossing as a practical and efficient selection technique, and motivates the exploration of novel forms of expressive multi-touch crossing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2627–2636},
numpages = {10},
keywords = {stylus input, pointing, pen input, crossing, touch input, multi-touch, goal crossing, fitts, target selection, ffitts},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250967,
author = {De Luca, Alexander},
title = {Session Details: Risks and Security},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250967},
doi = {10.1145/3250967},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557322,
author = {Bursztein, Elie and Moscicki, Angelique and Fabry, Celine and Bethard, Steven and Mitchell, John C. and Jurafsky, Dan},
title = {Easy Does It: More Usable CAPTCHAs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557322},
doi = {10.1145/2556288.2557322},
abstract = {Websites present users with puzzles called CAPTCHAs to curb abuse caused by computer algorithms masquerading as people. While CAPTCHAs are generally effective at stopping abuse, they might impair website usability if they are not properly designed. In this paper we describe how we designed two new CAPTCHA schemes for Google that focus on maximizing usability. We began by running an evaluation on Amazon Mechanical Turk with over 27,000 respondents to test the usability of different feature combinations. Then we studied user preferences using Google's consumer survey infrastructure. Finally, drawing on the insights gleaned during those studies, we tested our new captcha schemes first on Mechanical Turk and then on a fraction of production traffic. The resulting scheme is now an integral part of our production system and is served to millions of users. Our scheme achieved a 95.3% human accuracy, a 6.7.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2637–2646},
numpages = {10},
keywords = {world wide web, quantitative usability testing and evaluation, CAPTCHA, empirical methods, user studies, security},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556978,
author = {Harbach, Marian and Hettig, Markus and Weber, Susanne and Smith, Matthew},
title = {Using Personal Examples to Improve Risk Communication for Security &amp; Privacy Decisions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556978},
doi = {10.1145/2556288.2556978},
abstract = {IT security systems often attempt to support users in taking a decision by communicating associated risks. However, a lack of efficacy as well as problems with habituation in such systems are well known issues. In this paper, we propose to leverage the rich set of personal data available on smartphones to communicate risks using personalized examples. Examples of private information that may be at risk can draw the users' attention to relevant information for a decision and also improve their response. We present two experiments that validate this approach in the context of Android app permissions. Private information that becomes accessible given certain permissions is displayed when a user wants to install an app, demonstrating the consequences this installation might have. We find that participants made more privacy-conscious choices when deciding which apps to install. Additionally, our results show that our approach causes a negative affect in participants, which makes them pay more attention.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2647–2656},
numpages = {10},
keywords = {privacy, personalization, usable security, risks, consequences, examples, android, permissions},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557330,
author = {Shay, Richard and Ion, Iulia and Reeder, Robert W. and Consolvo, Sunny},
title = {"My Religious Aunt Asked Why i Was Trying to Sell Her Viagra": Experiences with Account Hijacking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557330},
doi = {10.1145/2556288.2557330},
abstract = {With so much of our lives digital, online, and not entirely under our control, we risk losing access to our communications, reputation, and data. Recent years have brought a rash of high-profile account compromises, but account hijacking is not limited to high-profile accounts. In this paper, we report results of a survey about people's experiences with and attitudes toward account hijacking. The problem is widespread; 30% of our 294 participants had an email or social networking account accessed by an unauthorized party. Five themes emerged from our results: (1) compromised accounts are often valuable to victims, (2) attackers are mostly unknown, but sometimes known, to victims, (3) users acknowledge some responsibility for keeping their accounts secure, (4) users' understanding of important security measures is incomplete, and (5) harm from account hijacking is concrete and emotional. We discuss implications for designing security mechanisms to improve chances for user adoption.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2657–2666},
numpages = {10},
keywords = {google consumer survey, account hijacking, mechanical turk, account compromise, attackers, microsurvey, online accounts, authentication, survey, security},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557292,
author = {Felt, Adrienne Porter and Reeder, Robert W. and Almuhimedi, Hazim and Consolvo, Sunny},
title = {Experimenting at Scale with Google Chrome's SSL Warning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557292},
doi = {10.1145/2556288.2557292},
abstract = {Web browsers show HTTPS authentication warnings (i.e., SSL warnings) when the integrity and confidentiality of users' interactions with websites are at risk. Our goal in this work is to decrease the number of users who click through the Google Chrome SSL warning. Prior research showed that the Mozilla Firefox SSL warning has a much lower click-through rate (CTR) than Chrome. We investigate several factors that could be responsible: the use of imagery, extra steps before the user can proceed, and style choices. To test these factors, we ran six experimental SSL warnings in Google Chrome 29 and measured 130,754 impressions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2667–2670},
numpages = {4},
keywords = {SSL warnings, interstitials, active warnings, browser security warnings, interruptive warnings},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557275,
author = {Vaniea, Kami E. and Rader, Emilee and Wash, Rick},
title = {Betrayed by Updates: How Negative Experiences Affect Future Security},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557275},
doi = {10.1145/2556288.2557275},
abstract = {Installing security-relevant software updates is one of the best computer protection mechanisms. However, users do not always choose to install updates. Through interviewing non-expert Windows users, we found that users frequently decide not to install future updates, regardless of whether they are important for security, after negative experiences with past updates. This means that even non-security updates (such as user interface changes) can impact the security of a computer. We discuss three themes impacting users' willingness to install updates: unexpected new features in an update, the difficulty of assessing whether an update is ``worth it', and confusion about why an update is necessary.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2671–2674},
numpages = {4},
keywords = {human factors, security, software updates},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/3250968,
author = {Sambasivan, Nithya},
title = {Session Details: CHI for Social Development},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250968},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1}
}

@inproceedings{10.1145/2556288.2557323,
author = {Balestrini, Mara and Bird, Jon and Marshall, Paul and Zaro, Alberto and Rogers, Yvonne},
title = {Understanding Sustained Community Engagement: A Case Study in Heritage Preservation in Rural Argentina},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557323},
doi = {10.1145/2556288.2557323},
abstract = {HCI projects are increasingly evaluating technologies in the wild, which typically involves working with communities over extended periods, often with the goal of effecting sustainable change. However, there are few descriptions of projects that have been successful in the long-term. In this paper we investigate what factors are important for developing long lasting community ICT interventions. We do this by analysing a successful action research project and provide five recommendations for facilitating sustained community engagement. CrowdMemo aimed to preserve local heritage in a town in rural Argentina and the project was set up so that it could be continued by the community once researchers had left. Participants created videos about personal memories of the town and over 600 people attended the premiere where they were first screened. The impact has not just been short-term and there has been sustained engagement with the project by stakeholders in the town and wider region: the local school integrated digital storytelling into its curriculum; the approach has been adopted by two nearby towns; and the project has influenced regional government educational policy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2675–2684},
numpages = {10},
keywords = {action research, research in the wild, digital storytelling, community engagement, hci4d},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557196,
author = {Durrant, Abigail C. and Kirk, David S. and Reeves, Stuart},
title = {Human Values in Curating a Human Rights Media Archive},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557196},
doi = {10.1145/2556288.2557196},
abstract = {Cultural institutions, such as museums, often curate politically and ethically sensitive materials. Increasingly, Internet-enabled, digital technology intersects with these curatorial practices offering new opportunities for public and scholarly engagement. We report on a case study of human rights media archiving at a genocide memorial centre in Rwanda, motivated by our interests in ICT support to memorialisation practices. Through an analysis of our discussions with staff about their work, we report on how accounts of the Rwandan Genocide are being captured and curated to support the centre's humanitarian agenda and associated values. We identify transferable curatorial concerns for human rights media communication amongst scholarly networks and public audiences worldwide, elucidating interaction design challenges for supportive ICT and contributing to HCI discourses on Value Sensitive Design and cultural engagement with sensitive materials.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2685–2694},
numpages = {10},
keywords = {genocide, rwanda, human rights media, value sensitive design, memorial, curation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557376,
author = {Ahmed, Syed Ishtiaque and Jackson, Steven J. and Ahmed, Nova and Ferdous, Hasan Shahid and Rifat, Md. Rashidujjaman and Rizvi, A.S.M and Ahmed, Shamir and Mansur, Rifat Sabbir},
title = {<i>Protibadi</i>: A Platform for Fighting Sexual Harassment in Urban Bangladesh},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557376},
doi = {10.1145/2556288.2557376},
abstract = {Public sexual harassment has emerged as a large and growing concern in urban Bangladesh, with deep and damaging implications for gender security, justice, and rights of public participation. In this paper we describe an integrated program of ethnographic and design work meant to understand and address such problems. For one year we conducted surveys, interviews, and focus groups around sexual harassment with women at three different universities in Dhaka. Based on this input, we developed "Protibadi", a web and mobile phone based application designed to report, map, and share women's stories around sexual harassment in public places. In August 2013 the system launched, user studies were conducted, and public responses were monitored to gauge reactions, strengths, and limits of the system. This paper describes the findings of our ethnographic and design-based work, and suggests lessons relevant to other HCI efforts to understand and design around difficult and culturally sensitive problems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2695–2704},
numpages = {10},
keywords = {design, sexual harassment, bangladesh, hci4d, postcolonial computing, ethnography, ictd},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557277,
author = {Oduor, Erick and Neustaedter, Carman and Judge, Tejinder K. and Hennessy, Kate and Pang, Carolyn and Hillman, Serena},
title = {How Technology Supports Family Communication in Rural, Suburban, and Urban Kenya},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557277},
doi = {10.1145/2556288.2557277},
abstract = {Much ICTD research for sub-Saharan Africa has focused on how technology related interventions have aimed to incorporate marginalized communities towards global economic growth. Our work builds on this. We present results from an exploratory qualitative study on the family communication practices of family members who communicate both within and between rural, suburban, and urban settings in Kenya. Our findings reveal that family communication focuses on economic support, well-being, life advice, and everyday coordination of activities. We also outline social factors that affect family communication, including being an eldest child, having a widowed sibling, and having reduced access to technology because of gender, literacy, or one's financial situation. Lastly, we discuss new opportunities for technology design and articulate the challenges that designers will face if creating or deploying family communication technologies in Kenya.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2705–2714},
numpages = {10},
keywords = {awareness, ict4d, mobile devices, family communication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250993,
author = {Nichols, Jeffrey},
title = {Session Details: Question and Answer Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250993},
doi = {10.1145/3250993},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557202,
author = {Piccardi, Tiziano and Convertino, Gregorio and Zancanaro, Massimo and Wang, Ji and Archambeau, Cedric},
title = {Towards Crowd-Based Customer Service: A Mixed-Initiative Tool for Managing Q&amp;A Sites},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557202},
doi = {10.1145/2556288.2557202},
abstract = {In this paper, we propose a mixed-initiative approach to integrate a Q&amp;A site based on a crowd of volunteers with a standard operator-based help desk, ensuring quality of customer service. Q&amp;A sites have emerged as an efficient way to address questions in various domains by leveraging crowd knowledge. However, they lack sufficient reliability to be the sole basis of customer service applications. We built a proof-of-concept mixed-initiative tool that helps a crowd-manager to decide if a question will get a satisfactory and timely answer by the crowd or if it should be redirected to a dedicated operator. A user experiment found that our tool reduced the participants' cognitive load and improved their performance, in terms of their precision and recall. In particular, those with higher performance benefited more than those with lower performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2725–2734},
numpages = {10},
keywords = {customer care, crowdsourcing, q&amp;a, mixed initiative},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557181,
author = {Rzeszotarski, Jeffrey M. and Morris, Meredith Ringel},
title = {Estimating the Social Costs of Friendsourcing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557181},
doi = {10.1145/2556288.2557181},
abstract = {Every day users of social networking services ask their followers and friends millions of questions. These friendsourced questions not only provide informational benefits, but also may reinforce social bonds. However, there is a limit to how much a person may want to friendsource. They may be uncomfortable asking questions that are too private, might not want to expend others' time or effort, or may feel as though they have already accrued too many social debts. These perceived social costs limit the potential benefits of friendsourcing. In this paper we explore the perceived social costs of friendsourcing on Twitter via a monetary choice. We develop a model of how users value the attention and effort of their social network while friendsourcing, compare and contrast it with paid question answering in a crowdsourced labor market, and provide future design considerations for better supporting friendsourcing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2735–2744},
numpages = {10},
keywords = {friendsourcing, crowdsourcing, twitter, sns q&amp;a},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557240,
author = {Liao, Q. Vera and Fu, Wai-Tat},
title = {Expert Voices in Echo Chambers: Effects of Source Expertise Indicators on Exposure to Diverse Opinions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557240},
doi = {10.1145/2556288.2557240},
abstract = {We studied how a source expertise indicator impacted users' information seeking behavior when using a system aggregating diverse opinions, and how it interacted with a source position indicator to shape users' selectivity of information. We found that, for both attitude consistent and inconsistent information, the expertise indicator increased the selection of sources indicated to have high expertise and decreased that of low expertise. Moreover, when both source expertise and position indicators were present, users' selective exposure tendency, i.e., preferential selection of attitude consistent sources over inconsistent ones, decreased among expert sources. Moreover, we found that the expertise indicator could benefit encouraging common ground seeking with different others by increasing the agreement with, and perceived expertise of inconsistent sources indicated to be experts. Design implications for moderating selective exposure by highlighting the utility of dissonant information were discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2745–2754},
numpages = {10},
keywords = {source expertise, selective exposure, diversity seeking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557175,
author = {Rzeszotarski, Jeffrey M. and Spiro, Emma S. and Matias, Jorge Nathan and Monroy-Hern\'{a}ndez, Andr\'{e}s and Morris, Meredith Ringel},
title = {Is Anyone out There? Unpacking Q&amp;A Hashtags on Twitter},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557175},
doi = {10.1145/2556288.2557175},
abstract = {In addition to posting news and status updates, many Twitter users post questions that seek various types of subjective and objective information. These questions are often labeled with 'Q&amp;A' hashtags, such as #lazyweb or #twoogle. We surveyed Twitter users and found they employ these Q&amp;A hashtags both as a topical signifier (this tweet needs an answer!) and to reach out to those beyond their immediate followers (a community of helpful tweeters who monitor the hashtag). However, our log analysis of thousands of hashtagged Q&amp;A exchanges reveals that nearly all replies to hashtagged questions come from a user's immediate follower network, contradicting users' beliefs that they are tapping into a larger community by tagging their question tweets. This finding has implications for designing next-generation social search systems that reach and engage a wide audience of answerers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2755–2758},
numpages = {4},
keywords = {information seeking, q&amp;a, hashtags, social search, twitter},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557081,
author = {Gilbert, Eric},
title = {What If We Ask a Different Question? Social Inferences Create Product Ratings Faster},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557081},
doi = {10.1145/2556288.2557081},
abstract = {Consumer product reviews are the backbone of commerce online. Most commonly, sites ask users for their personal opinions on a product or service. I conjecture, however, that this traditional method of eliciting reviews often invites idiosyncratic viewpoints. In this paper, I present a statistical study examining the differences between traditionally elicited product ratings (i.e., "How do you rate this product'") and social inference ratings (i.e., "How do you think other people will rate this product'"). In 5 of 6 trials, I find that social inference ratings produce the same aggregate product rating as the one produced via traditionally elicited ratings. In all cases, however, social inferences yield less variance. This is significant because using social inference ratings 1) therefore converges on the true aggregate product rating faster, and 2) is a cheap design intervention on the part of existing sites.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2759–2762},
numpages = {4},
keywords = {social psychology, ecommerce, ratings, product reviews},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250994,
author = {Patern', Fabio},
title = {Session Details: Cross-Device Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250994},
doi = {10.1145/3250994},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556956,
author = {Chapuis, Olivier and Bezerianos, Anastasia and Frantzeskakis, Stelios},
title = {Smarties: An Input System for Wall Display Development},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556956},
doi = {10.1145/2556288.2556956},
abstract = {Wall-sized displays can support data visualization and collaboration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It consists of an interface running on touch mobile devices for input, a communication protocol between devices and the wall, and a library that implements the protocol and handles synchronization, locking and input conflicts. The library presents the input as an event loop with callback functions. Each touch mobile has multiple cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can control simple cursors on the wall application, or specific content (objects or groups of them). The types of associated widgets are decided by the wall application, making the mobile interface customizable by the wall application it connects to.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2763–2772},
numpages = {10},
keywords = {multi-cursors, hand-held touch devices, wall display, cscw, input toolkit},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557170,
author = {Hamilton, Peter and Wigdor, Daniel J.},
title = {Conductor: Enabling and Understanding Cross-Device Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557170},
doi = {10.1145/2556288.2557170},
abstract = {The proliferation of inexpensive connected devices has created a situation where a person, at any given moment, is surrounded by interactive computers. Despite this fact, there are very few means by which a user may take advantage of this large number of screens. We present Conductor, a prototype framework which serves as an exemplar for the construction of cross-device applications. We present a series of interaction methods by which users can easily share information, chain tasks across devices, and manage sessions across devices. We also present a cross-device usage scenario which utilizes several cross-device applications built within our prototype framework. We also describe a user study, which helped us to understand how users will take advantage of a large number of devices in support of performance of a sense making task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2773–2782},
numpages = {10},
keywords = {multi-device environments, optimization, user interface design, cross-device applications, distributed user interfaces, information sharing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557199,
author = {Yang, Jishuo and Wigdor, Daniel},
title = {Panelrama: Enabling Easy Specification of Cross-Device Web Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557199},
doi = {10.1145/2556288.2557199},
abstract = {We present Panelrama, a web-based framework for the construction of applications using distributed user interfaces (DUIs). Our implementation provides developers with low migration costs through built-in mechanisms for the synchronization of a UI state, requiring minimal changes to existing languages. Additionally, we describe a solution to categorize device characteristics and dynamically change UI allocation to best-fit devices. We illustrate the use of Panelrama through three sample applications which demonstrate its support for known interaction methods, we also present the results of a developer study, which validates our belief that cross-device application experiences can be easily implemented using our framework.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2783–2792},
numpages = {10},
keywords = {multi-device environments, distributed user interfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556980,
author = {Nebeling, Michael and Mintsi, Theano and Husmann, Maria and Norrie, Moira},
title = {Interactive Development of Cross-Device User Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556980},
doi = {10.1145/2556288.2556980},
abstract = {Current GUI builders provide a design environment for user interfaces that target either a single type or fixed set of devices, and provide little support for scenarios in which the user interface, or parts of it, are distributed over multiple devices. Distributed user interfaces have received increasing attention over the past years. There are different, often model-based, approaches that focus on technical issues. This paper presents XDStudio--a new GUI builder designed to support interactive development of cross-device web interfaces. XDStudio implements two complementary authoring modes with a focus on the design process of distributed user interfaces. First, simulated authoring allows designing for a multi-device environment on a single device by simulating other target devices. Second, on-device authoring allows the design process itself to be distributed over multiple devices, as design and development take place on the target devices themselves. To support interactive development for multi-device environments, where not all devices may be present at design and run-time, XDStudio supports switching between the two authoring modes, as well as between design and use modes, as required. This paper focuses on the design of XDStudio, and evaluates its support for two distribution scenarios.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2793–2802},
numpages = {10},
keywords = {distributed authoring, simulated authoring, distributed user interfaces, multi-device},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250995,
author = {Morris, Dan},
title = {Session Details: Exergaming for Health and Fitness},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250995},
doi = {10.1145/3250995},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557268,
author = {Singh, Aneesha and Klapper, Annina and Jia, Jinni and Fidalgo, Antonio and Tajadura-Jim\'{e}nez, Ana and Kanakam, Natalie and Bianchi-Berthouze, Nadia and Williams, Amanda},
title = {Motivating People with Chronic Pain to Do Physical Activity: Opportunities for Technology Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557268},
doi = {10.1145/2556288.2557268},
abstract = {Physical activity is important for improving quality of life in people with chronic pain. However, actual or anticipated pain exacerbation, and lack of confidence when doing physical activity, make it difficult to maintain and build towards long-term activity goals. Research guiding the design of interactive technology to motivate and support physical activity in people with chronic pain is lacking. We conducted studies with: (1) people with chronic pain, to understand how they maintained and increased physical activity in daily life and what factors deterred them; and (2) pain-specialist physiotherapists, to understand how they supported people with chronic pain. Building on this understanding, we investigated the use of auditory feedback to address some of the psychological barriers and needs identified and to increase self-efficacy, motivation and confidence in physical activity. We conclude by discussing further design opportunities based on the overall findings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2803–2812},
numpages = {10},
keywords = {chronic pain, interactive systems design, auditory feedback, physical activity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557160,
author = {Uzor, Stephen and Baillie, Lynne},
title = {Investigating the Long-Term Use of Exergames in the Home with Elderly Fallers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557160},
doi = {10.1145/2556288.2557160},
abstract = {Rehabilitation has been shown to significantly reduce the risk of falling in older adults. However, low adherence to rehabilitation exercises in the home means that seniors often do not get the therapy that they require. We propose that the use of tailored exergames could encourage adherence to falls rehabilitation in the home, as exergames have proved successful in clinical settings. We describe the results from the first known study to investigate the long-term (12 weeks) use of exergames, designed in close collaboration with elderly users, for falls rehabilitation in the home. Our findings suggest that there is an untapped potential of exergames for home rehabilitation use, as our findings show that there was better adherence to exercise in participants who used the exergames, versus those who used standard care. Finally, we make recommendations for designers, on the design of exergames for the rehabilitation of seniors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2813–2822},
numpages = {10},
keywords = {games, user studies, rehabilitation., falls, exergames, home, elderly},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557190,
author = {Miller, Andrew D. and Mynatt, Elizabeth D.},
title = {StepStream: A School-Based Pervasive Social Fitness System for Everyday Adolescent Health},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557190},
doi = {10.1145/2556288.2557190},
abstract = {Computer-supported fitness interventions for adolescents have the potential to improve adolescents' attitudes and perceptions about physical activity through peer influence and interpersonal accountability. Past research has explored the potential of interventions based on competition and social-comparison mechanisms. We present a new approach: school-based, pervasive social fitness systems. We describe one such system: StepStream, a pedometer-based microblog we designed and deployed for four weeks with 42 US middle school students. StepStream users improved their attitudes about fitness and increased their sense of social support for fitness. The least-active students also increased their daily activity. We show that our school-based social fitness approach performed comparably in attitude and behavior change to more competitive or direct-comparison systems. These results expand the strategies available computer-supported fitness interventions. Our school-based social fitness approach to everyday adolescent health shows the potential for social computing systems to positively influence offline health behaviors in real-world settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2823–2832},
numpages = {10},
keywords = {deployments, social computing, fitness intervention, youth, adolescents, pervasive health},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557299,
author = {Mauriello, Matthew and Gubbels, Michael and Froehlich, Jon E.},
title = {Social Fabric Fitness: The Design and Evaluation of Wearable E-Textile Displays to Support Group Running},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557299},
doi = {10.1145/2556288.2557299},
abstract = {Group exercise has multiple benefits including greater adherence to fitness regimens, increased enjoyment among participants, and enhanced workout intensity. While a large number of technology tools have emerged to support real-time feedback of individual performance, tools to support group fitness are limited. In this paper, we present a set of wearable e-textile displays for running groups called Social Fabric Fitness (SFF). SFF provides a glanceable, shared screen on the back of the wearer's shirt to increase awareness and motivation of group fitness performance. We discuss parallel prototyping of three designs-one flexible e-ink and two flexible LED-based displays; the selection and refinement of one design; and two evaluations'a field study of 10 running groups and two case studies of running races. Our qualitative findings indicate that SFF improves awareness of individual and group performance, helps groups stay together, and improves in-situ motivation. We close with reflections for future athletic e-textile displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2833–2842},
numpages = {10},
keywords = {wearables, visualization, quantified self, personal informatics, glanceable displays, fitness},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250996,
author = {Hoonhout, Jettie},
title = {Session Details: Sensory Experiences: Smell and Taste},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250996},
doi = {10.1145/3250996},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557008,
author = {Obrist, Marianna and Tuch, Alexandre N. and Hornbaek, Kasper},
title = {Opportunities for Odor: Experiences with Smell and Implications for Technology},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557008},
doi = {10.1145/2556288.2557008},
abstract = {Technologies for capturing and generating smell are emerging, and our ability to engineer such technologies and use them in HCI is rapidly developing. Our understanding of how these technologies match the experiences with smell that people have or want to have is surprisingly limited. We therefore investigated the experience of smell and the emotions that accompany it. We collected stories from 439 participants who described personally memorable smell experiences in an online questionnaire. Based on the stories we developed 10 categories of smell experience. We explored the implications of the categories for smell-enhanced technology design by (a) probing participants to envision technologies that match their smell story and (b) having HCI researchers brainstorm technologies using the categories as design stimuli. We discuss how our findings can benefit research on personal memories, momentary and first time experiences, and wellbeing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2843–2852},
numpages = {10},
keywords = {smell-enhanced technology, narratives, smell, designing for smell., olfaction, odor, smell stories, smell experiences, design brainstorming, user experience, crowdsourcing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557007,
author = {Obrist, Marianna and Comber, Rob and Subramanian, Sriram and Piqueras-Fiszman, Betina and Velasco, Carlos and Spence, Charles},
title = {Temporal, Affective, and Embodied Characteristics of Taste Experiences: A Framework for Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557007},
doi = {10.1145/2556288.2557007},
abstract = {We present rich descriptions of taste experience through an analysis of the diachronic and synchronic experiences of each of the five basic taste qualities: sweet, sour, salt, bitter, and umami. Our findings, based on a combination of user experience evaluation techniques highlight three main themes: temporality, affective reactions, and embodiment. We present the taste characteristics as a framework for design and discuss each taste in order to elucidate the design qualities of individual taste experiences. These findings add a semantic understanding of taste experiences, their temporality enhanced through descriptions of the affective reactions and embodiment that the five basic tastes elicit. These findings are discussed on the basis of established psychological and behavioral phenomena, highlighting the potential for taste-enhanced design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2853–2862},
numpages = {10},
keywords = {user experience, sensory research, explicitation interview technique, taste experiences, taste, sensual evaluation tool},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557087,
author = {Seah, Sue Ann and Martinez Plasencia, Diego and Bennett, Peter D. and Karnik, Abhijit and Otrocol, Vlad Stefan and Knibbe, Jarrod and Cockburn, Andy and Subramanian, Sriram},
title = {SensaBubble: A Chrono-Sensory Mid-Air Display of Sight and Smell},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557087},
abstract = {We present SensaBubble, a chrono-sensory mid-air display system that generates scented bubbles to deliver information to the user via a number of sensory modalities. The system reliably produces single bubbles of specific sizes along a directed path. Each bubble produced by SensaBubble is filled with fog containing a scent relevant to the notification. The chrono-sensory aspect of SensaBubble means that information is presented both temporally and multimodally. Temporal information is enabled through two forms of persistence: firstly, a visual display projected onto the bubble which only endures until it bursts; secondly, a scent released upon the bursting of the bubble slowly disperses and leaves a longer-lasting perceptible trace of the event. We report details of SensaBubble's design and implementation, as well as results of technical and user evaluations. We then discuss and demonstrate how SensaBubble can be adapted for use in a wide range of application contexts -- from an ambient peripheral display for persistent alerts, to an engaging display for gaming or education.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2863–2872},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557026,
author = {Wei, Jun and Ma, Xiaojuan and Zhao, Shengdong},
title = {Food Messaging: Using Edible Medium for Social Messaging},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557026},
doi = {10.1145/2556288.2557026},
abstract = {Food is more than just a means of survival; it is also a form of communication. In this paper, we investigate the potential of food as a social message carrier (a.k.a., food messaging). To investigate how people accept, use, and perceive food messaging, we conducted exploratory interviews, a field study, and follow-up interviews over four weeks in a large information technology (IT) company. We collected 904 messages sent by 343 users. Our results suggest strong acceptance of food messaging as an alternative message channel. Further analysis implies that food messaging embodies characteristics of both text messaging and gifting. It is preferred in close relationships for its evocation of positive emotions. As the first field study on edible social messaging, our empirical findings provide valuable insights into the uniqueness of food as a message carrier and its capabilities to promote greater social bonding.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2873–2882},
numpages = {10},
keywords = {edible social messaging, food messaging, food printer, field study, affective communication, food hci},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250997,
author = {Boring, Sebastian},
title = {Session Details: Multitouch Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250997},
doi = {10.1145/3250997},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556958,
author = {Wagner, Julie and Lecolinet, Eric and Selker, Ted},
title = {Multi-Finger Chords for Hand-Held Tablets: Recognizable and Memorable},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556958},
doi = {10.1145/2556288.2556958},
abstract = {Despite the demonstrated benefits of multi-finger input, todays gesture vocabularies offer a limited number of postures and gestures. Previous research designed several posture sets, but does not address the limited human capacity of retaining them. We present a multi-finger chord vocabulary, introduce a novel hand-centric approach to detect the identity of fingers on off-the-shelf hand-held tablets, and report on the detection accuracy. A between-subjects experiment comparing "random" to a "categorized" chord-command mapping found that users retained categorized mappings more accurately over one week than random ones. In response to the logical posture-language structure, people adapted to logical memorization strategies, such as 'exclusion', 'order', and 'category', to minimize the amount of information to retain. We conclude that structured chord-command mappings support learning, short-, and long-term retention of chord- command mappings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2883–2892},
numpages = {10},
keywords = {multi-finger chord, chord-command mapping, finger identification, hand-held tablet},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557029,
author = {Olafsdottir, Halla B. and Tsandilas, Theophanis and Appert, Caroline},
title = {Prospective Motor Control on Tabletops: Planning Grasp for Multitouch Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557029},
doi = {10.1145/2556288.2557029},
abstract = {Substantial amount of research in Psychology has studied how people manipulate objects in the physical world. This work has unveiled that people show strong signs of prospective motor planning, i.e., they choose initial grasps that avoid uncomfortable end postures and facilitate object manipulation. Interactive tabletops allow their users great flexibility in the manipulation of virtual objects but to our knowledge previous work has never examined whether prospective motor control takes place in this context. To test this, we ran three experiments. We systematically studied how users adapt their grasp when asked to translate and rotate virtual objects on a multitouch tabletop. Our results demonstrate that target position and orientation significantly affect the orientation of finger placement on the object. We analyze our results in the light of the most recent model of planning for manipulating physical objects and identify their implications for the design of tabletop interfaces. },
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2893–2902},
numpages = {10},
keywords = {acquisition and manipulation, movement planning, end-state comfort effect, multitouch, range of motion, tabletops},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557282,
author = {Alzayat, Ayman and Hancock, Mark and Nacenta, Miguel},
title = {Quantitative Measurement of Virtual vs. Physical Object Embodiment through Kinesthetic Figural after Effects},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557282},
doi = {10.1145/2556288.2557282},
abstract = {Over the past decade, multi-touch surfaces have become commonplace, with many researchers and practitioners describing the benefits of their natural, physical-like interactions. We present a pair of studies that empirically investigates the psychophysical effects of direct interaction with both physical and virtual artefacts. We use the phenomenon of Kinesthetic Figural After Effects-a change in understanding of the physical size of an object after a period of exposure to an object of different size. Our studies show that, while this effect is robustly reproducible when using physical artefacts, this same effect does not manifest when manipulating virtual artefacts on a direct, multi-touch tabletop display. We contribute quantitative evidence suggesting a psychophysical difference in our response to physical vs. virtual objects, and discuss future research directions to explore measurable phenomena to evaluate the presence of physical-like changes from virtual on-screen objects.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2903–2912},
numpages = {10},
keywords = {physical interaction, multi-touch, embodied interaction, tangible user interfaces, tabletop displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557012,
author = {Harrison, Chris and Xiao, Robert and Schwarz, Julia and Hudson, Scott E.},
title = {TouchTools: Leveraging Familiarity and Skill with Physical Tools to Augment Touch Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557012},
doi = {10.1145/2556288.2557012},
abstract = {The average person can skillfully manipulate a plethora of tools, from hammers to tweezers. However, despite this remarkable dexterity, gestures on today's touch devices are simplistic, relying primarily on the chording of fingers: one-finger pan, two-finger pinch, four-finger swipe and similar. We propose that touch gesture design be inspired by the manipulation of physical tools from the real world. In this way, we can leverage user familiarity and fluency with such tools to build a rich set of gestures for touch interaction. With only a few minutes of training on a proof-of-concept system, users were able to summon a variety of virtual tools by replicating their corresponding real-world grasps.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2913–2916},
numpages = {4},
keywords = {tangible computing, capacitive sensing, surface computing, multitouch, touchscreen, gesture design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250998,
author = {Egelman, Serge},
title = {Session Details: Authentication and Passwords},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250998},
doi = {10.1145/3250998},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557153,
author = {Chowdhury, Soumyadeb and Poet, Ron and Mackenzie, Lewis},
title = {Passhint: Memorable and Secure Authentication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557153},
doi = {10.1145/2556288.2557153},
abstract = {People find it difficult to remember multiple alphanumeric as well as graphical passwords. We propose a Passhint authentication system (PHAS), where the users have to choose four images and create hints for each one of them in order to register a new password. During authentication, they have to recognize only the target images, which are displayed with their corresponding hints, among collections of 15 decoy images, in a four step process. A usability study was conducted with 40 subjects. They created 1 Mikon, 1 doodle, 1 art and 1 object password and then recalled each password after a period of two weeks (without any practice sessions). The results demonstrated that the memorability of multiple passwords in PHAS is better than in existing Graphical authentication systems (GASs). Although the registration time is high, authentication time for successful attempts is either equivalent to or less than the time reported for previous GASs. A guessability study conducted with the same subjects revealed that art passwords are the least guessable, followed by Mikon, doodle and objects in that order. The results strongly suggest the use of art passwords in PHAS, which would offer usable as well as secure authentication. The preliminary results indicate that PHAS has solved the memorability problem with multiple passwords. We propose two new features that could enhance the security offered by PHAS, but the usability of these features would need to be tested before they could be adopted in practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2917–2926},
numpages = {10},
keywords = {usability, guessability, graphical authentication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557377,
author = {Shay, Richard and Komanduri, Saranga and Durity, Adam L. and Huh, Phillip (Seyoung) and Mazurek, Michelle L. and Segreti, Sean M. and Ur, Blase and Bauer, Lujo and Christin, Nicolas and Cranor, Lorrie Faith},
title = {Can Long Passwords Be Secure and Usable?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557377},
doi = {10.1145/2556288.2557377},
abstract = {To encourage strong passwords, system administrators employ password-composition policies, such as a traditional policy requiring that passwords have at least 8 characters from 4 character classes and pass a dictionary check. Recent research has suggested, however, that policies requiring longer passwords with fewer additional requirements can be more usable and in some cases more secure than this traditional policy. To explore long passwords in more detail, we conducted an online experiment with 8,143 participants. Using a cracking algorithm modified for longer passwords, we evaluate eight policies across a variety of metrics for strength and usability. Among the longer policies, we discover new evidence for a security/usability tradeoff, with none being strictly better than another on both dimensions. However, several policies are both more usable and more secure that the traditional policy we tested. Our analyses additionally reveal common patterns and strings found in cracked passwords. We discuss how system administrators can use these results to improve password-composition policies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2927–2936},
numpages = {10},
keywords = {security policy, password-composition policies, usable security, authentication, passwords},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557097,
author = {De Luca, Alexander and Harbach, Marian and von Zezschwitz, Emanuel and Maurer, Max-Emanuel and Slawik, Bernhard Ewald and Hussmann, Heinrich and Smith, Matthew},
title = {Now You See Me, Now You Don't: Protecting Smartphone Authentication from Shoulder Surfers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557097},
doi = {10.1145/2556288.2557097},
abstract = {In this paper, we present XSide, an authentication mechanism that uses the front and the back of smartphones to enter stroke-based passwords. Users can switch sides during input to minimize the risk of shoulder surfing. We performed a user study (n = 32) to explore how switching sides during authentication affects usability and security of the system. The results indicate that switching the sides increases security while authentication speed stays relatively fast (≤ 4 seconds). The paper furthermore provides insights on accuracy of eyes-free input (as used in XSide) and shows how 3D printed prototype cases can improve the back-of-device interaction experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2937–2946},
numpages = {10},
keywords = {back-of-device interaction, authentication, security},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557212,
author = {Thorpe, Julie and Al-Badawi, Muath and MacRae, Brent and Salehi-Abari, Amirali},
title = {The Presentation Effect on Graphical Passwords},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557212},
doi = {10.1145/2556288.2557212},
abstract = {We provide a simple yet powerful demonstration of how an unobtrusive change to a graphical password interface can modify the distribution of user chosen passwords, and thus possibly the security it provides. The only change to the interface is how the background image is presented to the user in the password creation phase--we call the effect of this change the "presentation effect". We demonstrate the presentation effect by performing a comparative user study of two groups using the same background image, where the image is presented in two different ways prior to password creation. Our results show a statistically different distribution of user's graphical passwords, with no observed usability consequences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2947–2950},
numpages = {4},
keywords = {graphical passwords, passwords, user authentication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557346,
author = {Burgbacher, Ulrich and Hinrichs, Klaus},
title = {An Implicit Author Verification System for Text Messages Based on Gesture Typing Biometrics},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557346},
doi = {10.1145/2556288.2557346},
abstract = {Gesture typing is a popular text input method used on smartphones. Gesture keyboards are based on word gestures that subsequently trace all letters of a word on a virtual keyboard. Instead of tapping a word key by key, the user enters a word gesture with a single continuous stroke. In this paper, we introduce an implicit user verification approach for short text messages that are entered with a gesture keyboard. We utilize the way people interact with gesture keyboards to extract behavioral biometric features. We propose a proof-of-concept classification framework that learns the gesture typing behavior of a person and is able to decide whether a gestured message was written by the legitimate user or an imposter. Data collected from gesture keyboard users in a user study is used to assess the performance of the classification framework, demonstrating that the technique has considerable promise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2951–2954},
numpages = {4},
keywords = {implicit authentication, mobile phone security, behavioral biometrics, gesture keyboards},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250999,
author = {Wulf, Volker},
title = {Session Details: Policies and Practice: Doing the Right Thing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250999},
doi = {10.1145/3250999},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557367,
author = {Harvey, John and Golightly, David and Smith, Andrew},
title = {HCI as a Means to Prosociality in the Economy},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557367},
doi = {10.1145/2556288.2557367},
abstract = {HCI research often involves intervening in the economic lives of people, but researchers only rarely give explicit consideration to what actually constitutes prosociality in the economy. Much has been said previously regarding sustainability but this has largely focused on environmental rather than interpersonal relations. This paper provides an analysis of how prosocial HCI has been discussed and continues to be defined as a research field. Based on a corpus of published works, we describe a variety of genres of work relating to prosocial HCI. Key intellectual differences are explored, including the epistemological and ethical positions involved in designing for prosocial outcomes as well as how HCI researchers posit economic decision-making. Finally, emerging issues and opportunities for further debate and collaboration are discussed in turn.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2955–2964},
numpages = {10},
keywords = {hci, prosocial, economic anthropology},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557364,
author = {Grimpe, Barbara and Hartswood, Mark and Jirotka, Marina},
title = {Towards a Closer Dialogue between Policy and Practice: Responsible Design in HCI},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557364},
doi = {10.1145/2556288.2557364},
abstract = {Given the potent and pervasive nature of modern technologies, this paper lays out the complexities involved in achieving responsible design. In order to do this we will first compare an emerging policy-oriented programme of research known as RRI (Responsible Research and Innovation) with initiatives in HCI. A focus on the similarities and differences may highlight to what extent responsibility is already and successfully embedded within the concerns and practices of design and use, and what may yet need to be incorporated for responsible design. The paper then discusses the challenges of 'naturalising' the very ambitious programme of RRI within specific design activities and concerns, through the lens of four analytic concepts: reflexivity; responsiveness; inclusion; and anticipation. Finally, we make a case for a pragmatic, 'unromantic', but engaged reinterpretation of RRI for HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2965–2974},
numpages = {10},
keywords = {innovation, responsible design, value-sensitive design, ethics, user-centered design, governance, participatory design, critical design, risk society},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557061,
author = {Bellotti, Victoria M.E. and Cambridge, Sara and Hoy, Karen and Shih, Patrick C. and Handalian, Lisa Renery and Han, Kyungsik and Carroll, John M.},
title = {Towards Community-Centered Support for Peer-to-Peer Service Exchange: Rethinking the Timebanking Metaphor},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557061},
doi = {10.1145/2556288.2557061},
abstract = {Commercial peer-to-peer service exchange businesses, such as AirBnB, Lyft and TaskRabbit, are expanding rapidly, but their non-profit counterparts are lagging behind. We conducted a field study of the most prominent of these, timebanking; a system in which 'time dollars' are earned and spent by people providing services for and receiving them from each other. Our study exposed problems with the very metaphor of banking itself, which deter participation. In this paper we discuss how these problems can be tackled with user experience design for systems supporting timebanking. Our design ideas emphasize the personal and social benefits of participation, and avoid such unappealing concepts as debt and neediness that the timebanking metaphor falls afoul of.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2975–2984},
numpages = {10},
keywords = {user experience design, field study, timebanking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251000,
author = {Cheshire, Coye},
title = {Session Details: Journalism and Social News},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251000},
doi = {10.1145/3251000},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557262,
author = {Eveleigh, Alexandra and Jennett, Charlene and Blandford, Ann and Brohan, Philip and Cox, Anna L.},
title = {Designing for Dabblers and Deterring Drop-Outs in Citizen Science},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557262},
doi = {10.1145/2556288.2557262},
abstract = {In most online citizen science projects, a large proportion of participants contribute in small quantities. To investigate how low contributors differ from committed volunteers, we distributed a survey to members of the Old Weather project, followed by interviews with respondents selected according to a range of contribution levels. The studies reveal a complex relationship between motivations and contribution. Whilst high contributors were deeply engaged by social or competitive features, low contributors described a solitary experience of 'dabbling' in projects for short periods. Since the majority of participants exhibit this small-scale contribution pattern, there is great potential value in designing interfaces to tempt lone workers to complete 'just another page', or to lure early drop-outs back into participation. This includes breaking the work into components which can be tackled without a major commitment of time and effort, and providing feedback on the quality and value of these contributions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2985–2994},
numpages = {10},
keywords = {engagement, dabblers, motivation, citizen science},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557054,
author = {Taylor, Nick and Frohlich, David M. and Egglestone, Paul and Marshall, Justin and Rogers, Jon and Blum-Ross, Alicia and Mills, John and Shorter, Mike and Olivier, Patrick},
title = {Utilising Insight Journalism for Community Technology Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557054},
doi = {10.1145/2556288.2557054},
abstract = {We describe the process of insight journalism, in which local amateur journalists were used to generate unique insights into the digital needs of a community. We position this as a means for communities to represent themselves to designers, both as a method of designing community technologies and as a first step towards supporting innovation at a local level. To demonstrate insight journalism, we present two case studies of community technologies that were directly inspired, informed and evaluated by journalistic content. Based on this experience, we evaluate the role that insight journalism can play in designing for communities, the particular characteristics that it lends to the design process and how it might be employed to support sustainable community innovation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2995–3004},
numpages = {10},
keywords = {citizen journalism, co-design, local innovation, design, community, participatory design, ethnography},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557228,
author = {Gao, Tong and Hullman, Jessica R. and Adar, Eytan and Hecht, Brent and Diakopoulos, Nicholas},
title = {NewsViews: An Automated Pipeline for Creating Custom Geovisualizations for News},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557228},
doi = {10.1145/2556288.2557228},
abstract = {Interactive visualizations add rich, data-based context to online news articles. Geographic maps are currently the most prevalent form of these visualizations. Unfortunately, designers capable of producing high-quality, customized geovisualizations are scarce. We present NewsViews, a novel automated news visualization system that generates interactive, annotated maps without requiring professional designers. NewsViews' maps support trend identification and data comparisons relevant to a given news article. The NewsViews system leverages text mining to identify key concepts and locations discussed in articles (as well as potential annotations), an extensive repository of 'found' databases, and techniques adapted from cartography to identify and create visually 'interesting' thematic maps. In this work, we develop and evaluate key criteria in automatic, annotated, map generation and experimentally validate the key features for successful representations (e.g., relevance to context, variable selection, 'interestingness' of representation and annotation quality).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3005–3014},
numpages = {10},
keywords = {interactive maps, narrative information visualization, online news, geovisualization, text summarization},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557114,
author = {Garbett, Andrew Thomas and Comber, Rob and Egglestone, Paul and Glancy, Maxine and Olivier, Patrick},
title = {Finding "Real People": Trust and Diversity in the Interface between Professional and Citizen Journalists},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557114},
doi = {10.1145/2556288.2557114},
abstract = {The increase of social media and web blogs has enabled a new generation of citizen journalism to provide new perspectives into local communities. However traditional news organisations are currently struggling to incorporate this new form of journalism into their existing organisational workflow. We present an analysis from 10 interviews with professional journalists and explore the current issues faced by professional journalists when searching for reliable and reputable local news sources as well as the perceived role of citizen journalists within a large news organisation. From this analysis we present a set of design implications for building systems that support interaction between citizen and professional journalists in order to encourage participatory news production and diversify national news perspectives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3015–3024},
numpages = {10},
keywords = {reputation, citizen journalism, journalism, trust, diversity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251001,
author = {Alexander, Jason},
title = {Session Details: Interruptions and Distractions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251001},
doi = {10.1145/3251001},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557204,
author = {Mark, Gloria and Iqbal, Shamsi T. and Czerwinski, Mary and Johns, Paul},
title = {Bored Mondays and Focused Afternoons: The Rhythm of Attention and Online Activity in the Workplace},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557204},
doi = {10.1145/2556288.2557204},
abstract = {While distractions using digital media have received attention in HCI, understanding engagement in workplace activities has been little explored. We logged digital activity and continually probed perspectives of 32 information workers for five days in situ to understand how attentional states change with context. We present a framework of how engagement and challenge in work relate to focus, boredom, and rote work. Overall, we find more focused attention than boredom in the workplace. Focus peaks mid-afternoon while boredom is highest in early afternoon. People are happiest doing rote work and most stressed doing focused work. On Mondays people are most bored but also most focused. Online activities are associated with different attentional states, showing different patterns at beginning and end of day, and before and after a mid-day break. Our study shows how rhythms of attentional states are associated with context and time, even in a dynamic workplace environment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3025–3034},
numpages = {10},
keywords = {experience sampling, focus, multi-tasking, empirical study, workplace, engagement, attention, computer logging},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557109,
author = {Shrot, Tammar and Rosenfeld, Avi and Golbeck, Jennifer and Kraus, Sarit},
title = {CRISP: An Interruption Management Algorithm Based on Collaborative Filtering},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557109},
doi = {10.1145/2556288.2557109},
abstract = {Interruptions can have a significant impact on users working to complete a task. When people are collaborating, either with other users or with systems, coordinating interruptions is an important factor in maintaining efficiency and preventing information overload. Computer systems can observe user behavior, model it, and use this to optimize the interruptions to minimize disruption. However, current techniques often require long training periods that make them unsuitable for online collaborative environments where new users frequently participate.In this paper, we present a novel synthesis between Collaborative Filtering methods and machine learning classification algorithms to create a fast learning algorithm, CRISP. CRISP exploits the similarities between users in order to apply data from known users to new users, therefore requiring less information on each person. Results from user studies indicate the algorithm significantly improves users' performances in completing the task and their perception of how long it took to complete each task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3035–3044},
numpages = {10},
keywords = {interruption management (cost estimation), collaborative filtering, classification algorithm},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557066,
author = {B\"{o}hmer, Matthias and Lander, Christian and Gehring, Sven and Brumby, Duncan P. and Kr\"{u}ger, Antonio},
title = {Interrupted by a Phone Call: Exploring Designs for Lowering the Impact of Call Notifications for Smartphone Users},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557066},
doi = {10.1145/2556288.2557066},
abstract = {Mobile phones have evolved significantly in recent years from single-purpose communication devices to multi-purpose computing devices. Despite this evolution, the interaction model for how incoming calls are handled has barely changed. Current-generation smartphones still use abrupt full-screen notifications to alert users to incoming calls, demanding a decision to either accept or decline the call. These full-screen notifications forcibly interrupt whatever activity the user was already engaged in. This might be undesirable when the user's primary task was more important than the incoming call. This paper explores the design space for how smartphones can alert users to incoming calls. We consider designs that allow users to postpone calls and also to multiplex by way of a smaller partial-screen notification. These design alternatives were evaluated in both a small-scale controlled lab study as well as a large-scale naturalistic in-the-wild study. Results show that a multiplex design solution works best because it allows people to continue working on their primary task while being made aware that there is a caller on the line. The contribution of this work is an enhanced interaction design for handling phone calls, and an understanding of how people use it for handling incoming calls.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3045–3054},
numpages = {10},
keywords = {app usage, interruptions, phone calls, smartphones},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557189,
author = {Sahami Shirazi, Alireza and Henze, Niels and Dingler, Tilman and Pielot, Martin and Weber, Dominik and Schmidt, Albrecht},
title = {Large-Scale Assessment of Mobile Notifications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557189},
doi = {10.1145/2556288.2557189},
abstract = {Notifications are a core feature of mobile phones. They inform users about a variety of events. Users may take immediate action or ignore them depending on the importance of a notification as well as their current context. The nature of notifications is manifold, applications use them both sparsely and frequently. In this paper we present the first large-scale analysis of mobile notifications with a focus on users' subjective perceptions. We derive a holistic picture of notifications on mobile phones by collecting close to 200 million notifications from more than 40,000 users. Using a data-driven approach, we break down what users like and dislike about notifications. Our results reveal differences in importance of notifications and how users value notifications from messaging apps as well as notifications that include information about people and events. Based on these results we derive a number of findings about the nature of notifications and guidelines to effectively use them.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3055–3064},
numpages = {10},
keywords = {large-scale, in the wild, mobile phone, mobile hci, apps, notification},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251002,
author = {Froehlich, Jon},
title = {Session Details: Decisions, Recommendations, and Machine Learning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251002},
doi = {10.1145/3251002},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557211,
author = {Solomon, Jacob},
title = {Customization Bias in Decision Support Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557211},
doi = {10.1145/2556288.2557211},
abstract = {Many Decision Support Systems (DSS) afford customization of inputs or algorithms before generating recommendations to a decision maker. This paper describes an experiment in which users make decisions assisted by recommendations of a DSS in a fantasy baseball game. This experiment shows that the act of customizing a DSS can lead to biased decision making. I show that users who believe they have customized a DSS's recommendation algorithm are more likely to follow the recommendations regardless of their accuracy. I also show that this customization bias is the result of using a DSS to seek confirmatory information in a recommendation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3065–3074},
numpages = {10},
keywords = {decision support systems, fantasy sports},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557238,
author = {Kulesza, Todd and Amershi, Saleema and Caruana, Rich and Fisher, Danyel and Charles, Denis},
title = {Structured Labeling for Facilitating Concept Evolution in Machine Learning},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557238},
doi = {10.1145/2556288.2557238},
abstract = {Labeling data is a seemingly simple task required for training many machine learning systems, but is actually fraught with problems. This paper introduces the notion of concept evolution, the changing nature of a person's underlying concept (the abstract notion of the target class a person is labeling for, e.g., spam email, travel related web pages) which can result in inconsistent labels and thus be detrimental to machine learning. We introduce two structured labeling solutions, a novel technique we propose for helping people define and refine their concept in a consistent manner as they label. Through a series of five experiments, including a controlled lab study, we illustrate the impact and dynamics of concept evolution in practice and show that structured labeling helps people label more consistently in the presence of concept evolution than traditional labeling.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3075–3084},
numpages = {10},
keywords = {interactive machine learning, concept evolution},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557069,
author = {Loepp, Benedikt and Hussein, Tim and Ziegler, J\"{u}ergen},
title = {Choice-Based Preference Elicitation for Collaborative Filtering Recommender Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557069},
doi = {10.1145/2556288.2557069},
abstract = {We present an approach to interactive recommending that combines the advantages of algorithmic techniques with the benefits of user-controlled, interactive exploration in a novel manner. The method extracts latent factors from a matrix of user rating data as commonly used in Collaborative Filtering, and generates dialogs in which the user iteratively chooses between two sets of sample items. Samples are chosen by the system for low and high values of each latent factor considered. The method positions the user in the latent factor space with few interaction steps, and finally selects items near the user position as recommendations.In a user study, we compare the system with three alternative approaches including manual search and automatic recommending. The results show significant advantages of our approach over the three competing alternatives in 15 out of 24 possible parameter comparisons, in particular with respect to item fit, interaction effort and user control. The findings corroborate our assumption that the proposed method achieves a good trade-off between automated and interactive functions in recommender systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3085–3094},
numpages = {10},
keywords = {matrix factorization, user interfaces, recommender systems, interactive recommending},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557176,
author = {Lasecki, Walter S. and Weingard, Leon and Ferguson, George and Bigham, Jeffrey P.},
title = {Finding Dependencies between Actions Using the Crowd},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557176},
doi = {10.1145/2556288.2557176},
abstract = {Activity recognition can provide computers with the context underlying user inputs, enabling more relevant responses and more fluid interaction. However, training these systems is difficult because it requires observing every possible sequence of actions that comprise a given activity. Prior work has enabled the crowd to provide labels in real-time to train automated systems on-the-fly, but numerous examples are still needed before the system can recognize an activity on its own. To reduce the need to collect this data by observing users, we introduce ARchitect, a system that uses the crowd to capture the dependency structure of the actions that make up activities. Our tests show that over seven times as many examples can be collected using our approach versus relying on direct observation alone, demonstrating that by leveraging the understanding of the crowd, it is possible to more easily train automated systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3095–3098},
numpages = {4},
keywords = {constraint finding, crowdsourcing, activity recognition},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557011,
author = {Deng, Jia and Russakovsky, Olga and Krause, Jonathan and Bernstein, Michael S. and Berg, Alex and Fei-Fei, Li},
title = {Scalable Multi-Label Annotation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557011},
doi = {10.1145/2556288.2557011},
abstract = {We study strategies for scalable multi-label annotation, or for efficiently acquiring multiple labels from humans for a collection of items. We propose an algorithm that exploits correlation, hierarchy, and sparsity of the label distribution. A case study of labeling 200 objects using 20,000 images demonstrates the effectiveness of our approach. The algorithm results in up to 6x reduction in human computation time compared to the naive method of querying a human annotator for the presence of every object in every image.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3099–3102},
numpages = {4},
keywords = {crowdsourcing, human computation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251003,
author = {Takagi, Hironobu},
title = {Session Details: Accessibility},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251003},
doi = {10.1145/3251003},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557237,
author = {Carrington, Patrick and Hurst, Amy and Kane, Shaun K.},
title = {Wearables and Chairables: Inclusive Design of Mobile Input and Output Techniques for Power Wheelchair Users},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557237},
doi = {10.1145/2556288.2557237},
abstract = {Power wheelchair users often use and carry multiple mobile computing devices. Many power wheelchair users have some upper body motor impairment that can make using these devices difficult. We believe that mobile device accessibility could be improved through designs that take into account users' functional abilities and take advantage of available space around the wheelchair itself. In this paper we present findings from multiple design sessions and interviews with 13 power wheelchair users and 30 clinicians, exploring the placement and form factor possibilities for input and output on a power wheelchair. We found that many power wheelchair users could benefit from chairable technology that is designed to work within the workspace of the wheelchair, whether worn on the body or mounted on he wheelchair frame. We present participants' preferences for chairable input and output devices, and identify possible design configurations for wearable and chairable devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3103–3112},
numpages = {10},
keywords = {input, natural user interface, mobile computing, accessibility, power wheelchair, wearable computers, participatory design, output},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557328,
author = {Manduchi, Roberto and Coughlan, James M.},
title = {The Last Meter: Blind Visual Guidance to a Target},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557328},
doi = {10.1145/2556288.2557328},
abstract = {Smartphone apps can use object recognition software to provide information to blind or low vision users about objects in the visual environment. A crucial challenge for these users is aiming the camera properly to take a well-framed picture of the desired target object. We investigate the effects of two fundamental constraints of object recognition -- frame rate and camera field of view -- on a blind person's ability to use an object recognition smartphone app. The app was used by 18 blind participants to find visual targets beyond arm's reach and approach them to within 30 cm. While we expected that a faster frame rate or wider camera field of view should always improve search performance, our experimental results show that in many cases increasing the field of view does not help, and may even hurt, performance. These results have important implications for the design of object recognition systems for blind users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3113–3122},
numpages = {10},
keywords = {wayfinding, assistive technology, blindness, camera-based access to information},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557085,
author = {Ye, Hanlu and Malu, Meethu and Oh, Uran and Findlater, Leah},
title = {Current and Future Mobile and Wearable Device Use by People with Visual Impairments},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557085},
doi = {10.1145/2556288.2557085},
abstract = {With the increasing popularity of mainstream wearable devices, it is critical to assess the accessibility implications of such technologies. For people with visual impairments, who do not always need the visual display of a mobile phone, alternative means of eyes-free wearable interaction are particularly appealing. To explore the potential impacts of such technology, we conducted two studies. The first was an online survey that included 114 participants with visual impairments and 101 sighted participants; we compare the two groups in terms of current device use. The second was an interview and design probe study with 10 participants with visual impairments. Our findings expand on past work to characterize a range of trends in smartphone use and accessibility issues therein. Participants with visual impairments also responded positively to two eyes-free wearable device scenarios: a wristband or ring and a glasses-based device. Discussions on projected use of these devices suggest that small, easily accessible, and discreet wearable input could positively impact the ability of people with visual impairments to access information on the go and to participate in certain social interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3123–3132},
numpages = {10},
keywords = {wearable computing, visual impairments, accessibility},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557415,
author = {Wu, Shaomei and Adamic, Lada A.},
title = {Visually Impaired Users on an Online Social Network},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557415},
doi = {10.1145/2556288.2557415},
abstract = {In this paper we present the first large-scale empirical study of how visually impaired people use online social networks, specifically Facebook. We identify a sample of 50K visually impaired users, and study the activities they perform, the content they produce, and the friendship networks they build on Facebook. We find that visually impaired users participate on Facebook (e.g. status updates, comments, likes) as much as the general population, and receive more feedback (i.e., comments and likes) on average on their content. By analyzing the content produced by visually impaired users, we find that they share their experience and issues related to vision impairment. We also identify distinctive patterns in their language and technology use. We also show that, compared to other users, visually impaired users have smaller social networks, but such differences have decreased over time. Our findings have implications for improving the utility and usability of online social networks for visually impaired users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3133–3142},
numpages = {10},
keywords = {facebook, social networking sites, social media, visually impaired users, vision disability},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251004,
author = {Solovey, Erin},
title = {Session Details: Tangible Interactions and Technologies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251004},
doi = {10.1145/3251004},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557016,
author = {Schmidt, Dominik and Ramakers, Raf and Pedersen, Esben W. and Jasper, Johannes and K\"{o}hler, Sven and Pohl, Aileen and Rantzsch, Hannes and Rau, Andreas and Schmidt, Patrick and Sterz, Christoph and Yurchenko, Yanina and Baudisch, Patrick},
title = {Kickables: Tangibles for Feet},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557016},
doi = {10.1145/2556288.2557016},
abstract = {We introduce the concept of tangibles that users can manipulate with their feet. We call them kickables. Unlike traditional tangibles, kickables allow for very large interaction surfaces as kickables reside on the ground. The main benefit of kickables over other foot-based modalities, such as foot touch, is their strong affordance, which we validate in two user studies. This affordance makes kickables well-suited for walk-up installations, such as tradeshows or museum exhibits.We present a custom design as well as five families of standard kickables to help application designers create kickable applications faster. Each family supports multiple standard controls, such as push buttons, switches, dials, and sliders. Each type explores a different design principle, in particular different mechanical constraints. We demonstrate an implementation on our pressure-sensing floor.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3143–3152},
numpages = {10},
keywords = {foot-based interaction, affordance., tangibles, interactive floor},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557105,
author = {Liang, Rong-Hao and Chan, Liwei and Tseng, Hung-Yu and Kuo, Han-Chih and Huang, Da-Yuan and Yang, De-Nian and Chen, Bing-Yu},
title = {GaussBricks: Magnetic Building Blocks for Constructive Tangible Interactions on Portable Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557105},
doi = {10.1145/2556288.2557105},
abstract = {This work describes a novel building block system for tangible interaction design, GaussBricks, which enables real-time constructive tangible interactions on portable displays. Given its simplicity, the mechanical design of the magnetic building blocks facilitates the construction of configurable forms. The form constructed by the magnetic building blocks, which are connected by the magnetic joints, allows users to stably manipulate with various elastic force feedback mechanisms. With an analog Hall-sensor grid mounted to its back, a portable display determines the geometrical configuration and detects various user interactions in real time. This work also introduce several methods to enable shape changing, multi-touch input, and display capabilities in the construction. The proposed building block system enriches how individuals interact with the portable displays physically.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3153–3162},
numpages = {10},
keywords = {magnetism, tangible interactions, constructive assembly, portable displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556991,
author = {Pillias, Cl\'{e}ment and Robert-Bouchard, Rapha\"{e}l and Levieux, Guillaume},
title = {Designing Tangible Video Games: Lessons Learned from the Sifteo Cubes},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556991},
doi = {10.1145/2556288.2556991},
abstract = {In this paper, we present a collaborative game designed for Sifteo Cubes, a new tangible interface for multiplayer games. We discuss how this game exploits the platform's interface to transfer some of the game mechanics into the non-digital world, and how this approach affects both the player's experience and the design process. We present the technical limitations encountered during game development and analyze video recordings of play sessions with regard to the play strategies developed by the players. Then, we identify two properties that this game shares with many other games on tangible platforms and discuss how these properties influence both the game design process and the player experience. We advocate that these properties provide players with more freedom and relatedness, while helping to create an easy-to-learn and customizable gameplay, despite their own design limitations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3163–3166},
numpages = {4},
keywords = {video game design, mixed-reality games, player strategies, tangible video game, tangible user interface, sifteo cubes},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557331,
author = {Le Goc, Mathieu and Taylor, Stuart and Izadi, Shahram and Keskin, Cem},
title = {A Low-Cost Transparent Electric Field Sensor for 3d Interaction on Mobile Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557331},
doi = {10.1145/2556288.2557331},
abstract = {We contribute a thin, transparent, and low-cost design for electric field sensing, allowing for 3D finger and hand tracking and gestures on mobile devices. Our approach requires no direct instrumentation of the hand or body, and is non-optical, allowing for a compact form-factor that is resilient to ambient illumination. Our simple driver electronics are based on an off-the-shelf chip that removes the need for building custom analog electronics. We describe the design of our transparent electrode array, and present a machine learning algorithm for mapping from signal measurements at the receivers to 3D positions. We demonstrate non-contact motion gestures, and precise 3D hand and finger localization. We conclude by discussing limitations and future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3167–3170},
numpages = {4},
keywords = {mobile, electric-field sensing, nui, 3d sensing, non-optical},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251005,
author = {Bailey, Brian},
title = {Session Details: Head-Worn Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251005},
doi = {10.1145/3251005},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557058,
author = {Ens, Barrett M. and Finnegan, Rory and Irani, Pourang P.},
title = {The Personal Cockpit: A Spatial Interface for Effective Task Switching on Head-Worn Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557058},
doi = {10.1145/2556288.2557058},
abstract = {As wearable computing goes mainstream, we must improve the state of interface design to keep users productive with natural-feeling interactions. We present the Personal Cockpit, a solution for mobile multitasking on head-worn displays. We appropriate empty space around the user to situate virtual windows for use with direct input. Through a design-space exploration, we run a series of user studies to fine-tune our layout of the Personal Cockpit. In our final evaluation, we compare our design against two baseline interfaces for switching between everyday mobile applications. This comparison highlights the deficiencies of current view-fixed displays, as the Personal Cockpit provides a 40% improvement in application switching time. We demonstrate of several useful implementations and a discussion of important problems for future implementation of our design on current and near-future wearable devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3171–3180},
numpages = {10},
keywords = {multi-display environment, head-worn display, task switching, head-mounted display, virtual window management, spatial user interface, spatial input},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556984,
author = {Serrano, Marcos and Ens, Barrett M. and Irani, Pourang P.},
title = {Exploring the Use of Hand-to-Face Input for Interacting with Head-Worn Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556984},
doi = {10.1145/2556288.2556984},
abstract = {We propose the use of Hand-to-Face input, a method to interact with head-worn displays (HWDs) that involves contact with the face. We explore Hand-to-Face interaction to find suitable techniques for common mobile tasks. We evaluate this form of interaction with document navigation tasks and examine its social acceptability. In a first study, users identify the cheek and forehead as predominant areas for interaction and agree on gestures for tasks involving continuous input, such as document navigation. These results guide the design of several Hand-to-Face navigation techniques and reveal that gestures performed on the cheek are more efficient and less tiring than interactions directly on the HWD. Initial results on the social acceptability of Hand-to-Face input allow us to further refine our design choices, and reveal unforeseen results: some gestures are considered culturally inappropriate and gender plays a role in selection of specific Hand-to-Face interactions. From our overall results, we provide a set of guidelines for developing effective Hand-to-Face interaction techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3181–3190},
numpages = {10},
keywords = {input techniques, hwd, mobile interfaces, body interaction, hmd, head-worn display},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557405,
author = {Lissermann, Roman and Huber, Jochen and Schmitz, Martin and Steimle, J\"{u}rgen and M\"{u}hlh\"{a}user, Max},
title = {Permulin: Mixed-Focus Collaboration on Multi-View Tabletops},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557405},
abstract = {We contribute Permulin, an integrated set of interaction and visualization techniques for multi-view tabletops to support co-located collaboration across a wide variety of collaborative coupling styles. These techniques (1) provide support both for group work and for individual work, as well as for the transitions in-between, (2) contribute sharing and peeking techniques to support mutual awareness and group coordination during phases of individual work, (3) reduce interference during group work on a group view, and (4) directly integrate with conventional multi-touch input. We illustrate our techniques in a proof-of-concept implementation with the two example applications of map navigation and photo collages. Results from two user studies demonstrate that Permulin supports fluent transitions between individual and group work and exhibits unique awareness properties that allow participants to be highly aware of each other during tightly coupled collaboration, while being able to unobtrusively perform individual work during loosely coupled collaboration.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3191–3200},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557063,
author = {Lauber, Felix and Butz, Andreas},
title = {In-Your-Face, yet Unseen? Improving Head-Stabilized Warnings to Reduce Reaction Time},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557063},
doi = {10.1145/2556288.2557063},
abstract = {One unique property of head-mounted displays (HMDs) is that content can easily be displayed at a fixed position within the user's field of view (head-stabilized). This ensures that critical information (e.g. warnings) is continuously visible and can, in principle, be perceived as quickly as possible. We examined this strategy with a physically and visually distracted driver. We ran two consecutive studies in a driving simulator, comparing different warning visualizations in a head-up display (HUD) and a HMD. In an initial study, we found no significant effects of warning type or display technology on the reaction times. In a second study, after modifying our visualization to include a visual reference marker, we found that with only this minor change, reaction times were significantly lower in the HMD when compared to the HUD. Our insights can help others design better head-stabilized notifications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3201–3204},
numpages = {4},
keywords = {head-up displays, head-mounted displays, driver safety},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251006,
author = {Fussell, Susan},
title = {Session Details: Applications of Body Sensing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251006},
doi = {10.1145/3251006},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557060,
author = {Wang, Hao-Chuan and Lai, Chien-Tung},
title = {Kinect-Taped Communication: Using Motion Sensing to Study Gesture Use and Similarity in Face-to-Face and Computer-Mediated Brainstorming},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557060},
doi = {10.1145/2556288.2557060},
abstract = {One key difference between face-to-face (F2F) communication and computer-mediated communication (CMC) is the availability of visual cues. It is often assumed that the reduction of visibility in audio and video conferencing may negatively impact the use of gesture to communicate, and thus negatively influence other outcomes. In this paper we "Kinect-taped" F2F and CMC communication in brainstorming groups by using motion sensors to record and analyze group members' hand movements during communication. We investigate how different media influence gesture use and gestural similarity, and how the use of gesture associates with level of understanding and brainstorming performance. Implications to future research and design are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3205–3214},
numpages = {10},
keywords = {communication accommodation, kinect, computer-mediated communication, non-verbal communication, motion sensing, gesture},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557027,
author = {Bachynskyi, Myroslav and Oulasvirta, Antti and Palmas, Gregorio and Weinkauf, Tino},
title = {Is Motion Capture-Based Biomechanical Simulation Valid for HCI Studies? Study and Implications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557027},
doi = {10.1145/2556288.2557027},
abstract = {Motion-capture-based biomechanical simulation is a non-invasive analysis method that yields a rich description of posture, joint, and muscle activity in human movement. The method is presently gaining ground in sports, medicine, and industrial ergonomics, but it also bears great potential for studies in HCI where the physical ergonomics of a design is important. To make the method more broadly accessible, we study its predictive validity for movements and users typical to studies in HCI. We discuss the sources of error in biomechanical simulation and present results from two validation studies conducted with a state-of-the-art system. Study I tested aimed movements ranging from multitouch gestures to dancing, finding out that the critical limiting factor is the size of movement. Study II compared muscle activation predictions to surface-EMG recordings in a 3D pointing task. The data shows medium-to-high validity that is, however, constrained by some characteristics of the movement and the user. We draw concrete recommendations to practitioners and discuss challenges to developing the method further.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3215–3224},
numpages = {10},
keywords = {biomechanical simulation, physical ergonomics, optical motion capture., empirical methods, validity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557116,
author = {Morris, Dan and Saponas, T. Scott and Guillory, Andrew and Kelner, Ilya},
title = {RecoFit: Using a Wearable Sensor to Find, Recognize, and Count Repetitive Exercises},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557116},
doi = {10.1145/2556288.2557116},
abstract = {Although numerous devices exist to track and share exercise routines based on running and walking, these devices offer limited functionality for strength-training exercises. We introduce RecoFit, a system for automatically tracking repetitive exercises - such as weight training and calisthenics - via an arm-worn inertial sensor. Our goal is to provide real-time and post-workout feedback, with no user-specific training and no intervention during a workout. Toward this end, we address three challenges: (1) segmenting exercise from intermittent non-exercise periods, (2) recognizing which exercise is being performed, and (3) counting repetitions. We present cross-validation results on our training data and results from a study assessing the final system, totaling 114 participants over 146 sessions. We achieve precision and recall greater than 95% in identifying exercise periods, recognition of 99%, 98%, and 96% on circuits of 4, 7, and 13 exercises respectively, and counting that is accurate to ±1 repetition 93% of the time. These results suggest that our approach enables a new category of fitness tracking devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3225–3234},
numpages = {10},
keywords = {inertial sensors, fitness, machine learning},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556957,
author = {Vosoughi, Soroush},
title = {Improving Automatic Speech Recognition through Head Pose Driven Visual Grounding},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556957},
doi = {10.1145/2556288.2556957},
abstract = {In this paper, we present a multimodal speech recognition system for real world scene description tasks. Given a visual scene, the system dynamically biases its language model based on the content of the visual scene and visual attention of the speaker. Visual attention is used to focus on likely objects within the scene. Given a spoken description the system then uses the visually biased language model to process the speech. The system uses head pose as a proxy for the visual attention of the speaker. Readily available standard computer vision algorithms are used to recognize the objects in the scene and automatic real time head pose estimation is done using depth data captured via a Microsoft Kinect. The system was evaluated on multiple participants. Overall, incorporating visual information into the speech recognizer greatly improved speech recognition accuracy. The rapidly decreasing cost of 3D sensing technologies such as the Kinect allows systems with similar underlying principles to be used for many speech recognition tasks where there is visual information.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3235–3238},
numpages = {4},
keywords = {visual attention, automatic speech recognition, language models, visual grounding, head pose estimation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3251007,
author = {Shami, N. Sadat},
title = {Session Details: Urban Communities and Social Media},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3251007},
doi = {10.1145/3251007},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557319,
author = {Masden, Christina A. and Grevet, Catherine and Grinter, Rebecca E. and Gilbert, Eric and Edwards, W. Keith},
title = {Tensions in Scaling-up Community Social Media: A Multi-Neighborhood Study of Nextdoor},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557319},
doi = {10.1145/2556288.2557319},
abstract = {This paper presents a study of Nextdoor, a social media system designed to support local neighborhoods. While not the first system designed to support community engagement, Nextdoor has a number of attributes that make it distinct. Our study, across three communities in a major U.S. city, illustrates that Nextdoor inhabits an already-rich ecosystem of community-oriented social media, but is being appropriated by its users for use in different ways than these existing media. Nextdoor also raises tensions in how it defines the boundaries of neighborhoods, and in the privacy issues it raises among its users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3239–3248},
numpages = {10},
keywords = {civic engagement, social media, local social media, nextdoor},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557401,
author = {Cranshaw, Justin B. and Luther, Kurt and Kelley, Patrick Gage and Sadeh, Norman},
title = {Curated City: Capturing Individual City Guides through Social Curation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557401},
doi = {10.1145/2556288.2557401},
abstract = {We report on our design of Curated City, a website that lets people build their own personal guide to the city's neighborhoods by chronicling their favorite experiences. Although users make their own personal guides, they are immersed in a social curatorial experience where they are influenced directly and indirectly by the guides of others. We use a 2-week field trial involving 20 residents of Pittsburgh as a technological probe to explore the initial design decisions, and we further refine the design landscape through subject interviews. Based on this study, we identify a set of design recommendations for building scalable social platforms for curating the experiences of the city.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3249–3258},
numpages = {10},
keywords = {urban computing, location-based services, social computing, social curation, neighborhoods, mental maps, local search},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557053,
author = {Laureyssens, Thomas and Coenen, Tanguy and Claeys, Laurence and Mechant, Peter and Criel, Johan and Vande Moere, Andrew},
title = {ZWERM: A Modular Component Network Approach for an Urban Participation Game},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557053},
doi = {10.1145/2556288.2557053},
abstract = {As information technology is increasingly embedded in our cities, opportunities arise to design novel applications that benefit urban communities. We describe the design and evaluation of ZWERM (Dutch for the term 'swarm'), a public game that was specifically designed for augmenting community participation in urban neighborhoods. A network of ten components has been designed, some of which had different interfaces and design approaches: from totem-like Trees for gathering around with RFID cards to playful Sparrows that react on whistle sounds. After implementing the urban game in two city neighborhoods, we investigated the impact of each of these components on their communities. Our insights are useful for the public interaction design of future urban, interactive networks that aim to positively influence community participation and social cohesion.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3259–3268},
numpages = {10},
keywords = {social cohesion, urban intervention, social engagement, network, urban game, social informatics, gamification},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557266,
author = {McGookin, David K. and Brewster, Stephen A. and Christov, Georgi},
title = {Studying Digital Graffiti as a Location-Based Social Network},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557266},
doi = {10.1145/2556288.2557266},
abstract = {Increasing amounts of geo-tagged social media have led to interest in how that media can be re-integrated into the physical environment. Yet, although location information is often automatically appended to media, little is know about how users consider location in its creation and viewing. Using Graffiti as a design meme, we developed a novel social media service to investigate these issues. A two week field study showed how users incorporated both utilitarian and playful aspects of location into their social media creation, as well as revealing a disconnect between the location-media relationship intended by creators and perceived by viewers. We outline implications of our work for services that seek to repurpose existing geo-tagged social media in the design of novel services.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3269–3278},
numpages = {10},
keywords = {geo-social media, pico projection, digigraff, graffiti},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250969,
author = {Geerts, David},
title = {Session Details: Social Media Usage},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250969},
doi = {10.1145/3250969},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556977,
author = {Chan, Rosanna Yuen-Yan and Li, Silu and Hui, Diane},
title = {Social Epistemic Cognition in Online Interactions},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556977},
doi = {10.1145/2556288.2556977},
abstract = {Social media and online social networks dramatically change the way in which knowledge is acquired and disseminated. How do we re-understand about human knowledge and knowing? This work aims at extending the current understanding of human epistemic cognition in online social environments, where epistemic cognition refers to cognitions and cognitive processes related to epistemic matters such as knowledge and beliefs justification. We approach our inquiry with mixed methods: (1) quantitative study to test whether epistemic cognition might differ in individual and social contexts, and whether online interactions might mediate the later; and (2) social cognitive task analysis with interviews to manifest the intricate interplay of dynamics between social epistemic cognition and online interactions. We introduce the new construct of social epistemic cognition and contribute to the field of HCI with an evolved theory which states that epistemic cognition can be promoted in online social environments as mediated by online interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3289–3298},
numpages = {10},
keywords = {social epistemology, cognitive task analysis, cscl, epistemic cognition, online interactions, learning sciences.},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557143,
author = {Yue, Yanzhen and Ma, Xiaojuan and Jiang, Zhenhui},
title = {Share Your View: Impact of Co-Navigation Support and Status Composition in Collaborative Online Shopping},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557143},
doi = {10.1145/2556288.2557143},
abstract = {Collaborative online shopping, an emerging paradigm in e-commerce, allows remote shoppers to extend purchase-oriented social interactions into the digital environment. Online vendors have been experimenting ways to facilitate this activity. However, more research needs to be done on identifying what feature can create a pleasing shopping experience and ultimately encourage spending. In this paper, we present an exploration of the impact of co-navigation supports, including location cue, split screen, and shared view, on the experiences and performance of 60 co-shopper dyads. We also studied if status composition of shopping companions played a role in this process. By analyzing about 1800 minutes of eye-tracking data, video footages, and web logs, we found that split screen encouraged more diverse product search, shared view enabled better coordination, and location cue was the least distracting. Co-buyers achieved better factual and inference understanding, though buyer-advisor dyads were more likely to stay together.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3299–3308},
numpages = {10},
keywords = {status composition, co-buyers, shared view, buyer-advisor, eye-tracking, split screen, collaborative online shopping, co-navigation, location cue},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557384,
author = {Reitberger, Wolfgang H. and Spreicer, Wolfgang and Fitzpatrick, Geraldine},
title = {Nutriflect: Reflecting Collective Shopping Behavior and Nutrition},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557384},
doi = {10.1145/2556288.2557384},
abstract = {A poor nutritional state, as is the case for many people today, can increase risks for cancer, cardiovascular disease and obesity. Technology supported approaches could potentially be used to positively influence food consumption. We present the Nutriflect system, which utilizes users' shopping data to inform them about their long term shopping behavior. In an initial study we conducted structured interviews in grocery stores. Based on the results we implemented a system that visualized a household's collective shopping information via situated displays. The aim was to raise awareness about shopping habits and to enable reflection about nutrition without burdening the users with the manual entry of their eating habits. We evaluated the system in a 4 week field study in 8 households with 21 users. The results indicate that contextually situated displays, showing shopping patterns against personal nutrition goals, can foster a reflective and respectful approach towards better shopping and nutrition.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3309–3318},
numpages = {10},
keywords = {nutrition, awareness, situated displays, behavior change, reflection, field study, shopping},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556973,
author = {Pielot, Martin and de Oliveira, Rodrigo and Kwak, Haewoon and Oliver, Nuria},
title = {Didn't You See My Message? Predicting Attentiveness to Mobile Instant Messages},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556973},
doi = {10.1145/2556288.2556973},
abstract = {Mobile instant messaging (e.g., via SMS or WhatsApp) often goes along with an expectation of high attentiveness, i.e., that the receiver will notice and read the message within a few minutes. Hence, existing instant messaging services for mobile phones share indicators of availability, such as the last time the user has been online. However, in this paper we not only provide evidence that these cues create social pressure, but that they are also weak predictors of attentiveness. As remedy, we propose to share a machine-computed prediction of whether the user will view a message within the next few minutes or not. For two weeks, we collected behavioral data from 24 users of mobile instant messaging services. By the means of machine-learning techniques, we identified that simple features extracted from the phone, such as the user's interaction with the notification center, the screen activity, the proximity sensor, and the ringer mode, are strong predictors of how quickly the user will attend to the messages. With seven automatically selected features our model predicts whether a phone user will view a message within a few minutes with 70.6% accuracy and a precision for fast attendance of 81.2%},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3319–3328},
numpages = {10},
keywords = {availability, asynchronous communication, messaging, attentiveness, mobile devices, prediction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250970,
author = {Forlizzi, Jodi},
title = {Session Details: Games and Education},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250970},
doi = {10.1145/3250970},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557393,
author = {Harpstead, Erik and MacLellan, Christopher J. and Aleven, Vincent and Myers, Brad A.},
title = {Using Extracted Features to Inform Alignment-Driven Design Ideas in an Educational Game},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557393},
doi = {10.1145/2556288.2557393},
abstract = {As educational games have become a larger field of study, there has been a growing need for analytic methods that can be used to assess game design and inform iteration. While much previous work has focused on the measurement of student engagement or learning at a gross level, we argue that new methods are necessary for measuring the alignment of a game to its target learning goals at an appropriate level of detail to inform design decisions. We present a novel technique that we have employed to examine alignment in an open-ended educational game. The approach is based on examining how the game reacts to representative student solutions that do and do not obey target principles. We demonstrate this method using real student data and discuss how redesign might be informed by these techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3329–3338},
numpages = {10},
keywords = {analytics, alignment, game user research, educational games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557157,
author = {O'Rourke, Eleanor and Haimovitz, Kyla and Ballweber, Christy and Dweck, Carol and Popovi\'{c}, Zoran},
title = {Brain Points: A Growth Mindset Incentive Structure Boosts Persistence in an Educational Game},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557157},
doi = {10.1145/2556288.2557157},
abstract = {There is great interest in leveraging video games to improve student engagement and motivation. However, educational games are not uniformly effective, and little is known about how in-game rewards affect children's learning-related behavior. In this work, we argue that educational games can be improved by fundamentally changing their incentive structures to promote the growth mindset, or the belief that intelligence is malleable. We present "brain points," a system that encourages the development of growth mindset behaviors by directly incentivizing effort, use of strategy, and incremental progress. Through a study of 15,000 children, we show that the "brain points" system encourages more low-performing students to persist in the educational game Refraction when compared to a control, and increases overall time played, strategy use, and perseverance after challenge. We believe that this growth mindset incentive structure has great potential in many educational environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3339–3348},
numpages = {10},
keywords = {growth mindset, educational games, incentive structures},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557392,
author = {Liu, Yun-En and Mandel, Travis and Brunskill, Emma and Popovi\'{c}, Zoran},
title = {Towards Automatic Experimentation of Educational Knowledge},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557392},
doi = {10.1145/2556288.2557392},
abstract = {We present a general automatic experimentation and hypothesis generation framework that utilizes a large set of users to explore the effects of different parts of an intervention parameter space on any objective function. We also incorporate importance sampling, allowing us to run these automatic experiments even if we cannot give out the exact intervention distributions that we want. To show the utility of this framework, we present an implementation in the domain of fractions and numberlines, using an online educational game as the source of players. Our system is able to automatically explore the parameter space and generate hypotheses about what types of numberlines lead to maximal short-term transfer; testing on a separate dataset shows the most promising hypotheses are valid. We briefly discuss our results in the context of the wider educational literature, showing that one of our results is not explained by current research on multiple fraction representations, thus proving our ability to generate potentially interesting hypotheses to test.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3349–3358},
numpages = {10},
keywords = {datamining, education, games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557074,
author = {Wohn, Donghee Yvette},
title = {Spending Real Money: Purchasing Patterns of Virtual Goods in an Online Social Game},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557074},
doi = {10.1145/2556288.2557074},
abstract = {Researchers have found that 'social' factors contribute to purchasing intentions of virtual goods in an online social game, but little is known about actual purchasing behavior. Study 1 examined the relationship between social factors and virtual goods purchasing patterns using large scale data obtained by server logs of an online social game. Exchange of virtual goods and number of friends increased the likelihood of spending real money compared to no spending. Among those who did spend real money, giving virtual goods to others was the strongest factor associated with the amount of spending. Study 2 examined purchasing patterns of players who spent real money: high real-money spenders were buying items for visual customization while low spenders were buying consumable items necessary to sustain playing the game.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3359–3368},
numpages = {10},
keywords = {e-commerce, consumer behavior, virtual goods, social exchange, social game, customization, big data},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250971,
author = {Ogan, Amy},
title = {Session Details: Learning and Games},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250971},
doi = {10.1145/3250971},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556954,
author = {Li, Wei and Grossman, Tovi and Fitzmaurice, George},
title = {CADament: A Gamified Multiplayer Software Tutorial System},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556954},
doi = {10.1145/2556288.2556954},
abstract = {We present CADament, a gamified multiplayer tutorial system for learning AutoCAD. Compared with existing gamified software tutorial systems, CADament generates engaging learning experience through competitions. We investigate two variations of our game, where over-the-shoulder learning was simulated by providing viewports into other player's screens. We introduce an empirical lab study methodology where participants compete with one another, and we study knowledge transfer effects by tracking the migration of strategies between players during the study session. Our study shows that CADament has an advantage over pre-authored tutorials for improving learners' performance, increasing motivation, and stimulating knowledge transfer.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3369–3378},
numpages = {10},
keywords = {tutorial, multiplayer, learning, game},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557217,
author = {Dontcheva, Mira and Morris, Robert R. and Brandt, Joel R. and Gerber, Elizabeth M.},
title = {Combining Crowdsourcing and Learning to Improve Engagement and Performance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557217},
doi = {10.1145/2556288.2557217},
abstract = {Crowdsourcing complex creative tasks remains difficult, in part because these tasks require skilled workers. Most crowdsourcing platforms do not help workers acquire the skills necessary to accomplish complex creative tasks. In this paper, we describe a platform that combines learning and crowdsourcing to benefit both the workers and the requesters. Workers gain new skills through interactive step-by-step tutorials and test their knowledge by improving real-world images submitted by requesters. In a series of three deployments spanning two years, we varied the design of our platform to enhance the learning experience and improve the quality of the crowd work. We tested our approach in the context of LevelUp for Photoshop, which teaches people how to do basic photograph improvement tasks using Adobe Photoshop. We found that by using our system workers gained new skills and produced high-quality edits for requested images, even if they had little prior experience editing images.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3379–3388},
numpages = {10},
keywords = {crowdsourcing, training, games},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557281,
author = {Dunwell, Ian and de Freitas, Sara and Petridis, Panagiotis and Hendrix, Maurice and Arnab, Sylvester and Lameras, Petros and Stewart, Craig},
title = {A Game-Based Learning Approach to Road Safety: The Code of Everand},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557281},
doi = {10.1145/2556288.2557281},
abstract = {Game and gamification elements are increasingly seeing use as part of interface designs for applications seeking to engage and retain users whilst transferring information. This paper presents an evaluation of a game-based approach seeking to improve the road safety behaviour amongst children aged 9-15 within the UK, made available outside of a classroom context as an online, browser-based, free-to-play game. The paper reports on data for 99,683 players over 315,882 discrete logins, supplemented by results from a nationally-representative survey of children at UK schools (n=1,108), an incentivized survey of the player-base (n=1,028), and qualitative data obtained through a series of one-to-one interviews aged 9-14 (n=28). Analysis demonstrates the reach of the game to its target demographic, with 88.13% of players within the UK. A 3.94 male/female ratio was observed amongst players surveyed, with an age distribution across the target range of 9-15. Noting mean and median playtimes of 93 and 31 minutes (n=99,683), it is suggested such an approach to user engagement and retention can surpass typical contact times obtained through other forms of web-based content. The size of the player-base attracted to the game and players' qualitative feedback demonstrates the potential for serious games deployed on a national scale.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3389–3398},
numpages = {10},
keywords = {game-based interfaces, attitudinal change, gamification, e-learning, serious games, road safety},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557368,
author = {Monserrat, Toni-Jan Keith Palma and Li, Yawen and Zhao, Shengdong and Cao, Xiang},
title = {L.IVE: An Integrated Interactive Video-Based Learning Environment},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557368},
doi = {10.1145/2556288.2557368},
abstract = {In this paper, we introduce L.IVE: an online interactive video-based learning environment with an alternative design and architecture that integrates three major interface components: video, comment threads, and assessments. This is in contrast with the approach of existing interfaces which visually separate these components. Our study, which compares L.IVE with existing popular video-based learning environments, suggests advantages in this integrated approach as compared to the separated approach in learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3399–3402},
numpages = {4},
keywords = {l.ive, video-based online learning, interactive video},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250972,
author = {Cherry, Erin},
title = {Session Details: Persuasive Technologies and Applications},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250972},
doi = {10.1145/3250972},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557099,
author = {Hsu, Anne and Yang, Jing and Yilmaz, Yigit Han and Haque, Md Sanaul and Can, Cengiz and Blandford, Ann E.},
title = {Persuasive Technology for Overcoming Food Cravings and Improving Snack Choices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557099},
doi = {10.1145/2556288.2557099},
abstract = {A central challenge in weight management is the difficulty of overcoming desires for excessive and unhealthy food. Yet, studies show that when people are able to resist their desires for unhealthy choices, they experience pride and satisfaction. In order to alleviate the former and support the latter, we designed, implemented and tested a mobile application for improving snacking behavior. Our application delivers a food craving reduction intervention at the moment of need and allows users to track how often they successfully resisted cravings. Our craving reduction intervention is based on recent research that shows that food cravings can be reduced through imagery techniques. We conducted a week-long evaluation of our application, comparing the effectiveness of our application to a basic tracking application. We found that our imagery application significantly reduced both overall snacking and unhealthy snacking compared to a simple snack-tracking application.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3403–3412},
numpages = {10},
keywords = {weight management, user-centered design, persuasive technologies, mobile, behavior change, wellness},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556962,
author = {Gerling, Kathrin Maria and Mandryk, Regan L. and Birk, Max Valentin and Miller, Matthew and Orji, Rita},
title = {The Effects of Embodied Persuasive Games on Player Attitudes toward People Using Wheelchairs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556962},
doi = {10.1145/2556288.2556962},
abstract = {People using wheelchairs face barriers in their daily lives, many of which are created by people who surround them. Promoting positive attitudes towards persons with disabilities is an integral step in removing these barriers and improving their quality of life. In this context, persuasive games offer an opportunity of encouraging attitude change. We created a wheelchair-controlled persuasive game to study how embodied interaction can be applied to influence player attitudes over time. Our results show that the game intervention successfully raised awareness for challenges that people using wheelchairs face, and that embodied interaction is a more effective approach than traditional input in terms of retaining attitude change over time. Based on these findings, we provide design strategies for embodied interaction in persuasive games, and outline how our findings can be leveraged to help designers create effective persuasive experiences beyond games.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3413–3422},
numpages = {10},
keywords = {disability, persuasive games, attitude change, embodied interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557390,
author = {Ruggiero, Dana N.},
title = {Spent: Changing Students' Affective Learning toward Homelessness through Persuasive Video Game Play},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557390},
doi = {10.1145/2556288.2557390},
abstract = {To investigate whether a persuasive game may serve as a way to increase affective learning about homelessness, this study examined the effects of procedural rhetoric and ethos in a video game designed to put the player in the shoes of an almost-homeless person. Data were collected from 5139 students across four states. Examination revealed that playing the game or doing the reading significantly increased the affective learning score after treatment with the game group scoring 1.57 points higher and the reading group scoring .66 points higher out of a score of 6. Findings indicate that students who played Spent sustained significantly higher scores after three weeks. Overall, findings suggest that when students play a video game that is designed using persuasive mechanics an affective change can be measured empirically.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3423–3432},
numpages = {10},
keywords = {video games, affective learning, persuasive mechanics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557418,
author = {Fiore, Andrew T. and Cheshire, Coye and Shaw Taylor, Lindsay and Mendelsohn, G.A.},
title = {Incentives to Participate in Online Research: An Experimental Examination of "Surprise" Incentives},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557418},
doi = {10.1145/2556288.2557418},
abstract = {The recruitment of participants for online survey research presents many challenges. In this work, we present four experiments examining how two different kinds of "surprise" financial incentives affect the rate of participation in a longitudinal study when participants are initially solicited with either an appeal to intrinsic motivation to participate in research or one that also offers extrinsic financial incentives. We find that unexpected financial incentives ("existence surprises") presented to people who click a recruitment advertisement focused on intrinsic incentives lead to a lower recruitment rate than do the same incentives offered to those who clicked an advertisement that led them to expect it. However, when potential participants expect a financial incentive, surprising them with a higher amount ("amount surprises") yields a higher recruitment rate. We interpret these results in the context of crowding theory. Neither type of surprise affected ongoing participation, measured as the number of questions and questionnaires completed over the course of the study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3433–3442},
numpages = {10},
keywords = {incentives, motivation, online research recruitment},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250973,
author = {Hilliges, Otmar},
title = {Session Details: Whole Body Sensing and Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250973},
doi = {10.1145/3250973},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556989,
author = {Schwarz, Julia and Marais, Charles Claudius and Leyvand, Tommer and Hudson, Scott E. and Mankoff, Jennifer},
title = {Combining Body Pose, Gaze, and Gesture to Determine Intention to Interact in Vision-Based Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556989},
doi = {10.1145/2556288.2556989},
abstract = {Vision-based interfaces, such as those made popular by the Microsoft Kinect, suffer from the Midas Touch problem: every user motion can be interpreted as an interaction. In response, we developed an algorithm that combines facial features, body pose and motion to approximate a user's intention to interact with the system. We show how this can be used to determine when to pay attention to a user's actions and when to ignore them. To demonstrate the value of our approach, we present results from a 30-person lab study conducted to compare four engagement algorithms in single and multi-user scenarios. We found that combining intention to interact with a 'raise an open hand in front of you' gesture yielded the best results. The latter approach offers a 12% improvement in accuracy and a 20% reduction in time to engage over a baseline 'wave to engage' gesture currently used on the Xbox 360.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3443–3452},
numpages = {10},
keywords = {vision-based input, input segmentation, learned models, user engagement, free-space interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557043,
author = {Hayashi, Eiji and Maas, Manuel and Hong, Jason I.},
title = {Wave to Me: User Identification Using Body Lengths and Natural Gestures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557043},
doi = {10.1145/2556288.2557043},
abstract = {We introduce a body-based identification system that leverages individual differences in body segment lengths and hand waving gesture patterns. The system identifies users based on a two-second hand waving gesture captured by a Microsoft Kinect. To evaluate our system, we collected 8640 gesture measurements from 75 participants through two lab studies and a field study. In the first lab study, we evaluated the feasibility of our concept and basic properties of features to narrow down the design space. In the second lab study, our system achieved a 1% equal error rate in user identification among seven registered users after two weeks following initial registration. We also found that our system was robust even when lower body segments could not be measured because of occlusions. In the field study, our system achieved 0.5 to 1.6% equal error rates, demonstrating that the system also works well in ecologically valid situations. Lastly, throughout the studies, our participants were positive about the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3453–3462},
numpages = {10},
keywords = {user identification, gesture, natural user interface},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557101,
author = {Cheng, Lung-Pan and L\"{u}hne, Patrick and Lopes, Pedro and Sterz, Christoph and Baudisch, Patrick},
title = {Haptic Turk: A Motion Platform Based on People},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557101},
doi = {10.1145/2556288.2557101},
abstract = {Motion platforms are used to increase the realism of virtual interaction. Unfortunately, their size and weight is proportional to the size of what they actuate. We present haptic turk, a different approach to motion platforms that is light and mobile. The key idea is to replace motors and mechanical components with humans. All haptic turk setups consist of a player who is supported by one or more turkers. The player enjoys an interactive experience, such as a flight simulation. The motion in the player's experience is generated by the turkers who manually lift, tilt, and push the player's limbs or torso. To get the timing and force right, timed motion instructions in a format familiar from rhythm games are displayed on turkers' mobile devices, which they attach to the player's body. We demonstrate a range of installations based on mobile phones, projectors, and head-mounted displays. In our user study, participants rated not only the experience as player as enjoyable (6.1/7), but also the experience as a turker (4.4/7). The approach of leveraging humans allows us to deploy our approach anytime anywhere, as we demonstrate by experimentally deploying at an art festival in the Nevada desert.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3463–3472},
numpages = {10},
keywords = {motion platform, force-feedback, immersion, haptics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556965,
author = {Downs, John and Vetere, Frank and Howard, Steve and Loughnan, Steve and Smith, Wally},
title = {Audience Experience in Social Videogaming: Effects of Turn Expectation and Game Physicality},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556965},
doi = {10.1145/2556288.2556965},
abstract = {Videogames are often played socially with both co-players and audiences. Audience members' experiences are not well understood, nor are the factors of videogaming sessions that influence their experience. We conducted a study to examine the effects of game physicality and turn anticipation on audience members' experiences in social videogaming sessions. Pairs of participants played games under three conditions of physicality (controller-based, Wii, and Kinect) and their expectation of turn-taking was manipulated. Their enjoyment, game engagement, social engagement and sense of participation were measured. We found that the introduction of turn-taking into the session had positive effects for audience members -- both anticipated and residual play effects -- and that Kinect gameplay resulted in a more enjoyable experience for audience members. We argue that audience members' experience changes as they become more active within a session, and suggest there are design opportunities between purely active 'players' and passive 'audience members'.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3473–3482},
numpages = {10},
keywords = {turn-taking, audience experience, social gaming, physical videogames},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250974,
author = {Forlines, Clifton},
title = {Session Details: Novel Mobile Displays and Devices},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250974},
doi = {10.1145/3250974},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557208,
author = {Sahami Shirazi, Alireza and Abdelrahman, Yomna and Henze, Niels and Schneegass, Stefan and Khalilbeigi, Mohammadreza and Schmidt, Albrecht},
title = {Exploiting Thermal Reflection for Interactive Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557208},
doi = {10.1145/2556288.2557208},
abstract = {Thermal cameras have recently drawn the attention of HCI researchers as a new sensory system enabling novel interactive systems. They are robust to illumination changes and make it easy to separate human bodies from the image background. Far-infrared radiation, however, has another characteristic that distinguishes thermal cameras from their RGB or depth counterparts, namely thermal reflection. Common surfaces reflect thermal radiation differently than visual light and can be perfect thermal mirrors. In this paper, we show that through thermal reflection, thermal cameras can sense the space beyond their direct field-of-view. A thermal camera can sense areas besides and even behind its field-of-view through thermal reflection. We investigate how thermal reflection can increase the interaction space of projected surfaces using camera-projection systems. We moreover discuss the reflection characteristics of common surfaces in our vicinity in both the visual and thermal radiation bands. Using a proof-of-concept prototype, we demonstrate the increased interaction space for hand-held camera-projection system. Furthermore, we depict a number of promising application examples that can benefit from the thermal reflection characteristics of surfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3483–3492},
numpages = {10},
keywords = {camera-projector system, thermal imaging, roughness, reflection, heat},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557325,
author = {Martinez Plasencia, Diego and Joyce, Edward and Subramanian, Sriram},
title = {MisTable: Reach-through Personal Screens for Tabletops},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557325},
doi = {10.1145/2556288.2557325},
abstract = {We present MisTable, a tabletop system that combines a conventional horizontal interactive surface with personal screens between the user and the tabletop surface. These personal screens, built using fog, are both see-through and reach-through. Being see-through provides direct line of sight of the personal screen and the elements behind it on the tabletop. Being reach-through allows the user to switch from interacting with the personal screen to reaching through it to interact with the tabletop or the space above it. The personal screen allows a range of customisations and novel interactions such as presenting 2D personal contents on the screen, 3D contents above the tabletop or augmenting and relighting tangible objects differently for each user. Besides, having a personal screen for each user allows us to customize the view of each of them according to their identity or preferences. Finally, the personal screens preserve all well-established tabletop interaction techniques like touch and tangible interactions. We explore the challenges in building such a reach-through system through a proof-of-concept implementation and discuss the possibilities afforded by the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3493–3502},
numpages = {10},
keywords = {tabletops systems, fog screens., see-through displays, reach-through displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557306,
author = {Ahmaniemi, Teemu T. and Kildal, Johan and Haveri, Merja},
title = {What is a Device Bend Gesture Really Good For?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557306},
abstract = {Device deformation allows new types of gestures to be used in interaction. We identify that the gesture/use-case pairings proposed by interaction designers are often driven by factors relating improved tangibility, spatial directionality and strong metaphorical bonds. With this starting point, we argue that some of the designs may not make use of the full potential of deformation gestures as continuous, bipolar input techniques. In two user studies, we revisited the basics of deformation input by taking a new systematic look at the question of matching gestures with use cases. We observed comparable levels of UX when using bend input in different continuous bipolar interactions, irrespective of the choice of tangibility, directionality and metaphor. We concluded that device bend gestures use their full potential when used to control continuous bipolar parameters, and when quick reactions are needed. From our studies, we also identify relative strengths of absolute and relative mappings, and report a Fitts' law study for device bending input.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3503–3512},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557075,
author = {Winkler, Christian and L\"{o}chtefeld, Markus and Dobbelstein, David and Kr\"{u}ger, Antonio and Rukzio, Enrico},
title = {SurfacePhone: A Mobile Projection Device for Single- and Multiuser Everywhere Tabletop Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557075},
doi = {10.1145/2556288.2557075},
abstract = {To maintain a mobile form factor, the screen real estate of a mobile device canIn this paper we present SurfacePhone; a novel configuration of a projector phone which aligns the projector to project onto a physical surface to allow tabletop-like interaction in a mobile setup. The projection is created behind the upright standing phone and is touch and gesture-enabled. Multiple projections can be merged to create shared spaces for multi-user collaboration. We investigate this new setup, starting with the concept that we evaluated with a concept prototype. Furthermore we present our technical prototype, a mobile phone case with integrated projector that allows for the aforementioned interaction. We discuss its technical requirements and evaluate the accuracy of interaction in a second user study. We conclude with lessons learned and design guidelines.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3513–3522},
numpages = {10},
keywords = {mobile multi display environment, projector phone, interactive surfaces},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250975,
author = {Bardzell, Jeffrey},
title = {Session Details: HCI Paradigms: Past, Present and Future},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250975},
doi = {10.1145/3250975},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557004,
author = {Hornb\ae{}k, Kasper and Sander, S\o{}ren S. and Bargas-Avila, Javier Andr\'{e}s and Grue Simonsen, Jakob},
title = {Is Once Enough? On the Extent and Content of Replications in Human-Computer Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557004},
doi = {10.1145/2556288.2557004},
abstract = {A replication is an attempt to confirm an earlier study's findings. It is often claimed that research in Human-Computer Interaction (HCI) contains too few replications. To investigate this claim we examined four publication outlets (891 papers) and found 3% attempting replication of an earlier result. The replications typically confirmed earlier findings, but treated replication as a confirm/not-confirm decision, rarely analyzing effect sizes or comparing in depth to the replicated paper. When asked, most authors agreed that their studies were replications, but rarely planned them as such. Many non-replication studies could have corroborated earlier work if they had analyzed data differently or used minimal effort to collect extra data. We discuss what these results mean to HCI, including how reporting of studies could be improved and how conferences/journals may change author instructions to get more replications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3523–3532},
numpages = {10},
keywords = {replications},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557185,
author = {Sun, Huatong and Hart-Davidson, William F.},
title = {Binding the Material and the Discursive with a Relational Approach of Affordances},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557185},
doi = {10.1145/2556288.2557185},
abstract = {As Norman's vision of affordances developed twenty-six years ago is unable to address complex challenges faced by today's designers, we outline a view of affordances as discursive relations in HCI design. This argument is framed in the discussion of a larger trend of work beyond the HCI field, the scholarship on relational affordances from the fields of communication and organization studies. Through comparison and interrogation, we maintain a relational approach of affordances that bind the material and the discursive will help us to address design issues such as discursive power, cultural values, performed identities, mediated agency, and articulated voices in this increasingly globalized world and design culturally sensitive technology for transformation and emancipation. With a few cases, this paper deciphers the hidden power relationship of interaction design and suggests ways of we should design for social affordances.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3533–3542},
numpages = {10},
keywords = {ideology, cross-cultural design, culture, materiality, affordance, discursive, critical design, hci, hci4d, identity},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557111,
author = {Kuutti, Kari and Bannon, Liam J.},
title = {The Turn to Practice in HCI: Towards a Research Agenda},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557111},
doi = {10.1145/2556288.2557111},
abstract = {This paper argues that a new paradigm for HCI research, which we label the 'practice' perspective, has been emerging in recent years. This stands in contrast to the prevailing mainstream HCI paradigm, which we term the 'interaction' perspective. The 'practice turn', as it has been dubbed in the social sciences, provides a conceptual frame to organize a variety of issues emerging in more recent HCI research. While this approach has been present in certain strands of HCI research for some time, it has not been articulated fully to date. In this paper, we provide a short account of the main tenets of this perspective, and then show how it can illuminate some of the recent debates within HCI. Our argument is one which does not seek to replace extant HCI theories, but rather to provide an alternative, complementary theoretical lens which may illuminate the present confusion among both researchers and practitioners as to the direction of HCI. The paper articulates a set of issues which can help direct HCI research programs, as well as highlighting the potential contribution of the HCI field to this practice approach itself, in terms of a more nuanced understanding of emerging practices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3543–3552},
numpages = {10},
keywords = {theory, research, methodology, practice},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556969,
author = {Liu, Yong and Goncalves, Jorge and Ferreira, Denzil and Xiao, Bei and Hosio, Simo and Kostakos, Vassilis},
title = {CHI 1994-2013: Mapping Two Decades of Intellectual Progress through Co-Word Analysis},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556969},
doi = {10.1145/2556288.2556969},
abstract = {This study employs hierarchical cluster analysis, strategic diagrams and network analysis to map and visualize the intellectual landscape of the CHI conference on Human Computer Interaction through the use of co-word analysis. The study quantifies and describes the thematic evolution of the field based on a total of 3152 CHI articles and their associated 16035 keywords published between 1994 and 2013. The analysis is conducted for two time periods (1994-2003, 2004-2013) and a comparison between them highlights the underlying trends in our community. More significantly, this study identifies the evolution of major themes in the discipline, and highlights individual topics as popular, core, or backbone research topics within HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3553–3562},
numpages = {10},
keywords = {conceptual evolution, bibliometric study, coherence, cohesion, hci, co-word analysis},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250976,
author = {Gergle, Darren},
title = {Session Details: PolitiCHI},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250976},
doi = {10.1145/3250976},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557197,
author = {De Choudhury, Munmun and Monroy-Hern\'{a}ndez, Andr\'{e}s and Mark, Gloria},
title = {"Narco" Emotions: Affect and Desensitization in Social Media during the Mexican Drug War},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557197},
doi = {10.1145/2556288.2557197},
abstract = {Social media platforms have emerged as prominent information sharing ecosystems in the context of a variety of recent crises, ranging from mass emergencies, to wars and political conflicts. We study affective responses in social media and how they might indicate desensitization to violence experienced in communities embroiled in an armed conflict. Specifically, we examine three established affect measures: negative affect, activation, and dominance as observed on Twitter in relation to a number of statistics on protracted violence in four major cities afflicted by the Mexican Drug War. During a two year period (Aug 2010 - Dec 2012), while violence was on the rise in these regions, our findings show a decline in negative emotional expression as well as a rise in emotional arousal and dominance in Twitter posts: aspects known to be psychological markers of desensitization. We discuss the implications of our work for behavioral health, facilitating rehabilitation efforts in communities enmeshed in an acute and persistent urban warfare, and the impact on civic engagement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3563–3572},
numpages = {10},
keywords = {desensitization, social media, affect, crisis informatics},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557100,
author = {Crivellaro, Clara and Comber, Rob and Bowers, John and Wright, Peter C. and Olivier, Patrick},
title = {A Pool of Dreams: Facebook, Politics and the Emergence of a Social Movement},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557100},
doi = {10.1145/2556288.2557100},
abstract = {In this paper we present insights from an empirical analysis of data from an emergent social movement primarily located on a Facebook page to contribute understanding of the conduct of everyday politics in social media and through this open up research agendas for HCI. The analysis focuses on how interactions and contributions facilitated the emergence of a collective with political will. We lay out an exploration of the intrinsic relationship between cultural memories, cultural expression and everyday politics and show how diverging voices co-constructed dynamic collectives capable of political action. We look at how interactions through the Facebook page challenge traditional ways for conceiving politics and the political. We outline possible research agendas in the field of everyday politics, which are sensitive to the everyday acts of resistance enclosed in the ordinary.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3573–3582},
numpages = {10},
keywords = {activism, discourse, politics, collectives, social media},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556971,
author = {Voida, Amy and Dombrowski, Lynn and Hayes, Gillian R. and Mazmanian, Melissa},
title = {Shared Values/Conflicting Logics: Working around e-Government Systems},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556971},
doi = {10.1145/2556288.2556971},
abstract = {In this paper, we describe results from fieldwork conducted at a social services site where the workers evaluate citizens' applications for food and medical assistance submitted via an e-government system. These results suggest value tensions that result - not from different stakeholders with different values - but from differences among how stakeholders enact the same shared value in practice. In the remainder of this paper, we unpack the distinct and conflicting interpretations or logics of three shared values - efficiency, access, and education. In particular, we analyze what happens when social services workers have ideas about what it means to expand access, increase efficiency, and educate the public that conflict with the logics embedded in the e-government system. By distinguishing between overarching values and specific logics, we provide an analytic framework for exploring value tensions as values are enacted in practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3583–3592},
numpages = {10},
keywords = {values, e-government, social services},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557311,
author = {Knowles, Bran and Blair, Lynne and Coulton, Paul and Lochrie, Mark},
title = {Rethinking Plan A for Sustainable HCI},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557311},
doi = {10.1145/2556288.2557311},
abstract = {This paper challenges the sustainable HCI community to move away from a focus on demand and instead address climate change as a supply problem. We identify a new route to impact, namely addressing the psychological barriers that interfere with political mobilization toward limiting the use of fossil fuels. Five barriers are explored as a means of re-focusing research objectives for the community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3593–3596},
numpages = {4},
keywords = {supply, psychological barriers, climate change, sustainability, activism},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250977,
author = {Perry, Mark},
title = {Session Details: Location-Based Services and Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250977},
doi = {10.1145/3250977},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557404,
author = {Prasad, Manoj and Taele, Paul and Goldberg, Daniel and Hammond, Tracy A.},
title = {HaptiMoto: Turn-by-Turn Haptic Route Guidance Interface for Motorcyclists},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557404},
doi = {10.1145/2556288.2557404},
abstract = {A national study by the Australian Transport Safety Bureau revealed that motorcyclist deaths were nearly thirty times more prevalent than that of drivers of other vehicles. These fatalities represent approximately 5% of all highway deaths each year, yet motorcycles account for only 2% of all registered vehicles in the USA. Motorcyclists are highly exposed on the road, so maintaining situational awareness at all times is crucial. Route guidance systems enable users to efficiently navigate between locations using dynamic visual maps and audio directions, and have been well tested with motorists, but remain unsafe for use by motorcyclists. Audio/visual routing systems decrease motorcyclists' situational awareness and vehicle control, and thus elevate chances of an accident. To enable motorcyclists to take advantage of route guidance while maintaining situational awareness, we created HaptiMoto, a wearable haptic route guidance system. HaptiMoto uses tactile signals to encode the distance and direction of approaching turns, thus avoiding interference with audio/visual awareness. Our evaluations demonstrate that HaptiMoto is both intuitive and a safer alternative for motorcyclists compared to existing solutions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3597–3606},
numpages = {10},
keywords = {advanced traveler information system, vibro-tactile, tactile interface, route guidance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557003,
author = {M\"{o}ller, Andreas and Kranz, Matthias and Diewald, Stefan and Roalter, Luis and Huitl, Robert and Stockinger, Tobias and Koelle, Marion and Lindemann, Patrick A.},
title = {Experimental Evaluation of User Interfaces for Visual Indoor Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557003},
doi = {10.1145/2556288.2557003},
abstract = {Mobile location recognition by capturing images of the environment (visual localization) is a promising technique for indoor navigation in arbitrary surroundings. However, it has barely been investigated so far how the user interface (UI) can cope with the challenges of the vision-based localization technique, such as varying quality of the query images. We implemented a novel UI for visual localization, consisting of Virtual Reality (VR) and Augmented Reality (AR) views that actively communicate and ensure localization accuracy. If necessary, the system encourages the user to point the smartphone at distinctive regions to improve localization quality. We evaluated the UI in a experimental navigation task with a prototype, informed by initial evaluation results using design mockups. We found that VR can contribute to efficient and effective indoor navigation even at unreliable location and orientation accuracy. We discuss identified challenges and share lessons learned as recommendations for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3607–3616},
numpages = {10},
keywords = {augmented reality, mobile interaction, virtual reality, visual localization, indoor navigation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557156,
author = {Pritchard, Gary and Vines, John and Briggs, Pam and Thomas, Lisa and Olivier, Patrick},
title = {Digitally Driven: How Location Based Services Impact the Work Practices of London Bus Drivers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557156},
doi = {10.1145/2556288.2557156},
abstract = {This paper examines how an occupational group has adapted to the demands of working with a Location Based Service (LBS). Instead of following a rigid timetable, London's bus drivers are now required to maintain an equal distance between the bus in front and the one behind. Our qualitative study employs ethnographic fieldwork and in-depth semi-structured interviews to elicit drivers' perspectives of the new system and show how it has modified their driving and general work conditions. We explore how passengers influence the movement of the bus and how the technology frames bus drivers' relationships to their managers and commuters. This work contributes to our understanding of the impact of LBS in the workplace and shows how technological imperatives can be established that cause unanticipated consequences and gradually undermine human relationships.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3617–3626},
numpages = {10},
keywords = {lbs, auto ethnography, lbd, location based services, ethnography, location based devices, public transport},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557289,
author = {Dancu, Alexandru and Franjcic, Zlatko and Fjeld, Morten},
title = {Smart Flashlight: Map Navigation Using a Bike-Mounted Projector},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557289},
doi = {10.1145/2556288.2557289},
abstract = {While mobile phones affect our behavior and tend to separate us from our physical environment, this very environment could instead become a responsive part of the information domain. For navigation using a map while cycling in an urban environment, we studied two alternative solutions: smartphone display and projection on the road. This paper firstly demonstrates by proof-of-concept a GPS-based map navigation using a bike-mounted projector. Secondly, it implements a prototype using both a projector and a smartphone mounted on a bike, comparing them for use in a navigation system for nighttime cycling. Thirdly, it examines how visuo-spatial factors influence navigation. We believe that our findings will be useful for designing navigation systems for bikes and even for cars, helping cyclists and drivers be more attentive to their environment while navigating, and to provide useful information while moving.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3627–3630},
numpages = {4},
keywords = {bike, smartphone, field of view, navigation, gps, visuo-spatial, pico-projector},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557370,
author = {Lee, Key Jung and Joo, Yeon Kyoung and Nass, Clifford},
title = {Partially Intelligent Automobiles and Driving Experience at the Moment of System Transition},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557370},
doi = {10.1145/2556288.2557370},
abstract = {The current study (N = 49) took a user-centered approach to explore how level of automation (pedal automated, wheel automated or fully automated driving) and the interface modality (switching automation on or off via touch or voice control) in automated vehicles influence drivers' perceived experience and performance. The results found that full or wheel automation in vehicles was perceived significantly more intelligent than pedal automation. Furthermore, drivers in the pedal automation condition reported greater nervousness when using the touch interface than the voice interface. This tendency was not found among drivers in the full and wheel automation conditions. Drivers who used the voice interface to control automated driving had fewer driving mistakes than those who operated the touch interface. Our findings have important psychological and practical implications for designing a user interface for automated vehicles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3631–3634},
numpages = {4},
keywords = {in-car interfaces, automated car, situational awareness, safe driving, partial automation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250978,
author = {Dow, Steven},
title = {Session Details: Crowdsourcing},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250978},
doi = {10.1145/3250978},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557044,
author = {Truong, Khai N. and Shihipar, Thariq and Wigdor, Daniel J.},
title = {Slide to X: Unlocking the Potential of Smartphone Unlocking},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557044},
doi = {10.1145/2556288.2557044},
abstract = {Unlock gestures are performed by billions of users across the world multiple times a day. Beyond preventing accidental input on mobile devices, they currently serve little to no other purpose. In this paper, we explore how replacing the regular unlock screen with one that asks the user to perform a simple, optional task, can benefit a wealth of application domains, including data collection, personal-health metrics collection, and human intelligence tasks. We evaluate this concept, which we refer to as Slide to X. Further, we show that people are willing to perform microtasks presented through this interface and continue to do so throughout the day while they visit different locations as part of their daily routines. We then discuss how to implement this concept and demonstrate three applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3635–3644},
numpages = {10},
keywords = {phone unlock, microtasks, dual-purpose interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556996,
author = {Vaish, Rajan and Wyngarden, Keith and Chen, Jingshu and Cheung, Brandon and Bernstein, Michael S.},
title = {Twitch Crowdsourcing: Crowd Contributions in Short Bursts of Time},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556996},
doi = {10.1145/2556288.2556996},
abstract = {To lower the threshold to participation in crowdsourcing, we present twitch crowdsourcing: crowdsourcing via quick contributions that can be completed in one or two seconds. We introduce Twitch, a mobile phone application that asks users to make a micro-contribution each time they unlock their phone. Twitch takes advantage of the common habit of turning to the mobile phone in spare moments. Twitch crowdsourcing activities span goals such as authoring a census of local human activity, rating stock photos, and extracting structured data from Wikipedia pages. We report a field deployment of Twitch where 82 users made 11,240 crowdsourcing contributions as they used their phone in the course of everyday life. The median Twitch activity took just 1.6 seconds, incurring no statistically distinguishable costs to unlock speed or cognitive load compared to a standard slide-to-unlock interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3645–3654},
numpages = {10},
keywords = {microtasking, mobile crowdsourcing, crowdsourcing},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556967,
author = {Forlines, Clifton and Miller, Sarah and Guelcher, Leslie and Bruzzi, Robert},
title = {Crowdsourcing the Future: Predictions Made with a Social Network},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556967},
doi = {10.1145/2556288.2556967},
abstract = {Researchers have long known that aggregate estimations built from the collected opinions of a large group of people often outperform the estimations of individual experts. This phenomenon is generally described as the "Wisdom of Crowds". This approach has shown promise with respect to the task of accurately forecasting future events. Previous research has demonstrated the value of utilizing meta-forecasts (forecasts about what others in the group will predict) when aggregating group predictions. In this paper, we describe an extension to meta-forecasting and demonstrate the value of modeling the familiarity among a population's members (its social network) and applying this model to forecast aggregation. A pair of studies demonstrates the value of taking this model into account, and the described technique produces aggregate forecasts for future events that are significantly better than the standard Wisdom of Crowds approach as well as previous meta-forecasting techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3655–3664},
numpages = {10},
keywords = {aggregation, meta-forecast, crowd-sourcing, bayesian truth serum, forecasting, social network},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557155,
author = {Alagarai Sampath, Harini and Rajeshuni, Rajeev and Indurkhya, Bipin},
title = {Cognitively Inspired Task Design to Improve User Performance on Crowdsourcing Platforms},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557155},
doi = {10.1145/2556288.2557155},
abstract = {Recent research in human computation has focused on improving the quality of work done by crowd workers on crowdsourcing platforms. Multiple approaches have been adopted like filtering crowd workers through qualification tasks, and aggregating responses from multiple crowd workers to obtain consensus. We investigate here how improving the presentation of the task itself by using cognitively inspired features affects the performance of crowd workers. We illustrate this with a case-study for the task of extracting text from scanned images. We generated six task-presentation designs by modifying two parameters - visual saliency of the target fields and working memory requirements - and conducted experiments on Amazon Mechanical Turk (AMT) and with an eye-tracker in the lab setting. Our results identify which task-design parameters (e.g. highlighting target fields) result in improved performance, and which ones do not (e.g. reducing the number of distractors). In conclusion, we claim that the use of cognitively inspired features for task design is a powerful technique for maximizing the performance of crowd workers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3665–3674},
numpages = {10},
keywords = {visual saliency, working memory, cognitive psychology, crowdsourcing, eye tracking, mechanical turk, task design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250979,
author = {Zhou, Michelle},
title = {Session Details: Desktop Search and History},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250979},
doi = {10.1145/3250979},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557356,
author = {Marshall, Catherine C. and Lindley, Si\^{a}n E.},
title = {Searching for Myself: Motivations and Strategies for Self-Search},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557356},
doi = {10.1145/2556288.2557356},
abstract = {We present findings from a qualitative study of self-search, also known as ego or vanity search. In the context of a broader study about personal online content, participants were asked to search for themselves using their own computers and the browsers and queries they would normally adopt. Our analysis highlights five motivations for self-search: as a form of identity management; to discover reactions to and reuse of user-generated media; to re-find personal content; as a form of entertainment; and to reveal lost or forgotten content. Strategies vary according to motivation, and may differ markedly from typical information-seeking, with users looking deep into the results and using image search to identify content about themselves. We argue that two dimensions underpin ways of improving self-search: controllability and expectedness, and discuss what these dimensions imply for design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3675–3684},
numpages = {10},
keywords = {archive, vanity search, ego search, self-search, doppelganger, identity, autosurveillance, aggregation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557014,
author = {Fitchett, Stephen and Cockburn, Andy and Gutwin, Carl},
title = {Finder Highlights: Field Evaluation and Design of an Augmented File Browser},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557014},
doi = {10.1145/2556288.2557014},
abstract = {Navigating to files through a hierarchy is often a slow, laborious, and repetitive task. Recent lab studies showed that file browser interface augmentations, such as Icon Highlights and Search Directed Navigation, have the potential to reduce file retrieval times. However, for this potential to be realised in actual systems, further study is necessary to address two important issues. First, there are important design and implementation challenges in advancing the research prototypes previously evaluated into complete interactive systems that can be used for real work. Second, it is unknown how real users would employ these systems while engaged in actual work; would the potential performance improvements suggested by the earlier lab studies be realised? We therefore describe the design, implementation, and longitudinal field study evaluation of Finder Highlights, a file browser plugin for the OS X 'Finder' that adds support for Icon Highlights and Search Directed Navigation. Study results confirm that the augmentations are effective in reducing real-world file retrieval times, with retrieval times 13% faster when using Finder Highlights compared to the standard tool (10.6 s versus 12.2 s), while also emphasising important differences between lab and field studies. In summary, the paper strongly suggests that large-scale deployment of interface augmentations to file browsers, particularly Icon Highlights, will have a marked effect in improving users' real-world file retrieval.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3685–3694},
numpages = {10},
keywords = {revisitation, file navigation, file retrieval, prediction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557023,
author = {Massey, Charlotte and TenBrook, Sean and Tatum, Chaconne and Whittaker, Steve},
title = {PIM and Personality: What Do Our Personal File Systems Say about Us?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557023},
doi = {10.1145/2556288.2557023},
abstract = {Individual differences are prevalent in personal information management (PIM). There is large variation between individuals in how they structure and retrieve information from personal archives. These differences make it hard to develop general PIM tools. However we know little about the origins of these differences. We present two studies evaluating whether differences arise from personality traits, by exploring whether different personalities structure personal archives differently. The first exploratory study asks participants to identify PIM cues that signal personality traits. While the aim was to identify cues, these cues also proved surprisingly accurate indicators of personality. In a second study, to evaluate these cues, we directly measure relations between structure and traits. We demonstrate that Conscientiousness predicts file organization, particularly PC users' desktops. Neurotic people may also keep more desktop files. One implication is that systems might be customized for different personalities. We also advance personality theory, showing that personal digital artifacts signal personality.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3695–3704},
numpages = {10},
keywords = {file systems, personality, individual differences, personal information management},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557032,
author = {Geymayer, Thomas and Steinberger, Markus and Lex, Alexander and Streit, Marc and Schmalstieg, Dieter},
title = {Show Me the Invisible: Visualizing Hidden Content},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557032},
doi = {10.1145/2556288.2557032},
abstract = {Content on computer screens is often inaccessible to users because it is hidden, e.g., occluded by other windows, outside the viewport, or overlooked. In search tasks, the efficient retrieval of sought content is important. Current software, however, only provides limited support to visualize hidden occurrences and rarely supports search synchronization crossing application boundaries. To remedy this situation, we introduce two novel visualization methods to guide users to hidden content. Our first method generates awareness for occluded or out-of-viewport content using see-through visualization. For content that is either outside the screen's viewport or for data sources not opened at all, our second method shows off-screen indicators and an on-demand smart preview. To reduce the chances of overlooking content, we use visual links, i.e., visible edges, to connect the visible content or the visible representations of the hidden content. We show the validity of our methods in a user study, which demonstrates that our technique enables a faster localization of hidden content compared to traditional search functionality and thereby assists users in information retrieval tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3705–3714},
numpages = {10},
keywords = {hidden content, off-screen content, occluded content, visual linking},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250980,
author = {Guerreiro, Tiago},
title = {Session Details: Lost and Found in Translation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250980},
doi = {10.1145/3250980},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557215,
author = {Hautasaari, Ari MJ and Yamashita, Naomi and Gao, Ge},
title = {"Maybe It Was a Joke": Emotion Detection in Text-Only Communication by Non-Native English Speakers},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557215},
doi = {10.1145/2556288.2557215},
abstract = {Previous studies have shown that people can effectively detect emotions in text-only messages written in their native languages. But is this the same for non-native speakers' In this paper, we conduct an experiment where native English speakers (NS) and Japanese non-native English speakers (NNS) rate the emotional valence in text-only messages written by native English-speaking authors. They also annotate all emotional cues (words, symbols and emoticons) that affected their rating. Accuracy of NS and NNS ratings and annotations are calculated by comparing their average correlations with author ratings and annotations used as a gold standard. Our results conclude that NNS are significantly less accurate at detecting the emotional valence of messages, especially when the messages include highly negative words. Although NNS are as accurate as NS at detecting emotional cues, they are not able to make use of symbols (exclamation marks) and emoticons to detect the emotional valence of text-only messages.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3715–3724},
numpages = {10},
keywords = {text-only communication, emotion, non-native speaker, computer-mediated communication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556985,
author = {Savva, Manolis and Chang, Angel X. and Manning, Christopher D. and Hanrahan, Pat},
title = {TransPhoner: Automated Mnemonic Keyword Generation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556985},
doi = {10.1145/2556288.2556985},
abstract = {We present TransPhoner: a system that generates keywords for a variety of scenarios including vocabulary learning, phonetic transliteration, and creative word plays. We select effective keywords by considering phonetic, orthographic and semantic word similarity, and word concept imageability. We show that keywords provided by TransPhoner improve learner performance in an online vocabulary learning study, with the improvement being more pronounced for harder words. Participants rated TransPhoner keywords as more helpful than a random keyword baseline, and almost as helpful as manually selected keywords. Comments also indicated higher engagement in the learning task, and more desire to continue learning. We demonstrate additional applications to tasks such as pure phonetic transliteration, generation of mnemonics for complex vocabulary, and topic-based transformation of song lyrics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3725–3734},
numpages = {10},
keywords = {mnemonic keywords},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556993,
author = {Robinson, Simon and Pearson, Jennifer S. and Jones, Matt},
title = {AudioCanvas: Internet-Free Interactive Audio Photos},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556993},
doi = {10.1145/2556288.2556993},
abstract = {In this paper we present a novel interaction technique that helps to make textual information more accessible to those with low or no textual literacy skills. AudioCanvas allows cameraphone users to interact directly with their own photos of printed media to receive audio feedback or narration. The use of a remote telephone-based service also allows our design to be used over a standard phone line, removing the need for data connections, which can be problematic in developing regions. We show the value of the technique via user evaluations in both a rural Indian village and a South African township.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3735–3738},
numpages = {4},
keywords = {developing regions, camera phones, qr codes, audio},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556982,
author = {Leiva, Luis A. and Alabau, Vicent},
title = {The Impact of Visual Contextualization on UI Localization},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556982},
doi = {10.1145/2556288.2556982},
abstract = {Translating the text in an interface is a challenging task. Besides the jargon and technical terms, many of the strings are often very short, such as those shown in buttons and pull-down menus. Then, as a result of the lack of visual context in the traditional localization process, an important ambiguity problem arises. We study three approaches to solve this problem: using plain gettext (baseline condition), using gettext plus being able to operate the UI, and translating the UI in-place. We found that translators are substantially faster with plain gettext but commit a significantly higher number of errors in comparison to the other approaches. Unexpectedly, the mixed condition was slower and more error-prone than in-place translation. The latter was found to be comparable to plain gettext in terms of time, although some strings passed unnoticed as the UI was operated. Based on our results, we arrive at a set of recommendations to augment localization tools to improve translator's productivity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3739–3742},
numpages = {4},
keywords = {localization, i18n, internationalization, translation, l10n},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557171,
author = {Xu, Bin and Gao, Ge and Fussell, Susan R. and Cosley, Dan},
title = {Improving Machine Translation by Showing Two Outputs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557171},
doi = {10.1145/2556288.2557171},
abstract = {We propose to improve real-time communication between people who do not share a common language by foregrounding potential problems in machine translation. We developed a prototype chat tool that displays two parallel translations of each chat turn, with the thought that comparing the translations might both highlight problems and provide resources for resolving them. We conducted a user study to investigate how people use and like such an interface compared to a standard one-translation interface. On balance, users preferred two translations to one, using them to both notice differences and infer meaning from uncertain translations, with no increase in workload. This suggests that this interface may help improve cross-lingual communication in practical applications and lays the groundwork for a larger design space around systems that highlight possible errors to support communication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3743–3746},
numpages = {4},
keywords = {multiple translations, machine translation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250981,
author = {Guha, Mona Leigh},
title = {Session Details: Participatory Design},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250981},
doi = {10.1145/3250981},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557244,
author = {Benton, Laura and Vasalou, Asimina and Khaled, Rilla and Johnson, Hilary and Gooch, Daniel},
title = {Diversity for Design: A Framework for Involving Neurodiverse Children in the Technology Design Process},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557244},
doi = {10.1145/2556288.2557244},
abstract = {The neurodiversity movement seeks to positively reframe certain neurological conditions, such as autism spectrum disorders (ASD) and dyslexia, by concentrating on their strengths. In recent years, neurodiverse children have increasingly been involved in the technology design process, but the design approaches adopted have focused mostly on overcoming difficulties of working with these children, leaving their strengths untapped. We present a new participatory design (PD) framework, Diversity for Design (D4D), which provides guidance for technology designers working with neurodiverse children in establishing PD methods that capitalize on children's strengths and also support potential difficulties. We present two case studies of use of the D4D framework, involving children with ASD and dyslexia, showing how it informed the development and refinement of PD methods tailored to these populations. In addition, we show how to apply the D4D framework to other neurodiverse populations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3747–3756},
numpages = {10},
keywords = {autism, dyslexia, children, neurodiversity, participatory design},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557396,
author = {Robinson, Charlotte L. and Mancini, Clara and van der Linden, Janet and Guest, Claire and Harris, Robert},
title = {Canine-Centered Interface Design: Supporting the Work of Diabetes Alert Dogs},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557396},
doi = {10.1145/2556288.2557396},
abstract = {Many people with Diabetes live with the continuous threat of hypoglycemic attacks and the danger of going into coma. Diabetes Alert Dogs are trained to detect the onset of an attack before the condition of the human handler they are paired with deteriorates, giving them time to take action. We investigated requirements for designing an alarm system allowing dogs to remotely call for help when their human falls unconscious before being able to react to an alert. Through a multispecies ethnographic approach we focus on the requirements for a physical canine user interface, involving dogs, their handlers and specialist dog trainers in the design process. We discuss tensions between the requirements for canine and the human users, argue the need for increased sensitivity towards the needs of individual dogs that goes beyond breed specific physical characteristics, and reflect on how we can move from designing for dogs to designing with dogs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3757–3766},
numpages = {10},
keywords = {animal-computer interaction, multispecies ethnography, user-centered design, diabetes alert dog, human-animal interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557115,
author = {W\"{a}rnest\r{a}l, Pontus and Svedberg, Petra and Nygren, Jens},
title = {Co-Constructing Child Personas for Health-Promoting Services with Vulnerable Children},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557115},
doi = {10.1145/2556288.2557115},
abstract = {The availability of health-promoting resources for young children diagnosed with cancer who are transitioning from intensive care to everyday life is limited. In the context of designing digital peer support services for children who are considered vulnerable due to clinical and age-related aspects, there are several challenges that put critical requirements on a user-centered design process. This paper reports on a new method for co-constructing child-personas that are tailored for developing health-promoting services where empirical data is restricted due to practical and ethical reasons. In particular, we are proposing to focus children design workshop sessions on salutogenesis, and complement this with a pathogenic perspective by interviewing healthcare professionals and parents. We also introduce the use of proxy personas, and redemption scenarios in the form of comicboards, both collaboratively constructed by children and designers through storytelling. By applying four progressive steps of data collection and analysis we arrive at authentic child-personas that can be used to design and develop health-promoting services for children in vulnerable life stages.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3767–3776},
numpages = {10},
keywords = {user experience, participatory design, interaction design, digital peer support, personas, vulnerable children, social interaction, methodology},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557301,
author = {Kusunoki, Diana S. and Sarcevic, Aleksandra and Weibel, Nadir and Marsic, Ivan and Zhang, Zhan and Tuveson, Genevieve and Burd, Randall S.},
title = {Balancing Design Tensions: Iterative Display Design to Support Ad Hoc and Multidisciplinary Medical Teamwork},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557301},
doi = {10.1145/2556288.2557301},
abstract = {In this paper, we describe how we developed an information display prototype for trauma resuscitation teams based on design ideas and feedback from clinicians. Our approach is grounded in participatory design, emphasizing the importance of gaining long-term commitment from clinicians in system development. Through a series of participatory design workshops, heuristic evaluation, and simulated resuscitation sessions, we identified the main information features to include on our display. Our results focus on how we balanced the design tensions that emerged when addressing the ad hoc, hierarchical, and multidisciplinary nature of trauma teamwork. We discuss the implications of balancing role-based differences for each information feature, as well as two major design tensions: process-based vs. state-based designs and role-based vs. team-based displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3777–3786},
numpages = {10},
keywords = {information displays, teamwork, trauma resuscitation, healthcare, participatory design, design tensions},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250982,
author = {Baillie, Lynne},
title = {Session Details: Brain Computer Interfaces},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250982},
doi = {10.1145/3250982},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557015,
author = {Vi, Chi Thanh and Jamil, Izdihar and Coyle, David and Subramanian, Sriram},
title = {Error Related Negativity in Observing Interactive Tasks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557015},
doi = {10.1145/2556288.2557015},
abstract = {Error Related Negativity is triggered when a user either makes a mistake or the application behaves differently from their expectation. It can also appear while observing another user making a mistake. This paper investigates ERN in collaborative settings where observing another user (the executer) perform a task is typical and then explores its applicability to HCI. We first show that ERN can be detected on signals captured by commodity EEG headsets like an Emotiv headset when observing another person perform a typical multiple-choice reaction time task. We then investigate the anticipation effects by detecting ERN in the time interval when an executer is reaching towards an answer. We show that we can detect this signal with both a clinical EEG device and with an Emotiv headset. Our results show that online single trial detection is possible using both headsets during tasks that are typical of collaborative interactive applications. However there is a trade-off between the detection speed and the quality/prices of the headsets. Based on the results, we discuss and present several HCI scenarios for use of ERN in observing tasks and collaborative settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3787–3796},
numpages = {10},
keywords = {brain computer interface, tabletop, electroencephalography, error related negativity, eeg},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557230,
author = {Afergan, Daniel and Peck, Evan M. and Solovey, Erin T. and Jenkins, Andrew and Hincks, Samuel W. and Brown, Eli T. and Chang, Remco and Jacob, Robert J.K.},
title = {Dynamic Difficulty Using Brain Metrics of Workload},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557230},
doi = {10.1145/2556288.2557230},
abstract = {Dynamic difficulty adjustments can be used in human-computer systems in order to improve user engagement and performance. In this paper, we use functional near-infrared spectroscopy (fNIRS) to obtain passive brain sensing data and detect extended periods of boredom or overload. From these physiological signals, we can adapt a simulation in order to optimize workload in real-time, which allows the system to better fit the task to the user from moment to moment. To demonstrate this idea, we ran a laboratory study in which participants performed path planning for multiple unmanned aerial vehicles (UAVs) in a simulation. Based on their state, we varied the difficulty of the task by adding or removing UAVs and found that we were able to decrease error by 35% over a baseline condition. Our results show that we can use fNIRS brain sensing to detect task difficulty in real-time and construct an interface that improves user performance through dynamic difficulty adjustment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3797–3806},
numpages = {10},
keywords = {fnirs, dynamic difficulty, bci, passive brain-computer interface, workload, uav, near-infrared spectroscopy},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556974,
author = {Pike, Matthew F. and Maior, Horia A. and Porcheron, Martin and Sharples, Sarah C. and Wilson, Max L.},
title = {Measuring the Effect of Think Aloud Protocols on Workload Using FNIRS},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556974},
doi = {10.1145/2556288.2556974},
abstract = {The Think Aloud Protocol (TAP) is a verbalisation technique widely employed in HCI user studies to give insight into user experience, yet little work has explored the impact that TAPs have on participants during user studies. This paper utilises a brain sensing technique, fNIRS, to observe the effect that TAPs have on participants. Functional Near-Infrared Spectroscopy (fNIRS) is a brain sensing technology that offers the potential to provide continuous, detailed insight into brain activity, enabling an objective view of cognitive processes during complex tasks. Participants were asked to perform a mathematical task under 4 conditions: nonsense verbalisations, passive concurrent think aloud protocol, invasive concurrent think aloud protocol, and a baseline of silence. Subjective ratings and performance measures were collected during the study. Our results provide a novel view into the effect that different forms of verbalisation have on workload during tasks. Further, the results provide a means for estimating the effect of spoken artefacts when measuring workload, which is another step towards our goal of proactively involving fNIRS analysis in ecologically valid user studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3807–3816},
numpages = {10},
keywords = {human cognition, functional near-infrared spectroscopy, fnirs, think aloud protocol, bci, hci},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557076,
author = {Lee, Yi-Chieh and Lin, Wen-Chieh and King, Jung-Tai and Ko, Li-Wei and Huang, Yu-Ting and Cherng, Fu-Yin},
title = {An EEG-Based Approach for Evaluating Audio Notifications under Ambient Sounds},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557076},
doi = {10.1145/2556288.2557076},
abstract = {Audio notifications are an important means of prompting users of electronic products. Although useful in most environments, audio notifications are ineffective in certain situations, especially against particular auditory backgrounds or when the user is distracted. Several studies have used behavioral performance to evaluate audio notifications, but these studies failed to achieve consistent results due to factors including user subjectivity and environmental differences; thus, a new method and more objective indicators are necessary. In this study, we propose an approach based on electroencephalography (EEG) to evaluate audio notifications by measuring users' auditory perceptual responses (mismatch negativity) and attention shifting (P3a). We demonstrate our approach by applying it to the usability testing of audio notifications in realistic scenarios, such as users performing a major task amid ambient noises. Our results open a new perspective for evaluating the design of the audio notifications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3817–3826},
numpages = {10},
keywords = {mismatch negativity, audio notifications, human cognition, usability testing, electroencephalography (eeg)},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250983,
author = {Olwal, Alex},
title = {Session Details: 3D Printing and Fabrication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250983},
doi = {10.1145/3250983},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557005,
author = {Mueller, Stefanie and Mohr, Tobias and Guenther, Kerstin and Frohnhofen, Johannes and Baudisch, Patrick},
title = {FaBrickation: Fast 3D Printing of Functional Objects by Integrating Construction Kit Building Blocks},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557005},
doi = {10.1145/2556288.2557005},
abstract = {We present a new approach to rapid prototyping of functional objects, such as the body of a head-mounted display. The key idea is to save 3D printing time by automatically substituting sub-volumes with standard building blocks'in our case Lego bricks. When making the body for a head-mounted display, for example, getting the optical path right is paramount. Users thus mark the lens mounts as "high-resolution" to indicate that these should later be 3D printed. faBrickator then 3D prints these parts. It also generates instructions that show users how to create everything else from Lego bricks. If users iterate on the design later, faBrickator offers even greater benefit as it allows re-printing only the elements that changed. We validated our system at the example of three 3D models of functional objects. On average, our system fabricates objects 2.44 times faster than traditional 3D printing while requiring only 14 minutes of manual assembly.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3827–3834},
numpages = {8},
keywords = {rapid prototyping, physical prototyping, building blocks, 3d printing, design iteration},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557144,
author = {Khot, Rohit Ashok and Hjorth, Larissa and Mueller, Florian 'Floyd'},
title = {Understanding Physical Activity through 3D Printed Material Artifacts},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557144},
abstract = {In this paper, we advocate a novel approach of representing physical activity in the form of material artifacts. By designing such material representations, we aim to understand what these artifacts might offer in terms of reflecting upon physical activity. For example, what types of affect do material artifacts, representing ones' physical activity create for the user' In order to advance this understanding, we designed a system called SweatAtoms that transforms the physical activity data based on heart rate into 3D printed material artifacts. We conducted an 'in the wild study' by deploying our system in six households where participants were experiencing five different material representations of their physical activity for a period of two weeks each. We found that the material artifacts made participants more conscious about their involvement in physical activity and illustrated different levels of engagement with the artifacts. Along with reporting the gained insights from the deployments, we offer reflections on designing material representations for physical activity. We hope that our work will inspire designers to consider new possibilities afforded by digital fabrication to support user's experience with physical activity by utilizing interactive technologies at our disposal.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3835–3844},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557310,
author = {Swaminathan, Saiganesh and Shi, Conglei and Jansen, Yvonne and Dragicevic, Pierre and Oehlberg, Lora A. and Fekete, Jean-Daniel},
title = {Supporting the Design and Fabrication of Physical Visualizations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557310},
doi = {10.1145/2556288.2557310},
abstract = {Physical visualizations come in increasingly diverse forms, and are used in domains including art and entertainment, business analytics, and scientific research. However, creating physical visualizations requires laborious craftsmanship and demands expertise in both data visualization and digital fabrication. We present three case studies that illustrate limitations of current visualization fabrication workflows. We then present MakerVis, a prototype tool that integrates the entire process of creating physical visualizations, from data filtering to physical fabrication. Design sessions with three end users demonstrate how tools such as MakerVis can dramatically lower the barriers to producing physical visualizations. Observations and interviews from these sessions highlighted future research areas, including customization support, using material properties to represent data variables, and allowing the reuse of physical data objects in new visualizations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3845–3854},
numpages = {10},
keywords = {physical visualization, infovis, digital fabrication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557090,
author = {Weichel, Christian and Lau, Manfred and Kim, David and Villar, Nicolas and Gellersen, Hans W.},
title = {MixFab: A Mixed-Reality Environment for Personal Fabrication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557090},
doi = {10.1145/2556288.2557090},
abstract = {Personal fabrication machines, such as 3D printers and laser cutters, are becoming increasingly ubiquitous. However, designing objects for fabrication still requires 3D modeling skills, thereby rendering such technologies inaccessible to a wide user-group. In this paper, we introduce MixFab, a mixed-reality environment for personal fabrication that lowers the barrier for users to engage in personal fabrication. Users design objects in an immersive augmented reality environment, interact with virtual objects in a direct gestural manner and can introduce existing physical objects effortlessly into their designs. We describe the design and implementation of MixFab, a user-defined gesture study that informed this design, show artifacts designed with the system and describe a user study evaluating the system's prototype.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3855–3864},
numpages = {10},
keywords = {direct manipulation, 3d printing, mixed-reality, personal fabrication, 3d modeling},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250984,
author = {Elmqvist, Niklas},
title = {Session Details: Modeling Users and Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250984},
doi = {10.1145/3250984},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557093,
author = {Bailly, Gilles and Oulasvirta, Antti and Brumby, Duncan P. and Howes, Andrew},
title = {Model of Visual Search and Selection Time in Linear Menus},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557093},
doi = {10.1145/2556288.2557093},
abstract = {This paper presents a novel mathematical model for visual search and selection time in linear menus. Assuming two visual search strategies, serial and directed, and a pointing sub-task, it captures the change of performance with five fac- tors: 1) menu length, 2) menu organization, 3) target position, 4) absence/presence of target, and 5) practice. The novel aspect is that the model is expressed as probability density distribution of gaze, which allows for deriving total selection time. We present novel data that replicates and extends the Nielsen menu selection paradigm and uses eye-tracking and mouse tracking to confirm model predictions. The same parametrization yielded a high fit to both menu selection time and gaze distributions. The model has the potential to improve menu designs by helping designers identify more effective solutions without conducting empirical studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3865–3874},
numpages = {10},
keywords = {visual search, linear menus, mathematical predictive models, eye-tracking, user performance},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557324,
author = {Kieras, David E. and Hornof, Anthony J.},
title = {Towards Accurate and Practical Predictive Models of Active-Vision-Based Visual Search},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557324},
doi = {10.1145/2556288.2557324},
abstract = {Being able to predict the performance of interface designs using models of human cognition and performance is a long-standing goal of HCI research. This paper presents recent advances in cognitive modeling which permit increasingly realistic and accurate predictions for visual human-computer interaction tasks such as icon search by incorporating an "active vision" approach which emphasizes eye movements to visual features based on the availability of features in relationship to the point of gaze. A high fidelity model of a classic visual search task demonstrates the value of incorporating visual acuity functions into models of visual performance. The features captured by the high-fidelity model are then used to formulate a model simple enough for practical use, which is then implemented in an easy-to-use GLEAN modeling tool. Easy-to-use predictive models for complex visual search are thus feasible and should be further developed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3875–3884},
numpages = {10},
keywords = {visual acuity, cognitive architecture, human performance modeling, visual search, goms},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557351,
author = {Zhang, Yunfeng and Hornof, Anthony J.},
title = {Understanding Multitasking through Parallelized Strategy Exploration and Individualized Cognitive Modeling},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557351},
doi = {10.1145/2556288.2557351},
abstract = {Human multitasking often involves complex task interactions and subtle tradeoffs which might be best understood through detailed computational cognitive modeling, yet traditional cognitive modeling approaches may not explore a sufficient range of task strategies to reveal the true complexity of multitasking behavior. This study proposes a systematic approach for exploring a large number of strategies using a computer-cluster-based parallelized modeling system. The paper demonstrates the efficacy of the approach for investigating and revealing the effects of different microstrategies on human performance, both within and across individuals, for a time-pressured multimodal dual task. The modeling results suggest that multitasking performance is not simply a matter of interleaving cognitive and sensorimotor processing but is instead heavily influenced by the selection of subtask microstrategies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3885–3894},
numpages = {10},
keywords = {multitasking, task strategies., high performance computing, cognitive modeling, multimodal, model comparison},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557064,
author = {Brumby, Duncan P. and Cox, Anna L. and Chung, Jacqueline and Fernandes, Byron},
title = {How Does Knowing What You Are Looking for Change Visual Search Behavior?},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557064},
doi = {10.1145/2556288.2557064},
abstract = {When searching a display, users sometimes know what the target is but sometimes do not. It has generally been assumed that for this latter case people must engage in a deeper semantic evaluation of items during the search process. This idea is central to Information Foraging theory. But do people actually spend longer assessing items when engaged in a semantically demanding search task' We investigate this by having participants locate target items in 16-item menus. Participants were either told exactly what to look for (known-item search) or they were told the category that the target belonged to (semantic search). Participants were faster and more accurate at known-item searches. Eye-movement data show that this was because participants were more likely to skip over items when performing known-item searches. Contrary to expectation, we found limited empirical evidence to support the idea that deeper semantic evaluations of items lead to longer gaze durations (this occurred only when items were arranged very close together). This finding is important because it reveals how people adopt different eye gaze strategies depending on the kind of search activity they are engaged in.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3895–3898},
numpages = {4},
keywords = {information foraging, visual search, eye-tracking, menus},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556999,
author = {Oulasvirta, Antti},
title = {Automated Nonlinear Regression Modeling for HCI},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556999},
doi = {10.1145/2556288.2556999},
abstract = {Predictive models in HCI, such as models of user performance, are often expressed as multivariate nonlinear regressions. This approach has been preferred, because it is compact and allows scrutiny. However, existing modeling tools in HCI, along with the common statistical packages, are limited to predefined nonlinear models or support linear models only. To assist researchers in the task of identifying novel nonlinear models, we propose a stochastic local search method that constructs equations iteratively. Instead of predefining a model equation, the researcher defines constraints that guide the search process. Comparison of outputs to published baselines in HCI shows improvements in model fit in seven out of 11 cases. We present a few ways in which the method can help HCI researchers explore modeling problems. We conclude that the approach is particularly suitable for complex datasets that have many predictor variables.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3899–3902},
numpages = {4},
keywords = {predictive modeling in human--computer interaction, multivariate nonlinear regression models, model selection},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250985,
author = {McGrenere, Joanna},
title = {Session Details: Engaging Older Adults through Technology},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250985},
doi = {10.1145/3250985},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557133,
author = {Hope, Alexis and Schwaba, Ted and Piper, Anne Marie},
title = {Understanding Digital and Material Social Communications for Older Adults},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557133},
doi = {10.1145/2556288.2557133},
abstract = {Online technologies are promising for helping older adults maintain social connectedness, particularly with younger people, yet many older adults resist or participate minimally in the mainstream technologies used by younger members of their social network. We present results from an interview study involving 22 older adults (age 71-92) to understand communication preferences and values related to social media. Seniors articulate many concerns with online social media, including the time required for legitimate participation, the loss of deeper communication, content irrelevance, and privacy. Additionally, older adults engage in social practices that could be supported by online social technologies, but they rarely use such tools. The theme of material social communications emerges from our data, and we examine this in context of online social media. We conclude with design considerations for the development of social media for older adults, and as part of this we describe the notion of bridging technologies as a framework for intergenerational communication design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3903–3912},
numpages = {10},
keywords = {materiality., older adults, social media, social network sites},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557184,
author = {Rogers, Yvonne and Paay, Jeni and Brereton, Margot and Vaisutis, Kate L. and Marsden, Gary and Vetere, Frank},
title = {Never Too Old: Engaging Retired People Inventing the Future with MaKey MaKey},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557184},
doi = {10.1145/2556288.2557184},
abstract = {Within HCI, aging is often viewed in terms of designing assistive technologies to improve the lives of older people, such as those who are suffering from frailty or memory loss. Our research adopts a very different approach, reframing the relationship in terms of wisdom, creativity and invention. We ran a series of workshops where groups of retirees, aged between early 60s and late 80s, used the MaKey MaKey inventor's toolkit. We asked them to think about inventing the future and suggest ideas for new technologies. Our findings showed that they not only rose to the challenge but also mastered the technology, collaborated intensely together while using it and freely and at length discussed their own, their family's and others' relationship with technology. We discuss the value of empowering people in this way and consider what else could be invented to enable more people to be involved in the design and use of creative technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3913–3922},
numpages = {10},
keywords = {invention, future technology, retired people, makey makey, creativity, aging, toolkits},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556992,
author = {Norval, Chris and Arnott, John L. and Hanson, Vicki L.},
title = {What's on Your Mind? Investigating Recommendations for Inclusive Social Networking and Older Adults},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556992},
doi = {10.1145/2556288.2556992},
abstract = {Social networking sites (SNSs) are becoming increasingly popular as a method for social interaction. While research has reported benefits associated with components of SNS usage, a digital divide has emerged between younger and older users. SNSs can be useful for communicating with family members and helping one feel digitally included; however, there are a wide range of reasons why many older adults choose not to use this kind of technology. We present a series of user studies investigating the barriers and challenges that SNSs can present to older users. These user studies led to the derivation of user recommendations to mitigate these barriers. The recommendations were then evaluated within a comparative evaluation which involved 25 older adults completing tasks on two interface versions of a simulation SNS. We present the recommendations and the methods of their creation and evaluation. Implications for developers of SNSs are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3923–3932},
numpages = {10},
keywords = {inclusive design, recommendations, comparative evaluation, older adults, social networking sites},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557248,
author = {Sun, Yuling and Ding, Xianghua and Lindtner, Silvia and Lu, Tun and Gu, Ning},
title = {Being Senior and ICT: A Study of Seniors Using ICT in China},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557248},
doi = {10.1145/2556288.2557248},
abstract = {System design for seniors often focuses on the decline of their biological capabilities and social connectedness. This approach has been challenged as too simplistic to capture what it really means to be senior. This paper presents a qualitative study of 17 seniors in urban China (age ranging from 50s to 70s), who have adopted and incorporated ICT into their daily lives. Findings from this study show that the ways in which seniors attend to ICT are not simply shaped by changes in health or other wellbeing, but also by their life attitudes, value systems, relationships to younger generations as well as historical specifics during their coming of age. This paper contributes by showing that 1) what it means to be senior is shaped from within a whole social ecology of past and current experiences, values and interactions; 2) senior identities are not fixed, but continuously negotiated, articulated and enacted through ICT; 3) social interaction and access of technologies are highly intertwined.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3933–3942},
numpages = {10},
keywords = {companionship, elders, ict, seniors, qualitative study, values, cross-generational communication},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250986,
author = {Thomas, John},
title = {Session Details: Computer Mediated Intimacy and Romance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250986},
doi = {10.1145/3250986},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557127,
author = {Bardzell, Jeffrey and Bardzell, Shaowen and Zhang, Guo and Pace, Tyler},
title = {The Lonely Raccoon at the Ball: Designing for Intimacy, Sociability, and Selfhood},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557127},
doi = {10.1145/2556288.2557127},
abstract = {Designing for sociable systems requires, among other abilities, a sensitivity to the meanings, structures, and nuances of technology-mediated experiences that are simultaneously felt by users to be intimate and also social. Such a sensitivity is not easily acquired, and design researchers have recommended the use of social theories to guide designers' readings of technology-mediated social experiences. We use philosopher Michel Foucault's theory of identity (and social power, discourse, sexuality, creativity, and style) known as "the care of the self," as a scaffold with which to produce a sensitive interpretation of the intimacy (and expert social creative) practices of adult users of the virtual world Second Life (SL). This reading sheds light on several skilled and creative intimacy practices in SL. It also offers a philosophically grounded hermeneutic strategy for designers interested in analyzing intimate experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3943–3952},
numpages = {10},
keywords = {amateurs, intimacy, creativity, maker culture, design, making, hci, sexuality, identity, sociability, user experience},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557177,
author = {Scissors, Lauren E. and Roloff, Michael E and Gergle, Darren},
title = {Room for Interpretation: The Role of Self-Esteem and CMC in Romantic Couple Conflict},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557177},
doi = {10.1145/2556288.2557177},
abstract = {This work explores the role of communication technologies during romantic couple conflict, and the impact that self-esteem has on behavior, preferences for communication channels, and attitudes about mediated communication during conflict. Results revealed that lower levels of self-esteem and communicating via text messaging (vs. face-to-face) were associated with increased distancing and perceived partner distancing behaviors. Lower levels of self-esteem and using mediated communication were also associated with a greater likelihood of thinking that a conflict had a negative impact on the relationship. Yet, there was no evidence to suggest that individuals with lower levels of self-esteem exhibited more negative behaviors and perceptions in text-based communication than in FtF communication. In addition, lower levels of self-esteem were associated with increased use of and preferences for text-based mediated communication over FtF communication during conflict. Overall, this study suggests that both self-esteem and communication channel impact the nature of romantic couple conflict.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3953–3962},
numpages = {10},
keywords = {cscw, romantic couples, relationships, self-esteem, computer-mediated communication (cmc), conflict},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557343,
author = {Mullenbach, Joe and Shultz, Craig and Colgate, J. Edward and Piper, Anne Marie},
title = {Exploring Affective Communication through Variable-Friction Surface Haptics},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557343},
doi = {10.1145/2556288.2557343},
abstract = {This paper explores the use of variable friction surface haptics enabled by the TPad Tablet to support affective communication between pairs of users. We introduce three haptic applications for the TPad Tablet (text messaging, image sharing, and virtual touch) and evaluate the applications with 24 users, including intimate couples and strangers. Participants used haptics to communicate literal texture, denote action within a scene, convey emotional information, highlight content, express and engage in physical playfulness, and to provide one's partner with an experience or sensation. We conclude that users readily associate haptics with emotional expression and that the intimacy of touch in the contexts we study is best suited for communications with close social partners.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3963–3972},
numpages = {10},
keywords = {tablet, touchscreen, surface haptics, communication, variable friction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557166,
author = {Park, Joohee and Park, Young-Woo and Nam, Tek-Jin},
title = {Wrigglo: Shape-Changing Peripheral for Interpersonal Mobile Communication},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557166},
doi = {10.1145/2556288.2557166},
abstract = {We introduce Wrigglo, a shape-changing smart phone peripheral that allows pairs of users to share wriggling movements with one another. Attached to a smart phone, Wrigglo captures the sender's motions and activates the receiver's Wrigglo which repeats the motion simultaneously. The result of our in-lab use observation with twelve couples showed that Wrigglo supported emotional and functional roles of body gestures and postures, creating vocabularies related to the motion of specific body parts and, to some extent, reflected the connected user's presence through the device's movement. Through its peripheral anthropomorphization, Wrigglo can deliver new forms of telepresence by embodied posturing and gesturing in mobile communication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3973–3976},
numpages = {4},
keywords = {shape-changing, remote communication, mobile peripheral},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250987,
author = {Olivier, Patrick},
title = {Session Details: Network of Care},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250987},
doi = {10.1145/3250987},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557035,
author = {Siriaraya, Panote and Ang, Chee Siang},
title = {Recreating Living Experiences from Past Memories through Virtual Worlds for People with Dementia},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557035},
doi = {10.1145/2556288.2557035},
abstract = {This paper describes a study aimed to understand the use of 3D virtual world (VW) technology to support life engagement for people with dementia in long-term care. Three versions of VW prototypes (reminiscence room, virtual tour and gardening) utilising gestured-base interaction were developed iteratively. These prototypes were tested with older residents (80+) with dementia in care homes and their caregivers. Data collection was based on observations of how the residents and care staff interacted collaboratively with the VW. We discussed in depth the use of VWs in stimulating past memories and how this technology could help enhance their sense of self through various means. We also highlighted key approaches in designing VWs to sustain attention, create ludic experiences and facilitate interaction for older people with dementia.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3977–3986},
numpages = {10},
keywords = {3d virtual worlds, gesture-based interaction, dementia, older people, care home},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557307,
author = {Wan, Lin and M\"{u}ller, Claudia and Wulf, Volker and Randall, David William},
title = {Addressing the Subtleties in Dementia Care: Pre-Study &amp; Evaluation of a GPS Monitoring System},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557307},
doi = {10.1145/2556288.2557307},
abstract = {In this work we present a user-centered development process for a GPS-based monitoring system to be used in dementia care. Our research covers a full design process including a qualitative-empirical pre-study, the prototyping process and the investigation of long-term appropriation processes of the stable prototypes in three different practice environments. Specifically, we deal with the problem of 'wandering' by persons suffering from late-phase dementia. Although GPS tracking is not a novel technological objective, the usage of those systems in dementia care remains very low. The paper therefore takes a socio-technical stance on development and appropriation of GPS technology in dementia care and assesses the practical and ideological issues surrounding care to understand why. We additionally provide design research in two different settings, familial and institutional care, and report on the design of a GPS-based tracking system reflecting these considerations. What comes to the fore is the need for ICT to reflect complex organizational, ideological and practical issues that form part of a moral universe where sensitivity is crucial.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3987–3996},
numpages = {10},
keywords = {gps monitoring system, autonomy, privacy, evaluation, dementia},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557344,
author = {Zhou, Xiaomu and Sun, Si and Yang, Jiang},
title = {Sweet Home: Understanding Diabetes Management via a Chinese Online Community},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557344},
doi = {10.1145/2556288.2557344},
abstract = {China has overtaken India and the U.S. as host to the largest diabetic population in the world. Many problems exist in the Chinese healthcare system and very small number of diabetes patients receives treatment. Our paper reports on a case study through the lens of an online diabetes patient community, Sweet Home. We conducted participant observations, text analysis, and interviews, to understand the health management of patients at Sweet Home. Our findings reveal that patients' understanding of diabetes, their choice of treatments, their routine management, and their interactions with others (in the physical world) and among themselves (in the online world) are influenced by many factors: belief in traditional Chinese versus western medicine, cultural and social norms regarding social eating and drinking, conflicts over self-images, and responses to comments and pressures of coworkers. That is, social context may significantly affect patients' behaviors and each individual patient's actions may also help reshape the social context. We draw out implications for how our society as a whole may respond to these issues, from the perspective of public health, education, and information technology design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3997–4006},
numpages = {10},
keywords = {online community, chinese table culture, chinese medicine, social eating, diabetes, chronic disease management},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250988,
author = {Dixon, Morgan},
title = {Session Details: Tutorials},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250988},
doi = {10.1145/3250988},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557142,
author = {Lafreniere, Ben and Grossman, Tovi and Matejka, Justin and Fitzmaurice, George},
title = {Investigating the Feasibility of Extracting Tool Demonstrations from In-Situ Video Content},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557142},
doi = {10.1145/2556288.2557142},
abstract = {Short video demonstrations are effective resources for helping users to learn tools in feature-rich software. However manually creating demonstrations for the hundreds (or thousands) of individual features in these programs would be impractical. In this paper, we investigate the potential for identifying good tool demonstrations from within screen recordings of users performing real-world tasks. Using an instrumented image-editing application, we collected workflow video content and log data from actual end users. We then developed a heuristic for identifying demonstration clips, and had the quality of a sample set of clips evaluated by both domain experts and end users. This multi-step approach allowed us to characterize the quality of 'naturally occurring' tool demonstrations, and to derive a list of good and bad features of these videos. Finally, we conducted an initial investigation into using machine learning techniques to distinguish between good and bad demonstrations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4007–4016},
numpages = {10},
keywords = {learning, help, feature-rich software, toolclips, in-situ usage data, video tooltips},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556986,
author = {Kim, Juho and Nguyen, Phu Tran and Weir, Sarah and Guo, Philip J. and Miller, Robert C. and Gajos, Krzysztof Z.},
title = {Crowdsourcing Step-by-Step Information Extraction to Enhance Existing How-to Videos},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556986},
doi = {10.1145/2556288.2556986},
abstract = {Millions of learners today use how-to videos to master new skills in a variety of domains. But browsing such videos is often tedious and inefficient because video player interfaces are not optimized for the unique step-by-step structure of such videos. This research aims to improve the learning experience of existing how-to videos with step-by-step annotations.We first performed a formative study to verify that annotations are actually useful to learners. We created ToolScape, an interactive video player that displays step descriptions and intermediate result thumbnails in the video timeline. Learners in our study performed better and gained more self-efficacy using ToolScape versus a traditional video player.To add the needed step annotations to existing how-to videos at scale, we introduce a novel crowdsourcing workflow. It extracts step-by-step structure from an existing video, including step times, descriptions, and before and after images. We introduce the Find-Verify-Expand design pattern for temporal and visual annotation, which applies clustering, text processing, and visual analysis algorithms to merge crowd output. The workflow does not rely on domain-specific customization, works on top of existing videos, and recruits untrained crowd workers. We evaluated the workflow with Mechanical Turk, using 75 cooking, makeup, and Photoshop videos on YouTube. Results show that our workflow can extract steps with a quality comparable to that of trained annotators across all three domains with 77% precision and 81% recall.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4017–4026},
numpages = {10},
keywords = {crowdsourcing, video annotation., how-to videos},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557407,
author = {Wang, Cheng-Yao and Chu, Wei-Chen and Chen, Hou-Ren and Hsu, Chun-Yen and Chen, Mike Y.},
title = {EverTutor: Automatically Creating Interactive Guided Tutorials on Smartphones by User Demonstration},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557407},
doi = {10.1145/2556288.2557407},
abstract = {We present EverTutor, a system that automatically generates interactive tutorials on smartphone from user demonstration. For tutorial authors, it simplifies the tutorial creation. For tutorial users, it provides contextual step-by-step guidance and avoids the frequent context switching between tutorials and users' primary tasks. In order to generate the tutorials automatically, EverTutor records low-level touch events to detect gestures and identify on-screen targets. When a tutorial is browsed, the system uses vision-based techniques to locate the target regions and overlays the corresponding input prompt contextually. It also identifies the correctness of users' interaction to guide the users step by step. We conducted a 6-person user study for creating tutorials and a 12-person user study for browsing tutorials, and we compared EverTutor's interactive tutorials to static and video ones. Study results show that creating tutorials by EverTutor is simpler and faster than producing static and video tutorials. Also, when using the tutorials, the task completion time for interactive tutorials were 3-6 times faster than static and video tutorials regardless of age group. In terms of user preference, 83% of the users chose interactive type as the preferred tutorial type and rated it easiest to follow and easiest to understand.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4027–4036},
numpages = {10},
keywords = {touchscreen gesture, contextual help, tutorials, smartphone},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557118,
author = {Bunt, Andrea and Dubois, Patrick and Lafreniere, Ben and Terry, Michael A. and Cormack, David T.},
title = {TaggedComments: Promoting and Integrating User Comments in Online Application Tutorials},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557118},
doi = {10.1145/2556288.2557118},
abstract = {User comments posted to popular online tutorials constitute a rich additional source of information for readers, yet current designs for displaying user comments on tutorial webpages do little to support their use. Instead, comments are separated from the tutorial content they reference and tend to be ordered according to post date. We propose and evaluate the TaggedComments system, a new approach to displaying comments that users post to online tutorials. Using tags supplied by commenters, TaggedComments seeks to enhance the role of user comments by 1) improving their visibility, 2) allowing users to personalize their use of the comments according to their particular information needs, and 3) providing direct access to potentially helpful comments from the tutorial content. A laboratory evaluation with 16 participants shows that, in comparison to the standard comment layout, TaggedComments significantly improves users' subjective impressions of comment utility when interacting with Photoshop tutorials.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4037–4046},
numpages = {10},
keywords = {web-based tutorials, feature-rich software, tagging},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250989,
author = {Kirk, David},
title = {Session Details: Driving Interfaces and Evaluations},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250989},
doi = {10.1145/3250989},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557321,
author = {Hong, Jin-Hyuk and Margines, Ben and Dey, Anind K.},
title = {A Smartphone-Based Sensing Platform to Model Aggressive Driving Behaviors},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557321},
doi = {10.1145/2556288.2557321},
abstract = {Driving aggressively increases the risk of accidents. Assessing a person's driving style is a useful way to guide aggressive drivers toward having safer driving behaviors. A number of studies have investigated driving style, but they often rely on the use of self-reports or simulators, which are not suitable for the real-time, continuous, automated assessment and feedback on the road. In order to understand and model aggressive driving style, we construct an in-vehicle sensing platform that uses a smartphone instead of using heavyweight, expensive systems. Utilizing additional cheap sensors, our sensing platform can collect useful information about vehicle movement, maneuvering and steering wheel movement. We use this data and apply machine learning to build a driver model that evaluates drivers' driving styles based on a number of driving-related features. From a naturalistic data collection from 22 drivers for 3 weeks, we analyzed the characteristics of drivers who have an aggressive driving style. Our model classified those drivers with an accuracy of 90.5% (violation-class) and 81% (questionnaire-class). We describe how, in future work, our model can be used to provide real-time feedback to drivers using only their current smartphone.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4047–4056},
numpages = {10},
keywords = {driving assessment, in-vehicle sensing platform, smartphone},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557068,
author = {Solovey, Erin T. and Zec, Marin and Garcia Perez, Enrique Abdon and Reimer, Bryan and Mehler, Bruce},
title = {Classifying Driver Workload Using Physiological and Driving Performance Data: Two Field Studies},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557068},
doi = {10.1145/2556288.2557068},
abstract = {Understanding the driver's cognitive load is important for evaluating in-vehicle user interfaces. This paper describes experiments to assess machine learning classification algorithms on their ability to automatically identify elevated cognitive workload levels in drivers, leading towards the development of robust tools for automobile user interface evaluation. We look at using both driver performance as well as physiological data. These measures can be collected in real-time and do not interfere with the primary task of driving the vehicle. We report classification accuracies of up to 90% for detecting elevated levels of cognitive load, and show that the inclusion of physiological data leads to higher classification accuracy than vehicle sensor data evaluated alone. Finally, we show results suggesting that models can be built to classify cognitive load across individuals, instead of building individual models for each per-son. By collecting data from drivers in two large field studies on the highway (20 drivers and 99 drivers), this work extends prior work and demonstrates feasibility and potential of such measures for HCI research in vehicles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4057–4066},
numpages = {10},
keywords = {skin conductance, heart rate, physiological computing, driving, machine learning, cognitive workload},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2556988,
author = {Politis, Ioannis and Brewster, Stephen A. and Pollick, Frank},
title = {Evaluating Multimodal Driver Displays under Varying Situational Urgency},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556988},
doi = {10.1145/2556288.2556988},
abstract = {Previous studies have investigated audio, visual and tactile driver warnings, indicating the importance of communicating the appropriate level of urgency to the drivers. However, these modalities have never been combined exhaustively and tested under conditions of varying situational urgency to assess their effectiveness both in the presence and absence of critical driving events. This paper describes an experiment evaluating all multimodal combinations of such warnings under two contexts of situational urgency: a lead car braking and not braking. The results showed that participants responded quicker to more urgent warnings, especially in the presence of a car braking. They also responded faster to the multimodal as opposed to unimodal signals. Driving behaviour improved in the presence of the warnings and the absence of a car braking. These results highlight the influence of urgency and number of modalities in warning design and indicate the utility of non-visual warnings in driving.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4067–4076},
numpages = {10},
keywords = {visual, simulator, audio, tactile, response time, steering angle, warnings, multimodal interaction, situational urgency, lateral deviation},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250990,
author = {M\"{u}ller, J\"{o}rg},
title = {Session Details: Gesture-Based Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250990},
doi = {10.1145/3250990},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557113,
author = {Rovelo Ruiz, Gustavo Alberto and Vanacken, Davy and Luyten, Kris and Abad, Francisco and Camahort, Emilio},
title = {Multi-Viewer Gesture-Based Interaction for Omni-Directional Video},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557113},
abstract = {Omni-directional video (ODV) is a novel medium that offers viewers a 360º panoramic recording. This type of content will become more common within our living rooms in the near future, seeing that immersive displaying technologies such as 3D television are on the rise. However, little attention has been given to how to interact with ODV content. We present a gesture elicitation study in which we asked users to perform mid-air gestures that they consider to be appropriate for ODV interaction, both for individual as well as collocated settings. We are interested in the gesture variations and adaptations that come forth from individual and collocated usage. To this end, we gathered quantitative and qualitative data by means of observations, motion capture, questionnaires and interviews. This data resulted in a user-defined gesture set for ODV, alongside an in-depth analysis of the variation in gestures we observed during the study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4077–4086},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557219,
author = {Reetz, Adrian and Gutwin, Carl},
title = {Making Big Gestures: Effects of Gesture Size on Observability and Identification for Co-Located Group Awareness},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557219},
doi = {10.1145/2556288.2557219},
abstract = {Co-located work environments allow people to maintain awareness by observing others' actions (called consequen-tial communication), but the computerization of many tasks has dramatically reduced the observability of work actions. The recent interest in gestural interaction techniques offers the possibility of recreating some of the noticeability of previous work actions, but little is known about the observability and identifiability of command gestures. To investigate these basic issues, we carried out a study that asked people to observe and identify different sizes and morphologies of gestures from different locations, while carrying out an attention-demanding primary task. We studied small (tablet sized), medium (monitor-sized), and large (full-arm) gestures. Our study showed that although size did have significant effects, as expected, even small gestures were highly noticeable (rates above 75%) and identifiable (rates above 69%). Our results provide empirical guidance about the ways that gesture size, morphology, and location affect observation, and show that gestural interaction has potential for improving group awareness in co-located environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4087–4096},
numpages = {10},
keywords = {gestures, consequential communication, group awareness},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557051,
author = {Probst, Kathrin and Lindlbauer, David and Haller, Michael and Schwartz, Bernhard and Schrempf, Andreas},
title = {A Chair as Ubiquitous Input Device: Exploring Semaphoric Chair Gestures for Focused and Peripheral Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557051},
doi = {10.1145/2556288.2557051},
abstract = {During everyday office work we are used to controlling our computers with keyboard and mouse, while the majority of our body remains unchallenged and the physical workspace around us stays largely unattended. Addressing this untapped potential, we explore the concept of turning a flexible office chair into a ubiquitous input device. To facilitate daily desktop work, we propose the utilization of semaphoric chair gestures that can be assigned to specific application functionalities. The exploration of two usage scenarios in the context of focused and peripheral interaction demonstrates high potential of chair gestures as additional input modality for opportunistic, hands-free interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4097–4106},
numpages = {10},
keywords = {interactive chair, input technologies, gestural interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557373,
author = {Valdes, Consuelo and Eastman, Diana and Grote, Casey and Thatte, Shantanu and Shaer, Orit and Mazalek, Ali and Ullmer, Brygg and Konkel, Miriam K.},
title = {Exploring the Design Space of Gestural Interaction with Active Tokens through User-Defined Gestures},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557373},
doi = {10.1145/2556288.2557373},
abstract = {Multi-touch and tangible interfaces provide unique opportunities for enhancing learning and discovery with big data. However, existing interaction techniques have limitations when manipulating large data sets. Our goal is to define novel interaction techniques for multi-touch and tangible interfaces, which support the construction of complex queries for big data. In this paper, we present results from a study which investigates the use of gestural interaction with active tokens for manipulating large data sets. In particular, we studied user expectations of a hybrid tangible and gestural language engaging this space. Our main results include a vocabulary of user-defined gestures for interaction with active tokens, which extends beyond familiar multi-touch gestures; characterization of the design space of gestural interaction with active tokens; and insight into participants' mental models, including common metaphors. We also present implications for the design of multi-touch and tangible interfaces with active tokens.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4107–4116},
numpages = {10},
keywords = {tabletop, queries, physical tokens., multi-display environments, gestures, cross-device interaction},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/3250991,
author = {Quigley, Aaron},
title = {Session Details: Interactive Surfaces and Pervasive Displays},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250991},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1}
}

@inproceedings{10.1145/2556288.2557365,
author = {Winkler, Christian and Seifert, Julian and Dobbelstein, David and Rukzio, Enrico},
title = {Pervasive Information through Constant Personal Projection: The Ambient Mobile Pervasive Display (AMP-D)},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557365},
doi = {10.1145/2556288.2557365},
abstract = {The vision of pervasive ambient information displays which show relevant information has not yet come true. One of the main reasons is the limited number of available displays in the environment which is a fundamental requirement of the original vision. We introduce the concept of an Ambient Mobile Pervasive Display AMP-D which is a wearable projector system that constantly projects an ambient information display in front of the user. The floor display provides serendipitous access to public and personal information. The display is combined with a projected display on the user's hand, forming a continuous interaction space that is controlled by hand gestures. The paper introduces this novel device concept, discusses its interaction design, and explores its advantages through various implemented application examples. Furthermore, we present the AMP-D prototype which illustrates the involved challenges concerning hardware, sensing, and visualization.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4117–4126},
numpages = {10},
keywords = {personal projection, augmented reality, ambient displays, pervasive displays},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557071,
author = {R\"{a}dle, Roman and Jetter, Hans-Christian and M\"{u}ller, Jens and Reiterer, Harald},
title = {Bigger is Not Always Better: Display Size, Performance, and Task Load during Peephole Map Navigation},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557071},
doi = {10.1145/2556288.2557071},
abstract = {Dynamic peephole navigation is an increasingly popular technique for navigating large information spaces such as maps. Users can view the map through handheld, spatially aware displays that serve as peepholes and navigate the map by moving these displays in physical space. We conducted a controlled experiment of peephole map navigation with 16 participants to better understand the effect of a peephole's size on users' map navigation behavior, navigation performance, and task load. Simulating different peephole sizes from 4' (smartphone) up to 120' (control condition), we confirmed that larger peepholes significantly improve learning speed, navigation speed, and reduce task load; however, this added benefit diminishes with growing sizes. Our data shows that a relatively small, tablet-sized peephole can serve as a 'sweet spot' between peephole size and both user navigation performance and user task load.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4127–4136},
numpages = {10},
keywords = {user study, experimentation, navigation performance, map navigation, peephole navigation, display size},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557172,
author = {Grau, Alex M. and Hendee, Charles and Rizzo, John-Ross and Perlin, Ken},
title = {Mechanical Force Redistribution: Enabling Seamless, Large-Format, High-Accuracy Surface Interaction},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557172},
doi = {10.1145/2556288.2557172},
abstract = {We present Mechanical Force Redistribution (MFR): a method of sensing which creates an anti-aliased image of forces applied to a surface. This technique mechanically focuses the force from a surface onto adjacent discrete forcels (force sensing cells) by way of protrusions (small bumps or pegs), allowing for high-accuracy interpolation between adjacent discrete forcels. MFR works with any force transducing technique or material, including force variable resistive inks, piezoelectric materials and capacitive force plates. MFR sensors can be tiled such that the signal is continuous across contiguous tiles. By minimizing active materials and computational complexity, MFR makes large-format interactive walls, collaborative tabletops and high-resolution floor tiles possible and economically feasible.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4137–4146},
numpages = {10},
keywords = {pressure, input device, floors, walls, large format, sensor, force, mechanical force redistribution, tabletop},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557020,
author = {Liu, Can and Chapuis, Olivier and Beaudouin-Lafon, Michel and Lecolinet, Eric and Mackay, Wendy E.},
title = {Effects of Display Size and Navigation Type on a Classification Task},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557020},
doi = {10.1145/2556288.2557020},
abstract = {The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-and-zoom and are therefore slower than the wall for difficult tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4147–4156},
numpages = {10},
keywords = {classification task, wall-size display, pan-and-zoom, lenses, physical navigation, overview+detail},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/3250992,
author = {Odom, William},
title = {Session Details: Social Media for Relationships},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250992},
doi = {10.1145/3250992},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2556288.2557059,
author = {Brubaker, Jed R. and Dombrowski, Lynn S. and Gilbert, Anita M. and Kusumakaulika, Nafiri and Hayes, Gillian R.},
title = {Stewarding a Legacy: Responsibilities and Relationships in the Management of Post-Mortem Data},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557059},
doi = {10.1145/2556288.2557059},
abstract = {This paper extends research on the giving and inheriting of digital artifacts by examining social network site accounts post-mortem. Given the important role that social network sites play in online bereavement practices, we conducted a series of in-depth qualitative interviews to explore issues around inheritance and post-mortem data management of Facebook accounts. We found that participants focused less on ownership of the data, and instead on the duties and potential conflicts associated with maintaining an account post-mortem. Subsequently, we argue for 'stewardship' as an alternative to inheritance for framing post-mortem data management practices. Analysis of post-mortem data management activities highlights how stewards are accountable and responsible to the deceased and various survivors. However, weighing competing responsibilities is complicated by varied relationships with disparate survivors, as well as the inability to consult with the deceased. Based on our findings, we claim that post-mortem solutions need to account for the needs of stewards in addition to those of the deceased and survivors. We suggest that a model of stewardship better accounts for the interpersonal responsibilities that accompany online data than inheritance alone.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4157–4166},
numpages = {10},
keywords = {qualitative study, inheritance, social network sites, stewardship, facebook, digital legacy, death},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2557059_R50298,
author = {Strnadl, Christoph F.},
title = {Review ID:R50298 for DOI: 10.1145/2556288.2557059},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557059_R50298}
}

@inproceedings{10.1145/2556288.2557290,
author = {Waycott, Jenny and Davis, Hilary and Vetere, Frank and Morgans, Amee and Gruner, Alan and Ozanne, Elizabeth and Kulik, Lars},
title = {Captioned Photographs in Psychosocial Aged Care: Relationship Building and Boundary Work},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557290},
doi = {10.1145/2556288.2557290},
abstract = {In this paper we examine the use of a novel social technology to support the provision of formal aged care services to clients who live in their own homes. Social technologies offer enormous potential for enhancing aged care, but research on their use in aged care has largely focused on institutional or informal care settings, rather than formal care in the home. Meanwhile, technologies for aging in place typically focus on monitoring and security, rather than psychosocial support. We conducted a field study in which aged care managers used a photo and message-sharing tool to communicate with clients living in their own homes. Our findings demonstrate that visual and social forms of communication are valuable for supporting psychosocial care-giving, but there are barriers to effectively adopting new communication tools in this setting. Time constraints inhibited care managers' use of the technology, which was also influenced by their efforts to carefully maintain boundaries between their personal and professional lives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4167–4176},
numpages = {10},
keywords = {photo-sharing, ipad, aged care, social technologies},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inbook{10.1145/2556288.2557255,
author = {Forghani, Azadeh and Neustaedter, Carman},
title = {The Routines and Needs of Grandparents and Parents for Grandparent-Grandchild Conversations over Distance},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557255},
abstract = {A variety of systems have been designed to support communication between distance-separated grandparents and grandchildren. Yet there are few studies of the actual conversational routines of these groups as well as the social challenges that might arise as a result of technology usage. To address this gap, we conducted an interview and diary study that explores the conversational practices of distance-separated grandparents and young grandchildren (aged 3-10) from the perspective of the grandparents and parents of the children. Our results describe the focus of grandparent-grandchild conversations and show that grandparent-grandchild communication is not without its challenges: grandparents sometimes feel self-conscious, perceive that parents or children will be annoyed if they ask too many questions, and do not want to interfere too much in their grandchildren's lives. The implication is that designs should attempt to support the conversation routines and needs of grandparents and grandchildren while attempting to mitigate the social challenges.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4177–4186},
numpages = {10}
}

@inproceedings{10.1145/2556288.2557094,
author = {Burke, Moira and Kraut, Robert E.},
title = {Growing Closer on Facebook: Changes in Tie Strength through Social Network Site Use},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557094},
doi = {10.1145/2556288.2557094},
abstract = {Scientists debate whether people grow closer to their friends through social networking sites like Facebook, whether those sites displace more meaningful interaction, or whether they simply reflect existing ties. Combining server log analysis and longitudinal surveys of 3,649 Facebook users reporting on relationships with 26,134 friends, we find that communication on the site is associated with changes in reported relationship closeness, over and above effects attributable to their face-to-face, phone, and email contact. Tie strength increases with both one-on-one communication, such as posts, comments, and messages, and through reading friends' broadcasted content, such as status updates and photos. The effect is greater for composed pieces, such as comments, posts, and messages than for 'one-click' actions such as 'likes.' Facebook has a greater impact on non-family relationships and ties who do not frequently communicate via other channels.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {4187–4196},
numpages = {10},
keywords = {social relationships, facebook, tie strength, social network sites, relational closeness, families, friendship},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@dataset{10.1145/review-2556288.2557094_R51179,
author = {Peoples, Cathryn},
title = {Review ID:R51179 for DOI: 10.1145/2556288.2557094},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557094_R51179}
}

@dataset{10.1145/review-2556288.2557094_R51216,
author = {Jane, Sandhya},
title = {Review ID:R51216 for DOI: 10.1145/2556288.2557094},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-2556288.2557094_R51216}
}

