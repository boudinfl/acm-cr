@inproceedings{10.1145/571985.571987,
author = {Bellotti, Victoria and Ducheneaut, Nicolas and Howard, Mark and Neuwirth, Christine and Smith, Ian and Smith, Trevor},
title = {FLANNEL: Adding Computation to Electronic Mail during Transmission},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571987},
doi = {10.1145/571985.571987},
abstract = {In this paper, we describe FLANNEL, an architecture for adding computational capabilities to email. FLANNEL allows email to be modified by an application while in transit between sender and receiver. This modification is done without modification to the endpoints---mail clients---at either end. This paper also describes interaction techniques that we have developed to allow senders of email to quickly and easily select computations to be performed by FLANNEL. Through, our experience, we explain the properties that applications must have in order to be successful in the context of FLANNEL.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {1–10},
numpages = {10},
keywords = {communications channel, web applications, electronic mail, computational email},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.571988,
author = {Tullio, Joe and Goecks, Jeremy and Mynatt, Elizabeth D. and Nguyen, David H.},
title = {Augmenting Shared Personal Calendars},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571988},
doi = {10.1145/571985.571988},
abstract = {In this paper, we describe Augur, a groupware calendar system to support personal calendaring practices, informal workplace communication, and the socio-technical evolution of the calendar system within a workgroup. Successful design and deployment of groupware calendar systems have been shown to depend on several converging, interacting perspectives. We describe calendar-based work practices as viewed from these perspectives, and present the Augur system in support of them. Augur allows users to retain the flexibility of personal calendars by anticipating and compensating for inaccurate calendar entries and idiosyncratic event names. We employ predictive user models of event attendance, intelligent processing of calendar text, and discovery of shared events to drive novel calendar visualizations that facilitate interpersonal communication. In addition, we visualize calendar access to support privacy management and long-term evolution of the calendar system.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {11–20},
numpages = {10},
keywords = {text classification, social visualization, privacy management, groupware calendar system, user modeling},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.571989,
author = {Golovchinsky, Gene and Denoue, Laurent},
title = {Moving Markup: Repositioning Freeform Annotations},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571989},
doi = {10.1145/571985.571989},
abstract = {Freeform digital ink annotation allows readers to interact with documents in an intuitive and familiar manner. Such marks are easy to manage on static documents, and provide a familiar annotation experience. In this paper, we describe an implementation of a freeform annotation system that accommodates dynamic document layout. The algorithm preserves the correct position of annotations when documents are viewed with different fonts or font sizes, with different aspect ratios, or on different devices. We explore a range of heuristics and algorithms required to handle common types of annotation, and conclude with a discussion of possible extensions to handle special kinds of annotations and changes to documents.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {21–30},
numpages = {10},
keywords = {repositioning annotations, freeform digital ink, dynamic document layout, annotation},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.571991,
author = {Greenberg, Saul and Boyle, Michael},
title = {Customizable Physical Interfaces for Interacting with Conventional Applications},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571991},
doi = {10.1145/571985.571991},
abstract = {When using today's productivity applications, people rely heavily on graphical controls (GUI widgets) as the way to invoke application functions and to obtain feedback. Yet we all know that certain controls can be difficult or tedious to find and use. As an alternative, a customizable physical interface lets an end-user easily bind a modest number of physical controls to similar graphical counterparts. The user can then use the physical control to invoke the corresponding graphical control's function, or to display its graphical state in a physical form. To show how customizable physical interfaces work, we present examples that illustrate how our combined phidgets® and widget tap packages are used to link existing application widgets to physical controls. While promising, our implementation prompts a number of issues relevant to others pursuing interface customization.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {31–40},
numpages = {10},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.571992,
author = {Mackay, Wendy E. and Pothier, Guillaume and Letondal, Catherine and B\o{}egh, Kaare and S\o{}rensen, Hans Erik},
title = {The Missing Link: Augmenting Biology Laboratory Notebooks},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571992},
doi = {10.1145/571985.571992},
abstract = {Using a participatory design process, we created three prototype augmented laboratory notebooks that provide the missing link between paper, physical artifacts and on-line data. The final a-book combines a graphics tablet and a PDA. The tablet captures writing on the paper notebook and the PDA acts as an "interaction lens" or window between physical and electronic documents. Our approach is document-centered, with a software architecture based on layers of physical and electronic information.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {41–50},
numpages = {10},
keywords = {interaction lens, a-book, information layers, SVG, interactive paper, augmented reality, augmented laboratory note-books},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.571993,
author = {Poupyrev, Ivan and Maruyama, Shigeaki and Rekimoto, Jun},
title = {Ambient Touch: Designing Tactile Interfaces for Handheld Devices},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571993},
doi = {10.1145/571985.571993},
abstract = {This paper investigates the sense of touch as a channel for communicating with miniature handheld devices. We embedded a PDA with a TouchEngineTM --- a thin, miniature lower-power tactile actuator that we have designed specifically to use in mobile interfaces (Figure 1). Unlike previous tactile actuators, the TouchEngine is a universal tactile display that can produce a wide variety of tactile feelings from simple clicks to complex vibrotactile patterns. Using the TouchEngine, we began exploring the design space of interactive tactile feedback for handheld computers. Here, we investigated only a subset of this space: using touch as the ambient, background channel of interaction. We proposed a general approach to design such tactile interfaces and described several implemented prototypes. Finally, our user studies demonstrated 22% faster task completion when we enhanced handheld tilting interfaces with tactile feedback.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {51–60},
numpages = {10},
keywords = {mobile devices and interfaces, tactile feedback},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.571995,
author = {Fogarty, James and Forlizzi, Jodi and Hudson, Scott E.},
title = {Specifying Behavior and Semantic Meaning in an Unmodified Layered Drawing Package},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571995},
doi = {10.1145/571985.571995},
abstract = {In order to create and use rich custom appearances, designers are often forced to introduce an unnatural gap into the design process. For example, a designer creating a skin for a music player must separately specify the appearance of the elements in the music player skin and the mapping between these visual elements and the functionality provided by the music player. This gap between appearance and semantic meaning creates a number of problems. We present a set of techniques that allows designers to use their preferred drawing tool to specify both appearance and semantic meaning. We demonstrate our techniques in an unmodified version of Adobe Photoshop®, but our techniques are general and adaptable to nearly any layered drawing package.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {61–70},
numpages = {10},
keywords = {visual specification, visual design tools, prototyping},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.571996,
author = {Terry, Michael and Mynatt, Elizabeth D.},
title = {Side Views: Persistent, on-Demand Previews for Open-Ended Tasks},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571996},
doi = {10.1145/571985.571996},
abstract = {We introduce Side Views, a user interface mechanism that provides on-demand, persistent, and dynamic previews of commands. Side Views are designed to explicitly support the practices and needs of expert users engaged in openended tasks. In this paper, we summarize results from field studies of expert users that motivated this work, then discuss the design of Side Views in detail. We show how Side Views' design affords their use as tools for clarifying, comparing, and contrasting commands; generating alternative visualizations; experimenting without modifying the original data (i.e., "what-if" tools); and as tools that support the serendipitous discovery of viable alternatives. We then convey lessons learned from implementing Side Views in two sample applications, a rich text editor and an image manipulation application. These contributions include a discussion of how to implement Side Views for commands with parameters, for commands that require direct user input (such as mouse strokes for a paint program), and for computationally-intensive commands.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {71–80},
numpages = {10},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.571997,
author = {Lee, Johnny C. and Forlizzi, Jodi and Hudson, Scott E.},
title = {The Kinetic Typography Engine: An Extensible System for Animating Expressive Text},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571997},
doi = {10.1145/571985.571997},
abstract = {Kinetic typography --- text that uses movement or other temporal change --- has recently emerged as a new form of communication. As we hope to illustrate in this paper, kinetic typography can be seen as bringing some of the expressive power of film --- such as its ability to convey emotion, portray compelling characters, and visually direct attention --- to the strong communicative properties of text. Although kinetic typography offers substantial promise for expressive communications, it has not been widely exploited outside a few limited application areas (most notably in TV advertising). One of the reasons for this has been the lack of tools directly supporting it, and the accompanying difficulty in creating dynamic text. This paper presents a first step in remedying this situation --- an extensible and robust system for animating text in a wide variety of forms. By supporting an appropriate set of carefully factored abstractions, this engine provides a relatively small set of components that can be plugged together to create a wide range of different expressions. It provides new techniques for automating effects used in traditional cartoon animation, and provides specific support for typographic manipulations.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {81–90},
numpages = {10},
keywords = {automating animation effects, time-based presentation, dynamic text, kinetic typography},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.571999,
author = {Igarashi, Takeo and Hughes, John F.},
title = {Clothing Manipulation},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.571999},
doi = {10.1145/571985.571999},
abstract = {This paper presents interaction techniques (and the underlying implementations) for putting clothes on a 3D character and manipulating them. The user paints freeform marks on the clothes and corresponding marks on the 3D character; the system then puts the clothes around the body so that corresponding marks match. Internally, the system grows the clothes on the body surface around the marks while maintaining basic cloth constraints via simple relaxation steps. The entire computation takes a few seconds. After that, the user can adjust the placement of the clothes by an enhanced dragging operation. Unlike standard dragging where the user moves a set of vertices in a single direction in 3D space, our dragging operation moves the cloth along the body surface to make possible more flexible operations. The user can apply pushpins to fix certain cloth points during dragging. The techniques are ideal for specifying an initial cloth configuration before applying a more sophisticated cloth simulation.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {91–100},
numpages = {10},
keywords = {user interface, clothing},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572000,
author = {Burtnyk, Nicholas and Khan, Azam and Fitzmaurice, George and Balakrishnan, Ravin and Kurtenbach, Gordon},
title = {StyleCam: Interactive Stylized 3D Navigation Using Integrated Spatial &amp; Temporal Controls},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572000},
doi = {10.1145/571985.572000},
abstract = {This paper describes StyleCam, an approach for authoring 3D viewing experiences that incorporate stylistic elements that are not available in typical 3D viewers. A key aspect of StyleCam is that it allows the author to significantly tailor what the user sees and when they see it. The resulting viewing experience can approach the visual richness and pacing of highly authored visual content such as television commercials or feature films. At the same time, StyleCam allows for a satisfying level of interactivity while avoiding the problems inherent in using unconstrained camera models. The main components of StyleCam are camera surfaces which spatially constrain the viewing camera; animation clips that allow for visually appealing transitions between different camera surfaces; and a simple, unified, interaction technique that permits the user to seamlessly and continuously move between spatial-control of the camera and temporal-control of the animated transitions. Further, the user's focus of attention is always kept on the content, and not on extraneous interface widgets. In addition to describing the conceptual model of StyleCam, its current implementation, and an example authored experience, we also present the results of an evaluation involving real users.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {101–110},
numpages = {10},
keywords = {3D viewers, interaction techniques, camera controls, 3D navigation, 3D visualization},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572001,
author = {Tsang, Michael and Fitzmaurice, George W. and Kurtenbach, Gordon and Khan, Azam and Buxton, Bill},
title = {Boom Chameleon: Simultaneous Capture of 3D Viewpoint, Voice and Gesture Annotations on a Spatially-Aware Display},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572001},
doi = {10.1145/571985.572001},
abstract = {We introduce the Boom Chameleon, a novel input/output device consisting of a flat-panel display mounted on a tracked mechanical boom. The display acts as a physical window into 3D virtual environments, through which a one-to-one mapping between real and virtual space is preserved. The Boom Chameleon is further augmented with a touch-screen and a microphone/speaker combination. We present a 3D annotation application that exploits this unique configuration in order to simultaneously capture viewpoint, voice and gesture information. Design issues are discussed and results of an informal user study on the device and annotation software are presented. The results show that the Boom Chameleon annotation facilities have the potential to be an effective, easy to learn and operate 3D design review system.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {111–120},
numpages = {10},
keywords = {voice, spatially-aware display, annotation, gesture, 3D navigation},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572003,
author = {Dey, Anind and Mankoff, Jennifer and Abowd, Gregory and Carter, Scott},
title = {Distributed Mediation of Ambiguous Context in Aware Environments},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572003},
doi = {10.1145/571985.572003},
abstract = {Many context-aware services make the assumption that the context they use is completely accurate. However, in reality, both sensed and interpreted context is often ambiguous. A challenge facing the development of realistic and deployable context-aware services, therefore, is the ability to handle ambiguous context. In this paper, we describe an architecture that supports the building of context-aware services that assume context is ambiguous and allows for mediation of ambiguity by mobile users in aware environments. We illustrate the use of our architecture and evaluate it through three example context-aware services, a word predictor system, an In/Out Board, and a reminder tool.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {121–130},
numpages = {10},
keywords = {mediation, aware environments, ubiquitous computing, context-aware computing, ambiguity, error handling},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572004,
author = {Olsen, Dan R. and Peachey, Jon R.},
title = {Query-by-Critique: Spoken Language Access to Large Lists},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572004},
doi = {10.1145/571985.572004},
abstract = {Spoken language interfaces provide highly mobile, small form-factor, hands-free, eyes-free interaction with information. Uniform access to large lists of information using spoken interfaces is highly desirable, but problematic due to inherent limitations of speech. A speech widget for lists of attributed objects is described that provides for approximate queries to retrieve desired items. User tests demonstrate that this is an effective technique for accessing information using speech.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {131–140},
numpages = {10},
keywords = {tables, spoken language interfaces, search},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572005,
author = {Schmandt, Chris and Kim, Jang and Lee, Kwan and Vallejo, Gerardo and Ackerman, Mark},
title = {Mediated Voice Communication via Mobile IP},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572005},
doi = {10.1145/571985.572005},
abstract = {Impromptu is a mobile audio device which uses wireless Internet Protocol (IP) to access novel computer-mediated voice communication channels. These channels show the richness of IP-based communication as compared to conventional mobile telephony, adding audio processing and storage in the network, and flexible, user-centered call control protocols. These channels may be synchronous, asynchronous, or event-triggered, or even change modes as a function of other user activity. The demands of these modes plus the need to navigate with an entirely non-visual user interface are met with a number of audio-oriented user interaction techniques.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {141–150},
numpages = {10},
keywords = {ubiquitous computing, audio user interfaces, computer-mediated communication, speech user interfaces},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572007,
author = {Swindells, Colin and Inkpen, Kori M. and Dill, John C. and Tory, Melanie},
title = {That One There! Pointing to Establish Device Identity},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572007},
doi = {10.1145/571985.572007},
abstract = {Computing devices within current work and play environments are relatively static. As the number of 'networked' devices grows, and as people and their devices become more dynamic, situations will commonly arise where users will wish to use 'that device there' instead of navigating through traditional user interface widgets such as lists. This paper describes a process for identifying devices through a pointing gesture using custom tags and a custom stylus called the gesturePen. Implementation details for this system are provided along with qualitative and quantitative results from a formal user study. As ubiquitous computing environments become more pervasive, people will rapidly switch their focus between many computing devices. The results of our work demonstrate that our gesturePen method can improve the user experience in ubiquitous environments by facilitating significantly faster interactions between computing devices.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {151–160},
numpages = {10},
keywords = {gesturePen, gesturing, PDA, identification, infrared (IR) tag, pointing, handheld computer},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572008,
author = {Nichols, Jeffrey and Myers, Brad A. and Higgins, Michael and Hughes, Joseph and Harris, Thomas K. and Rosenfeld, Roni and Pignol, Mathilde},
title = {Generating Remote Control Interfaces for Complex Appliances},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572008},
doi = {10.1145/571985.572008},
abstract = {The personal universal controller (PUC) is an approach for improving the interfaces to complex appliances by introducing an intermediary graphical or speech interface. A PUC engages in two-way communication with everyday appliances, first downloading a specification of the appliance's functions, and then automatically creating an interface for controlling that appliance. The specification of each appliance includes a high-level description of every function, a hierarchical grouping of those functions, and dependency information, which relates the availability of each function to the appliance's state. Dependency information makes it easier for designers to create specifications and helps the automatic interface generators produce a higher quality result. We describe the architecture that supports the PUC, and the interface generators that use our specification language to build high-quality graphical and speech interfaces.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {161–170},
numpages = {10},
keywords = {pebbles, appliances, remote control, universal speech interface (USI), handheld computers, personal digital assistants (PDAs), personal universal controller (PUC)},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572009,
author = {Newman, Mark W. and Izadi, Shahram and Edwards, W. Keith and Sedivy, Jana Z. and Smith, Trevor F.},
title = {User Interfaces When and Where They Are Needed: An Infrastructure for Recombinant Computing},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572009},
doi = {10.1145/571985.572009},
abstract = {Users in ubiquitous computing environments need to be able to make serendipitous use of resources that they did not anticipate and of which they have no prior knowledge. The Speakeasy recombinant computing framework is designed to support such ad hoc use of resources on a network. In addition to other facilities, the framework provides an infrastructure through which device and service user interfaces can be made available to users on multiple platforms. The framework enables UIs to be provided for connections involving multiple entities, allows these UIs to be delivered asynchronously, and allows them to be injected by any party participating in a connection.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {171–180},
numpages = {10},
keywords = {ubiquitous computing, asynchronous user interfaces, recombinant computing, speakeasy},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572011,
author = {Pangaro, Gian and Maynes-Aminzade, Dan and Ishii, Hiroshi},
title = {The Actuated Workbench: Computer-Controlled Actuation in Tabletop Tangible Interfaces},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572011},
doi = {10.1145/571985.572011},
abstract = {The Actuated Workbench is a device that uses magnetic forces to move objects on a table in two dimensions. It is intended for use with existing tabletop tangible interfaces, providing an additional feedback loop for computer output, and helping to resolve inconsistencies that otherwise arise from the computer's inability to move objects on the table. We describe the Actuated Workbench in detail as an enabling technology, and then propose several applications in which this technology could be useful.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {181–190},
numpages = {10},
keywords = {actuation, computer supported cooperative work, synchronization, object tracking, tangible user interfaces, physical interaction, interactive surface},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572012,
author = {Hurst, Nathan and Marriott, Kim and Moulder, Peter},
title = {Dynamic Approximation of Complex Graphical Constraints by Linear Constraints},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572012},
doi = {10.1145/571985.572012},
abstract = {Current constraint solving techniques for interactive graphical applications cannot satisfactorily handle constraints such as non-overlap, or containment within non-convex shapes or shapes with smooth edges. We present a generic new technique for efficiently handling such kinds of constraints based on trust regions and linear arithmetic constraint solving. Our approach is to model these more complex constraints by a dynamically changing conjunction of linear constraints. At each stage, these give a local approximation to the complex constraints. During direct manipulation, linear constraints in the current local approximation can become active indicating that the current solution is on the boundary of the trust region for the approximation. The associated complex constraint is notified and it may choose to modify the current linear approximation. Empirical evaluation demonstrates that it is possible to (re-)solve systems of linear constraints that are dynamically approximating complex constraints such as non-overlap sufficiently quickly to support direct manipulation in interactive graphical applications.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {191–200},
numpages = {10},
keywords = {direct manipulation, containment, constraint-solving, trust regions, non-overlap, linearization of constraints},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572013,
author = {Partridge, Kurt and Chatterjee, Saurav and Sazawal, Vibha and Borriello, Gaetano and Want, Roy},
title = {TiltType: Accelerometer-Supported Text Entry for Very Small Devices},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572013},
doi = {10.1145/571985.572013},
abstract = {TiltType is a novel text entry technique for mobile devices. To enter a character, the user tilts the device and presses one or more buttons. The character chosen depends on the button pressed, the direction of tilt, and the angle of tilt. TiltType consumes minimal power and requires little board space, making it appropriate for wristwatch-sized devices. But because controlled tilting of one's forearm is fatiguing, a wristwatch using this technique must be easily removable from its wriststrap. Applications include two-way paging, text entry for watch computers, web browsing, numeric entry for calculator watches, and existing applications for PDAs.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {201–204},
numpages = {4},
keywords = {accelerometer applications, wearable computing, interaction techniques, wristwatch computers, mobile devices, input/output devices, text entry},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572014,
author = {Wobbrock, Jacob O. and Forlizzi, Jodi and Hudson, Scott E. and Myers, Brad A.},
title = {WebThumb: Interaction Techniques for Small-Screen Browsers},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572014},
doi = {10.1145/571985.572014},
abstract = {The proliferation of wireless handheld devices is placing the World Wide Web in the palms of users, but this convenience comes at a high interactive cost. The Web that came of age on the desktop is ill-suited for use on the small displays of handhelds. Today, handheld browsing often feels like browsing on a PC with a shrunken desktop. Overreliance on scrolling is a big problem in current handheld browsing. Users confined to viewing a small portion of each page often lack a sense of the overall context --- they may feel lost in a large page and be forced to remember the locations of items as those items scroll out of view. In this paper, we present a synthesis of interaction techniques to address these problems. We implemented these techniques in a prototype, WebThumb, that can browse the live Web.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {205–208},
numpages = {4},
keywords = {interaction techniques, kinetic typography, thumbnails, small displays, zooming, handheld devices, web browsing},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572016,
author = {Booth, Kellogg S. and Fisher, Brian D. and Lin, Chi Jui Raymond and Argue, Ritchie},
title = {The "Mighty Mouse" Multi-Screen Collaboration Tool},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572016},
doi = {10.1145/571985.572016},
abstract = {Many computer operating systems provide seamless support for multiple display screens, but there are few cross-platform tools for collaborative use of multiple computers in a shared display environment. Mighty Mouse is a novel groupware tool built on the public domain VNC protocol. It is tailored specifically for face-to-face collaboration where multiple heterogeneous computers (usually laptops) are viewed simultaneously (usually via projectors) by people working together on a variety of applications under various operating systems. Mighty Mouse uses only the remote input capability of VNC, but enhances this with various features to support flexible movement between the various platforms, "floor control" to facilitate smooth collaboration, and customization features to accommodate different user, platform, and application preferences in a relatively seamless manner. The design rationale arises from specific observations about how people collaborate in meetings, which allows certain simplifying assumptions to be made in the implementation.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {209–212},
numpages = {4},
keywords = {virtual network computing, keyboard mappings, cut-and-paste, low-fidelity prototyping, single display groupware, collaboration},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572017,
author = {Bell, Blaine and H\"{o}llerer, Tobias and Feiner, Steven},
title = {An Annotated Situation-Awareness Aid for Augmented Reality},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572017},
doi = {10.1145/571985.572017},
abstract = {We present a situation-awareness aid for augmented reality systems based on an annotated "world in miniature." Our aid is designed to provide users with an overview of their environment that allows them to select and inquire about the objects that it contains. Two key capabilities are discussed that are intended to address the needs of mobile users. The aid's position, scale, and orientation are controlled by a novel approach that allows the user to inspect the aid without the need for manual interaction. As the user alternates their attention between the physical world and virtual aid, popup annotations associated with selected objects can move freely between the objects' representations in the two models.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {213–216},
numpages = {4},
keywords = {augmented reality, mobile computing, user interaction, world in miniature},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572018,
author = {Hsieh, Haowei and Shipman, Frank M.},
title = {Manipulating Structured Information in a Visual Workspace},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572018},
doi = {10.1145/571985.572018},
abstract = {This paper describes the VITE system, a visual workspace that supports two-way mapping for projecting structured information to a two-dimensional workspace and updating the structured information based on user interactions in the workspace. This is related to information visualization, but reflecting visual edits in the structured data requires a two-way mapping from data to visualization and from visualization to data. VITE provides users with an interface for designing two-way mappings. Mappings are reusable on different datasets and may be switched within a task. An evaluation of VITE was conducted to study how people use two-way mapping and how two-way mapping can help in problem solving tasks. The results show that users could quickly design visual mappings to help their problem-solving tasks. Users developed more sophisticated strategies for visual problem-solving over time.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {217–226},
numpages = {10},
keywords = {editable visualizations, information workspace, two-way mappings, information visualization},
location = {Paris, France},
series = {UIST '02}
}

@inproceedings{10.1145/571985.572019,
author = {Johanson, Brad and Hutchins, Greg and Winograd, Terry and Stone, Maureen},
title = {PointRight: Experience with Flexible Input Redirection in Interactive Workspaces},
year = {2002},
isbn = {1581134886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/571985.572019},
doi = {10.1145/571985.572019},
abstract = {We describe the design of and experience with PointRight, a peer-to-peer pointer and keyboard redirection system that operates in multi-machine, multi-user environments. PointRight employs a geometric model for redirecting input across screens driven by multiple independent machines and operating systems. It was created for interactive workspaces that include large, shared displays and individual laptops, but is a general tool that supports many different configurations and modes of use. Although previous systems have provided for re-routing pointer and keyboard control, in this paper we present a more general and flexible system, along with an analysis of the types of re-binding that must be handled by any pointer redirection system This paper describes the system, the ways in which it has been used, and the lessons that have been learned from its use over the last two years.},
booktitle = {Proceedings of the 15th Annual ACM Symposium on User Interface Software and Technology},
pages = {227–234},
numpages = {8},
keywords = {multi-display environments, input redirection, ubiquitous computing},
location = {Paris, France},
series = {UIST '02}
}

