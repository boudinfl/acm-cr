@inproceedings{10.1145/3313831.3376786,
author = {La Delfa, Joseph and Baytas, Mehmet Aydin and Patibanda, Rakesh and Ngari, Hazel and Khot, Rohit Ashok and Mueller, Florian 'Floyd'},
title = {Drone Chi: Somaesthetic Human-Drone Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376786},
doi = {10.1145/3313831.3376786},
abstract = {Somaesthetics - motivated by improving life quality via appreciation for bodily and sensory experiences - is increasingly influencing HCI designs. Investigating the potential of drones as a material for somaesthetic HCI, we designed Drone Chi: a Tai Chi-inspired close-range human-drone interaction experience. The design process for Drone Chi has been informed by the soma design approach and the Somaesthetic Appreciation concept from HCI literature. The artifact expands somaesthetic HCI by exemplifying dynamic and intimate somaesthetic interactions with a robotic design material, and body movements in expansive 3D space. To characterize the Drone Chi experience, we conducted an empirical study with 32 participants. Analysis of participant accounts revealed 4 themes that articulate different aspects of the experience: Looping Mental States, Environment, Agency vs. Control, and Physical Narratives. From these accounts and our craft knowledge, we derive 5 design implications to guide the development of movement-based close-range drone interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {drones, somaesthetics, movement, soma design, human-drone interaction, tai chi, somaesthetic appreciation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@book{10.1145/3313831,
author = {Bernhaupt, Regina and Mueller, Florian 'Floyd' and Verweij, David and Andres, Josh and McGrenere, Joanna and Cockburn, Andy and Avellino, Ignacio and Goguey, Alix and Bj\o{}rn, Pernille and Zhao, Shengdong (Shen) and Samson, Briane Paul and Kocielnik, Rafal},
title = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Aloha!We are excited to welcome you to CHI 2020 in beautiful Honolulu, Hawai'i!Although CHI has strong origins in the USA, it has never been to Hawai'i. We see this rather "unusual" location for a conference as both an acknowledgement of the role underrepresented regions play in the field of Human-Computer Interaction as well as a symbol for more outreach to the rest of the world.The ACM CHI Conference on Human Factors in Computing Systems is the premier international conference of Human-Computer Interaction. CHI - pronounced "kai" - is a place where researchers and practitioners gather from across the world to discuss the latest in interactive technology. We are a multicultural community from highly diverse backgrounds who together investigate new and creative ways for people to interact.CHI has a rich history of bringing together people from different disciplines, cultures, sectors, communities and backgrounds. Through CHI, designers, researchers and practitioners come together with the common purpose of creating technology that works for people and society.We are increasingly realizing how our technology use is changing how we delineate work and pleasure, how it is advancing our productivity but at the same time threatening our wellbeing. In choosing a beautiful location like Hawai'i, we hope we highlight the importance of work-life balance and also elicit new discussions on such critical perspectives about the future of interactive technology.Thanks to our massive numbers of volunteers and help from ACM and its SIGCHI members, we are excited to present a vibrant technical and social programme for you to experience. Over six days, participants can join and continue to engage with the CHI community and explore technology and world-class research, and engage in discussions with designers, researchers, students, and practitioners!Ho'omalu-o means "to conserve; to use or manage wisely" in the Hawaiian language. One of our goals for CHI 2020 is to make more sustainable choices wherever we can, recognising, of course, that any travel, especially to locations like ours, has a significant impact on the environment. Working with the Sustainability Chairs, we have chosen recycled, biodegradable or eco-friendly products and engaged with local suppliers, wherever possible. We have implemented options to reduce travel related to the conference organisation by using videoconference meetings as much as possible. We have worked with the CHI Steering and Executive Committee to identify future opportunities to reduce travel and to reduce the number of meetings. We have removed the conference bag and gifts by default and encouraged the selection of more sustainable food choices (including the decision not to serve red meat). We have also chosen reusable or compostable crockery and cutlery where possible and are donating any remaining food to a homeless shelter to avoid food waste.Furthermore, we have chosen to locate all activities in or near the Convention Centre and negotiated deals with hotels nearby to reduce the need for transportation. The Convention Centre itself is the first and only public assembly convention centre to earn LEED v.4 O+M Gold Certification in the United States. In the spirit of Ho'omaluo- , we have also decided to set the default temperature in the venue higher to reduce air condition energy usage.A particular highlight is the Interactivity programme, which will be launched at the Reception on Monday evening, giving a live glimpse into the future with hands-on prototypes, design experiences as well as inspirational technologies.We are also excited to continue the commitment to making CHI, and CHI content, more widely accessible. We will be live-streaming even more paper sessions. We also provide a nursing room, all-gender bathrooms, badge pronouns, a desensitization room and a prayer room.}
}

@inproceedings{10.1145/3313831.3376448,
author = {Wacharamanotham, Chat and Eisenring, Lukas and Haroz, Steve and Echtler, Florian},
title = {Transparency of CHI Research Artifacts: Results of a Self-Reported Survey},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376448},
doi = {10.1145/3313831.3376448},
abstract = {Several fields of science are experiencing a "replication crisis" that has negatively impacted their credibility. Assessing the validity of a contribution via replicability of its experimental evidence and reproducibility of its analyses requires access to relevant study materials, data, and code. Failing to share them limits the ability to scrutinize or build-upon the research, ultimately hindering scientific progress.Understanding how the diverse research artifacts in HCI impact sharing can help produce informed recommendations for individual researchers and policy-makers in HCI. Therefore, we surveyed authors of CHI 2018-2019 papers, asking if they share their papers' research materials and data, how they share them, and why they do not. The results (34% response rate) show that sharing is uncommon, partly due to misunderstandings about the purpose of sharing and reliable hosting. We conclude with recommendations for fostering open research practices.This paper and all data and materials are freely available at https://osf.io/3bu6t.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {data availability, public data sharing, open data, open science},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376209,
author = {Li, Chi-Hsun and Yeh, Su-Fang and Chang, Tang-Jie and Tsai, Meng-Hsuan and Chen, Ken and Chang, Yung-Ju},
title = {A Conversation Analysis of Non-Progress and Coping Strategies with a Banking Task-Oriented Chatbot},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376209},
doi = {10.1145/3313831.3376209},
abstract = {Task-oriented chatbots are becoming popular alternatives for fulfilling users' needs, but few studies have investigated how users cope with conversational 'non-progress' (NP) in their daily lives. Accordingly, we analyzed a three-month conversation log between 1,685 users and a task-oriented banking chatbot. In this data, we observed 12 types of conversational NP; five types of content that was unexpected and challenging for the chatbot to recognize; and 10 types of coping strategies. Moreover, we identified specific relationships between NP types and strategies, as well as signs that users were about to abandon the chatbot, including 1) three consecutive incidences of NP, 2) consecutive use of message reformulation or switching subjects, and 3) using message reformulation as the final strategy. Based on these findings, we provide design recommendations for task-oriented chatbots, aimed at reducing NP, guiding users through such NP, and improving user experiences to reduce the cessation of chatbot use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {chatbot, coping strategies, conversation analysis, breakdowns, non-progress},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376865,
author = {Wang, Chi and Huang, Da-Yuan and Hsu, Shuo-Wen and Lin, Cheng-Lung and Chiu, Yeu-Luen and Hou, Chu-En and Chen, Bing-Yu},
title = {Gaiters: Exploring Skin Stretch Feedback on Legs for Enhancing Virtual Reality Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376865},
doi = {10.1145/3313831.3376865},
abstract = {We propose generating two-dimensional skin stretch feedback on the user's legs. Skin stretch is useful cutaneous feedback to induce the perception of virtual textures and illusory forces and to deliver directional cues. This feedback has been applied to the head, body, and upper limbs to simulate rich physical properties in virtual reality (VR). However, how to expand the benefit of skin stretch feedback and apply it to the lower limbs, remains to be explored. Our first two psychophysical studies examined the minimum changes in skin stretch distance and stretch angle that are perceivable by participants. We then designed and implemented Gaiters, a pair of ungrounded, leg-worn devices, each of which is able to generate multiple two-dimensional skin stretches on the skin of the user's leg. With Gaiters, we conducted an exploratory study to understand participants' experiences when coupling skin stretch patterns with various lower limb actions. The results indicate that rich haptic experiences can be created by our prototype. Finally, a user evaluation indicates that participants enjoyed the experiences when using Gaiters and considered skin stretch as compelling haptic feedback on the legs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {haptics, skin stretch feedback, sheartactors, leg-worn device, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376262,
author = {Liao, Yi-Chi and Kim, Sunjun and Lee, Byungjoo and Oulasvirta, Antti},
title = {Button Simulation and Design via FDVV Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376262},
doi = {10.1145/3313831.3376262},
abstract = {Designing a push-button with desired sensation and performance is challenging because the mechanical construction must have the right response characteristics. Physical simulation of a button's force-displacement (FD) response has been studied to facilitate prototyping; however, the simulations' scope and realism have been limited. In this paper, we extend FD modeling to include vibration (V) and velocity-dependence characteristics (V). The resulting FDVV models better capture tactility characteristics of buttons, including snap. They increase the range of simulated buttons and the perceived realism relative to FD models. The paper also demonstrates methods for obtaining these models, editing them, and simulating accordingly. This end-to-end approach enables the analysis, prototyping, and optimization of buttons, and supports exploring designs that would be hard to implement mechanically.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {haptic, button, tactility, input device, simulation, force feedback, haptic rendering, vibration, fdvv model, fd model, modeling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376557,
author = {Tian, Yang and Bai, Yuming and Zhao, Shengdong and Fu, Chi-Wing and Yang, Tianpei and Heng, Pheng Ann},
title = {Virtually-Extended Proprioception: Providing Spatial Reference in VR through an Appended Virtual Limb},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376557},
doi = {10.1145/3313831.3376557},
abstract = {Selecting targets directly in the virtual world is difficult due to the lack of haptic feedback and inaccurate estimation of egocentric distances. Proprioception, the sense of self-movement and body position, can be utilized to improve virtual target selection by placing targets on or around one's body. However, its effective scope is limited closely around one's body. We explore the concept of virtually-extended proprioception by appending virtual body parts mimicking real body parts to users' avatars, to provide spatial reference to virtual targets. Our studies suggest that our approach facilitates more efficient target selection in VR as compared to no reference or using an everyday object as reference. Besides, by cultivating users' sense of ownership on the appended virtual body part, we can further enhance target selection performance. The effects of transparency and granularity of the virtual body part on target selection performance are also discussed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {spatial reference, proprioception, target selection, appended limb, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376131,
author = {Xiao, Ziang and Zhou, Michelle X. and Chen, Wenxi and Yang, Huahai and Chi, Changyan},
title = {If I Hear You Correctly: Building and Evaluating Interview Chatbots with Active Listening Skills},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376131},
doi = {10.1145/3313831.3376131},
abstract = {Interview chatbots engage users in a text-based conversation to draw out their views and opinions. It is, however, challenging to build effective interview chatbots that can handle user free-text responses to open-ended questions and deliver engaging user experience. As the first step, we are investigating the feasibility and effectiveness of using publicly available, practical AI technologies to build effective interview chatbots. To demonstrate feasibility, we built a prototype scoped to enable interview chatbots with a subset of active listening skills-the abilities to comprehend a user's input and respond properly. To evaluate the effectiveness of our prototype, we compared the performance of interview chatbots with or without active listening skills on four common interview topics in a live evaluation with 206 users. Our work presents practical design implications for building effective interview chatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interview chatbot, chatbot platform, active listening, deep learning, ai chatbot, conversational agents},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376368,
author = {Meena, Yogesh Kumar and Seunarine, Krishna and Sahoo, Deepak Ranjan and Robinson, Simon and Pearson, Jennifer and Zhang, Chi and Carnie, Matt and Pockett, Adam and Prescott, Andrew and Thomas, Suzanne K. and Lee, Harrison Ka Hin and Jones, Matt},
title = {PV-Tiles: Towards Closely-Coupled Photovoltaic and Digital Materials for Useful, Beautiful and Sustainable Interactive Surfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376368},
doi = {10.1145/3313831.3376368},
abstract = {The interactive, digital future with its seductive vision of Internet-of-Things connected sensors, actuators and displays comes at a high cost in terms of both energy demands and the clutter it brings to the physical world. But what if such devices were made of materials that enabled them to self-power their interactive features? And, what if those materials were directly used to build aesthetically pleasing environments and objects that met practical physical needs as well as digital ones? In this paper we introduce PV-Tiles ? a novel material that closely couples photovoltaic energy harvesting and light sensing materials with digital interface components. We consider potential contexts, use-cases and light gestures surfaced through co-creation workshops; and, present initial technological designs and prototypes. The work opens a new set of opportunities and collaborations between HCI and material science, stimulating technical and design pointers to accommodate and exploit the material's properties.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {self-powered devices, internet of things, interaction design, sustainability, connected home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376206,
author = {Lockton, Dan and Lallemand, Carine},
title = {Meeting Designers Where They Are: Using Industry Events as a Research Venue for HCI and Design Methods Development},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376206},
doi = {10.1145/3313831.3376206},
abstract = {There is much work in the CHI community about the 'industry-academia divide', and how to bridge it. One key crossover between HCI/UX scientists and practitioners is the development and use of tools and methods-boundary objects between academia and practice. Among other forms of collaboration, there is an underdeveloped opportunity for academics to make use of industry events (conferences, meetups, design jams) as a research venue in the context of tool and method development. This paper describes three cases from work in academia-industry engagement over the last decade, in which workshops or experiments have been run at industry events as a way of trialling and developing tools directly with practitioners. We discuss advantages of this approach and extract key insights and practical implications, highlighting how the CHI community might use this method more widely, gathering relevant research outcomes while contributing to knowledge exchange between academia and practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design tools, industry events, method development, industry-academia engagement, practitioners},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376723,
author = {Tyack, April and Mekler, Elisa D.},
title = {Self-Determination Theory in HCI Games Research: Current Uses and Open Questions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376723},
doi = {10.1145/3313831.3376723},
abstract = {Self-Determination Theory (SDT), a major psychological theory of human motivation, has become increasingly popular in Human-Computer Interaction (HCI) research on games and play. However, it remains unclear how SDT has advanced HCI games research, or how HCI games scholars engage with the theory. We reviewed 110 CHI and CHI PLAY papers that cited SDT to gain a better understanding of the ways the theory has contributed to HCI games research. We find that SDT, and in particular, the concepts of need satisfaction and intrinsic motivation, have been widely applied to analyse the player experience and inform game design. Despite the popularity of SDT-based measures, however, prominent core concepts and mini-theories are rarely considered explicitly, and few papers engage with SDT beyond descriptive accounts. We highlight conceptual gaps at the intersection of SDT and HCI games research, and identify opportunities for SDT propositions, concepts, and measures to more productively inform future work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–22},
numpages = {22},
keywords = {games, play, self-determination theory, motivation, gamification, player experience, theory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376201,
author = {Zhou, Rui and DiSalvo, Betsy},
title = {User's Role in Platform Infrastructuralization: WeChat as an Exemplar},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376201},
doi = {10.1145/3313831.3376201},
abstract = {Recent years have witnessed the rise of platforms such as Facebook and Google. Gigantic in scope and becoming omnipresent, these platforms are acquiring qualities of infrastructure, which is large-scale connected systems that support people's activities invisibly. Recent scholarship has identified WeChat, the most popular mobile social platform in China, as infrastructure. WeChat follows a platform logic to expand, and by conforming to the Chinese government's techno-nationalist focus, it has gradually become an infrastructure in China. We contribute to the understanding of platform infrastructuralization by taking WeChat as a case, highlighting the user's role in this process. We find user contributes to WeChat's infrastructuralization through a three-level interaction process: to practice, to appropriate, and to create. By calling out the user's role in platform infra-structuralization, we discuss how the CHI community can contribute to a better understanding of this phenomenon.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {platform, social network, user, wechat, infrastructure, china},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376791,
author = {Naiakshina, Alena and Danilova, Anastasia and Gerlitz, Eva and Smith, Matthew},
title = {On Conducting Security Developer Studies with CS Students: Examining a Password-Storage Study with CS Students, Freelancers, and Company Developers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376791},
doi = {10.1145/3313831.3376791},
abstract = {Ecological validity is a major concern in usable security studies with developers. Many studies are conducted with computer science (CS) students out of convenience, since recruiting professional software developers in sufficient numbers is very challenging. In a password-storage study, Naiakshina et al. (CHI'19) showed that CS students behave similarly to freelance developers recruited online. While this is a promising result for conducting developer studies with students, an open question remains: Do professional developers employed in companies behave similarly as well? To provide more insight into the ecological validity of recruiting students for security developer studies, we replicated the study of Naiakshina et al. with developers from diverse companies in Germany. We found that developers employed in companies performed better than students and freelancers in a direct comparison. However, treatment effects were found to be significant in all groups; the treatment effects on CS students also held for company developers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {usable security and privacy, developer password study, student developer, security developer study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376522,
author = {Murad, Christine and Munteanu, Cosmin},
title = {Designing Voice Interfaces: Back to the (Curriculum) Basics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376522},
doi = {10.1145/3313831.3376522},
abstract = {Voice user interfaces (VUIs) are rapidly increasing in popularity in the consumer space. This leads to a concurrent explosion of available applications for such devices, with many industries rushing to offer voice interactions for their products. This pressure is then transferred to interface designers; however, a large majority of designers have been only trained to handle the usability challenges specific to Graphical User Interfaces (GUIs). Since VUIs differ significantly in design and usability from GUIs, we investigate in this paper the extent to which current educational resources prepare designers to handle the specific challenges of VUI design. For this, we conducted a preliminary scoping scan and syllabi meta review of HCI curricula at more than twenty top international HCI departments, revealing that the current offering of VUI design training within HCI education is rather limited. Based on this, we advocate for the updating of HCI curricula to incorporate VUI design, and for the development of VUI-specific pedagogical artifacts to be included in new curricula.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {voice user interface, conversational interface, speech, hci education, vui design, hci curriculum},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376351,
author = {Tancred, Nicoletta and Turkay, Selen and Vickery, Nicole and Wyeth, Peta and McCoombe, Anna},
title = {Understanding Women Modders Using the Serious Leisure Perspective},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376351},
doi = {10.1145/3313831.3376351},
abstract = {Modding, the act of custom creation in videogames, is a large enterprise comprising millions of people. Despite the large number of individuals creating mods, our understanding of who modders are and their motivation for modding is limited. This is especially true for minority groups, including women. In prior research with modding communities, women modders were consistently underrepresented. Using a mixed-method survey (N = 68) that incorporates the Serious Leisure Framework, this study begins to unravel women's participation in modding activities. We begin to identify who women modders are, examine what motivates them to mod, and investigate their modding practices. Results show that women modders value the creation of multiple mod types, including cosmetic, environmental and gameplay modification. They are primarily motivated by self-gratification and enjoyment. These findings create new insights into how women interact with gaming environments, as well as identifying those aspects of the experience that motivate women's engagement in modding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {women modding, modders, modding, serious leisure, custom content, video games, game modifications},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376871,
author = {McNaney, Roisin and Tsekleves, Emmanuel and Synnott, Jonathan},
title = {Future Opportunities for IoT to Support People with Parkinson's},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376871},
doi = {10.1145/3313831.3376871},
abstract = {Recent years have seen an explosion of internet of things (IoT) technologies being released to the market. There has also been an emerging interest in the potentials of IoT devices to support people with chronic health conditions. In this paper, we describe the results of engagements to scope the future potentials of IoT for supporting people with Parkinson's (PwP). We ran a 2-day multi-disciplinary event with professionals with expertise in Parkinson's and IoT, to explore the opportunities, challenges and benefits. We then ran 4 workshops, engaging 13 PwP and caregivers, to scope out the needs, values and desires that the community has for utilizing IoT to monitor their symptoms. This work contributes considerations for future IoT solutions that might support PwP in better understanding their condition, through the provision of objective measurements that correspond to their, currently unmeasured, subjective experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {self-monitoring, quantified self, design, iot, parkinson's},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376170,
author = {Evans, Hayley and Lakshmi, Udaya and Watson, Hue and Ismail, Azra and Sherrill, Andrew M. and Kumar, Neha and Arriaga, Rosa I.},
title = {Understanding the Care Ecologies of Veterans with PTSD},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376170},
doi = {10.1145/3313831.3376170},
abstract = {Post-traumatic stress disorder (PTSD) disproportionately affects United States veterans, yet they may be reluctant to seek or engage in care. We interview 21 participants, including veterans with PTSD, clinicians who treat veterans and friends and family that support veterans through mental health ordeals. We investigate the military identity these veterans share. We explore how this may add to their reluctance in care-seeking behaviors. We also explore the roles of human and non-human intermediaries in ecologies of care and the potential for enhancing patient empowerment in current clinical treatment contexts. We discuss how military culture can be utilized in clinical care, how multiple perspectives can be leveraged to create a more holistic view of the patient, and finally, how veterans can be empowered during treatment. We conclude with recommendations for the design of sociotechnical systems that prioritize the above in support of the mental well-being of veterans with PTSD.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mental health, care ecologies, veteran care, treatment, therapy, ptsd},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376145,
author = {Reinders, Samuel and Butler, Matthew and Marriott, Kim},
title = {"Hey Model!" – Natural User Interactions and Agency in Accessible Interactive 3D Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376145},
doi = {10.1145/3313831.3376145},
abstract = {While developments in 3D printing have opened up opportunities for improved access to graphical information for people who are blind or have low vision (BLV), they can provide only limited detailed and contextual information. Interactive 3D printed models (I3Ms) that provide audio labels and/or a conversational agent interface potentially overcome this limitation. We conducted a Wizard-of-Oz exploratory study to uncover the multi-modal interaction techniques that BLV people would like to use when exploring I3Ms, and investigated their attitudes towards different levels of model agency. These findings informed the creation of an I3M prototype of the solar system. A second user study with this model revealed a hierarchy of interaction, with BLV users preferring tactile exploration, followed by touch gestures to trigger audio labels, and then natural language to fill in knowledge gaps and confirm understanding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {individuals with disabilities &amp; assistive technologies, accessibility, touch/haptic/pointing/gesture, input techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376564,
author = {Mudliar, Preeti},
title = {Whither Humane-Computer Interaction? Adult and Child Value Conflicts in the Biometric Fingerprinting for Food},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376564},
doi = {10.1145/3313831.3376564},
abstract = {This paper reports on the value conflicts that beneficiaries experience when engaging in the monthly ritual of the biometric authentication of their fingerprints to claim state-sponsored food entitlements in India. Drawing on value-based orientations to HCI inquiry, the study locates the interactions around the biometric process to illustrate the ways in which beneficiaries find their values of time, dignity, and privacy, consistently disregarded by the interactive demands of the biometric system. Additionally, to cope with these value conflicts, some beneficiaries pass on the responsibilities of completing the biometric process to the children in their families. While adult beneficiaries are vocal and articulate about the value tensions in their lives, children cope with the anxieties of interacting with the biometric process, silently; even as they experience conflicts in their education, play, and study time.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social justice, values, aadhaar, biometrics, food security},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376692,
author = {Mlakar, Sara and Haller, Michael},
title = {Design Investigation of Embroidered Interactive Elements on Non-Wearable Textile Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376692},
doi = {10.1145/3313831.3376692},
abstract = {As smart textiles are becoming more present in our lives, investigating and designing textile interfaces has started getting more and more attention. Still, very little research has been done on how to design interactive elements for non-wearable textile interfaces for the best recognition, perception, and interaction. In this paper, we present initial assumptions for designing such interfaces, which we derived from working intensively with our partners from the industry. These have been further explored with experts from the field during interviews, and finally tested in a user study. As a conclusion of the study, we define five design recommendations for textile interfaces and present several prototypes that demonstrate them in practice. Our recommendations cover tactile contrast between textures, heights, and shapes; minimal recognizable size of elements; perception of concave and convex shapes as interactive elements; indication of interaction through shape; and recognition of tactile symbols.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {expert interviews, user study, textile interfaces, embroidery, non-wearables, smart textiles, design recommendations},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376502,
author = {Salminen, Joni and Guan, Kathleen and Jung, Soon-Gyo and Chowdhury, Shammur A. and Jansen, Bernard J.},
title = {A Literature Review of Quantitative Persona Creation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376502},
doi = {10.1145/3313831.3376502},
abstract = {Quantitative persona creation (QPC) has tremendous potential, as HCI researchers and practitioners can leverage user data from online analytics and digital media platforms to better understand their users and customers. However, there is a lack of a systematic overview of the QPC methods and progress made, with no standard methodology or known best practices. To address this gap, we review 49 QPC research articles from 2005 to 2019. Results indicate three stages of QPC research: Emergence, Diversification, and Sophistication. Sharing resources, such as datasets, code, and algorithms, is crucial to achieving the next stage (Maturity). For practitioners, we provide guiding questions for assessing QPC readiness in organizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {quantitative persona creation, literature review, personas},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376770,
author = {Salminen, Joni and Jung, Soon-Gyo and Chowdhury, Shammur and Seng\"{u}n, Sercan and Jansen, Bernard J.},
title = {Personas and Analytics: A Comparative User Study of Efficiency and Effectiveness for a User Identification Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376770},
doi = {10.1145/3313831.3376770},
abstract = {Personas are a well-known technique in human computer interaction. However, there is a lack of rigorous empirical research evaluating personas relative to other methods. In this 34-participant experiment, we compare a persona system and an analytics system, both using identical user data, for efficiency and effectiveness for a user identification task. Results show that personas afford faster task completion than the analytics system, as well as outperforming analytics with significantly higher user identification accuracy. Qualitative analysis of think-aloud transcripts shows that personas have other benefits regarding learnability and consistency. However, the analytics system affords insights and capabilities that personas cannot due to inherent design differences. Findings support the use of personas to learn about users, empirically confirming some of the stated benefits in the literature, while also highlighting the limitations of personas that may necessitate the use of accompanying methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {analytics systems, personas, mixed methods},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376599,
author = {Semertzidis, Nathan and Scary, Michaela and Andres, Josh and Dwivedi, Brahmi and Kulwe, Yutika Chandrashekhar and Zambetta, Fabio and Mueller, Florian Floyd},
title = {Neo-Noumena: Augmenting Emotion Communication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376599},
doi = {10.1145/3313831.3376599},
abstract = {The subjective experience of emotion is notoriously difficult to interpersonally communicate. We believe that technology can challenge this notion through the design of neuroresponsive systems for interpersonal communication. We explore this through "Neo-Noumena", a communicative neuroresponsive system that uses brain-computer interfacing and artificial intelligence to read one's emotional states and dynamically represent them to others in mixed reality through two head-mounted displays. In our study five participant pairs were given Neo-Noumena for three days, using the system freely. Measures of emotional competence demonstrated a statistically significant increase in participants' ability to interpersonally regulate emotions. Furthermore, participant interviews revealed themes regarding Spatiotemporal Actualization, Objective Representation, and Preternatural Transmission. We also suggest design strategies for future augmented emotion communication systems. We intend that work gives guidance towards a future in which our ability to interpersonally communicate emotion is augmented beyond traditional experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {emotion communication, mixed reality, brain-computer interfacing, machine learning, eeg, emotion recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376549,
author = {Trieu, Penny and Baym, Nancy K.},
title = {Private Responses for Public Sharing: Understanding Self-Presentation and Relational Maintenance via Stories in Social Media},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376549},
doi = {10.1145/3313831.3376549},
abstract = {With nearly two billion users, social media Stories-an ephemeral format of sharing-are increasingly popular and projected to overtake sharing via public feeds. Sharing via Stories differs from Feeds sharing by removing the visible feedback (e.g. "likes" and "comments") which has come to characterize social media. Given the salience of responses visibility to self-presentation and relational maintenance in social media literature, we conducted semi-structured interviews (N = 22) to explore how people understand these processes when using Stories. We find that users have lower expectations for responses with Stories and experience lower pressure for self-presentation. This fosters more frequent sharing and a sense of daily connectedness, which strong ties can find valuable. Finally, the act of viewing takes on new significance of signaling attention when made known to the sharer. Our findings point to the importance of effort and attention in understanding responses on social media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social media, self-presentation, stories, relational maintenance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376278,
author = {Chapko, Dorota and Frumiento, Pino and Edwards, Nalini and Emeh, Lizzie and Kennedy, Donald and McNicholas, David and Overton, Michaela and Snead, Mark and Steward, Robyn and Sutton, Jenny M. and Jeffreys, Evie and Long, Catherine and Croll-Knight, Jess and Connors, Ben and Castell-Ward, Sam and Coke, David and McPeake, Bethany and Renel, William and McGinley, Chris and Remington, Anna and Whittuck, Dora and Kieffer, John and Ewans, Sarah and Williams, Mark and Grierson, Mick},
title = {"We Have Been Magnified for Years - Now You Are under the Microscope!": Co-Researchers with Learning Disabilities Created an Online Survey to Challenge Public Understanding of Learning Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376278},
doi = {10.1145/3313831.3376278},
abstract = {Public attitudes towards learning disabilities (LDs) are generally reported as positive, inclusive and empathetic. However, these findings do not reflect the lived experiences of people with LDs. To shed light on this disparity, a team of co-researchers with LDs created the first online survey to challenge public understanding of LDs, asking questions in ways that are important to them and represent how they see themselves. Here, we describe and evaluate the process of creating an accessible survey platform and an online survey in a research team consisting of academic and non-academic professionals with and without LDs or autism. Through this inclusive research process, the co-designed survey met the expectations of the co-researchers and was well-received by the initial survey respondents. We reflect on the co-researchers' perspectives following the study completion, and consider the difficulties and advantages we encountered deploying such approaches and their potential implications on future survey data analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {disability, design, attitudes, video, survey, participatory/inclusive research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376267,
author = {Tigwell, Garreth W. and Gorman, Benjamin M. and Menzies, Rachel},
title = {Emoji Accessibility for Visually Impaired People},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376267},
doi = {10.1145/3313831.3376267},
abstract = {Emoji are graphical symbols that appear in many aspects of our lives. Worldwide, around 36 million people are blind and 217 million have a moderate to severe visual impairment. This portion of the population may use and encounter emoji, yet it is unclear what accessibility challenges emoji introduce. We first conducted an online survey with 58 visually impaired participants to understand how they use and encounter emoji online, and the challenges they experience. We then conducted 11 interviews with screen reader users to understand more about the challenges reported in our survey findings. Our interview findings demonstrate that technology is both an enabler and a barrier, emoji descriptors can hinder communication, and therefore the use of emoji impacts social interaction. Using our findings from both studies, we propose best practice when using emoji and recommendations to improve the future accessibility of emoji for visually impaired people.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visual impairments, accessibility, emoji, cmc},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376870,
author = {Yuan, Arianna and Li, Yang},
title = {Modeling Human Visual Search Performance on Realistic Webpages Using Analytical and Deep Learning Methods},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376870},
doi = {10.1145/3313831.3376870},
abstract = {Modeling visual search not only offers an opportunity to predict the usability of an interface before actually testing it on real users but also advances scientific understanding about human behavior. In this work, we first conduct a set of analyses on a large-scale dataset of visual search tasks on realistic webpages. We then present a deep neural network that learns to predict the scannability of webpage content, i.e., how easy it is for a user to find a specific target. Our model leverages both heuristic-based features such as target size and unstructured features such as raw image pixels. This approach allows us to model complex interactions that might be involved in a realistic visual search task, which can not be achieved by traditional analytical models. We analyze the model behavior to offer our insights into how the salience map learned by the model aligns with human intuition.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual attention, performance modeling, deep learning, convolutional neural network, webpage, scannability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376653,
author = {Tuli, Anupriya and Chopra, Shaan and Singh, Pushpendra and Kumar, Neha},
title = {Menstrual (Im)Mobilities and Safe Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376653},
doi = {10.1145/3313831.3376653},
abstract = {In cultural contexts where menstruation is a stigmatized health topic, daily management of menstrual hygiene comes with its set of challenges. Our research aims to identify and examine such challenges faced during menstruation in the urban environs of Delhi, India. Through participatory design activities and interviews conducted with 35 participants who identified as menstruating and female, and a survey with 139 responses, we investigate how participants deal with their periods on the go. We also examine participants' conceptualizations of safe spaces, where they are able to deal with their period on their own terms. Finally, we discuss how menstrual mobilities are being, and might be, supported through technology-based interventions for a third space, targeting the legibility, literacy, and legitimacy of surrounding environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {safe spaces, menstrual hygiene, mobilities, menstrual health, menstruation, india, hci4d},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376315,
author = {Strengers, Yolande and Qu, Lizhen and Xu, Qiongkai and Knibbe, Jarrod},
title = {Adhering, Steering, and Queering: Treatment of Gender in Natural Language Generation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376315},
doi = {10.1145/3313831.3376315},
abstract = {Natural Language Generation (NLG) supports the creation of personalized, contextualized, and targeted content. However, the algorithms underpinning NLG have come under scrutiny for reinforcing gender, racial, and other problematic biases. Recent research in NLG seeks to remove these biases through principles of fairness and privacy. Drawing on gender and queer theories from sociology and Science and Technology studies, we consider how NLG can contribute towards the advancement of gender equity in society. We propose a conceptual framework and technical parameters for aligning NLG with feminist HCI qualities. We present three approaches: (1) adhering to current approaches of removing sensitive gender attributes, (2) steering gender differences away from the norm, and (3) queering gender by troubling stereotypes. We discuss the advantages and limitations of these approaches across three hypothetical scenarios; newspaper headlines, job advertisements, and chatbots. We conclude by discussing considerations for implementing this framework and related ethical and equity agendas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {natural language generation, feminist hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376842,
author = {Goffin, Pascal and Blascheck, Tanja and Isenberg, Petra and Willett, Wesley},
title = {Interaction Techniques for Visual Exploration Using Embedded Word-Scale Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376842},
doi = {10.1145/3313831.3376842},
abstract = {We describe a design space of view manipulation interactions for small data-driven contextual visualizations (word-scale visualizations). These interaction techniques support an active reading experience and engage readers through exploration of embedded visualizations whose placement and content connect them to specific terms in a document. A reader could, for example, use our proposed interaction techniques to explore word-scale visualizations of stock market trends for companies listed in a market overview article. When readers wish to engage more deeply with the data, they can collect, arrange, compare, and navigate the document using the embedded word-scale visualizations, permitting more visualization-centric analyses. We support our design space with a concrete implementation, illustrate it with examples from three application domains, and report results from two experiments. The experiments show how view manipulation interactions helped readers examine embedded visualizations more quickly and with less scrolling and yielded qualitative feedback on usability and future opportunities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interaction techniques, text visualization, word-scale visualization, glyphs, information visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376410,
author = {Tholander, Jakob and Normark, Maria},
title = {Crafting Personal Information - Resistance, Imperfection, and Self-Creation in Bullet Journaling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376410},
doi = {10.1145/3313831.3376410},
abstract = {Bullet journals are hand-written and self-created combinations of calendar, journal and planner. Central to this practice is how personal information is managed through a craft-based process. Based on a qualitative study, we discuss a set of themes that emerged in our analysis of this practice. We discuss how open-ended use of various materials for crafting of personal information engages in: 1) deliberate and strategic boundary work of what information to include and how combinations of data provide holistic and novel views of practitioner's life situations; 2) processes of self-creation and reflection on personal life trajectories; 3) appreciation of ourselves and the world around us as imperfect; and 4) ways of resisting the "business-like efficiency" that come with the large quantities of information that permeate contemporary life. We propose that this opens up new directions for thinking about how technologies of personal information may come into play in people's lives.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {imperfection, analogue materials, personal informatics, making by hand, bullet journaling, self-creation, crafts},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376532,
author = {Parker, Callum and Tomitsch, Martin and Davies, Nigel and Valkanova, Nina and Kay, Judy},
title = {Foundations for Designing Public Interactive Displays That Provide Value to Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376532},
doi = {10.1145/3313831.3376532},
abstract = {Public interactive displays (PID) are a promising technology for providing information and collecting feedback in public spaces. Research on PIDs has shown that, like all public displays, their efficacy is reduced by display blindness. Rather than increase the visual attention-grabbing nature of PIDs, we propose that additional understanding is required around how and when these displays are able to offer value to users. We tackle this through a systematic analysis of PID studies published in the literature, which led to 9 aspects of value across 4 factors: people, location, community, and time. We discuss the identified aspects and their utility for the design of PIDs through a review of our own deployments carried out by 4 different labs across 5 countries. We conclude with a set of recommendations for identifying and optimising the intended value of future PIDs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {literature review, public interactive displays, design recommendations, in-the-wild, value, public displays, deployments},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376617,
author = {Zhu, Junyi and Blumberg, Lotta-Gili and Zhu, Yunyi and Nisser, Martin and Carlson, Ethan Levi and Wen, Xin and Shum, Kevin and Quaye, Jessica Ayeley and Mueller, Stefanie},
title = {CurveBoards: Integrating Breadboards into Physical Objects to Prototype Function in the Context of Form},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376617},
doi = {10.1145/3313831.3376617},
abstract = {CurveBoards are breadboards integrated into physical objects. In contrast to traditional breadboards, CurveBoards better preserve the object's look and feel while maintaining high circuit fluidity, which enables designers to exchange and reposition components during design iteration. Since CurveBoards are fully functional, i.e., the screens are displaying content and the buttons take user input, designers can test interactive scenarios and log interaction data on the physical prototype while still being able to make changes to the component layout and circuit design as needed. We present an interactive editor that enables users to convert 3D models into CurveBoards and discuss our fabrication technique for making CurveBoard prototypes. We also provide a technical evaluation of CurveBoard's conductivity and durability and summarize informal user feedback.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personal fabrication, breadboards, electronic prototyping},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376826,
author = {Hansen, Derek L. and Hughes, Amanda Lee and Cram, Sophie and Harker, Austin Bond and Ashton, Brinnley and Hirschi, Karli and Dorton, Ben and Bothwell, Nate and Stevens, Ashley},
title = {The DELAY Framework: Designing for Extended LAtencY},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376826},
doi = {10.1145/3313831.3376826},
abstract = {This paper introduces the Designing for Extended Latency (DELAY) Framework meant to inspire new systems that support social interaction in high-latency settings such as interplanetary communication, intermittent internet access, and time-zone incompatibilities. The framework includes six dimensions: Goal, Communication Genre, Sequencing, Cardinality, Mutability, and Responsiveness. We describe the iterative design process used to create the Framework, as well as three novel prototypes designed to increase social connectedness and social presence in high-latency situations: 1) the InSync app that allows partners to perform activities simultaneously even though they only see proof of their synchronicity later; 2) the After the Beep system that lets users leave IoT messages that are triggered by the recipients; and 3) the Surrogate platform where players play group battle games against "surrogate" artificial intelligence avatars that mimic unavailable individuals. Data from two design workshops validates the usefulness of the framework for generating new solutions to high-latency scenarios.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interplanetary communication, delayed communication, social connectedness, delay framework, high-latency, social presence, interpersonal communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376364,
author = {Pschetz, Larissa and Dixon, Billy and Pothong, Kruakae and Bailey, Arlene and Glean, Allister and Soares, Luis Louren\c{c}o and Enright, Jessica A.},
title = {Designing Distributed Ledger Technologies for Social Change: The Case of CariCrop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376364},
doi = {10.1145/3313831.3376364},
abstract = {Distributed ledger technologies (DLTs) have been celebrated for promoting transparency, trust, and efficiency in several domains. However, recent research has also pointed out the potential of these technologies to increase power asymmetries and deepen social inequality. In this paper, we contribute to this discussion by reporting on a collective effort of academics, development partners, local authorities, businesses, and farming groups to look at the potential of DLTs, particularly Blockchains, to support socio-economic development in rural communities in the Caribbean. We present a series of design concepts resulting from this effort and reflect on a method to facilitate stakeholders' experience of possible implementations and enable them to voice concerns, preferences, and expectations. Results from workshops with different groups of stakeholders contribute insights into opportunities and limitations of these applications to enable social development and to level the playing field in agricultural exchanges in developing countries.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {farming, agricultural development, distributed ledger technologies, blockchain},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376429,
author = {Biggs, Heidi R. and Desjardins, Audrey},
title = {High Water Pants: Designing Embodied Environmental Speculation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376429},
doi = {10.1145/3313831.3376429},
abstract = {In this paper, we present the High Water Pants: speculative wearable technology which makes climate change tangible for everyday cyclists. The pants work by mechanically shortening when a cyclist wearing the pants enters an area of Seattle, USA, which is projected to be impacted by sea-level rise in 30-80 years. This interaction 'bends time' by allowing cyclists to feel future climate change data in the present. First, we discuss the research through design process of creating the High Water Pants including foundational research, a description of the design concept and results of a preliminary study with the pants. Second, we discuss three implications of the pants for human-computer interaction (HCI): (1) they offer the concept of a 'present/future' paradigm for embodied speculation, (2) our research process demonstrates how to successfully involve more-than-human perspectives, and (3) we articulate how the High Water Pants respond to shifts in HCI's framing of sustainability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cycling, speculative design, research through design, sustainability, wearables, embodied speculation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376756,
author = {Ku, Pin-Sung and Gong, Jun and Wu, Te-Yen and Wei, Yixin and Tang, Yiwen and Ens, Barrett and Yang, Xing-Dong},
title = {Zippro: The Design and Implementation of An Interactive Zipper},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376756},
doi = {10.1145/3313831.3376756},
abstract = {Zippers are common in a wide variety of objects that we use daily. This work investigates how we can take advantage of such common daily activities to support seamless interaction with technology. We look beyond simple zipper-sliding interactions explored previously to determine how to weave foreground and background interactions into a vocabulary of natural usage patterns. We begin by conducting two user studies to understand how people typically interact with zippers. The findings identify several opportunities for zipper input and sensing, which inform the design of Zippro, a self-contained prototype zipper slider, which we evaluate with a standard jacket zipper. We conclude by demonstrating several applications that make use of the identified foreground and background input methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wearable, zipper, smart things},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376779,
author = {Ku, Pin-Sung and Shao, Qijia and Wu, Te-Yen and Gong, Jun and Zhu, Ziyan and Zhou, Xia and Yang, Xing-Dong},
title = {ThreadSense: Locating Touch on an Extremely Thin Interactive Thread},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376779},
doi = {10.1145/3313831.3376779},
abstract = {We propose a new sensing technique for one-dimensional touch input workable on an interactive thread of less than 0.4 mm thick. Our technique locates up to two touches using impedance sensing with a spacing resolution unachievable by the existing methods. Our approach is also unique in that it locates a touch based on a mathematical model describing the change in thread impedance in relation to the touch locations. This allows the system to be easily calibrated by the user touching a known location(s) on the thread. The system can thus quickly adapt to various environmental settings and users. A system evaluation showed that our system could track the slide motion of a finger with an average error distance of 6.13 mm and 4.16 mm using one and five touches for calibration, respectively. The system could also distinguish between single touch and two concurrent touches with an accuracy of 99% and could track two concurrent touches with an average error distance of 8.55 mm. We demonstrate new interactions enabled by our sensing approach in several unique applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touch input, fabric, impedance sensing, thread},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376474,
author = {Hudson, Lorraine and Amponsah, Clement and Bampoe, Josephine Ohenewa and Marshall, Julie and Owusu, Nana Akua Victoria and Hussein, Khalid and Linington, Jess and Banks Gross, Zoe and Stokes, Jane and McNaney, R\'{o}is\'{\i}n},
title = {Co-Designing Digital Tools to Enhance Speech and Language Therapy Training in Ghana},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376474},
doi = {10.1145/3313831.3376474},
abstract = {Ghana has a population of over 27 million people, of which 1 in 15 may have a communication disability. The number of speech and language therapists (SLTs) available to support these people remains remarkably small, presenting a major workforce challenge. As an emerging profession, there remain significant challenges around educating the first generation of SLTs. Ghana, however, has a healthy digital infrastructure which can be taken advantage of. We describe a comprehensive study which aimed to co-design a set of locally appropriate digital tools to enhance SLT training in Ghana. We contribute insights into how digital tools could support social learning and the transition from student to independent practitioner and future clinical supervisor. We offer a set of design recommendations for creating an online Community of Practice to enhance continuing professional development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile learning, speech and language therapy, co-design, ghana},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376181,
author = {Kong, Ha-Kyung and Karahalios, Karrie},
title = {Addressing Cognitive and Emotional Barriers in Parent-Clinician Communication through Behavioral Visualization Webtools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376181},
doi = {10.1145/3313831.3376181},
abstract = {Effective communication between clinicians and parents of young children with developmental delays can decrease parents' anxiety, help them handle bad news, and improve their adherence to proposed interventions. However, parents have reported dissatisfaction regarding their current communication with clinicians, and they face cognitive and emotional challenges when discussing their child's developmental delays. In this paper, we present visualization as a facilitator of parent-clinician communication and how it could address existing communication challenges. Parents and clinicians anticipated visualization webtools would aid their communication by helping parents gain a better understanding of their child, acting as objective evidence, and highlighting the strength of the child as well as important medical concepts. In addition, visualization can act as a longitudinal record, helping parents track, explore, and share their child's developmental progress. Finally, we propose visualization as a tool to guide parents in their transition from feeling emotional and disempowered to advocating with confidence.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {developmental delays, visualization, clinical communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376132,
author = {Wang, Bryan and Grossman, Tovi},
title = {BlyncSync: Enabling Multimodal Smartwatch Gestures with Synchronous Touch and Blink},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376132},
doi = {10.1145/3313831.3376132},
abstract = {Input techniques have been drawing abiding attention along with the continual miniaturization of personal computers. In this paper, we present BlyncSync, a novel multi-modal gesture set that leverages the synchronicity of touch and blink events to augment the input vocabulary of smartwatches with a rapid gesture, while at the same time, offers a solution to the false activation problem of blink-based input. BlyncSync contributes the concept of a mutual delimiter, where two modalities are used to jointly delimit the intention of each other's input. A study shows that BlyncSync is 33% faster than using a baseline input delimiter (physical smartwatch button), with only 150ms in overhead cost compared to traditional touch events. Furthermore, our data indicates that the gesture can be tuned to elicit a true positive rate of 97% and a false positive rate of 1.68%.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {blyncsync, smartwatch, mobile hci, gaze ui, wearables, mutual delimiter},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376479,
author = {Mayer, Sven and Laput, Gierad and Harrison, Chris},
title = {Enhancing Mobile Voice Assistants with WorldGaze},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376479},
doi = {10.1145/3313831.3376479},
abstract = {Contemporary voice assistants require that objects of inter-est be specified in spoken commands. Of course, users are often looking directly at the object or place of interest ? fine-grained, contextual information that is currently unused. We present WorldGaze, a software-only method for smartphones that provides the real-world gaze location of a user that voice agents can utilize for rapid, natural, and precise interactions. We achieve this by simultaneously opening the front and rear cameras of a smartphone. The front-facing camera is used to track the head in 3D, including estimating its direction vector. As the geometry of the front and back cameras are fixed and known, we can raycast the head vector into the 3D world scene as captured by the rear-facing camera. This allows the user to intuitively define an object or region of interest using their head gaze. We started our investigations with a qualitative exploration of competing methods, before developing a functional, real-time implementation. We conclude with an evaluation that shows WorldGaze can be quick and accurate, opening new multimodal gaze+voice interactions for mobile voice agents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {worldgaze, mobile interaction, interaction techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376238,
author = {Liang, Yuan and Fan, Hsuan Wei and Fang, Zhujun and Miao, Leiying and Li, Wen and Zhang, Xuan and Sun, Weibin and Wang, Kun and He, Lei and Chen, Xiang 'Anthony'},
title = {OralCam: Enabling Self-Examination and Awareness of Oral Health Using a Smartphone Camera},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376238},
doi = {10.1145/3313831.3376238},
abstract = {Due to a lack of medical resources or oral health awareness, oral diseases are often left unexamined and untreated, affecting a large population worldwide. With the advent of low-cost, sensor-equipped smartphones, mobile apps offer a promising possibility for promoting oral health. However, to the best of our knowledge, no mobile health (mHealth) solutions can directly support a user to self-examine their oral health condition. This paper presents OralCam, the first interactive app that enables end-users' self-examination of five common oral conditions (diseases or early disease signals) by taking smartphone photos of one's oral cavity. OralCam allows a user to annotate additional information (e.g. living habits, pain, and bleeding) to augment the input image, and presents the output hierarchically, probabilistically and with visual explanations to help a laymen user understand examination results. Developed on our in-house dataset that consists of 3,182 oral photos annotated by dental experts, our deep learning based framework achieved an average detection sensitivity of 0.787 over five conditions with high localization accuracy. In a week-long in-the-wild user study (N=18), most participants had no trouble using OralCam and interpreting the examination results. Two expert interviews further validate the feasibility of OralCam for promoting users' awareness of oral health.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {artificial intelligence, mobile health, deep learning, oral health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376856,
author = {Tigwell, Garreth W. and Crabb, Michael},
title = {Household Surface Interactions: Understanding User Input Preferences and Perceived Home Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376856},
doi = {10.1145/3313831.3376856},
abstract = {Households contain a variety of surfaces that are used in a number of activity contexts. As ambient technology becomes commonplace in our homes, it is only a matter of time before these surfaces become linked to computer systems for Household Surface Interaction (HSI). However, little is known about the user experience attached to HSI, and the potential acceptance of HSI within modern homes. To address this problem, we ran a mixed methods user study with 39 participants to examine HSI using nine household surfaces and five common gestures (tap, press, swipe, drag, and pinch). We found that under the right conditions, surfaces with some amount of texture can enhance HSI. Furthermore, perceived good and poor user experience varied among participants for surface type indicating individual preferences. We present findings and design considerations based on surface characteristics and the challenges that users perceive they may have with HSI within their homes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {surface texture, user experience, materiality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376248,
author = {Hsu, Chen-Yuan and Wei, Li-Yi and You, Lihua and Zhang, Jian Jun},
title = {Autocomplete Element Fields},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376248},
doi = {10.1145/3313831.3376248},
abstract = {Aggregate elements are ubiquitous in natural and man-made objects. Interactively authoring these elements with varying anisotropy and deformability can require high artistic skills and manual labor. To reduce input workload and enhance output quality, we present an autocomplete system that can help users distribute and align such elements over different domains. Through a brushing interface, users can place and mix a few elements, and let our system automatically populate more elements for the remaining output. Furthermore, aggregate elements often require proper direction/scalar fields for proper arrangements, but fully specifying such fields across entire domains can be difficult or inconvenient for ordinary users. To address this usability challenge, we formulate element fields that can smoothly orient all the elements based on partial user specifications without requiring full input fields in any step. We validate our prototype system with a pilot user study and show applications in design, collage, and modeling.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {element, field, interface, synthesis, modeling, anisotropy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376342,
author = {Desjardins, Audrey and Biggs, Heidi R. and Key, Cayla and Viny, Jeremy E.},
title = {IoT Data in the Home: Observing Entanglements and Drawing New Encounters},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376342},
doi = {10.1145/3313831.3376342},
abstract = {Internet of Things (IoT) technologies for the home are gaining in popularity, generating exponential data byproducts. Yet, everyday relationships between home dwellers and domestic IoT data often remain secondary interactions, preventing deeper understanding and awareness of data tracked in the home. Our paper offers a design ethnography and design inquiry which examine these human-data entanglements. Findings from working with 10 inhabitants who interact with their IoT data illustrate five characteristics of current data encounters: manifesting, inquiring, exposing, repositioning, and broadening. In response, we used speculative sketches to refine, refract and complicate these encounters. We argue that data do not have to be laborious, tidy or the byproduct of a service, but rather lively and affecting. We further suggest new modes of engagement with data which expand or step away from self-improvement and reflection: through diverse acts of noticing, by allowing data to remain invisible, and by embracing imaginative practices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design ethnography, data, internet of things, home, speculative, research-through-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376596,
author = {Barathi, Soumya C. and Proulx, Michael and O'Neill, Eamonn and Lutteroth, Christof},
title = {Affect Recognition Using Psychophysiological Correlates in High Intensity VR Exergaming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376596},
doi = {10.1145/3313831.3376596},
abstract = {User experience estimation of VR exergame players by recognising their affective state could enable us to personalise and optimise their experience. Affect recognition based on psychophysiological measurements has been successful for moderate intensity activities. High intensity VR exergames pose challenges as the effects of exercise and VR headsets interfere with those measurements. We present two experiments that investigate the use of different sensors for affect recognition in a VR exergame. The first experiment compares the impact of physical exertion and gamification on psychophysiological measurements during rest, conventional exercise, VR exergaming, and sedentary VR gaming. The second experiment compares underwhelming, overwhelming and optimal VR exergaming scenarios. We identify gaze fixations, eye blinks, pupil diameter and skin conductivity as psychophysiological measures suitable for affect recognition in VR exergaming and analyse their utility in determining affective valence and arousal. Our findings provide guidelines for researchers of affective VR exergames.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {affect recognition, VR exergaming, high intensity exercise, psychophysiological correlates},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376371,
author = {Yoo, Soojeong and Gough, Phillip and Kay, Judy},
title = {Embedding a VR Game Studio in a Sedentary Workplace: Use, Experience and Exercise Benefits},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376371},
doi = {10.1145/3313831.3376371},
abstract = {Many people, especially those in sedentary occupations, fail to achieve the recommended levels of physical activity. Virtual reality (VR) games have the potential to overcome this because they are fun and also can be physically demanding. This paper explores whether a VR game studio can help workers in sedentary jobs to get valuable levels of exercise. We studied how 11 participants used our VR game studio in a sedentary workplace over 8-weeks and their perceptions of the experience. We analysed the physical exertion in the VR game studio, comparing this to their step counts from a smartwatch. All participants achieved valuable levels of physical activity and mood benefits. Importantly, for 6 participants, only with the VR game studio did they meet recommended activity levels. Our key contributions are insights about the use of a workplace VR game studio and its health benefits.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality game, exercise, sedentary workplace, head-mounted display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376293,
author = {Fan, Jenny and Zhang, Amy X.},
title = {Digital Juries: A Civics-Oriented Approach to Platform Governance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376293},
doi = {10.1145/3313831.3376293},
abstract = {As concerns have grown regarding harmful content spread on social media, platform mechanisms for content moderation have become increasingly significant. However, many existing platform governance structures lack formal processes for democratic participation by users of the platform. Drawing inspiration from constitutional jury trials in many legal systems, this paper proposes digital juries as a civics-oriented approach for adjudicating content moderation cases. Building on existing theoretical models of jury decision-making, we outline a 5-stage model characterizing the space of design considerations in a digital jury process. We implement two examples of jury designs involving blind-voting and deliberation. From users who participate in our jury implementations, we gather informed judgments of the democratic legitimacy of a jury process for content moderation. We find that digital juries are perceived as more procedurally just than existing common platform moderation practices, but also find disagreement over whether jury decisions should be enforced or used as recommendations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {institutional design, content moderation, governance, civics, platforms, online speech, democracy, social media, juries},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376744,
author = {Smith, C. Estelle and Nevarez, Eduardo and Zhu, Haiyi},
title = {Disseminating Research News in HCI: Perceived Hazards, How-To's, and Opportunities for Innovation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376744},
doi = {10.1145/3313831.3376744},
abstract = {Mass media afford researchers critical opportunities to disseminate research findings and trends to the general public. Yet researchers also perceive that their work can be miscommunicated in mass media, thus generating unintended understandings of HCI research by the general public. We conduct a Grounded Theory analysis of interviews with 12 HCI researchers and find that miscommunication can occur at four origins along the socio-technical infrastructure known as the Media Production Pipeline (MPP) for science news. Results yield researchers' perceived hazards of disseminating their work through mass media, as well as strategies for fostering effective communication of research. We conclude with implications for augmenting or innovating new MPP technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {media production pipeline, mass communication, science communications, miscommunication, journalism, mass media, news production},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376129,
author = {Mor, Hila and Yu, Tianyu and Nakagaki, Ken and Miller, Benjamin Harvey and Jia, Yichen and Ishii, Hiroshi},
title = {Venous Materials: Towards Interactive Fluidic Mechanisms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376129},
doi = {10.1145/3313831.3376129},
abstract = {Venous Materials is a novel concept and approach of an interactive material utilizing fluidic channels. We present a design method for fluidic mechanisms that respond to deformation by mechanical inputs from the user, such as pressure and bending. We designed a set of primitive venous structures that act as embedded analog fluidic sensors, displaying flow and color change. In this paper, we consider the fluid as the medium to drive tangible information triggered by deformation, and at the same time, to function as a responsive display of that information. To provide users with a simple way to create and validate designs of fluidic structures, we built a software platform and design tool UI. This design tool allows users to quickly design the geometry, and simulate the flow with intended mechanical force dynamically. We present a range of applications that demonstrate how Venous Materials can be utilized to augment interactivity of everyday physical objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {programmable materials, microfluidics, human material interactions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376166,
author = {Karusala, Naveena and Wang, Ding and O'Neill, Jacki},
title = {Making Chat at Home in the Hospital: Exploring Chat Use by Nurses},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376166},
doi = {10.1145/3313831.3376166},
abstract = {In this paper, we examine WhatsApp use by nurses in India. Globally, personal chat apps have taken the workplace by storm, and healthcare is no exception. In the hospital setting, this raises questions around how chat apps are integrated into hospital work and the consequences of using such personal tools for work. To address these questions, we conducted an ethnographic study of chat use in nurses' work in a large multi-specialty hospital. By examining how chat is embedded in the hospital, rather than focusing on individual use of personal tools, we throw new light on the adoption of personal tools at work — specifically what happens when such tools are adopted and used as though they were organisational tools. In doing so, we explicate their impact on invisible work [77] and the creep of work into personal time, as well as how hierarchy and power play out in technology use. Thus, we point to the importance of looking beyond individual adoption by knowledge workers when studying the impact of personal tools at work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {chat apps, whatsapp, hospital communication, ethnography, nursing, workplace studies, work-life balance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376863,
author = {Jung, Jingun and Lee, Sangyoon and Hong, Jiwoo and Youn, Eunhye and Lee, Geehyuk},
title = {Voice+Tactile: Augmenting In-Vehicle Voice User Interface with Tactile Touchpad Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376863},
doi = {10.1145/3313831.3376863},
abstract = {Promisingly, driving is adapting to a Voice User Interface (VUI) that lets drivers utilize diverse applications with little effort. However, the VUI has innate usability issues, such as a turn-taking problem, a short-term memory workload, inefficient controls, and difficulty correcting errors. To overcome these weaknesses, we explored supplementing the VUI with tactile interaction. As an early result, we present the Voice+Tactile interactions that augment the VUI via multi-touch inputs and high-resolution tactile outputs. We designed various Voice+Tactile interactions to support different VUI interaction stages and derived four Voice+Tactile interaction themes: Status Feedback, Input Adjustment, Output Control, and Finger Feedforward. A user study showed that the Voice+Tactile interactions improved the VUI efficiency and its user experiences without incurring significant additional distraction overhead on driving. We hope these early results open new research questions to improve in-vehicle VUI with a tactile channel.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {voice user interface, tactile feedback touchpad, in-vehicle user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376413,
author = {Pusateri, Juliet and Leng, Judith and Wang, Qian and Chen, Xiangzhu and Hammer, Jessica},
title = {Designing Games for Healthy Sleep},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376413},
doi = {10.1145/3313831.3376413},
abstract = {A sleep deficit has far-reaching consequences, but for many people, healthy sleep is not a priority or a possibility. We explore the potential for "sleepy games" as a genre of transformational games. To explore this design space, we prototyped nine games through an iterative design process. Based on analysis of design decisions and the games as artifacts, we identify seven design challenges for sleepy games: agency and control; physiological and mental arousal; intervention timing; social embeddedness; multisensory experience; vulnerability; and identity and values. We expand on three games with playtesting to show how these design challenges unfold for players in practice, show the impact on players' lives, and discuss sleepy games as creative, social, and situated practices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sleep, games for health, transformational games, game design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376494,
author = {Lerner, Sorin},
title = {Projection Boxes: On-the-Fly Reconfigurable Visualization for Live Programming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376494},
doi = {10.1145/3313831.3376494},
abstract = {Live programming is a regime in which the programming environment provides continual feedback, most often in the form of runtime values. In this paper, we present Projection Boxes, a novel visualization technique for displaying runtime values of programs. The key idea behind projection boxes is to start with a full semantics of the program, and then use projections to pick a subset of the semantics to display. By varying the projection used, projection boxes can encode both previously known visualization techniques, and also new ones. As such, projection boxes provide an expressive and configurable framework for displaying runtime information. Through a user study we demonstrate that (1) users find projection boxes and their configurability useful (2) users are not distracted by the always-on visualization (3) a key driving force behind the need for a configurable visualization for live programming lies with the wide variation in programmer preferences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {program visualization, live programming, programming environment, debugging},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376758,
author = {Jain, Dhruv and Mack, Kelly and Amrous, Akli and Wright, Matt and Goodman, Steven and Findlater, Leah and Froehlich, Jon E.},
title = {HomeSound: An Iterative Field Deployment of an In-Home Sound Awareness System for Deaf or Hard of Hearing Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376758},
doi = {10.1145/3313831.3376758},
abstract = {We introduce HomeSound, an in-home sound awareness system for Deaf and hard of hearing (DHH) users. Similar to the Echo Show or Nest Hub, HomeSound consists of a microphone and display, and uses multiple devices installed in each home. We iteratively developed two prototypes, both of which sense and visualize sound information in real-time. Prototype 1 provided a floorplan view of sound occurrences with waveform histories depicting loudness and pitch. A three-week deployment in four DHH homes showed an increase in participants' home- and self-awareness but also uncovered challenges due to lack of line of sight and sound classification. For Prototype 2, we added automatic sound classification and smartwatch support for wearable alerts. A second field deployment in four homes showed further increases in awareness but misclassifications and constant watch vibrations were not well received. We discuss findings related to awareness, privacy, and display placement and implications for future home sound awareness technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {sound awareness, smart home, deaf and hard of hearing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376702,
author = {McGill, Mark and Brewster, Stephen and McGookin, David and Wilson, Graham},
title = {Acoustic Transparency and the Changing Soundscape of Auditory Mixed Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376702},
doi = {10.1145/3313831.3376702},
abstract = {Auditory headsets capable of actively or passively intermixing both real and virtual sounds are in-part acoustically transparent. This paper explores the consequences of acoustic transparency, both on the perception of virtual audio content, given the presence of a real-world auditory backdrop, and more broadly in facilitating a wearable, personal, private, always-available soundspace. We experimentally compare passive acoustically transparent, and active noise cancelling, orientation-tracked auditory headsets across a range of content types, both indoors and outdoors for validity. Our results show differences in terms of presence, realness and externalization for select content types. Via interviews and a survey, we discuss attitudes toward acoustic transparency (e.g. being perceived as safer), the potential shifts in audio usage that might be precipitated by adoption, and reflect on how such headsets and experiences fit within the area of Mixed Reality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {audio, acoustic transparency, mixed reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376523,
author = {Suzuki, Ryo and Hedayati, Hooman and Zheng, Clement and Bohn, James L. and Szafir, Daniel and Do, Ellen Yi-Luen and Gross, Mark D. and Leithinger, Daniel},
title = {RoomShift: Room-Scale Dynamic Haptics for VR with Furniture-Moving Swarm Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376523},
doi = {10.1145/3313831.3376523},
abstract = {RoomShift is a room-scale dynamic haptic environment for virtual reality, using a small swarm of robots that can move furniture. RoomShift consists of nine shape-changing robots: Roombas with mechanical scissor lifts. These robots drive beneath a piece of furniture to lift, move and place it. By augmenting virtual scenes with physical objects, users can sit on, lean against, place and otherwise interact with furniture with their whole body; just as in the real world. When the virtual scene changes or users navigate within it, the swarm of robots dynamically reconfigures the physical environment to match the virtual content. We describe the hardware and software implementation, applications in virtual tours and architectural design and interaction techniques.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {room-scale haptics, virtual reality, haptic interfaces, swarm robots},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376773,
author = {Eschler, Jordan and Burgess, Eleanor R. and Reddy, Madhu and Mohr, David C.},
title = {Emergent Self-Regulation Practices in Technology and Social Media Use of Individuals Living with Depression},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376773},
doi = {10.1145/3313831.3376773},
abstract = {Much human-computer interaction work related to depression focuses on the population level (e.g., studying social media hashtags related to depression) or evaluates prototypes for digital interventions to manage depression. However, little is known about how people living with depression perceive and manage technology use, such as time spent on social media per day. For this study, we interviewed 30 individuals living with depression to explore their technology and social media use. We find that these individuals demonstrated emergent practices related to self-regulation, such as learning to monitor and adjust technology use to improve their emotional, cognitive, and behavioral health. Our findings add a human-centered viewpoint to the relationship between living with depression and technology and social media use. We present design implications of these findings for better empowering individuals with depression to encourage their natural inclinations to self-regulate technology and social media use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social media, self-regulation, depression, qualitative},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376369,
author = {Avrahami, Daniel and Williams, Kristin and Lee, Matthew L. and Tokunaga, Nami and Tjahjadi, Yulius and Marlow, Jennifer},
title = {Celebrating Everyday Success: Improving Engagement and Motivation Using a System for Recording Daily Highlights},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376369},
doi = {10.1145/3313831.3376369},
abstract = {The demands of daily work offer few opportunities for workers to take stock of their own progress, big or small, which can lead to lower motivation, engagement, and higher risk of burnout. We present Highlight Matome, a personal online tool that encourages workers to quickly record and rank a single work highlight each day, helping them gain awareness of their own successes. We describe results from a field experiment investigating our tool's effectiveness for improving workers' engagement, perceptions, and affect. Thirty-three knowledge workers in Japan and the U.S. used Highlight Matome for six weeks. Our results show that using our tool for less than one minute each day significantly increased measures of work engagement, dedication, and positivity. A qualitative analysis of the highlights offers a window into participants' emotions and perceptions. We discuss implications for theories of inner work life and worker well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {work engagement, well-being, knowledge workers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376246,
author = {Maddali, Hanuma Teja and Lazar, Amanda},
title = {Sociality and Skill Sharing in the Garden},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376246},
doi = {10.1145/3313831.3376246},
abstract = {Gardening is an activity that involves a number of dimensions of increasing interest to HCI and CSCW researchers, including recreation, sustainability, and engagement with nature. This paper considers the garden setting in order to understand the role that collaborative and social computing technologies might play for practitioners engaging in outdoor skilled activities. We conducted participant observations with nine experienced gardeners aged 22-71 years. Through this process, we find that gardeners continuously configure their environments to accommodate their preferences for sociality. They share embodied skills and help others attune to sensory information in person, but also influence learning through the features in their garden that are observed by others. This paper provides an understanding of sociality in the garden, highlights skill sharing as a key domain for design in this space, and contributes design considerations for collaborative technologies in outdoor settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gardening, sociality, participant observation, skill sharing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376290,
author = {Schaekermann, Mike and Cai, Carrie J. and Huang, Abigail E. and Sayres, Rory},
title = {Expert Discussions Improve Comprehension of Difficult Cases in Medical Image Assessment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376290},
doi = {10.1145/3313831.3376290},
abstract = {Medical data labeling workflows critically depend on accurate assessments from human experts. Yet human assessments can vary markedly, even among medical experts. Prior research has demonstrated benefits of labeler training on performance. Here we utilized two types of labeler training feedback: highlighting incorrect labels for difficult cases ("individual performance" feedback), and expert discussions from adjudication of these cases. We presented ten generalist eye care professionals with either individual performance alone, or individual performance and expert discussions from specialists. Compared to performance feedback alone, seeing expert discussions significantly improved generalists' understanding of the rationale behind the correct diagnosis while motivating changes in their own labeling approach; and also significantly improved average accuracy on one of four pathologies in a held-out test set. This work suggests that image adjudication may provide benefits beyond developing trusted consensus labels, and that exposure to specialist discussions can be an effective training intervention for medical diagnosis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {diagnosis, adjudication, medical images, labeler training},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376404,
author = {Stangl, Abigale and Morris, Meredith Ringel and Gurari, Danna},
title = {"Person, Shoes, Tree. Is the Person Naked?" What People with Vision Impairments Want in Image Descriptions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376404},
doi = {10.1145/3313831.3376404},
abstract = {Access to digital images is important to people who are blind or have low vision (BLV). Many contemporary image description efforts do not take into account this population's nuanced image description preferences. In this paper, we present a qualitative study that provides insight into 28 BLV people's experiences with descriptions of digital images from news websites, social networking sites/platforms, eCommerce websites, employment websites, online dating websites/platforms, productivity applications, and e-publications. Our findings reveal how image description preferences vary based on the source where digital images are encountered and the surrounding context. We provide recommendations for the development of next-generation image description technologies inspired by our empirical analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {alt text, accessibility, image captions, visual impairment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376844,
author = {Karyda, Maria and Ry\"{o}ppy, Merja and Buur, Jacob and Lucero, Andr\'{e}s},
title = {Imagining Data-Objects for Reflective Self-Tracking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376844},
doi = {10.1145/3313831.3376844},
abstract = {While self-tracking data is typically captured real-time in a lived experience, the data is often stored in a manner detached from the context where it belongs. Research has shown that there is a potential to enhance people's lived experiences with data-objects (artifacts representing contextually relevant data), for individual and collective reflections through a physical portrayal of data. This paper expands that research by studying how to design contextually relevant data-objects based on people's needs. We conducted a participatory research project with five households using object theater as a core method to encourage participants to speculate upon combinations of meaningful objects and personal data archives. In this paper, we detail three aspects that seem relevant for designing data-objects: social sharing, contextual ambiguity and interaction with the body. We show how an experience-centric view on data-objects can contribute with the contextual, social and bodily interplay between people, data and objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {object theater, experience, personal objects, data-objects},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376710,
author = {Laschke, Matthias and Braun, Christoph and Neuhaus, Robin and Hassenzahl, Marc},
title = {Meaningful Technology at Work - A Reflective Design Case of Improving Radiologists' Wellbeing Through Medical Technology},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376710},
doi = {10.1145/3313831.3376710},
abstract = {In radiology, medical technology providers (MTP) focus mainly on technology-related issues, such as image quality or efficiency of reporting. Broader notions of radiology as "meaningful work" are largely seen as out of scope for an MTP. The present paper challenges this. In a real-world case with a large MTP, we showed that medical technology could be designed more holistically to explicitly improve radiologists' wellbeing. We first gathered work practices experienced as especially conducive to wellbeing. From there, we distilled ideal practices to increase wellbeing and turned them into two software applications. The MTP's initial skepticism dissolved, while radiologists unanimously emphasized wellbeing and demonstrated how they work towards improving it. Based on our insights, the applications resonated well among the radiologists involved, the healthcare provider, and other customers of the MTP. We close with a critical reflection of the challenges and opportunities of designing wellbeing-driven technology in the work domain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {technology at work, practice-based, job design, wellbeing-driven design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376615,
author = {Abdul, Ashraf and von der Weth, Christian and Kankanhalli, Mohan and Lim, Brian Y.},
title = {COGAM: Measuring and Moderating Cognitive Load in Machine Learning Model Explanations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376615},
doi = {10.1145/3313831.3376615},
abstract = {Interpretable machine learning models trade -off accuracy for simplicity to make explanations more readable and easier to comprehend. Drawing from cognitive psychology theories in graph comprehension, we formalize readability as visual cognitive chunks to measure and moderate the cognitive load in explanation visualizations. We present Cognitive-GAM (COGAM) to generate explanations with desired cognitive load and accuracy by combining the expressive nonlinear generalized additive models (GAM) with simpler sparse linear models. We calibrated visual cognitive chunks with reading time in a user study, characterized the trade-off between cognitive load and accuracy for four datasets in simulation studies, and evaluated COGAM against baselines with users. We found that COGAM can decrease cognitive load without decreasing accuracy and/or increase accuracy without increasing cognitive load. Our framework and empirical measurement instruments for cognitive load will enable more rigorous assessment of the human interpretability of explainable AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {explainable artificial intelligence, explanations, generalized additive models, cognitive load, visual explanations},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376519,
author = {Leake, Mackenzie and Shin, Hijung Valentina and Kim, Joy O. and Agrawala, Maneesh},
title = {Generating Audio-Visual Slideshows from Text Articles Using Word Concreteness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376519},
doi = {10.1145/3313831.3376519},
abstract = {We present a system that automatically transforms text articles into audio-visual slideshows by leveraging the notion of word concreteness, which measures how strongly a word or phrase is related to some perceptible concept. In a formative study we learn that people not only prefer such audio-visual slideshows but find that the content is easier to understand compared to text articles or text articles augmented with images. We use word concreteness to select search terms and find images relevant to the text. Then, based on the distribution of concrete words and the grammatical structure of an article, we time-align selected images with audio narration obtained through text-to-speech to produce audio-visual slideshows. In a user evaluation we find that our concreteness-based algorithm selects images that are highly relevant to the text. The quality of our slideshows is comparable to slideshows produced manually using standard video editing tools, and people strongly prefer our slideshows to those generated using a simple keyword-search based approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {word concreteness, audio-visual slideshows, text-to-video},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376612,
author = {Lu, Zhicong and Jiang, Yue and Lu, Cheng and Naaman, Mor and Wigdor, Daniel},
title = {The Government's Dividend: Complex Perceptions of Social Media Misinformation in China},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376612},
doi = {10.1145/3313831.3376612},
abstract = {The social media environment in China has become the dominant source of information and news over the past decade. This news environment has naturally suffered from challenges related to mis- and dis-information, encumbered by an increasingly complex landscape of factors and players including social media services, fact-checkers, censorship policies, and astroturfing. Interviews with 44 Chinese WeChat users were conducted to understand how individuals perceive misinformation and how it impacts their news consumption practices. Overall, this work exposes the diverse attitudes and coping strategies that Chinese users employ in complex social media environments. Due to the complex nature of censorship in China and participants' lack of understanding of censor-ship, they expressed varied opinions about its influence on the credibility of online information sources. Further, although most participants claimed that their opinions would not be easily swayed by astroturfers, many admitted that they could not effectively distinguish astroturfers from ordinary Internet users. Participants' inability to make sense of comments found online lead many participants to hold pro-censorship attitudes: the Government's Dividend.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {fake news, misinformation, astroturfing, trust, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376834,
author = {Gr\o{}nb\ae{}k, Jens Emil and Rasmussen, Majken Kirkegaard and Halskov, Kim and Petersen, Marianne Graves},
title = {KirigamiTable: Designing for Proxemic Transitions with a Shape-Changing Tabletop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376834},
doi = {10.1145/3313831.3376834},
abstract = {A core challenge in tabletop research is to support transitions between individual activities and team work. Shape-changing tabletops open up new opportunities for addressing this challenge. However, interaction design for shape-changing furniture is in its early stages - so far, research has mainly focused on triggering shape-changes, and less on the actual interface transitions. We present KirigamiTable - a novel actuated shape-changing tabletop for supporting transitions in collaborative work. Our work builds on the concept of Proxemic Transitions, considering the dynamic interplay between social interactions, interactive technologies and furniture. With KirigamiTable, we demonstrate the potential of interactions for proxemic transitions that combine transformation of shape and digital contents. We highlight challenges for shape-changing tabletops: initiating shape and content transformations, cooperative control, and anticipating shape-change. To address these challenges, we propose a set of novel interaction techniques, including shape-first and content-first interaction, cooperative gestures, and physical and digital preview of shape-changes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {shape-changing interfaces, transitions, collaboration, interaction techniques, interactive tabletops, proxemics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376741,
author = {Klefeker, Josephine and striegl, libi and Devendorf, Laura},
title = {What HCI Can Learn from ASMR: Becoming Enchanted with the Mundane},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376741},
doi = {10.1145/3313831.3376741},
abstract = {In this paper we explore how the qualities of Autonomous Sensory Meridian Response (ASMR) media - its pairing of sonic and visual design, ability to subvert fast-paced technology for slow experiences, production of somatic responses, and attention to the everyday-might reveal new design possibilities for interactions with wearable technology. We recount our year-long design inquiry into the subject which began with an interview with a "live" ASMR creator and design probes, a series of first-person design exercises, and resulted in the creation of two interactive garments for attending, noticing, and becoming enchanted with our our everyday surroundings. We conclude by suggesting that these ASMR inspired designs cultivate personal, intimate, embodied, and felt practices of attention within our everyday, mundane, environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {asmr media, sonic interaction, smart textiles, wearable technology, enchantment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376281,
author = {Li, Quan and Lin, Huanbin and Wei, Xiguang and Huang, Yangkun and Fan, Lixin and Du, Jian and Ma, Xiaojuan and Chen, Tianjian},
title = {MaraVis: Representation and Coordinated Intervention of Medical Encounters in Urban Marathon},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376281},
doi = {10.1145/3313831.3376281},
abstract = {There is an increased use of Internet-of-Things and wearable sensing devices in the urban marathon to ensure effective response to unforeseen medical needs. However, the massive amount of real-time, heterogeneous movement and psychological data of runners impose great challenges on prompt medical incident analysis and intervention. Conventional approaches compile such data into one dashboard visualization to facilitate rapid data absorption but fail to support joint decision-making and operations in medical encounters. In this paper, we present MaraVis, a real-time urban marathon visualization and coordinated intervention system. It first visually summarizes real-time marathon data to facilitate the detection and exploration of possible anomalous events. Then, it calculates an optimal camera route with an arrangement of shots to guide offline effort to catch these events in time with a smooth view transition. We conduct a within-subjects study with two baseline systems to assess the efficacy of MaraVis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {anomaly detection, shot chaining, marathon visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376737,
author = {Wang, Yanan and Amores, Judith and Maes, Pattie},
title = {On-Face Olfactory Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376737},
doi = {10.1145/3313831.3376737},
abstract = {On-face wearables are currently limited to piercings, tattoos, or interactive makeup that aesthetically enhances the user, and have been minimally used for scent-delivery methods. However, on-face scent interfaces could provide an advantage for personal scent delivery in comparison with other modalities or body locations since they are closer to the nose. In this paper, we present the mechanical and industrial design details of a series of form factors for on-face olfactory wearables that are lightweight and can be adhered to the skin or attached to glasses or piercings. We assessed the usability of three prototypes by testing with 12 participants in a within-subject study design while they were interacting in pairs at a close personal distance. We compare two of these designs with an "off-face" olfactory necklace and evaluate their social acceptance, comfort as well as perceived odor intensity for both the wearer and observer.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {wearable device, on-face interfaces, scent display, fashion, jewelry, wearability, olfaction, olfactory interfaces, on-face wearables},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376581,
author = {Gupta, Maya and Abdolrahmani, Ali and Edwards, Emory and Cortez, Mayra and Tumang, Andrew and Majali, Yasmin and Lazaga, Marc and Tarra, Samhitha and Patil, Prasad and Kuber, Ravi and Branham, Stacy M.},
title = {Towards More Universal Wayfinding Technologies: Navigation Preferences Across Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376581},
doi = {10.1145/3313831.3376581},
abstract = {Accessibility researchers have been studying wayfinding technologies for people with disabilities for decades, typically focusing on solutions within disability populations - for example, technologies to support blind navigation. Yet, we know little about wayfinding needs across disabilities. In this paper, we describe a qualitative interview study examining the urban navigational experiences of 27 people who identified as older adults and/or who had cognitive, visual, hearing, and/or mobility disabilities. We found that many navigation route preferences were shared across disabilities (e.g., desire to avoid carpeted areas), while others diverged or were in tension (e.g., the need to avoid noisy areas while staying near main thoroughfares). To support design for multiple disability groups, we identify four dimensions of navigation preferences - technology, route, assistance, experience - and describe how these might usefully inform design of more universally usable wayfinding technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visual impairment, navigation, deaf, older adults, accessibility, mobility impairment, cognitive impairment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376506,
author = {Schaekermann, Mike and Beaton, Graeme and Sanoubari, Elaheh and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Ambiguity-Aware AI Assistants for Medical Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376506},
doi = {10.1145/3313831.3376506},
abstract = {Artificial intelligence (AI) assistants for clinical decision making show increasing promise in medicine. However, medical assessments can be contentious, leading to expert disagreement. This raises the question of how AI assistants should be designed to handle the classification of ambiguous cases. Our study compared two AI assistants that provide classification labels for medical time series data along with quantitative uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware AI based on real-world expert discussions to highlight cases likely to lead to expert disagreement, and to present arguments for conflicting classification choices. Our results demonstrate that ambiguity-aware AI can alter expert workflows by significantly increasing the proportion of contentious cases reviewed. We also found that the relevance of AI-provided arguments (selected from guidelines either randomly or by experts) affected experts' accuracy at revising AI-suggested labels. Our work contributes a novel perspective on the design of AI for contentious clinical assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {medical data analysis, artificial intelligence, ambiguity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376805,
author = {Dahl, Yngve and Svan\ae{}s, Dag},
title = {Facilitating Democracy: Concerns from Participatory Design with Asymmetric Stakeholder Relations in Health Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376805},
doi = {10.1145/3313831.3376805},
abstract = {This paper addresses how facilitation can implicate what, whose and how perspectives and values become embedded in the results from participatory design activities. Inspired by Donald Sch\"{o}n's reflection-on-action theory, an analysis of our facilitator performances in three design activities involving health care stakeholder groups with asymmetric relations has been performed. The analysis highlights the often subtle and unforeseen ways by which facilitator actions influence who "has a say". The results emphasize how continuous introspective analyses and reflections may improve the facilitator's attentiveness to actions that may inadvertently impede the disfavored party. In the long-term, neglect may threaten the integrity of participatory design as a democratic and empowering design approach. The shift towards a practice-perspective on facilitation goes beyond the efforts of the individual practitioner. The cultivation of the reflective facilitator, a concern of relevance for the Human?Computer Interaction and Participatory Design community as a whole, is considered.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {participation, reflection, facilitation, asymmetries},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376335,
author = {Kaul, Oliver Beren and Rohs, Michael and Simon, Benjamin and Demir, Kerem Can and Ferry, Kamillo},
title = {Vibrotactile Funneling Illusion and Localization Performance on the Head},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376335},
doi = {10.1145/3313831.3376335},
abstract = {The vibrotactile funneling illusion is the sensation of a single (non-existing) stimulus somewhere in-between the actual stimulus locations. Its occurrence depends upon body location, distance between the actuators, signal synchronization, and intensity. Related work has shown that the funneling illusion may occur on the forehead. We were able to reproduce these findings and explored five further regions to get a more complete picture of the occurrence of the funneling illusion on the head. The results of our study (24 participants) show that the actuator distance, for which the funneling illusion occurs, strongly depends upon the head region. Moreover, we evaluated the centralizing bias (smaller perceived than actual actuator distances) for different head regions, which also showed widely varying characteristics. We computed a detailed heat map of vibrotactile localization accuracies on the head. The results inform the design of future tactile head-mounted displays that aim to support the funneling illusion.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {centralizing bias, phantom sensation, funneling illusion, tactile feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376765,
author = {Li, Jingyi and Brandt, Joel and Mech, Radom\'{\i}r and Agrawala, Maneesh and Jacobs, Jennifer},
title = {Supporting Visual Artists in Programming through Direct Inspection and Control of Program Execution},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376765},
doi = {10.1145/3313831.3376765},
abstract = {Programming offers new opportunities for visual art creation, but understanding and manipulating the abstract representations that make programming powerful can pose challenges for artists who are accustomed to manual tools and concrete visual interaction. We hypothesize that we can reduce these barriers through programming environments that link state to visual artwork output. We created Demystified Dynamic Brushes (DDB), a tool that bidirectionally links code, numerical data, and artwork across the programming interface and the execution environment - i.e., the artist's in-progress artwork. DDB automatically records stylus input as artists draw, and stores a history of brush state and output in relation to the input. This structure enables artists to inspect current and past numerical input, state, and output and control program execution through the direct selection of visual geometric elements in the drawing canvas. An observational study suggests that artists engage in program inspection when they can visually access geometric state information on the drawing canvas in the process of manual drawing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual art, creativity support tools, programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376365,
author = {Karduni, Alireza and Wesslen, Ryan and Cho, Isaac and Dou, Wenwen},
title = {Du Bois Wrapped Bar Chart: Visualizing Categorical Data with Disproportionate Values},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376365},
doi = {10.1145/3313831.3376365},
abstract = {We propose a visualization technique, Du Bois wrapped bar chart, inspired by work of W.E.B Du Bois. Du Bois wrapped bar charts enable better large-to-small bar comparison by wrapping large bars over a certain threshold. We first present two crowdsourcing experiments comparing wrapped and standard bar charts to evaluate (1) the benefit of wrapped bars in helping participants identify and compare values; (2) the characteristics of data most suitable for wrapped bars. In the first study (n=98) using real-world datasets, we find that wrapped bar charts lead to higher accuracy in identifying and estimating ratios between bars. In a follow-up study (n=190) with 13 simulated datasets, we find participants were consistently more accurate with wrapped bar charts when certain category values are disproportionate as measured by entropy and H-spread. Finally, in an in-lab study, we investigate participants' experience and strategies, leading to guidelines for when and how to use wrapped bar charts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {evaluation, crowdsourcing, mechanical turk, information visualization, bar chart, user study, graphical perception},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376437,
author = {Fraser, C. Ailie and Kim, Joy O. and Shin, Hijung Valentina and Brandt, Joel and Dontcheva, Mira},
title = {Temporal Segmentation of Creative Live Streams},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376437},
doi = {10.1145/3313831.3376437},
abstract = {Many artists broadcast their creative process through live streaming platforms like Twitch and YouTube, and people often watch archives of these broadcasts later for learning and inspiration. Unfortunately, because live stream videos are often multiple hours long and hard to skim and browse, few can leverage the wealth of knowledge hidden in these archives. We present an approach for automatic temporal segmentation of creative live stream videos. Using an audio transcript and a log of software usage, the system segments the video into sections that the artist can optionally label with meaningful titles. We evaluate this approach by gathering feedback from expert streamers and comparing automatic segmentations to those made by viewers. We find that, while there is no one "correct" way to segment a live stream, our automatic method performs similarly to viewers, and streamers find it useful for navigating their streams after making slight adjustments and adding section titles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {creativity, video segmentation, live streaming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376294,
author = {Mustafa, Maryam and Batool, Amna and Fatima, Beenish and Nawaz, Fareeda and Toyama, Kentaro and Raza, Agha Ali},
title = {Patriarchy, Maternal Health and Spiritual Healing: Designing Maternal Health Interventions in Pakistan},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376294},
doi = {10.1145/3313831.3376294},
abstract = {We examine the opportunities and challenges in designing for maternal health in low-income, low-resource communities in patriarchal and religious contexts. Pakistan faces a crisis in maternal health with a maternal mortality ratio of 178 deaths per 100,000 live births, as compared to the developed-country average of just 12 deaths per 100,000. Through a 6-month long qualitative, empirical study we examine the prevalent beliefs and practices around maternal health in Pakistan, the access women have to health-care, the existing religious practices that influence them and the agency they exert in their own health-care decision making. We reveal the rampant misinformation among mothers and health workers, house-hold power dynamics that impact maternal health and the deep link between maternal health and religious beliefs. We also show how current maternal health care interventions fit poorly into this context and discuss alternate design recommendations for meeting the maternal health needs of these women.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {maternal health, patriarchy, hci4d},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376489,
author = {Henrikson, Rorik and Grossman, Tovi and Trowbridge, Sean and Wigdor, Daniel and Benko, Hrvoje},
title = {Head-Coupled Kinematic Template Matching: A Prediction Model for Ray Pointing in VR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376489},
doi = {10.1145/3313831.3376489},
abstract = {This paper presents a new technique to predict the ray pointer landing position for selection movements in virtual reality (VR) environments. The technique adapts and extends a prior 2D kinematic template matching method to VR environments where ray pointers are used for selection. It builds on the insight that the kinematics of a controller and Head-Mounted Display (HMD) can be used to predict the ray's final landing position and angle. An initial study provides evidence that the motion of the head is a key input channel for improving prediction models. A second study validates this technique across a continuous range of distances, angles, and target sizes. On average, the technique's predictions were within 7.3° of the true landing position when 50% of the way through the movement and within 3.4° when 90%. Furthermore, compared to a direct extension of Kinematic Template Matching, which only uses controller movement, this head-coupled approach increases prediction accuracy by a factor of 1.8x when 40% of the way through the movement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ray pointing, target prediction, virtual reality, template matching, vr, kinematics, endpoint prediction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376390,
author = {Yang, Saelyne and Lee, Changyoon and Shin, Hijung Valentina and Kim, Juho},
title = {Snapstream: Snapshot-Based Interaction in Live Streaming for Visual Art},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376390},
doi = {10.1145/3313831.3376390},
abstract = {Live streaming visual art such as drawing or using design software is gaining popularity. An important aspect of live streams is the direct and real-time communication between streamers and viewers. However, currently available text-based interaction limits the expressiveness of viewers as well as streamers, especially when they refer to specific moments or objects in the stream. To investigate the feasibility of using snapshots of streamed content as a way to enhance streamer-viewer interaction, we introduce Snapstream, a system that allows users to take snapshots of the live stream, annotate them, and share the annotated snapshots in the chat. Streamers can also verbally reference a specific snapshot during streaming to respond to viewers' questions or comments. Results from live deployments show that participants communicate more expressively and clearly with increased engagement using Snapstream. Participants used snapshots to reference part of the artwork, give suggestions on it, make fun images or memes, and log intermediate milestones. Our findings suggest that visual interaction enables richer experiences in live streaming.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online interaction, context sharing, live streaming, chat interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376277,
author = {An, Pengcheng and Holstein, Kenneth and d'Anjou, Bernice and Eggen, Berry and Bakker, Saskia},
title = {The TA Framework: Designing Real-Time Teaching Augmentation for K-12 Classrooms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376277},
doi = {10.1145/3313831.3376277},
abstract = {Recently, the HCI community has seen increased interest in the design of teaching augmentation (TA): tools that extend and complement teachers' pedagogical abilities during ongoing classroom activities. Examples of TA systems are emerging across multiple disciplines, taking various forms: e.g., ambient displays, wearables, or learning analytics dashboards. However, these diverse examples have not been analyzed together to derive more fundamental insights into the design of teaching augmentation. Addressing this opportunity, we broadly synthesize existing cases to propose the TA framework. Our framework specifies a rich design space in five dimensions, to support the design and analysis of teaching augmentation. We contextualize the framework using existing designs cases, to surface underlying design trade-offs: for example, balancing actionability of presented information with teachers' needs for professional autonomy, or balancing unobtrusiveness with informativeness in the design of TA systems. Applying the TA framework, we identify opportunities for future research and design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {classroom, augmented intelligence, k-12, dashboards, teacher, orchestration, ambient intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376343,
author = {Garzotto, Franca and Beccaluva, Eleonora and Gianotti, Mattia and Riccardi, Fabiano},
title = {Interactive Multisensory Environments for Primary School Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376343},
doi = {10.1145/3313831.3376343},
abstract = {Interactive Multi-Sensory Environments (iMSEs) are room-sized interactive installations equipped with digitally enriched physical materials and ambient embedded devices. These items can sense users' presence, gestures, movements, and manipulation, and react by providing gentle stimulation (e.g., light, sound, projections, blowing bubbles, tactile feel, aromas) to different senses. Most of prior research on iMSEs investigates their use for persons with disabilities (e.g., autism). Our work focuses on the use of iMSEs in primary education contexts and for mixed groups of young students, i.e., children with and without disability. The paper describes the latest version of an iMSE called Magic Room that has been installed in two local schools. We report two empirical studies devoted to understand how the Magic Room could be used in inclusive educational settings, and to explore its potential benefits.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {smart object, embodied interaction, children, well-being, children with special needs, primary school, smart space, interactive multisensory environment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376177,
author = {Hohman, Fred and Wongsuphasawat, Kanit and Kery, Mary Beth and Patel, Kayur},
title = {Understanding and Visualizing Data Iteration in Machine Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376177},
doi = {10.1145/3313831.3376177},
abstract = {Successful machine learning (ML) applications require iterations on both modeling and the underlying data. While prior visualization tools for ML primarily focus on modeling, our interviews with 23 ML practitioners reveal that they improve model performance frequently by iterating on their data (e.g., collecting new data, adding labels) rather than their models. We also identify common types of data iterations and associated analysis tasks and challenges. To help attribute data iterations to model performance, we design a collection of interactive visualizations and integrate them into a prototype, Chameleon, that lets users compare data features, training/testing splits, and performance across data versions. We present two case studies where developers apply system to their own evolving datasets on production ML projects. Our interface helps them verify data collection efforts, find failure cases stretching across data versions, capture data processing changes that impacted performance, and identify opportunities for future data iterations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive interfaces, data iteration, machine learning iteration, evolving datasets, visual analytics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376243,
author = {Wolf, Dennis and Rogers, Katja and Kunder, Christoph and Rukzio, Enrico},
title = {JumpVR: Jump-Based Locomotion Augmentation for Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376243},
doi = {10.1145/3313831.3376243},
abstract = {One of the great benefits of virtual reality (VR) is the implementation of features that go beyond realism. Common "unrealistic" locomotion techniques (like teleportation) can avoid spatial limitation of tracking, but minimize potential benefits of more realistic techniques (e.g. walking). As an alternative that combines realistic physical movement with hyper-realistic virtual outcome, we present JumpVR, a jump-based locomotion augmentation technique that virtually scales users' physical jumps. In a user study (N=28), we show that jumping in VR (regardless of scaling) can significantly increase presence, motivation and immersion compared to teleportation, while largely not increasing simulator sickness. Further, participants reported higher immersion and motivation for most scaled jumping variants than forward-jumping. Our work shows the feasibility and benefits of jumping in VR and explores suitable parameters for its hyper-realistic scaling. We discuss design implications for VR experiences and research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {vr, hyper realism, jumping, immersion, virtual reality, super human},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376762,
author = {Gupta, Saumya and Tanenbaum, Theresa Jean and Muralikumar, Meena Devii and Marathe, Aparajita S.},
title = {Investigating Roleplaying and Identity Transformation in a Virtual Reality Narrative Experience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376762},
doi = {10.1145/3313831.3376762},
abstract = {In this paper we describe the design and evaluation of The Next Fairy Tale (TNFT) VR, a theatrical interactive storytelling system created in virtual reality and informed by performing arts theories. TNFT was designed to produce opportunities for interactors to experience role-taking and character identification using design principles drawn from actor training and theatrical performance. We report the results of a pilot qualitative study of interactors using TNFT to explore the elements of the design that supported or hindered roleplaying behavior. We identify four design patterns that supported roleplaying in the system: (1) using explicit roles to set player expectations, (2) embracing the "mask and the mirror" effect, (3) attending to visual and interactional details, and (4) easing the player gently into the roleplaying experience. These patterns speak to a broader need to support roleplay through explicit scaffolding of desired player behaviors in digital narrative experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {drama, narrative, interactive performance, virtual reality, interactive digital storytelling, roleplaying},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376620,
author = {Waern, Annika and Rajkowska, Paulina and Johansson, Karin B. and Bac, Jon and Spence, Jocelyn and L\o{}vlie, Anders Sundnes},
title = {Sensitizing Scenarios: Sensitizing Designer Teams to Theory},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376620},
doi = {10.1145/3313831.3376620},
abstract = {Concepts and theories that emerge within the social sciences tend to be nuanced, dealing with complex social phenomena. While their relevance to design could be high, it is difficult to make sense of them in design projects, especially when participants have a variety of backgrounds. We report on our experiences using role-play scenarios as a way to sensitize heterogeneous designer teams to complex theoretical concepts related to museology as social and cultural phenomena. We discuss design requirements on such scenarios, and the importance of connecting their execution closely to the context of the design and the current stage of the design process.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sensitizing concepts, sensitizing designers, role-play, social science theory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376447,
author = {Yan, Jing Nathan and Gu, Ziwei and Lin, Hubert and Rzeszotarski, Jeffrey M.},
title = {Silva: Interactively Assessing Machine Learning Fairness Using Causality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376447},
doi = {10.1145/3313831.3376447},
abstract = {Machine learning models risk encoding unfairness on the part of their developers or data sources. However, assessing fairness is challenging as analysts might misidentify sources of bias, fail to notice them, or misapply metrics. In this paper we introduce Silva, a system for exploring potential sources of unfairness in datasets or machine learning models interactively. Silva directs user attention to relationships between attributes through a global causal view, provides interactive recommendations, presents intermediate results, and visualizes metrics. We describe the implementation of Silva, identify salient design and technical challenges, and provide an evaluation of the tool in comparison to an existing fairness optimization tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {machine learning fairness, interactive system, bias},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376811,
author = {Oh, Changhoon and Choi, Jinhan and Lee, Sungwoo and Park, SoHyun and Kim, Daeryong and Song, Jungwoo and Kim, Dongwhan and Lee, Joonhwan and Suh, Bongwon},
title = {Understanding User Perception of Automated News Generation System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376811},
doi = {10.1145/3313831.3376811},
abstract = {Automated journalism refers to the generation of news articles using computer programs. Although it is widely used in practice, its user experience and interface design remain largely unexplored. To understand the user perception of an automated news system, we designed NewsRobot, a research prototype that automatically generated news on major events of the PyeongChang 2018 Winter Olympic Games in real-time. It produces six types of news by combining two kinds of content (general/individualized) and three styles (text, text+image, text+image+sound). A total of 30 users participated in using NewsRobot, completing surveys and interviews on their experience. Our findings are as follows: (1) Users preferred individualized news yet considered it less credible, (2) more presentation elements were appreciated but only if their quality was assured, and (3) NewsRobot was considered factual and accurate yet shallow in depth. Based on our findings, we discuss implications for designing automated journalism user interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multimedia modality, robot journalism, automated journalism, automated news generation system},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376453,
author = {Encinas, Enrique and Durrant, Abigail C. and Mitchell, Robb and Blythe, Mark},
title = {Metaprobes, Metaphysical Workshops and Sketchy Philosophy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376453},
doi = {10.1145/3313831.3376453},
abstract = {The intersection of philosophy and HCI is a longstanding site of interest for the field that has been attracting special attention in recent years. In this paper, we present metaphysical probes (Metaprobes) as a tool for design-led philosophical inquiry. A Metaprobe is a design artifact used to study a metaphysical idea without concealing the philosophical tools mobilized by the designers or the designerly knowledge attained after deployment. We introduce the concept of a Metaphysical Workshop. This is the set of sketchy philosophical notions that a designer mobilizes in order to research a philosophical idea through design. We then present a case study that comprises: the philosophical issue under examination, the Metaprobes designed to study it, the metaphysical workshop used and the designerly insight produced. We conclude with a discussion of the potentials and weaknesses of Metaprobes in relation to other critical and speculative research-through-design practices. We aim to provide one way to make philosophies already present in design more explicit and make other philosophical concepts relevant to HCI more accessible and workable for designers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design fiction, ontology, metaphysics, philosophy, research through design, research fiction, cultural probes},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376660,
author = {Cila, Nazli and Ferri, Gabriele and de Waal, Martijn and Gloerich, Inte and Karpinski, Tara},
title = {The Blockchain and the Commons: Dilemmas in the Design of Local Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376660},
doi = {10.1145/3313831.3376660},
abstract = {This paper addresses the design dilemmas that arise when distributed ledger technologies (DLT) are to be applied in the governance of artificial material commons. DLTs, such as blockchain, are often presented as enabling technologies for self-governing communities, provided by their consensus mechanisms, transparent administration, and incentives for collaboration and cooperation. Yet, these affordances may also undermine public values such as privacy and displace human agency in governance procedures. In this paper, the conflicts regarding the governance of communities which collectively manage and produce a commons are discussed through the case of a fictional energy community. Three mechanisms are identified in this process: tracking use of and contributions to the commons; managing resources, and negotiating the underlying rule sets and user rights. Our effort is aimed at contributing to the HCI community by introducing a framework of three mechanisms and six design dilemmas that can aid in balancing conflicting values in the design of local platforms for commons-based resource management.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {commons, governance, energy community, platformization, blockchain, design dilemmas},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376832,
author = {Monaco, John V.},
title = {Bug or Feature? Covert Impairments to Human Computer Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376832},
doi = {10.1145/3313831.3376832},
abstract = {Computer users commonly experience interaction anomalies, such as the text cursor jumping to another location in a document, perturbed mouse pointer motion, or a disagreement between tactile input and touch screen location. These anomalies impair interaction and require the user to take corrective measures, such as resetting the text cursor or correcting the trajectory of the pointer to reach a desired target. Impairments can result from software bugs, physical hardware defects, and extraneous input. However, some designs alter the course of interaction through covert impairments, anomalies introduced intentionally and without the user's knowledge. There are various motivations for doing so rooted in disparate fields including biometrics, electronic voting, and entertainment. We examine this kind of deception by systematizing four different ways computer interaction may become impaired and three different goals of the designer, providing insight to the design of systems that implement covert impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {deception, behavior change, interaction, cybersecurity, influence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376648,
author = {Unbehaun, David and Aal, Konstantin and Vaziri, Daryoush Daniel and Tolmie, Peter David and Wieching, Rainer and Randall, David and Wulf, Volker},
title = {Social Technology Appropriation in Dementia: Investigating the Role of Caregivers in Engaging People with Dementia with a Videogame-Based Training System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376648},
doi = {10.1145/3313831.3376648},
abstract = {There has been increasing interest in designing for dementia in recent years. Empirical investigation is now needed of the long-term role of caregivers in appropriating ICTs into the complex daily life of people with dementia (PwD). We present here the outcomes of a 4-month evaluation of the individual, social and institutional impact of a videogame-based training system. The everyday behavior and interactions of 52 PwD and 25 caregivers was studied qualitatively, focusing on the role played by caregivers in integrating the system into daily routines. Our results indicate that the successful appropriation of ICT for PwD depends partly on the physical, cognitive and social benefits for PwD, but especially on the added value perceived by their social care-network. We discuss the need for design in dementia to develop more socially embedded innovations that can address the social actors involved and thus contribute to practical solutions for professional and private care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {dementia, appropriation, exergame, care, caregiver, ICT},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376183,
author = {Prpa, Mirjana and Stepanova, Ekaterina R. and Schiphorst, Thecla and Riecke, Bernhard E. and Pasquier, Philippe},
title = {Inhaling and Exhaling: How Technologies Can Perceptually Extend Our Breath Awareness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376183},
doi = {10.1145/3313831.3376183},
abstract = {Attending to breath is a self-awareness practice that exists within many contemplative and reflective traditions and is recognized for its benefits to well-being. Our current technological landscape embraces a large body of systems that utilize breath data in order to foster self-awareness. This paper seeks to deepen our understanding of the design space of systems that perceptually extend breath awareness. Our contribution is twofold: (1) our analysis reveals how the underlying theoretical frameworks shape the system design and its evaluation, and (2) how system design features support perceptual extension of breath awareness. We review and critically analyze 31 breath-based interactive systems. We identify 4 theoretical frameworks and 3 design strategies for interactive systems that perceptually extend breath awareness. We reflect upon this design space from both a theoretical and system design perspective, and propose future design directions for developing systems that "listen to" breath and perceptually extend it.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {breathing regulation, perceptually extending, breath, mindfulness-based design, soma design, breathing synchronization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376420,
author = {McNutt, Andrew and Kindlmann, Gordon and Correll, Michael},
title = {Surfacing Visualization Mirages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376420},
doi = {10.1145/3313831.3376420},
abstract = {Dirty data and deceptive design practices can undermine, invert, or invalidate the purported messages of charts and graphs. These failures can arise silently: a conclusion derived from a particular visualization may look plausible unless the analyst looks closer and discovers an issue with the backing data, visual specification, or their own assumptions. We term such silent but significant failures . We describe a conceptual model of mirages and show how they can be generated at every stage of the visual analytics process. We adapt a methodology from software testing, , as a way of automatically surfacing potential mirages at the visual encoding stage of analysis through modifications to the underlying data and chart specification. We show that metamorphic testing can reliably identify mirages across a variety of chart types with relatively little prior knowledge of the data or the domain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {deceptive visualization, information visualization, visualization testing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376521,
author = {Kim, Sunyoung and Li, Muyang},
title = {Awareness, Understanding, and Action: A Conceptual Framework of User Experiences and Expectations about Indoor Air Quality Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376521},
doi = {10.1145/3313831.3376521},
abstract = {With the advent of new sensors and technologies, smart devices that monitor the level of indoor air quality (IAQ) are increasingly available to create a healthy home environment. However, little has been studied regarding design principles for effective IAQ visualizations to help better understand and improve IAQ. We analyzed Amazon reviews of IAQ monitors and their design components for IAQ visualizations. Based on our findings, we created a conceptual framework to explain the process of facilitating an effective IAQ visualization with a proposed set of design considerations in each stage. The process includes helping users easily understand what is happing to IAQ (awareness), what it means to them (understanding), and what to do with the information (action), which results in two outcomes, knowledge gain and emotional relief. We hope our framework can help practitioners and researchers in designing eco-feedback system and beyond to advance both research and practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {indoor air quality, peripheral display, design principles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376306,
author = {Xu, Zheer and Chen, Weihao and Zhao, Dongyang and Luo, Jiehui and Wu, Te-Yen and Gong, Jun and Yin, Sicheng and Zhai, Jialun and Yang, Xing-Dong},
title = {BiTipText: Bimanual Eyes-Free Text Entry on a Fingertip Keyboard},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376306},
doi = {10.1145/3313831.3376306},
abstract = {We present a bimanual text input method on a miniature fingertip keyboard, that invisibly resides on the first segment of a user's index finger on both hands. Text entry can be carried out using the thumb-tip to tap the tip of the index finger. The design of our keyboard layout followed an iterative process, where we first conducted a study to understand the natural expectation of the handedness of the keys in a QWERTY layout for users. Among a choice of 67,108,864 design variations, we identified 1295 candidates offering a good satisfaction for user expectations. Based on these results, we computed an optimized bimanual keyboard layout, while considering the joint optimization problems of word ambiguity and movement time. Our user evaluation revealed that participants achieved an average text entry speed of 23.4 WPM.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {micro finger gesture, bimanual input, text entry, wearable},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376867,
author = {Zhu, Haining and Moffa, Zachary J. and Carroll, John M.},
title = {Relational Aspects in Patient-Provider Interactions: A Facial Paralysis Case Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376867},
doi = {10.1145/3313831.3376867},
abstract = {Facial appearance is significant for everyday interactions, but hundreds of thousands of people have interactions negatively affected by facial paralysis (FP) annually. FP treatment utilizes multiple components and requires significant collaboration amongst multidisciplinary specialists and patients. Complex interactions in these contexts offer ample challenges for designers to technologically support healthcare providers in their processes. We conduct a formative case study, employing 20 clinic observations and 11 interviews, to investigate FP treatment workflow. We use cognitive authority theory (CAT) to understand relational factors in patient-provider collaboration. We then pinpoint structural and relational components of workflow challenges and discuss the utility of these distinctions; notably, we identify that patient adherence lapses caused by perceived plateaus may be primarily relational and caused by unmet expectations. Our work adds to patient-provider interaction literature and sheds light upon technology design for healthcare team contexts with significant patient obligations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {therapy, workflow, multidisciplinary team, cognitive authority theory, patient-provider interaction, facial paralysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376481,
author = {Wilberz, Alexander and Leschtschow, Dominik and Trepkowski, Christina and Maiero, Jens and Kruijff, Ernst and Riecke, Bernhard},
title = {FaceHaptics: Robot Arm Based Versatile Facial Haptics for Immersive Environments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376481},
doi = {10.1145/3313831.3376481},
abstract = {This paper introduces FaceHaptics, a novel haptic display based on a robot arm attached to a head-mounted virtual reality display. It provides localized, multi-directional and movable haptic cues in the form of wind, warmth, moving and single-point touch events and water spray to dedicated parts of the face not covered by the head-mounted display.The easily extensible system, however, can principally mount any type of compact haptic actuator or object. User study 1 showed that users appreciate the directional resolution of cues, and can judge wind direction well, especially when they move their head and wind direction is adjusted dynamically to compensate for head rotations. Study 2 showed that adding FaceHaptics cues to a VR walkthrough can significantly improve user experience, presence, and emotional responses.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {haptics, user study, virtual reality, presence, robot arm, perception, immersive environments, emotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376344,
author = {Beneteau, Erin and Boone, Ashley and Wu, Yuxing and Kientz, Julie A. and Yip, Jason and Hiniker, Alexis},
title = {Parenting with Alexa: Exploring the Introduction of Smart Speakers on Family Dynamics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376344},
doi = {10.1145/3313831.3376344},
abstract = {Smart speakers have become pervasive in family homes, creating the potential for these devices to influence parent-child dynamics and parenting behaviors. We investigate the impact of introducing a smart speaker to 10 families with children, over four weeks. We use pre- and post- deployment interviews with the whole family and in-home audio capture of parent-child interactions with the smart speaker for our analysis. Despite the smart speaker causing occasional conflict in the home, we observed that parents lever-aged the smart speaker to further parenting goals. We found three forms of influence the smart speaker has on family dynamics: 1) fostering communication, 2) disrupting access, and 3) augmenting parenting. All of these influences arise from a communally accessible, stand-alone voice interface which democratizes family access to technology. We discuss design implications in furthering parenting practices and behaviors as the capabilities of the technology continue to improve.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {parenting, families, parental mediation, voice interfaces, child development, smart speakers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376212,
author = {Lee, Sangyoon and Lim, Youn-kyung and Lee, Geehyuk},
title = {MirrorPad: Mirror on Touchpad for Direct Pen Interaction in the Laptop Environment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376212},
doi = {10.1145/3313831.3376212},
abstract = {There are needs for pen interaction on a laptop, and the market sees many pen-enabled laptop products. Many of these laptops can be transformed into tablets, when pen interaction is needed. In a real situation, however, a workflow often requires both keyboard and pen interactions, and such a convertible feature may not be effective. In this study, we introduce MirrorPad, a novel interface device contained in a laptop for direct pen interaction. It is both a normal touchpad and a viewport for pen interaction with a mirrored region on the screen. We report findings and decisions obtained from the design iterations that we conducted with users to refine MirrorPad toward the final design. In the user study, MirrorPad showed the same performance as that of the laptop configuration during keyboard interaction and a performance similar to that of the tablet configuration during pen interaction. The user study results confirmed that MirrorPad effectively supports a workflow, which requires interspersed keyboard and pen interactions, thereby achieving its initial goal.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {laptop environment, direct pen interaction, touchpad with display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376743,
author = {Kim, Taewan and Ruensuk, Mintra and Hong, Hwajung},
title = {In Helping a Vulnerable Bot, You Help Yourself: Designing a Social Bot as a Care-Receiver to Promote Mental Health and Reduce Stigma},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376743},
doi = {10.1145/3313831.3376743},
abstract = {Helping others can have a positive effect on both the giver and the receiver. However, supporting someone with depression can be complicated and overwhelming. To address this, we proposed a Facebook-based social bot displaying depressive symptoms and disclosing vulnerable experiences that allows users to practice providing reactions online. We investigated how 55 college students interacted with the social bot for three weeks and how these support-giving experiences affected their mental health and stigma. By responding to the bot, the participants reframed their own negative experiences, reported reduced feelings of danger regarding an individual with depression and increased willingness to help the person, and presented favorable attitudes toward seeking treatment for depression. We discuss design opportunities for accessible social bots that could help users to keep practicing peer support interventions without fear of negative consequences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {college student, social bot, depression, health, stigma, mental health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376360,
author = {Schubhan, Marc and Altmeyer, Maximilian and Buchheit, Dominic and Lessel, Pascal},
title = {Investigating User-Created Gamification in an Image Tagging Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376360},
doi = {10.1145/3313831.3376360},
abstract = {Commonly, gamification is designed by developers and not by end-users. In this paper we investigate an approach where users take control of this process. Firstly, users were asked to describe their own gamification concepts which would motivate them to put more effort into an image tagging task. We selected this task as gamification has already been shown to be effective here in previous work. Based on these descriptions, an implementation was made for each concept and given to the creator. In a between-subjects study (n=71), our approach was compared to a no-gamification condition and two conditions with fixed gamification settings. We found that providing participants with an implementation of their own concept significantly increased the amount of generated tags compared to the other conditions. Although the quality of tags was lower, the number of usable tags remained significantly higher in comparison, suggesting the usefulness of this approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user-driven game design, motivation, replication, customization, bottom-up},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376376,
author = {Valencia, Stephanie and Pavel, Amy and Santa Maria, Jared and Yu, Seunga (Gloria) and Bigham, Jeffrey P. and Admoni, Henny},
title = {Conversational Agency in Augmentative and Alternative Communication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376376},
doi = {10.1145/3313831.3376376},
abstract = {Augmented communicators (ACs) use augmentative and alternative communication (AAC) technologies to speak. Prior work in AAC research has looked to improve efficiency and expressivity of AAC via device improvements and user training. However, ACs also face constraints in communication beyond their device and individual abilities such as when they can speak, what they can say, and who they can address. In this work, we recast and broaden this prior work using conversational agency as a new frame to study AC communication. We investigate AC conversational agency with a study examining different conversational tasks between four triads of expert ACs, their close conversation partners (paid aide or parent), and a third party (experimenter). We define metrics to analyze AAC conversational agency quantitatively and qualitatively. We conclude with implications for future research to enable ACs to easily exercise conversational agency.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {cerebral palsy, accessibility, aac, agency, conversation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376349,
author = {Pandey, Maulishree and Subramonyam, Hariharan and Sasia, Brooke and Oney, Steve and O'Modhrain, Sile},
title = {Explore, Create, Annotate: Designing Digital Drawing Tools with Visually Impaired People},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376349},
doi = {10.1145/3313831.3376349},
abstract = {People often use text in their drawings to communicate their ideas. For visually impaired people, adding textual information to tactile graphics is challenging. Labeling in braille is a laborious process and clutters the drawings. Audio labels provide an alternative way to add text. However, digital drawing tools for visually impaired people have not examined the use of audio for creating labels. We conducted a study comprising three tasks with 11 visually impaired adults. Our goal was to understand how participants explored and created labeled tactile graphics (both braille and audio), and their interaction preferences. We find that audio labels were quicker to use and easier to create. However, braille labels enabled flexible exploration strategies. We also find that participants preferred multimodal interaction commands, and report hand postures and movements observed during the drawing process for designing recognizable interactions. Based on our findings, we derive design implications for digital drawing tools.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {tactile graphics, blind, drawing applications, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376178,
author = {Swart, Michael and Lopez, Ylana and Mathur, Arunesh and Chetty, Marshini},
title = {Is This An Ad?: Automatically Disclosing Online Endorsements On YouTube With AdIntuition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376178},
doi = {10.1145/3313831.3376178},
abstract = {Undisclosed online endorsements on social media can be misleading to users who may not know when viewed content contains advertisements. Despite federal regulations requiring content creators to disclose online endorsements, studies suggest that less than 10% do so in practice. To overcome this issue, we need knowledge of how to best detect online endorsements, knowledge about how prevalent online endorsements are in the wild, and ways to design systems to automatically disclose advertising content to viewers. To that end, we designed, implemented, and evaluated a tool called AdIntuition which automatically discloses when YouTube videos contain affiliate marketing, a type of social media endorsement. We evaluated AdIntuition with 783 users using a survey, field deployment, and diary study. We discuss our findings and recommendations for future measurements of and tools to detect and alert users about affiliate marketing content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {influencer, social media, browser extension, advertisements},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376658,
author = {Barbareschi, Giulia and Holloway, Catherine and Arnold, Katherine and Magomere, Grace and Wetende, Wycliffe Ambeyi and Ngare, Gabriel and Olenja, Joyce},
title = {The Social Network: How People with Visual Impairment Use Mobile Phones in Kibera, Kenya},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376658},
doi = {10.1145/3313831.3376658},
abstract = {Living in an informal settlement with a visual impairment can be very challenging resulting in social exclusion. Mobile phones have been shown to be hugely beneficial to people with sight loss in formal and high-income settings. However, little is known about whether these results hold true for people with visual impairment (VIPs) in informal settlements. We present the findings of a case study of mobile technology use by VIPs in Kibera, an informal settlement in Nairobi. We used contextual interviews, ethnographic observations and a co-design workshop to explore how VIPs use mobile phones in their daily lives, and how this use influences the social infrastructure of VIPs. Our findings suggest that mobile technology supports and shapes the creation of social infrastructure. However, this is only made possible through the existing support networks of the VIPs, which are mediated through four types of interaction: direct, supported, dependent and restricted.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {informal settlements, Kibera, ICT4D, participatory design, HCI4D, accessibility, Kenya},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376676,
author = {Hoggenmueller, Marius and Hespanhol, Luke and Tomitsch, Martin},
title = {Stop and Smell the Chalk Flowers: A Robotic Probe for Investigating Urban Interaction with Physicalised Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376676},
doi = {10.1145/3313831.3376676},
abstract = {HCI researchers have begun to more systematically study non-digital transient approaches for displaying information in public space, for example, in the form of chalk infographics. These approaches provide several benefits compared to digital displays, such as: ad-hoc deployment, barrier-free interaction, and being more sustainable. However, one limitation is their hyperlocal scale and impact. Speculating on urban robots as agents for scaling up physicalised displays, we describe the exploratory design and deployment of Woodie, a slow-moving robot that draws on the ground using conventional chalk sticks. We deployed Woodie for three weeks in a quiet laneway situated within a highly urbanised area. Data collected from observations, video logs and interviews revealed that Woodie successfully attracted people's attention and acted as a facilitator for collaborative, creative placemaking. Furthermore, Woodie provoked emotional responses and was perceived as a living being. Findings are interpreted to describe opportunities urban robots provide for the design of future pervasive urban displays.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {human-robot interaction, urban probe, urban media, design, pervasive displays, urban robotic displays, physicalised displays},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376782,
author = {Srinivasan, Arjun and Lee, Bongshin and Henry Riche, Nathalie and Drucker, Steven M. and Hinckley, Ken},
title = {InChorus: Designing Consistent Multimodal Interactions for Data Visualization on Tablet Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376782},
doi = {10.1145/3313831.3376782},
abstract = {While tablet devices are a promising platform for data visualization, supporting consistent interactions across different types of visualizations on tablets remains an open challenge. In this paper, we present multimodal interactions that function consistently across different visualizations, supporting common operations during visual data analysis. By considering standard interface elements (e.g., axes, marks) and grounding our design in a set of core concepts including operations, parameters, targets, and instruments, we systematically develop interactions applicable to different visualization types. To exemplify how the proposed interactions collectively facilitate data exploration, we employ them in a tablet-based system, InChorus that supports pen, touch, and speech input. Based on a study with 12 participants performing replication and factchecking tasks with InChorus, we discuss how participants adapted to using multimodal input and highlight considerations for future multimodal visualization systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tablet devices, pen, touch, speech, multimodal interaction, data visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376171,
author = {Wilson, Cara and Sitbon, Laurianne and Ploderer, Bernd and Opie, Jeremy and Brereton, Margot},
title = {Self-Expression by Design: Co-Designing the ExpressiBall with Minimally-Verbal Children on the Autism Spectrum},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376171},
doi = {10.1145/3313831.3376171},
abstract = {Expressing one's thoughts and feelings is a fundamental human need - the basis for communication and social interaction. We ask, how do minimally-verbal children on the autism spectrum express themselves? How can we better recognise instances of self-expression? And how might technologies support and encourage self-expression? To address these questions, we undertook co-design research at an autism-specific primary school with 20 children over one school year. This paper contributes six Modalities of Self-Expression, through which children self-express and convey their design insights. Each modality of self-expression can occur across two different dimensions (socio-expressive and auto-expressive) and can be of a fundamental or an integrative nature. Further, we contribute the design trajectory of a tangible ball prototype, the ExpressiBall, which - through voice, sounds, lights, and motion sensors - explores how tangible technologies can support this range of expressive modalities. Finally, we discuss the concept of Self-Expression by Design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tangible, multimodal, autism, self-expression, minimally-verbal, non-verbal, children, modalities, play},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376681,
author = {Wu, Te-Yen and Qi, Shutong and Chen, Junchi and Shang, MuJie and Gong, Jun and Seyed, Teddy and Yang, Xing-Dong},
title = {Fabriccio: Touchless Gestural Input on Interactive Fabrics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376681},
doi = {10.1145/3313831.3376681},
abstract = {We present Fabriccio, a touchless gesture sensing technique developed for interactive fabrics using Doppler motion sensing. Our prototype was developed using a pair of loop antennas (one for transmitting and the other for receiving), made of conductive thread that was sewn onto a fabric substrate. The antenna type, configuration, transmission lines, and operating frequency were carefully chosen to balance the complexity of the fabrication process and the sensitivity of our system for touchless hand gestures, performed at a 10 cm distance. Through a ten-participant study, we evaluated the performance of our proposed sensing technique across 11 touchless gestures as well as 1 touch gesture. The study result yielded a 92.8% cross-validation accuracy and 85.2% leave-one-session-out accuracy. We conclude by presenting several applications to demonstrate the unique interactions enabled by our technique on soft objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interactive fabrics, doppler effect, touchless gesture},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376645,
author = {Rubin, Jennifer D. and Blackwell, Lindsay and Conley, Terri D.},
title = {Fragile Masculinity: Men, Gender, and Online Harassment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376645},
doi = {10.1145/3313831.3376645},
abstract = {Harassment is a persistent problem in contemporary online environments, with women disproportionately experiencing its most severe forms. While critical scholars posit that online gender harassment may be linked to men's anxieties about fulfilling normative masculine gender roles, this relationship has not been examined by empirical research. We survey 264 young men between the ages of 18-24 about their masculinity anxieties and their perceptions of harassment directed at a woman on Twitter. We find that men who perceive themselves as less masculine than average men report higher endorsement of harassment. Further, we find that the relationship between masculinity anxieties and harassment endorsement is mediated by men's adherence to masculine norms and toxic disinhibition. We interpret these results through the lens of social media's specific affordances, and we discuss their implications for technology designers and other practitioners who wish to better detect, prevent, and remediate online harassment by accounting for the role of gender.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {women, misogyny, online harassment, social media, masculinity, gender},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376531,
author = {Wallace, Jayne and Montague, Kyle and Duncan, Trevor and Carvalho, Lu\'{\i}s P. and Koulidou, Nantia and Mahoney, Jamie and Morrissey, Kellie and Craig, Claire and Groot, Linnea Iris and Lawson, Shaun and Olivier, Patrick and Trueman, Julie and Fisher, Helen},
title = {ReFind: Design, Lived Experience and Ongoingness in Bereavement},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376531},
doi = {10.1145/3313831.3376531},
abstract = {We describe the design and use of ReFind, a handheld artefact made for people who are bereaved and are ready to re-explore their relationship to the deceased person. ReFind was made within a project seeking to develop new ways to curate and create digital media to support ongoingness - an active, dynamic component of continuing bonds. We draw on bereavement theory and care championing practices that enable a continued sense of connection between someone bereaved and a person who has died. We present the design development of ReFind and the lived experience of the piece by the first author. We discuss our wider methodology which includes autobiographical design and reflections on if and how the piece supported ongoing connections, the challenges faced, and insights gained.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {lived experience, autoethnography, ongoingness, bereavement, physical/digital, autobiographical, digital images, relational selves, grief, death, photographs, design, continuing bonds},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376363,
author = {Hui, Julie and Barber, Nefer Ra and Casey, Wendy and Cleage, Suzanne and Dolley, Danny C. and Worthy, Frances and Toyama, Kentaro and Dillahunt, Tawanna R.},
title = {Community Collectives: Low-Tech Social Support for Digitally-Engaged Entrepreneurship},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376363},
doi = {10.1145/3313831.3376363},
abstract = {With the rise of social media, entrepreneurs are feeling the pressure to adopt digital tools for their work. However, the upfront effort and resources needed to participate on these platforms is ever more complex, particularly in underresourced contexts. Through participatory action research over two years in Detroit's Eastside, we found that local entrepreneurs preferred to become engaged digitally through a community collective, which involved (a) resource-connecting organizations, (b) regular in-person meetings, (c) paper planning tools, and (d) practice and validation. Together, these elements combined to provide (1) awareness and willingness to use digital tools, (2) regular opportunities to build internet self-efficacy, and (3) ways to collectively overcome digital obstacles. We discuss our findings in the context of digital engagement and entrepreneurship, and outline recommendations for digital platforms seeking to better support economic mobility more broadly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {entrepreneurship, participatory action research, qualitative methods, community informatics, digital divide, digital literacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376610,
author = {Jiang, Yue and Stuerzlinger, Wolfgang and Zwicker, Matthias and Lutteroth, Christof},
title = {ORCSolver: An Efficient Solver for Adaptive GUI Layout with OR-Constraints},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376610},
doi = {10.1145/3313831.3376610},
abstract = {OR-constrained (ORC) graphical user interface layouts unify conventional constraint-based layouts with flow layouts, which enables the definition of flexible layouts that adapt to screens with different sizes, orientations, or aspect ratios with only a single layout specification. Unfortunately, solving ORC layouts with current solvers is time-consuming and the needed time increases exponentially with the number of widgets and constraints. To address this challenge, we propose ORCSolver, a novel solving technique for adaptive ORC layouts, based on a branch-and-bound approach with heuristic preprocessing. We demonstrate that ORCSolver simplifies ORC specifications at runtime and our approach can solve ORC layout specifications efficiently at near-interactive rates.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {constraint-based layout, visual interface design, optimization, layout manager, gui builder, visual programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376597,
author = {Yoo, Daisy and Tabard, Aur\'{e}lien and Ducros, Alix and Dalsgaard, Peter and Klokmose, Clemens Nylandsted and Eriksson, Eva and Serholt, Sofia},
title = {Computational Alternatives Vignettes for Place- and Activity-Centered Digital Services in Public Libraries},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376597},
doi = {10.1145/3313831.3376597},
abstract = {We investigate how to design community technologies for public events. We do so with a focus on technologies that give rise to new forms of participation and knowledge co-production in public libraries. Specifically, we deployed a digital service at a major public library during its four-week creative workshop series. The system offered an alternative way for people to work together as a community, to go beyond achieving individual goals, and to contribute to the achievement of public goals (e.g., building community bookshelves). We report on how the system has reconfigured physical spaces and afforded new social practices in the library. We propose Computational Alternatives as a fruitful approach for gaining situated, nuanced insights into a technology's possible adoption. We offer key insights in the form of computational alternatives vignettes -- grounded stories that encapsulate sociotechnical implications of technology, pointing to plausible alternative futures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {knowledge sharing, place-centric, public libraries, third places, computational alternatives, library events},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376153,
author = {Clegg, Tamara and Greene, Daniel M. and Beard, Nate and Brunson, Jasmine},
title = {Data Everyday: Data Literacy Practices in a Division I College Sports Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376153},
doi = {10.1145/3313831.3376153},
abstract = {Data analysis is central to sports training. Today, cutting-edge digital technologies are deployed to measure and improve athletes' performance. But too often researchers focus on the technology collecting performance data at the expense of understanding athletes' experiences with data. This is particularly the case in the understudied context of collegiate athletics, where competition is fierce, tools for data analysis abound, and the institution actively manages athletes' lives. By investigating how student-athletes analyze their performance data and are analyzed in turn, we can better understand the individual and institutional factors that make data literacy practices in athletics meaningful and productive-or not. Our pilot interview study of student-athletes at one Division I university reveals a set of opportunities for student-athletes to engage with and learn from data analytics practices. These opportunities come with a set of contextual tensions that should inform the design of new technologies for collegiate sports settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hci and sports, data literacy, personal informatics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376356,
author = {Markum, Robert B. and Toyama, Kentaro},
title = {Digital Technology, Meditative and Contemplative Practices, and Transcendent Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376356},
doi = {10.1145/3313831.3376356},
abstract = {Meditative and contemplative practices are common among U.S. adults, but the impact of digital technology use on these practices and on associated transcendent experiences is poorly understood. Through semi-structured interviews with sixteen experienced practitioners from a variety of traditions, we find that practitioners consider digital technology to be a mixed blessing. While they see its practical value, they are wary of its stimulation-based effects and find minimal usefulness in commercial meditation apps. They also feel that digital technology use may interfere with possible transcendent experiences. The practitioners, however, applied insights from their respective practices to strategically mitigate digital technology's negative effects in three ways: limiting its use to instrumental purposes, using technology interactions as grist for self-reflection, and integrating technology itself into a site for practice. Specific design recommendations are discussed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {techno-spirituality, meditative and contemplative practices, digital technology, transcendent experiences},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376704,
author = {Gan, Yumei and Greiffenhagen, Christian and Reeves, Stuart},
title = {Connecting Distributed Families: Camera Work for Three-Party Mobile Video Calls},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376704},
doi = {10.1145/3313831.3376704},
abstract = {Mobile video calling technologies have become a critical link to connect distributed families. However, these technologies have been principally designed for video calling between two parties, whereas family video calls involve young children often comprise three parties, namely a co-present adult (a parent or grandparent) helping with the interaction between the child and another remote adult. We examine how manipulation of phone cameras and management of co-present children is used to stage parent-child interactions. We present results from a video-ethnographic study based on 40 video recordings of video calls between 'left-behind' children and their migrant parents in China. Our analysis reveals a key practice of 'facilitation work', performed by grandparents, as a crucial feature of three-party calls. Facilitation work offers a new concept for HCI's broader conceptualisation of mobile video calling, suggesting revisions that design might take into consideration for triadic interactions in general.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {camera work, conversation analysis, mobile video calls, distributed families, facilitation work},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376850,
author = {Olgado, Benedict Salazar and Pei, Lucy and Crooks, Roderic},
title = {Determining the Extractive Casting Mold of Intimate Platforms through Document Theory},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376850},
doi = {10.1145/3313831.3376850},
abstract = {This paper introduces document theory as a mechanism to analyze intimate platforms as sociotechnical systems. The theory, developed in documentation studies and applied to HCI, focuses on the casting mold or how agents, through particular means and modes, produce documents that govern social relations. We studied the process of creating a profile by identifying and mapping out the fields asked among the ten most popular online dating apps in the US. By looking at dating profiles as documents and their creation as a process of documentation, we argue that the current casting mold of these intimate platforms is designed to extract profit via invisibilization of labor in digital networks leading to the emergence of a constrained rational market agent. Our study illustrates how document theory makes visible the assumptions of technological systems, calling on us to imagine alternatives beyond incremental design changes given broader structural realities of market and power.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {document theory, intimate platforms, political economy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376848,
author = {Wacker, Philipp and Wagner, Adrian and Voelker, Simon and Borchers, Jan},
title = {Heatmaps, Shadows, Bubbles, Rays: Comparing Mid-Air Pen Position Visualizations in Handheld AR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376848},
doi = {10.1145/3313831.3376848},
abstract = {In Handheld Augmented Reality, users look at AR scenes through the smartphone held in their hand. In this setting, having a mid-air pointing device like a pen in the other hand greatly expands the interaction possibilities. For example, it lets users create 3D sketches and models while on the go. However, perceptual issues in Handheld AR make it difficult to judge the distance of a virtual object, making it hard to align a pen to it. To address this, we designed and compared different visualizations of the pen's position in its virtual environment, measuring pointing precision, task time, activation patterns, and subjective ratings of helpfulness, confidence, and comprehensibility of each visualization. While all visualizations resulted in only minor differences in precision and task time, subjective ratings of perceived helpfulness and confidence favor a 'heatmap' technique that colors the objects in the scene based on their distance to the pen.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {depth cues, smartphone, mid-air, depth perception, 3D pen, modeling, interaction, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376192,
author = {Fern\'{a}ndez Camporro, Marina and Marquardt, Nicolai},
title = {Live Sketchnoting Across Platforms: Exploring the Potential and Limitations of Analogue and Digital Tools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376192},
doi = {10.1145/3313831.3376192},
abstract = {Sketchnoting is the process of creating a visual record with combined text and imagery of an event or presentation. Although analogue tools are still the most common method for sketchnoting, the use of digital tools is increasing. We conducted a study to better understand the current practices, techniques, compromises and opportunities of creating both pen&amp;paper and digital sketchnotes. Our research combines insights from semi-structured interviews with the findings from a within-subjects observational study where ten participants created real time sketchnotes of two video presentations on both paper and digital tablet. We report our key findings, categorised into six themes: insights into sense of space; trade-offs with flexibility; choice paradox and cognitive load; matters of perception, accuracy and texture; issues around confidence; and practicalities. We discuss those findings, the potential and limitations of different methods, and implications for the design of future digital sketchnoting tools.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {tablet, sketching, visual note taking, sketchnoting, digital ink, pen interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376821,
author = {Rietzler, Michael and Deubzer, Martin and Dreja, Thomas and Rukzio, Enrico},
title = {Telewalk: Towards Free and Endless Walking in Room-Scale Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376821},
doi = {10.1145/3313831.3376821},
abstract = {Natural navigation in VR is challenging due to spatial limitations. While Teleportation enables navigation within very small physical spaces and without causing motion sickness symptoms, it may reduce the feeling of presence and spacial awareness. Redirected walking (RDW), in contrast, allows users to naturally walk while staying inside a finite, but still very large, physical space. We present Telewalk, a novel locomotion approach that combines curvature and translation gains known from RDW research in a perceivable way. This combination enables Telewalk to be applied even within a physical space of 3m x 3m. Utilizing the head rotation as input device enables directional changes without any physical turns to keep the user always on an optimal circular path inside the real world while freely walking inside the virtual one. In a user study we found that even though motion sickness susceptible participants reported respective symptoms, Telewalk did result in stronger feelings of presence and immersion and was seen as more natural then Teleportation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {virtual reality, redirected walking, Telewalk},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376255,
author = {Tabassum, Madiha and Kropczynski, Jess and Wisniewski, Pamela and Lipford, Heather Richter},
title = {Smart Home Beyond the Home: A Case for Community-Based Access Control},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376255},
doi = {10.1145/3313831.3376255},
abstract = {As smart devices are becoming commonplace in homes, we need to explore the needs of not just the residents of the home, but also of secondary stakeholders who may be granted access to these devices from outside of the home. We conducted a mixed methods study, which included a survey of 163 smart home device owners and a follow-up interview with 13 individuals who currently share their smart home devices with others outside of their home. Nearly half (47.8%) of our survey participants shared at least one smart home device with someone that did not live with them. Individuals sought greater safety and security by providing remote access to trusted family members or friends. By understanding users' perspectives about privacy and trust in relation to sharing smart home devices beyond the home, we build a case for community-based access control of smart home devices in the Internet of Things.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {smart home, access control, community},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376196,
author = {Creed, Chris and Frutos-Pascual, Maite and Williams, Ian},
title = {Multimodal Gaze Interaction for Creative Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376196},
doi = {10.1145/3313831.3376196},
abstract = {We present a new application ("Sakura") that enables people with physical impairments to produce creative visual design work using a multimodal gaze approach. The system integrates multiple features tailored for gaze interaction including the selection of design artefacts via a novel grid approach, control methods for manipulating canvas objects, creative typography, a new color selection approach, and a customizable guide technique facilitating the alignment of design elements. A user evaluation (N=24) found that non-disabled users were able to utilize the application to complete common design activities and that they rated the system positively in terms of usability. A follow-up study with physically impaired participants (N=6) demonstrated they were able to control the system when working towards a website design, rating the application as having a good level of usability. Our research highlights new directions in making creative activities more accessible for people with physical impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interface design, eye gaze design, gaze interaction, eye gaze tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376509,
author = {Kj\ae{}rup, Maria and Skov, Mikael B. and Agerholm, Niels},
title = {Digital-Enabled Last Mile: A Study of Passenger Trips in Rural, Low-Density Populated Areas},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376509},
doi = {10.1145/3313831.3376509},
abstract = {Public transportation in rural areas is difficult due to low numbers of passengers and diverse needs, also reflected in the last mile problem that points to the distance to access transportation hubs in order to connect with core networks of transportation. In this paper, we study public transportation in rural areas using a digital-enabled, demand-responsive service called Plustur. This service was recently introduced as an effort to increase mobility in underserved rural areas by creating routes ad-hoc to answer to the last mile(s). We study how passengers and drivers understand Plustur, as well as experience the role of passenger. Our findings show that Plustur is viewed as a benefit for autonomy of mobility in rural areas, however is lacking in addressing integration of modes of mobilities, flexibility and spontaneous trips. We contribute with design implications for digital multimodal mobility services.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {demand-responsive transit, mobility on demand, mobility as a service, digital-enabled passenger trips},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376393,
author = {Wong, Pui Chung and Zhu, Kening and Yang, Xing-Dong and Fu, Hongbo},
title = {Exploring Eyes-Free Bezel-Initiated Swipe on Round Smartwatches},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376393},
doi = {10.1145/3313831.3376393},
abstract = {Bezel-based gestures expand the interaction space of touch-screen devices (e.g., smartphones and smartwatches). Existing works have mainly focused on bezel-initiated swipe (BIS) on square screens. To investigate the usability of BIS on round smartwatches, we design six different circular bezel layouts, by dividing the bezel into 6, 8, 12, 16, 24, and 32 segments. We evaluate the user performance of BIS on these layouts in an eyes-free situation. The results show that the performance of BIS is highly orientation dependent, and varies significantly among users. Using the Support-Vector-Machine (SVM) model significantly increases the accuracy on 6-, 8-, 12-, and 16-segment layouts. We then compare the performance of personal and general SVM models, and find that personal models significantly improve the accuracy for 8-, 12-, 16-, and 24-segment layouts. Lastly, we discuss the potential smartwatch applications enabled by the BIS.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {bezel, eyes-free, bezel-initiated gestures, round smartwatches},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376631,
author = {Garg, Radhika and Sengupta, Subhasree},
title = {Conversational Technologies for In-Home Learning: Using Co-Design to Understand Children's and Parents' Perspectives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376631},
doi = {10.1145/3313831.3376631},
abstract = {Today, Conversational Agents (CA) are deeply integrated into the daily lives of millions of families, which has led children to extensively interact with such devices. Studies have suggested that the social nature of CA makes them a good learning companion for children. Therefore, to understand children's preferences for the use of CAs for the purpose of in-home learning, we conducted three participatory design sessions. In order to identify parents' requirements in this regard, we also included them in the third session. We found that children expect such devices to possess a personality and an advanced level of intelligence, and support multiple content domains and learning modes and human-like conversations. Parents desire such devices to include them in their children's learning activities, foster social engagement, and to allow them to monitor their children's use. This understanding will inform the design of future CAs for the purpose of in-home learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {participatory design, cooperative inquiry, learning, conversational agents, parents, home, learning technology, learning companion, co-design, children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376582,
author = {Bahng, Sojung and Kelly, Ryan M. and McCormack, Jon},
title = {Reflexive VR Storytelling Design Beyond Immersion: Facilitating Self-Reflection on Death and Loneliness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376582},
doi = {10.1145/3313831.3376582},
abstract = {This research examines the reflexive dimensions of cinematic virtual reality (CVR) storytelling. We created Anonymous, an interactive CVR piece that employs a reflexive storytelling method. This method is based on distancing effects and is used to elicit audience awareness and self-reflection about loneliness and death. To understand the audience's experiences, we conducted in-depth interviews to study which design factors and elements prompted reflexive thoughts and feelings. Our findings highlight how the audience experience was impacted by four reflexive dimensions: abstract and minimal aesthetics, everyday materials and textures, the restriction of control, and multiple, disembodied points of view. We use our findings to discuss how these dimensions can inform the design of VR storytelling experiences that provoke self and social reflection.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {alienation, immersive storytelling, distancing effect, virtual reality, cinematic vr, reflexivity, estrangement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376852,
author = {M\"{u}ller, Florian and Schmitz, Martin and Schmitt, Daniel and G\"{u}nther, Sebastian and Funk, Markus and M\"{u}hlh\"{a}user, Max},
title = {Walk The Line: Leveraging Lateral Shifts of the Walking Path as an Input Modality for Head-Mounted Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376852},
doi = {10.1145/3313831.3376852},
abstract = {Recent technological advances have made head-mounted displays (HMDs) smaller and untethered, fostering the vision of ubiquitous interaction in a digitally augmented physical world. Consequently, a major part of the interaction with such devices will happen on the go, calling for interaction techniques that allow users to interact while walking. In this paper, we explore lateral shifts of the walking path as a hands-free input modality. The available input options are visualized as lanes on the ground parallel to the user's walking path. Users can select options by shifting the walking path sideways to the respective lane. We contribute the results of a controlled experiment with 18 participants, confirming the viability of our approach for fast, accurate, and joyful interactions. Further, based on the findings of the controlled experiment, we present three example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {augmented reality, input, head-mounted display, walking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376771,
author = {Zhu, Suwen and Kim, Yoonsang and Zheng, Jingjie and Luo, Jennifer Yi and Qin, Ryan and Wang, Liuping and Fan, Xiangmin and Tian, Feng and Bi, Xiaojun},
title = {Using Bayes' Theorem for Command Input: Principle, Models, and Applications},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376771},
doi = {10.1145/3313831.3376771},
abstract = {Entering commands on touchscreens can be noisy, but existing interfaces commonly adopt deterministic principles for deciding targets and often result in errors. Building on prior research of using Bayes' theorem to handle uncertainty in input, this paper formalized Bayes' theorem as a generic guiding principle for deciding targets in command input (referred to as "BayesianCommand"), developed three models for estimating prior and likelihood probabilities, and carried out experiments to demonstrate the effectiveness of this formalization. More specifically, we applied BayesianCommand to improve the input accuracy of (1) point-and-click and (2) word-gesture command input. Our evaluation showed that applying BayesianCommand reduced errors compared to using deterministic principles (by over 26.9% for point-and-click and by 39.9% for word-gesture command input) or applying the principle partially (by over 28.0% and 24.5%).},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {bayes' theorem, command input, touchscreen, point-and-click, word-gesture shortcuts},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376515,
author = {Wong, Richmond Y. and Khovanskaya, Vera and Fox, Sarah E. and Merrill, Nick and Sengers, Phoebe},
title = {Infrastructural Speculations: Tactics for Designing and Interrogating Lifeworlds},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376515},
doi = {10.1145/3313831.3376515},
abstract = {This paper introduces "infrastructural speculations," an orientation toward speculative design that considers the complex and long-lived relationships of technologies with broader systems, beyond moments of immediate invention and design. As modes of speculation are increasingly used to interrogate questions of broad societal concern, it is pertinent to develop an orientation that foregrounds the "lifeworld" of artifacts-the social, perceptual, and political environment in which they exist. While speculative designs often imply a lifeworld, infrastructural speculations place lifeworlds at the center of design concern, calling attention to the cultural, regulatory, environmental, and repair conditions that enable and surround particular future visions. By articulating connections and affinities between speculative design and infrastructure studies research, we contribute a set of design tactics for producing infrastructural speculations. These tactics help design researchers interrogate the complex and ongoing entanglements among technologies, institutions, practices, and systems of power when gauging the stakes of alternate lifeworlds.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {lifeworld, futures, infrastructure, design research, speculative design, infrastructure studies},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376835,
author = {Chen, Yan and Pandey, Maulishree and Song, Jean Y. and Lasecki, Walter S. and Oney, Steve},
title = {Improving Crowd-Supported GUI Testing with Structural Guidance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376835},
doi = {10.1145/3313831.3376835},
abstract = {Crowd testing is an emerging practice in Graphical User Interface (GUI) testing, where developers recruit a large number of crowd testers to test GUI features. It is often easier and faster than a dedicated quality assurance team, and its output is more realistic than that of automated testing. However, crowds of testers working in parallel tend to focus on a small set of commonly-used User Interface (UI) navigation paths, which can lead to low test coverage and redundant effort. In this paper, we introduce two techniques to increase crowd testers' coverage: interactive event-flow graphs and GUI-level guidance. The interactive event-flow graphs track and aggregate every tester's interactions into a single directed graph that visualizes the cases that have already been explored. Crowd testers can interact with the graphs to find new navigation paths and increase the coverage of the created tests. We also use the graphs to augment the GUI (GUI-level guidance) to help testers avoid only exploring common paths. Our evaluation with 30 crowd testers on 11 different test pages shows that the techniques can help testers avoid redundant effort while also increasing untrained testers' coverage by 55%. These techniques can help us develop more robust software that works in more mission-critical settings not only by performing more thorough testing with the same effort that has been put in before but also by integrating them into different parts of the development pipeline to make more reliable software in the early development stage.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {software testing, crowdsourcing, GUI testing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376470,
author = {Fang, Cathy and Zhang, Yang and Dworman, Matthew and Harrison, Chris},
title = {Wireality: Enabling Complex Tangible Geometries in Virtual Reality with Worn Multi-String Haptics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376470},
doi = {10.1145/3313831.3376470},
abstract = {Today's virtual reality (VR) systems allow users to explore immersive new worlds and experiences through sight. Unfortunately, most VR systems lack haptic feedback, and even high-end consumer systems use only basic vibration motors. This clearly precludes realistic physical interactions with virtual objects. Larger obstacles, such as walls, railings, and furniture are not simulated at all. In response, we developed Wireality, a self-contained worn system that allows for individual joints on the hands to be accurately arrested in 3D space through the use of retractable wires that can be programmatically locked. This allows for convincing tangible interactions with complex geometries, such as wrapping fingers around a railing. Our approach is lightweight, low-cost, and low-power, criteria important for future, worn consumer uses. In our studies, we further show that our system is fast-acting, spatially-accurate, high-strength, comfortable, and immersive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {string-driven, grasp, force feedback, haptics, touch, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376452,
author = {Son, Kihoon and Chun, Hwiwon and Park, Sojin and Hyun, Kyung Hoon},
title = {C-Space: An Interactive Prototyping Platform for Collaborative Spatial Design Exploration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376452},
doi = {10.1145/3313831.3376452},
abstract = {C-Space is an interactive prototyping platform for collaborative spatial design exploration. Spatial design projects often begin with conceptualization that includes abstract diagramming, zoning, and massing to provide a foundation for making design decisions. Specifically, abstract diagrams guide designers to explore alternative designs without thinking prematurely about the details. However, complications arise when communicating ambiguous and incomplete designs to collaborators. To overcome this drawback, designers devote considerable amounts of time and resources into searching for design references and creating rough prototypes to explicate their design concepts better. Therefore, this study proposes C-Space, a novel design support system that integrates the abstract diagram with design reference retrieval and prototyping through a tangible user interface and augmented reality. Through a user study with 12 spatial designers, we verify that C-Space promotes rapid and robust spatial design exploration, inducing collaborative discussions and motivating users to interact with designs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-computer interaction, spatial design, design collaboration, tangible user interface, design support system, prototyping, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376830,
author = {Kim, Yoojung and Bhattacharya, Arpita and Kientz, Julie A. and Lee, Jin Ha},
title = {"It Should Be a Game for Fun, Not Exercise": Tensions in Designing Health-Related Features for Pok\'{e}Mon GO},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376830},
doi = {10.1145/3313831.3376830},
abstract = {Leveraging existing popular games such as Pok\'{e}mon GO to promote health can engage people in healthy activities without sacrificing gaming appeal. However, little is known about what potential tensions arise from incorporating new health-related features to already existing and popular games and how to resolve those tensions from players' perspectives. In this paper, we identify design tensions surrounding the appeals of Pok\'{e}mon GO, perspectives on different health needs, and mobile health technologies. By conducting surveys and design workshops with 20 avid Pok\'{e}mon GO players, we demonstrate four design tensions: (1) diverse goals and rewards vs. data accuracy, (2) strong bonds between players and characters vs. gaming obsession, (3) collaborative play vs. social anxiety, and (4) connection of in-real-life experiences with the game vs. different individual contexts. We provide design implications to resolve these tensions in Pok\'{e}mon GO and discuss how to extend our findings to the broader context of health promotion in location-based games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {location-based game, game design, health-related game feature, design tension, pokemon go, augmented reality game, health promotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376753,
author = {Hu, Donghan and Lee, Sang Won},
title = {ScreenTrack: Using a Visual History of a Computer Screen to Retrieve Documents and Web Pages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376753},
doi = {10.1145/3313831.3376753},
abstract = {Computers are used for various purposes and frequent context switch is inevitable. In this setting, retrieving the documents, files, and web pages that have been used for a task can be a challenge. While modern applications provide a history of recent documents for users to resume work, this is not sufficient to retrieve all the digital resources relevant to a given primary document. The histories currently available - file names, web page titles, or URLs - does not take into account the complex dependencies that exist among resources across applications. To address this problem, we tested the idea of using a visual history of a computer screen to retrieve digital resources within a few days through the development of ScreenTrack. ScreenTrack is software that captures screenshots of a computer at regular intervals. It then generates a time-lapse video from the captured screenshots and lets users retrieve a recently opened document or web page from a screenshot that they recognize from its visuals. Through a controlled user study, it was found that participants were able to retrieve requested information more quickly with ScreenTrack than under the control condition. A follow-up study showed that the participants used ScreenTrack to retrieve previously used resources, in order to resume interrupted tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {self-tracking, task resumption, productivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376503,
author = {Iravantchi, Yasha and Goel, Mayank and Harrison, Chris},
title = {Digital Ventriloquism: Giving Voice to Everyday Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376503},
doi = {10.1145/3313831.3376503},
abstract = {Smart speakers with voice agents are becoming increasingly common. However, the agent's voice always emanates from the device, even when that information is contextually and spatially relevant elsewhere. Digital Ventriloquism allows smart speakers to render sound onto everyday objects, such that it appears they are speaking and are interactive. This can be achieved without any modification of objects or the environment. For this, we used a highly directional pan-tilt ultrasonic array. By modulating a 40 kHz ultrasonic signal, we can emit sound that is inaudible "in flight" and demodulates to audible frequencies when impacting a surface through acoustic parametric interaction. This makes it appear as though the sound originates from an object and not the speaker. We ran a study in which we projected speech onto five objects in three environments, and found that participants were able to correctly identify the source object 92% of the time and correctly repeat the spoken message 100% of the time, demonstrating our digital ventriloquy is both directional and intelligible.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {iot, vr/ar, interaction, smart speakers, ultrasound},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376148,
author = {Martinez-Maldonado, Roberto and Echeverria, Vanessa and Fernandez Nieto, Gloria and Buckingham Shum, Simon},
title = {From Data to Insights: A Layered Storytelling Approach for Multimodal Learning Analytics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376148},
doi = {10.1145/3313831.3376148},
abstract = {Significant progress to integrate and analyse multimodal data has been carried out in the last years. Yet, little research has tackled the challenge of visualising and supporting the sensemaking of multimodal data to inform teaching and learning. It is na\"{\i}ve to expect that simply by rendering multiple data streams visually, a teacher or learner will be able to make sense of them. This paper introduces an approach to unravel the complexity of multimodal data by organising it into meaningful layers that explain critical insights to teachers and students. The approach is illustrated through the design of two data storytelling prototypes in the context of nursing simulation. Two authentic studies with educators and students identified the potential of the approach to create learning analytics interfaces that communicate insights on team performance, as well as concerns in terms of accountability and automated insights discovery.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {CSCW, visualization, teamwork, data storytelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376795,
author = {Avellino, Ignacio and Bailly, Gilles and Arico, Mario and Morel, Guillaume and Canlorbe, Geoffroy},
title = {Multimodal and Mixed Control of Robotic Endoscopes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376795},
doi = {10.1145/3313831.3376795},
abstract = {Bedside robotic endoscopes render surgeons autonomous from assistants, potentially improving surgical outcome and decreasing costs. Why then have they not been widely adopted? We take a step back and first characterize classic (non-robotic) endoscope use through observations, literature and a domain expert interview. We review the literature on bedside robotic endoscopes and find that existing controls, individually, do not have the power to support both intended and appropriated endoscope uses. We thus explore combining controls to support this diversity of uses. Through an iterative cycle, we design and implement a multimodal and mixed-initiative technique that combines two user controls and one system control. Our evaluations confirm that individual controls do not satisfy the diversity of endoscope uses, and also that our technique indeed does so. Our work highlights the relevance of HCI research in the medical domain through robotic systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mixed-initiative interfaces, minimally invasive surgery, robotic endoscope manipulator},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376292,
author = {Wang, Bo-Xiang and Wang, Yu-Wei and Chen, Yen-Kai and Tseng, Chun-Miao and Hsu, Min-Chien and Hsieh, Cheng An and Lee, Hsin-Ying and Chen, Mike Y.},
title = {Miniature Haptics: Experiencing Haptic Feedback through Hand-Based and Embodied Avatars},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376292},
doi = {10.1145/3313831.3376292},
abstract = {We present Miniature Haptics, a new approach to providing realistic haptic experiences by applying miniaturized haptic feedback to hand-based, embodied avatars. By shrinking haptics to a much smaller scale, Miniature Haptics enables the exploration of new haptic experiences that are not practical to create at the full, human-body scale. Using Finger Walking in Place (FWIP) as an example avatar embodiment and control method, we first explored the feasibility of Miniature Haptics then conducted a human factors study to understand how people map their full-body skeletal model to their hands. To understand the user experience of Miniature Haptic, we developed a miniature football haptic display, and results from our user study show that Miniature Haptics significantly improved the realism and enjoyment of the experience and is preferred by users (p &lt; 0.05). In addition, we present two miniature motion platforms supporting the haptic experiences of: 1) rapidly changing ground height for platform jumping games such as Super Mario Bros and 2) changing terrain slope. Overall, Miniature Haptics makes it possible to explore novel haptic experiences that have not been practical before.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {finger walking, haptics, embodiment illusion, embodied avatar},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376491,
author = {Muthukumarana, Sachith and Elvitigala, Don Samitha and Forero Cortes, Juan Pablo and Matthies, Denys J.C. and Nanayakkara, Suranga},
title = {Touch Me Gently: Recreating the Perception of Touch Using a Shape-Memory Alloy Matrix},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376491},
doi = {10.1145/3313831.3376491},
abstract = {We present a wearable forearm augmentation that enables the recreation of natural touch sensation by applying shear-forces onto the skin. In contrast to previous approaches, we arrange light-weight and stretchable 3x3cm plasters in a matrix onto the skin. Individual plasters were embedded with lines of shape-memory alloy (SMA) wires to generate shear-forces. Our design is informed by a series of studies investigating the perceptibility of different sizes, spacings, and attachments of plasters on the forearm. Our matrix arrangement enables the perception of touches, for instance, feeling ones wrist being grabbed or the arm being stroked. Users rated the recreated touch sensations as being fairly similar to a real touch (4.1/5). Even without a visual representation, users were able to correctly distinguish them with an overall accuracy of 94.75%. Finally, we explored two use cases showing how AR and VR could be empowered with experiencing recreated touch sensations on the forearm.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touch perception, shape memory alloys, recreation of touch, haptics, pinching, wearable},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376432,
author = {Dixon, Emma and Lazar, Amanda},
title = {Approach Matters: Linking Practitioner Approaches to Technology Design for People with Dementia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376432},
doi = {10.1145/3313831.3376432},
abstract = {Technology design for dementia is an active and growing area. Though work to date has largely addressed functional needs, there is a growing recognition of the importance of supporting meaningful activities. However, technology for active, rather than passive, engagement is relatively novel beyond specific applications (e.g., music or reminiscence therapy). To better understand how to support active engagement of people with dementia in activities, we interviewed nineteen practitioners. Our findings reveal differing approaches to making sense of the actions of people with dementia, as well as to engaging them in activities. We discuss the importance of tracing epistemological understandings of dementia to different configurations of technology for people living with dementia and provide a practical guide to support designers to do so. Finally, we discuss considerations for the design of dementia technologies around facilitating self-actualization and managing emotional exposure for care-providers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {practitioners, dementia, design, meaningful activities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376561,
author = {Wang, Jinping and Yang, Hyun and Shao, Ruosi and Abdullah, Saeed and Sundar, S. Shyam},
title = {Alexa as Coach: Leveraging Smart Speakers to Build Social Agents That Reduce Public Speaking Anxiety},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376561},
doi = {10.1145/3313831.3376561},
abstract = {Public speaking anxiety is one of the most common social phobias. We explore the feasibility of using a conversational agent to reduce this anxiety. We developed a public-speaking tutor on the Amazon Alexa platform that enables users to engage in cognitive reconstruction exercises. We also investigated how the sociability of the agent might affect its performance as a tutor. A user study of 53 college students with fear of public speaking showed that the interaction with the agent served to assuage pre-speech state anxiety. Agent sociability improved the sense of interpersonal closeness, which was associated with lower pre-speech anxiety. Moreover, sociability of the agent increased participants' satisfaction and their willingness to continue engagement. Our findings, thus, have implications not only for addressing public speaking anxiety in a scalable way but also for the design of future conversational agents using smart speaker platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {public speaking anxiety, conversational agent, experiment, sociability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376187,
author = {Parviainen, Emmi and S\o{}ndergaard, Marie Louise Juul},
title = {Experiential Qualities of Whispering with Voice Assistants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376187},
doi = {10.1145/3313831.3376187},
abstract = {We present a Research through Design project that explores how whispering influences the ways people experience and interact with voice assistants. The research project includes a co-speculation workshop and the use of a design probe, which culminated in the production of a design fiction short film. Our design-led inquiry contributes with experiential qualities of whispering with voice assistants: creepiness, trust, and intimacy. Furthermore, we present how whispering opens up new dimensions of how and when voice interaction could be used. We propose that designers of whispering voice assistants should reflect on how they facilitate the experiential qualities of creepiness, trust, and intimacy, and reflect on the potential challenges whispering brings to the relation between a user and a voice assistant.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design fiction, research through design, voice interaction, whispering, experiential qualities, voice assistants},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376846,
author = {Williams, Francis and Bock, Alexander and Doraiswamy, Harish and Donatelli, Cassandra and Hall, Kayla and Summers, Adam and Panozzo, Daniele and Silva, Cl\'{a}udio T.},
title = {Unwind: Interactive Fish Straightening},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376846},
doi = {10.1145/3313831.3376846},
abstract = {The ScanAllFish project is a large-scale effort to scan all the world's 33,100 known species of fishes. It has already generated thousands of volumetric CT scans of fish species which are available on open access platforms such as the Open Science Framework. To achieve a scanning rate required for a project of this magnitude, many specimens are grouped together into a single tube and scanned all at once. The resulting data contain many fish which are often bent and twisted to fit into the scanner. Our system, Unwind, is a novel interactive visualization and processing tool which extracts, unbends, and untwists volumetric images of fish with minimal user interaction. Our approach enables scientists to interactively unwarp these volumes to remove the undesired torque and bending using a piecewise-linear skeleton extracted by averaging isosurfaces of a harmonic function connecting the head and tail of each fish. The result is a volumetric dataset of a individual, straight fish in a canonical pose defined by the marine biologist expert user. We have developed Unwind in collaboration with a team of marine biologists: Our system has been deployed in their labs, and is presently being used for dataset construction, biomechanical analysis, and the generation of figures for scientific publication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visual analytics, ct scan data, volumetric deformation, visualization, visualization toolkits, interactive system},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376551,
author = {Cho, Eugene and Sundar, S. Shyam and Abdullah, Saeed and Motalebi, Nasim},
title = {Will Deleting History Make Alexa More Trustworthy? Effects of Privacy and Content Customization on User Experience of Smart Speakers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376551},
doi = {10.1145/3313831.3376551},
abstract = {"Always-on" smart speakers have raised privacy and security concerns, to address which vendors have introduced customizable privacy settings. But, does the act of customizing one's privacy preferences have any effects on user experience and trust? To address this question, we developed an app for Amazon Alexa and conducted a user study (N = 90). Our data show that the affordance to customize privacy settings enhances trust and usability for regular users, while it has adverse effects on power users. In addition, only enabling privacy-setting customization without allowing content customization negatively affects trust among users with higher privacy concerns. When they can customize both content and privacy settings, user trust is highest. That is, while privacy customization may cause reactance among power users, allowing privacy-concerned individuals to simultaneously customize content can help to alleviate the resultant negative effect on trust. These findings have implications for designing more privacy-sensitive and trustworthy smart speakers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {customization, power usage, security, voice assistant(s), privacy concern, smart speaker(s)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376747,
author = {Ghosh, Arup Kumar and Hughes, Charles E. and Wisniewski, Pamela J.},
title = {Circle of Trust: A New Approach to Mobile Online Safety for Families},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376747},
doi = {10.1145/3313831.3376747},
abstract = {Traditional parental control applications designed to protect children and teens from online risks do so through parental restrictions and privacy-invasive monitoring. We propose a new approach to adolescent online safety that aims to strike a balance between a teen's privacy and their online safety through active communication and fostering trust between parents and children. We designed and developed an Android "app" called Circle of Trust and conducted a mixed methods user study of 17 parent-child pairs to understand their perceptions about the app. Using a within-subjects experimental design, we found that parents and children significantly preferred our new app design over existing parental control apps in terms of perceived usefulness, ease of use, and behavioral intent to use. By applying a lens of Value Sensitive Design to our interview data, we uncovered that parents and children who valued privacy, trust, freedom, and balance of power preferred our app over traditional apps. However, those who valued transparency and control preferred the status quo. Overall, we found that our app was better suited for teens than for younger children.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mobile smart phones, parental mediation, adolescent online safety, technical monitoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376538,
author = {Raissi, Reyhaneh and Dimara, Evanthia and Berry, Jacquelyn H. and Gray, Wayne D. and Bailly, Gilles},
title = {Retroactive Transfer Phenomena in Alternating User Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376538},
doi = {10.1145/3313831.3376538},
abstract = {We investigated retroactive transfer when users alternate between different interfaces. Retroactive transfer is the influence of a newly learned interface on users' performance with a previously learned interface. In an interview study, participants described their experiences when alternating between different interfaces, e.g. different operating systems, devices or techniques. Negative retroactive transfer related to text entry was the most frequently reported incident. We then reported a laboratory experiment that investigated the impact of similarity between two abstract keyboard layouts, and the number of alternations between them, on retroactive interference. Results indicated that even small changes in the interference interface produced a significant performance drop for the entire previously learned interface. The amplitude of this performance drop decreases with the number of alternations. We suggest that retroactive transfer should receive more attention in HCI, as the ubiquitous nature of interactions across applications and systems requires users to increasingly alternate between similar interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {keyboard layout, skill transfer, retroactive interference},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376217,
author = {Li, Yang and Sarcar, Sayan and Kim, Sunjun and Ren, Xiangshi},
title = {Swap: A Replacement-Based Text Revision Technique for Mobile Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376217},
doi = {10.1145/3313831.3376217},
abstract = {Text revision is an important task to ensure the accuracy of text content. Revising text on mobile devices is cumbersome and time-consuming due to the imprecise caret control and the repetitive use of the backspace. We present Swap, a novel replacement-based technique to facilitate text revision on mobile devices. We conducted two user studies to validate the feasibility and the effectiveness of Swap compared to traditional text revision techniques. Results showed that Swap reduced efforts in caret control and repetitive backspace pressing during the text revision process. Most participants preferred to use the replacement-based technique rather than backspace and caret. They also commented that the new technique is easy to learn, and it makes text revision rapid and intuitive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual keyboard, backspace, mobile device, text revision, caret control},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376859,
author = {Altarriba Bertran, Ferran and M\'{a}rquez Segura, Elena and Isbister, Katherine},
title = {Technology for Situated and Emergent Play: A Bridging Concept and Design Agenda},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376859},
doi = {10.1145/3313831.3376859},
abstract = {Despite the capacity of play to spontaneously emerge in our daily life, the scope of application of play design in HCI is generally narrower, specifically targeting areas of pure leisure, or wholly utilitarian and productive play. Here we focus on the value of play design to respond to and support our natural gravitation towards emergent play that helps to meet our social and emotional needs. We present a bridging concept: Technology for Situated and Emergent Play, i.e. technology design that supports playful engagement that emerges interwoven with our everyday activities outside leisure, and that enriches these activities with socio-emotional value. Our intermediate-level contribution has value as a synthesis piece: it weaves together theories of play and play design and bridges them with concrete design examples. As a bridging concept, it contributes: i) theoretical grounding; ii) inspiring design exemplars that illustrate the theory and foreground its value; and iii) design articulations in the form of valuable experiential qualities and design features. Our work can help to focus design agendas for playful technology and inspire future designs in this space.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {playfulness, play, interaction design, hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376147,
author = {Matulic, Fabrice and Arakawa, Riku and Vogel, Brian and Vogel, Daniel},
title = {PenSight: Enhanced Interaction with a Pen-Top Camera},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376147},
doi = {10.1145/3313831.3376147},
abstract = {We propose mounting a downward-facing camera above the top end of a digital tablet pen. This creates a unique and practical viewing angle for capturing the pen-holding hand and the immediate surroundings which can include the other hand. The fabrication of a prototype device is described and the enabled interaction design space is explored, including dominant and non-dominant hand pose recognition, tablet grip detection, hand gestures, capturing physical content in the environment, and detecting users and pens. A deep learning computer vision pipeline is developed for classification, regression, and keypoint detection to enable these interactions. Example applications demonstrate usage scenarios and a qualitative user evaluation confirms the potential of the approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {hand pose estimation, pen input, tablet input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376767,
author = {Reyes-Cruz, Gisela and Fischer, Joel E. and Reeves, Stuart},
title = {Reframing Disability as Competency: Unpacking Everyday Technology Practices of People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376767},
doi = {10.1145/3313831.3376767},
abstract = {More than a billion people in the world live with some form of visual impairment, and a wide variety of technologies are now routinely used by them in the course of 'getting on' in everyday life. However, little is known about the ways in which assistive and non-assistive technologies are brought to bear on material practices. We present findings from a four-month ethnographic study facilitated by a local branch of a UK charity that supports people with visual impairments. Our study explores mainstream and assistive technology use within their everyday lives. We identify three main sites for technology use: social relations and communication practices, textual reading practices, and mobility practices. Via an ethnographic approach we contribute to understanding how people accomplish such practices, and in doing so, uncover the practical competencies that enable people with visual impairments to conduct their everyday activities. Thus we investigate how disability can be thought of in terms of competencies, arguing that understanding of competencies can enrich the design of technologies that fit the needs of people with visual impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ethnomethodology, visual impairments, assistive technology, ethnography, disability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376233,
author = {Zhu, Fengyuan and Grossman, Tovi},
title = {BISHARE: Exploring Bidirectional Interactions Between Smartphones and Head-Mounted Augmented Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376233},
doi = {10.1145/3313831.3376233},
abstract = {In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {augmented reality, mixed-reality computing, smartphones, cross-device computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376472,
author = {Colley, Mark and Walch, Marcel and Gugenheimer, Jan and Askari, Ali and Rukzio, Enrico},
title = {Towards Inclusive External Communication of Autonomous Vehicles for Pedestrians with Vision Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376472},
doi = {10.1145/3313831.3376472},
abstract = {People with vision impairments (VIP) are among the most vulnerable road users in traffic. Autonomous vehicles are believed to reduce accidents but still demand some form of external communication signaling relevant information to pedestrians. Recent research on the design of vehicle-pedestrian communication (VPC) focuses strongly on concepts for a non-disabled population. Our work presents an inclusive user-centered design for VPC, beneficial for both vision impaired and seeing pedestrians. We conducted a workshop with VIP (N=6), discussing current issues in road traffic and comparing communication concepts proposed by literature. A thematic analysis unveiled two important themes: number of communicating vehicles and content (affecting duration). Subsequently, we investigated these in a second user study in virtual reality (N=33, 8 VIP) comparing the VPC between groups of abilities. We found that trust and understanding is enhanced and cognitive load reduced when all relevant vehicles communicate; high content messages also reduce cognitive load.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {external communication, inclusive design research, accessibility, autonomous vehicles, vulnerable road users},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376718,
author = {Beede, Emma and Baylor, Elizabeth and Hersch, Fred and Iurchenko, Anna and Wilcox, Lauren and Ruamviboonsuk, Paisan and Vardoulakis, Laura M.},
title = {A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376718},
doi = {10.1145/3313831.3376718},
abstract = {Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {deep learning, diabetes, health, human-centered ai},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376699,
author = {Ding, Xianghua and Gui, Xinning and Ma, Xiaojuan and Ding, Zhaofei and Chen, Yunan},
title = {Getting the Healthcare We Want: The Use of Online "Ask the Doctor" Platforms in Practice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376699},
doi = {10.1145/3313831.3376699},
abstract = {Online Ask the Doctor (AtD) services allow access to health professionals anytime anywhere beyond existing patient-provider relationships. Recently, many free-market AtD platforms have emerged and been adopted by a large scale of users. However, it is still unclear how people make use of these AtD platforms in practice. In this paper, we present an interview study with 12 patients/caregivers who had experience using AtD in China, highlighting patient agency in seeking more reliable and cost-effective healthcare beyond clinic settings. Specifically, we illustrate how they make strategic choices online on AtD platforms, and how they strategically integrate online and offline services together for healthcare. This paper contributes an empirical study of the use of large-scale AtD platforms in practice, demonstrates patient agency for healthcare beyond clinic settings, and recommends design implications for online healthcare services.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {AtD, patient agency, healthcare engagement, ask the doctor services, online healthcare services, healthcare navigation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376689,
author = {Claisse, Caroline and Petrelli, Daniela and Ciolfi, Luigina and Dulake, Nick and Marshall, Mark T. and Durrant, Abigail C.},
title = {Crafting Critical Heritage Discourses into Interactive Exhibition Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376689},
doi = {10.1145/3313831.3376689},
abstract = {This paper argues how a more reflective design practice that embraces critical discourses can transform interactive exhibition design and therefore the museum visiting experience. Four framing arguments underpin our exhibition design making: the value of materiality, visiting as an aesthetic experience, challenging the authorized voice, and heritage as a process. These arguments were embodied through design, art and craft practice into one interactive exhibition at a house museum. We draw from our design process discussing the implications that adopting an approach informed by critical heritage debates has on exhibition design and suggest three sensitizing concepts (polyvocal narratives, dialogical interaction, interweaving time and space) bridging the practice of interactive exhibition design and critical heritage theory.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {critical heritage, tangible interaction, exhibition design, craft practice, reflective practice},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376337,
author = {Logler, Nick and Pitt, Caroline and Gao, Xin and Hishikawa, Allison Marie and Yip, Jason and Friedman, Batya},
title = {"I Feel Like This is a Bad Thing": Investigating Disassembly in Action for Novices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376337},
doi = {10.1145/3313831.3376337},
abstract = {Materials are dynamic-they can be shaped and changed. Often however, our tools and technologies appear to fix materials in place. Disassembly is one practice that provides openings to explore and understand the dynamic nature of material. In this research, we investigate possibilities that emerge from disassembly. Specifically, we studied how novices disassembled a common digital artifact-desktop printers. We worked with 21 young people and family members across two evening workshops at a middle school. We report on the workshop interactions, categories of actions of disassembly, and four in-depth vignettes showcasing disassembly in action. In the discussion, we reflect on disassembly and permission, sustainability, the joy of disassembling, and design considerations in support of disassembly. Our contributions include: (1) extending existing theoretical framings about artifacts and materials; (2) an empirical study documenting the process by which novices disassemble; and (3) preliminary design and policy considerations that enable disassembly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design theory, play, making, unmaking, materials, novices, disassembly, empowerment, design principles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376268,
author = {Turmo Vidal, Laia and Zhu, Hui and Riego-Delgado, Abraham},
title = {BodyLights: Open-Ended Augmented Feedback to Support Training Towards a Correct Exercise Execution},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376268},
doi = {10.1145/3313831.3376268},
abstract = {Technologies targeting a correct execution of physical training exercises typically use pre-determined models for what they consider correct, automatizing instruction and feedback. This falls short on catering to diverse trainees and exercises. We explore an alternative design approach, in which technology provides open-ended feedback for trainers and trainees to use during training. With a personal trainer we designed the augmentation of 18 strength training exercises with BodyLights: 3D printed wearable projecting lights that augment body movement and orientation. To study them, 15 trainees at different skill levels trained three times with our personal trainer and BodyLights. Our findings show that BodyLights catered to a wide range of trainees and exercises, and supported understanding, executing and correcting diverse technique parameters. We discuss design features and methodological aspects that allowed this; and what open-ended feedback offered in comparison to current technology approaches to support training towards a correct exercise execution.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {rtd, activity design, wearables, augmented feedback, strength training, physical training, correct performance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376493,
author = {Wirfs-Brock, Jordan and Mennicken, Sarah and Thom, Jennifer},
title = {Giving Voice to Silent Data: Designing with Personal Music Listening History},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376493},
doi = {10.1145/3313831.3376493},
abstract = {Music streaming services collect listener data to support personalization and discovery of their extensive catalogs. Yet this data is typically used in ways that are not immediately apparent to listeners. We conducted design workshops with ten Spotify listeners to imagine future voice assistant (VA) interactions leveraging logged music data. We provided participants with detailed personal music listening data, such as play-counts and temporal patterns, which grounded their design ideas in their current behaviors. In the interactions participants designed, VAs did not simply speak their data out loud; instead, participants envisioned how data could implicitly support introspection, behavior change, and exploration. We present reflections on how VAs could evolve from voice-activated remote controls to intelligent music coaches and how personal data can be leveraged as a design resource.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {speculative design, participatory design, voice assistants, personal informatics, music, co-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376424,
author = {Xiao, Sijia and Metaxa, Dana\"{e} and Park, Joon Sung and Karahalios, Karrie and Salehi, Niloufar},
title = {Random, Messy, Funny, Raw: Finstas as Intimate Reconfigurations of Social Media},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376424},
doi = {10.1145/3313831.3376424},
abstract = {Among many young people, the creation of a finsta-a portmanteau of "fake" and "Instagram" which describes secondary Instagram accounts-provides an outlet to share emotional, low-quality, or indecorous content with their close friends. To study why people create and maintain finstas, we conducted a qualitative study through interviews with finsta users and content analysis of video bloggers exposing their finsta on YouTube. We found that one way that young people deal with mounting social pressures is by reconfiguring online platforms and changing their purposes, norms, expectations, and currencies. Carving out smaller spaces accessible only to close friends allows users the opportunity for a more unguarded, vulnerable, and unserious performance. Drawing on feminist theory, we term this process intimate reconfiguration. Through this reconfiguration finsta users repurpose an existing and widely-used social platform to create opportunities for more meaningful and reciprocal forms of social support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {performance, reconfiguration, finsta, feminist hci},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376345,
author = {Devendorf, Laura and Andersen, Kristina and Kelliher, Aisling},
title = {Making Design Memoirs: Understanding and Honoring Difficult Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376345},
doi = {10.1145/3313831.3376345},
abstract = {Design is commonly understood as a storytelling practice, yet we have few narratives with which to describe the felt experiences of struggle, pain, and difficulty, beyond treating them as subjects to resolve. This work uses the praxis of embodied design as a way to bring more complex narratives to the community for contemplation---to engage and entangle personal and difficult stories within a public context. We propose the term Design Memoirs for these first-person practices and reflections. Design Memoirs are subjective and corporeal in nature, and provide a direct and observable way to reckon with felt experiences through, and for, design. We demonstrate Design Memoirs by drawing on our own experiences as mothers, caregivers, and corporeal subjects. Following Barad, we propose a practice of diffractive reading to locate resonances between Design Memoirs which render difficult autobiographical material addressable, shareable, and open for new interpretations. We present this strategy as a method for arriving at deeper understandings of difficult experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {design fiction, autobiographical design, motherhood, design research, methodology, design memoirs},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376265,
author = {Gerling, Kathrin and Dickinson, Patrick and Hicks, Kieran and Mason, Liam and Simeone, Adalberto L. and Spiel, Katta},
title = {Virtual Reality Games for People Using Wheelchairs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376265},
doi = {10.1145/3313831.3376265},
abstract = {Virtual Reality (VR) holds the promise of providing engaging embodied experiences, but little is known about how people with disabilities engage with it. We explore challenges and opportunities of VR gaming for wheelchair users. First, we present findings from a survey that received 25 responses and gives insights into wheelchair users' motives to (non-) engage with VR and their experiences. Drawing from this survey, we derive design implications which we tested through implementation and qualitative evaluation of three full-body VR game prototypes with 18 participants. Our results show that VR gaming engages wheelchair users, though nuanced consideration is required for the design of embodied immersive experiences for minority bodies, and we illustrate how designers can create meaningful, positive experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {accessibility, virtual reality, games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376706,
author = {Kelliher, Aisling and Zilevu, Setor and Rikakis, Thanassis and Ahmed, Tamim and Truong, Yen and Wolf, Steven L.},
title = {Towards Standardized Processes for Physical Therapists to Quantify Patient Rehabilitation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376706},
doi = {10.1145/3313831.3376706},
abstract = {Physical rehabilitation typically requires therapists to make judgements about patient movement and functional improvement using subjective observation. This process makes it challenging to quantitatively track, compute and predict long-term patient improvement. We therefore propose a novel methodical approach to the standardized and interpretable quantification of patient movement during rehabilitation. We describe the expert-led development of a movement assessment rubric and an accompanying quantitative rating system. We present our movement capture and annotation computational tools designed to implement the rubric and assist therapists in the quantitative documentation and assessment of rehabilitation. We describe results from a movement capture study of the tool with nine stroke survivors and a movement rating study with four therapists. Findings from these studies highlight potential optimal methodical process paths for individuals engaged in capturing, understanding and predicting human movement performance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {stroke rehabilitation, human movement capture, human movement assessment, home based rehabilitation therapy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376874,
author = {Leung, Weiwen and Zhang, Zheng and Jibuti, Daviti and Zhao, Jinhao and Klein, Maximilian and Pierce, Casey and Robert, Lionel and Zhu, Haiyi},
title = {Race, Gender and Beauty: The Effect of Information Provision on Online Hiring Biases},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376874},
doi = {10.1145/3313831.3376874},
abstract = {We conduct a study of hiring bias on a simulation platform where we ask Amazon MTurk participants to make hiring decisions for a mathematically intensive task. Our findings suggest hiring biases against Black workers and less attractive workers, and preferences towards Asian workers, female workers and more attractive workers. We also show that certain UI designs, including provision of candidates' information at the individual level and reducing the number of choices, can significantly reduce discrimination. However, provision of candidate's information at the subgroup level can increase discrimination. The results have practical implications for designing better online freelance marketplaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {gig economy, hiring, discrimination},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376745,
author = {Fiesler, Casey},
title = {Lawful Users: Copyright Circumvention and Legal Constraints on Technology Use},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376745},
doi = {10.1145/3313831.3376745},
abstract = {The study of human-computer interaction requires consideration of aspects of interactions with technology that may be outside of the control of both user and designer. One example of when a user's question of "can I do this?" may have an answer beyond technological affordances is that of legal constraints. This paper considers an example of this phenomenon: section 1201 of the Digital Millennium Copyright Act (DMCA) in the United States, which criminalizes circumventing copyright protection such as digital rights management (DRM). The DMCA also includes a triennial policymaking process that considers exemptions to the law to protect "lawful users" from adverse effects. Through an analysis of public comments of support for exemptions, this paper explores the ways in which users see the law as a hindrance to desired uses of technology. This analysis sheds light on users' expectations for rights of use, how these expectations clash with policy, and what this might mean for technology designers. Drawing lessons from the infrastructure problem in HCI, this paper concludes with laying out solutions that can both work within policy constraints, and more importantly, work to change them.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {ownership, dmca, policy, drm, infrastructure, accessibility, law, copyright},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376273,
author = {Kurze, Albrecht and Bischof, Andreas and Totzauer, S\"{o}ren and Storz, Michael and Eibl, Maximilian and Brereton, Margot and Berger, Arne},
title = {Guess the Data: Data Work to Understand How People Make Sense of and Use Simple Sensor Data from Homes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376273},
doi = {10.1145/3313831.3376273},
abstract = {Simple smart home sensors, e.g. for temperature or light, increasingly collect seemingly inconspicuous data. Prior work has shown that human sensemaking of such sensor data can reveal domestic activities. Such sensemaking presents an opportunity to empower people to understand the implications of simple smart home sensors. To investigate, we developed and field-tested the Guess the Data method, which enabled people to use and make sense of live data from their homes and to collectively interpret and reflect on anonymized data from the homes in our study. Our findings show how participants reconstruct behavior, both individually and collectively, expose the sensitive personal data of others, and use sensor data as evidence and for lateral surveillance within the household. We discuss the potential of our method as a participatory HCI method for investigating design of the IoT and implications created by doing data work on home sensors.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {networked sensing systems, privacy, iot, personal data, internet of things, data work, smart home, sensor data},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376426,
author = {Hong, Matthew K. and Lakshmi, Udaya and Do, Kimberly and Prahalad, Sampath and Olson, Thomas and Arriaga, Rosa I. and Wilcox, Lauren},
title = {Using Diaries to Probe the Illness Experiences of Adolescent Patients and Parental Caregivers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376426},
doi = {10.1145/3313831.3376426},
abstract = {Adolescents with chronic conditions must work with family caregivers to manage their illness experiences. To explore how technology can support collaborative documentation of these experiences, we designed and distributed a paper diary probe kit in a two-week field deployment with 12 adolescent-parent dyads (24 participants). Three insights emerged from the study that highlight how technology can support shared illness management: 1) provide scaffolds to recognize physical and emotional experiences in the context of daily activities; 2) help families reconstruct patient experiences; and 3) adapt to individual preferences for capturing, representing and sharing experiences. We discuss opportunities for HCI research that follow from these findings and conclude by reflecting on the benefits and limitations of using diary probes with adolescent patients and their parental caregivers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {co-design, family-centered design, health, chronic illness, family informatics, diary studies, adolescents, probes},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376322,
author = {Zhang, Xinlei and Miyaki, Takashi and Rekimoto, Jun},
title = {WithYou: Automated Adaptive Speech Tutoring With Context-Dependent Speech Recognition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376322},
doi = {10.1145/3313831.3376322},
abstract = {Learning to speak in foreign languages is hard. Speech shadowing has been rising as a proven way to practice speaking, which asks a learner to listen and repeat a native speech template as simultaneously as possible. However, shadowing can be hard to do because learners can frequently fail to follow the speech and unintentionally interrupt a practice session. Worse, as a technical way to evaluate shadowing performance in real-time has not been established, no automated solutions are available to help. In this paper, we propose a technical framework with context-dependent speech recognition to evaluate shadowing in real-time. We propose a shadowing tutor system called WithYou, which can automatically adjust the playback and the difficulty of a speech template when learners fail, so shadowing becomes smooth and tailored. Results from a user study show that WithYou provides greater speech improvements (14%) than the conventional method (2.7%) with a lower cognitive load.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {intelligent tutoring system, language learning, computer assisted language learning (call), speaking, shadowing, speech recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376334,
author = {Ces\'{a}rio, Vanessa and Petrelli, Daniela and Nisi, Valentina},
title = {Teenage Visitor Experience: Classification of Behavioral Dynamics in Museums},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376334},
doi = {10.1145/3313831.3376334},
abstract = {Teenagers' engagement in museums is much talked about but little research has been done to understand their behavior and inform design. Findings from co-design sessions with teenagers suggested they value games and stories when thinking about enjoyable museum tours. Informed by these findings and working with a natural history museum, we designed: a story-based tour (Turning Point) and a game-based tour (Haunted Encounters), informed by similar content. The two strategies were evaluated with 78 teenagers (15-19 years old) visiting the museum as part of an educational school trip. We assessed teenagers' personality in class; qualitative and quantitative data on their engagement, experience, and usability of the apps were collected at the museum. The triangulation of quantitative and qualitative data show personality traits mapping into different behaviors. We offer implications for the design of museum apps targeted to teenagers, a group known as difficult to reach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {teenagers, storytelling, mobile experience, museums, visitor experience, co-design, game},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376271,
author = {Wang, Zezhong and Sundin, Lovisa and Murray-Rust, Dave and Bach, Benjamin},
title = {Cheat Sheets for Data Visualization Techniques},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376271},
doi = {10.1145/3313831.3376271},
abstract = {This paper introduces the concept of 'cheat sheets' for data visualization techniques, a set of concise graphical explanations and textual annotations inspired by infographics, data comics, and cheat sheets in other domains. Cheat sheets aim to address the increasing need for accessible material that supports a wide audience in understanding data visualization techniques, their use, their fallacies and so forth. We have carried out an iterative design process with practitioners, teachers and students of data science and visualization, resulting six types of cheat sheet (anatomy, construction, visual patterns, pitfalls, false-friends and well-known relatives) for six types of visualization, and formats for presentation. We assess these with a qualitative user study using 11 participants that demonstrates the readability and usefulness of our cheat sheets.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cheat sheet, visualization literacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376203,
author = {Meschtscherjakov, Alexander and D\"{o}ttlinger, Christine and Kaiser, Tim and Tscheligi, Manfred},
title = {Chase Lights in the Peripheral View: How the Design of Moving Patterns on an LED Strip Influences the Perception of Speed in an Automotive Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376203},
doi = {10.1145/3313831.3376203},
abstract = {LEDs on a strip, when turned on and off in a specific order, result in the perception of apparent motion (i.e. beta movement). In the automotive domain such chase lights have been used to alter drivers' perception of driving speed by manipulating the pixel speed of LEDs. We argue that the perceived velocity of beta movement in the peripheral view is not only based on the actual pixel speed but can be influenced by other factors such as frequency, width and brightness of lit LED segments. We conducted a velocity matching experiment (N=25) by systematically varying these three properties, in order to determine their influence on a participant's perceived velocity in a vehicle mock-up. Results show that a higher frequency and stronger brightness increased perceived velocity, whereas segment width had no influence. We discuss how findings may be applied when designing systems that use beta movement to influence the perception of ambient light velocity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {chase lights, velocity perception, peripheral vision, moving patterns},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376305,
author = {Aigner, Roland and Pointner, Andreas and Preindl, Thomas and Parzer, Patrick and Haller, Michael},
title = {Embroidered Resistive Pressure Sensors: A Novel Approach for Textile Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376305},
doi = {10.1145/3313831.3376305},
abstract = {We present a novel method for augmenting arbitrary fabrics with textile-based pressure sensors using an off-the-shelf embroidery machine. We apply resistive textiles and conductive yarns on top of a base fabric, to yield a flexible and versatile continuous sensing device, which is based on the widespread principle of force sensitive resistors. The patches can easily be attached to measurement and/or computing devices, e.g. for controlling accessories. In this paper, we investigate the impacts of related design and fabrication parameters, introduce five different pattern designs, and discuss their pros and cons. We present crucial insights and recommendations for design and manufacturing of embroidered pressure sensors. Our sensors show a very low activation threshold, as well as good dynamic range, signal-to-noise ratio, and part-to-part repeatability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {space-filling patterns, embroidery, smart textiles, embroidered force sensitive resistance, textile sensor},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376174,
author = {Mitchell Finnigan, Samantha and Clear, Adrian K.},
title = {"No Powers, Man!": A Student Perspective on Designing University Smart Building Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376174},
doi = {10.1145/3313831.3376174},
abstract = {Smart buildings offer an opportunity for better performance and enhanced experience by contextualising services and interactions to the needs and practices of occupants. Yet, this vision is limited by established approaches to building management, delivered top-down through professional facilities management teams, opening up an interaction-gap between occupants and the spaces they inhabit. To address the challenge of how smart buildings might be more inclusively managed, we present the results of a qualitative study with student occupants of a smart building, with design workshops including building walks and speculative futuring. We develop new understandings of how student occupants conceptualise and evaluate spaces as they experience them, and of how building management practices might evolve with new sociotechnical systems that better leverage occupant agency. Our findings point to important directions for HCI research in this nascent area, including the need for HBI (Human-Building Interaction) design to challenge entrenched roles in building management.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sustainability, sustainable hci, walking, speculative design, human-building interaction, hbi},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376590,
author = {Liao, Q. Vera and Gruen, Daniel and Miller, Sarah},
title = {Questioning the AI: Informing Design Practices for Explainable AI User Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376590},
doi = {10.1145/3313831.3376590},
abstract = {A surge of interest in explainable AI (XAI) has led to a vast collection of algorithmic work on the topic. While many recognize the necessity to incorporate explainability features in AI systems, how to address real-world user needs for understanding AI remains an open question. By interviewing 20 UX and design practitioners working on various AI products, we seek to identify gaps between the current XAI algorithmic work and practices to create explainable AI products. To do so, we develop an algorithm-informed XAI question bank in which user needs for explainability are represented as prototypical questions users might ask about the AI, and use it as a study probe. Our work contributes insights into the design space of XAI, informs efforts to support design practices in this space, and identifies opportunities for future XAI work. We also provide an extended XAI question bank and discuss how it can be used for creating user-centered XAI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {user experience, explainable AI, human-AI interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376430,
author = {Svan\ae{}s, Dag and Barkhuus, Louise},
title = {The Designer's Body as Resource in Design: Exploring Combinations of Point-of-View and Tense},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376430},
doi = {10.1145/3313831.3376430},
abstract = {The design of wearable, tangible and embedded interactive products requires a focus on bodily/kinesthetic aspects of the user experience, that is, how the product "feels" in use. Although best practice in user-centered design (such as iterative design, prototyping, user testing) also applies for this new type of product, the designer's skill set needs to be supplemented with design methods and practices that utilize bodily intelligence and empathy with the user. We present a framework for categorizing such body-centered design practices based on two dimensions: point-of-view (1st, 2nd, 3rd person) and tense (past, present, future). Inspired by Merleau-Ponty's phenomenology of the body, Shusterman's work on somaesthetics, and Buber's theories on intersubjectivity, the framework provides a language for talking about different ways designers and co-designers can utilize their body as a design resource. The intention is not to be prescriptive on method, but to provide guidance during planning, execution and analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {designer training, design process, body-centered design, user experience, somaesthetics, phenomenology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376659,
author = {Fernando, Piyum and Kuznetsov, Stacey},
title = {OScH in the Wild: Dissemination of Open Science Hardware and Implications for HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376659},
doi = {10.1145/3313831.3376659},
abstract = {Open Science Hardware (OScH) refers to open-source alternatives for proprietary scientific equipment. While the OScH movement aims to reduce barriers for scientific experimentation both in and beyond professional labs, disseminating OScH for widespread adoption proves to be challenging in practice. To this end, we examined real-world practices related to the dissemination of OScH through a two-part study. First, we developed an open science hardware, a DIY incubator, and disseminated it through the Instructables website and maker workshops. In parallel, we interviewed eight open science hardware practitioners from different parts of the world. Insights from interviews together with our own self-reflections revealed how different OScH dissemination modalities serve unique purposes. Our findings also reveal several challenges for widespread adoption of OScH and the importance of collaborations between OScH developers. We conclude by discussing the opportunities for HCI to lower barriers for customization, support internationalization of OScH, and scaffold proactive distributed collaborations between developers and users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {open science hardware, maker movement, diy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376569,
author = {Choi, Dasom and Kwak, Daehyun and Cho, Minji and Lee, Sangsu},
title = {"Nobody Speaks That Fast!" An Empirical Study of Speech Rate in Conversational Agents for People with Vision Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376569},
doi = {10.1145/3313831.3376569},
abstract = {The number of people with vision impairments using Conversational Agents (CAs) has increased because of the potential of this technology to support them. As many visually impaired people are accustomed to understanding fast speech, most screen readers or voice assistant systems offer speech rate settings. However, current CAs are designed to interact at a human-like speech rate without considering their accessibility. In this study, we tried to understand how people with vision impairments use CA at a fast speech rate. We conducted a 20-day in-home study that examined the CA use of 10 visually impaired people at default and fast speech rates. We investigated the difference in visually impaired people's CA use with different speech rates and their perception toward CA at each rate. Based on these findings, we suggest considerations for the future design of CA speech rate for those with visual impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {conversational agents, speech rate, accessibility, people with vision impairments},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376492,
author = {Gen\c{c}, H\"{u}seyin Ugur and Coskun, Aykut},
title = {Designing for Social Interaction in the Age of Excessive Smartphone Use},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376492},
doi = {10.1145/3313831.3376492},
abstract = {Excessive smartphone use has negative effects on our social relations as well as on our mental and psychological health. Most of the previous work to avoid these negative effects is based on a top-down approach such as restricting or limiting users' use of smartphones. Diverging from previous work, we followed a bottom-up approach to understand the practice of smartphone use in public settings from the users' perspective. We conducted observations in four coffeehouses, six focus group sessions with 46 participants and three design workshops with 15 designers. We identified five themes that help better understand smartphone use behavior in public settings and four alternative design approaches to mediate this behavior, namely enlighteners, preventers, supporters, and compliers. We discuss the implications of these themes and approaches for designing future interactive technologies aimed at mediating excessive smartphone use behavior.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smartphone, focus group design workshop, design for behavioral change},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376783,
author = {Smith, C. Estelle and Yu, Bowen and Srivastava, Anjali and Halfaker, Aaron and Terveen, Loren and Zhu, Haiyi},
title = {Keeping Community in the Loop: Understanding Wikipedia Stakeholder Values for Machine Learning-Based Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376783},
doi = {10.1145/3313831.3376783},
abstract = {On Wikipedia, sophisticated algorithmic tools are used to assess the quality of edits and take corrective actions. However, algorithms can fail to solve the problems they were designed for if they conflict with the values of communities who use them. In this study, we take a Value-Sensitive Algorithm Design approach to understanding a community-created and -maintained machine learning-based algorithm called the Objective Revision Evaluation System (ORES)---a quality prediction system used in numerous Wikipedia applications and contexts. Five major values converged across stakeholder groups that ORES (and its dependent applications) should: (1) reduce the effort of community maintenance, (2) maintain human judgement as the final authority, (3) support differing peoples' differing workflows, (4) encourage positive engagement with diverse editor groups, and (5) establish trustworthiness of people and algorithms within the community. We reveal tensions between these values and discuss implications for future research to improve algorithms like ORES.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {wikipedia, community values, peer production, value sensitive algorithm design, machine learning, ORES},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376633,
author = {Tseng, Emily and Okeke, Fabian and Sterling, Madeline and Dell, Nicola},
title = {"We Can Learn. Why Not?": Designing Technologies to Engender Equity for Home Health Aides},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376633},
doi = {10.1145/3313831.3376633},
abstract = {HCI researchers have increasingly studied how technology might improve the lives of marginalized workers. We explored this question through a qualitative study with home health aides in New York City, a vulnerable group of frontline caregivers whose work with patients is poorly paid and highly stressful, often involving life-or-death situations. To elicit the perspectives of aides and their supervisors on how technology interventions might contribute to moving aides towards a better future, we created a design provocation that centers aides' needs and suggests more equitable roles for them within the home care ecosystem. Findings from design sessions with 16 aides, nurses, and aide coordinators illuminate the ethical and pragmatic dilemmas inherent in this complex ecosystem, and show that designing technology for equity requires attention to structural problems in addition to workers' stated needs. We analyze our findings through the lens of social justice-oriented interaction design, and discuss how our work extends key strategies within this framework.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design provocation, home care, home health aides, design for social justice},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376157,
author = {Komatsu, Takanori and Yamada, Seiji},
title = {Exploring Auditory Information to Change Users' Perception of Time Passing as Shorter},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376157},
doi = {10.1145/3313831.3376157},
abstract = {Although the processing speed of computers has been drastically increasing year by year, users still have to wait for computers to complete tasks or to respond. To cope with this, several studies have proposed presenting certain visual information to users to change their perception of time passing as shorter, e.g., progress bars with animated ribbing or faster/slower virtual clocks. As speech interfaces such as smart speakers are becoming popular, a novel method is required to make users perceive the passing of time as shorter by presenting auditory stimuli. We thus prepared 20 pieces of auditory information as experimental stimuli; that is, 11 auditory stimuli that have the same 10.1-second duration but different numbers of 0.1-second sine-wave sounds and 9 other auditory stimuli that have the same 10.1-second duration and numbers of sounds but different interval patterns between the sounds. We conducted three experiments to figure out which kinds of auditory stimuli can change users' perception of time passing as shorter. We found that a 10.1-second auditory stimulus that has 0.1-second sine-wave sounds appearing 11 times with intervals between the sounds that narrow rapidly in a linear fashion was perceived as shortest at about 9.3 seconds, which was 7.6% shorter than the actual duration of the stimulus. We also found that different interval patterns of sounds in auditory information significantly affected users' perception of time passing as shorter, while different numbers of sounds did not.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {waiting time, eyes-free interaction, auditory information, users' perception of time passing, filled-duration illusion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376222,
author = {Correll, Michael and Bertini, Enrico and Franconeri, Steven},
title = {Truncating the Y-Axis: Threat or Menace?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376222},
doi = {10.1145/3313831.3376222},
abstract = {Bar charts with y-axes that don't begin at zero can visually exaggerate effect sizes. However, advice for whether or not to truncate the y-axis can be equivocal for other visualization types. In this paper we present examples of visualizations where this y-axis truncation can be beneficial as well as harmful, depending on the communicative and analytic intent. We also present the results of a series of crowd-sourced experiments in which we examine how y-axis truncation impacts subjective effect size across visualization types, and we explore alternative designs that more directly alert viewers to this truncation. We find that the subjective impact of axis truncation is persistent across visualizations designs, even for designs with explicit visual cues that indicate truncation has taken place. We suggest that designers consider the scale of the meaningful effect sizes and variation they intend to communicate, regardless of the visual encoding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {information visualization, deceptive visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376664,
author = {Prpa, Mirjana and Fdili-Alaoui, Sarah and Schiphorst, Thecla and Pasquier, Philippe},
title = {Articulating Experience: Reflections from Experts Applying Micro-Phenomenology to Design Research in HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376664},
doi = {10.1145/3313831.3376664},
abstract = {Third wave HCI initiated a slow transformation in the methods of UX research: from widely used quantitative approaches to more recently employed qualitative techniques. Articulating the nuances, complexity, and diversity of a user's experience beyond surface descriptions remains a challenge within design. One qualitative method — micro-phenomenology — has been used in HCI/Design research since 2001. Yet, no systematic understanding of micro-phenomenology has been presented, particularly from the perspective of HCI/Design researchers who actively use it in design contexts. We interviewed 5 HCI/Design experts who utilize micro-phenomenology and present their experiences with the method. We illustrate how this method has been applied by the selected experts through developing a practice, and present conditions under which the descriptions of the experience unfold, and the values that this method can provide to HCI/Design field. Our contribution highlights the value of micro-phenomenology in articulating the experience of designers and participants, developing vocabulary for multi-sensory experiences, and unfolding embodied tacit knowledge.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {empirical methods, user experience, micro-phenomenology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376528,
author = {Homewood, Sarah and Boer, Laurens and Vallg\r{a}rda, Anna},
title = {Designers in White Coats: Deploying Ovum, a Fertility Tracking Device},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376528},
doi = {10.1145/3313831.3376528},
abstract = {As self-tracking practices continue to proliferate, there has been a call for a consideration of how the design of these devices influence the users experience of themselves and their bodies beyond utility, efficacy and accuracy. The research product Ovum was designed to facilitate a DIY, shared, domestic experience, rather than an expert-led, individual, clinical experience of fertility tracking. Ovum uses the method of saliva sampling to determine ovulation. This paper unpacks the findings from a three-month long deployment of Ovum with seven couples trying to conceive. Besides an evaluation of the device in terms of the three experiential qualities aimed for in the design process, we report on the consequences of executing a design deployment that resembles a clinical trial. We contribute our experience in order to develop an understanding of how designing for the body places interaction designers in novel and complex situations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {fertility, research through design, women's health, ovulation, self-tracking, menstrual cycles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376456,
author = {Phadke, Shruti and Mitra, Tanushree},
title = {Many Faced Hate: A Cross Platform Study of Content Framing and Information Sharing by Online Hate Groups},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376456},
doi = {10.1145/3313831.3376456},
abstract = {Hate groups are increasingly using multiple social media platforms to promote extremist ideologies. Yet we know little about their communication practices across platforms. How do hate groups (or "in-groups"), frame their hateful agenda against the targeted group or the "out-group?" How do they share information? Utilizing "framing" theory from social movement research and analyzing domains in the shared links, we juxtapose the Facebook and Twitter communication of 72 Southern Poverty Law Center (SPLC) designated hate groups spanning five hate ideologies. Our findings show that hate groups use Twitter for educating the audience about problems with the out-group, maintaining positive self-image by emphasizing in-group's high social status, and for demanding policy changes to negatively affect the out-group. On Facebook, they use fear appeals, call for active participation in group events (membership requests), all while portraying themselves as being oppressed by the out-group and failed by the system. Our study unravels the ecosystem of cross-platform communication by hate groups, suggesting that they use Facebook for group radicalization and recruitment, while Twitter for reaching a diverse follower base.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cross-platform, framing, hate groups, information sharing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376632,
author = {Obada-Obieh, Borke and Huang, Yue and Beznosov, Konstantin},
title = {The Burden of Ending Online Account Sharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376632},
doi = {10.1145/3313831.3376632},
abstract = {Many people share online accounts, even in situations where high privacy and security are expected. Naturally, the sharing of these accounts does not endure forever. This paper reports the privacy and security challenges that people experience when they stop online account sharing. We conducted semi-structured interviews with 25 participants who stopped sharing at least one online account in the 12 months preceding the study. Our results suggest that users experience cognitive and psychosocial burdens when ending account sharing. We offer suggestions for how to improve the design of online accounts to support users better when they end account sharing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online shared accounts, usable security and privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376535,
author = {Rumsey, Alyssa and Le Dantec, Christopher A.},
title = {Manufacturing Change: The Impact of Virtual Environments on Real Organizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376535},
doi = {10.1145/3313831.3376535},
abstract = {Manufacturing workplaces are becoming sites of intense change as technologies like IoT and AR/VR are beginning to make deep inroads into how complex products are engi-neered and assembled. These categories of technologies are becoming prominent in manufacturing because they offer potential solutions to the problems of unskilled labor and workforce shortages. Technology has the potential to shift manufacturing in both large and small ways, to better un-derstand how a manufacturing organization might appropri-ate VR, we ran a study with a global aviation manufacturer headquartered the United States. To document the changing nature of work via this class of technologies we conducted a VR study which facilitated access to participant observation and interviews (n=21). Our findings provide initial insights into the organizational impact of VR on human perfor-mance augmentation and skill acquisition revealing the larger infrastructural challenges facing the adoption of con-sumer grade smart technologies in industrial workplace settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, field studies, qualitative methods},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376887,
author = {Heyer, Jeremy and Raveendranath, Nirmal Kumar and Reda, Khairi},
title = {Pushing the (Visual) Narrative: The Effects of Prior Knowledge Elicitation in Provocative Topics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376887},
doi = {10.1145/3313831.3376887},
abstract = {Narrative visualization is a popular style of data-driven storytelling. Authors use this medium to engage viewers with complex and sometimes controversial issues. A challenge for authors is to not only deliver new information, but to also overcome people's biases and misconceptions. We study how people adjust their attitudes toward (or away from) a message experienced through a narrative visualization. In a mixed-methods analysis, we investigate whether eliciting participants' prior beliefs, and visualizing those beliefs alongside actual data, can increase narrative persuasiveness. We find that incorporating priors does not significantly affect attitudinal change. However, participants who externalized their beliefs expressed greater surprise at the data. Their comments also indicated a greater likelihood of acquiring new information, despite the minimal change in attitude. Our results also extend prior findings, showing that visualizations are more persuasive than equivalent textual data representations for exposing contentious issues. We discuss the implications and outline future research directions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {persuasion, debiasing, belief elicitation, narrative visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376807,
author = {Xie, Yao and Chen, Melody and Kao, David and Gao, Ge and Chen, Xiang 'Anthony'},
title = {CheXplain: Enabling Physicians to Explore and Understand Data-Driven, AI-Enabled Medical Imaging Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376807},
doi = {10.1145/3313831.3376807},
abstract = {The recent development of data-driven AI promises to automate medical diagnosis; however, most AI functions as 'black boxes' to physicians with limited computational knowledge. Using medical imaging as a point of departure, we conducted three iterations of design activities to formulate CheXplain — a system that enables physicians to explore and understand AI-enabled chest X-ray analysis: (i) a paired survey between referring physicians and radiologists reveals whether, when, and what kinds of explanations are needed; (ii) a low-fidelity prototype co-designed with three physicians formulates eight key features; and (iii) a high-fidelity prototype evaluated by another six physicians provides detailed summative insights on how each feature enables the exploration and understanding of AI. We summarize by discussing recommendations for future work to design and implement explainable medical AI systems that encompass four recurring themes: motivation, constraint, explanation, and justification.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {system design, explainable artificial intelligence, physician-centered design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376341,
author = {Chikersal, Prerna and Belgrave, Danielle and Doherty, Gavin and Enrique, Angel and Palacios, Jorge E. and Richards, Derek and Thieme, Anja},
title = {Understanding Client Support Strategies to Improve Clinical Outcomes in an Online Mental Health Intervention},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376341},
doi = {10.1145/3313831.3376341},
abstract = {Online mental health interventions are increasingly important in providing access to, and supporting the effectiveness of, mental health treatment. While these technologies are effective, user attrition and early disengagement are key challenges. Evidence suggests that integrating a human supporter into such services mitigates these challenges, however, it remains under-studied how supporter involvement benefits client outcomes, and how to maximize such effects. We present our analysis of 234,735 supporter messages to discover how different support strategies correlate with clinical outcomes. We describe our machine learning methods for: (i) clustering supporters based on client outcomes; (ii) extracting and analyzing linguistic features from supporter messages; and (iii) identifying context-specific patterns of support. Our findings indicate that concrete, positive and supportive feedback from supporters that reference social behaviors are strongly associated with better outcomes; and show how their importance varies dependent on different client situations. We discuss design implications for personalized support and supporter interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {unsupervised learning, digital behavioral intervention, data mining, ai, support, machine learning, mental health, cbt},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376471,
author = {Campo Woytuk, Nadia and S\o{}ndergaard, Marie Louise Juul and Ciolfi Felice, Marianela and Balaam, Madeline},
title = {Touching and Being in Touch with the Menstruating Body},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376471},
doi = {10.1145/3313831.3376471},
abstract = {We describe a Research through Design project-Curious Cycles-a collection of objects and interactions which encourage people to be in close contact with their menstruating body. Throughout a full menstrual cycle, five participants used Curious Cycles to look at their bodies in unfamiliar ways and to touch their bodily fluids, specifically, menstrual blood, saliva, and cervical mucus. The act of touching and looking led to the construction of new knowledge about the self and to a nurturing appreciation for the changing body. Yet, participants encountered and reflected upon frictions within themselves, their home, and their social surroundings, which stem from societal stigma and preconceptions about menstruation and bodily fluids. We call for and show how interaction design can engage with technologies that mediate self-touch as a first step towards reconfiguring the way menstruating bodies are treated in society.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {menstrual cycles, feminist hci, touching, menstruation, women's health, research through design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376526,
author = {Kozubaev, Sandjar and Elsden, Chris and Howell, Noura and S\o{}ndergaard, Marie Louise Juul and Merrill, Nick and Schulte, Britta and Wong, Richmond Y.},
title = {Expanding Modes of Reflection in Design Futuring},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376526},
doi = {10.1145/3313831.3376526},
abstract = {Design futuring approaches, such as speculative design, design fiction and others, seek to (re)envision futures and explore alternatives. As design futuring becomes established in HCI design research, there is an opportunity to expand and develop these approaches. To that end, by reflecting on our own research and examining related work, we contribute five modes of reflection. These modes concern formgiving, temporality, researcher positionality, real-world engagement, and knowledge production. We illustrate the value of each mode through careful analysis of selected design exemplars and provide questions to interrogate the practice of design futuring. Each reflective mode offers productive resources for design practitioners and researchers to articulate their work, generate new directions for their work, and analyze their own and others' work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {research through design, futures-oriented design, speculative design, design futuring, futures, design methods},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376498,
author = {Li, Yifang and Vishwamitra, Nishant and Hu, Hongxin and Caine, Kelly},
title = {Towards A Taxonomy of Content Sensitivity and Sharing Preferences for Photos},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376498},
doi = {10.1145/3313831.3376498},
abstract = {Determining which photos are sensitive is difficult. Although emerging computer vision systems can label content items, previous attempts to distinguish private or sensitive content fall short. There is no human-centered taxonomy that describes what content is sensitive or how sharing preferences for content differs across recipients. To fill this gap, we introduce a new sensitive content elicitation method which surmounts limitations of previous approaches, and, using this new method, collected sensitive content from 116 participants. We also recorded participants' sharing preferences with 20 recipient groups. Next, we conducted a card sort to surface user-defined categories of sensitive content. Using data from these studies, we generated a taxonomy that identifies 28 categories of sensitive content. We also establish how sharing preferences for content differs across groups of recipients. This taxonomy can serve as a framework for understanding photo privacy, which can, in turn, inform new photo privacy protection mechanisms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {privacy, photo privacy, security, sensitive content},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376180,
author = {Chen, Kun-Ting and Dwyer, Tim and Marriott, Kim and Bach, Benjamin},
title = {DoughNets: Visualising Networks Using Torus Wrapping},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376180},
doi = {10.1145/3313831.3376180},
abstract = {We investigate visualisations of networks on a 2-dimensional torus topology, like an opened-up and flattened doughnut. That is, the network is drawn on a rectangular area while "wrapping" specific links around the border. Previous work on torus drawings of networks has been mostly theoretical, limited to certain classes of networks, and not evaluated by human readability studies. We offer a simple interactive layout approach applicable to general graphs. We use this to find layouts affording better aesthetics in terms of conventional measures like more equal edge length and fewer crossings. In two controlled user studies we find that torus layout with either additional context or interactive panning provided significant performance improvement (in terms of error and time) over torus layout without either of these improvements, to the point that it is comparable to standard non-torus layout.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {torus topology, user study, network visualization, graph visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376562,
author = {Ogawa, Nami and Narumi, Takuji and Kuzuoka, Hideaki and Hirose, Michitaka},
title = {Do You Feel Like Passing Through Walls?: Effect of Self-Avatar Appearance on Facilitating Realistic Behavior in Virtual Environments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376562},
doi = {10.1145/3313831.3376562},
abstract = {Preventing users from walking through virtual boundaries (e.g., walls) is an important issue to be addressed in room-scale virtual environments (VEs), considering the safety and design limitations. Sensory feedback from wall collisions has been shown to be effective; however, it can disrupt the immersion. We assumed that a greater sense of presence would discourage users from walking through walls and conducted a two-factor between-subjects experiment (N = 92) that controls the anthropomorphism (realistic or abstract) and visibility (full-body or hand-only) of self-avatars. We analyzed the participants' behaviors and the moment they first penetrated the wall in game-like VEs that gradually instigated participants to penetrate the walls. The results showed that the realistic full-body self-avatar was the most effective for discouraging the participants from penetrating the walls. Furthermore, the participants with lower presence tended to walk through the walls sooner. This study can contribute to applications that require realistic user responses in VEs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {body ownership, self-avatar, presence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376438,
author = {Sidenmark, Ludwig and Clarke, Christopher and Zhang, Xuesong and Phu, Jenny and Gellersen, Hans},
title = {Outline Pursuits: Gaze-Assisted Selection of Occluded Objects in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376438},
doi = {10.1145/3313831.3376438},
abstract = {In 3D environments, objects can be difficult to select when they overlap, as this affects available target area and increases selection ambiguity. We introduce Outline Pursuits which extends a primary pointing modality for gaze-assisted selection of occluded objects. Candidate targets within a pointing cone are presented with an outline that is traversed by a moving stimulus. This affords completion of the selection by gaze attention to the intended target's outline motion, detected by matching the user's smooth pursuit eye movement. We demonstrate two techniques implemented based on the concept, one with a controller as the primary pointer, and one in which Outline Pursuits are combined with head pointing for hands-free selection. Compared with conventional raycasting, the techniques require less movement for selection as users do not need to reposition themselves for a better line of sight, and selection time and accuracy are less affected when targets become highly occluded.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, smooth pursuits, eye tracking, occlusion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376598,
author = {Troiano, Giovanni Maria and Wood, Matthew and Harteveld, Casper},
title = {"And This, Kids, Is How I Met Your Mother": Consumerist, Mundane, and Uncanny Futures with Sex Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376598},
doi = {10.1145/3313831.3376598},
abstract = {Sex Robots are no longer science fiction and may soon be-come widespread. While much discussion has developed in academia on their moral and social impact, sex robots have yet to be examined from a critical design perspective and are under-explored in HCI. We use the Story Completion Method(SCM) to explore commonplace assumptions around futures with sex robots and discuss those from a critical design perspective. Thirty five participants completed a story stem of a human encountering a sex robot or vice-versa. Through thematic analysis, we show narratives of consumerist relation-ships between humans and sex robots, stories that describe sex robots as highly-efficient sex workers that (out)perform humans in routinal sex activities, and narratives that explore sex robots as empathetic and sentient beings. Our participant-created stories both reinforce and challenge established norms of sex robots and raise questions that concern responsible design and ethics in HCI. Finally, we show opportunities and limitations of using multiple-perspective story stems in SCM},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {sex robots, research fiction, ethics, story completion method, human-robot interaction, sexual HCI, speculative design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376530,
author = {Roldan, Wendy and Gao, Xin and Hishikawa, Allison Marie and Ku, Tiffany and Li, Ziyue and Zhang, Echo and Froehlich, Jon E. and Yip, Jason},
title = {Opportunities and Challenges in Involving Users in Project-Based HCI Education},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376530},
doi = {10.1145/3313831.3376530},
abstract = {Users are fundamental to HCI. However, little is known about how HCI education introduces students to working with users, particularly those different from themselves. To better understand design students' engagement, reactions, and reflections with users, we investigate a case study of a graduate-level 10-week prototyping studio course that partnered with a children's co-design team. HCI students participated in two co-design sessions with children to design a STEM learning experience for youth. We conducted participant observations, interviews with 14 students, and analyzed final artifacts. Our findings demonstrate the communication challenges and strategies students experienced, how students observed issues of power dynamics, and students' perceived value in engaging with users. We contribute empirical evidence of how HCI students directly interact with target users, principles for reflective HCI pedagogy, and highlight the need for more intentional investigation into HCI educational practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {reflection, hci education, user-centered design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376518,
author = {Bassen, Jonathan and Balaji, Bharathan and Schaarschmidt, Michael and Thille, Candace and Painter, Jay and Zimmaro, Dawn and Games, Alex and Fast, Ethan and Mitchell, John C.},
title = {Reinforcement Learning for the Adaptive Scheduling of Educational Activities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376518},
doi = {10.1145/3313831.3376518},
abstract = {Adaptive instruction for online education can increase learning gains and decrease the work required of learners, instructors, and course designers. Reinforcement Learning (RL) is a promising tool for developing instructional policies, as RL models can learn complex relationships between course activities, learner actions, and educational outcomes. This paper demonstrates the first RL model to schedule educational activities in real time for a large online course through active learning. Our model learns to assign a sequence of course activities while maximizing learning gains and minimizing the number of items assigned. Using a controlled experiment with over 1,000 learners, we investigate how this scheduling policy affects learning gains, dropout rates, and qualitative learner feedback. We show that our model produces better learning gains using fewer educational activities than a linear assignment condition, and produces similar learning gains to a self-directed condition using fewer educational activities and with lower dropout rates.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online education, adaptive learning, reinforcement learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376866,
author = {Sun, Dong and Feng, Zezheng and Chen, Yuanzhe and Wang, Yong and Zeng, Jia and Yuan, Mingxuan and Pong, Ting-Chuen and Qu, Huamin},
title = {DFSeer: A Visual Analytics Approach to Facilitate Model Selection for Demand Forecasting},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376866},
doi = {10.1145/3313831.3376866},
abstract = {Selecting an appropriate model to forecast product demand is critical to the manufacturing industry. However, due to the data complexity, market uncertainty and users' demanding requirements for the model, it is challenging for demand analysts to select a proper model. Although existing model selection methods can reduce the manual burden to some extent, they often fail to present model performance details on individual products and reveal the potential risk of the selected model. This paper presents DFSeer, an interactive visualization system to conduct reliable model selection for demand forecasting based on the products with similar historical demand. It supports model comparison and selection with different levels of details. Besides, it shows the difference in model performance on similar products to reveal the risk of model selection and increase users' confidence in choosing a forecasting model. Two case studies and interviews with domain experts demonstrate the effectiveness and usability of DFSeer.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {time series, product demand forecasting, model selection, interactive visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376673,
author = {Fu, Xinyi and Zhu, Yaxin and Xiao, Zhijing and Xu, Yingqing and Ma, Xiaojuan},
title = {RestoreVR: Generating Embodied Knowledge and Situated Experience of Dunhuang Mural Conservation via Interactive Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376673},
doi = {10.1145/3313831.3376673},
abstract = {In Dunhuang Mogao Grottoes, unique Buddhist murals of ancient China are preserved. Unfortunately, the exquisite murals are suffering from degradation. Experts have been trying to enhance public's awareness of mural protection, but there's no efficacious means to attract interest and popularize knowledge yet. In this paper, we propose RestoreVR, an interactive virtual reality (VR) system engaging users to experience Dunhuang mural restoration in a digital tour in the cave. Based on an online survey with the public and in-depth interviews with five Dunhuang experts, we derive a set of design requirements for generating embodied knowledge and situated experience in VR to bridge the gap between highly specialized experts and general audiences. Accordingly, we design RestoreVR and conduct a between-subjects user study to compare our system with traditional methods. The results suggest that RestoreVR significantly improves user experience and awareness of CH protection over existing methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {survey, cultural heritage, interactive virtual reality, dunhuang, mural conservation, implementation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376752,
author = {Kizilcec, Rene F. and Saltarelli, Andrew and Bonfert-Taylor, Petra and Goudzwaard, Michael and Hamonic, Ella and Sharrock, R\'{e}mi},
title = {Welcome to the Course: Early Social Cues Influence Women's Persistence in Computer Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376752},
doi = {10.1145/3313831.3376752},
abstract = {First impressions influence subsequent behavior, especially when deciding how much effort to invest in an activity such as taking an online course. In computer programming courses, a context where social group stereotypes are salient, social cues early in the course can be used strategically to affirm members of historically underrepresented groups in their sense of belonging. We tested this idea in two randomized field experiments (N=53,922) by varying the social identity and status of the presenter of a welcome video and assessing online learners' persistence and achievement. Counter to our hypotheses, we found lower persistence among women in certain age groups if the welcome video was presented by a female instructor or by lower-status peers. Men remained unaffected. The results suggest that women are more responsive to social cues in online STEM courses, an environment where their social identity has been negatively stereotyped. Presenting a male and female instructor together was an effective strategy for retaining women in the course.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {education, psychology, gender, inclusion, computer science},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376184,
author = {Richardson, Mike L. and Lloyd-Esenkaya, Tayfun and Petrini, Karin and Proulx, Michael J.},
title = {Reading with the Tongue: Individual Differences Affect the Perception of Ambiguous Stimuli with the BrainPort},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376184},
doi = {10.1145/3313831.3376184},
abstract = {There is an increasing interest in non-visual interfaces for HCI to take advantage of the information processing capability of the other sensory modalities. The BrainPort is a vision-to-tactile sensory substitution device that conveys information through electro-stimulation on the tongue. As the tongue is a horizontal surface, it makes for an interesting platform to study the brain's representation of space. But which way is up on the tongue? We provided participants with perceptually ambiguous stimuli and measured how often different perspectives were adopted; furthermore, whether camera orientation and gender had an effect. Additionally, we examined whether personality (trait extraversion and openness) could predict the perspective taken. We found that self-centered perspectives were predominantly adopted, and that trait openness may predict perspective. This research demonstrates how individual differences can affect the usability of sensory substitution devices, and highlights the need for flexible and customisable interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {tactile interfaces, sensory substitution, user preferences, individual differences in computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376486,
author = {Heshmat, Yasamin and Neustaedter, Carman and McCaffrey, Kyle and Odom, William and Wakkary, Ron and Yang, Zikun},
title = {FamilyStories: Asynchronous Audio Storytelling for Family Members Across Time Zones},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376486},
doi = {10.1145/3313831.3376486},
abstract = {Family members who are separated across time zones can easily miss out on feeling connected. We designed and studied the usage of an asynchronous storytelling system, called FamilyStories, to explore the use of audio-based sharing. FamilyStories allows family members to share activities and experiences over distance in different time zones using three different devices that contain different contextual features. To evaluate the design, we conducted a five-week long field study with two family member pairs. Our results show the value of slow, flexible, and non-suggestive interfaces for asynchronous audio communication. We also found ephemerality helped in the sharing of 'instant' feelings, while large time zone differences could be 'synchronized' with time delayed messages. We raise these as design opportunities for asynchronous audio storytelling systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {slow technology, family communication, domestic, audio, asynchronous communication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376283,
author = {Morales-Martinez, Gabriela and Latreille, Paul and Denny, Paul},
title = {Nationality and Gender Biases in Multicultural Online Learning Environments: The Effects of Anonymity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376283},
doi = {10.1145/3313831.3376283},
abstract = {Online learning environments eliminate geographical barriers and enable new forms of collaboration between students at large scale. Self-presentation within such environments affects how students interact with learning content and with each other. We explore how anonymity/identifiability in user profile design impacts student interactions in a large multicultural classroom across two geographical locations. After triangulating 150,000 online interactions with questionnaires and focus groups, we provide three major findings. First, being identifiable had a significant impact on how students accessed and rated content created by their peers. Second, when identifiable, cultural differences became more prominent, leading some students to avoid content created by classmates of certain nationalities. Finally, when students interacted with their real identities, there were significant and negative gender effects which were absent when students were anonymous. These findings contribute to our understanding of social dynamics within multicultural learning environments, and raise practical implications for tool design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {nationality bias, peerwise, identity, online education, gender bias, computer-mediated communication, oles, anonymity, peer ratings, vles, online learning environments},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376225,
author = {Storer, Kevin M. and Judge, Tejinder K. and Branham, Stacy M.},
title = {"All in the Same Boat": Tradeoffs of Voice Assistant Ownership for Mixed-Visual-Ability Families},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376225},
doi = {10.1145/3313831.3376225},
abstract = {A growing body of evidence suggests Voice Assistants (VAs) are highly valued by people with vision impairments (PWVI) and much less so by sighted users. Yet, many are deployed in homes where both PWVI and sighted family members reside. Researchers have yet to study whether VA use and perceived benefits are affected in settings where one person has a visual impairment and others do not. We conducted six in-depth interviews with partners to understand patterns of domestic VA use in mixed-visual-ability families. Although PWVI were more motivated to acquire VAs, used them more frequently, and learned more proactively about their features, partners with vision identified similar benefits and disadvantages of having VAs in their home. We found that the universal usability of VAs both equalizes experience across abilities and presents complex tradeoffs for families-regarding interpersonal relationships, domestic labor, and physical safety-which are weighed against accessibility benefits for PWVI and complicate the decision to fully integrate VAs in the home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {home, vision impairment, universal usability, voice assistant, mixed-visual-ability settings},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376151,
author = {Seering, Joseph and Hammer, Jessica and Kaufman, Geoff and Yang, Diyi},
title = {Proximate Social Factors in First-Time Contribution to Online Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376151},
doi = {10.1145/3313831.3376151},
abstract = {In the course of every member's integration into an online community, a decision must be made to participate for the first time. The challenges of effective recruitment, management, and retention of new users have been extensively explored in social computing research. However, little work has looked at in-the-moment factors that lead users to decide to participate instead of "lurk", conditions which can be shaped to draw new users in at crucial moments. In this work we analyze 183 million messages scraped from chatrooms on the livestreaming platform Twitch in order to understand differences between first-time participants' and regulars' behaviors and to identify conditions that encourage first-time participation. We find that presence of diverse types of users increases likelihood of new participation, with effects depending on the size of the community. We also find that information-seeking behaviors in first-time participation are negatively associated with retention in the short and medium term.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {twitch, online communities, participation, newcomers, retention, social roles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376634,
author = {Kow, Yong Ming and Nardi, Bonnie and Cheng, Wai Kuen},
title = {Be Water: Technologies in the Leaderless Anti-ELAB Movement in Hong Kong},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376634},
doi = {10.1145/3313831.3376634},
abstract = {We examine a leaderless social movement characterized by participants' autonomy and the absence of leaders and organizations. We conducted a participant observation study of the Anti-ELAB movement in Hong Kong. Focusing on the organization of a protest march, we collected thousands of lines of discourse in the LIHKG Forum and the Telegram instant messaging system. Our grounded theory analysis revealed hundreds of groups acting within a symbiotic network. Participants promoted an ethos of empowering individual participants and groups to act autonomously. At the same time, participants' extensive use of hyperlinks and polls orchestrated a coherent social movement. We discuss how this novel formation can mediate successful leaderless movements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {anti-elab, ethnography, hong kong, leaderless social movement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376391,
author = {Kotut, Lindah and Horning, Michael and Stelter, Timothy L. and McCrickard, D. Scott},
title = {Preparing for the Unexpected: Community Framework for Social Media Use and Social Support by Trail Thru-Hikers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376391},
doi = {10.1145/3313831.3376391},
abstract = {A months-long hike of the Appalachian Trail often involve long-term preparation and life-altering decisions. Would-be hikers leverage institutional knowledge from literature and online forums to physically and mentally prepare for such an arduous hike. Their use of social platforms provide useful insights on motivations for undertaking the thru-hike, how they deal with unexpected conditions on the trail and understand choices made in conditions of scarcity. By analyzing over 100,000 Reddit posts and comments in r/AppalachianTrail and applying a Sense of Community theory, we sought to understand hikers' identity as community members, how their emotional and practical needs are met, and how they evolve. We found that the role and language of thru-hikers change as they progress from pre-hike, on-hike, and post-hike stages, from a questioner early on, to an expert post-hike. We conclude with design recommendations to support offline communities online.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {appalachian trail, trail community, information seeking, thru-hike, rural computing, long-distance hiking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376221,
author = {Peng, Xiaolan and Huang, Jin and Denisova, Alena and Chen, Hui and Tian, Feng and Wang, Hongan},
title = {A Palette of Deepened Emotions: Exploring Emotional Challenge in Virtual Reality Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376221},
doi = {10.1145/3313831.3376221},
abstract = {Recent work introduced the notion of 'emotional challenge' promising for understanding more unique and diverse player experiences (PX). Although emotional challenge has immediately attracted HCI researchers' attention, the concept has not been experimentally explored, especially in virtual reality (VR), one of the latest gaming environments. We conducted two experiments to investigate how emotional challenge affects PX when separately from or jointly with conventional challenge in VR and PC conditions. We found that relatively exclusive emotional challenge induced a wider range of different emotions in both conditions, while the adding of emotional challenge broadened emotional responses only in VR. In both experiments, VR significantly enhanced the measured PX of emotional responses, appreciation, immersion and presence. Our findings indicate that VR may be an ideal medium to present emotional challenge and also extend the understanding of emotional (and conventional) challenge in video games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, emotion, emotional challenge, games, player experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376868,
author = {Voelker, Simon and Hueber, Sebastian and Corsten, Christian and Remy, Christian},
title = {HeadReach: Using Head Tracking to Increase Reachability on Mobile Touch Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376868},
doi = {10.1145/3313831.3376868},
abstract = {People often operate their smartphones with only one hand, using just their thumb for touch input. With today's larger smartphones, this leads to a reachability issue: Users can no longer comfortably touch everywhere on the screen without changing their grip. We investigate using the head tracking in modern smartphones to address this reachability issue. We developed three interaction techniques, pure head (PH), head + touch (HT), and head area + touch (HA), to select targets beyond the reach of one's thumb. In two user studies, we found that selecting targets using HT and HA had higher success rates than the default direct touch (DT) while standing (by about 9%) and walking (by about 12%), while being moderately slower. HT and HA were also faster than one of the best techniques, BezelCursor (BC) (by about 20% while standing and 6% while walking), while having the same success rate.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user study, force input, gaze selection, head tracking, reachability, walking, touch input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376746,
author = {Bae, Suyun Sandra and Kwon, Oh-Hyun and Chandrasegaran, Senthil and Ma, Kwan-Liu},
title = {Spinneret: Aiding Creative Ideation through Non-Obvious Concept Associations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376746},
doi = {10.1145/3313831.3376746},
abstract = {Mind mapping is a popular way to explore a design space in creative thinking exercises, allowing users to form associations between concepts. Yet, most existing digital tools for mind mapping focus on authoring and organization, with little support for addressing the challenges of mind mapping such as stagnation and design fixation. We present Spinneret, a functional approach to aid mind mapping by providing suggestions based on a knowledge graph. Spinneret uses biased random walks to explore the knowledge graph in the neighborhood of an existing concept node in the mind map, and provides "suggestions" for the user to add to the mind map. A comparative study with a baseline mind-mapping tool reveals that participants created more diverse and distinct concepts with Spinneret, and reported that the suggestions inspired them to think of ideas they would otherwise not have explored.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mind mapping, knowledge graph, creativity, suggestion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376425,
author = {Vasquez, Joshua and Twigg-Smith, Hannah and Tran O'Leary, Jasper and Peek, Nadya},
title = {Jubilee: An Extensible Machine for Multi-Tool Fabrication},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376425},
doi = {10.1145/3313831.3376425},
abstract = {We present Jubilee, an open-source hardware machine with automatic tool-changing and interchangeable bed plates. As digital fabrication tools have become more broadly accessible, tailoring those machines to new users and novel workflows has become central to HCI research. However, the lack of hardware infrastructure makes custom application development cumbersome. We identify a need for an extensible platform to allow HCI researchers to develop workflows for fabrication, material exploration, and other applications. Jubilee addresses this need. It can automatically and repeatably change tools in the same operation. It can be built with a combination of simple 3D-printed and readily available parts. It has several standard head designs for a variety of applications including 3D printing, syringe-based liquid handling, imaging, and plotting. We present Jubilee with a comprehensive set of assembly instructions and kinematic mount templates for user-designed tools and bed plates. Finally we demonstrate Jubilee's multi-tool workflow functionality with a series of example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {digital fabrication, toolchanging, multi-tool workflows},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376721,
author = {Zhong, Ce and Wakkary, Ron and Zhang, Xiao and Chen, Amy Yo Sue},
title = {TransTexture Lamp: Understanding Lived Experiences with Deformation Through a Materiality Lens},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376721},
doi = {10.1145/3313831.3376721},
abstract = {This paper provides a materiality perspective to understanding lived experiences with a deformable domestic artefact, named transTexture lamp. The lamp is an interactive light with a deformable lampshade surface. We deployed transTexture lamps in the homes of three professional designers for two months with the aim of exploring possible interactions and engagements with the deformable lamp. Our findings show how participants experienced transTexture through pleasurable interactions and how they experienced deformation over time from reflections on these interactions. Analyzing the data through a materiality lens unpacked a creative process of drawing on the deformable lampshade surface, which results in the accumulation of substrates and transformations of deformations. These findings suggest opportunities for future material-centered interaction design research and practices in HCI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {material-centered interaction design, materiality, computational design, research-through-design, deformation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376845,
author = {Lee, Bridjet and Muldner, Kasia},
title = {Instructional Video Design: Investigating the Impact of Monologue- and Dialogue-Style Presentations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376845},
doi = {10.1145/3313831.3376845},
abstract = {Instructional videos are frequently used in online courses and websites. Such videos may include an instructor delivering a monologue-style presentation, or alternatively, engaging in a dialogue with a student who appears in the video alongside of the instructor. We compared three instructional video designs (N = 77), including monologue and dialogue style presentations. To obtain a comprehensive view of the impact of video design, we used a variety of measures, including eye tracking data, learning gains, self-efficacy, cognitive load, social presence, and interest. Despite eye tracking data showing that participants in speaker-visible conditions spent significantly less time on the domain content, learning and related variables were similar in all three conditions, a result we confirmed with Bayesian statistics that provided substantial evidence for the null model. Altogether, we provide evidence that learning and interest are not enhanced by a dialogue-style presentation or visual presence of the instructor. However, further work is needed to investigate the effect of other domains, speaker persona and saliency, and configuration of the speakers in the instructional video.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {dialogue presentation, visual presence, interest, eye tracking, monologue presentation, instructional video design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376728,
author = {Gleason, Cole and Pavel, Amy and McCamey, Emma and Low, Christina and Carrington, Patrick and Kitani, Kris M. and Bigham, Jeffrey P.},
title = {Twitter A11y: A Browser Extension to Make Twitter Images Accessible},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376728},
doi = {10.1145/3313831.3376728},
abstract = {Social media platforms are integral to public and private discourse, but are becoming less accessible to people with vision impairments due to an increase in user-posted images. Some platforms (i.e. Twitter) let users add image descriptions (alternative text), but only 0.1% of images include these. To address this accessibility barrier, we created Twitter A11y, a browser extension to add alternative text on Twitter using six methods. For example, screenshots of text are common, so we detect textual images, and create alternative text using optical character recognition. Twitter A11y also leverages services to automatically generate alternative text or reuse them from across the web. We compare the coverage and quality of Twitter A11y's six alt-text strategies by evaluating the timelines of 50 self-identified blind Twitter users. We find that Twitter A11y increases alt-text coverage from 7.6% to 78.5%, before crowdsourcing descriptions for the remaining images. We estimate that 57.5% of returned descriptions are high-quality. We then report on the experiences of 10 participants with visual impairments using the tool during a week-long deployment. Twitter A11y increases access to social media platforms for people with visual impairments by providing high-quality automatic descriptions for user-posted images.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {screen reader, accessibility, twitter, social media},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376313,
author = {Zhou, Qian and Sykes, Sarah and Fels, Sidney and Kin, Kenrick},
title = {Gripmarks: Using Hand Grips to Transform In-Hand Objects into Mixed Reality Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376313},
doi = {10.1145/3313831.3376313},
abstract = {We introduce Gripmarks, a system that enables users to opportunistically use objects they are already holding as input surfaces for mixed reality head-mounted displays (HMD). Leveraging handheld objects reduces the need for users to free up their hands or acquire a controller to interact with their HMD. Gripmarks associate a particular hand grip with the shape primitive of the physical object without the need of object recognition or instrumenting the object. From the grip pose and shape primitive we can infer the surface of the object. With an activation gesture, we can enable the object for use as input to the HMD. With five gripmarks we demonstrate a recognition rate of 94.2%; we show that our grip detection benefits from the physical constraints of holding an object. We explore two categories of input objects 1) tangible surfaces and 2) tangible tools and present two representative applications. We discuss the design and technical challenges for expanding the concept.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {gripmarks, tangible objects, grip recognition, mixed reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376781,
author = {Winkler, Rainer and Hobert, Sebastian and Salovaara, Antti and S\"{o}llner, Matthias and Leimeister, Jan Marco},
title = {Sara, the Lecturer: Improving Learning in Online Education with a Scaffolding-Based Conversational Agent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376781},
doi = {10.1145/3313831.3376781},
abstract = {Enrollment in online courses has sharply increased in higher education. Although online education can be scaled to large audiences, the lack of interaction between educators and learners is difficult to replace and remains a primary challenge in the field. Conversational agents may alleviate this problem by engaging in natural interaction and by scaffolding learners' understanding similarly to educators. However, whether this approach can also be used to enrich online video lectures has largely remained unknown. We developed Sara, a conversational agent that appears during an online video lecture. She provides scaffolds by voice and text when needed and includes a voice-based input mode. An evaluation with 182 learners in a 2 x 2 lab experiment demonstrated that Sara, compared to more traditional conversational agents, significantly improved learning in a programming task. This study highlights the importance of including scaffolding and voice-based conversational agents in online videos to improve meaningful learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {online education, interactivity, voice interaction, conversational agent, online videos, experiment, scaffolding},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376657,
author = {Wang, Xiyao and Besan\c{c}on, Lonni and Rousseau, David and Sereno, Mickael and Ammi, Mehdi and Isenberg, Tobias},
title = {Towards an Understanding of Augmented Reality Extensions for Existing 3D Data Analysis Tools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376657},
doi = {10.1145/3313831.3376657},
abstract = {We present an observational study with domain experts to understand how augmented reality (AR) extensions to traditional PC-based data analysis tools can help particle physicists to explore and understand 3D data. Our goal is to allow researchers to integrate stereoscopic AR-based visual representations and interaction techniques into their tools, and thus ultimately to increase the adoption of modern immersive analytics techniques in existing data analysis workflows. We use Microsoft's HoloLens as a lightweight and easily maintainable AR headset and replicate existing visualization and interaction capabilities on both the PC and the AR view. We treat the AR headset as a second yet stereoscopic screen, allowing researchers to study their data in a connected multi-view manner. Our results indicate that our collaborating physicists appreciate a hybrid data exploration setup with an interactive AR extension to improve their understanding of particle collision events.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {immersive analytics, 3D visualization, user interface, hybrid visualization system},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376877,
author = {V\"{o}lkel, Sarah Theres and Haeuslschmid, Renate and Werner, Anna and Hussmann, Heinrich and Butz, Andreas},
title = {How to Trick AI: Users' Strategies for Protecting Themselves from Automatic Personality Assessment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376877},
doi = {10.1145/3313831.3376877},
abstract = {Psychological targeting tries to influence and manipulate users' behaviour. We investigated whether users can protect themselves from being profiled by a chatbot, which automatically assesses users' personality. Participants interacted twice with the chatbot: (1) They chatted for 45 minutes in customer service scenarios and received their actual profile (baseline). (2) They then were asked to repeat the interaction and to disguise their personality by strategically tricking the chatbot into calculating a falsified profile. In interviews, participants mentioned 41 different strategies but could only apply a subset of them in the interaction. They were able to manipulate all Big Five personality dimensions by nearly 10%. Participants regarded personality as very sensitive data. As they found tricking the AI too exhaustive for everyday use, we reflect on opportunities for privacy protective designs in the context of personality-aware systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {automatic personality assessment, chatbot, personality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376822,
author = {Khurana, Rushil and Goel, Mayank},
title = {Eyes on the Road: Detecting Phone Usage by Drivers Using On-Device Cameras},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376822},
doi = {10.1145/3313831.3376822},
abstract = {Using a phone while driving is distracting and dangerous. It increases the accident chances by 400%. Several techniques have been proposed in the past to detect driver distraction due to phone usage. However, such techniques usually require instrumenting the user or the car with custom hardware. While detecting phone usage in the car can be done by using the phone's GPS, it is harder to identify whether the phone is used by the driver or one of the passengers. In this paper, we present a lightweight, software-only solution that uses the phone's camera to observe the car's interior geometry to distinguish phone position and orientation. We then use this information to distinguish between driver and passenger phone use. We collected data in 16 different cars with 33 different users and achieved an overall accuracy of 94% when the phone is held in hand and 92.2% when the phone is docked (1 sec. delay). With just a software upgrade, this work can enable smartphones to proactively adapt to the user's context in the car and and substantially reduce distracted driving incidents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {position sensing, situational impairments, driver detection, in-car behavior},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376815,
author = {Putze, Felix and Ihrig, Tilman and Schultz, Tanja and Stuerzlinger, Wolfgang},
title = {Platform for Studying Self-Repairing Auto-Corrections in Mobile Text Entry Based on Brain Activity, Gaze, and Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376815},
doi = {10.1145/3313831.3376815},
abstract = {Auto-correction is a standard feature of mobile text entry. While the performance of state-of-the-art auto-correct methods is usually relatively high, any errors that occur are cumbersome to repair, interrupt the flow of text entry, and challenge the user's agency over the process. In this paper, we describe a system that aims to automatically identify and repair auto-correction errors. This system comprises a multi-modal classifier for detecting auto-correction errors from brain activity, eye gaze, and context information, as well as a strategy to repair such errors by replacing the erroneous correction or suggesting alternatives. We integrated both parts in a generic Android component and thus present a research platform for studying self-repairing end-to-end systems. To demonstrate its feasibility, we performed a user study to evaluate the classification performance and usability of our approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {EEG, auto-correction, eye gaze, self-repair, text entry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376614,
author = {Lin, Chuan-en and Cheng, Ta Ying and Ma, Xiaojuan},
title = {ARchitect: Building Interactive Virtual Experiences from Physical Affordances by Bringing Human-in-the-Loop},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376614},
doi = {10.1145/3313831.3376614},
abstract = {Automatic generation of Virtual Reality (VR) worlds which adapt to physical environments have been proposed to enable safe walking in VR. However, such techniques mainly focus on the avoidance of physical objects as obstacles and overlook their interaction affordances as passive haptics. Current VR experiences involving interaction with physical objects in surroundings still require verbal instruction from an assisting partner. We present ARchitect, a proof-of-concept prototype that allows flexible customization of a VR experience with human-in-the-loop. ARchitect brings in an assistant to map physical objects to virtual proxies of matching affordances using Augmented Reality (AR). In a within-subjects study (9 user pairs) comparing ARchitect to a baseline condition, assistants and players experienced decreased workload and players showed increased VR presence and trust in the assistant. Finally, we defined design guidelines of ARchitect for future designers and implemented three demonstrative experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {affordance, architect, passive haptics, asymmetric, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376138,
author = {Han, Teng and Wang, Sirui and Wang, Sijia and Fan, Xiangmin and Liu, Jie and Tian, Feng and Fan, Mingming},
title = {Mouill\'{e}: Exploring Wetness Illusion on Fingertips to Enhance Immersive Experience in VR},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376138},
doi = {10.1145/3313831.3376138},
abstract = {Providing users with rich sensations is beneficial to enhance their immersion in Virtual Reality (VR) environments. Wetness is one such imperative sensation that affects users' sense of comfort and helps users adjust grip force when interacting with objects. Researchers have recently begun to explore ways to create wetness illusions, primarily on a user's face or body skin. In this work, we extended this line of research by creating wetness illusion on users' fingertips. We first conducted a user study to understand the effect of thermal and tactile feedback on users' perceived wetness sensation. Informed by the findings, we designed and evaluated a prototype---Mouill\'{e}---that provides various levels of wetness illusions on fingertips for both hard and soft items when users squeeze, lift, or scratch it. Study results indicated that users were able to feel wetness with different levels of temperature changes and they were able to distinguish three levels of wetness for simulated VR objects. We further presented applications that simulated an ice cube, an iced cola bottle, and a wet sponge, etc, to demonstrate its use in VR.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {wetness illusion, user study, virtual reality, prototype},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376527,
author = {Carstensdottir, Elin and Partlan, Nathan and Sutherland, Steven and Duke, Tyler and Ferris, Erika and Richter, Robin M. and Valladares, Maria and Seif El-Nasr, Magy},
title = {Progression Maps: Conceptualizing Narrative Structure for Interaction Design Support},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376527},
doi = {10.1145/3313831.3376527},
abstract = {Interactive narratives are frequently designed for learning and training applications, such as social training. In these contexts, designers may be inexperienced in storytelling and interaction design, and it may be difficult to quickly build an effective experience, even for experienced designers. Designers often approach this problem through iterative design. To augment and reduce iteration, we argue for the utility of employing models to reason about, evaluate, and improve designs. While there has been much previous work on interactive narrative models, none of them capture aspects of the interaction design necessary for testing and evaluation. In this paper we propose a new computational model called Progression Maps, which abstracts interaction design elements of the narrative's structure and visualizes its interaction properties. We report on the model, its implementation, and two studies evaluating its use. Our results demonstrate Progression Maps' effectiveness in communicating the underlying design through an easily understandable visualization.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {game design, interactive narrative, interaction design, visualization, design assistance tools, graph-based models, interactive narrative model},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376156,
author = {Petro, Gwen and Gonzales, Amy and Calarco, Jessica},
title = {"Out of Luck": Socio-Economic Differences in Student Coping Responses to Technology Problems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376156},
doi = {10.1145/3313831.3376156},
abstract = {Despite high levels of digital technology access among college students, technology disruption remains an issue. This study was conducted to understand how technology disruption might contribute to socio-economic disparities in academic performance. Data were analyzed from a non-representative sample of 748 undergraduate students. We examined socio-economic differences in types of technology problems students experience; the consequences of those problems; and beliefs about how to handle future problems. Socio-economic status was not associated with types of technology problems, but it was associated with greater negative consequences and less-efficacious beliefs about handling future situations. These findings are consistent with sociological work on socio-economic differences in student help-seeking. They also elaborate mechanistic understanding of the technology maintenance construct. Finally, for those interested in designing to reduce socio-economic inequalities, they suggest the need for interfaces that go beyond information accessibility to facilitate student empowerment and student-teacher communication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {schools/educational setting, accessibility, education/learning, empirical study that tells us about people},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376792,
author = {Lindley, Joseph and Akmal, Haider Ali and Pilling, Franziska and Coulton, Paul},
title = {Researching AI Legibility through Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376792},
doi = {10.1145/3313831.3376792},
abstract = {Everyday interactions with computers are increasingly likely to involve elements of Artificial Intelligence (AI). Encompassing a broad spectrum of technologies and applications, AI poses many challenges for HCI and design. One such challenge is the need to make AI's role in a given system legible to the user in a meaningful way. In this paper we employ a Research through Design (RtD) approach to explore how this might be achieved. Building on contemporary concerns and a thorough exploration of related research, our RtD process reflects on designing imagery intended to help increase AI legibility for users. The paper makes three contributions. First, we thoroughly explore prior research in order to critically unpack the AI legibility problem space. Second, we respond with design proposals whose aim is to enhance the legibility, to users, of systems using AI. Third, we explore the role of design-led enquiry as a tool for critically exploring the intersection between HCI and AI research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {legibility, human-data interaction, research through design, machine learning, artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376680,
author = {Andalibi, Nazanin and Buss, Justin},
title = {The Human in Emotion Recognition on Social Media: Attitudes, Outcomes, Risks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376680},
doi = {10.1145/3313831.3376680},
abstract = {Emotion recognition algorithms recognize, infer, and harvest emotions using data sources such as social media behavior, streaming service use, voice, facial expressions, and biometrics in ways often opaque to the people providing these data. People's attitudes towards emotion recognition and the harms and outcomes they associate with it are important yet unknown. Focusing on social media, we interviewed 13 adult U.S. social media users to fill this gap. We find that people view emotions as insights to behavior, prone to manipulation, intimate, vulnerable, and complex. Many find emotion recognition invasive and scary, associating it with autonomy and control loss. We identify two categories of emotion recognition's risks: individual and societal. We discuss findings' implications for algorithmic accountability and argue for considering emotion data as sensitive. Using a Science and Technology Studies lens, we advocate that technology users should be considered as a relevant social group in emotion recognition advancements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {ethics, emotion recognition, social media, algorithmic accountability, emotion AI, privacy, AI ethics, fairness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376250,
author = {Kim, Seoyoung and Thakur, Arti and Kim, Juho},
title = {Understanding Users' Perception Towards Automated Personality Detection with Group-Specific Behavioral Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376250},
doi = {10.1145/3313831.3376250},
abstract = {Thanks to advanced sensing and logging technology, automatic personality assessment (APA) with users' behavioral data in the workplace is on the rise. While previous work has focused on building APA systems with high accuracy, little research has attempted to understand users' perception towards APA systems. To fill this gap, we take a mixed-methods approach: we (1) designed a survey (n=89) to understand users'social workplace behavior both online and offline and their privacy concerns; (2) built a research probe that detects personality from online and offline data streams with up to 81.3% accuracy, and deployed it for three weeks in Korea (n=32); and (3) conducted post-interviews (n=9). We identify privacy issues in sharing data and system-induced change in natural behavior as important design factors for APA systems. Our findings suggest that designers should consider the complex relationship between users' perception and system accuracy for a more user-centered APA design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {automatic personality assessment (apa), privacy, co-located group, user perception, tracking, behavior change},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376194,
author = {Bachynskyi, Myroslav and M\"{u}ller, J\"{o}rg},
title = {Dynamics of Aimed Mid-Air Movements},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376194},
doi = {10.1145/3313831.3376194},
abstract = {Mid-air arm movements are ubiquitous in VR, AR, and gestural interfaces. While mouse movements have received some attention, the dynamics of mid-air movements are understudied in HCI. In this paper we present an exploratory analysis of the dynamics of aimed mid-air movements. We explore the 3rd order lag (3OL) and existing 2nd order lag (2OL) models for modeling these dynamics. For a majority of movements the 3OL model captures mid-air dynamics better, in particular acceleration. The models can effectively predict the complete time series of position, velocity and acceleration of aimed movements given an initial state and a target using three (2OL) or four (3OL) free parameters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {movement dynamics, aimed movements, control theory, mid-air movements},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376839,
author = {Stemasov, Evgeny and Wagner, Tobias and Gugenheimer, Jan and Rukzio, Enrico},
title = {Mix&amp;Match: Towards Omitting Modelling Through In-Situ Remixing of Model Repository Artifacts in Mixed Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376839},
doi = {10.1145/3313831.3376839},
abstract = {The accessibility of tools to model artifacts is one of the core driving factors for the adoption of Personal Fabrication. Subsequently, model repositories like Thingiverse became important tools in (novice) makers' processes. They allow them to shorten or even omit the design process, offloading a majority of the effort to other parties. However, steps like measurement of surrounding constraints (e.g., clearance) which exist only inside the users' environment, can not be similarly outsourced. We propose Mix&amp;Match a mixed-reality-based system which allows users to browse model repositories, preview the models in-situ, and adapt them to their environment in a simple and immediate fashion. Mix&amp;Match aims to provide users with CSG operations which can be based on both virtual and real geometry. We present interaction patterns and scenarios for Mix&amp;Match, arguing for the combination of mixed reality and model repositories. This enables almost modelling-free personal fabrication for both novices and expert makers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {in-situ modelling, mixed reality, model repositories, personal fabrication, 3D printing, in-situ previews},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376230,
author = {Joshi, Nikhita and Matejka, Justin and Anderson, Fraser and Grossman, Tovi and Fitzmaurice, George},
title = {MicroMentor: Peer-to-Peer Software Help Sessions in Three Minutes or Less},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376230},
doi = {10.1145/3313831.3376230},
abstract = {While synchronous one-on-one help for software learning is rich and valuable, it can be difficult to find and connect with someone who can provide assistance. Through a formative user study, we explore the idea of fixed-duration, one-on-one help sessions and find that 3 minutes is often enough time for novice users to explain their problem and receive meaningful help from an expert. To facilitate this type of interaction, we developed MicroMentor, an on-demand help system that connects users via video chat for 3-minute help sessions. MicroMentor automatically attaches relevant supplementary materials and uses contextual information, such as command history and expertise, to encourage the most qualified users to accept incoming requests. These help sessions are recorded and archived, building a bank of knowledge that can further help a broader audience. Through a user study, we find MicroMentor to be useful and successful in connecting users for short teaching moments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {quick help, one-on-one help, software learning, mentoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376707,
author = {Schneegass, Christina and Kosch, Thomas and Baumann, Andrea and Rusu, Marius and Hassib, Mariam and Hussmann, Heinrich},
title = {BrainCoDe: Electroencephalography-Based Comprehension Detection during Reading and Listening},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376707},
doi = {10.1145/3313831.3376707},
abstract = {The pervasive availability of media in foreign languages is a rich resource for language learning. However, learners are forced to interrupt media consumption whenever comprehension problems occur. We present BrainCoDe, a method to implicitly detect vocabulary gaps through the evaluation of event-related potentials (ERPs). In a user study (N=16), we evaluate BrainCoDe by investigating differences in ERP amplitudes during listening and reading of known words compared to unknown words. We found significant deviations in N400 amplitudes during reading and in N100 amplitudes during listening when encountering unknown words. To evaluate the feasibility of ERPs for real-time applications, we trained a classifier that detects vocabulary gaps with an accuracy of 87.13% for reading and 82.64% for listening, identifying eight out of ten words correctly as known or unknown. We show the potential of BrainCoDe to support media learning through instant translations or by generating personalized learning content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {EEG, implicit comprehension detection, language learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376329,
author = {Wong-Villacres, Marisol and DiSalvo, Carl and Kumar, Neha and DiSalvo, Betsy},
title = {Culture in Action: Unpacking Capacities to Inform Assets-Based Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376329},
doi = {10.1145/3313831.3376329},
abstract = {The field of Human-Computer Interaction (HCI) aims at securing a lasting impact for technology-based interventions in the context of social inequities. Increasingly, HCI scholars are proposing assets-based design as an effective approach towards this issue. Rather than starting from people's needs and deficits, this approach posits that design should start from a deep understanding of people's assets. A pending issue, however, is how to account for the situated nature of assets; that is, how to decide which asset to leverage and for what design purpose. Drawing from cultural sociology and shifting the emphasis from assets to capacities, we propose Swidler's theory of culture-in-action as an analytical lens for unpacking the complex relationship between capacities, goals, and structural limitations. Leveraging findings from a Participatory Design engagement with 35 Latino immigrant parents for envisioning parent-education technologies, we demonstrate the applicability of this lens. We contribute to HCI scholarship by further discussing 1) how to analyze capacities' design potential, and 2) the methodological particularities for collecting them.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {culture, immigrant parents, assets-based, participatory design, capacities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376333,
author = {Zhu, Mengjia and Memar, Amirhossein H. and Gupta, Aakar and Samad, Majed and Agarwal, Priyanshu and Visell, Yon and Keller, Sean J. and Colonnese, Nicholas},
title = {PneuSleeve: In-Fabric Multimodal Actuation and Sensing in a Soft, Compact, and Expressive Haptic Sleeve},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376333},
doi = {10.1145/3313831.3376333},
abstract = {Integration of soft haptic devices into garments can improve their usability and wearability for daily computing interactions. In this paper, we introduce PneuSleeve, a fabric-based, compact, and highly expressive forearm sleeve which can render a broad range of haptic stimuli including compression, skin stretch, and vibration. The haptic stimuli are generated by controlling pneumatic pressure inside embroidered stretchable tubes. The actuation configuration includes two compression actuators on the proximal and distal forearm, and four uniformly distributed linear actuators around and tangent to the forearm. Further, to ensure a suitable grip force, two soft mutual capacitance sensors are fabricated and integrated into the compression actuators, and a closed-loop force controller is implemented. We physically characterize the static and dynamic behavior of the actuators, as well as the performance of closed-loop control. We quantitatively evaluate the psychophysical characteristics of the six actuators in a set of user studies. Finally, we show the expressiveness of PneuSleeve by evaluating combined haptic stimuli using subjective assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {multimodal haptic display, vibration, closed-loop haptic rendering, compression, wearables, pneumatic actuation, haptics, skin stretch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376348,
author = {Romat, Hugo and Henry Riche, Nathalie and Hurter, Christophe and Drucker, Steven and Amini, Fereshteh and Hinckley, Ken},
title = {Dear Pictograph: Investigating the Role of Personalization and Immersion for Consuming and Enjoying Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376348},
doi = {10.1145/3313831.3376348},
abstract = {Much of the visualization literature focuses on assessment of visual representations with regard to their effectiveness for understanding data. In the present work, we instead focus on making data visualization experiences more enjoyable, to foster deeper engagement with data. We investigate two strategies to make visualization experiences more enjoyable and engaging: personalization, and immersion. We selected pictographs (composed of multiple data glyphs) as this representation affords creative freedom, allowing people to craft symbolic or whimsical shapes of personal significance to represent data. We present the results of a qualitative study with 12 participants crafting pictographs using a large pen-enabled device and while immersed within a VR environment. Our results indicate that personalization and immersion both have positive impact on making visualizations more enjoyable experiences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {immersion, personalization, visualization, qualitative study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376234,
author = {Park, Keunwoo and Kim, Daehwa and Heo, Seongkook and Lee, Geehyuk},
title = {MagTouch: Robust Finger Identification for a Smartwatch Using a Magnet Ring and a Built-in Magnetometer},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376234},
doi = {10.1145/3313831.3376234},
abstract = {Completing tasks on smartwatches often requires multiple gestures due to the small size of the touchscreens and the lack of sufficient number of touch controls that are easily accessible with a finger. We propose to increase the number of functions that can be triggered with the touch gesture by enabling a smartwatch to identify which finger is being used. We developed MagTouch, a method that uses a magnetometer embedded in an off-the-shelf smartwatch. It measures the magnetic field of a magnet fixed to a ring worn on the middle finger. By combining the measured magnetic field and the touch location on the screen, MagTouch recognizes which finger is being used. The tests demonstrated that MagTouch can differentiate among the three fingers used to make contacts at a success rate of 95.03%.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {magnetic, smartwatch, finger identification, touch},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376395,
author = {Seifi, Hasti and Oppermann, Michael and Bullard, Julia and MacLean, Karon E. and Kuchenbecker, Katherine J.},
title = {Capturing Experts' Mental Models to Organize a Collection of Haptic Devices: Affordances Outweigh Attributes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376395},
doi = {10.1145/3313831.3376395},
abstract = {Humans rely on categories to mentally organize and understand sets of complex objects. One such set, haptic devices, has myriad technical attributes that affect user experience in complex ways. Seeking an effective navigation structure for a large online collection, we elicited expert mental categories for grounded force-feedback haptic devices: 18 experts (9 device creators, 9 interaction designers) reviewed, grouped, and described 75 devices according to their similarity in a custom card-sorting study. From the resulting quantitative and qualitative data, we identify prominent patterns of tagging versus binning, and we report 6 uber-attributes that the experts used to group the devices, favoring affordances over device specifications. Finally, we derive 7 device categories and 9 subcategories that reflect the imperfect yet semantic nature of the expert mental models. We visualize these device categories and similarities in the online haptic collection, and we offer insights for studying expert understanding of other human-centered technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {information visualization, mental model, haptic hardware collection, expert-sourced categorization, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376311,
author = {Luria, Michal and Zheng, Rebecca and Huffman, Bennett and Huang, Shuangni and Zimmerman, John and Forlizzi, Jodi},
title = {Social Boundaries for Personal Agents in the Interpersonal Space of the Home},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376311},
doi = {10.1145/3313831.3376311},
abstract = {The presence of voice activated personal assistants (VAPAs) in people's homes rises each year [31]. Industry efforts are invested in making interactions with VAPAs more personal by leveraging information from messages and calendars, and by accessing user accounts for 3rd party services. However, the use of personal data becomes more complicated in interpersonal spaces, such as people's homes. Should a shared agent access the information of many users? If it does, how should it navigate issues of privacy and control? Designers currently lack guidelines to help them design appropriate agent behaviors. We used Speed Dating to explore inchoate social mores around agent actions within a home, including issues of proactivity, interpersonal conflict, and agent prevarication. Findings offer new insights on how more socially sophisticated agents might sense, make judgements about, and navigate social roles and individuals. We discuss how our findings might impact future research and future agent behaviors.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social robots, embodied agents, voice activated personal assistants, interaction design, conversational agents, speed dating},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376350,
author = {Pe\~{n}a-Araya, Vanessa and Bezerianos, Anastasia and Pietriga, Emmanuel},
title = {A Comparison of Geographical Propagation Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376350},
doi = {10.1145/3313831.3376350},
abstract = {Geographical propagation phenomena occur in multiple domains, such as in epidemiology and social media. Propagation dynamics are often complex, and visualizations play a key role in helping subject-matter experts understand and analyze them. However, there is little empirical data about the effectiveness of the various strategies used to visualize geographical propagation. To fill this gap, we conduct an experiment to evaluate the effectiveness of three strategies: an animated map, small-multiple maps, and a single map with glyphs. We compare them under five tasks that vary in one of the following dimensions: propagation scope, direction, speed, peaks, and spatial jumps. Our results show that small-multiple maps perform best overall, but that the effectiveness of each visualization varies depending on the task considered.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {propagation, small-multiples, animation, geo-temporal data},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376739,
author = {Louie, Ryan and Coenen, Andy and Huang, Cheng Zhi and Terry, Michael and Cai, Carrie J.},
title = {Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376739},
doi = {10.1145/3313831.3376739},
abstract = {While generative deep neural networks (DNNs) have demonstrated their capacity for creating novel musical compositions, less attention has been paid to the challenges and potential of co-creating with these musical AIs, especially for novices. In a needfinding study with a widely used, interactive musical AI, we found that the AI can overwhelm users with the amount of musical content it generates, and frustrate them with its non-deterministic output. To better match co-creation needs, we developed AI-steering tools, consisting of Voice Lanes that restrict content generation to particular voices; Example-Based Sliders to control the similarity of generated content to an existing example; Semantic Sliders to nudge music generation in high-level directions (happy/sad, conventional/surprising); and Multiple Alternatives of generated content to audition and choose from. In a summative study (N=21), we discovered the tools not only increased users' trust, control, comprehension, and sense of collaboration with the AI, but also contributed to a greater sense of self-efficacy and ownership of the composition relative to the AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {generative deep neural networks, co-creation, human-ai interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376415,
author = {Hanson, Julia and Wei, Miranda and Veys, Sophie and Kugler, Matthew and Strahilevitz, Lior and Ur, Blase},
title = {Taking Data Out of Context to Hyper-Personalize Ads: Crowdworkers' Privacy Perceptions and Decisions to Disclose Private Information},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376415},
doi = {10.1145/3313831.3376415},
abstract = {Data brokers and advertisers increasingly collect data in one context and use it in another. When users encounter a misuse of their data, do they subsequently disclose less information? We report on human-subjects experiments with 25 in-person and 280 online participants. First, participants provided personal information amidst distractor questions. A week later, while participants completed another survey, they received either a robotext or online banner ad seemingly unrelated to the study. Half of the participants received an ad containing their name, partner's name, preferred cuisine, and location; others received a generic ad. We measured how many of 43 potentially invasive questions participants subsequently chose to answer. Participants reacted negatively to the personalized ad, yet answered nearly all invasive questions accurately. We unpack our results relative to the privacy paradox, contextual integrity, and power dynamics in crowdworker platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user study, hyper-personalization, creepy, targeted advertising},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376577,
author = {Houben, Maarten and Brankaert, Rens and Bakker, Saskia and Kenning, Gail and Bongers, Inge and Eggen, Berry},
title = {The Role of Everyday Sounds in Advanced Dementia Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376577},
doi = {10.1145/3313831.3376577},
abstract = {The representation of sounds derived from everyday life can be beneficial for people with dementia by evoking memories and emotional responses. Despite this potential, integrating sound and sound-based interventions in care facilities has not received much research attention. In this paper, we present the findings from a field study that explored the responses of 19 people with advanced dementia to a selection of everyday sounds presented to them in a care home and the role of these responses in the care environment. To study this, we deployed Vita, a 'pillow-like' sound player, in two dementia care facilities for four weeks, during which observations were recorded. Afterwards, we conducted interviews with caregivers who used Vita in everyday care practice. Our findings reveal how everyday sounds provided by Vita stimulated meaningful conversation, playfulness, and connection between residents and caregivers. Furthermore, we propose design implications for integrating everyday sounds in dementia care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {soundscapes, design, everyday sounds, care home, dementia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376210,
author = {V\"{o}lkel, Sarah Theres and Sch\"{o}del, Ramona and Buschek, Daniel and Stachl, Clemens and Winterhalter, Verena and B\"{u}hner, Markus and Hussmann, Heinrich},
title = {Developing a Personality Model for Speech-Based Conversational Agents Using the Psycholexical Approach},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376210},
doi = {10.1145/3313831.3376210},
abstract = {We present the first systematic analysis of personality dimensions developed specifically to describe the personality of speech-based conversational agents. Following the psycholexical approach from psychology, we first report on a new multi-method approach to collect potentially descriptive adjectives from 1) a free description task in an online survey (228 unique descriptors), 2) an interaction task in the lab (176 unique descriptors), and 3) a text analysis of 30,000 online reviews of conversational agents (Alexa, Google Assistant, Cortana) (383 unique descriptors). We aggregate the results into a set of 349 adjectives, which are then rated by 744 people in an online survey. A factor analysis reveals that the commonly used Big Five model for human personality does not adequately describe agent personality. As an initial step to developing a personality model, we propose alternative dimensions and discuss implications for the design of agent personalities, personality-aware personalisation, and future research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {conversational agents, big 5, personality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376802,
author = {Monastero, Beatrice and McGookin, David and Takala, Tapio},
title = {"I Just Leaned on It!" Exploring Opportunistic Social Discovery of a Technologically Augmented Cushion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376802},
doi = {10.1145/3313831.3376802},
abstract = {While personal devices are often used to connect online with others far away, public media rarely offers opportunities to connect with collocated individuals. We explore novel interaction strategies to enhance opportunistic collocated sociality through technologically augmented daily objects. ThinkCushion is an augmented cushion allowing users to record and playback audio messages either explicitly or implicitly by leaning on it. We deployed ThinkCushion in an open coworking space and gathered quantitative and qualitative data over one month to unveil how individuals discovered it and interacted. We individuate three modes of discovery (serendipitous, spectated and facilitated) and their relations with situated socio-spatial aspects. We discuss the interplay of active and passive interaction modalities for locally accessing and creating content, and how verbal content can be used in either performative or informative ways. We suggest future research on how to design public technologies supporting collocated sociality already from the phase of technological discovery.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sociality, embedded systems, opportunistic interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376303,
author = {Strandholt, Patrick L. and Dogaru, Oana A. and Nilsson, Niels C. and Nordahl, Rolf and Serafin, Stefania},
title = {Knock on Wood: Combining Redirected Touching and Physical Props for Tool-Based Interaction in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376303},
doi = {10.1145/3313831.3376303},
abstract = {When physical props serve as proxies for virtual tools used to manipulate the virtual environment, it is challenging to provide appropriate haptic feedback. Redirected tool-mediated manipulation addresses this challenge by distorting the mapping between physical and virtual tools to provide a sensation of manipulating the virtual environment, when the physical tool comes into contact with another physical prop. For example, a virtual hammer's position can be offset to ensure that physical impacts accompany each strike of a virtual nail. We demonstrate the idea by showing that it can be used to create sensations of impact and resistance when driving a virtual nail into a surface, when tightening a virtual screw, and when sawing through a virtual plank. The results of a user study indicate that the proposed approach is perceived as more realistic than interaction with a single physical prop or controller and no notable detriments to precision were observed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {passive haptics, redirected touching, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376301,
author = {Yang, Qian and Steinfeld, Aaron and Ros\'{e}, Carolyn and Zimmerman, John},
title = {Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376301},
doi = {10.1145/3313831.3376301},
abstract = {Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {prototyping, sketching, artificial intelligence, user experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376578,
author = {Voelker, Simon and Hueber, Sebastian and Holz, Christian and Remy, Christian and Marquardt, Nicolai},
title = {GazeConduits: Calibration-Free Cross-Device Collaboration through Gaze and Touch},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376578},
doi = {10.1145/3313831.3376578},
abstract = {We present GazeConduits, a calibration-free ad-hoc mobile interaction concept that enables users to collaboratively interact with tablets, other users, and content in a cross-device setting using gaze and touch input. GazeConduits leverages recently introduced smartphone capabilities to detect facial features and estimate users' gaze directions. To join a collaborative setting, users place one or more tablets onto a shared table and position their phone in the center, which then tracks users present as well as their gaze direction to determine the tablets they look at. We present a series of techniques using GazeConduits for collaborative interaction across mobile devices for content selection and manipulation. Our evaluation with 20 simultaneous tablets on a table shows that GazeConduits can reliably identify which tablet or collaborator a user is looking at.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {gaze input, cross-device interaction, touch input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376875,
author = {Wu, Jason and Harrison, Chris and Bigham, Jeffrey P. and Laput, Gierad},
title = {Automated Class Discovery and One-Shot Interactions for Acoustic Activity Recognition},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376875},
doi = {10.1145/3313831.3376875},
abstract = {Acoustic activity recognition has emerged as a foundational element for imbuing devices with context-driven capabilities, enabling richer, more assistive, and more accommodating computational experiences. Traditional approaches rely either on custom models trained in situ, or general models pre-trained on preexisting data, with each approach having accuracy and user burden implications. We present Listen Learner, a technique for activity recognition that gradually learns events specific to a deployed environment while minimizing user burden. Specifically, we built an end-to-end system for self-supervised learning of events labelled through one-shot interaction. We describe and quantify system performance 1) on preexisting audio datasets, 2) on real-world datasets we collected, and 3) through user studies which uncovered system behaviors suitable for this new type of interaction. Our results show that our system can accurately and automatically learn acoustic events across environments (e.g., 97% precision, 87% recall), while adhering to users' preferences for non-intrusive interactive behavior.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {acoustic activity recognition, automatic class discovery},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376675,
author = {Kraus, Matthias and Angerbauer, Katrin and Buchm\"{u}ller, Juri and Schweitzer, Daniel and Keim, Daniel A. and Sedlmair, Michael and Fuchs, Johannes},
title = {Assessing 2D and 3D Heatmaps for Comparative Analysis: An Empirical Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376675},
doi = {10.1145/3313831.3376675},
abstract = {Heatmaps are a popular visualization technique that encode 2D density distributions using color or brightness. Experimental studies have shown though that both of these visual variables are inaccurate when reading and comparing numeric data values. A potential remedy might be to use 3D heatmaps by introducing height as a third dimension to encode the data. Encoding abstract data in 3D, however, poses many problems, too. To better understand this tradeoff, we conducted an empirical study (N=48) to evaluate the user performance of 2D and 3D heatmaps for comparative analysis tasks. We test our conditions on a conventional 2D screen, but also in a virtual reality environment to allow for real stereoscopic vision. Our main results show that 3D heatmaps are superior in terms of error rate when reading and comparing single data items. However, for overview tasks, the well-established 2D heatmap performs better.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {heatmaps, virtual reality, visual analytics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376252,
author = {Kang, Seokbin and Shokeen, Ekta and Byrne, Virginia L. and Norooz, Leyla and Bonsignore, Elizabeth and Williams-Pierce, Caro and Froehlich, Jon E.},
title = {ARMath: Augmenting Everyday Life with Math Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376252},
doi = {10.1145/3313831.3376252},
abstract = {We introduce ARMath, a mobile Augmented Reality (AR) system that allows ch ildren to discover mathematical concepts in familiar, ord inary objects and engage with math problems in meaningful contexts. Leveraging advanced computer vision, ARMath recognizes everyday objects, visualizes their mathematical attributes, and turns them into tangible or virtual manipulatives. Using the manipulatives, children can solve problems that situate math operations or concepts in specific everyday contexts. Informed by four participatory design sessions with teachers and children, we developed five ARMath modules to support basic arithmetic and 2D geometry. We also conducted an exploratory evaluation of ARMath with 27 children (ages 5-8) at a local children's museum. Our findings demonstrate how ARMath engages children in math learning, how failures in AI can be used as learning opportunities, and challenges that children face when using ARMath.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {human-ai interaction, learning, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376450,
author = {Park, Sunjeong and Lim, Youn-kyung},
title = {Investigating User Expectations on the Roles of Family-Shared AI Speakers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376450},
doi = {10.1145/3313831.3376450},
abstract = {AI assistants that use a voice user interface (VUI), such as AI speakers, have become popular in family homes. However, it is still unclear what roles the AI speaker can support within the family unit. We investigated the roles of an AI speaker as a family-shared technology. By conducting a one-week participatory user study, we discovered that family members' co-ownership toward the AI speaker was the key in the development of its family-oriented roles. Our findings showed seven domains of user expectations on these roles, and we realized that all the expectations can be represented as family cohesion. In addition, privacy awareness was emphasized regarding personal supports. Finally, we discuss a new perspective for AI speaker design and offer two suggestions: 1) leveraging human-likeness to develop its potential roles of supporting the unit of a family and 2) interpreting the home context to seamlessly connect family and personal supporting roles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {AI speaker, participatory design study, family},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376712,
author = {Arimatsu, Kazuyuki and Mori, Hideki},
title = {Evaluation of Machine Learning Techniques for Hand Pose Estimation on Handheld Device with Proximity Sensor},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376712},
doi = {10.1145/3313831.3376712},
abstract = {Tracking finger movement for natural interaction using hand is commonly studied. For vision-based implementations of finger tracking in virtual reality (VR) application, finger movement is occluded by a handheld device which is necessary for auxiliary input, thus tracking finger movement using cameras is still challenging. Finger tracking controllers using capacitive proximity sensors on the surface are starting to appear. However, research on estimating articulated hand pose from curved capacitance sensing electrodes is still immature. Therefore, we built a prototype with 62 electrodes and recorded training datasets using an optical tracking system. We have introduced 2.5D representation to apply convolutional neural network methods on a capacitive image of the curved surface, and two types of network architectures based on recent achievements in the computer vision field were evaluated with our dataset. We also implemented real-time interactive applications using the prototype and demonstrated the possibility of intuitive interaction using fingers in VR applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hand pose estimation, finger tracking controller, virtual reality, capacitive image, human computer interactiton},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376602,
author = {Miniukovich, Aliaksei and Marchese, Maurizio},
title = {Relationship Between Visual Complexity and Aesthetics of Webpages},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376602},
doi = {10.1145/3313831.3376602},
abstract = {Substantial HCI research investigated the relationship between webpage complexity and aesthetics, but without a definitive conclusion. Some research showed an inverse linear correlation, some other showed an inverted u-shaped curve, while the rest showed no relationship at all. Such a lack of clarity complicates hypothesis formulation and result interpretation for future research, and lowers the reliability and generalizability of potential advice for Web design practice. We re-collected complexity and aesthetics ratings for five datasets previously used in webpage aesthetics and complexity research. The results were mixed, but suggested an inverse linear relationship with a weaker u-shaped sub-component. A subsequent visual inspection of revealed several confounding factors that may have led to the mixed results, including some webpages looking broken or archaic. The second data collection showed that accounting for these factors generally eliminates the u-shaped tendency of the complexity-aesthetics relationship, at least, for a relatively homogeneous sample of English-speaking participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {web design, user study, visual aesthetics, quantitative analyses, graphical user interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376463,
author = {Spagnolli, Anna and Mora, Diletta and Fanchin, Matteo and Orso, Valeria and Gamberini, Luciano},
title = {Automation and Creativity: A Case Study of DJs' and VJs' Ambivalent Positions on Automated Visual Software},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376463},
doi = {10.1145/3313831.3376463},
abstract = {Computerized solutions in the domain of creativity and expressive performance increasingly provide art and artists with exciting new opportunities. However, the combination of automation and creativity also raises controversies and resistance in some user groups. This paper considers the case of software-generated visuals in live music performance and tries to make sense of the ambivalent response given by its intended users (i.e., DJs and VJs). We carried out seven face-to-face interviews, an online survey (N = 102) and 25 interviews at a distance to unravel DJs' and VJs' positions on automated visual software. Four core controversies were eventually identified, gravitating around the implications of using such software on DJs' and VJs' identities as artists and on their competitive advantage in their activity sector. The conclusions reconnect these findings with the larger issue of understanding the users' responses to automation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {ambivalence, live music performance, acceptance, creativity, automation, argumentation, visual software},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376685,
author = {Slegers, Karin and Kouwenberg, Kristel and Lou\v{c}ova, Tereza and Daniels, Ramon},
title = {Makers in Healthcare: The Role of Occupational Therapists in the Design of DIY Assistive Technology},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376685},
doi = {10.1145/3313831.3376685},
abstract = {Advancements in personal fabrication technologies (e.g. 3D printing) resulted in a rising interest in 'do-it-yourself assistive technology' (DIY AT). Clinical knowledge is considered fundamental for DIY AT design, but research into making DIY AT by clinicians is limited. In this paper, we explore occupational therapists' attitudes towards 3D printing both before and after gaining hands-on experience with 3D modelling software. In addition, as clinicians indicate to prefer collaborations with experienced designers, we organized a codesign study with occupational therapists and professional designers to conceptualize a feasible collaborative DIY-AT design process. The results of our studies show an overall enthusiasm of occupational therapists towards 3D printing, but the perceived impact of 3D printing on their job performance decreased after gaining hands-on experience. Collaborating with designers seems a viable way forward. We propose a model for a collaborative design process, highlighting different phases and the roles that occupational therapists and designers play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {3D printing, digital fabrication, occupational therapy, DIY assistive technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376317,
author = {Kumar, Chandan and Hedeshy, Ramin and MacKenzie, I. Scott and Staab, Steffen},
title = {TAGSwipe: Touch Assisted Gaze Swipe for Text Entry},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376317},
doi = {10.1145/3313831.3376317},
abstract = {The conventional dwell-based methods for text entry by gaze are typically slow and uncomfortable. A swipe-based method that maps gaze path into words offers an alternative. However, it requires the user to explicitly indicate the beginning and ending of a word, which is typically achieved by tedious gaze-only selection. This paper introduces TAGSwipe, a bi-modal method that combines the simplicity of touch with the speed of gaze for swiping through a word. The result is an efficient and comfortable dwell-free text entry method. In the lab study TAGSwipe achieved an average text entry rate of 15.46 wpm and significantly outperformed conventional swipe-based and dwell-based methods in efficacy and user satisfaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {swipe, eye tracking, dwell-free typing, word-level text entry, multimodal interaction, touch input, eye typing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376726,
author = {Wang, Xingbo and Zeng, Haipeng and Wang, Yong and Wu, Aoyu and Sun, Zhida and Ma, Xiaojuan and Qu, Huamin},
title = {VoiceCoach: Interactive Evidence-Based Training for Voice Modulation Skills in Public Speaking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376726},
doi = {10.1145/3313831.3376726},
abstract = {The modulation of voice properties, such as pitch, volume, and speed, is crucial for delivering a successful public speech. However, it is challenging to master different voice modulation skills. Though many guidelines are available, they are often not practical enough to be applied in different public speaking situations, especially for novice speakers. We present VoiceCoach, an interactive evidence-based approach to facilitate the effective training of voice modulation skills. Specifically, we have analyzed the voice modulation skills from 2623 high-quality speeches (i.e., TED Talks) and use them as the benchmark dataset. Given a voice input, VoiceCoach automatically recommends good voice modulation examples from the dataset based on the similarity of both sentence structures and voice modulation skills. Immediate and quantitative visual feedback is provided to guide further improvement. The expert interviews and the user study provide support for the effectiveness and usability of VoiceCoach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {voice modulation, data visualization, evidence-based training, public speaking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376254,
author = {Jardine, Jacinta and Earley, Caroline and Richards, Derek and Timulak, Ladislav and Palacios, Jorge E. and Duffy, Daniel and Tierney, Karen and Doherty, Gavin},
title = {The Experience of Guided Online Therapy: A Longitudinal, Qualitative Analysis of Client Feedback in a Naturalistic RCT},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376254},
doi = {10.1145/3313831.3376254},
abstract = {Internet-delivered Cognitive Behavioural Therapy (iCBT) is an effective treatment for depression and anxiety disorders. However longitudinal qualitative research into the client's subjective experience of this form of treatment ?in the wild' is relatively scarce. We present an analysis of secondary outcomes in a naturalistic RCT conducted within the UK's Improving Access to Psychological Therapies programme. We evaluated clients' expectations, experience, and context of usage of iCBT, across three timepoints. Results are discussed in terms of the creation of a therapeutic space online, the impact of hope, expectations and personal factors on the therapeutic experience, iCBT as "therapy on the go" and developing skills for life. While iCBT on the whole provides a positive, supportive and therapeutic experience for clients, the study identified managing expectations, polarized preferences, momentary help-seeking and long-term support as important aspects of the experience to consider in future design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {user experience, icbt, longitudinal study, mental health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376666,
author = {Masaki, Hiroaki and Shibata, Kengo and Hoshino, Shui and Ishihama, Takahiro and Saito, Nagayuki and Yatani, Koji},
title = {Exploring Nudge Designs to Help Adolescent SNS Users Avoid Privacy and Safety Threats},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376666},
doi = {10.1145/3313831.3376666},
abstract = {A nudge is a method to influence individual choices without taking away freedom of choice. We are interested in whether nudges can help adolescents avoid privacy and safety threats on social network services (SNS). We conducted an online survey to compare how 11 different nudge designs influence decisions on 9 scenarios featuring various privacy and safety threats. We collected 29,608 responses from adolescent SNS users (self-claimed high school and university students), and found that nudges can help to educe potentially risk choices. Participants were more likely to avoid potentially risky choices when presented with negative frames (e.g., "90% of users would not share a photo without permission'') than affirmative ones (e.g., "10% of users would''). Social nudges displaying statistics on how likely other people would make potentially risky decisions can have a negative effect in comparison to a nudge with only general privacy and safety suggestions. We conclude by providing design considerations for privacy/safety nudges targeting adolescent SNS users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {large-scale survey, social nudges, online privacy and safety, adolescent sns users},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376484,
author = {Faas, Stefanie M. and Kao, Andrea C. and Baumann, Martin},
title = {A Longitudinal Video Study on Communicating Status and Intent for Self-Driving Vehicle – Pedestrian Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376484},
doi = {10.1145/3313831.3376484},
abstract = {With self-driving vehicles (SDVs), pedestrians cannot rely on communication with the driver anymore. Industry experts and policymakers are proposing an external Human-Machine Interface (eHMI) communicating the automated status. We investigated whether additionally communicating SDVs' intent to give right of way further improves pedestrians' street crossing. To evaluate the stability of these eHMI effects, we conducted a three-session video study with N=34 pedestrians where we assessed subjective evaluations and crossing onset times. This is the first work capturing long-term effects of eHMIs. Our findings add credibility to prior studies by showing that eHMI effects last (acceptance, user experience) or even increase (crossing onset, perceived safety, trust, learnability, reliance) with time. We found that pedestrians benefit from an eHMI communicating SDVs' status, and that additionally communicating SDVs' intent adds further value. We conclude that SDVs should be equipped with an eHMI communicating both status and intent.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {intent, pedestrians, self-driving vehicles, status, external human-machine interface, information need},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376542,
author = {Rho, Eugenia Ha Rim and Mazmanian, Melissa},
title = {Political Hashtags &amp; the Lost Art of Democratic Discourse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376542},
doi = {10.1145/3313831.3376542},
abstract = {In this work, we investigate whether and how the presence of political hashtags in social media news articles influences the way people discuss news content. Specifically, we examine how political hashtags in news posts act as a design characteristic that affects the quality of online discourse. We use a randomized control experiment to assess how the presence versus absence of political hashtags (particularly the most prevalently used #MeToo and #BlackLivesMatter) in social media news posts shapes discourse across a general audience (n=3205). Key findings show differences in topical focus, emotional tone of discourse, and rhetorical styles between commenters who were shown news posts with political hashtags versus those shown news posts without the hashtags. Compared to the control group, those shown hashtagged news posts heavily focus on the politics of the hashtag, use more words associated with fear, anger, and disgust in their comments, and exhibit black-and-white rhetoric and less emotionally temperate expressions in their arguments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {civil discourse, control experiment, digital journalism, online social movements, political hashtags, social media news},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376888,
author = {Wu, Qin and Yu, Chenmei and Chen, Yanjun and Yao, Jiayu and Wu, Xi and Peng, Xiaolan and Han, Teng},
title = {Squeeze the Ball: Designing an Interactive Playground towards Aiding Social Activities of Children with Low-Function Autism},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376888},
doi = {10.1145/3313831.3376888},
abstract = {Most intervention methods used for social skills training in children with autism are dedicated to high-functioning autism (HFA). However, extensive neurological and developmental disorders of low-functioning autism (LFA) have hampered their adoption. In this study, we observed and interviewed children with LFA, and their teachers, from a local educational institution, to better understand the children's social needs and barriers. Then, with the aim of aiding the children with their social activities, we illustrate the design process of SqueeBall, an interactive playground equipment. We evaluated the design with 18 children (16 with LFA and 2 with HFA) between 2.5 and 7 years of age. Results showed that these children had a pleasant game experience when the group bonded, and the equipment had a positive effect on aiding them in various ways. Finally, we discuss the challenges and opportunities of multimedia interaction techniques in aiding children with LFA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {autism, tangible interaction, social communication intervention, low-function autism, disability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376396,
author = {Kruzan, Kaylee Payne and Whitlock, Janis and Bazarova, Natalya N. and Miller, Katherine D. and Chapman, Julia and Won, Andrea Stevenson},
title = {Supporting Self-Injury Recovery: The Potential for Virtual Reality Intervention},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376396},
doi = {10.1145/3313831.3376396},
abstract = {In this paper, we explore the use of virtual reality (VR) in assisting individuals who self-injure. Past work on self-injury in HCI has focused almost exclusively on mobile applications and message boards. As VR systems become more common, it is worth exploring what unique affordances of the technology can be leveraged to support self-injury reduction and cessation. Research on VR intervention and self-injury treatment informed the design of three novel virtual reality experiences. Nineteen interviews were conducted with individuals with current, or a past history of, self-injury with the goals of uncovering overall impressions of the perceived efficacy of VR with this population, as well as better understanding key mechanisms which impact their experience. Our analysis reveals four key elements common across all experiences: transportation, embodiment, immersion/distraction, and sense of control, and additional themes within each unique experience. We discuss the implications of these findings for future intervention design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, intervention, self-injury},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376199,
author = {Klamka, Konstantin and Horak, Tom and Dachselt, Raimund},
title = {Watch+Strap: Extending Smartwatches with Interactive StrapDisplays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376199},
doi = {10.1145/3313831.3376199},
abstract = {While smartwatches are widely adopted these days, their input and output space remains fairly limited by their screen size. We present StrapDisplays-interactive watchbands with embedded display and touch technologies-that enhance commodity watches and extend their input and output capabilities. After introducing the physical design space of these StrapDisplays, we explore how to combine a smartwatch and straps in a synergistic Watch+Strap system. Specifically, we propose multiple interface concepts that consider promising content distributions, interaction techniques, usage types, and display roles. For example, the straps can enrich watch apps, display visualizations, provide glanceable feedback, or help avoiding occlusion issues. Further, we provide a modular research platform incorporating three StrapDisplay prototypes and a flexible web-based software architecture, demonstrating the feasibility of our approach. Early brainstorming sessions with 15 participants informed our design process, while later interviews with six experts supported our concepts and provided valuable feedback for future developments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {smartwatch, mobile visualization, interactive watchband, flexible displays, mobile interaction, wearable device, mde},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376500,
author = {Chidziwisano, George Hope and Wyche, Susan and Oduor, Erick},
title = {GridAlert: Using a Sensor-Based Technology to Monitor Power Blackouts in Kenyan Homes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376500},
doi = {10.1145/3313831.3376500},
abstract = {Power blackouts (outages) are a common occurrence in Kenyan households. They affect people's livelihoods, and damage their property (household electrical items). We explore the role of GridAlert-a sensor-based technology we designed-in monitoring power blackouts. We worked with local technicians to design GridAlert's housing and integrate GridAlert with Kenya's electricity infrastructure. Then, we used interview, observation, diary, and data logging methods to understand 18 households' experiences using the system. Our findings provide insights for using sensor-based technology to monitor power usage and blackouts in Kenyan households. We also present participants' thoughts about GridAlert's housing, and about how it influenced their actions when using the system. We use these findings to discuss design insights for power monitoring systems, and to offer new perspectives on the role of technology in monitoring blackouts in Kenyan households.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {electricity, kenya, monitoring, sensors, domestic technology, blackouts, hardware},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376231,
author = {Jung, Heekyoung},
title = {In Search of Forms for Evocative and Generative Reflection: Exploratory Studies and a Design Proposal},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376231},
doi = {10.1145/3313831.3376231},
abstract = {Today an increasing number of personal informatics tools and platforms support intended behavior change and goal achievement through data-based self-reflection. The scope of self-reflection expands with emerging sources, goals, and challenges of human well-being, demanding for reframing recent computer-mediated reflective practice. This study investigates a broader range of contexts and forms of self-reflection that support navigating one's mind and goals beyond achieving preset goals. This paper describes contemporary issues on human well-being and two exploratory studies-one conducted in a traveling artists' residency and the other in a design studio class-which surveyed various triggers, contexts, and forms of self-reflection. By connecting the insights from the two studies, I propose evocative and generative reflection as an alternative perspective to tracking-based, goal-oriented reflection and discuss implications for the design for reflection with a focus on the creative dimension of human well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {creativity, reflective forms, reflection, well-being},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376541,
author = {Wells, Thomas and Houben, Steven},
title = {CollabAR – Investigating the Mediating Role of Mobile AR Interfaces on Co-Located Group Collaboration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376541},
doi = {10.1145/3313831.3376541},
abstract = {Mobile Augmented Reality (AR) technology is enabling new applications for different domains including architecture, education or medical work. As AR interfaces project digital data, information and models into the real world, it allows for new forms of collaborative work. However, despite the wide availability of AR applications, very little is known about how AR interfaces mediate and shape collaborative practices. This paper presents a study which examines how a mobile AR (M-AR) interface for inspecting and discovering AR models of varying complexity impacts co-located group practices. We contribute new insights into how current mobile AR interfaces impact co-located collaboration. Our results show that M-AR interfaces induce high mental load and frustration, cause a high number of context switches between devices and group discussion, and overall leads to a reduction in group interaction. We present design recommendations for future work focusing on collaborative AR interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {co-located collaboration, mobile augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376534,
author = {Schr\"{o}der, Christoph and Al Zaidawi, Sahar Mahdie Klim and Prinzler, Martin H.U. and Maneth, Sebastian and Zachmann, Gabriel},
title = {Robustness of Eye Movement Biometrics Against Varying Stimuli and Varying Trajectory Length},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376534},
doi = {10.1145/3313831.3376534},
abstract = {Recent results suggest that biometric identification based on human's eye movement characteristics can be used for authentication. In this paper, we present three new methods and benchmark them against the state-of-the-art. The best of our new methods improves the state-of-the-art performance by 5.2 percentage points. Furthermore, we investigate some of the factors that affect the robustness of the recognition rate of different classifiers on gaze trajectories, such as the type of stimulus and the tracking trajectory length. We find that the state-of-the-art method only works well when using the same stimulus for testing that was used for training. By contrast, our novel method more than doubles the identification accuracy for these transfer cases. Furthermore, we find that with only 90 seconds of eye tracking data, 86.7% accuracy can be achieved.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {eye movement biometrics, eye tracking, gaze detection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376475,
author = {Lee, Kwangyoung and Cho, Hyewon and Toshnazarov, Kobiljon and Narziev, Nematjon and Rhim, So Young and Han, Kyungsik and Noh, YoungTae and Hong, Hwajung},
title = {Toward Future-Centric Personal Informatics: Expecting Stressful Events and Preparing Personalized Interventions in Stress Management},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376475},
doi = {10.1145/3313831.3376475},
abstract = {Stress is caused by a variety of events in our daily lives. By anticipating stressful situations, we can prepare and better cope with stressors when they actually occur. However, many past-centric personal informatics (PI) tools focus on capturing events that already happened and analyzing the data. In this work, we examine how anticipation — a future-centric self-tracking practice — could be used to manage daily stress levels. To address this, we built MindForecaster, a calendar- mediated stress anticipation application that allows users to expect stressful events in advance, generates activities to mitigate stress, and evaluates actual stress levels compared to previously estimated stress levels. In a 30-day deployment with 47 users, the users who explicitly planned and executed coping interventions reported reduced stress more than those who only expected stressful events. We suggest design implications for stress management by incorporating the properties of anticipation into current PI models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {self-experimentation, intervention, coping planning, stress, future-centric personal informatics, anticipation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376458,
author = {Tachtler, Franziska and Michel, Toni and Slov\'{a}k, Petr and Fitzpatrick, Geraldine},
title = {Supporting the Supporters of Unaccompanied Migrant Youth: Designing for Social-Ecological Resilience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376458},
doi = {10.1145/3313831.3376458},
abstract = {Unaccompanied migrant youth, fleeing to a new country without their parents, are exposed to mental health risks. Resilience interventions mitigate such risks, but access can be hindered by systemic and personal barriers. While much work has recently addressed designing technology to promote mental health, none has focused on the needs of these populations. This paper presents the results of interviews with 18 professional/ volunteer support workers and 5 unaccompanied migrant youths, followed by three design workshops. The results point to the diverse systems that can facilitate youths' resilience development. The relationship between the youth and volunteers acting as mentors is particularly important for increasing resilience but comes with challenges. This suggests the relevance of a social-ecological model of resilience with a focus on designing technology to support the mentors in order to help them better support the youth. We conclude by mapping out the design space for mentor support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {care, refugees, mental health technology, resilience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376440,
author = {Abu-Salma, Ruba and Livshits, Benjamin},
title = {Evaluating the End-User Experience of Private Browsing Mode},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376440},
doi = {10.1145/3313831.3376440},
abstract = {In this paper, we investigate why users of private browsing mode misunderstand the benefits and limitations of private browsing. We design and conduct a three-part study: (1) an analytic evaluation of the user interface of private mode in different browsers; (2) a qualitative user study to explore user mental models of private browsing; (3) a participatory design study to investigate why existing browser disclosures, the in-browser explanations of private mode, do not communicate the actual protection of private mode. We find the user interface of private mode in different browsers violated well-established design guidelines and heuristics. Further, most participants had incorrect mental models of private browsing, influencing their understanding and usage of private mode. We also find existing browser disclosures did not explain the primary security goal of private mode. Drawing from the results of our study, we extract a set of recommendations to improve the design of disclosures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human-computer interaction, usable security and privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376709,
author = {Saint-Lot, Julie and Imbert, Jean-Paul and Dehais, Fr\'{e}d\'{e}ric},
title = {Red Alert: A Cognitive Countermeasure to Mitigate Attentional Tunneling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376709},
doi = {10.1145/3313831.3376709},
abstract = {Attentional tunneling, that is the inability to detect unexpected changes in the environment, has been shown to have critical consequences in air traffic control. The motivation of this study was to assess the design of a cognitive countermeasure dedicated to mitigate such failure of attention. The Red Alert cognitive countermeasure relies on a brief orange-red flash (300 ms) that masks the entire screen with a 15% opacity. Twenty-two air traffic controllers faced two demanding scenarios, with or without the cognitive countermeasure. The volunteers were not told about the Red Alert so as to assess the intuitiveness of the design without prior knowledge. Behavioral results indicated that the cognitive countermeasure reduced reaction time and improved the detection of the notification when compared to the classical operational design. Further analyses showed this effect was even stronger for half of our participants (91.7% detection rate) who intuitively understood the purpose of this design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {air traffic controller (atco), air traffic control, notification, countermeasure, attentional tunneling, interruption},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376359,
author = {Jo, Eunkyung and Toombs, Austin L. and Gray, Colin M. and Hong, Hwajung},
title = {Understanding Parenting Stress through Co-Designed Self-Trackers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376359},
doi = {10.1145/3313831.3376359},
abstract = {New parents often experience significant stress as they take on new roles and responsibilities. Stress management and mental wellbeing are two areas in which personal informatics (PI) research has gained attention, and there is an opportunity to investigate how parenting stress can be mitigated through PI practices. In this paper, we present the results of a co-designed technology probe study through which we deployed individualized self-trackers with new parents. We investigate the stress management topics new parents are interested in tracking and how — and with what goals---they engage in self-directed PI practices. Our findings indicate that PI practices can potentially enable parents to: re-discover positive aspects of their everyday lives; identify better-suited stress management strategies; and facilitate spousal communication about shared responsibilities. We discuss how self-tracking experiences for the mental wellness of parents can be better designed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {self-tracking, stress management, parenting, personal informatics, new parents, co-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376881,
author = {Stobert, Elizabeth and Barrera, David and Homier, Val\'{e}rie and Kollek, Daniel},
title = {Understanding Cybersecurity Practices in Emergency Departments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376881},
doi = {10.1145/3313831.3376881},
abstract = {Emergency departments (EDs) have unique operational requirements within hospitals. They have strong availability demands, are staffed by rotating personnel, and must provide services as quickly as possible. Modern EDs are also heavily computerized, and as such cybersecurity practices play a key role in meeting the expected operational standards. To better understand the cybersecurity challenges in EDs, we conducted a survey asking 347 ED personnel across Canada about their cybersecurity practices. The survey collected information relating to authentication and password management, use of personal devices for handling patient data, Internet connectivity on personal and hospital systems, and institutional security policies. Our results show that across multiple hospitals, deployed computer security systems fail to integrate with the requirements of staff and patients, leading to interruptions and inefficiencies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {usability, hospitals, security, medicine},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376546,
author = {Kuzminykh, Anastasia and Rintel, Sean},
title = {Classification of Functional Attention in Video Meetings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376546},
doi = {10.1145/3313831.3376546},
abstract = {Participants in video meetings have long struggled with asymmetrical attention levels, especially when participants are distributed unevenly. While technological advances offer exciting opportunities to augment remote users' attention, the phenomenological complexity of attention means that to design attention-fostering features we must first understand what aspects of it are functionally meaningful to support. In this paper, we present a functional classification of observable attention for video meetings. The classification was informed by two studies on sense-making and selectiveness of attention in work meetings. It includes categories of attention accessible for technological support, their functions in a meeting process, and meeting-related activities that correspond to these functions. This classification serves as a multi-level representation of attention and informs the design of features aiming to support remote participants' attention in video meetings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {attention, video-mediated communication, meetings, engagement, features},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376327,
author = {Lee, Chunggi and Kim, Sanghoon and Han, Dongyun and Yang, Hongjun and Park, Young-Woo and Kwon, Bum Chul and Ko, Sungahn},
title = {GUIComp: A GUI Design Assistant with Real-Time, Multi-Faceted Feedback},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376327},
doi = {10.1145/3313831.3376327},
abstract = {Users may face challenges while designing graphical user interfaces, due to a lack of relevant experience and guidance. This paper aims to investigate the issues users face during the design process, and how to resolve them. To this end, we conducted semi-structured interviews, based on which we built a GUI prototyping assistance tool called GUIComp. This tool can be connected to GUI design software as an extension, and it provides real-time, multi-faceted feedback on a user's current design. Additionally, we conducted two user studies, in which we asked participants to create mobile GUIs with or without GUIComp, and requested online workers to assess the created GUIs. The experimental results show that GUIComp facilitated iterative designs and the participants with GUIComp had better a user experience and produced more acceptable designs than those who did not use it.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gui design, design feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376392,
author = {Ogbonnaya-Ogburu, Ihudiya Finda and Smith, Angela D.R. and To, Alexandra and Toyama, Kentaro},
title = {Critical Race Theory for HCI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376392},
doi = {10.1145/3313831.3376392},
abstract = {The human-computer interaction community has made some efforts toward racial diversity, but the outcomes remain meager. We introduce critical race theory and adapt it for HCI to lay a theoretical basis for race-conscious efforts, both in research and within our community. Building on the theory's original tenets, we argue that racism is pervasive in everyday socio-technical systems; that the HCI community is prone to "interest convergence", where concessions to inclusion require benefits to those in power; and that the neoliberal underpinnings of the technology industry itself propagate racism. Critical race theory uses storytelling as a means to upend deep-seated assumptions, and we relate several personal stories to highlight ongoing problems of race in HCI. The implications: all HCI research must be attuned to issues of race; participation of underrepresented minorities must be sought in all of our activities; and as a community, we cannot become comfortable while racial disparities exist.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {theory, race, racism, critical race theory, storytelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376480,
author = {Schneider, Adrian L. Jessup and Keiver, Kathy and Pritchard Orr, Alison and Reynolds, James N. and Golubovich, Neven and Graham, T.C. Nicholas},
title = {Toward the Design of Enjoyable Games for Children with Fetal Alcohol Spectrum Disorder},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376480},
doi = {10.1145/3313831.3376480},
abstract = {Fetal Alcohol Spectrum Disorder (FASD) is a heterogeneous and complex set of disorders caused by prenatal alcohol exposure, estimated to affect 2-5% of the North American population. Deficits associated with FASD affect social skill development and executive function, including emotional regulation and impulse control. These deficits can increase the difficulty of playing digital games. While considerable research has been performed in understanding how to design games for people with neurodevelopmental disorders in general, there is little data on how to design engaging games for children with FASD. We conducted a ten-week in-school gaming trial with eleven elementary-aged children with diagnosed or suspected FASD. Participants enjoyed playing together and responded well to the in-game reward system, while some game elements caused unexpected frustration. Based on our observations, we advise that games for FASD be designed to have low cost of failure, avoid retracting options, account for taking breaks when needed, show progression in rewards, and enable cooperative play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social play, game design, fetal alcohol spectrum disorder, executive function, FASD},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376128,
author = {Andres, Josh and schraefel, m.c. and Semertzidis, Nathan and Dwivedi, Brahmi and Kulwe, Yutika C. and von Kaenel, Juerg and Mueller, Florian Floyd},
title = {Introducing Peripheral Awareness as a Neurological State for Human-Computer Integration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376128},
doi = {10.1145/3313831.3376128},
abstract = {In this work we introduce peripheral awareness as a neurological state for real-time human-computer integration, where the human is assisted by a computer to interact with the world. Changes to the field of view in peripheral awareness have been linked with quality of human performance. This instinctive narrowing of vision that occurs as a threat is perceived has implications in activities that benefit from the user having a wide field of view, such as cycling to navigate the environment. We present "Ena", a novel EEG-eBike system that draws from the user's neural activity to determine when the user is in a state of peripheral awareness to regulate engine support. A study with 20 participants revealed various themes and tactics suggesting that peripheral awareness as a neurological state is viable to align human-machine integration with internal bodily processes. Ena suggests that our work facilitates a safe and enjoyable human-computer integration experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {inbodied interaction, peripheral awareness, human-system partnership, human-computer-integration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376435,
author = {Ernala, Sindhu Kiranmai and Burke, Moira and Leavitt, Alex and Ellison, Nicole B.},
title = {How Well Do People Report Time Spent on Facebook? An Evaluation of Established Survey Questions with Recommendations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376435},
doi = {10.1145/3313831.3376435},
abstract = {Many studies examining social media use rely on self-report survey questions about how much time participants spend on social media platforms. Because they are challenging to answer accurately and susceptible to various biases, these self-reported measures are known to contain error -- although the specific contours of this error are not well understood. This paper compares data from ten self-reported Facebook use survey measures deployed in 15 countries (N = 49,934) against data from Facebook's server logs to describe factors associated with error in commonly used survey items from the literature. Self-reports were moderately correlated with actual Facebook use (r = 0.42 for the best-performing question), though participants significantly overestimated how much time they spent on Facebook and underestimated the number of times they visited. People who spent a lot of time on the platform were more likely to misreport their time, as were teens and younger adults, which is notable because of the high reliance on college-aged samples in many fields. We conclude with recommendations on the most accurate ways to collect time-spent data via surveys.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {well-being, time spent, self-reports, survey validation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376778,
author = {Lee, DoYoung and Lee, SooHwan and Oakley, Ian},
title = {Nailz: Sensing Hand Input with Touch Sensitive Nails},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376778},
doi = {10.1145/3313831.3376778},
abstract = {Touches between the fingers of an unencumbered hand represent a ready-to-use, eyes-free and expressive input space suitable for interacting with wearable devices such as smart glasses or watches. While prior work has focused on touches to the inner surface of the hand, touches to the nails, a practical site for mounting sensing hardware, have been comparatively overlooked. We extend prior implementations of single touch sensing nails to a full set of five and explore their potential for wearable input. We present design ideas and an input space of 144 touches (taps, flicks and swipes) derived from an ideation workshop. We complement this with data from two studies characterizing the subjective comfort and objective characteristics (task time, accuracy) of each touch. We conclude by synthesizing this material into a set of 29 viable nail touches, assessing their performance in a final study and illustrating how they could be used by presenting, and qualitatively evaluating, two example applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wearable, touch sensing fingernail, eyes-free, finger input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376540,
author = {Zagermann, Johannes and Pfeil, Ulrike and von Bauer, Philipp and Fink, Daniel and Reiterer, Harald},
title = {"It's in My Other Hand!" – Studying the Interplay of Interaction Techniques and Multi-Tablet Activities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376540},
doi = {10.1145/3313831.3376540},
abstract = {Cross-device interaction with tablets is a popular topic in HCI research. Recent work has shown the benefits of including multiple devices into users' workflows while various interaction techniques allow transferring content across devices. However, users are only reluctantly using multiple devices in combination. At the same time, research on cross-device interaction struggles to find a frame of reference to compare techniques or systems. In this paper, we try to address these challenges by studying the interplay of interaction techniques, device utilization, and task-specific activities in a user study with 24 participants from different but complementary angles of evaluation using an abstract task, a sensemaking task, and three interaction techniques. We found that different interaction techniques have a lower influence than expected, that work behaviors and device utilization depend on the task at hand, and that participants value specific aspects of cross-device interaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cross-device interaction, interaction techniques, evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376708,
author = {Seering, Joseph and Luria, Michal and Ye, Connie and Kaufman, Geoff and Hammer, Jessica},
title = {It Takes a Village: Integrating an Adaptive Chatbot into an Online Gaming Community},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376708},
doi = {10.1145/3313831.3376708},
abstract = {While the majority of research in chatbot design has focused on creating chatbots that engage with users one-on-one, less work has focused on the design of conversational agents for online communities. In this paper we present results from a three week test of a social chatbot in an established online community. During this study, the chatbot "grew up" from "birth" through its teenage years, engaging with community members and "learning" vocabulary from their conversations. We discuss the design of this chatbot, how users' interactions with it evolved over the course of the study, and how it impacted the community as a whole. We discuss how we addressed challenges in developing a chatbot whose vocabulary could be shaped by users, and conclude with implications for the role of machine learning in social interactions in online communities and potential future directions for design of community-based chatbots.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {chatbot, babybot, twitch, long-term study, community interaction, AI, machine learning, interaction design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376312,
author = {Sauv\'{e}, Kim and Potts, Dominic and Alexander, Jason and Houben, Steven},
title = {A Change of Perspective: How User Orientation Influences the Perception of Physicalizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376312},
doi = {10.1145/3313831.3376312},
abstract = {As physicalizations encode data in their physical 3D form, the orientation in which the user is viewing the physicalization may impact the way the information is perceived. However, this relation between user orientation and perception of physical properties is not well understood or studied. To investigate this relation, we conducted an experimental study with 20 participants who viewed 6 exemplars of physicalizations from 4 different perspectives. Our findings show that perception is directly influenced by user orientation as it affects (i) the number and type of clusters, (ii) anomalies and (iii) extreme values identified within a physicalization. Our results highlight the complexity and variability of the relation between user orientation and perception of physicalizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {physical visualization, data physicalization, user orientation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376591,
author = {Lee, Sooyeon and Reddie, Madison and Tsai, Chun-Hua and Beck, Jordan and Rosson, Mary Beth and Carroll, John M.},
title = {The Emerging Professional Practice of Remote Sighted Assistance for People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376591},
doi = {10.1145/3313831.3376591},
abstract = {People with visual impairments (PVI) must interact with a world they cannot see. Remote sighted assistance (RSA) has emerged as a conversational assistive technology. We interviewed RSA assistants ("agents") who provide assistance to PVI via a conversational prosthetic called Aira (https://aira.io/) to understand their professional practice. We identified four types of support provided: scene description, navigation, task performance, and social engagement. We discovered that RSA provides an opportunity for PVI to appropriate the system as a richer conversational/social support tool. We studied and identified patterns in how agents provide assistance and how they interact with PVI as well as the challenges and strategies associated with each context. We found that conversational interaction is highly context-dependent. We also discuss implications for design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual impairment, human powered accessibility, assistive technology, remote sighted assistance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376600,
author = {Di Geronimo, Linda and Braz, Larissa and Fregnan, Enrico and Palomba, Fabio and Bacchelli, Alberto},
title = {UI Dark Patterns and Where to Find Them: A Study on Mobile Applications and User Perception},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376600},
doi = {10.1145/3313831.3376600},
abstract = {A Dark Pattern (DP) is an interface maliciously crafted to deceive users into performing actions they did not mean to do. In this work, we analyze Dark Patterns in 240 popular mobile apps and conduct an online experiment with 589 users on how they perceive Dark Patterns in such apps. The results of the analysis show that 95% of the analyzed apps contain one or more forms of Dark Patterns and, on average, popular applications include at least seven different types of deceiving interfaces. The online experiment shows that most users do not recognize Dark Patterns, but can perform better in recognizing malicious designs if informed on the issue. We discuss the impact of our work and what measures could be applied to alleviate the issue.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ethical design, user experiments, dark patterns},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376794,
author = {Shin, Joon Gi and Kim, Doheon and So, Chaehan and Saakes, Daniel},
title = {Body Follows Eye: Unobtrusive Posture Manipulation Through a Dynamic Content Position in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376794},
doi = {10.1145/3313831.3376794},
abstract = {While virtual objects are likely to be a part of future interfaces, we lack knowledge of how the dynamic position of virtual objects influences users' posture. In this study, we investigated users' posture change following the unobtrusive and swift motions of a content window in virtual reality (VR). In two perception studies, we estimated the perception threshold on undetectable slow motions and displacement during an eye blink. In a formative study, we compared users' performance, posture change as well as subjective responses on unobtrusive, swift, and no motions. Based on the result, we designed concept applications and explored potential design space of moving virtual content for unobtrusive posture change. With our study, we discuss the interfaces that control users and the initial design guidelines of unobtrusive posture manipulation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, posture change, unobtrusive interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376626,
author = {von Willich, Julius and Schmitz, Martin and M\"{u}ller, Florian and Schmitt, Daniel and M\"{u}hlh\"{a}user, Max},
title = {Podoportation: Foot-Based Locomotion in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376626},
doi = {10.1145/3313831.3376626},
abstract = {Virtual Reality (VR) allows for infinitely large environments. However, the physical traversable space is always limited by real-world boundaries. This discrepancy between physical and virtual dimensions renders traditional locomotion methods used in real world unfeasible. To alleviate these limitations, research proposed various artificial locomotion concepts such as teleportation, treadmills, and redirected walking. However, these concepts occupy the user's hands, require complex hardware or large physical spaces. In this paper, we contribute nine VR locomotion concepts for foot-based locomotion, relying on the 3D position of the user's feet and the pressure applied to the sole as input modalities. We evaluate our concepts and compare them to state-of-the-art point &amp; teleport technique in a controlled experiment with 20 participants. The results confirm the viability of our approaches for foot-based and engaging locomotion. Further, based on the findings, we contribute a wireless hardware prototype implementation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {foot-based input, virtual reality, locomotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376496,
author = {Cockburn, Andy and Lewis, Blaine and Quinn, Philip and Gutwin, Carl},
title = {Framing Effects Influence Interface Feature Decisions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376496},
doi = {10.1145/3313831.3376496},
abstract = {Studies in psychology have shown that framing effects, where the positive or negative attributes of logically equivalent choices are emphasised, influence people's decisions. When outcomes are uncertain, framing effects also induce patterns of choice reversal, where decisions tend to be risk averse when gains are emphasised and risk seeking when losses are emphasised. Studies of these effects typically use potent framing stimuli, such as the mortality of people suffering from diseases or personal financial standing. We examine whether these effects arise in users' decisions about interface features, which typically have less visceral consequences, using a crowd-sourced study based on snap-to-grid drag-and-drop tasks (n = 842). The study examined several framing conditions: those similar to prior psychological research, and those similar to typical interaction choices (enabling/disabling features). Results indicate that attribute framing strongly influences users' decisions, that these decisions conform to patterns of risk seeking for losses, and that patterns of choice reversal occur.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {attribute framing, interface decisions, framing effects, risky choice framing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376883,
author = {Beneteau, Erin},
title = {Who Are You Asking?: Qualitative Methods for Involving AAC Users as Primary Research Participants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376883},
doi = {10.1145/3313831.3376883},
abstract = {When trying to understand people's perspectives, qualitative researchers in HCI often use methods which assume participants can easily communicate verbally. There are few dedicated resources in HCI which provide an overview of qualitative methods to effectively gather the perspectives of people who cannot easily communicate verbally; specifically, people who use Augmentative and Alternative Communication (AAC). As a result, AAC users might be excluded from studies using methods such as interviews or focus groups, even if they fit the researcher's target population. To address this problem, I review literature from both HCI and therapeutic AAC research fields to discuss methods used with AAC users. In addition, I present relevant case examples from my own qualitative research and propose a framework to guide HCI researchers on choosing appropriate methods when involving AAC users as central research participants. I also identify design opportunities for HCI researchers to innovate on the tools and methods used for qualitative research with AAC users. This paper provides an easily accessible overview of qualitative methods HCI researchers can use with AAC users as participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {qualitative research, augmentative and alternative communication, methods, hci, aac, disabilities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376394,
author = {Duchowski, Andrew T. and Krejtz, Krzysztof and Gehrer, Nina A. and Bafna, Tanya and B\ae{}kgaard, Per},
title = {The Low/High Index of Pupillary Activity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376394},
doi = {10.1145/3313831.3376394},
abstract = {A novel eye-tracked measure of pupil diameter oscillation is derived as an indicator of cognitive load. The new metric, termed the Low/High Index of Pupillary Activity (LHIPA), is able to discriminate cognitive load (vis-a-vis task difficulty) in several experiments where the Index of Pupillary Activity fails to do so. Rationale for the LHIPA is tied to the functioning of the human autonomic nervous system yielding a hybrid measure based on the ratio of Low/High frequencies of pupil oscillation. The paper's contribution is twofold. First, full documentation is provided for the calculation of the LHIPA. As with the IPA, it is possible for researchers to apply this metric to their own experiments where a measure of cognitive load is of interest. Second, robustness of the LHIPA is shown in analysis of three experiments, a restrictive fixed-gaze number counting task, a less restrictive fixed-gaze n-back task, and an applied eye-typing task.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {task difficulty, eye tracking, pupillometry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376750,
author = {Hirsch, Tad},
title = {Practicing Without a License: Design Research as Psychotherapy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376750},
doi = {10.1145/3313831.3376750},
abstract = {This paper considers the potential for participants to experience psychotherapeutic effects through their involvement in design research. Drawing on literature in human-computer interaction, psychotherapy, and feminist sociology, I argue that vulnerable participants may experience qualitative interviews therapeutically when they engage in reflexive activity about sensitive topics with researchers who employ psychotherapeutic techniques that encourage disclosure and reflection. I discuss ethical concerns and suggest the need for trauma-informed research practices, updated consent procedures, and revised pedagogy that better support researchers and participants engaged in emotionally charged encounters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {psychotherapy, emotion work, qualitative research, semi-structured interviewing, trauma-informed research, design research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376405,
author = {Burova, Alisa and M\"{a}kel\"{a}, John and Hakulinen, Jaakko and Keskinen, Tuuli and Heinonen, Hanna and Siltanen, Sanni and Turunen, Markku},
title = {Utilizing VR and Gaze Tracking to Develop AR Solutions for Industrial Maintenance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376405},
doi = {10.1145/3313831.3376405},
abstract = {Augmented reality (AR) presents a variety of possibilities for industrial maintenance. However, the development of real-world AR solutions has been limited due to the technological capabilities and uncertainty with respect to safety at deployment. We introduce the approach of using AR simulation in virtual reality (VR) coupled with gaze tracking to enable resource-efficient AR development. We tested in-field AR guidance and safety awareness features in an iterative development-evaluation process with experts from the elevator maintenance industry. We further conducted a survey, utilizing actual gaze data from the evaluation to elicit comments from industry experts on the usefulness of AR simulation and gaze tracking. Our results show the potential of AR within VR approach combined with gaze tracking. With this framework, AR solutions can be iteratively and safely tested without actual implementation, while gaze data provide advanced objective means to evaluate the designed AR content, documentation usage, and safety awareness.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, industrial maintenance, virtual prototyping, augmented reality, gaze tracking, safety},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376228,
author = {Hsieh, Ching-Yu and Chiang, Yi-Shyuan and Chiu, Hung-Yu and Chang, Yung-Ju},
title = {Bridging the Virtual and Real Worlds: A Preliminary Study of Messaging Notifications in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376228},
doi = {10.1145/3313831.3376228},
abstract = {Virtual reality (VR) platforms provide their users with immersive virtual environments, but disconnect them from real-world events. The increasing length of VR sessions can therefore be expected to boost users' needs to obtain information about external occurrences such as message arrival. Yet, how and when to present these real-world notifications to users engaged in VR activities remains underexplored. We conducted an experiment to investigate individuals' receptivity during four VR activities (Loading, 360 Video, Treasure Hunt, Rhythm Game) to message notifications delivered using three types of displays (head-mounted, controller, and movable panel). While higher engagement generally led to higher perceptions that notifications were ill-timed and/or disruptive, the suitability of notification displays to VR activities was influenced by the time-sensitiveness of VR content, overlapping use of modalities for delivering alerts, the display locations, and a requirement that the display be moved for notifications to be seen. Specific design suggestions are also provided.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interruptibility, receptivity, virtual reality, notification systems, eye-tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376810,
author = {Yan, Yukang and Yu, Chun and Zheng, Wengrui and Tang, Ruining and Xu, Xuhai and Shi, Yuanchun},
title = {FrownOnError: Interrupting Responses from Smart Speakers by Facial Expressions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376810},
doi = {10.1145/3313831.3376810},
abstract = {In the conversations with smart speakers, misunderstandings of users' requests lead to erroneous responses. We propose FrownOnError, a novel interaction technique that enables users to interrupt the responses by intentional but natural facial expressions. This method leverages the human nature that the facial expression changes when we receive unexpected responses. We conducted a first user study (N=12) to understand users' intuitive reactions to the correct and incorrect responses. Our results reveal the significant difference in the frequency of occurrence and intensity of users' facial expressions between two conditions, and frowning and raising eyebrows are intuitive to perform and easy to control. Our second user study (N=16) evaluated the user experience and interruption efficiency of FrownOnError and the third user study (N=12) explored suitable conversation recovery strategies after the interruptions. Our results show that FrownOnError can be accurately detected (precision: 97.4%, recall: 97.6%), provides the most timely interruption compared to the baseline methods of wake-up word and button press, and is rated as most intuitive and easiest to be performed by users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {voice user interface, facial expression, conversation interruption},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376713,
author = {Dema, Tshering and Brereton, Margot and Esteban, Michael and Soro, Alessandro and Sherub, Sherub and Roe, Paul},
title = {Designing in the Network of Relations for Species Conservation: The Playful Tingtibi Community Birdhouse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376713},
doi = {10.1145/3313831.3376713},
abstract = {This paper investigates connecting people in remote communities through nature in order to foster stewardship and conservation of endangered species. Global citizen science technologies have found success in urban, developed countries, but they typically rely on large distributed populations to gather or analyze data and do not suit sparsely populated and remote contexts. We undertook a long-term field study to iteratively co-design a tangible and playful nature engagement prototype in a remote World Heritage Area community. The prototype design fosters learning through ambient sounds as well as exploration and discovery of species through nature soundscape recordings. We found that the prototypes amplified locals' interest, became embedded in community relations and gradually led to placemaking of new engagement 'spaces' and of newer forms. We contribute lessons learned on how design can foster nature engagement and stewardship of endangered species by heeding Suchman's call for design to "enter networks of relations that make technology possible". We contribute design implications and new design foci HCI/Citizen science engagement for species conservation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {citizen science interfaces, wilderness soundscapes, nature engagement, endangered species stewardship, social and playful, network of relations, tingtibi birdhouse},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376816,
author = {Funk, Markus and Tobisch, Vanessa and Emfield, Adam},
title = {Non-Verbal Auditory Input for Controlling Binary, Discrete, and Continuous Input in Automotive User Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376816},
doi = {10.1145/3313831.3376816},
abstract = {Using auditory input while driving is becoming increasingly popular for making distraction-free inputs while driving. However, we argue that auditory input is more than just using speech. Thus, in this work, we explore using Non-Verbal Auditory Input (NVAI) for interacting with smart assistants while driving. Through an online study with 100 participants, we initially investigated users' input preferences for binary, discrete, and continuous data types. After identifying the top three modalities for NVAI, we subsequently conducted an in-person study with 16 participants. In our study, the participants tested these input modalities for three different input data types regarding their accuracy, driver-distraction, and social acceptability, while operating a driving simulator. The results reveal that, although clapping hands for making input was initially preferred in our online survey, it is snapping fingers for binary input and discrete input and humming for making continuous input that is the preferred NVAI modality while driving.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {non-verbal auditory interaction, automotive user interfaces, voice-user interface, speech input},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376468,
author = {Soni, Nikita and Gleaves, Schuyler and Neff, Hannah and Morrison-Smith, Sarah and Esmaeili, Shaghayegh and Mayne, Ian and Bapat, Sayli and Schuman, Carrie and Stofer, Kathryn A. and Anthony, Lisa},
title = {Adults' and Children's Mental Models for Gestural Interactions with Interactive Spherical Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376468},
doi = {10.1145/3313831.3376468},
abstract = {Interactive spherical displays offer numerous opportunities for engagement and education in public settings. Prior work established that users' touch-gesture patterns on spherical displays differ from those on flatscreen tabletops, and speculated that these differences stem from dissimilarity in how users conceptualize interactions with these two form factors. We analyzed think-aloud data collected during a gesture elicitation study to understand adults' and children's (ages 7 to 11) conceptual models of interaction with spherical displays and compared them to conceptual models of interaction with tabletop displays from prior work. Our findings confirm that the form factor strongly influenced users' mental models of interaction with the sphere. For example, participants conceptualized that the spherical display would respond to gestures in a similar way as real-world spherical objects like physical globes. Our work contributes new understanding of how users draw upon the perceived affordances of the sphere as well as prior touchscreen experience during their interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {touchscreen gestures, touchscreen displays, mental models, interactive spherical displays, children, adults},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376454,
author = {Hofman, Jake M. and Goldstein, Daniel G. and Hullman, Jessica},
title = {How Visualizing Inferential Uncertainty Can Mislead Readers About Treatment Effects in Scientific Results},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376454},
doi = {10.1145/3313831.3376454},
abstract = {When presenting visualizations of experimental results, scientists often choose to display either inferential uncertainty (e.g., uncertainty in the estimate of a population mean) or outcome uncertainty (e.g., variation of outcomes around that mean) about their estimates. How does this choice impact readers' beliefs about the size of treatment effects? We investigate this question in two experiments comparing 95% confidence intervals (means and standard errors) to 95% prediction intervals (means and standard deviations). The first experiment finds that participants are willing to pay more for and overestimate the effect of a treatment when shown confidence intervals relative to prediction intervals. The second experiment evaluates how alternative visualizations compare to standard visualizations for different effect sizes. We find that axis rescaling reduces error, but not as well as prediction intervals or animated hypothetical outcome plots (HOPs), and that depicting inferential uncertainty causes participants to underestimate variability in individual outcomes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {judgment and decision making, uncertainty visualization, effect sizes, confidence intervals, prediction intervals},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376284,
author = {Abdulgalimov, Dinislam and Kirkham, Reuben and Nicholson, James and Vlachokyriakos, Vasilis and Briggs, Pam and Olivier, Patrick},
title = {Designing for Employee Voice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376284},
doi = {10.1145/3313831.3376284},
abstract = {Employee voice and workplace democracy have a positive impact on employee wellbeing and the performance of organizations. In this paper, we conducted interviews with employees to identify facilitators and inhibitors for voice within the workplace and a corresponding set of appropriate qualities: Civility, Validity, Safety and Egalitarianism. We then operationalised these qualities as a set of design goals - Assured Anonymity, Constructive Moderation, Adequate Slowness and Controlled Access - in the design and development of a secure anonymous employee voice system. Our novel take on the Enterprise Social Network aims to foster good citizenship whilst also promoting frank yet constructive discussion. We reflect on a two-week deployment of our system, the diverse range of candid discussions that emerged around important workplace issues and the potential for change within the host organization. We conclude by reflecting on the ways in which our approach shaped discourse and supported the creation of a trusted environment for employee voice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {employee voice, anonymous online communities, cscw, enterprise social networks, workplace},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376358,
author = {Yoshida, Shigeo and Sun, Yuqian and Kuzuoka, Hideaki},
title = {PoCoPo: Handheld Pin-Based Shape Display for Haptic Rendering in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376358},
doi = {10.1145/3313831.3376358},
abstract = {We introduce PoCoPo, the first handheld pin-based shape display that can render various 2.5D shapes in hand in realtime. We designed the display small enough for a user to hold it in hand and carry it around, thereby enhancing the haptic experiences in a virtual environment. PoCoPo has 18 motor-driven pins on both sides of a cuboid, providing the sensation of skin contact on the user's palm and fingers. We conducted two user studies to understand the capability of PoCoPo. The first study showed that the participants were generally successful in distinguishing the shapes rendered by PoCoPo with an average success rate of 88.5%. In the second study, we investigated the acceptable visual size of a virtual object when PoCoPo rendered a physical object of a certain size. The result led to a better understanding of the acceptable differences between the perceptions of visual size and haptic size.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {haptic device, handheld device, virtual reality, shape display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376787,
author = {Yeo, Dohyeon and Kim, Gwangbin and Kim, Seungjun},
title = {Toward Immersive Self-Driving Simulations: Reports from a User Study across Six Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376787},
doi = {10.1145/3313831.3376787},
abstract = {As self-driving car technology matures, autonomous vehicle research is moving toward building more human-centric interfaces and accountable experiences. Driving simulators avoid many ethical and regulatory concerns about self-driving cars and play a key role in testing new interfaces or autonomous driving scenarios. However, apart from validity studies for manual driving simulation, the capabilities of driving simulators in replicating the experience of self-driving cars have not been widely investigated. In this paper, we build six self-driving simulation platforms with varying levels of visual and motion fidelities ranging from a screen-based in-lab simulator to the mixed-reality on-road simulator we propose. We compare the sense of presence and simulator sickness for each simulator composition, as well as its visual and motion fidelities with a user study. Our novel mixed-reality automotive driving simulator, named MAXIM, showed highest fidelity and presence. Our findings suggest how visual and motion configurations affect experience in autonomous driving simulators.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {driving simulator, autonomous driving, mixed reality, user studies, immersive technology, on-road simulation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376330,
author = {Nebeling, Michael and Speicher, Maximilian and Wang, Xizi and Rajaram, Shwetha and Hall, Brian D. and Xie, Zijian and Raistrick, Alexander R. E. and Aebersold, Michelle and Happ, Edward G. and Wang, Jiayin and Sun, Yanan and Zhang, Lotus and Ramsier, Leah E. and Kulkarni, Rhea},
title = {MRAT: The Mixed Reality Analytics Toolkit},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376330},
doi = {10.1145/3313831.3376330},
abstract = {Significant tool support exists for the development of mixed reality (MR) applications; however, there is a lack of tools for analyzing MR experiences. We elicit requirements for future tools through interviews with 8 university research, instructional, and media teams using AR/VR in a variety of domains. While we find a common need for capturing how users perform tasks in MR, the primary differences were in terms of heuristics and metrics relevant to each project. Particularly in the early project stages, teams were uncertain about what data should, and even could, be collected with MR technologies. We designed the Mixed Reality Analytics Toolkit (MRAT) to instrument MR apps via visual editors without programming and enable rapid data collection and filtering for visualizations of MR user sessions. With MRAT, we contribute flexible interaction tracking and task definition concepts, an extensible set of heuristic techniques and metrics to measure task success, and visual inspection tools with in-situ visualizations in MR. Focusing on a multi-user, cross-device MR crisis simulation and triage training app as a case study, we then show the benefits of using MRAT, not only for user testing of MR apps, but also performance tuning throughout the design process.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interaction tracking, augmented/virtual reality, user testing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376259,
author = {Dogar, Fahad R. and Qazi, Ihsan Ayyub and Tariq, Ali Raza and Murtaza, Ghulam and Ahmad, Abeer and Stocking, Nathan},
title = {MissIt: Using Missed Calls for Free, Extremely Low Bit-Rate Communication in Developing Regions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376259},
doi = {10.1145/3313831.3376259},
abstract = {Mobile devices have become the primary mode for Internet access in developing countries. Yet typical data plans and SMS costs can be overwhelming for low income users in these countries. In this paper, we explore the design and usability of a free but extremely low bit rate communication channel to address this challenge. We propose, a data communication channel that uses to transmit messages between phones, thereby sacrificing performance in exchange for low cost. While the data rate of is extremely low (&lt;1 bps), our prototype implementation and small scale user studies explore the feasibility of this idea for different types of messaging scenarios. Our results show that could be a viable option for messaging scenarios that require short, pre-determined responses (e.g., survey questions) while for traditional SMS-style messaging, a suitable user interface and other customizations are likely required to make it a viable option for users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {missed-calls, networks, ictd},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376774,
author = {Feltwell, Tom and Wood, Gavin and Brooker, Phillip and Rowland, Scarlett and Baumer, Eric P. S. and Long, Kiel and Vines, John and Barnett, Julie and Lawson, Shaun},
title = {Broadening Exposure to Socio-Political Opinions via a Pushy Smart Home Device},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376774},
doi = {10.1145/3313831.3376774},
abstract = {Motivated by the effects of the filter bubble and echo chamber phenomena on social media, we developed a smart home device, Spkr, that unpredictably "pushes" socio-political discussion topics into the home. The device utilised trending Twitter discussions, categorised by their socio-political alignment, to present people with a purposefully assorted range of viewpoints. We deployed Spkr in 10 homes for 28 days with a diverse range of participants and interviewed them about their experiences. Our results show that Spkr presents a novel means of combating selective exposure to socio-political issues, providing participants with identifiably diverse viewpoints. Moreover, Spkr acted as a conversational prompt for discussion within the home, initiating collective processes and engaging those who would not often be involved in political discussions. We demonstrate how smart home assistants can be used as a catalyst for provocation by altering and pluralising political discussions within households.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {selective exposure, socio-political discussion, echo chamber, viewpoint diversity, smart home technology, Nolan chart, filter bubble, pushy device},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376836,
author = {Xu, Xuhai and Shi, Haitian and Yi, Xin and Liu, WenJia and Yan, Yukang and Shi, Yuanchun and Mariakakis, Alex and Mankoff, Jennifer and Dey, Anind K.},
title = {EarBuddy: Enabling On-Face Interaction via Wireless Earbuds},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376836},
doi = {10.1145/3313831.3376836},
abstract = {Past research regarding on-body interaction typically requires custom sensors, limiting their scalability and generalizability. We propose EarBuddy, a real-time system that leverages the microphone in commercial wireless earbuds to detect tapping and sliding gestures near the face and ears. We develop a design space to generate 27 valid gestures and conducted a user study (N=16) to select the eight gestures that were optimal for both human preference and microphone detectability. We collected a dataset on those eight gestures (N=20) and trained deep learning models for gesture detection and classification. Our optimized classifier achieved an accuracy of 95.3%. Finally, we conducted a user study (N=12) to evaluate EarBuddy's usability. Our results show that EarBuddy can facilitate novel interaction and that users feel very positively about the system. EarBuddy provides a new eyes-free, socially acceptable input method that is compatible with commercial wireless earbuds and has the potential for scalability and generalizability},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {face and ear interaction, wireless earbuds, gesture recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376860,
author = {Jahanbakhsh, Farnaz and Cranshaw, Justin and Counts, Scott and Lasecki, Walter S. and Inkpen, Kori},
title = {An Experimental Study of Bias in Platform Worker Ratings: The Role of Performance Quality and Gender},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376860},
doi = {10.1145/3313831.3376860},
abstract = {We study how the ratings people receive on online labor platforms are influenced by their performance, gender, their rater's gender, and displayed ratings from other raters. We conducted a deception study in which participants collaborated on a task with a pair of simulated workers, who varied in gender and performance level, and then rated their performance. When the performance of paired workers was similar, low-performing females were rated lower than their male counterparts. Where there was a clear performance difference between paired workers, low-performing females were preferred over a similarly-performing male peer. Furthermore, displaying an average rating from other raters made ratings more extreme, resulting in high performing workers receiving significantly higher ratings and low performers lower ratings compared to when average ratings were absent. This work contributes an empirical understanding of when biases in ratings manifest, and offers recommendations for how online work platforms can counter these biases.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {bias in ratings, digital ratings, social mimicry, gender discrimination, bias in gig platforms},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376677,
author = {Oppenlaender, Jonas and Milland, Kristy and Visuri, Aku and Ipeirotis, Panos and Hosio, Simo},
title = {Creativity on Paid Crowdsourcing Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376677},
doi = {10.1145/3313831.3376677},
abstract = {Crowdsourcing platforms are increasingly being harnessed for creative work. The platforms' potential for creative work is clearly identified, but the workers' perspectives on such work have not been extensively documented. In this paper, we uncover what the workers have to say about creative work on paid crowdsourcing platforms. Through a quantitative and qualitative analysis of a questionnaire launched on two different crowdsourcing platforms, our results revealed clear differences between the workers on the platforms in both preferences and prior experience with creative work. We identify common pitfalls with creative work on crowdsourcing platforms, provide recommendations for requesters of creative work, and discuss the meaning of our findings within the broader scope of creativity-oriented research. To the best of our knowledge, we contribute the first extensive worker-oriented study of creative work on paid crowdsourcing platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {creativity support tools, creativity, creative work, creative tasks, crowdsourcing, creativity tests},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376876,
author = {Wolf, Dennis and Gugenheimer, Jan and Combosch, Marco and Rukzio, Enrico},
title = {Understanding the Heisenberg Effect of Spatial Interaction: A Selection Induced Error for Spatially Tracked Input Devices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376876},
doi = {10.1145/3313831.3376876},
abstract = {Virtual and augmented reality head-mounted displays (HMDs) are currently heavily relying on spatially tracked input devices (STID) for interaction. These STIDs are all prone to the phenomenon that a discrete input (e.g. button press) will disturb the position of the tracker, resulting in a different selection point during ray-cast interaction (Heisenberg Effect of Spatial Interaction). Besides the knowledge of its existence, there is currently a lack of a deeper understanding of its severity, structure and impact on throughput and angular error during a selection task. In this work, we present a formal evaluation of the Heisenberg effect and the impact of body posture, arm position and STID degrees of freedom on its severity. In a Fitt's Law inspired user study (N=16), we found that the Heisenberg effect is responsible for 30.45% of the overall errors occurring during a pointing task, but can be reduced by 25.4% using a correction function.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {vr, offset, pointing, correction, heisenberg effect, selection, stid},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376198,
author = {Yeo, Hui-Shyong and Feng, Wenxin and Huang, Michael Xuelin},
title = {WATouCH: Enabling Direct Input on Non-Touchscreen Using Smartwatch's Photoplethysmogram and IMU Sensor Fusion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376198},
doi = {10.1145/3313831.3376198},
abstract = {Interacting with non-touchscreens such as TV or public displays can be difficult and inefficient. We propose WATouCH, a novel method that localizes a smartwatch on a display and allows direct input by turning the smartwatch into a tangible controller. This low-cost solution leverages sensor fusion of the built-in inertial measurement unit (IMU) and photoplethysmogram (PPG) sensor on a smartwatch that is used for heart rate monitoring. Specifically, WATouCH tracks the smartwatch movement using IMU data and corrects its location error caused by drift using the PPG responses to a dynamic visual pattern on the display. We conducted a user study on two tasks -- a point and click and line tracing task -- to evaluate the system usability and user performance. Evaluation results suggested that our sensor fusion mechanism effectively confined IMU-based localization error, achieved encouraging targeting and tracing precision, was well received by the participants, and thus opens up new opportunities for interaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {direct input, smartwatch, tangible input, public display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376563,
author = {Alonzo, Oliver and Seita, Matthew and Glasser, Abraham and Huenerfauth, Matt},
title = {Automatic Text Simplification Tools for Deaf and Hard of Hearing Adults: Benefits of Lexical Simplification and Providing Users with Autonomy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376563},
doi = {10.1145/3313831.3376563},
abstract = {Automatic Text Simplification (ATS), which replaces text with simpler equivalents, is rapidly improving. While some research has examined ATS reading-assistance tools, little has examined preferences of adults who are deaf or hard-of-hearing (DHH), and none empirically evaluated lexical simplification technology (replacement of individual words) with these users. Prior research has revealed that U.S. DHH adults have lower reading literacy on average than their hearing peers, with unique characteristics to their literacy profile. We investigate whether DHH adults perceive a benefit from lexical simplification applied automatically or when users are provided with greater autonomy, with on-demand control and visibility as to which words are replaced. Formative interviews guided the design of an experimental study, in which DHH participants read English texts in their original form and with lexical simplification applied automatically or on-demand. Participants indicated that they perceived a benefit form lexical simplification, and they preferred a system with on-demand simplification.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {reading assistance, lexical simplification, people who are deaf or hard of hearing, autonomy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376858,
author = {Kleinberger, R\'{e}becca and Harrington, Anne H. K. and Yu, Lydia and van Troyer, Akito and Su, David and Baker, Janet M. and Miller, Gabriel},
title = {Interspecies Interactions Mediated by Technology: An Avian Case Study at the Zoo},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376858},
doi = {10.1145/3313831.3376858},
abstract = {Enrichment is a methodology for caregivers to offer zoo animals improved psychological and physiological well-being. Although many species rely on auditory senses, sonic enrichment is rarely implemented. Zoo soundscapes are dominated by human-generated noises and do not respond meaningfully to animals' behavior. Designing interactive sonic enrichment systems for animals presents unique ergonomic, ethical, and agency-related challenges. We present a case study of such design. We deployed two novel interventions at the San Diego Zoo to allow Sampson, a music-savvy hyacinth macaw, to gain control over his sonic environment. Our results suggest that (1) the bird uses, understands, and benefits from the system, and (2) visitors play a major role in Sampson's engagement with this technology. With his new agency, the bird seemingly gains more control over his interactions with the public, creating an interspecies experience mediated by technology. The resulting animal-human-computer interaction may inform mediated interspecies experiences in the future.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interspecies interactions, animal computer interaction, animal agency, sonic enrichment, enrichment, animal music},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376158,
author = {Manuel, Jennifer and Crivellaro, Clara},
title = {Place-Based Policymaking and HCI: Opportunities and Challenges for Technology Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376158},
doi = {10.1145/3313831.3376158},
abstract = {There has been a growing interest in HCI in designing and developing technology to support democratic participation, particularly in the domain of urban planning or place-based research. In addition, the HCI field has increasingly considered the intersection of HCI and policymaking to understand how our research can have a broader impact. In this paper, we report on a series of workshops with citizens and city planners to explore place-based policymaking through the case study of neighbourhood planning in the UK. Our analysis highlights the tensions, opportunities and challenges faced by citizens in creating policy. Drawing from our findings, we stress the need for HCI to be actively involved in supporting, innovating and (re)designing civic policymaking processes while emphasising design considerations for the development of technological tools.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {digital civics, policymaking, citizen participation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376829,
author = {Syeda, Uzma Haque and Murali, Prasanth and Roe, Lisa and Berkey, Becca and Borkin, Michelle A.},
title = {Design Study "Lite" Methodology: Expediting Design Studies and Enabling the Synergy of Visualization Pedagogy and Social Good},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376829},
doi = {10.1145/3313831.3376829},
abstract = {Design studies are frequently used to conduct problem-driven visualization research by working with real-world domain experts. In visualization pedagogy, design studies are often introduced but rarely practiced due to their large time requirements. This limits students to a classroom curriculum, often involving projects that may not have implications beyond the classroom. Thus we present the Design Study "Lite" Methodology, a novel framework for implementing design studies with novice students in 14 weeks. We utilized the Design Study "Lite" Methodology in conjunction with Service-Learning to teach five Data Visualization courses and demonstrate that it benefits not only the students but also the community through service to non-profit partners. In this paper, we provide a detailed breakdown of the methodology and how Service-Learning can be incorporated with it. We also include an extensive reflection on the methodology and provide recommendations for future applications of the framework for teaching visualization courses and research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design studies, pedagogy, theory and methods, visualization, service-learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376467,
author = {Kim, Dae Hyun and Hoque, Enamul and Agrawala, Maneesh},
title = {Answering Questions about Charts and Generating Visual Explanations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376467},
doi = {10.1145/3313831.3376467},
abstract = {People often use charts to analyze data, answer questions and explain their answers to others. In a formative study, we find that such human-generated questions and explanations commonly refer to visual features of charts. Based on this study, we developed an automatic chart question answering pipeline that generates visual explanations describing how the answer was obtained. Our pipeline first extracts the data and visual encodings from an input Vega-Lite chart. Then, given a natural language question about the chart, it transforms references to visual attributes into references to the data. It next applies a state-of-the-art machine learning algorithm to answer the transformed question. Finally, it uses a template-based approach to explain in natural language how the answer is determined from the chart's visual features. A user study finds that our pipeline-generated visual explanations significantly outperform in transparency and are comparable in usefulness and trust to human-generated explanations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {explainable ai, question answering, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376505,
author = {Huang, Kai-Chieh and Sun, Chen-Kuo and Huang, Da-Yuan and Chen, Yu-Chun and Chang, Ruei-Che and Hsu, Shuo-wen and Yang, Chih-Yun and Chen, Bing-Yu},
title = {Glissade: Generating Balance Shifting Feedback to Facilitate Auxiliary Digital Pen Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376505},
doi = {10.1145/3313831.3376505},
abstract = {This paper introduces Glissade, a digital pen that generates balance shifting feedback by changing the weight distribution of the pen. A pulley system shifts a brass mass inside the pen to change the pen's center of mass and moment of inertia. When the mass is stationary, the pen delivers a constant yet natural sensation of weight, which can be used to convey a status. The pen can also generate a variety of haptic clues by actuating the mass according to the tilt or rotation of the pen, two commonly-used auxiliary pen input channels. Glissade demonstrates new possibilities that balance shifting feedback can bring to digital pen interactions. We validated the usability of this feedback by determining the recognizability of six balance patterns – a mix of static and dynamic patterns chosen based on our design considerations – in two controlled experiments. The results show that, on average, the participants could distinguish between the patterns with a 94.25% accuracy. At the end, we demonstrate a set of novel interactions enabled by Glissade and discuss the directions for future research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {digital pen, haptics, sensation of weight, balance shifting feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376164,
author = {Arshad, Muhammad Bilal and Sarwar, Muhammad Farhan and Zaidi, Meher Fatima and Shahid, Suleman},
title = {EAST: Early Autism Screening Tool for Preschoolers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376164},
doi = {10.1145/3313831.3376164},
abstract = {We describe the iterative co-design process and evaluation of an early autism screening tool (EAST). EAST is an intermediary interactive tablet based app that assists in the early-detection of Autism Spectrum Disorder (ASD) by screening preschoolers in Pakistan through play-based activities in a home, school or clinical setting. Medical professionals, parents of autistic children and teachers were surveyed through focus groups to understand the reasons that contribute to the increasing number of missed early detections, and late- or misdiagnoses. We also evaluate the acceptability, usability and validity of our tool. We tested EAST with both typically developed and autistic children on how they relate to people, imitation, motor skills, visual and intellectual response. They were scored via time taken, the number of wrong attempts, or incorrect answers and audiovisual feedback. This paper contributes towards a digital autism screening tool that delivers insights into the child's behaviour and enables collaboration among parents, teachers and medical professionals.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {digital tool, autism screening, preschool children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376377,
author = {Sarma, Abhraneel and Kay, Matthew},
title = {Prior Setting in Practice: Strategies and Rationales Used in Choosing Prior Distributions for Bayesian Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376377},
doi = {10.1145/3313831.3376377},
abstract = {Bayesian statistical analysis is steadily growing in popularity and use. Choosing priors is an integral part of Bayesian inference. While there exist extensive normative recommendations for prior setting, little is known about how priors are chosen in practice. We conducted a survey (N = 50) and interviews (N = 9) where we used interactive visualizations to elicit prior distributions from researchers experienced withBayesian statistics and asked them for rationales for those priors. We found that participants' experience and philosophy influence how much and what information they are willing to incorporate into their priors, manifesting as different levels of informativeness and skepticism. We also identified three broad strategies participants use to set their priors: centrality matching, interval matching, and visual mass allocation. We discovered that participants' understanding of the notion of 'weakly informative priors"-a commonly-recommended normative approach to prior setting-manifests very differently across participants. Our results have implications both for how to develop prior setting recommendations and how to design tools to elicit priors in Bayesian analysis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {bayesian inference, prior distributions, descriptive analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376637,
author = {Nebeling, Michael and Lewis, Katy and Chang, Yu-Cheng and Zhu, Lihan and Chung, Michelle and Wang, Piaoyang and Nebeling, Janet},
title = {XRDirector: A Role-Based Collaborative Immersive Authoring System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376637},
doi = {10.1145/3313831.3376637},
abstract = {Immersive authoring is an increasingly popular technique to design AR/VR scenes because design and testing can be done concurrently. Most existing systems, however, are single-user and limited to either AR or VR, thus constrained in the interaction techniques. We present XRDirector, a role-based collaborative immersive authoring system that enables designers to freely express interactions using AR and VR devices as puppets to manipulate virtual objects in 3D physical space. In XRDirector, we adapt roles known from filmmaking to structure the authoring process and help coordinate multiple designers in immersive authoring tasks. We study how novice AR/VR creators can take advantage of the roles and modes in XRDirector to prototype complex scenes with animated 3D characters, light effects, and camera movements, and also simulate interactive system behavior in a Wizard of Oz style. XRDirector's design was informed by case studies around complex 3D movie scenes and AR/VR games, as well as workshops with novice AR/VR creators. We show that XRDirector makes it easier and faster to create AR/VR scenes without the need for coding, characterize the issues in coordinating designers between AR and VR, and identify the strengths and weaknesses of each role and mode to mitigate the issues.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {immersive authoring, mixed-reality collaboration, ar/vr},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376507,
author = {D\"{o}rrenb\"{a}cher, Judith and L\"{o}ffler, Diana and Hassenzahl, Marc},
title = {Becoming a Robot - Overcoming Anthropomorphism with Techno-Mimesis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376507},
doi = {10.1145/3313831.3376507},
abstract = {Employing anthropomorphism in physical appearance and behavior is the most widespread strategy for designing social robots. In the present paper, we argue that imitating humans impedes the full exploration of robots' social abilities. In fact, their very 'thingness' (e.g., sensors, rationality) is able to create 'superpowers' that go beyond human abilities, such as endless patience. To better identify these special abilities, we develop a performative method called 'Techno-Mimesis' and explore it in a series of workshops with robot designers. Specifically, we create 'prostheses' to allow designers to transform themselves into their future robot to experience use cases from the robot's perspective, e.g., 'seeing' with a distance sensor rather than with eyes. This imperfect imitation helps designers to experience being human and being robot at the same time, making differences apparent and facilitating the discovery of a number of potential physical, cognitive, and communicational robotic superpowers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social robots, service robots, new animism, performative design method, anthropomorphism},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376777,
author = {Hoffswell, Jane and Li, Wilmot and Liu, Zhicheng},
title = {Techniques for Flexible Responsive Visualization Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376777},
doi = {10.1145/3313831.3376777},
abstract = {Responsive visualizations adapt to effectively present information based on the device context. Such adaptations are essential for news content that is increasingly consumed on mobile devices. However, existing tools provide little support for responsive visualization design. We analyze a corpus of 231 responsive news visualizations and discuss formative interviews with five journalists about responsive visualization design. These interviews motivate four central design guidelines: enable simultaneous cross-device edits, facilitate device-specific customization, show cross-device previews, and support propagation of edits. Based on these guidelines, we present a prototype system that allows users to preview and edit multiple visualization versions simultaneously. We demonstrate the utility of the system features by recreating four real-world responsive visualizations from our corpus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mobile devices, responsive design, news, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376595,
author = {Huang, Xiaoyun and Vitak, Jessica and Tausczik, Yla},
title = {"You Don't Have To Know My Past": How WeChat Moments Users Manage Their Evolving Self-Presentation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376595},
doi = {10.1145/3313831.3376595},
abstract = {Most social media platforms record, display, and archive users' personal histories. This persistence of posts over time can be problematic, as users' self-presentation goals and network composition change, but old content remains. In this paper, we explore an alternative feature that provides control over content persistence. We present findings from interviews with 16 users of the popular Chinese social media platform WeChat Moments. We focused on Moments' Time Limit setting, which makes social media data ephemeral to audiences, but persistent to posters. Interviewees described changes in their self-presentation goals and social network composition over time and reported the Time Limit feature helped them effortlessly manage their desired self-presentation as they matured. Drawing on these findings, we discuss design implications for social media to facilitate greater control over content visibility and persistence, which may have significant benefits for social media users with large and diverse networks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {wechat moments, self-presentation, persistence, ephemerality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376514,
author = {Frid, Emma and Gomes, Celso and Jin, Zeyu},
title = {Music Creation by Example},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376514},
doi = {10.1145/3313831.3376514},
abstract = {Short online videos have become the dominating media on social platforms. However, finding suitable music to accompany videos can be a challenging task to some video creators, due to copyright constraints, limitations in search engines, and required audio-editing expertise. One possible solution to these problems is to use AI music generation. In this paper we present a user interface (UI) paradigm that allows users to input a song to an AI engine and then interactively regenerate and mix AI-generated music. To arrive at this design, we conducted user studies with a total of 104 video creators at several stages of our design and development process. User studies supported the effectiveness of our approach and provided valuable insights about human-AI interaction as well as the design and evaluation of mixed-initiative interfaces in creative practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {artificial intelligence, music generation, algorithmic composition, mixed-initiative interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376302,
author = {Dylan, Thomas and Wood, Gavin and Durrant, Abigail C. and Vines, John and Torres, Pablo E. and Ulrich, Philip I. N. and Cukurova, Mutlu and Carr, Amanda and \c{C}er\c{c}i, Sena and Lawson, Shaun},
title = {Designing IoT Resources to Support Outdoor Play for Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376302},
doi = {10.1145/3313831.3376302},
abstract = {We describe a Research-through-Design (RtD) project that explores the Internet of Things (IoT) as a resource for children's free play outdoors. Based on initial insights from a design ethnography, we developed four RtD prototypes for social play in different scenarios of use outdoors, including congregating on a street or in a park to play physical games with IoT. We observed these prototypes in use by children in their free play in two community settings, and report on the qualitative analysis of our fieldwork. Our findings highlight the designs' material qualities that encouraged social and physical play under certain conditions, suggesting social affordances that are central to the success of IoT designs for free play outdoors. We provide directions for future research that addresses the challenges faced when deploying IoT with children, contributing new considerations for interaction design with children in outdoor settings and free play contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {digital playing out, internet of things, outdoor play, children, free play, pervasive play},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376324,
author = {Wu, Ziming and Jiang, Yulun and Liu, Yiding and Ma, Xiaojuan},
title = {Predicting and Diagnosing User Engagement with Mobile UI Animation via a Data-Driven Approach},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376324},
doi = {10.1145/3313831.3376324},
abstract = {Animation, a common design element in user interfaces (UI), can impact user engagement (UE) with mobile applications. To avoid impairing UE due to improper design of animation, designers rely on resource-intensive evaluation methods like user studies or expert reviews. To alleviate this burden, we propose a data-driven approach to assisting designers in examining UE issues with their animation designs. We first crowdsource UE assessments of mobile UI animations. Based on the collected data, we then build a novel deep learning model that captures both spatial and temporal features of animations to predict their UE levels. Evaluations show that our model achieves a reasonable accuracy. We further leverage the animation feature encoded by our model and a sample set of expert reviews to derive potential UE issues of a particular animation. Finally, we develop a proof-of-concept tool and evaluate its potential usage in actual design practices with experts},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {data-driven approach, user engagement, mobile ui animation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376587,
author = {Pei, Lucy and Crooks, Roderic},
title = {Attenuated Access: Accounting for Startup, Maintenance, and Affective Costs in Resource-Constrained Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376587},
doi = {10.1145/3313831.3376587},
abstract = {The term "digital divide" indexes a body of research at the intersection of digital technology and social equity, including research on inequality that criticizes and recapitulates the original concept. Based on a qualitative study at a community literacy center serving resettled refugees and immigrants, we show that the digital divide framework rests on a distributive logic, one that implies that distributing access to digital technology constitutes a form of social equity. Because this framework only considers valorized goods, skills, and uses, research has frequently ignored the startup, maintenance, and affective costs we found accompanied digital access for our participants. To account for these costs, we propose a theoretical adjustment to the digital divide framework, one where design is an act of configuring both costs and benefits together. We argue that considering such costs enables HCI researchers to engage more effectively with host communities in the non-innocent work of confronting inequity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {equity, immigrants and resettled refugees, social justice, digital access, digital divide},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376674,
author = {Thakkar, Divy and Kumar, Neha and Sambasivan, Nithya},
title = {Towards an AI-Powered Future That Works for Vocational Workers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376674},
doi = {10.1145/3313831.3376674},
abstract = {The future of work is speculated to undergo profound change with increased automation. Predictable jobs are projected to face high susceptibility to technological developments. Many economies in Global South are built around outsourcing and manual labour, facing a risk of job insecurity. In this paper, we examine the perceptions and practices around automated futures of work among a population that is highly vulnerable to algorithms and robots entering rule-based and manual domains: vocational technicians. We present results from participatory action research with 38 vocational technician students of low socio-economic status in Bangalore, India. Our findings show that technicians were unfamiliar with the growth of automation, but upon learning about it, articulated an emic vision for a future of work in-line with their value systems. Participants felt excluded by current technological platforms for skilling and job-seeking. We present opportunities for technology industry and policy makers to build a future of work for vulnerable communities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {hci4d, automation, ai, skills, vocational technicians, algorithmic fairness, india, policy, future of work},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376411,
author = {Zuckerman, Oren and Walker, Dina and Grishko, Andrey and Moran, Tal and Levy, Chen and Lisak, Barak and Wald, Iddo Yehoshua and Erel, Hadas},
title = {Companionship Is Not a Function: The Effect of a Novel Robotic Object on Healthy Older Adults' Feelings of "Being-Seen"},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376411},
doi = {10.1145/3313831.3376411},
abstract = {One of the challenges faced by healthy older adults is experiencing feelings of not "being-seen". Companion robots, commonly designed with zoomorphic or humanoid appearance show success among clinical older adults, but healthy older adults find them degrading. We present the design and implementation of a novel non-humanoid robot. The robot's primary function is a cognitive word game. Social interaction is conveyed as a secondary function, using non-verbal gestures, inspired by dancers' movement. In a lab study, 39 healthy older adults interacted with the prototype in 3 conditions: Companion-Function; Game-Function; and No-Function. Results show the non-verbal gestures were associated with feelings of "being-seen", and willingness to accept the robot into their home was influenced by its function, with game significantly higher than companion. We conclude that robot designers should further explore the potential of non-humanoid robots as a new class of companion robots, with a primary function that is not companionship.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {older adults, loneliness, successful aging, tangible interaction, social-interaction, non-humanoid robot, acceptance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376320,
author = {Hettiachchi, Danula and Sarsenbayeva, Zhanna and Allison, Fraser and van Berkel, Niels and Dingler, Tilman and Marini, Gabriele and Kostakos, Vassilis and Goncalves, Jorge},
title = {"Hi! I Am the Crowd Tasker" Crowdsourcing through Digital Voice Assistants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376320},
doi = {10.1145/3313831.3376320},
abstract = {Inspired by the increasing prevalence of digital voice assistants, we demonstrate the feasibility of using voice interfaces to deploy and complete crowd tasks. We have developed Crowd Tasker, a novel system that delivers crowd tasks through a digital voice assistant. In a lab study, we validate our proof-of-concept and show that crowd task performance through a voice assistant is comparable to that of a web interface for voice-compatible and voice-based crowd tasks for native English speakers. We also report on a field study where participants used our system in their homes. We find that crowdsourcing through voice can provide greater flexibility to crowd workers by allowing them to work in brief sessions, enabling multi-tasking, and reducing the time and effort required to initiate tasks. We conclude by proposing a set of design guidelines for the creation of crowd tasks for voice and the development of future voice-based crowdsourcing systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {smart speakers, digital voice assistants, crowdsourcing, voice user interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376316,
author = {Gero, Katy Ilonka and Ashktorab, Zahra and Dugan, Casey and Pan, Qian and Johnson, James and Geyer, Werner and Ruiz, Maria and Miller, Sarah and Millen, David R. and Campbell, Murray and Kumaravel, Sadhana and Zhang, Wei},
title = {Mental Models of AI Agents in a Cooperative Game Setting},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376316},
doi = {10.1145/3313831.3376316},
abstract = {As more and more forms of AI become prevalent, it becomes increasingly important to understand how people develop mental models of these systems. In this work we study people's mental models of AI in a cooperative word guessing game. We run think-aloud studies in which people play the game with an AI agent; through thematic analysis we identify features of the mental models developed by participants. In a large-scale study we have participants play the game with the AI agent online and use a post-game survey to probe their mental model. We find that those who win more often have better estimates of the AI agent's abilities. We present three components for modeling AI systems, propose that understanding the underlying technology is insufficient for developing appropriate conceptual models (analysis of behavior is also necessary), and suggest future work for studying the revision of mental models over time.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {games, mental models, think-aloud, word games, ai agents, artificial intelligence, conceptual models},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376482,
author = {Burke, Moira and Cheng, Justin and de Gant, Bethany},
title = {Social Comparison and Facebook: Feedback, Positivity, and Opportunities for Comparison},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376482},
doi = {10.1145/3313831.3376482},
abstract = {People compare themselves to one another both offline and online. The specific online activities that worsen social comparison are partly understood, though much existing research relies on people recalling their own online activities post hoc and is situated in only a few countries. To better understand social comparison worldwide and the range of associated behaviors on social media, a survey of 38,000 people from 18 countries was paired with logged activity on Facebook for the prior month. People who reported more frequent social comparison spent more time on Facebook, had more friends, and saw proportionally more social content on the site. They also saw greater amounts of feedback on friends' posts and proportionally more positivity. There was no evidence that social comparison happened more with acquaintances than close friends. One in five respondents recalled recently seeing a post that made them feel worse about themselves but reported conflicting views: half wished they hadn't seen the post, while a third felt very happy for the poster. Design opportunities are discussed, including hiding feedback counts, filters for topics and people, and supporting meaningful interactions, so that when comparisons do occur, people are less affected by them.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social media, well-being, facebook, social comparison, envy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376477,
author = {Das, Maitraye and Borgos-Rodriguez, Katya and Piper, Anne Marie},
title = {Weaving by Touch: A Case Analysis of Accessible Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376477},
doi = {10.1145/3313831.3376477},
abstract = {The rise of maker communities and fabrication tools creates new opportunities for participation in design work. With this has come an interest in increasing the accessibility of making for people with disabilities, which has mainly emphasized independence and empowerment through the creation of more accessible fabrication tools. To understand and rethink the notion of accessible making, we analyze the context and practices of a particular site of making: the communal weaving studio within an assisted living facility for people with vision impairments. Our analysis helps reconsider the material and social processes that constitute accessible making, including the ways makers attend to interactive material properties, negotiate co-creative embodied work, and value the labor of making. We discuss future directions for design and research on accessible making while highlighting tensions around assistance, collaboration, and how disabled labor is valued.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {vision impairments, materiality, making, disability, design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376808,
author = {Zhang, Tianyi and El Ali, Abdallah and Wang, Chen and Hanjalic, Alan and Cesar, Pablo},
title = {RCEA: Real-Time, Continuous Emotion Annotation for Collecting Precise Mobile Video Ground Truth Labels},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376808},
doi = {10.1145/3313831.3376808},
abstract = {Collecting accurate and precise emotion ground truth labels for mobile video watching is essential for ensuring meaningful predictions. However, video-based emotion annotation techniques either rely on post-stimulus discrete self-reports, or allow real-time, continuous emotion annotations (RCEA) only for desktop settings. Following a user-centric approach, we designed an RCEA technique for mobile video watching, and validated its usability and reliability in a controlled, indoor (N=12) and later outdoor (N=20) study. Drawing on physiological measures, interaction logs, and subjective workload reports, we show that (1) RCEA is perceived to be usable for annotating emotions while mobile video watching, without increasing users' mental workload (2) the resulting time-variant annotations are comparable with intended emotion attributes of the video stimuli (classification error for valence: 8.3%; arousal: 25%). We contribute a validated annotation technique and associated annotation fusion method, that is suitable for collecting fine-grained emotion annotations while users watch mobile videos.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {video, annotation, continuous, mobile, real-time, labels, emotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376695,
author = {Peng, Zhenhui and Guo, Qingyu and Tsang, Ka Wing and Ma, Xiaojuan},
title = {Exploring the Effects of Technological Writing Assistance for Support Providers in Online Mental Health Community},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376695},
doi = {10.1145/3313831.3376695},
abstract = {Textual comments from peers with informational and emotional support are beneficial to members of online mental health communities (OMHCs). However, many comments are not of high quality in reality. Writing support technologies that assess (AS) the text or recommend (RE) writing examples on the fly could potentially help support providers to improve the quality of their comments. However, how providers perceive and work with such technologies are under-investigated. In this paper, we present a technological prototype MepsBot which offers providers in-situ writing assistance in either AS or RE mode. Results of a mixed-design study with 30 participants show that both types of MepsBots improve users' confidence in and satisfaction with their comments. The AS-mode MepsBot encourages users to refine expressions and is deemed easier to use, while the RE-mode one stimulates more support-related content re-editions. We report concerns on MepsBot and propose design considerations for writing support technologies in OMHCs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mental health, writing support tools, informational support, online community, emotional support},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376299,
author = {Pradhan, Alisha and Jelen, Ben and Siek, Katie A. and Chan, Joel and Lazar, Amanda},
title = {Understanding Older Adults' Participation in Design Workshops},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376299},
doi = {10.1145/3313831.3376299},
abstract = {Design workshops are a popular means of including older adults in technology development. However, there are open questions around how to best scaffold this participation, particularly in supporting older adults to associate their designs with themselves, rather than designing for an "other older adult." By conducting workshops focusing on envisioning the future of internet of things (IoT) technologies at home, we provide an understanding of how older individuals participate in group activities to conceptualize technology for themselves. We find that at different stages of the design process, individuals shift in who they envision the end user of the technology: at first, they think about common older adult needs, then turn to designing for themselves. Individuals' attitudes towards technology also impact group dynamics along with final design ideas. Our discussion contributes to an understanding of how to support older adults in designing for themselves, new perspectives on aging-in-place technologies, and recommendations for configuring design workshops with older individuals.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {older adults, co-design, iot, participatory design, design workshops},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376353,
author = {Siu, Alexa F. and Sinclair, Mike and Kovacs, Robert and Ofek, Eyal and Holz, Christian and Cutrell, Edward},
title = {Virtual Reality Without Vision: A Haptic and Auditory White Cane to Navigate Complex Virtual Worlds},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376353},
doi = {10.1145/3313831.3376353},
abstract = {Current Virtual Reality (VR) technologies focus on rendering visuospatial effects, and thus are inaccessible for blind or low vision users. We examine the use of a novel white cane controller that enables navigation without vision of large virtual environments with complex architecture, such as winding paths and occluding walls and doors. The cane controller employs a lightweight three-axis brake mechanism to provide large-scale shape of virtual objects. The multiple degrees-of-freedom enables users to adapt the controller to their preferred techniques and grip. In addition, surface textures are rendered with a voice coil actuator based on contact vibrations; and spatialized audio is determined based on the progression of sound through the geometry around the user. We design a scavenger hunt game that demonstrates how our device enables blind users to navigate a complex virtual environment. Seven out of eight users were able to successfully navigate the virtual room (6x6m) to locate targets while avoiding collisions. We conclude with design consideration on creating immersive non-visual VR experiences based on user preferences for cane techniques, and cane material properties.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {blindness, virtual reality, white cane, mobility, 3d audio, visual impairments, auditory feedback, haptic feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376460,
author = {Smith, Taliesin L. and Moore, Emily B.},
title = {Storytelling to Sensemaking: A Systematic Framework for Designing Auditory Description Display for Interactives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376460},
doi = {10.1145/3313831.3376460},
abstract = {Auditory description display is verbalized text typically used to describe live, recorded, or graphical displays to support access for people who are blind or visually impaired. Significant prior research has resulted in guidelines for auditory description for non-interactive or minimally interactive contexts. A lack of auditory description for complex interactive environments remains a tremendous barrier to access for people with visual impairments. In this work, we present a systematic design framework for designing auditory description within complex interactive environments. We illustrate how modular descriptions aligned with this framework can result in an interactive storytelling experience constructed through user interactions. This framework has been used in a set of published and widely used interactive science simulations, and in its generalized form could be applied to a variety of contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interactive information spaces, auditory description display, description design, non-visual access},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376433,
author = {Robinson, Raquel Breejon and Reid, Elizabeth and Fey, James Collin and Depping, Ansgar E. and Isbister, Katherine and Mandryk, Regan L.},
title = {Designing and Evaluating 'In the Same Boat', A Game of Embodied Synchronization for Enhancing Social Play},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376433},
doi = {10.1145/3313831.3376433},
abstract = {Social closeness is important for health and well-being, but is difficult to maintain over a distance. Games can help connect people by strengthening existing relationships or creating new ones through shared playful experiences. We present the design and evaluation of 'In the Same Boat' (ITSB), a two-player infinite runner designed to foster social closeness in distributed dyads. ITSB leverages the synchronization of both players' input to steer a canoe down a river and avoid obstacles. We created two versions: embodied controls, which use players' physiological signals (breath rate, facial expressions), and standard keyboard controls. Results from a study with 35 dyads indicate that ITSB fostered affiliation, and while embodied controls were less intuitive, people enjoyed them more. Further, photos of the dyads were rated as happier and closer in the embodied condition, indicating the potential of embodied controls to foster social closeness in synchronized play over a distance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {physiological data, emotion, body games, social games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376755,
author = {Troiano, Giovanni Maria and Chen, Qinyu and Alba, \'{A}ngela Vargas and Robles, Gregorio and Smith, Gillian and Cassidy, Michael and Tucker-Raymond, Eli and Puttick, Gillian and Harteveld, Casper},
title = {Exploring How Game Genre in Student-Designed Games Influences Computational Thinking Development},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376755},
doi = {10.1145/3313831.3376755},
abstract = {Game design is increasingly used in modern education to foster Computational Thinking (CT). Yet, it is unclear how and if the game genre of student-designed games impact CT and programming. We explore how game genre impacts CT development and programming routines in Scratch games designed by 8th-grade students using a metrics-based approach (i.e., Dr. Scratch). Our findings show that designing particular games (e.g., action, storytelling) impact CT and programming development. We observe, for instance, that CT skills develop and consolidate fast, after which students can focus on aspects more specific to game design. Based on the results, we suggest that researchers and educators in constructionist learning consider the impact of game genre when designing game-based curricula for the learning of programming and CT.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {computational thinking, Dr. Scratch, video games, scratch, game-based learning, game design, constructionist learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376130,
author = {Yu, Junnan and Bai, Chenke and Roque, Ricarose},
title = {Considering Parents in Coding Kit Design: Understanding Parents' Perspectives and Roles},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376130},
doi = {10.1145/3313831.3376130},
abstract = {As education researchers, policymakers, and industry leaders recognize the importance of computing, many coding kits (toys and apps) have emerged to help young children learn to code at home. However, how parents perceive and support their children's use of the kits at home are less understood. In this study, we performed semi-structured interviews with eighteen parents who obtained coding kits for their young children for home use. The results show parents expected their kids to have fun and meaningful interactions with the kits. In supporting the play, parents took on various roles, mostly acting as spectator, scaffolder, and teacher. While parents perceived benefits of coding kits like a changed perspective on coding, they also reported concerns, such as their limited programming knowledge to provide help. Finally, we reflect on design and research implications to develop coding kits that consider parents' perspectives and important roles in supporting young children's exploration with computational thinking.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {parent roles, informal learning, educational technology, coding toys and kits, young children, parents' perspectives},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376613,
author = {Cordeil, Maxime and Bach, Benjamin and Cunningham, Andrew and Montoya, Bastian and Smith, Ross T. and Thomas, Bruce H. and Dwyer, Tim},
title = {Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality Data Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376613},
doi = {10.1145/3313831.3376613},
abstract = {We present Embodied Axes, a controller which supports selection operations for 3D imagery and data visualisations in Augmented Reality. The device is an embodied representation of a 3D data space -- each of its three orthogonal arms corresponds to a data axis or domain specific frame of reference. Each axis is composed of a pair of tangible, actuated range sliders for precise data selection, and rotary encoding knobs for additional parameter tuning or menu navigation. The motor actuated sliders support alignment to positions of significant values within the data, or coordination with other input: e.g., mid-air gestures in the data space, touch gestures on the surface below the data, or another Embodied Axes device supporting multi-user scenarios. We conducted expert enquiries in medical imaging which provided formative feedback on domain tasks and refinements to the design. Additionally, a controlled user study was performed and found that the Embodied Axes was overall more accurate than conventional tracked controllers for selection tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {tangible interaction, actuation, device, 3d visualisation, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376403,
author = {Qiu, Sihang and Gadiraju, Ujwal and Bozzon, Alessandro},
title = {Improving Worker Engagement Through Conversational Microtask Crowdsourcing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376403},
doi = {10.1145/3313831.3376403},
abstract = {The rise in popularity of conversational agents has enabled humans to interact with machines more naturally. Recent work has shown that crowd workers in microtask marketplaces can complete a variety of human intelligence tasks (HITs) using conversational interfaces with similar output quality compared to the traditional Web interfaces. In this paper, we investigate the effectiveness of using conversational interfaces to improve worker engagement in microtask crowdsourcing. We designed a text-based conversational agent that assists workers in task execution, and tested the performance of workers when interacting with agents having different conversational styles. We conducted a rigorous experimental study on Amazon Mechanical Turk with 800 unique workers, to explore whether the output quality, worker engagement and the perceived cognitive load of workers can be affected by the conversational agent and its conversational styles. Our results show that conversational interfaces can be effective in engaging workers, and a suitable conversational style has potential to improve worker engagement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user engagement, conversational style, cognitive task load, microtask crowdsourcing, conversational interface},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376219,
author = {Kaur, Harmanpreet and Nori, Harsha and Jenkins, Samuel and Caruana, Rich and Wallach, Hanna and Wortman Vaughan, Jennifer},
title = {Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376219},
doi = {10.1145/3313831.3376219},
abstract = {Machine learning (ML) models are now routinely deployed in domains ranging from criminal justice to healthcare. With this newfound ubiquity, ML has moved beyond academia and grown into an engineering discipline. To that end, interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study data scientists' use of two existing interpretability tools, the InterpretML implementation of GAMs and the SHAP Python package. We conduct a contextual inquiry (N=11) and a survey (N=197) of data scientists to observe how they use interpretability tools to uncover common issues that arise when building and evaluating ML models. Our results indicate that data scientists over-trust and misuse interpretability tools. Furthermore, few of our participants were able to accurately describe the visualizations output by these tools. We highlight qualitative themes for data scientists' mental models of interpretability tools. We conclude with implications for researchers and tool designers, and contextualize our findings in the social science literature.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interpretability, machine learning, user-centric evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376282,
author = {Blank, Christopher and Zaman, Shaila and Wesley, Amanveer and Tsiamyrtzis, Panagiotis and Da Cunha Silva, Dennis R. and Gutierrez-Osuna, Ricardo and Mark, Gloria and Pavlidis, Ioannis},
title = {Emotional Footprints of Email Interruptions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376282},
doi = {10.1145/3313831.3376282},
abstract = {Working in an environment with constant interruptions is known to affect stress, but how do interruptions affect emotional expression? Emotional expression can have significant impact on interactions among coworkers. We analyzed the video of 26 participants who performed an essay task in a laboratory while receiving either continual email interruptions or receiving a single batch of email. Facial videos of the participants were run through a convolutional neural network to determine the emotional mix via decoding of facial expressions. Using a novel co-occurrence matrix analysis, we showed that with batched email, a neutral emotional state is dominant with sadness being a distant second, and with continual interruptions, this pattern is reversed, and sadness is mixed with fear. We discuss the implications of these results for how interruptions can impact employees' well-being and organizational climate.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {email interruptions, facial expressions, emotions, co-occurence matrix, convolutional neural network},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376670,
author = {Huang, Gaoping and Rao, Pawan S. and Wu, Meng-Han and Qian, Xun and Nof, Shimon Y. and Ramani, Karthik and Quinn, Alexander J.},
title = {Vipo: Spatial-Visual Programming with Functions for Robot-IoT Workflows},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376670},
doi = {10.1145/3313831.3376670},
abstract = {Mobile robots and IoT (Internet of Things) devices can increase productivity, but only if they can be programmed by workers who understand the domain. This is especially true in manufacturing. Visual programming in the spatial context of the operating environment can enable mental models at a familiar level of abstraction. However, spatial-visual programming is still in its infancy; existing systems lack IoT integration and fundamental constructs, such as functions, that are essential for code reuse, encapsulation, or recursive algorithms. We present Vipo, a spatial-visual programming system for robot-IoT workflows. Vipo was designed with input from managers at six factories using mobile robots. Our user study (n=22) evaluated efficiency, correctness, comprehensibility of spatial-visual programming with functions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {spatial visual programming, robots, internet of things},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376149,
author = {Oleson, Alannah and Solomon, Meron and Ko, Amy J.},
title = {Computing Students' Learning Difficulties in HCI Education},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376149},
doi = {10.1145/3313831.3376149},
abstract = {Software developers often make interface design decisions and work with designers. Therefore, computing students who seek to become developers need some education about interface design. While prior work has studied difficulties that educators face when teaching design to computing students, there is comparatively little work on the difficulties computing students face when learning HCI design skills. To uncover these difficulties, we conducted two qualitative studies consisting of surveys and interviews with (1) computing students and (2) educators who teach interface design to computing students. Qualitative analysis of their responses revealed 18 types of learning difficulties students might experience in HCI design education, including difficulties around the mechanics of design work, project management skills, the wicked nature of design problems, and distorted perspectives on design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {hci education, learning difficulties, pedagogical content knowledge, interface design education},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376813,
author = {Wang, Ruotong and Harper, F. Maxwell and Zhu, Haiyi},
title = {Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376813},
doi = {10.1145/3313831.3376813},
abstract = {Algorithmic decision-making systems are increasingly used throughout the public and private sectors to make important decisions or assist humans in making these decisions with real social consequences. While there has been substantial research in recent years to build fair decision-making algorithms, there has been less research seeking to understand the factors that affect people's perceptions of fairness in these systems, which we argue is also important for their broader acceptance. In this research, we conduct an online experiment to better understand perceptions of fairness, focusing on three sets of factors: algorithm outcomes, algorithm development and deployment procedures, and individual differences. We find that people rate the algorithm as more fair when the algorithm predicts in their favor, even surpassing the negative effects of describing algorithms that are very biased against particular demographic groups. We find that this effect is moderated by several variables, including participants' education level, gender, and several aspects of the development procedure. Our findings suggest that systems that evaluate algorithmic fairness through users' feedback must consider the possibility of "outcome favorability" bias.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {algorithmoutcome, algorithm development, perceived fairness, algorithmic decision-making},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376516,
author = {Zhao, Yuhang and Kupferstein, Elizabeth and Rojnirun, Hathaitorn and Findlater, Leah and Azenkot, Shiri},
title = {The Effectiveness of Visual and Audio Wayfinding Guidance on Smartglasses for People with Low Vision},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376516},
doi = {10.1145/3313831.3376516},
abstract = {Wayfinding is a critical but challenging task for people who have low vision, a visual impairment that falls short of blindness. Prior wayfinding systems for people with visual impairments focused on blind people, providing only audio and tactile feedback. Since people with low vision use their remaining vision, we sought to determine how audio feedback compares to visual feedback in a wayfinding task. We developed visual and audio wayfinding guidance on smartglasses based on de facto standard approaches for blind and sighted people and conducted a study with 16 low vision participants. We found that participants made fewer mistakes and experienced lower cognitive load with visual feedback. Moreover, participants with a full field of view completed the wayfinding tasks faster when using visual feedback. However, many participants preferred audio feedback because of its shorter learning curve. We propose design guidelines for wayfinding systems for low vision.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {wayfinding, visual feedback, audio feedback, low vision, accessibility, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376291,
author = {Baykal, G\"{o}k\c{c}e Elif and Van Mechelen, Maarten and Eriksson, Eva},
title = {Collaborative Technologies for Children with Special Needs: A Systematic Literature Review},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376291},
doi = {10.1145/3313831.3376291},
abstract = {This paper presents a systematic literature review on collaborative technologies for children with special needs in ACM Digital Library. The aim of the review is to (1) reveal the current state of the art, (2) identify the types of technologies and contexts of use, the demographics and special needs of the target group, and the methodological approaches and theoretical groundings, and (3) define a future research agenda. The results of the systematic literature review show that collaborative technologies for children with special needs are increasingly gaining attention, mostly involve tangible and/or embodied interaction, and are often developed for use in the classroom. The target group that is most represented are boys between 6 to 12 years with Autism Spectrum Disorder. The results further show a wide range of evaluation criteria for measuring collaboration, an interchanging use of theoretical concepts and a lack of definitions for the concept collaboration, and a need for more demographically diverse studies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cci, special need, collaboration, collaborative technologies, collaborative learning, systematic literature review},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376512,
author = {Preechayasomboon, Pornthep and Israr, Ali and Samad, Majed},
title = {Chasm: A Screw Based Expressive Compact Haptic Actuator},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376512},
doi = {10.1145/3313831.3376512},
abstract = {We present a compact broadband linear actuator, Chasm, that renders expressive haptic feedback on wearable and handheld devices. Unlike typical motor-based haptic devices with integrated gearheads, Chasm utilizes a miniature leadscrew coupled to a motor shaft, thereby directly translating the high-speed rotation of the motor to the linear motion of a nut carriage without an additional transmission. Due to this simplicity, Chasm can render low-frequency skin-stretch and high-frequency vibrations, simultaneously and independently. We present the design of the actuator assembly and validate its electromechanical and perceptual performance. We then explore use cases and show design solutions for embedding Chasm in device prototypes. Finally, we report investigations with Chasm in two VR embodiments, i.e., in a headgear band to induce locomotion cues and in a handheld pointer to enhance dynamic manual interactions. Our explorations show wide use for Chasm in enhancing user interactions and experience in virtual and augmented settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multidimensional haptics, skin stretch, handheld haptics, wearable haptics, haptic devices},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376466,
author = {Pu, Xiaoying and Kay, Matthew},
title = {A Probabilistic Grammar of Graphics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376466},
doi = {10.1145/3313831.3376466},
abstract = {Visualizations depicting probabilities and uncertainty are used everywhere from medical risk communication to machine learning, yet these probabilistic visualizations are difficult to specify, prone to error, and their designs are cumbersome to explore. We propose a Probabilistic Grammar of Graphics (PGoG), an extension to Wilkinson's original framework. Inspired by the success of probabilistic programming languages, PGoG makes probability expressions, such as P(A|B), a first-class citizen in the language. PGoG abstractions also reflect the distinction between probability and frequency framing, a concept from the uncertainty communication literature. It is expressive, encompassing product plots, density plots, icon arrays, and dotplots, among other visualizations. Its coherent syntax ensures correctness (that the proportions of visual elements and their spatial placement reflect the underlying probability distribution) and reduces edit distance between probabilistic visualization specifications, potentially supporting more design exploration. We provide a proof-of-concept implementation of PGoG in R.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {grammar of graphics, uncertainty visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376272,
author = {Sheshadri, Smitha and Zhao, Shengdong and Chen, Yang and Fjeld, Morten},
title = {Learn with Haptics: Improving Vocabulary Recall with Free-Form Digital Annotation on Touchscreen Mobiles},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376272},
doi = {10.1145/3313831.3376272},
abstract = {Mobile vocabulary learning interfaces typically present material only in auditory and visual channels, underutilizing the haptic modality. We explored haptic-integrated learning by adding free-form digital annotation to mobile vocabulary learning interfaces. Through a series of pilot studies, we identified three design factors: annotation mode, presentation sequence, and vibrotactile feedback, that influence recall in haptic-integrated vocabulary interfaces. These factors were then evaluated in a within-subject comparative study using a digital flashcard interface as baseline. Results using a 84-item vocabulary showed that the 'whole word' annotation mode is highly effective, yielding a 24.21% increase in immediate recall scores and a 30.36% increase in the 7-day delayed scores. Effects of presentation sequence and vibrotactile feedback were more transient; they affected the results of immediate tests, but not the delayed tests. We discuss the implications of these factors for designing future mobile learning applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {haptics for learning, motoric engagement, multimodal learning, intersensory reinforced learning, mobile vocabulary learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376150,
author = {Warner, Mark and Kitkowska, Agnieszka and Gibbs, Jo and Maestre, Juan F. and Blandford, Ann},
title = {Evaluating 'Prefer Not to Say' Around Sensitive Disclosures},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376150},
doi = {10.1145/3313831.3376150},
abstract = {As people's offline and online lives become increasingly entwined, the sensitivity of personal information disclosed online is increasing. Disclosures often occur through structured disclosure fields (e.g., drop-down lists). Prior research suggests these fields may limit privacy, with non-disclosing users being presumed to be hiding undesirable information. We investigated this around HIV status disclosure in online dating apps used by men who have sex with men. Our online study asked participants (N=183) to rate profiles where HIV status was either disclosed or undisclosed. We tested three designs for displaying undisclosed fields. Visibility of undisclosed fields had a significant effect on the way profiles were rated, and other profile information (e.g., ethnicity) could affect inferences that develop around undisclosed information. Our research highlights complexities around designing for non-disclosure and questions the voluntary nature of these fields. Further work is outlined to ensure disclosure control is appropriately implemented around online sensitive information disclosures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {online privacy, disclosure, privacy, online dating, structured disclosure fields, prefer not to say, non-disclosure, privacy unraveling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376167,
author = {McDonald, Nora and Forte, Andrea},
title = {The Politics of Privacy Theories: Moving from Norms to Vulnerabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376167},
doi = {10.1145/3313831.3376167},
abstract = {Privacy and surveillance are central features of public discourse around use of computing systems. As the systems we design and study are increasingly used and regulated as potential instruments of surveillance, HCI researchers-even those whose focus is not privacy-find themselves needing to understand privacy in their work. Concepts like contextual integrity and boundary regulation have become touchstones for thinking about privacy in HCI. In this paper, we draw on HCI and privacy literature to understand the limitations of commonly used theories and examine their assumptions, politics, strengths, and weaknesses. We use a case study from the HCI literature to illustrate conceptual gaps in existing frameworks where privacy requirements can fall through. Finally, we advocate vulnerability as a core concept for privacy theorizing and examine how feminist, queer-Marxist, and intersectional thinking may augment our existing repertoire of privacy theories to create a more inclusive scholarship and design practice.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {feminist intersectional theory, queer theory, privacy theory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376445,
author = {Madaio, Michael A. and Stark, Luke and Wortman Vaughan, Jennifer and Wallach, Hanna},
title = {Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376445},
doi = {10.1145/3313831.3376445},
abstract = {Many organizations have published principles intended to guide the ethical development and deployment of AI systems; however, their abstract nature makes them difficult to operationalize. Some organizations have therefore produced AI ethics checklists, as well as checklists for more specific concepts, such as fairness, as applied to AI systems. But unless checklists are grounded in practitioners' needs, they may be misused. To understand the role of checklists in AI ethics, we conducted an iterative co-design process with 48 practitioners, focusing on fairness. We co-designed an AI fairness checklist and identified desiderata and concerns for AI fairness checklists in general. We found that AI fairness checklists could provide organizational infrastructure for formalizing ad-hoc processes and empowering individual advocates. We highlight aspects of organizational culture that may impact the efficacy of AI fairness checklists, and suggest future design directions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ML, ethics, AI, co-design, checklists, fairness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376241,
author = {Heyer, Jeremy and Schmitt, Zachary and Dombrowski, Lynn and Yarosh, Svetlana},
title = {Opportunities for Enhancing Access and Efficacy of Peer Sponsorship in Substance Use Disorder Recovery},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376241},
doi = {10.1145/3313831.3376241},
abstract = {Substance use disorders (SUDs) are characterized by an inability to decrease a substance use (e.g., alcohol or opioids) despite negative repercussions. SUDs are clinically diagnosable, hazardous, and considered a public health issue. Sponsorship, a specialized type of peer mentorship, is vital in the recovery process and originates from 12-step fellowship programs such as Alcoholics Anonymous (AA) and Narcotics Anonymous (NA). To investigate sponsorship relationship practices and to identify design opportunities for digitally-mediated peer support, we conducted 27 in-depth interviews with members of AA and NA. We identified five key sponsorship relationship practices relevant for designing social computing tools to support sponsorship and recovery: 1) assessing dyadic compatibility, 2) managing sponsorship with or without technology, 3) establishing boundaries, 4) building a peer support network, and 5) managing anonymity. We identify social computing and digitally-mediated design opportunities and implications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {technology for substance use, 12-step fellowships, peer health support, addiction, substance use disorders, recovery},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376566,
author = {Babaei, Ebrahim and Srivastava, Namrata and Newn, Joshua and Zhou, Qiushi and Dingler, Tilman and Velloso, Eduardo},
title = {Faces of Focus: A Study on the Facial Cues of Attentional States},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376566},
doi = {10.1145/3313831.3376566},
abstract = {Automatically detecting attentional states is a prerequisite for designing interventions to manage attention - knowledge workers' most critical resource. As a first step towards this goal, it is necessary to understand how different attentional states are made discernible through visible cues in knowledge workers. In this paper, we demonstrate the important facial cues to detect attentional states by evaluating a data set of 15 participants that we tracked over a whole workday, which included their challenge and engagement levels. Our evaluation shows that gaze, pitch, and lips part action units are indicators of engaged work; while pitch, gaze movements, gaze angle, and upper-lid raiser action units are indicators of challenging work. These findings reveal a significant relationship between facial cues and both engagement and challenge levels experienced by our tracked participants. Our work contributes to the design of future studies to detect attentional states based on facial cues.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {focus, attentional state, challenge, facial expression, engagement},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376323,
author = {Zhang, Tengxiang and Zeng, Xin and Zhang, Yinshuai and Sun, Ke and Wang, Yuntao and Chen, Yiqiang},
title = {ThermalRing: Gesture and Tag Inputs Enabled by a Thermal Imaging Smart Ring},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376323},
doi = {10.1145/3313831.3376323},
abstract = {The heterogeneous and ubiquitous input demands in smart spaces call for an input device that can enable rich and spontaneous interactions. We propose ThermalRing, a thermal imaging smart ring using low-resolution thermal camera for identity-anonymous, illumination-invariant, and power-efficient sensing of both dynamic and static gestures. We also design ThermalTag, thin and passive thermal imageable tags that reflect the heat from the human hand. ThermalTag can be easily made and applied onto everyday objects by users. We develop sensing techniques for three typical input demands: drawing gestures for device pairing, click and slide gestures for device control, and tag scan gestures for quick access. The study results show that ThermalRing can recognize nine drawing gestures with an overall accuracy of 90.9%, detect click gestures with an accuracy of 94.9%, and identify among six ThermalTags with an overall accuracy of 95.0%. Finally, we show the versatility and potential of ThermalRing through various applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart ring, thermal imaging, gesture recognition, interactive tags},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376662,
author = {Shipman, Frank M. and Marshall, Catherine C.},
title = {Ownership, Privacy, and Control in the Wake of Cambridge Analytica: The Relationship between Attitudes and Awareness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376662},
doi = {10.1145/3313831.3376662},
abstract = {Has widespread news of abuse changed the public's perceptions of how user-contributed content from social networking sites like Facebook and LinkedIn can be used? We collected two datasets that reflect participants' attitudes about content ownership, privacy, and control, one in April 2018, while Cambridge Analytica was still in the news, and another in February 2019, after the event had faded from the headlines, and aggregated the data according to participants' awareness of the story, contrasting the attitudes of those who reported the greatest awareness with those who reported the least. Participants with the greatest awareness of the news story's details have more polarized attitudes about reuse, especially the reuse of content as data. They express a heightened desire for data mobility, greater concern about networked privacy rights, increased skepticism of algorithmically targeted advertising and news, and more willingness for social media platforms to demand corrections of inaccurate or deceptive content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {facebook, cambridge analytica, privacy, linkedin, social media attitudes, ownership, data monetization, data use},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376476,
author = {Huang, Hsin-Yu and Ning, Chih-Wei and Wang, Po-Yao and Cheng, Jen-Hao and Cheng, Lung-Pan},
title = {Haptic-Go-Round: A Surrounding Platform for Encounter-Type Haptics in Virtual Reality Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376476},
doi = {10.1145/3313831.3376476},
abstract = {We present Haptic-go-round, a surrounding platform that allows deploying props and devices to provide haptic feedbacks in any direction in virtual reality experiences. The key component of Haptic-go-round is a motorized turntable that rotates the correct haptic device to the right direction at the right time to match what users are about to touch. We implemented a working platform including plug-and-play prop cartridges and a software interface that allow experience designers to agilely add their haptic components and use the platform for their applications. We conducted technical experiments and two user studies on Haptic-go-round to evaluate its performance. We report the results and discuss our insights and limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {props, virtual reality, encounter-type haptic feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376331,
author = {Zarei, Niloofar and Chu, Sharon Lynn and Quek, Francis and Rao, Nanjie 'Jimmy' and Brown, Sarah Anne},
title = {Investigating the Effects of Self-Avatars and Story-Relevant Avatars on Children's Creative Storytelling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376331},
doi = {10.1145/3313831.3376331},
abstract = {Storytelling is a critical step in the cognitive development of children. Particularly, this requires children to mentally project into the story context and to identify with the thoughts of the characters in their stories. We propose to support free imagination in creative storytelling through an enactment-based approach that allows children to embody an avatar and perform as the story character. We designed our story creation interface with two modes of avatar: the story-relevant avatar and the self-avatar, to investigate the effects of avatar design on the quality of children's creative products. In our study with 20 child participants, the results indicate that self-avatars can create a stronger sense of identification and embodied presence, while story-relevant avatars can provide a scaffold for mental projection.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {embodied interaction, virtual reality, expressive writing, storytelling, creativity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376608,
author = {Alshehri, Taghreed and Kirkham, Reuben and Olivier, Patrick},
title = {Scenario Co-Creation Cards: A Culturally Sensitive Tool for Eliciting Values},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376608},
doi = {10.1145/3313831.3376608},
abstract = {Values are an integral part of human identity and have a pervasive impact upon human behavior. This makes understanding them a central concern in the design of technology, as exemplified by approaches such as Value Sensitive Design ("VSD"). Identifying and concreting the values held by a given population can be a difficult endeavor, especially where there is a cultural barrier limiting an effective discussion of them, for example in societies where freedom of expression is discouraged. Addressing this concern requires an in-depth consideration of appropriate value elicitation methods, which responds to the fact that it is not possible to understand values detached from their cultural context. We introduce a novel implicit method, Scenario Co-Creation Cards, and show how it can be used to incorporate existing models of culture in the value elicitation process. We demonstrate this in a case study of Saudi women's visibility in the digital media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {value elicitation, vsd, scenarios, values, method, user research, cards, saudi arabia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376354,
author = {Kotut, Lindah and Bhatti, Neelma and Saaty, Morva and Haqq, Derek and Stelter, Timothy L. and McCrickard, D. Scott},
title = {Clash of Times: Respectful Technology Space for Integrating Community Stories in Intangible Exhibits},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376354},
doi = {10.1145/3313831.3376354},
abstract = {Emerging research in Human Computer Interaction (HCI) has considered the use of technology to preserve Intangible Cultural Heritage (ICH) while wrestling with the dilemma of local participation in the face of post-colonialism. There remains a need to understand how ICH is portrayed by museums and texts, how communities regard these representations, and how technology would affect preservation. We conducted a study in the North Rift region of Kenya to understand how ICH is preserved and disseminated by the museum in comparison with the community. The findings describe a respectful technology space where community needs and museum needs can co-exist. We also articulate social challenges that should be considered by designers when recommending or designing technological solutions. This paper concludes by recommending ways for researchers to smoothly integrate technology with ICH through community participation and an awareness of the respectful space.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {indigenous knowledge, respectful technology, post-colonial computing, intangible cultural heritage, hci4d},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376235,
author = {Zhang, Xiong and Engel, Jonathan and Evensen, Sara and Li, Yuliang and Demiralp, \c{C}a\u{g}atay and Tan, Wang-Chiew},
title = {Teddy: A System for Interactive Review Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376235},
doi = {10.1145/3313831.3376235},
abstract = {Reviews are integral to e-commerce services and products. They contain a wealth of information about the opinions and experiences of users, which can help better understand consumer decisions and improve user experience with products and services. Today, data scientists analyze reviews by developing rules and models to extract, aggregate, and understand information embedded in the review text. However, working with thousands of reviews, which are typically noisy incomplete text, can be daunting without proper tools. Here we first contribute results from an interview study that we conducted with fifteen data scientists who work with review text, providing insights into their practices and challenges. Results suggest data scientists need interactive systems for many review analysis tasks. Towards a solution, we then introduce Teddy, an interactive system that enables data scientists to quickly obtain insights from reviews and improve their extraction and modeling pipelines.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive systems, review analysis, contextual interviews, data science, text mining, schema generation, sentiment analysis, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376381,
author = {Nobre, Carolina and Wootton, Dylan and Harrison, Lane and Lex, Alexander},
title = {Evaluating Multivariate Network Visualization Techniques Using a Validated Design and Crowdsourcing Approach},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376381},
doi = {10.1145/3313831.3376381},
abstract = {Visualizing multivariate networks is challenging because of the trade-offs necessary for effectively encoding network topology and encoding the attributes associated with nodes and edges. A large number of multivariate network visualization techniques exist, yet there is little empirical guidance on their respective strengths and weaknesses. In this paper, we describe a crowdsourced experiment, comparing node-link diagrams with on-node encoding and adjacency matrices with juxtaposed tables. We find that node-link diagrams are best suited for tasks that require close integration between the network topology and a few attributes. Adjacency matrices perform well for tasks related to clusters and when many attributes need to be considered. We also reflect on our method of using validated designs for empirically evaluating complex, interactive visualizations in a crowdsourced setting. We highlight the importance of training, compensation, and provenance tracking.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {multivariate networks visualization, crowdsourced evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376499,
author = {Tuncer, Sylvaine and Brown, Barry},
title = {E-Scooters on the Ground: Lessons for Redesigning Urban Micro-Mobility},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376499},
doi = {10.1145/3313831.3376499},
abstract = {The worldwide deployment of rental electric scooters has generated new opportunities for urban mobility, but also intensified conflict over public space. This article reports on an ethnographic study of both rental and privately-owned e-scooters, mapping out the main problems and potentials around this new form of 'micro-mobility'. While it suffers from problems of reliability and conflict, user experience is an important part of e-scooters' appeal, an enjoyable way of 'hacking the city'. E-scooters have a hybrid character: weaving through the city, riders can switch between riding as a pedestrian, a car or a bicycle. Building on these results, we discuss how e-scooters, ridesharing services, and their apps could develop further, alongside the role for HCI in re-thinking urban transport and vehicle design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {micro-mobility, vehicle design, intermodal mobility, co-ordination in mobile interactions, user experience, electric scooters},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376601,
author = {Zhou, Qian and Wu, Fan and Fels, Sidney and Stavness, Ian},
title = {Closer Object Looks Smaller: Investigating the Duality of Size Perception in a Spherical Fish Tank VR Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376601},
doi = {10.1145/3313831.3376601},
abstract = {Fish Tank Virtual Reality (FTVR) displays provide compelling 3D experiences by rendering view-dependent imagery on a 2D screen. While users perceive a 3D object in space, they are actually looking at pixels on a 2D screen, thus, a perceptual duality exists between the object's pixels and the 3D percept potentially interfering with the experience. To investigate, we conducted an experiment to see whether the on-screen size of the 2D imagery affects the perceived object size in 3D space with different viewing conditions, including stereopsis. We found that the size of on-screen imagery significantly influenced object size perception, causing 83.3% under/overestimation of perceived size when viewing without stereopsis and reducing to 64.7% with stereopsis. Contrary to reality, objects look smaller when the viewer gets closer. Understanding the perceptual duality helps us to provide accurate perception of real-world objects depicted in the virtual environment and pave the way for 3D applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {spherical display, fish tank virtual reality, 3d perception},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376623,
author = {Marcu, Gabriela and Spiller, Allison N.},
title = {Collaborative Aspects of Collecting and Reflecting on Behavioral Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376623},
doi = {10.1145/3313831.3376623},
abstract = {Direct observation of behavior provides a unique type of data for reflecting on during a process of behavioral intervention. This study focuses on practitioners who specialize in operationalizing, recording, and monitoring behavior using data collection through paper-and-pencil or, increasingly, mobile computing. Applying an action research approach, we conducted fieldwork to understand observational data collection among practitioners providing children with special education support for behavioral needs. We present a model of collaborative data collection, which describes how practices are situated in the process of collecting data that are useful for reflection by teams of practitioners. We discuss how computer-assisted data collection could promote more systematic and rigorous practices, and design considerations for the collaborative aspects of collecting and reflecting on behavioral data. This study builds on research describing the practices of individuals who track their own behavioral data, and improves our understanding of informal documentation practices in organizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {computer-assisted data collection, behavioral intervention, action research},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376229,
author = {Saxena, Devansh and Badillo-Urquiola, Karla and Wisniewski, Pamela J. and Guha, Shion},
title = {A Human-Centered Review of Algorithms Used within the U.S. Child Welfare System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376229},
doi = {10.1145/3313831.3376229},
abstract = {The U.S. Child Welfare System (CWS) is charged with improving outcomes for foster youth; yet, they are overburdened and underfunded. To overcome this limitation, several states have turned towards algorithmic decision-making systems to reduce costs and determine better processes for improving CWS outcomes. Using a human-centered algorithmic design approach, we synthesize 50 peer-reviewed publications on computational systems used in CWS to assess how they were being developed, common characteristics of predictors used, as well as the target outcomes. We found that most of the literature has focused on risk assessment models but does not consider theoretical approaches (e.g., child-foster parent matching) nor the perspectives of caseworkers (e.g., case notes). Therefore, future algorithms should strive to be context-aware and theoretically robust by incorporating salient factors identified by past research. We provide the HCI community with research avenues for developing human-centered algorithms that redirect attention towards more equitable outcomes for CWS.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {child welfare system, human-centered algorithm design, algorithmic decision-making},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376619,
author = {Kim, Jinsoo and Oh, Seungjae and Park, Chaeyong and Choi, Seungmoon},
title = {Body-Penetrating Tactile Phantom Sensations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376619},
doi = {10.1145/3313831.3376619},
abstract = {In tactile interaction, a phantom sensation refers to an illusion felt on the skin between two distant points at which vibrations are applied. It can improve the perceptual spatial resolution of tactile stimulation with a few tactors. All phantom sensations reported in the literature act on the skin or out of the body, but no such reports exist for those eliciting sensations penetrating the body. This paper addresses tactile phantom sensations in which two vibration actuators on the dorsal and palmar sides of the hand present an illusion of vibration passing through the hand. We also demonstrate similar tactile illusions for the torso. For optimal design, we conducted user studies while varying vibration frequency, envelope function, stimulus duration, and penetrating direction. Based on the results, we present design guidelines on penetrating phantom sensations for its use in immersive virtual reality applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {phantom sensation, penetrating tactile sensation, vibrotactile feedback, tactile illusion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376352,
author = {Mironcika, Svetlana and Hupfeld, Annika and Frens, Joep and Wensveen, Stephan},
title = {I Am Not an Object: Reframing 3D Body Scanning for Co-Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376352},
doi = {10.1145/3313831.3376352},
abstract = {3D scanning technologies provide designers with tools to generate a digital representation of the human body that can be used in the design of ultra-personalized apparel and wearables. However, prior work shows that the body scanning process can be an uncomfortable experience for users. In this work, we take a first-person perspective to identify frictions in the experience of being body scanned compared to having one's body measurements taken by a professional tailor. Based on our findings, we offer a reframing of body scanning as a collaborative process, and discuss implications for the design of tools and processes that shift agency in the generation of body data towards users. Our paper is relevant to design researchers and practitioners interested in taking a co-design approach to ultra-personalization.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {personal data., 3d body scanning, 3d body data visualization, co-design, wearables, autoethnography, personalization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376574,
author = {Freiwald, Jann Philipp and Ariza, Oscar and Janeh, Omar and Steinicke, Frank},
title = {Walking by Cycling: A Novel In-Place Locomotion User Interface for Seated Virtual Reality Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376574},
doi = {10.1145/3313831.3376574},
abstract = {We introduce VR Strider, a novel locomotion user interface (LUI) for seated virtual reality (VR) experiences, which maps cycling biomechanics of the user's legs to virtual walking movements. The core idea is to translate the motion of pedaling on a mini exercise bike to a corresponding walking animation of a virtual avatar while providing audio-based tactile feedback on virtual ground contacts. We conducted an experiment to evaluate the LUI and our novel anchor-turning rotation control method regarding task performance, spatial cognition, VR sickness, sense of presence, usability and comfort in a path-integration task. The results show that VR Strider has a significant positive effect on the participants' angular and distance estimation, sense of presence and feeling of comfort compared to other established locomotion techniques, such as teleportation and joystick-based navigation. A confirmatory study further indicates the necessity of synchronized avatar animations for virtual vehicles that rely on pedalling.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, input techniques, embodied interaction, locomotion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376733,
author = {Batch, Andrea and Patnaik, Biswaksen and Akazue, Moses and Elmqvist, Niklas},
title = {Scents and Sensibility: Evaluating Information Olfactation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376733},
doi = {10.1145/3313831.3376733},
abstract = {Olfaction---the sense of smell---is one of the least explored of the human senses for conveying abstract information. In this paper, we conduct a comprehensive perceptual experiment on information olfactation: the use of olfactory and cross-modal sensory marks and channels to convey data. More specifically, following the example from graphical perception studies, we design an experiment that studies the perceptual accuracy of four cross-modal sensory channels---scent type, scent intensity, airflow, and temperature---for conveying three different types of data---nominal, ordinal, and quantitative. We also present details of a 24-scent multi-sensory display and its software framework that we designed in order to run this experiment. Our results yield a ranking of olfactory and cross-modal sensory channels that follows similar principles as classic rankings for visual channels.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {olfactory displays, smell, olfactory perception, information olfactation, evaluation, scents},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376727,
author = {Long, Duri and Magerko, Brian},
title = {What is AI Literacy? Competencies and Design Considerations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376727},
doi = {10.1145/3313831.3376727},
abstract = {Artificial intelligence (AI) is becoming increasingly integrated in user-facing technology, but public understanding of these technologies is often limited. There is a need for additional HCI research investigating a) what competencies users need in order to effectively interact with and critically evaluate AI and b) how to design learner-centered AI technologies that foster increased user understanding of AI. This paper takes a step towards realizing both of these goals by providing a concrete definition of AI literacy based on existing research. We synthesize a variety of interdisciplinary literature into a set of core competencies of AI literacy and suggest several design considerations to support AI developers and educators in creating learner-centered AI. These competencies and design considerations are organized in a conceptual framework thematically derived from the literature. This paper's contributions can be used to start a conversation about and guide future research on AI literacy within the HCI community.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {AI education, AI for K-12, machine learning, AI literacy, artificial intelligence, computing education},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376388,
author = {Spillane, Brendan and Hoe, Isla and Brady, Mike and Wade, Vincent and Lawless, S\'{e}amus},
title = {Tabloidization versus Credibility: Short Term Gain for Long Term Pain},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376388},
doi = {10.1145/3313831.3376388},
abstract = {Print news agencies have been under pressure from falling sales and advertising revenue and increased competition. As the Internet became the dominant medium, news agencies invested heavily in their websites and apps, providing their news for free, rather than selling a print edition. Reducing the cost of production and removing access barriers such as geographic location had the potential to increase readership and advertising, covering costs and maintaining profits. Unfortunately, this business model has for the most part failed. Many higher quality news agencies are now implementing paywalls on their news websites to once again monetize their product. Others have begun to emulate the look and feel of tabloid news websites to increase readership and stickiness and advertising revenue. This study shows the negative impact of such visual tabloidization on initial impressions of credibility, which may have long term detrimental effects on the news agency.The authors would like to dedicate this paper to the memory of Professor S\'{e}amus "Shay" Lawless, the supervisor of this work who died on May 16th 2019 after fulfilling his dream of summiting Mount Everest.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {credibility, news website design, tabloidization, first impressions, news website aesthetics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376838,
author = {Han, Changyo and Takahashi, Ryo and Yahagi, Yuchi and Naemura, Takeshi},
title = {PneuModule: Using Inflatable Pin Arrays for Reconfigurable Physical Controls on Pressure-Sensitive Touch Surfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376838},
doi = {10.1145/3313831.3376838},
abstract = {We present PneuModule, a tangible interface platform that enables users to reconfigure physical controls on pressure-sensitive touch surfaces using pneumatically-actuated inflatable pin arrays. PneuModule consists of a main module and extension modules. The main module is tracked on the touch surface and forwards continuous inputs from attached multiple extension modules to the touch surface. Extension modules have distinct mechanisms for user input, which pneumatically actuates the inflatable pins at the bottom of the main module through internal air pipes. The main module accepts multi-dimensional inputs since each pin is individually inflated by the corresponding air chamber. Also, since the extension modules are swappable and identifiable owing to the marker design, users can quickly customize the interface layout. We contribute to design details of inflatable pins and diverse pneumatic input control design examples for PneuModule. We also showcase the feasibility of PneuModule through a series of evaluations and interactive prototypes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {pneumatic actuation, tangible user interfaces, reconfigurable physical controls, pressure-sensitive touch surfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376162,
author = {Koelle, Marion and Ananthanarayan, Swamy and Boll, Susanne},
title = {Social Acceptability in HCI: A Survey of Methods, Measures, and Design Strategies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376162},
doi = {10.1145/3313831.3376162},
abstract = {With the increasing ubiquity of personal devices, social acceptability of human-machine interactions has gained relevance and growing interest from the HCI community. Yet, there are no best practices or established methods for evaluating social acceptability. Design strategies for increasing social acceptability have been described and employed, but so far not been holistically appraised and evaluated. We offer a systematic literature analysis (N=69) of social acceptability in HCI and contribute a better understanding of current research practices, namely, methods employed, measures and design strategies. Our review identified an unbalanced distribution of study approaches, shortcomings in employed measures, and a lack of interweaving between empirical and artifact-creating approaches. The latter causes a discrepancy between design recommendations based on user research, and design strategies employed in artifact creation. Our survey lays the groundwork for a more nuanced evaluation of social acceptability, the development of best practices, and a future research agenda.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–19},
numpages = {19},
keywords = {social acceptability, research methods, literature analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376682,
author = {El Ali, Abdallah and Yang, Xingyu and Ananthanarayan, Swamy and R\"{o}ggla, Thomas and Jansen, Jack and Hartcher-O'Brien, Jess and Jansen, Kaspar and Cesar, Pablo},
title = {ThermalWear: Exploring Wearable On-Chest Thermal Displays to Augment Voice Messages with Affect},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376682},
doi = {10.1145/3313831.3376682},
abstract = {Voice is a rich modality for conveying emotions, however emotional prosody production can be situationally or medically impaired. Since thermal displays have been shown to evoke emotions, we explore how thermal stimulation can augment perception of neutrally-spoken voice messages with affect. We designed ThermalWear, a wearable on-chest thermal display, then tested in a controlled study (N=12) the effects of fabric, thermal intensity, and direction of change. Thereafter, we synthesized 12 neutrally-spoken voice messages, validated (N=7) them, then tested (N=12) if thermal stimuli can augment their perception with affect. We found warm and cool stimuli (a) can be perceived on the chest, and quickly without fabric (4.7-5s) (b) do not incur discomfort (c) generally increase arousal of voice messages and (d) increase / decrease message valence, respectively. We discuss how thermal displays can augment voice perception, which can enhance voice assistants and support individuals with emotional prosody impairments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {voice, display, emotion, affect, prosody, chest, wearable, thermal},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376642,
author = {Wang, Cheng Yao and Sakashita, Mose and Ehsan, Upol and Li, Jingjin and Won, Andrea Stevenson},
title = {Again, Together: Socially Reliving Virtual Reality Experiences When Separated},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376642},
doi = {10.1145/3313831.3376642},
abstract = {To share a virtual reality (VR) experience remotely together, users usually record videos from an individual's point of view and then co-watch these videos. However, co-watching recorded videos limits users to reliving their memories from the perspective from which the video was captured. In this paper, we describe ReliveInVR, a new time-machine-like VR experience sharing method. ReliveInVR allows multiple users to immerse themselves in the relived experience together and independently view the experience from any perspective. We conducted a 1x3 within-subject study with 26 dyads to compare ReliveInVR with (1) co-watching 360-degree videos on desktop, and (2) co-watching 360-degree videos in VR. Our results suggest that participants reported higher levels of immersion and social presence in ReliveInVR. Participants in ReliveInVR also understood the shared experience better, discovered unnoticed things together and found the sharing experience more fulfilling. We discuss the design implications for sharing VR experiences over time and space.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {presence, immersion, virtual reality, social, shared experience, replay},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376446,
author = {Frommel, Julian and Sagl, Valentin and Depping, Ansgar E. and Johanson, Colby and Miller, Matthew K. and Mandryk, Regan L.},
title = {Recognizing Affiliation: Using Behavioural Traces to Predict the Quality of Social Interactions in Online Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376446},
doi = {10.1145/3313831.3376446},
abstract = {Online social interactions in multiplayer games can be supportive and positive or toxic and harmful; however, few methods can easily assess interpersonal interaction quality in games. We use behavioural traces to predict affiliation between dyadic strangers, facilitated through their social interactions in an online gaming setting. We collected audio, video, in-game, and self-report data from 23 dyads, extracted 75 features, trained Random Forest and Support Vector Machine models, and evaluated their performance predicting binary (high/low) as well as continuous affiliation toward a partner. The models can predict both binary and continuous affiliation with up to 79.1% accuracy (F1) and 20.1% explained variance (R2) on unseen data, with features based on verbal communication demonstrating the highest potential. Our findings can inform the design of multiplayer games and game communities, and guide the development of systems for matchmaking and mitigating toxic behaviour in online games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {cooperative games, bonding, affiliation, social interaction, recognition, prediction, machine learning, evaluation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376705,
author = {Maekawa, Azumi and Matsubara, Seito and Wakisaka, Sohei and Uriu, Daisuke and Hiyama, Atsushi and Inami, Masahiko},
title = {Dynamic Motor Skill Synthesis with Human-Machine Mutual Actuation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376705},
doi = {10.1145/3313831.3376705},
abstract = {This paper presents an approach for coupling robotic capability with human ability in dynamic motor skills, called "Human-Machine Mutual Actuation (HMMA)." We focus specifically on throwing motions and propose a method to control the release timing computationally. A system we developed achieves our concept, HMMA, by a robotic handheld device that acts as a release controller. We conducted user studies to validate the feasibility of the concept and clarify related technical issues to be tackled. We recognized that the system successfully performs on throwing according to the target while it exploits human ability. These empirical experiments suggest that robotic capability can be embedded into the users' motions without losing their senses of control. Throughout the user study, we also revealed several issues to be tackled in further research contributing to HMMA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human augmentation, motion sensing, human-machine mutual actuation, motor skill, robotic device},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376872,
author = {Baceviciute, Sarune and Mottelson, Aske and Terkildsen, Thomas and Makransky, Guido},
title = {Investigating Representation of Text and Audio in Educational VR Using Learning Outcomes and EEG},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376872},
doi = {10.1145/3313831.3376872},
abstract = {This paper reports findings from a between-subjects experiment that investigates how different learning content representations in virtual environments (VE) affect the process and outcomes of learning. Seventy-eight participants were subjected to an immersive virtual reality (VR) application, where they received identical instructional information, rendered in three different formats: as text in an overlay interface, as text embedded semantically in a virtual book, or as audio. Learning outcome measures, self-reports, and an electroencephalogram (EEG) were used to compare conditions. Results show that reading was superior to listening for the learning outcomes of retention, self-efficacy, and extraneous attention. Reading text from a virtual book was reported to be less cognitively demanding, compared to reading from an overlay interface. EEG analyses show significantly lower theta and higher alpha activation in the audio condition. The findings provide important considerations for the design of educational VR environments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {educational technology, eeg, learning, cognitive load, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376169,
author = {Iivari, Netta and Kinnula, Marianne and Kuure, Leena and Keisanen, Tiina},
title = {"Arseing around Was Fun!" – Humor as a Resource in Design and Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376169},
doi = {10.1145/3313831.3376169},
abstract = {Humor is an inevitable part of human life. Most of us are capable of experiencing and appreciating humor. From this perspective, surprisingly little HCI research can be found scrutinizing the existence, role, and potential of humor in our design practice. The gap remains also related to children and teenagers; there is a lack of studies appreciating the emergence and existence of humor in the design process without intentionally evoking it. Thus, this study examines humor as a naturally occurring phenomenon in the design process. The study was conducted in collaboration with a class of teenagers and their teachers. The study identifies various forms and functions of humor in the design process and reveals its situated, emergent nature as a resource in interaction within design. The study proposes a practical tool for designers for anticipating and potentially facilitating the emergence, forms and usages of humor as an interactional resource in design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design, teenager, interaction, nexus analysis, humor, children, making in education, discourse},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376678,
author = {Eriksson, Sara and H\"{o}\"{o}k, Kristina and Shusterman, Richard and Svanes, Dag and Unander-Scharin, Carl and Unander-Scharin, \r{A}sa},
title = {Ethics in Movement: Shaping and Being Shaped in Human-Drone Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376678},
doi = {10.1145/3313831.3376678},
abstract = {How is ethics shaped by the particularities of a design? Through a detailed video analysis, we explore how ethicality is shaped in interaction between a choreographer, a performer and a choir of five drones, performing together on the opera stage. We pinpoint how movements enabled by the human-drone assemblage may limit or liberate artistic expressions vis-\`{a}-vis the norms of operatic performance. From a somaesthetics perspective on ethics, we show how the process of crafting rich experiences together with drones can deepen sensory appreciation skills, leading to an increased understanding of underlying somatic drivers and imposed norms. Somatic awareness thereby enables a richer repertoire of movements, expanding the ability to freely choose how to act, and cultivating empathy towards others. This shifts our understanding of ethics in HCI as solely about abstract rules or policies 'out there' to also concern the specifics of how technology informs or dictates movement and experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {somaesthetics, drones, soma design, movement, ethics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376592,
author = {Chen, Yuan and Katsuragawa, Keiko and Lank, Edward},
title = {Understanding Viewport- and World-Based Pointing with Everyday Smart Devices in Immersive Augmented Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376592},
doi = {10.1145/3313831.3376592},
abstract = {Personal smart devices have demonstrated a variety of efficient techniques for pointing and selecting on physical displays. However, when migrating these input techniques to augmented reality, it is both unclear what the relative performance of different techniques will be given the immersive nature of the environment, and it is unclear how viewport-based versus world-based pointing methods will impact performance. To better understand the impact of device and viewing perspectives on pointing in augmented reality, we present the results of two controlled experiments comparing pointing conditions that leverage various smartphone- and smartwatch-based external display pointing techniques and examine viewport-based versus world-based target acquisition paradigms. Our results demonstrate that viewport-based techniques offer faster selection and that both smartwatch- and smartphone-based pointing techniques represent high-performance options for performing distant target acquisition tasks in augmented reality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {augmented reality, mobile devices, 3D pointing, input devices, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376497,
author = {Walker, Ashley Marie and DeVito, Michael A.},
title = {"'More Gay' Fits in Better": Intracommunity Power Dynamics and Harms in Online LGBTQ+ Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376497},
doi = {10.1145/3313831.3376497},
abstract = {Online spaces play crucial roles in the lives of most LGBTQ+ people, but can also replicate and exacerbate existing intracommunity tensions and power dynamics, potentially harming subgroups within this marginalized community. Using qualitative probes and interviews, we engaged a diverse group of 25 bi+ (attracted to more than one gender) people to explore these dynamics. We identify two types of intracommunity conflict that bi+ users face (validity and normative conflicts), and a resulting set of what we call latent harms, or coping strategies for dealing with conflict that have delayed negative psychological effects for bi+ users. Using intersectionality as a sensitizing concept to understand shifting power dynamics embedded in sociotechnical contexts, we discuss challenges for future design work including the need to account for intracommunity dynamics within marginalized groups and the utility of disentangling conflict from harm.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {pansexuality, bisexuality, power dynamics, social media, conflict, harm, intersectionality, online communities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376188,
author = {Robinson, Charlotte and Brul\'{e}, Emeline and Jackson, James and Torjussen, Alice and Kybett, Joshua and Appshaw, Tom},
title = {Tricks and Treats: Designing Technology to Support Mobility Assistance Dogs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376188},
doi = {10.1145/3313831.3376188},
abstract = {Assistance dogs are a key intervention to support the autonomy of people with tetraplegia. Previous research on assistive technologies have investigated ways to, ultimately, replace their labour using technology, for instance through the design of smart home environments. However, both the disability studies literature and our interviews suggest there is an immediate need to support these relationships, both in terms of training and bonding. Through a case study of an accessible dog treats dispenser, we investigate a technological intervention responding to these needs, detailing an appropriate design methodology and contributing insights into user requirements and preferences.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {assistive technology, disability, tetraplegia, assistance dog, service dog},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376738,
author = {Agarwal, Mohit and Sivakumar, Raghupathy},
title = {Charge for a Whole Day: Extending Battery Life for BCI Wearables Using a Lightweight Wake-Up Command},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376738},
doi = {10.1145/3313831.3376738},
abstract = {Commercially available EEG-based Brain-Computer Interface (BCI) wearable headsets are always-on and are thus power hungry, requiring users to charge the headsets multiple times a day. In this paper, we tackle the problem of wake-up command design and detection for BCI headsets, and explore how battery life can be made to last for approximately a whole day. The key challenge that we address is enabling the headset to operate in a near-sleep mode but still reliably detect and interpret an EEG-based wake-up command from the user. Towards addressing the challenge, we present a solution that is built upon eye-blinks. Our core contribution is Trance, a user-friendly and robust wake-up command for BCI headsets that is computationally lightweight. We show using experimental results coupled with multiple data sets collected through user-studies that Trance can extend battery life by approximately 2.7x or to approximately 10 hours for a typical wearable battery, while remaining user-friendly.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {input techniques, interaction design, wearable systems, brain-computer interfaces (bcis), eye tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376485,
author = {Gathani, Sneha and Lim, Peter and Battle, Leilani},
title = {Debugging Database Queries: A Survey of Tools, Techniques, and Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376485},
doi = {10.1145/3313831.3376485},
abstract = {Database management systems (or DBMSs) have been around for decades, and yet are still difficult to use, particularly when trying to identify and fix errors in user programs (or queries). We seek to understand what methods have been proposed to help people debug database queries, and whether these techniques have ultimately been adopted by DBMSs (and users). We conducted an interdisciplinary review of 112 papers and tools from the database, visualisation and HCI communities. To better understand whether academic and industry approaches are meeting the needs of users, we interviewed 20 database users (and some designers), and found surprising results. In particular, there seems to be a wide gulf between users' debugging strategies and the functionality implemented in existing DBMSs, as well as proposed in the literature. In response, we propose new design guidelines to help system designers to build features that more closely match users debugging strategies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {debugging databases, empirical study, survey, literature review, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376340,
author = {Mayer, Sven and Reinhardt, Jens and Schweigert, Robin and Jelke, Brighten and Schwind, Valentin and Wolf, Katrin and Henze, Niels},
title = {Improving Humans' Ability to Interpret Deictic Gestures in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376340},
doi = {10.1145/3313831.3376340},
abstract = {Collaborative Virtual Environments (CVEs) offer unique opportunities for human communication. Humans can interact with each other over a distance in any environment and visual embodiment they want. Although deictic gestures are especially important as they can guide other humans' attention, humans make systematic errors when using and interpreting them. Recent work suggests that the interpretation of vertical deictic gestures can be significantly improved by warping the pointing arm. In this paper, we extend previous work by showing that models enable to also improve the interpretation of deictic gestures at targets all around the user. Through a study with 28 participants in a CVE, we analyzed the errors users make when interpreting deictic gestures. We derived a model that rotates the arm of a pointing user's avatar to improve the observing users' accuracy. A second study with 24 participants shows that we can improve observers' accuracy by 22.9%. As our approach is not noticeable for users, it improves their accuracy without requiring them to learn a new interaction technique or distracting from the experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {correction model, deictic, ray tracing, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376211,
author = {Andrade, Ronny and Rogerson, Melissa J. and Waycott, Jenny and Baker, Steven and Vetere, Frank},
title = {Introducing the Gamer Information-Control Framework: Enabling Access to Digital Games for People with Visual Impairment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376211},
doi = {10.1145/3313831.3376211},
abstract = {In this paper, we present a foundation for understanding the elements that enable people with visual impairment to engage with digital games. This is defined by the gamer's relation- ships with information and with elements of control provided by the game, and is mediated through in-game metaphors and affordances when gamers interact as users or creators. This work complements previous research exploring the points of view of gamers with visual impairment by focusing on the games they play and prioritising the relationships between the key enablers of access to digital games. Using the framework to examine existing and missing components will enable de- signers to consider broader aspects of accessibility in game design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {audiogames, visual impairment, information, framework, digital games, control},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376182,
author = {Taber, Lee and Whittaker, Steve},
title = {"On Finsta, I Can Say 'Hail Satan'": Being Authentic but Disagreeable on Instagram},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376182},
doi = {10.1145/3313831.3376182},
abstract = {We use personality theory to compare self-presentation between multiple Instagram accounts, investigating authenticity and consistency. Many studies claim social media promote inauthentic self-presentation focused on socially desirable traits. At the same time, affordances suggest that self-presentation should be relatively consistent within one social medium. For 88 participants, we examine personality traits for 'real Instagram' ('Rinsta') versus 'fake Instagram' ('Finsta') accounts, comparing these with people's offline traits using mixed-methods. Counterintuitively, we find Finsta accounts often present socially undesirable traits. Furthermore, different accounts on the same social medium reveal quite different styles of self-presentation. Overall Finstas are more Extraverted, less Conscientious, and less Agreeable than Rinstas, although equally Neurotic as offline. Interviews indicate trait differences arise from differing audience perceptions. A large anonymous Rinsta audience promotes a carefully curated self. In contrast, a small but trusted Finsta audience can engender more authentic, but negative self-presentation. We discuss design and theory implications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {self-perception, social media, personality, finsta, rinsta, instagram, self-presentation, affordances, traits},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376558,
author = {Tsenova, Violeta and Wood, Gavin and Dolfini, Andrea and Tindley, Annie and Kirk, David},
title = {Un-Authorised View: Leveraging Volunteer Expertise in Heritage},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376558},
doi = {10.1145/3313831.3376558},
abstract = {Volunteers are an underused but important resource in presenting plural heritages within large heritage organizations. We report on a qualitative study at a heritage site in the UK which combined explorations of volunteers' practice and digital design. The study comprised of observational fieldwork with co-creative activities across eight linked workshops, where we explored the site with volunteers, and how we might leverage existing working structures to make new design prototypes. Our collective account contributes new insights on working with volunteers and the opportunities that arise from acknowledging them as genius loci - recognising them as experts of their own experience and capturing and supporting their skills as storytellers. Working with the volunteering staff in a co-design process we created innovative designs including our Un-authorised View, which draws out the unique perspectives and the personal stories at heritage destinations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {cultural probes, genius loci, digital storytelling, critical heritage, vr design, plural heritages},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376155,
author = {Subramonyam, Hariharan and Seifert, Colleen and Shah, Priti and Adar, Eytan},
title = {TexSketch: Active Diagramming through Pen-and-Ink Annotations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376155},
doi = {10.1145/3313831.3376155},
abstract = {Learning from text is a constructive activity in which sentence-level information is combined by the reader to build coherent mental models. With increasingly complex texts, forming a mental model becomes challenging due to a lack of background knowledge, and limits in working memory and attention. To address this, we are taught knowledge externalization strategies such as active reading and diagramming. Unfortunately, paper-and-pencil approaches may not always be appropriate, and software solutions create friction through difficult input modalities, limited workflow support, and barriers between reading and diagramming. For all but the simplest text, building coherent diagrams can be tedious and difficult. We propose Active Diagramming, an approach extending familiar active reading strategies to the task of diagram construction. Our prototype, texSketch, combines pen-and-ink interactions with natural language processing to reduce the cost of producing diagrams while maintaining the cognitive effort necessary for comprehension. Our user study finds that readers can effectively create diagrams without disrupting reading.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {active reading, pen-and-ink gestures, diagramming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376473,
author = {Wang, Yihong and Papangelis, Konstantinos and Saker, Michael and Lykourentzou, Ioanna and Chamberlain, Alan and Khan, Vassilis-Javed},
title = {Crowdsourcing in China: Exploring the Work Experiences of Solo Crowdworkers and Crowdfarm Workers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376473},
doi = {10.1145/3313831.3376473},
abstract = {Recent research highlights the potential of crowdsourcing in China. Yet very few studies explore the workplace context and experiences of Chinese crowdworkers. Those that do, focus mainly on the work experiences of solo crowdworkers but do not deal with issues pertaining to the substantial amount of people working in 'crowdfarms'. This article addresses this gap as one of its primary concerns. Drawing on a study that involves 48 participants, our research explores, compares and contrasts the work experiences of solo crowdworkers to those of crowdfarm workers. Our findings illustrate that the work experiences and context of the solo workers and crowdfarm workers are substantially different, with regards to their motivations, the ways they engage with crowdsourcing, the tasks they work on, and the crowdsourcing platforms they utilize. Overall, our study contributes to furthering the understandings on the work experiences of crowdworkers in China.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {work life balance, motivations and attitudes, work experience, crowdworkers, tasks, crowdsourcing, crowdfarms, reputation management, platform satisfaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376288,
author = {Davis, Keith M. and Kangassalo, Lauri and Spap\'{e}, Michiel and Ruotsalo, Tuukka},
title = {Brainsourcing: Crowdsourcing Recognition Tasks via Collaborative Brain-Computer Interfacing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376288},
doi = {10.1145/3313831.3376288},
abstract = {This paper introduces brainsourcing: utilizing brain responses of a group of human contributors each performing a recognition task to determine classes of stimuli. We investigate to what extent it is possible to infer reliable class labels using data collected utilizing electroencephalography (EEG) from participants given a set of common stimuli. An experiment (N=30) measuring EEG responses to visual features of faces (gender, hair color, age, smile) revealed an improved F1 score of 0.94 for a crowd of twelve participants compared to an F1 score of 0.67 derived from individual participants and a random chance of 0.50. Our results demonstrate the methodological and pragmatic feasibility of brainsourcing in labeling tasks and opens avenues for more general applications using brain-computer interfacing in a crowdsourced setting.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {brain-computer interfaces, crowdsourcing, brainsourcing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376696,
author = {Vezzoli, Yvonne and Kalantari, Sara and Kucirkova, Natalia and Vasalou, Asimina},
title = {Exploring the Design Space for Parent-Child Reading},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376696},
doi = {10.1145/3313831.3376696},
abstract = {Given the significant potential of shared book reading to promote children's learning, the design of e-books has focused on maximising this learning experience. However, recent studies have begun to show that shared reading is a broader opportunity for the family to spend quality time together. Our study aims to explore this perspective further, focusing on the types of parent-child interactions during shared reading and the ways in which shared reading may foster intimacy when parents and children read digital books. We used cultural probes and contextual interviews to capture the shared reading experiences of 7 parents and 6 children in their homes. We discuss the different nuances of the shared reading practices identified. We use these findings to suggest new design opportunities that support the complex practices of shared reading with technologies at home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {shared reading, families, cultural probes, parent-child reading, digital books},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376236,
author = {Olwal, Alex and Starner, Thad and Mainini, Gowa},
title = {E-Textile Microinteractions: Augmenting Twist with Flick, Slide and Grasp Gestures for Soft Electronics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376236},
doi = {10.1145/3313831.3376236},
abstract = {E-textile microinteractions advance cord-based interfaces by enabling the simultaneous use of precise continuous control and casual discrete gestures. We leverage the recently introduced I/O Braid sensing architecture to enable a series of user studies and experiments which help design suitable interactions and a real-time gesture recognition pipeline. Informed by a gesture elicitation study with 36 participants, we developed a user-dependent classifier for eight discrete gestures with 94% accuracy for 12 participants. In a formal evaluation we show that we can enable precise manipulation with the same architecture. Our quantitative targeting experiment suggests that twisting is faster than existing headphone button controls and is comparable in speed to a capacitive touch surface. Qualitative interview feedback indicates a preference for I/O Braid's interaction over that of in-line headphone controls. Our applications demonstrate how continuous and discrete gestures can be combined to form new, integrated e-textile microinteraction techniques for real-time continuous control, discrete actions and mode switching.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {soft electronics, interactive fabric, e-textile, smart textile, gestures, wearables, microinteractions, electronic textile},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376152,
author = {Liu, Zipeng and Liu, Zhicheng and Munzner, Tamara},
title = {Data-Driven Multi-Level Segmentation of Image Editing Logs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376152},
doi = {10.1145/3313831.3376152},
abstract = {Automatic segmentation of logs for creativity tools such as image editing systems could improve their usability and learnability by supporting such interaction use cases as smart history navigation or recommending alternative design choices. We propose a multi-level segmentation model that works for many image editing tasks including poster creation, portrait retouching, and special effect creation. The lowest-level chunks of logged events are computed using a support vector machine model and higher-level chunks are built on top of these, at a level of granularity that can be customized for specific use cases. Our model takes into account features derived from four event attributes collected in realistically complex Photoshop sessions with expert users: command, timestamp, image content, and artwork layer. We present a detailed analysis of the relevance of each feature and evaluate the model using both quantitative performance metrics and qualitative analysis of sample sessions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {log segmentation, image editing logs, multi-level hierarchy, interaction history},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376444,
author = {Chatterjee, Soujanya and Rahman, Md Mahbubur and Ahmed, Tousif and Saleheen, Nazir and Nemati, Ebrahim and Nathan, Viswam and Vatanparvar, Korosh and Kuang, Jilong},
title = {Assessing Severity of Pulmonary Obstruction from Respiration Phase-Based Wheeze-Sensing Using Mobile Sensors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376444},
doi = {10.1145/3313831.3376444},
abstract = {Obstructive pulmonary diseases cause limited airflow from the lung and severely affect patients' quality of life. Wheeze is one of the most prominent symptoms for them. High requirements imposed by traditional diagnosis methods make regular monitoring of pulmonary obstruction challenging, which hinders the opportunity of early intervention and prevention of significant exacerbation. In this work, we explore the feasibility of developing a mobile sensor-based system as a convenient means of assessing the severity of pulmonary obstruction via respiration phase-based symptomatic wheeze sensing. We conduct a 131 subjects' (91 patients and 40 healthy) study for the detection (F1: 87.96%) and characterization (F1: 79.47%) of wheeze. Subsequently, we develop novel wheeze metrics, which show a significant correlation (Pearson's correlation: -0.22, p-value: 0.024) with standard spirometry measure of pulmonary obstruction severity. This work takes a principal step towards the unobtrusive assessment of pulmonary condition from mobile sensor interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {pulmonary monitoring, mobile application, wheezing, mobile health (mhealth)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376833,
author = {Stowell, Elizabeth and O'Leary, Teresa K. and Kimani, Everlyne and Paasche-Orlow, Michael K. and Bickmore, Timothy and Parker, Andrea G.},
title = {Investigating Opportunities for Crowdsourcing in Church-Based Health Interventions: A Participatory Design Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376833},
doi = {10.1145/3313831.3376833},
abstract = {Churches play a major role in providing social support to address health inequities within Black communities, in part by connecting members to key organizations and services. While public health has a history of disseminating interventions in faith communities, little work has explored the use of crowdsourcing to tailor interventions to the unique culture of each church community. Following Community Based Participatory Research principles, we partnered with two predominantly Black churches, and report on a series of three participatory design sessions with nine participants. We developed a novel storyboarding method to explore how crowdsourcing could promote health in these faith-based communities. Our findings characterize existing supports within the church community, and how church social structures impact member access to these supports. We further identify motivations to engage with a church-situated health application, and how these motivations translate to crowdsourcing tasks. Finally, we discuss considerations for public health crowdsourcing tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {participatory design, health promotion, faith-based communities, crowdsourcing, mhealth, african-american},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376249,
author = {Wessely, Michael and Sethapakdi, Ticha and Castillo, Carlos and Snowden, Jackson C. and Hanton, Ollie and Qamar, Isabel P. S. and Fraser, Mike and Roudaut, Anne and Mueller, Stefanie},
title = {Sprayable User Interfaces: Prototyping Large-Scale Interactive Surfaces with Sensors and Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376249},
doi = {10.1145/3313831.3376249},
abstract = {We present Sprayable User Interfaces: room-sized interactive surfaces that contain sensor and display elements created by airbrushing functional inks. Since airbrushing is inherently mobile, designers can create large-scale user interfaces on complex 3D geometries where existing stationary fabrication methods fail. To enable Sprayable User Interfaces, we developed a novel design and fabrication pipeline that takes a desired user interface layout as input and automatically generates stencils for airbrushing the layout onto a physical surface. After fabricating stencils from cardboard or projecting stencils digitally, designers spray each layer with an airbrush, attach a microcontroller to the user interface, and the interface is ready to be used. Our technical evaluation shows that Sprayable User Interfaces work on various geometries and surface materials, such as porous stone and rough wood. We demonstrate our system with several application examples including interactive smart home applications on a wall and a soft leather sofa, an interactive smart city application, and interactive architecture in public office spaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {spraying, printed electronics, fabrication, airbrush, ubiquitous computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376715,
author = {Huang, Chieh-Yang and Huang, Shih-Hong and Huang, Ting-Hao Kenneth},
title = {Heteroglossia: In-Situ Story Ideation with the Crowd},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376715},
doi = {10.1145/3313831.3376715},
abstract = {Ideation is essential for creative writing. Many authors struggle to come up with ideas throughout the writing process, yet modern writing tools fail to provide on-the-spot assistance for writers when they get stuck. This paper introduces Heteroglossia, an add-on for Google Docs that allows writers to elicit story ideas from the online crowd using their text editors. Writers can share snippets of their working drafts and ask the crowd to provide follow-up story ideas based on it. Heteroglossia employs a strategy called "role play", where each worker is assigned a fictional character in a story and asked to brainstorm plot ideas from that character's perspective. Our deployment with two experienced story writers shows that Heteroglossia is easy to use and can generate interesting ideas. Heteroglossia allows us to gain insight into how future technologies can be developed to support ideation in creative writing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ideation, crowdsourcing, story, role play, creative writing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376161,
author = {Foley, Sarah and Pantidi, Nadia and McCarthy, John},
title = {Student Engagement in Sensitive Design Contexts: A Case Study in Dementia Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376161},
doi = {10.1145/3313831.3376161},
abstract = {There is a growing body of HCI work that seeks to understand and enhance the lived experience of people with dementia. The majority of this work involves researchers working alongside people with dementia and their carers, focused on the design project outcomes. In order to enrich the social context of this work, we explore broadening participation to include student volunteers. To encourage mutually engaging experiences in this design context, careful consideration of how to support both students and people with dementia is needed. In this paper, we present two case- studies of co-design projects between students and people with dementia. Our findings detail the use of design methods to reconfigure the role of the residents in care contexts and the students learning process. We discuss the project learning outcomes as well as practical and ethical considerations to support the use of design methods to support mutual engagement in sensitive contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {co-design, inter-generational engagement, experience-centered design, dementia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376869,
author = {Bedri, Abdelkareem and Li, Diana and Khurana, Rushil and Bhuwalka, Kunal and Goel, Mayank},
title = {FitByte: Automatic Diet Monitoring in Unconstrained Situations Using Multimodal Sensing on Eyeglasses},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376869},
doi = {10.1145/3313831.3376869},
abstract = {In an attempt to help users reach their health goals and practitioners understand the relationship between diet and disease, researchers have proposed many wearable systems to automatically monitor food consumption. When a person consumes food, he/she brings the food close to their mouth, take a sip or bite and chew, and then swallow. Most diet monitoring approaches focus on one of these aspects of food intake, but this narrow reliance requires high precision and often fails in noisy and unconstrained situations common in a person's daily life. In this paper, we introduce FitByte, a multi-modal sensing approach on a pair of eyeglasses that tracks all phases of food intake. FitByte contains a set of inertial and optical sensors that allow it to reliably detect food intake events in noisy environments. It also has an on-board camera that opportunistically captures visuals of the food as the user consumes it. We evaluated the system in two studies with decreasing environmental constraints with 23 participants. On average, FitByte achieved 89% F1-score in detecting eating and drinking episodes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ubiquitous computing, wearable computing, drinking detection, health sensing, earables, activity recognition, diet monitoring, eating detection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376462,
author = {Concannon, Shauna and Rajan, Natasha and Shah, Parthiv and Smith, Davy and Ursu, Marian and Hook, Jonathan},
title = {Brooke Leave Home: Designing a Personalized Film to Support Public Engagement with Open Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376462},
doi = {10.1145/3313831.3376462},
abstract = {Brooke Leave Home is a personalized film designed to engage a non-expert audience with open data about the support young adults receive when leaving the care system in England. The film draws upon a range of video-based data storytelling techniques to present each viewer with a personalized perspective on the topic based on data from their own local area. We present the film's design and describe how its storytelling techniques were developed to support viewers in understanding, and fostering empathic connections with, the data sources featured and the implications they have for care leavers. We also present a study with 47 viewers, which explores how these techniques were experienced and how effective they were in aiding engagement with the data included and its meaning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {video, data, personalization, storytelling, film, narrative},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376851,
author = {D\"{u}rr, Maximilian and Gr\"{o}schel, Carla and Pfeil, Ulrike and Reiterer, Harald},
title = {NurseCare: Design and 'In-The-Wild' Evaluation of a Mobile System to Promote the Ergonomic Transfer of Patients},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376851},
doi = {10.1145/3313831.3376851},
abstract = {Nurses are frequently required to transfer patients as part of their daily duties. However, the manual transfer of patients is a major risk factor for injuries to the back. Although the Kinaesthetics Care Conception can help to address this issue, existing support for the integration of the concept into nursing-care practice is low. We present NurseCare, a mobile system that aims to promote the practical application of ergonomic patient transfers based on the Kinaesthetics Care Conception. NurseCare consists of a wearable and a smartphone app. Key features of NurseCare include mobile accessible instructions for ergonomic patient transfers, in-situ feedback for the risky bending of the back, and long-term feedback. We evaluated NurseCare in a nine participant 'in-the-wild' evaluation. Results indicate that NurseCare can facilitate ergonomic work while providing a high user experience adequate to the nurses' work domain, and reveal how NurseCare can be incorporated in given practices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {`in-the-wild' evaluation, nursing care, mobile system},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376339,
author = {Lerner, Ada and He, Helen Yuxun and Kawakami, Anna and Zeamer, Silvia Catherine and Hoyle, Roberto},
title = {Privacy and Activism in the Transgender Community},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376339},
doi = {10.1145/3313831.3376339},
abstract = {Transgender people are marginalized, facing specific privacy concerns and high risk of online and offline harassment, discrimination, and violence. They also benefit tremendously from technology. We conducted semi-structured interviews with 18 transgender people from 3 U.S. cities about their computer security and privacy experiences broadly construed. Participants frequently returned to themes of activism and prosocial behavior, such as protest organization, political speech, and role-modeling transgender identities, so we focus our analysis on these themes. We identify several prominent risk models related to visibility, luck, and identity that participants used to analyze their own risk profiles, often as distinct or extreme. These risk perceptions may heavily influence transgender people's defensive behaviors and self-efficacy, jeopardizing their ability to defend themselves or gain technology's benefits. We articulate design lessons emerging from these ideas, contrasting and relating them to lessons about other marginalized groups whenever possible.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {gender identity, user-centered design, presentation management, privacy, social networks, transgender, security},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376197,
author = {Ackermans, Sander and Dey, Debargha and Ruijten, Peter and Cuijpers, Raymond H. and Pfleging, Bastian},
title = {The Effects of Explicit Intention Communication, Conspicuous Sensors, and Pedestrian Attitude in Interactions with Automated Vehicles},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376197},
doi = {10.1145/3313831.3376197},
abstract = {In this paper, we investigate the effect of an external human-machine interface (eHMI) and a conspicuous external vehicle appearance due to visible sensors on pedestrian interactions with automated vehicles (AVs). Recent research shows that AVs may need to explicitly communicate with the environment due to the absence of a driver. Furthermore, in interaction situations, an AV that looks different and conspicuous owing to an extensive sensor system may potentially lead to hesitation stemming from mistrust in automation. Thus, we evaluated in a virtual reality study how pedestrian attitude, the presence/absence of an eHMI, and a conspicuous sensor system affect their willingness to cross the road. Results recommend the use of an eHMI. A conspicuous appearance of automated-driving capability had no effect for the sample as a whole, although it led to more efficient crossing decisions for those with a more negative attitude towards AVs. Our findings contribute towards the effective design of future AV interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {automated driving, vehicle-pedestrian interaction, external appearance, automated vehicles, visible sensors, pedestrians, ehmi, vulnerable road users},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376215,
author = {Watson, Colin and Kirkham, Reuben and Kharrufa, Ahmed},
title = {PIP Kit: An Exploratory Investigation into Using Lifelogging to Support Disability Benefit Claimants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376215},
doi = {10.1145/3313831.3376215},
abstract = {Disability assessment processes are complex and stressful, with claimants finding it challenging to prepare an effective account of their disabilities to support their claim. This project focuses on a disability benefit called Personal Independence Payment (PIP), which is received by millions of people with disabilities in the UK. We present a multi-stage exploratory investigation into how lifelogging could help address the challenges claimants have in accessing disability benefits. In the first study, benefit advisors participated in interviews and workshops to inform the design of PIP Kit, a highly customisable prototype elicitation diary to help disability claimants articulate their experiences. In the second study, PIP Kit was trialled by benefit claimants whilst making their actual PIP claims. We found that PIP Kit helped empower claimants in understanding the claim process and assisted in building arguments for their claims. We also have identified clear principles for supporting disability benefit claimants with technological interventions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {social security, accessibility, disability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376525,
author = {Kristensson, Per Ola and Lilley, James and Black, Rolf and Waller, Annalu},
title = {A Design Engineering Approach for Quantitatively Exploring Context-Aware Sentence Retrieval for Nonspeaking Individuals with Motor Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376525},
doi = {10.1145/3313831.3376525},
abstract = {Nonspeaking individuals with motor disabilities typically have very low communication rates. This paper proposes a design engineering approach for quantitatively exploring context-aware sentence retrieval as a promising complementary input interface, working in tandem with a word-prediction keyboard. We motivate the need for complementary design engineering methodology in the design of augmentative and alternative communication and explain how such methods can be used to gain additional design insights. We then study the theoretical performance envelopes of a context-aware sentence retrieval system, identifying potential keystroke savings as a function of the parameters of the subsystems, such as the accuracy of the underlying auto-complete word prediction algorithm and the accuracy of sensed context information under varying assumptions. We find that context-aware sentence retrieval has the potential to provide users with considerable improvements in keystroke savings under reasonable parameter assumptions of the underlying subsystems. This highlights how complementary design engineering methods can reveal additional insights into design for augmentative and alternative communication.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {information retrieval, text entry, context-aware text entry, design engineering, augmentative and alternative communication, sentence prediction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376417,
author = {Taranta, Eugene M. and Pittman, Corey R. and Oakley, Jack P. and Maslych, Mykola and Maghoumi, Mehran and LaViola, Joseph J.},
title = {Moving Toward an Ecologically Valid Data Collection Protocol for 2D Gestures In Video Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376417},
doi = {10.1145/3313831.3376417},
abstract = {Those who design gesture recognizers and user interfaces often use data collection applications that enable users to comfortably produce gesture training samples. In contrast, games present unique contexts that impact cognitive load and have the potential to elicit rapid gesticulations as players react to dynamic conditions, which can result in high gesture form variability. However, the extent to which these gestures differ is presently unknown. To this end, we developed two games with unique mechanics, Follow the Leader (FTL) and Sleepy Town, as well as a standard data collection application. We collected gesture samples from 18 participants across all conditions for gestures of varying complexity, and through an analysis using relative, global, and distribution coverage measures, we confirm significant differences between conditions. We discuss the implications of our findings, and show that our FTL design is closer to being an ecologically valid data collection protocol with low implementation complexity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {follow the leader, gestures, ecologically validity, games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376585,
author = {Song, Yunpeng and Huang, Yun and Cai, Zhongmin and Hong, Jason I.},
title = {I'm All Eyes and Ears: Exploring Effective Locators for Privacy Awareness in IoT Scenarios},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376585},
doi = {10.1145/3313831.3376585},
abstract = {With the proliferation of IoT devices, there are growing concerns about being sensed or monitored by these devices unawares, especially in places perceived as private. We explore the design space of IoT locators to help people physically find nearby IoT devices. We first conducted a survey to understand people's willingness, current practices, and challenges in finding IoT devices. Our survey findings motivated us to design and implement low-cost locators (visual, auditory, and contextualized pictures) to help people find nearby devices. Through an iterative design process and two rounds of experiments, we found that these locators greatly reduced people's search time over a baseline of no locators. Many participants found the visual and auditory locators enjoyable. Some participants also appropriated the use of our system for other purposes, e.g., to learn about new IoT devices, instead of for privacy awareness.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {locator, privacy awareness, internet of things},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376416,
author = {Xu, Ying and Warschauer, Mark},
title = {What Are You Talking To?: Understanding Children's Perceptions of Conversational Agents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376416},
doi = {10.1145/3313831.3376416},
abstract = {Conversational agents (CAs) available in smart phones or smart speakers play an increasingly important role in young children's technological landscapes and life worlds. While a handful of studies have documented children's natural interactions with CAs, little is known about children's perceptions of CAs. To fill this gap, we examined three- to six-year-olds' perceptions of CAs' animate/artifact domain membership and properties, as well as their justifications for these perceptions. We found that children sometimes take a more nuanced position and spontaneously attribute both artifact and animate properties to CAs or view them as neither artifacts nor animate objects. This study extends current research on children's perceptions of intelligent artifacts by adding CAs as a new genre of study and provides some underlying knowledge that may guide the development of CAs to support young children's cognitive and social development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {conversational agents, children, animacy, perceptions, child-agent interactions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376257,
author = {Mallari, Keri and Inkpen, Kori and Johns, Paul and Tan, Sarah and Ramesh, Divya and Kamar, Ece},
title = {Do I Look Like a Criminal? Examining How Race Presentation Impacts Human Judgement of Recidivism},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376257},
doi = {10.1145/3313831.3376257},
abstract = {Understanding how racial information impacts human decision making in online systems is critical in today's world. Prior work revealed that race information of criminal defendants, when presented as a text field, had no significant impact on users' judgements of recidivism. We replicated and extended this work to explore how and when race information influences users' judgements, with respect to the saliency of presentation. Our results showed that adding photos to the race labels had a significant impact on recidivism predictions for users who identified as female, but not for those who identified as male. The race of the defendant also impacted these results, with black defendants being less likely to be predicted to recidivate compared to white defendants. These results have strong implications for how system-designers choose to display race information, and cautions researchers to be aware of gender and race effects when using Amazon Mechanical Turk workers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-ai collaboration, gender, mechanical turk, bias, recidivism, race, legal, crowd work},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376862,
author = {Zhang, Yixuan and Suhaimi, Nurul and Azghandi, Rana and Joseph, Mary Amulya and Kim, Miso and Griffin, Jacqueline and Parker, Andrea G.},
title = {Understanding the Use of Crisis Informatics Technology among Older Adults},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376862},
doi = {10.1145/3313831.3376862},
abstract = {Mass emergencies increasingly pose significant threats to human life, with a disproportionate burden being incurred by older adults. Research has explored how mobile technology can mitigate the effects of mass emergencies. However, less work has examined how mobile technologies support older adults during emergencies, considering their unique needs. To address this research gap, we interviewed 16 older adults who had recent experience with an emergency evacuation to understand the perceived value of using mobile technology during emergencies. We found that there was a lack of awareness and engagement with existing crisis apps. Our findings characterize the ways in which our participants did and did not feel crisis informatics tools address human values, including basic needs and esteem needs. We contribute an understanding of how older adults used mobile technology during emergencies and their perspectives on how well such tools address human values.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {emergencies, older adults, crisis informatics, human values},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376759,
author = {Tuncer, Sylvaine and Brown, Barry and Lindwall, Oskar},
title = {On Pause: How Online Instructional Videos Are Used to Achieve Practical Tasks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376759},
doi = {10.1145/3313831.3376759},
abstract = {Instructional videos have become an important site of everyday learning. This paper explores how these videos are used to complete practical tasks, analyzing video-recorded interactions between pairs of users. Users need to repeatedly pause their videos to be able to follow the instructions, and we document how pausing is used to coordinate and interweave watching and doing. We describe four purposes and types of pausing: finding task objects, turning to action, keeping up, and fixing problems. Building on these results, we discuss how video players could better support following instructions, and the role of basic user interface functions in complex tasks involving different forms of engagement with the physical world and with screen-based activity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pause button, video interface, ethnomethodology, instructional videos, video players},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376809,
author = {Ayobi, Amid and Marshall, Paul and Cox, Anna L.},
title = {Trackly: A Customisable and Pictorial Self-Tracking App to Support Agency in Multiple Sclerosis Self-Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376809},
doi = {10.1145/3313831.3376809},
abstract = {Self-tracking is an important part of self-care. However, predefined self-tracking approaches can impede people's agency in managing their health. We investigated a customisable and pictorial self-tracking approach in multiple sclerosis self-management by implementing and conducting a field study of Trackly: a prototype app that supports people in defining and colouring pictorial trackers, such as body shapes. We found that participants utilised the elements of Trackly designed to support agentive behaviour: they defined personally meaningful tracking parameters in their own words, and particularly valued being able to flexibly colour in and make sense of their pictorial trackers. Having been able to support their individual self-care intentions with Trackly, participants reported a spectrum of interrelated experiences of agency, including a sense of ownership, identity, self-awareness, mindfulness, and control. Our findings demonstrate the importance of supporting people's individual needs and creative capacities to foster mindful and personally meaningful engagement with health and wellbeing data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mood tracking, symptom monitoring, customisation, perceived control, self-reflection, customization, agency, self-awareness, mindfulness, self-tracking, bullet journaling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376575,
author = {Ebert, Nico and Ackermann, Kurt Alexander and Heinrich, Peter},
title = {Does Context in Privacy Communication Really Matter? — A Survey on Consumer Concerns and Preferences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376575},
doi = {10.1145/3313831.3376575},
abstract = {Privacy policies as a means of communicating with customers still prove ineffective. Researchers have recently suggested that a specific usage context should be considered to make privacy notices more relevant to users. To explore this approach further, we conducted an explorative online survey of privacy concerns and privacy information preferences with 642 participants for two different contexts (loyalty cards and fitness tracking). Our data shows some support for the suggestion that context may be a significant moderator of concerns and preferences. However, the corresponding effects are rather small and limited to specific concerns and information categories. In line with other research, the data supports the known hierarchy of concerns regarding unauthorized secondary use and improper data access, which seem to exceed concerns about erroneous data processing or excessive data collection in both contexts. Furthermore, participants considered information on personal rights and processing purposes more relevant than information on contact persons.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {policy, privacy, user preferences, privacy concerns},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376652,
author = {Jetter, Hans-Christian and R\"{a}dle, Roman and Feuchtner, Tiare and Anthes, Christoph and Friedl, Judith and Klokmose, Clemens Nylandsted},
title = {"In VR, Everything is Possible!": Sketching and Simulating Spatially-Aware Interactive Spaces in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376652},
doi = {10.1145/3313831.3376652},
abstract = {We propose using virtual reality (VR) as a design tool for sketching and simulating spatially-aware interactive spaces. Using VR, designers can quickly experience their envisioned spaces and interactions by simulating technologies such as motion tracking, multiple networked devices, or unusual form factors such as spherical touchscreens or bezel-less display tiles. Design ideas can be rapidly iterated without restrictions by the number, size, or shape and availability of devices or sensors in the lab. To understand the potentials and challenges of designing in VR, we conducted a user study with 12 interaction designers. As their tool, they used a custom-built virtual design environment with finger tracking and physics simulations for natural interactions with virtual devices and objects. Our study identified the designers' experience of space in relation to their own bodies and playful design explorations as key opportunities. Key challenges were the complexities of building a usable yet versatile VR-based "World Editor".},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {interaction design, interactive spaces, prototyping, sketching, simulation, spatial awareness, design tools, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376140,
author = {Sun, Jiao and Li, Yin and Chen, Charley and Lee, Jihae and Liu, Xin and Zhang, Zhongping and Huang, Ling and Shi, Lei and Xu, Wei},
title = {FDHelper: Assist Unsupervised Fraud Detection Experts with Interactive Feature Selection and Evaluation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376140},
doi = {10.1145/3313831.3376140},
abstract = {Online fraud is the well-known dark side of the modern Internet. Unsupervised fraud detection algorithms are widely used to address this problem. However, selecting features, adjusting hyperparameters, evaluating the algorithms, and eliminating false positives all require human expert involvement. In this work, we design and implement an end-to-end interactive visualization system, FDHelper, based on the deep understanding of the mechanism of the black market and fraud detection algorithms. We identify a workflow based on experience from both fraud detection algorithm experts and domain experts. Using a multi-granularity three-layer visualization map embedding an entropy-based distance metric ColDis, analysts can interactively select different feature sets, refine fraud detection algorithms, tune parameters and evaluate the detection result in near real-time. We demonstrate the effectiveness and significance of FDHelper through two case studies with state-of-the-art fraud detection algorithms, interviews with domain experts and algorithm experts, and a user study with eight first-time end users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {human computer interaction, fraud detection, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376820,
author = {Devendorf, Laura and Arquilla, Katya and Wirtanen, Sandra and Anderson, Allison and Frost, Steven},
title = {Craftspeople as Technical Collaborators: Lessons Learned through an Experimental Weaving Residency},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376820},
doi = {10.1145/3313831.3376820},
abstract = {While craft has had increasing influence on HCI research, HCI researchers tend to engage craft in limited capacities, often focusing on the juxtapositions of "traditional" craft and "innovative" computing. In this paper, we describe the structure and results of a six-week "experimental weaving residency" to show how HCI practitioners, engineers, and craftspeople perform similar work and can productively collaborate to envision new technological interfaces at early stages of development. We address both social and technical challenges of residencies and critically reflect on biases about technical and craft labor that we held prior to the residency. We share our experiences and lessons learned in the hopes of supporting future collaborations with craftspeople and broadening the techniques we use to address design challenges.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {collaboration models, feminist HCI, weaving, electrodes, smart textiles, artist residencies},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376135,
author = {Wilkins, Denise J. and Chitchyan, Ruzanna and Levine, Mark},
title = {Peer-to-Peer Energy Markets: Understanding the Values of Collective and Community Trading},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376135},
doi = {10.1145/3313831.3376135},
abstract = {Peer-to-peer energy-trading platforms (P2P) have the potential to transform the current energy system. However, research is presently scarce on how people would like to participate in, and what would they expect to gain from, such platforms. We address this gap by exploring these questions in the context of the UK energy market. Using a qualitative interview study, we examine how 45 people with an interest in renewable energy understand P2P. We find that the prospective users value the collective benefits of P2P, and understand participation as a mechanism to support social, ecological and economic benefits for communities and larger groups. Drawing on the findings from the interview analysis, we explore broad design characteristics that a prospective P2P energy trading platform should provide to meet the expectations and concerns voiced by our study participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {thematic analysis, semi-structured interview, sustainability, peer to peer energy trading platforms},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376716,
author = {Ahmadi, Michael and Eilert, Rebecca and Weibert, Anne and Wulf, Volker and Marsden, Nicola},
title = {Feminist Living Labs as Research Infrastructures for HCI: The Case of a Video Game Company},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376716},
doi = {10.1145/3313831.3376716},
abstract = {The number of women in IT is still low and companies struggle to integrate female professionals. The aim of our research is to provide methodological support for understanding and sharing experiences of gendered practices in the IT industry and encouraging sustained reflection about these matters over time. We established a Living Lab with that end in view, aiming to enhance female participation in the IT workforce and committing ourselves to a participatory approach to the sharing of women's experiences. Here, using the case of a German video game company which participated in our Lab, we detail our lessons learned. We show that this kind of long-term participation involves challenges over the lifetime of the project but can lead to substantial benefits for organizations. Our findings demonstrate that Living Labs are suitable for giving voice to marginalized groups, addressing their concerns and evoking change possibilities. Nevertheless, uncertainties about long-term sustainability remain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {participatory action research, gender, feminist HCI, living lab, feminist research, methodology, ethnography},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376332,
author = {Tyack, April and Wyeth, Peta and Johnson, Daniel},
title = {Restorative Play: Videogames Improve Player Wellbeing After a Need-Frustrating Event},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376332},
doi = {10.1145/3313831.3376332},
abstract = {People often use videogames to restore wellbeing after negative experiences in day-to-day life. Although some research suggests that play can restore wellbeing, few studies have investigated the means by which restoration occurs. We employed self-determination theory (SDT) to understand how and to what degree play improves wellbeing after a need-frustrating event, and how players understand experiences of competence in play. Sixty-five participants worked at a competence manipulation task prior to playing a competence-satisfying videogame. Competence, affect, and vitality improved during play, and in-game experiences of need frustration were observed to effectively predict post-play negative affect. Post-experiment interviews indicate that videogames are seen to support competence relative to perceived skill, extending our knowledge of how design can support competence and restoration. We demonstrate that play can restore wellbeing, present need frustration as a means to explain negative experiences with interactive systems, and discuss effects of design on competence.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {self-determination theory, wellbeing, need frustration, restoration, video games, player experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376697,
author = {Wiley, Katelyn and Vedress, Sarah and Mandryk, Regan L.},
title = {How Points and Theme Affect Performance and Experience in a Gamified Cognitive Task},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376697},
doi = {10.1145/3313831.3376697},
abstract = {Cognitive tasks are increasingly being gamified in an attempt to leverage the motivational power of games; however, they are sensitive to manipulation and literature is divided on how adding game elements affects participant performance and experience. We applied two popular gamification approaches (points/feedback and theme/narrative) to a typical cognitive task (the dot probe) and measured performance and experience in two studies (N1=287, N2=321). Similar to prior work, we confirm in Study1 that points increase reaction time and error rate, and positive affect. We replicated these results in Study2, and expanded our analysis to investigate participant experience. Our findings suggest that theme creates expectations of an interesting game, which gamified tasks fail to deliver, whereas points maintain enjoyment better throughout the task itself. Important for the development of gamified cognitive tasks, our findings suggest that novel approaches to gameful assessment may be better than the status quo.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {gamification, games, cognitive tasks, assessment, dot probe},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376431,
author = {Shi, Lei and Zhao, Yuhang and Gonzalez Penuela, Ricardo and Kupferstein, Elizabeth and Azenkot, Shiri},
title = {Molder: An Accessible Design Tool for Tactile Maps},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376431},
doi = {10.1145/3313831.3376431},
abstract = {Tactile materials are powerful teaching aids for students with visual impairments (VIs). To design these materials, designers must use modeling applications, which have high learning curves and rely on visual feedback. Today, Orientation and Mobility (O&amp;M) specialists and teachers are often responsible for designing these materials. However, most of them do not have professional modeling skills, and many are visually impaired themselves. To address this issue, we designed Molder, an accessible design tool for interactive tactile maps, an important type of tactile materials that can help students learn O&amp;M skills. A designer uses Molder to design a map using tangible input techniques, and Molder provides auditory feedback and high-contrast visual feedback. We evaluated Molder with 12 participants (8 with VIs, 4 sighted). After a 30-minute training session, the participants were all able to use Molder to design maps with customized tactile and interactive information.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visual impairments, tactile maps, design tool},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376300,
author = {Fu, Ernestine and Johns, Mishel and Hyde, David A. B. and Sibi, Srinath and Fischer, Martin and Sirkin, David},
title = {Is Too Much System Caution Counterproductive? Effects of Varying Sensitivity and Automation Levels in Vehicle Collision Avoidance Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376300},
doi = {10.1145/3313831.3376300},
abstract = {Autonomous vehicle system performance is limited by uncertainties inherent in the driving environment and challenges in processing sensor data. Engineers thus face the design decision of biasing systems toward lower sensitivity to potential threats (more misses) or higher sensitivity (more false alarms). We explored this problem for Automatic Emergency Braking systems in Level 3 autonomous vehicles, where the driver is required to monitor the system for failures. Participants (N=48) drove through a simulated suburban environment and experienced detection misses, perfect performance, or false alarms. We found that driver vigilance was greater for less-sensitive braking systems, resulting in improved performance during a potentially fatal failure. In addition, regardless of system bias, greater levels of autonomy resulted in significantly worse driver performance. Our results demonstrate that accounting for the effects of system bias on driver vigilance and performance will be critical design considerations as vehicle autonomy levels increase.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {controlled experiment, autonomous vehicles, automated emergency braking, simulation, human machine interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376418,
author = {Jensen, Emily and Dale, Meghan and Donnelly, Patrick J. and Stone, Cathlyn and Kelly, Sean and Godley, Amanda and D'Mello, Sidney K.},
title = {Toward Automated Feedback on Teacher Discourse to Enhance Teacher Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376418},
doi = {10.1145/3313831.3376418},
abstract = {Like anyone, teachers need feedback to improve. Due to the high cost of human classroom observation, teachers receive infrequent feedback which is often more focused on evaluating performance than on improving practice. To address this critical barrier to teacher learning, we aim to provide teachers with detailed and actionable automated feedback. Towards this end, we developed an approach that enables teachers to easily record high-quality audio from their classes. Using this approach, teachers recorded 142 classroom sessions, of which 127 (89%) were usable. Next, we used speech recognition and machine learning to develop teacher-generalizable computer-scored estimates of key dimensions of teacher discourse. We found that automated models were moderately accurate when compared to human coders and that speech recognition errors did not influence performance. We conclude that authentic teacher discourse can be recorded and analyzed for automatic feedback. Our next step is to incorporate the automatic models into an interactive visualization tool that will provide teachers with objective feedback on the quality of their discourse.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {natural language processing, classroom discourse, dialogic instruction, automatic speech recognition, audio recording},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376817,
author = {Kaur, Harmanpreet and Williams, Alex C. and McDuff, Daniel and Czerwinski, Mary and Teevan, Jaime and Iqbal, Shamsi T.},
title = {Optimizing for Happiness and Productivity: Modeling Opportune Moments for Transitions and Breaks at Work},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376817},
doi = {10.1145/3313831.3376817},
abstract = {Information workers perform jobs that demand constant multitasking, leading to context switches, productivity loss, stress, and unhappiness. Systems that can mediate task transitions and breaks have the potential to keep people both productive and happy. We explore a crucial initial step for this goal: finding opportune moments to recommend transitions and breaks without disrupting people during focused states. Using affect, workstation activity, and task data from a three-week field study (N=25), we build models to predict whether a person should continue their task, transition to a new task, or take a break.&nbsp;The R-squared values of our models are as high as 0.7, with only 15% error cases. We ask users to evaluate the timing of recommendations provided by a recommender that relies on these models. Our study shows that users find our transition and break recommendations to be well-timed, rating them as 86% and 77% accurate, respectively. We conclude with a discussion of the implications for intelligent systems that seek to guide task transitions and manage interruptions at work.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {workplace, productivity, affect, recommendations},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376436,
author = {Chen, Zhutian and Tong, Wai and Wang, Qianwen and Bach, Benjamin and Qu, Huamin},
title = {Augmenting Static Visualizations with PapARVis Designer},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376436},
doi = {10.1145/3313831.3376436},
abstract = {This paper presents an authoring environment for augmenting static visualizations with virtual content in augmented reality.Augmenting static visualizations can leverage the best of both physical and digital worlds, but its creation currently involves different tools and devices, without any means to explicitly design and debug both static and virtual content simultaneously. To address these issues, we design an environment that seamlessly integrates all steps of a design and deployment workflow through its main features: i) an extension to Vega, ii) a preview, and iii) debug hints that facilitate valid combinations of static and augmented content. We inform our design through a design space with four ways to augment static visualizations. We demonstrate the expressiveness of our tool through examples, including books, posters, projections, wall-sized visualizations. A user study shows high user satisfaction of our environment and confirms that participants can create augmented visualizations in an average of 4.63 minutes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data visualization authoring, visualization in augmented reality, augmented static visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376266,
author = {Kurzhals, Kuno and G\"{o}bel, Fabian and Angerbauer, Katrin and Sedlmair, Michael and Raubal, Martin},
title = {A View on the Viewer: Gaze-Adaptive Captions for Videos},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376266},
doi = {10.1145/3313831.3376266},
abstract = {Subtitles play a crucial role in cross-lingual distribution of multimedia content and help communicate information where auditory content is not feasible (loud environments, hearing impairments, unknown languages). Established methods utilize text at the bottom of the screen, which may distract from the video. Alternative techniques place captions closer to related content (e.g., faces) but are not applicable to arbitrary videos such as documentations. Hence, we propose to leverage live gaze as indirect input method to adapt captions to individual viewing behavior. We implemented two gaze-adaptive methods and compared them in a user study (n=54) to traditional captions and audio-only videos. The results show that viewers with less experience with captions prefer our gaze-adaptive methods as they assist them in reading. Furthermore, gaze distributions resulting from our methods are closer to natural viewing behavior compared to the traditional approach. Based on these results, we provide design implications for gaze-adaptive captions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {subtitles, video captions, eye tracking, gaze input, gaze-responsive display, multimedia},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376644,
author = {Park, So Yeon and Moore, Dylan James and Sirkin, David},
title = {What a Driver Wants: User Preferences in Semi-Autonomous Vehicle Decision-Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376644},
doi = {10.1145/3313831.3376644},
abstract = {Autonomous vehicle (AV) systems are developing at a rapid pace, not only in technological capabilities, but also in human-centered directions. Despite this development, we lack a nuanced understanding of driver preference in decision scenarios that semi-AVs will face, and of possible misalignment between semi-AV decisions and user preference. Using an online survey, we explore how participants would like semi-AVs to act and alert them of the vehicles' decisions in various scenarios. Participants reported varying levels of comfort with autonomy, desire to takeover control, and desire for AV informing. Individual differences, including level of experience with autonomy and situation awareness, affected perceptions of the vehicle. Our results highlight the importance of considering driver preference in AV decision-making, and we present an influence diagram that situates this factor among others. We also derive five design principles, including that a previous positive AV experience can lead to more harmful consequences for AVs when not aligned with driver preference.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {driver preferences, notifications, autonomous vehicles, decision-making, online study, transition of control},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376594,
author = {Zhu, Haining and Moffa, Zachary J. and Gui, Xinning and Carroll, John M.},
title = {Prehabilitation: Care Challenges and Technological Opportunities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376594},
doi = {10.1145/3313831.3376594},
abstract = {Millions of surgeries are performed in the US annually, and numbers are trending upwards. Traditional rehabilitative interventions are struggling to meet current demands, and researchers have turned to pre-operative interventions, or prehabilitation, to improve patient functions. However, existing literature primarily discusses efficacy or the use of commercial sensing devices, and lacks a clear comprehension of healthcare professionals' (HPs') needs and perspectives. User-centered stakeholder understandings are crucial for a technology's adoption, but prehabilitation literature lacks such understandings. Therefore we conduct semi-structured interviews with 12 prehabilitation healthcare professionals (HPs) to offer descriptions of care challenges, tool usage, and perspectives regarding suitable and effective technologies. These data can assist designers in fostering prehabilitation processes via tailored prehabilitation tools which meet HPs' needs and expectations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {psychological health, user-centered design, surgical care, physical health, rehabilitation, nutritional health, prehabilitation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376513,
author = {Davis, Josh Urban and Wu, Te-Yen and Shi, Bo and Lu, Hanyi and Panotopoulou, Athina and Whiting, Emily and Yang, Xing-Dong},
title = {TangibleCircuits: An Interactive 3D Printed Circuit Education Tool for People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376513},
doi = {10.1145/3313831.3376513},
abstract = {We present a novel haptic and audio feedback device that allows blind and visually impaired (BVI) users to understand circuit diagrams. TangibleCircuits allows users to interact with a 3D printed tangible model of a circuit which provides audio tutorial directions while being touched. Our system comprises an automated parsing algorithm which extracts 3D printable models as well as an audio interfaces from a Fritzing diagram. To better understand the requirements of designing technology to assist BVI users in learning hardware computing, we conducted a series of formative inquiries into the accessibility limitations of current circuit tutorial technologies. In addition, we derived insights and design considerations gleaned from conducting a formal comparative user study to understand the effectiveness of TangibleCircuits as a tutorial system. We found that BVI users were better able to understand the geometric, spatial and structural circuit information using TangibleCircuits, as well as enjoyed learning with our tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tangible user interfaces, accessibility, education tools, universal design, circuit prototyping},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376618,
author = {Zhao, Nanxuan and Kim, Nam Wook and Herman, Laura Mariah and Pfister, Hanspeter and Lau, Rynson W.H. and Echevarria, Jose and Bylinskii, Zoya},
title = {ICONATE: Automatic Compound Icon Generation and Ideation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376618},
doi = {10.1145/3313831.3376618},
abstract = {Compound icons are prevalent on signs, webpages, and infographics, effectively conveying complex and abstract concepts, such as "no smoking" and "health insurance", with simple graphical representations. However, designing such icons requires experience and creativity, in order to efficiently navigate the semantics, space, and style features of icons. In this paper, we aim to automate the process of generating icons given compound concepts, to facilitate rapid compound icon creation and ideation. Informed by ethnographic interviews with professional icon designers, we have developed ICONATE, a novel system that automatically generates compound icons based on textual queries and allows users to explore and customize the generated icons. At the core of ICONATE is a computational pipeline that automatically finds commonly used icons for sub-concepts and arranges them according to inferred conventions. To enable the pipeline, we collected a new dataset, Compicon1k, consisting of 1000 compound icons annotated with semantic labels (i.e., concepts). Through user studies, we have demonstrated that our tool is able to automate or accelerate the compound icon design process for both novices and professionals.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {icon design, ideogram, graphic design, design tools, pictogram, compound icon},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376751,
author = {Gerber, Michael A. and Schroeter, Ronald and Xiaomeng, Li and Elhenawy, Mohammed},
title = {Self-Interruptions of Non-Driving Related Tasks in Automated Vehicles: Mobile vs Head-Up Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376751},
doi = {10.1145/3313831.3376751},
abstract = {Automated driving raises new human factors challenges. There is a paradox that allows drivers to perform non-driving related tasks (NDRTs), while benefiting from a driver who regularly attends to the driving task. Systems that aim to better manage a driver's attention, encouraging task switching and interleaving, may help address this paradox. However, a better understanding of how drivers self-interrupt while engaging in NDRTs is required to inform such systems. This paper presents a counterbalanced within-subject simulator study with N=42 participants experiencing automated driving in a familiar driving environment. Participants chose a TV show to watch on a HUD and mobile display during two 15min drives on the same route. Eye and head tracking data revealed more self-interruptions in the HUD condition, suggesting a higher likelihood of a higher situation awareness. Our results may benefit the design of future attention management systems by informing the visual and temporal integration of the driving and non-driving related task.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {self-interruption, human-automation interaction, task engagement, attention management, conditionally automated vehicles, non-driving related task},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376641,
author = {Khan, Taslim Arefin and Yoon, Dongwook and McGrenere, Joanna},
title = {Designing an Eyes-Reduced Document Skimming App for Situational Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376641},
doi = {10.1145/3313831.3376641},
abstract = {Listening to text using read-aloud applications is a popular way for people to consume content when their visual attention is situationally impaired (e.g., commuting, walking, tired eyes). However, due to the linear nature of audio, such apps do not support skimming---a non-linear, rapid form of reading---essential for quickly grasping the gist and organization of difficult texts, like academic or professional documents. To support auditory skimming for situational impairments, we (1) identified the user needs and challenges in auditory skimming through a formative study (N=20), (2) derived the concept of "eyes-reduced" skimming that blends auditory and visual modes of reading, inspired by how participants mixed visual and non-visual interactions, (3) generated a set of design guidelines for eyes-reduced skimming, and (4) designed and evaluated a novel audio skimming app that embodies the guidelines. Our in-situ preliminary observation study (N=6) suggested that participants were positive about our design and were able to auditorily skim documents. We discuss design implications for eyes-reduced reading, read-aloud apps, and text-to-speech engines.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {situational impairments, accessibility, eyes-free, text-to-speech, interactive prototype, design guidelines, skim reading, mobile device, eyes-reduced},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376769,
author = {Marky, Karola and Zimmermann, Verena and Funk, Markus and Daubert, J\"{o}rg and Bleck, Kira and M\"{u}hlh\"{a}user, Max},
title = {Improving the Usability and UX of the Swiss Internet Voting Interface},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376769},
doi = {10.1145/3313831.3376769},
abstract = {Up to 20% of residential votes and up to 70% of absentee votes in Switzerland are cast online. The Swiss system aims to provide individual verifiability by different verification codes. The voters have to carry out verification on their own, making the usability and UX of the interface of great importance. To improve the usability, we first performed an evaluation with 12 human-computer interaction experts to uncover usability weaknesses of the Swiss Internet voting interface. Based on the experts' findings, related work, and an exploratory user study with 36 participants, we propose a redesign that we evaluated in a user study with 49 participants. Our study confirmed that the redesign indeed improves the detection of incorrect votes by 33% and increases the trust and understanding of the voters. Our studies furthermore contribute important lessons for designing verifiable e-voting systems in general.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {usability evaluation, individual verifiability, e-voting},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376419,
author = {Peck, Tabitha C. and Good, Jessica J. and Bourne, Kimberly A.},
title = {Inducing and Mitigating Stereotype Threat Through Gendered Virtual Body-Swap Illusions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376419},
doi = {10.1145/3313831.3376419},
abstract = {A psychological phenomenon termed "stereotype threat" has been shown to contribute to women's underperformance and underrepresentation in math and science fields. Within the virtual reality literature, a recent study utilized gendered body-swap illusions (i.e., women in male virtual bodies) to mitigate the effects of stereotype threat among a sample of female participants. The present research provides a much needed replication of this intervention, as well as a critical extension of virtual reality research on the Proteus Effect to test whether stereotype threat can be induced among male participants immersed in a female virtual body. Results supported both the replication and extension hypotheses; female participants embodied in male avatars were buffered from stereotype threat whereas male participants embodied in female avatars suffered from stereotype threat. Avatar gender also influenced participants' math confidence and awareness of the negative societal stereotype regarding women's math ability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {stereotype threat, embodiment, gender identity, self-avatars, body-swap illusions, gender, virtual reality, proteus effect},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376536,
author = {Lehmann, Florian and Buschek, Daniel},
title = {Heartbeats in the Wild: A Field Study Exploring ECG Biometrics in Everyday Life},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376536},
doi = {10.1145/3313831.3376536},
abstract = {This paper reports on an in-depth study of electrocardiogram (ECG) biometrics in everyday life. We collected ECG data from 20 people over a week, using a non-medical chest tracker. We evaluated user identification accuracy in several scenarios and observed equal error rates of 9.15% to 21.91%, heavily depending on 1) the number of days used for training, and 2) the number of heartbeats used per identification decision. We conclude that ECG biometrics can work in the wild but are less robust than expected based on the literature, highlighting that previous lab studies obtained highly optimistic results with regard to real life deployments. We explain this with noise due to changing body postures and states as well as interrupted measures. We conclude with implications for future research and the design of ECG biometrics systems for real world deployments, including critical reflections on privacy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {biometrics, electrocardiogram, ecg, field study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376861,
author = {Foley, Margaret and Casiez, G\'{e}ry and Vogel, Daniel},
title = {Comparing Smartphone Speech Recognition and Touchscreen Typing for Composition and Transcription},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376861},
doi = {10.1145/3313831.3376861},
abstract = {Ruan et al. found transcribing short phrases with speech recognition nearly 200% faster than typing on a smartphone. We extend this comparison to a novel composition task, using a protocol that enables a controlled comparison with transcription. Results show that both composing and transcribing with speech is faster than typing. But, the magnitude of this difference is lower with composition, and speech has a lower error rate than keyboard during composition, but not during transcription. When transcribing, speech outperformed typing in most NASA-TLX measures, but when composing, there were no significant differences between typing and speech for any measure except physical demand.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {text entry, mobile phones, speech recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376136,
author = {Tejada, Carlos E. and Ramakers, Raf and Boring, Sebastian and Ashbrook, Daniel},
title = {AirTouch: 3D-Printed Touch-Sensitive Objects Using Pneumatic Sensing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376136},
doi = {10.1145/3313831.3376136},
abstract = {3D printing technology can be used to rapidly prototype the look and feel of 3D objects. However, the objects produced are passive. There has been increasing interest in making these objects interactive, yet they often require assembling components or complex calibration. In this paper, we contribute AirTouch, a technique that enables designers to fabricate touch-sensitive objects with minimal assembly and calibration using pneumatic sensing. AirTouch-enabled objects are 3D printed as a single structure using a consumer-level 3D printer. AirTouch uses pre-trained machine learning models to identify interactions with fabricated objects, meaning that there is no calibration required once the object has completed printing. We evaluate our technique using fabricated objects with various geometries and touch sensitive locations, obtaining accuracies of at least 90% with 12 interactive locations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {pneumatic sensing, 3d printing, touch interactio},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376455,
author = {Asai, Kentaro and Fukusato, Tsukasa and Igarashi, Takeo},
title = {Integrated Development Environment with Interactive Scatter Plot for Examining Statistical Modeling},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376455},
doi = {10.1145/3313831.3376455},
abstract = {The development of a statistical modeling program requires example data to observe and verify the behavior of the program. Such example data are either taken from an existing dataset or synthesized using commands. Programmers may want to directly design an arbitrary dataset or modify it interactively, but it is difficult to do so in current development environments. We therefore propose combining a code editor with an interactive scatter plot editor to efficiently understand the behavior of statistical modeling algorithms. The user interactively creates and modifies the dataset on the scatter plot editor, while the system continuously executes the code in the editor, taking the data as input, and shows the result in the editor. This paper presents the design rationale behind the system and introduces several usage scenarios.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {statistical modeling, live programming, interactive data design and editing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376628,
author = {Drey, Tobias and Gugenheimer, Jan and Karlbauer, Julian and Milo, Maximilian and Rukzio, Enrico},
title = {VRSketchIn: Exploring the Design Space of Pen and Tablet Interaction for 3D Sketching in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376628},
doi = {10.1145/3313831.3376628},
abstract = {Sketching in virtual reality (VR) enhances perception and understanding of 3D volumes, but is currently a challenging task, as spatial input devices (e.g., tracked controllers) do not provide any scaffolding or constraints for mid-air interaction. We present VRSketchIn, a VR sketching application using a 6DoF-tracked pen and a 6DoF-tracked tablet as input devices, combining unconstrained 3D mid-air with constrained 2D surface-based sketching. To explore what possibilities arise from this combination of 2D (pen on tablet) and 3D input (6DoF pen), we present a set of design dimensions and define the design space for 2D and 3D sketching interaction metaphors in VR. We categorize prior art inside our design space and implemented a subset of metaphors for pen and tablet sketching in our prototype. To gain a deeper understanding which specific sketching operations users perform with 2D and which with 3D metaphors, we present findings of usability walkthroughs with six participants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sketching, pen and tablet, design space, interaction metaphors, virtual reality, mid-air painting},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376237,
author = {Di Bartolomeo, Sara and Pandey, Aditeya and Leventidis, Aristotelis and Saffo, David and Syeda, Uzma Haque and Carstensdottir, Elin and Seif El-Nasr, Magy and Borkin, Michelle A. and Dunne, Cody},
title = {Evaluating the Effect of Timeline Shape on Visualization Task Performance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376237},
doi = {10.1145/3313831.3376237},
abstract = {Timelines are commonly represented on a horizontal line, which is not necessarily the most effective way to visualize temporal event sequences. However, few experiments have evaluated how timeline shape influences task performance. We present the design and results of a controlled experiment run on Amazon Mechanical Turk (n=192) in which we evaluate how timeline shape affects task completion time, correctness, and user preference. We tested 12 combinations of 4 shapes --- horizontal line, vertical line, circle, and spiral — and 3 data types — recurrent, non-recurrent, and mixed event sequences. We found good evidence that timeline shape meaningfully affects user task completion time but not correctness and that users have a strong shape preference. Building on our results, we present design guidelines for creating effective timeline visualizations based on user task and data types. A free copy of this paper, the evaluation stimuli and data, and code are available https://osf.io/qr5yu/},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {temporal event sequences, timelines, controlled experiments, information visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376357,
author = {Ryding, Karin},
title = {The Silent Conversation: Designing for Introspection and Social Play in Art Museums},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376357},
doi = {10.1145/3313831.3376357},
abstract = {This paper presents an attempt to design for a combination of social play and introspection using a ludic approach within an art museum setting. The field trial is described of a mobile web app called 'Never let me go', a two-player system enabling visitors to an art museum to create impromptu experiences in-situ for a companion. The study reveals that players used the app for communicating with each other during the visit, often without speaking. This led to deeply personal and introspective moments, as well as, lots of teasing and playing. The implications of allowing for social, personal and playful experiences in an art museum are discussed, as well as, the advantages and challenges of designing for improvisation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {social, introspective, play, impromptu experience design, experience, personalisation, museums, art, affective, mobile},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376543,
author = {Hanton, Ollie and Wessely, Michael and Mueller, Stefanie and Fraser, Mike and Roudaut, Anne},
title = {ProtoSpray: Combining 3D Printing and Spraying to Create Interactive Displays with Arbitrary Shapes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376543},
doi = {10.1145/3313831.3376543},
abstract = {ProtoSpray is a fabrication method that combines 3D printing and spray coating, to create interactive displays of arbitrary shapes. Our approach makes novel use of 3D printed conductive channels to create base electrodes on 3D shapes. This is then combined with spraying active materials to produce illumination. We demonstrate the feasibility and benefits of this combined approach in 6 evaluations exploring different shaped topologies. We analyze factors such as spray orientations, surface topologies and printer resolutions, to discuss how spray nozzles can be integrated into traditional 3D printers. We present a series of ProtoSprayed objects demonstrating how our technique goes beyond existing fabrication techniques by allowing creation of displays on objects with curvatures as complex as a Mobius strip. Our work provides a platform to empower makers to use displays as a fabrication material.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {3d printing, electroluminescence, spraying, rapid prototyping, display, fabrication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376142,
author = {Gorski, Peter Leo and Acar, Yasemin and Lo Iacono, Luigi and Fahl, Sascha},
title = {Listen to Developers! A Participatory Design Study on Security Warnings for Cryptographic APIs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376142},
doi = {10.1145/3313831.3376142},
abstract = {The positive effect of security information communicated to developers through API warnings has been established. However, current prototypical designs are based on security warnings for end-users. To improve security feedback for developers, we conducted a participatory design study with 25 professional software developers in focus groups. We identify which security information is considered helpful in avoiding insecure cryptographic API use during development. Concerning console messages, participants suggested five core elements, namely message classification, title message, code location, link to detailed external resources, and color. Design guidelines for end-user warnings are only partially suitable in this context. Participants emphasized the importance of tailoring the detail and content of security information to the context. Console warnings call for concise communication; further information needs to be linked externally. Therefore, security feedback should transcend tools and should be adjustable by software developers across development tools, considering the work context and developer needs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {software development, participatory design, cryptographic apis, focus groups, developer console, security warning design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376407,
author = {Superti Pantoja, Luiza and Diederich, Kyle and Crawford, Liam and Corbett, Megan and Klemm, Samantha and Peterman, Kerry and Currin, Flannery and Hourcade, Juan Pablo},
title = {Play-Based Design: Giving 3- to 4-Year-Old Children a Voice in the Design Process},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376407},
doi = {10.1145/3313831.3376407},
abstract = {There has been a dramatic growth in interactive technology use by children under the age of 5 during the past decade. Despite this growth, children under the age of 5 typically participate only as users or testers in the design process in the overwhelming majority of projects targeting this population presented in key child-computer interaction venues. In this paper we introduce play-based design, an age-appropriate design method to give 3-4-year-old children a voice in the design process. More specifically, we contribute a thorough analysis of the use of existing methods to design technologies for children under the age of 5, a summary of the process that resulted in the development of play-based design, a detailed description of play-based design, a qualitative analysis of our experience implementing play-based design with two groups of children, and a discussion of play-based design's place among other methods, its advantages, and limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {preschool, design methods, children, play},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376244,
author = {Lee, Byungjoo and Nancel, Mathieu and Kim, Sunjun and Oulasvirta, Antti},
title = {AutoGain: Gain Function Adaptation with Submovement Efficiency Optimization},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376244},
doi = {10.1145/3313831.3376244},
abstract = {A well-designed control-to-display gain function can improve pointing performance with indirect pointing devices like trackpads. However, the design of gain functions is challenging and mostly based on trial and error. AutoGain is a novel method to individualize a gain function for indirect pointing devices in contexts where cursor trajectories can be tracked. It gradually improves pointing efficiency by using a novel submovement-level tracking+optimization technique that minimizes aiming error (undershooting/overshooting) for each submovement. We first show that AutoGain can produce, from scratch, gain functions with performance comparable to commercial designs, in less than a half-hour of active use. Second, we demonstrate AutoGain's applicability to emerging input devices (here, a Leap Motion controller) with no reference gain functions. Third, a one-month longitudinal study of normal computer use with AutoGain showed performance improvements from participants' default functions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {submovement, cd gain functions, human performance, pointing, pointing facilitation, pointer acceleration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376207,
author = {Rao, Hrishikesh V. and O'Modhrain, Sile},
title = {2Across: A Comparison of Audio-Tactile and Screen-Reader Based Representations of a Crossword Puzzle},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376207},
doi = {10.1145/3313831.3376207},
abstract = {Crosswords are a popular recreational game that relies on the spatial relationship between words. As a player answers clues, they begin to organize words to form an intersecting grid. A good non-visual representation should convey the interrelation of words and support the user in building a practical spatial image of the crossword grid. This paper looks at two approaches to representing a crossword puzzle for visually impaired users: a screen reader based crossword, and an audio-tactile crossword puzzle. We evaluate the designs in a study with 10 visually impaired participants. The audio-tactile representation was found to support the practical use of the crossword's spatial structure while the screen reader based puzzle leveraged participant's prior experience in navigating websites. The paper discusses critical aspects of our study and presents a perspective on the use of multimodal interfaces for such spatial applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {accessibility, refreshable braille display, audio-tactile},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376143,
author = {Ahmetovic, Dragan and Sato, Daisuke and Oh, Uran and Ishihara, Tatsuya and Kitani, Kris and Asakawa, Chieko},
title = {ReCog: Supporting Blind People in Recognizing Personal Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376143},
doi = {10.1145/3313831.3376143},
abstract = {We present ReCog, a mobile app that enables blind users to recognize objects by training a deep network with their own photos of such objects. This functionality is useful to differentiate personal objects, which cannot be recognized with pre-trained recognizers and may lack distinguishing tactile features. To ensure that the objects are well-framed in the captured photos, ReCog integrates a camera-aiming guidance that tracks target objects and instructs the user through verbal and sonification feedback to appropriately frame them.We report a two-session study with 10 blind participants using ReCog for object training and recognition, with and without guidance. We show that ReCog enables blind users to train and recognize their personal objects, and that camera-aiming guidance helps novice users to increase their confidence, achieve better accuracy, and learn strategies to capture better photos.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {photography guidance, object recognition, visual impairment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376216,
author = {Marathe, Megh and Chandra, Priyank},
title = {Officers Never Type: Examining the Persistence of Paper in e-Governance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376216},
doi = {10.1145/3313831.3376216},
abstract = {The Global South has seen a proliferation of e-governance initiatives aimed at digitizing governmental service delivery. However, paper continues to remain the primary medium of bureaucracy. During ethnographic fieldwork at the CM Helpline, a state-wide e-governance initiative in central India, we observed that even tech-savvy bureaucrats who fully supported both the initiative and its paper-to-electronic transition ensured that paper continues to persist in abundance. Drawing upon scholarship from HCI, anthropology, and science &amp; technology studies, we theorize this contradiction to uncover the circulations of power between people, paper, and electronic systems. We suggest that designers should recognize that new systems often disempower existing actors. The process of transition should integrate new systems into the existing ecosystem and plan for the graceful retirement of older technologies. In addition to machine errors, systems should be resilient to human errors. Finally, new systems should attend to sociocultural and historical specificities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {paper, power, design, persistence, bureaucracy, structural violence, e-governance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376780,
author = {P\"{a}\"{a}kk\"{o}nen, Juho and Nelimarkka, Matti and Haapoja, Jesse and Lampinen, Airi},
title = {Bureaucracy as a Lens for Analyzing and Designing Algorithmic Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376780},
doi = {10.1145/3313831.3376780},
abstract = {Scholarship on algorithms has drawn on the analogy between algorithmic systems and bureaucracies to diagnose shortcomings in algorithmic decision-making. We extend the analogy further by drawing on Michel Crozier's theory of bureaucratic organizations to analyze the relationship between algorithmic and human decision-making power. We present algorithms as analogous to impartial bureaucratic rules for controlling action, and argue that discretionary decision-making power in algorithmic systems accumulates at locations where uncertainty about the operation of algorithms persists. This key point of our essay connects with Alkhatib and Bernstein's theory of 'street-level algorithms', and highlights that the role of human discretion in algorithmic systems is to accommodate uncertain situations which inflexible algorithms cannot handle. We conclude by discussing how the analysis and design of algorithmic systems could seek to identify and cultivate important sources of uncertainty, to enable the human discretionary work that enhances systemic resilience in the face of algorithmic errors.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {automated decision-making, street-level bureaucracies, algorithmic power, uncertainty, bureaucracy, algorithmic systems, street-level algorithms},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376684,
author = {Alfaras, Miquel and Tsaknaki, Vasiliki and Sanches, Pedro and Windlin, Charles and Umair, Muhammad and Sas, Corina and H\"{o}\"{o}k, Kristina},
title = {From Biodata to Somadata},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376684},
doi = {10.1145/3313831.3376684},
abstract = {Biosensing technologies are increasingly available as off-the-shelf products, yet for many designers, artists and non-engineers, these technologies remain difficult to design with. Through a soma design stance, we devised a novel approach for exploring qualities in biodata. Our explorative process culminated in the design of three artefacts, coupling biosignals to tangible actuation formats. By making biodata perceivable as sound, in tangible form or directly on the skin, it became possible to link qualities of the measurements to our own somatics - our felt experience of our bodily bioprocesses - as they dynamically unfold, spurring somatically-grounded design discoveries of novel possible interactions. We show that making biodata attainable for a felt experience - or as we frame it: turning biodata into somadata - enables not only first-person encounters, but also supports collaborative design processes as the somadata can be shared and experienced dynamically, right at the moment when we explore design ideas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {affective technology, interaction design, biosensing, soma design, first-person perspective},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376560,
author = {Gorkovenko, Katerina and Burnett, Daniel J. and Thorp, James K. and Richards, Daniel and Murray-Rust, Dave},
title = {Exploring The Future of Data-Driven Product Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376560},
doi = {10.1145/3313831.3376560},
abstract = {Connected devices present new opportunities to advance design through data collection in the wild, similar to the way digital services evolve through analytics. However, it is still unclear how live data transmitted by connected devices informs the design of these products, going beyond performance optimisation to support creative practices. Design can be enriched by data captured by connected devices, from usage logs to environmental sensors, and data about the devices and people around them. Through a series of workshops, this paper contributes industry and academia perspectives on the future of data-driven product design. We highlight HCI challenges, issues and implications, including sensemaking and the generation of design insight. We further challenge current notions of data-driven design and envision ways in which future HCI research can develop ways to work with data in the design process in a connected, rich, human manner.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {in the wild, human-centred design, smart devices, design research, iot, data-driven design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376488,
author = {Cryan, Jenna and Tang, Shiliang and Zhang, Xinyi and Metzger, Miriam and Zheng, Haitao and Zhao, Ben Y.},
title = {Detecting Gender Stereotypes: Lexicon vs. Supervised Learning Methods},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376488},
doi = {10.1145/3313831.3376488},
abstract = {Biases in language influence how we interact with each other and society at large. Language affirming gender stereotypes is often observed in various contexts today, from recommendation letters and Wikipedia entries to fiction novels and movie dialogue. Yet to date, there is little agreement on the methodology to quantify gender stereotypes in natural language (specifically the English language). Common methodology (including those adopted by companies tasked with detecting gender bias) rely on a lexicon approach largely based on the original BSRI study from 1974.In this paper, we reexamine the role of gender stereotype detection in the context of modern tools, by comparatively analyzing efficacy of lexicon-based approaches and end-to-end, ML-based approaches prevalent in state-of-the-art natural language processing systems. Our efforts using a large dataset show that even compared to an updated lexicon-based approach, end-to-end classification approaches are significantly more robust and accurate, even when trained by moderately sized corpora.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {gender bias, lexicon, machine learning, gender stereotypes, natural language processing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376650,
author = {Richardson, Dan and Kharrufa, Ahmed},
title = {We Are the Greatest Showmen: Configuring a Framework for Project-Based Mobile Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376650},
doi = {10.1145/3313831.3376650},
abstract = {Little research has explored how mobile-learning technologies could be used by students to produce interactive artefacts during project-based learning processes. Following a design-based approach, we report on engagements spanning classroom and outdoor learning with students (ages 6-13) and teachers from three different UK schools and a summer school of Travelling Showchildren. Working within the time constraints of each context, we deployed a variety of configurations of a project-based mobile learning (PBML) framework intended to support the production of student-designed mobile-learning activities. We contribute insights gained from these engagements, including how mobile technologies can harness students' existing desire for independence and how they can be configured to leverage the physical and social attributes of place and community as learning resources. We argue for further exploration of the potential roles for mobile technologies within project-based learning, and contribute our PBML framework with recommendations for its re-configuration in response to contextual constraints.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {project-based learning, mobile-learning, digital civics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376367,
author = {Yang, Yalong and Marriott, Kim and Butler, Matthew and Goncu, Cagatay and Holloway, Leona},
title = {Tactile Presentation of Network Data: Text, Matrix or Diagram?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376367},
doi = {10.1145/3313831.3376367},
abstract = {Visualisations are commonly used to understand social, biological and other kinds of networks. Currently we do not know how to effectively present network data to people who are blind or have low-vision (BLV). We ran a controlled study with 8 BLV participants comparing four tactile representations: organic node-link diagram, grid node-link diagram, adjacency matrix and braille list. We found that the node-link representations were preferred and more effective for path following and cluster identification while the matrix and list were better for adjacency tasks. This is broadly in line with findings for the corresponding visual representations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {vision impairment, graphvisualization, blindness, adjacency matrix, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376790,
author = {Glenn, Terrell and Ipsita, Ananya and Carithers, Caleb and Peppler, Kylie and Ramani, Karthik},
title = {StoryMakAR: Bringing Stories to Life With An Augmented Reality &amp; Physical Prototyping Toolkit for Youth},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376790},
doi = {10.1145/3313831.3376790},
abstract = {Makerspaces can support educational experiences in prototyping for children. Storytelling platforms enable high levels of creativity and expression, but have high barriers of entry. We introduce StoryMakAR, which combines making and storytelling. StoryMakAR is a new AR-IoT system for children that uses block programming, physical prototyping, and event-based storytelling to bring stories to life. We reduce the barriers to entry for youth (Age=14-18) by designing an accessible, plug-and-play system through merging both electro-mechanical devices and virtual characters to create stories. We describe our initial design process, the evolution and workflow of StoryMakAR, and results from multiple single-session workshops with 33 high school students. Our preliminary studies led us to understand what students want to make. We provide evidence of how students both engage and have difficulties with maker-based storytelling. We also discuss the potential for StoryMakAR to be used as a learning environment for classrooms and younger students.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {maker culture, storytelling, augmented reality, children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376671,
author = {Bentley, Frank and O'Neill, Kathleen and Quehl, Katie and Lottridge, Danielle},
title = {Exploring the Quality, Efficiency, and Representative Nature of Responses Across Multiple Survey Panels},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376671},
doi = {10.1145/3313831.3376671},
abstract = {A common practice in HCI research is to conduct a survey to understand the generalizability of findings from smaller-scale qualitative research. These surveys are typically deployed to convenience samples, on low-cost platforms such as Amazon's Mechanical Turk or Survey Monkey, or to more expensive market research panels offered by a variety of premium firms. Costs can vary widely, from hundreds of dollars to tens of thousands of dollars depending on the platform used. We set out to understand the accuracy of ten different survey platforms/panels compared to ground truth data for a total of 6,007 respondents on 80 different aspects of demographic and behavioral questions. We found several panels that performed significantly better than others on certain topics, while different panels provided longer and more relevant open-ended responses. Based on this data, we highlight the benefits and pitfalls of using a variety of survey distribution options in terms of the quality, efficiency, and representative nature of the respondents and the types of responses that can be obtained.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {survey, representative, mturk, surveymonkey},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376191,
author = {T\"{u}rkay, Selen and Formosa, Jessica and Adinolf, Sonam and Cuthbert, Robert and Altizer, Roger},
title = {See No Evil, Hear No Evil, Speak No Evil: How Collegiate Players Define, Experience and Cope with Toxicity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376191},
doi = {10.1145/3313831.3376191},
abstract = {Toxicity in online environments is a complex and a systemic issue. Collegiate esports communities seem to be particularly vulnerable to toxic behaviors. In esports games, negative behavior, such as harassment, can create barriers to players achieving high performance and can reduce enjoyment which may cause them to leave the game. The aim of this study is to investigate how players define, experience and deal with toxicity in esports games that they play. Our findings from an interview study and five monthly follow ups with 19 participants from a university esports club show that players define toxicity as behaviors disrupt their morale and team dynamics, and are inclined to normalize negative behaviors, rationalize it as part of the competitive game culture akin to traditional sports, and participate a form of gamer classism, believing that toxicity is more common in lower level play than in professional and collegiate esports. There are many coping mechanisms employed by collegiate esports players, including ignoring offenders, deescalating tense encounters, and using tools to mute offenders. Understanding the motivations behind collegiate esports players' engagement with toxicity may help the growing sport plot a positive trajectory towards healthy play.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {competitive games, player perceptions, interview study, toxicity, esports},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376683,
author = {Naseem, Mustafa and Saleem, Bilal and St-Onge Ahmad, Sacha and Chen, Jay and Raza, Agha Ali},
title = {An Empirical Comparison of Technologically Mediated Advertising in Under-Connected Populations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376683},
doi = {10.1145/3313831.3376683},
abstract = {Information and Communication Technology interventions have the potential to improve outcomes in health and other development sectors in low-income settings. Large-scale impact, however, remains the central challenge for the HCI4D community as significant and diverse resources are typically required to scale such interventions beyond the pilot stage. In contrast, voice-based entertainment services accessible over simple phones, designed for similarly low-income, low-literate populations manage to scale 'virally' to tens of thousands of users with little to no advertising cost. Our study compares the outcomes of using voice-based entertainment to spread a maternal-health hotline against conventional advertisement channels including paper flyers, posters, radio, TV, social media and robocalls. Through an 11-week deployment in Pakistan where the hotline reached 21,770 users over 32,625 calls, we find that the entertainment service outperformed other channels on all popular user acquisition metrics, with the exception of robocalls, which lead in terms of spread.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {advertisement, ict4d, flyers, under-connected, low-literate, radio, social media, ivr, pakistan, tv, robocalls, banners, interactive voice response, hci4d, mobile phone, television},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376583,
author = {Hsu, Silas and Vaccaro, Kristen and Yue, Yin and Rickman, Aimee and Karahalios, Karrie},
title = {Awareness, Navigation, and Use of Feed Control Settings Online},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376583},
doi = {10.1145/3313831.3376583},
abstract = {Control settings are abundant and have significant effects on user experiences. One example of an impactful but understudied area is feed settings. In this study, we investigated awareness, navigation, and use of feed settings. We began by creating a taxonomy of feed settings on social media and search sites. Via an online survey, we measured awareness of Facebook feed settings. An in-person interview study then investigated how people navigated to and chose to set feed settings on their own feeds. We discovered that many participants did not believe ad personalization feed settings existed. Furthermore, we discovered a misalignment in the expectation and the function of settings, especially of ad personalization settings for many participants. Despite all participants struggling to find at least one setting, participants overall wanted to use settings: 94% altered at least one setting they encountered. From these results, we discuss implications and suggest design guidelines for settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {settings, social media, control, feeds},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376605,
author = {Watson, Hue and Moju-Igbene, Eyitemi and Kumari, Akanksha and Das, Sauvik},
title = {"We Hold Each Other Accountable": Unpacking How Social Groups Approach Cybersecurity and Privacy Together},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376605},
doi = {10.1145/3313831.3376605},
abstract = {Digital resources are often collectively owned and shared by small social groups (e.g., friends sharing Netflix accounts, roommates sharing game consoles, families sharing WhatsApp groups). Yet, little is known about (i) how these groups jointly navigate cybersecurity and privacy (S&amp;P) decisions for shared resources, (ii) how shared experiences influence individual S&amp;P attitudes and behaviors, and (iii) how well existing S&amp;P controls map onto group needs. We conducted group interviews and a supplemental diary study with nine social groups (n=34) of varying relationship types. We identified why, how and what resources groups shared, their jointly construed threat models, and how these factors influenced group strategies for securing shared resources. We also identified missed opportunities for cooperation and stewardship among group members that could have led to improved S&amp;P behaviors, and found that existing S&amp;P controls often fail to meet the needs of these small social groups.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {qualitative methods, interviews, security, groups, privacy, social cybersecurity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376165,
author = {Dev, Jayati and Rader, Emilee and Patil, Sameer},
title = {Why Johnny Can't Unsubscribe: Barriers to Stopping Unwanted Email},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376165},
doi = {10.1145/3313831.3376165},
abstract = {A large proportion of email messages in an average Internet user's inbox are unwanted commercial messages from mailing lists, bots, and so on. Although such messages often include instructions to unsubscribe, people still struggle with stopping unwanted email. We investigated the user experience of unsubscribing from unwanted email messages by recruiting 18 individuals for via a lab study followed by semi-structured interviews. Based on unsubscribing practices of the study participants, we synthesized eight common unsubscription mechanisms and identified the corresponding user experience challenges. We further uncovered alternative practices aimed at circumventing the need to unsubscribe. Our findings reveal frustration with the prevailing options for limiting access to the self by managing email boundaries. We apply our insight to offer design suggestions that could help commercial providers improve the user experience of unsubscribing and provide users more control over the email they receive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {privacy, boundary management, unsubscribing, newsletters, opt-out, unwanted email, mailing lists, marketing email},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376627,
author = {Hodge, James and Foley, Sarah and Brankaert, Rens and Kenning, Gail and Lazar, Amanda and Boger, Jennifer and Morrissey, Kellie},
title = {Relational, Flexible, Everyday: Learning from Ethics in Dementia Research},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376627},
doi = {10.1145/3313831.3376627},
abstract = {Engaging in participatory research in HCI raises numerous ethical complexities such as consent, researcher relationships, and participant compensation. Doing HCI work in the area of dementia amplifies these issues, and researchers in this area are modelling ethical stances to ensure researcher-participant relationships focus on meaningful engagement and care. This paper presents an insight into the kinds of ethical foci required when doing design research with people living with dementia and their carers. We interviewed 22 HCI researchers with experience working in dementia care contexts. Our qualitative analysis outlines subsequent lessons-learned, such as recognition of the participants, self-care, research impact, and subjectivity in ethical review boards. Furthermore, we found the complexity of navigating both "everyday" and more formal, institutional ethics in dementia research has implications beyond the context of working with people with dementia and outline key considerations for ethical practices in socially orientated HCI research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {care, lived experience, dementia, relational, emotion, ethics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376545,
author = {Dourish, Paul and Lawrence, Christopher and Leong, Tuck Wah and Wadley, Greg},
title = {On Being Iterated: The Affective Demands of Design Participation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376545},
doi = {10.1145/3313831.3376545},
abstract = {Iteration is a central feature of most HCI design methods, creating as it does opportunities for engagements with stakeholder groups. But what does iteration demand of those groups? Under what conditions do iterative engagements arise, and with what stakes? Building on experiences with Aboriginal Australian communities, and drawing on feminist and decolonial thinking, we examine the nature of iteration for HCI and how it frames encounters between design and use, with a focus on the affective dimension of engagement in iterative design processes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {iteration, postcolonial theory, cultural computing, feminist theory, user-centered design, decolonial theory, participation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376378,
author = {Lam, Amy T. and Griffin, Jonathan and Loeun, Matthew Austin and Cira, Nate J. and Lee, Seung Ah and Riedel-Kruse, Ingmar H.},
title = {Pac-Euglena: A Living Cellular Pac-Man Meets Virtual Ghosts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376378},
doi = {10.1145/3313831.3376378},
abstract = {The advancement of biotechnology enabled the development of "biotic video games", where human players manipulate real biological samples for fun and educational human-biology interactions. However, new design principles are needed to both leverage and mitigate biological properties (e.g., variability and stochasticity), and create unique play experiences that transcend traditional video games. This paper describes the implementation of Pac-Euglena, a biotic Pac-Man analog, where players guide live microscopic Euglena cells with light stimuli through a physical microfluidic maze. Through use of multi-modal stimuli, a mixed biology-digital-human reality is achieved, enabling cell interactions with virtual ghosts and collectibles. Through an iterative design process, we illustrate challenges and strategies for designing games with living organisms. A user study (n=18, conducted at a university event) showed that Pac-Euglena was fun, stimulated curiosity, and taught users about Euglena. We conclude with five general guidelines for the design and development of biotic games and HBI interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mixed reality, euglena gracilis, biotic games, augmented reality, biological user interfaces, human-biology interaction (hbi)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376831,
author = {Mirza-Babaei, Pejman and Stahlke, Samantha and Wallner, G\"{u}nter and Nova, Atiya},
title = {A Postmortem on Playtesting: Exploring the Impact of Playtesting on the Critical Reception of Video Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376831},
doi = {10.1145/3313831.3376831},
abstract = {Game studios aim to develop titles that deliver a fun and engaging experience for players. Playtesting promises to help identify opportunities to improve player experience and assist developers in achieving their design intent. However, a lack of research on the added value of playtesting means that many studios are still uncertain about its commercial viability and impact on product success. This gap in understanding is further complicated by the vague definition of "success" afforded by sales figures and review scores. In this paper, we assess reported feature quality of three commercial titles by analyzing playtesting reports and game reviews. By comparing themes and design issues expressed in game reviews to the results of pre-release playtesting for each game, we aim to highlight the value of playtesting and propose a set of guidelines for selecting playtest methods based on the needs of a given game evaluation. Through the real-world case studies presented, this paper contributes to the growing domain of games user research and highlights the value of playtesting in game development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {games user research, game reviews, playtesting},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376338,
author = {Scott, Kristen M. and Ashby, Simone and Hanna, Julian},
title = {"Human, All Too Human": NOAA Weather Radio and the Emotional Impact of Synthetic Voices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376338},
doi = {10.1145/3313831.3376338},
abstract = {The integration of text-to-speech into an open technology stack for low-power FM community radio stations is an opportunity to automate laborious processes and increase accessibility to information in remote communities. However, there are open questions as to the perceived contrast of synthetic voices with the local and intimate format of community radio. This paper presents an exploratory focus group on the topic, followed by a thematic analysis of public comments on YouTube videos of the synthetic voices used for broadcasting by National Oceanic and Atmospheric Administration (NOAA) Weather Radio. We find that despite observed reservations about the suitability of TTS for radio, there is significant evidence of anthropomorphism, nostalgia and emotional connection in relation to these voices. Additionally, introduction of a more "human sounding" synthetic voice elicited significant negative feedback. We identify pronunciation, speed, suitability to content and acknowledgment of limitations as more relevant factors in listeners' stated sense of connection.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {text-to-speech, anthropomorphism, uncanny valley, synthetic speech, noaa weather radio},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376524,
author = {August, Tal and Card, Dallas and Hsieh, Gary and Smith, Noah A. and Reinecke, Katharina},
title = {Explain like I Am a Scientist: The Linguistic Barriers of Entry to r/Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376524},
doi = {10.1145/3313831.3376524},
abstract = {As an online community for discussing research findings, r/science has the potential to contribute to science outreach and communication with a broad audience. Yet previous work suggests that most of the active contributors on r/science are science-educated people rather than a lay general public. One potential reason is that r/science contributors might use a different, more specialized language than used in other subreddits. To investigate this possibility, we analyzed the language used in more than 68 million posts and comments from 12 subreddits from 2018. We show that r/science uses a specialized language that is distinct from other subreddits. Transient (newer) authors of posts and comments on r/science use less specialized language than more frequent authors, and those that leave the community use less specialized language than those that stay, even when comparing their first comments. These findings suggest that the specialized language used in r/science has a gatekeeping effect, preventing participation by people whose language does not align with that used in r/science. By characterizing r/science's specialized language, we contribute guidelines and tools for increasing the number of contributors in r/science.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {reddit, science communication, social computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376379,
author = {Gr\o{}nb\ae{}k, Jens Emil and Knudsen, Mille Skovhus and O'Hara, Kenton and Krogh, Peter Gall and Vermeulen, Jo and Petersen, Marianne Graves},
title = {Proxemics Beyond Proximity: Designing for Flexible Social Interaction Through Cross-Device Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376379},
doi = {10.1145/3313831.3376379},
abstract = {Cross-device interactions enable ad hoc sharing of content and control in co-located collaboration. Cross-device research often draws from proxemics theory for designing interactions based on detection of spatial relations such as distance and orientation between people and devices. However, detection of human-human or human-device proximity also constrains flexibility in co-located social interaction. We suggest a proxemics-based approach to designing flexible cross-device interactions. From observations in a field study, we articulate how co-located sharing practices are shaped by the interplay between everyday mobile devices and the physical environment. Based on these insights, we present three cross-device prototypes as proofs-of-concept, demonstrating three design sensitivities for considering proxemics beyond proximity; incorporating features in the environment, enabling flexibility in interpersonal distance and orientation, and providing multiple alternative action possibilities. Drawing from characteristics of our prototypes, we discuss concrete proposals for designing cross-device interactions to enable flexible social interaction.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {sensing systems, interaction proxemics, cross-device interaction, ad hoc collaboration, proximity sensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376227,
author = {Wu, Shanel and Devendorf, Laura},
title = {Unfabricate: Designing Smart Textiles for Disassembly},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376227},
doi = {10.1145/3313831.3376227},
abstract = {Smart textiles development is combining computing and textile technologies to create tactile, functional objects such as smart garments, soft medical devices, and space suits. However, the field also combines the massive waste streams of both the digital electronics and textiles industries. The following work explores how HCI researchers might be poised to address sustainability and waste in future smart textiles development through interventions at design time. Specifically, we perform a design inquiry into techniques and practices for reclaiming and reusing smart textiles materials and explore how such techniques can be integrated into smart textiles design tools. Beginning with a practice in sustainable or "slow" fashion, unravelling a garment into yarn, the suite of explorations titled "Unfabricate" probes values of time and labor in crafting a garment; speculates how a smart textile garment may be designed with reuse in mind; and imagines how electronic and textile components may be given new life in novel uses.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {computer-aided design, weaving, smart textiles, sustainability, disassembly, unraveling, knitting},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376441,
author = {Yi, Xin and Wang, Chen and Bi, Xiaojun and Shi, Yuanchun},
title = {PalmBoard: Leveraging Implicit Touch Pressure in Statistical Decoding for Indirect Text Entry},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376441},
doi = {10.1145/3313831.3376441},
abstract = {We investigated how to incorporate implicit touch pressure, finger pressure applied to a touch surface during typing, to improve text entry performance via statistical decoding. We focused on one-handed touch-typing on indirect interface as an example scenario. We first collected typing data on a pressure-sensitive touchpad, and analyzed users' typing behavior such as touch point distribution, key-to-finger mappings, and pressure images. Our investigation revealed distinct pressure patterns for different keys. Based on the findings, we performed a series of simulations to iteratively optimize the statistical decoding algorithm. Our investigation led to a Markov-Bayesian decoder incorporating pressure image data into decoding. It improved the top-1 accuracy from 53% to 74% over a naive Bayesian decoder. We then implemented PalmBoard, a text entry method that implemented the Markov-Bayesian decoder and effectively supported one-handed touch-typing on indirect interfaces. A user study showed participants achieved an average speed of 32.8 WPM with 0.6% error rate. Expert typists could achieve 40.2 WPM with 30 minutes of practice. Overall, our investigation showed that incorporating implicit touch pressure is effective in improving text entry decoding.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {touch pressure, touch-typing, text entry, input prediction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376504,
author = {Wampfler, Rafael and Klingler, Severin and Solenthaler, Barbara and Schinazi, Victor R. and Gross, Markus},
title = {Affective State Prediction Based on Semi-Supervised Learning from Smartphone Touch Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376504},
doi = {10.1145/3313831.3376504},
abstract = {Gaining awareness of the user's affective states enables smartphones to support enriched interactions that are sensitive to the user's context. To accomplish this on smartphones, we propose a system that analyzes the user's text typing behavior using a semi-supervised deep learning pipeline for predicting affective states measured by valence, arousal, and dominance. Using a data collection study with 70 participants on text conversations designed to trigger different affective responses, we developed a variational auto-encoder to learn efficient feature embeddings of two-dimensional heat maps generated from touch data while participants engaged in these conversations. Using the learned embedding in a cross-validated analysis, our system predicted three levels (low, medium, high) of valence (AUC up to 0.84), arousal (AUC up to 0.82), and dominance (AUC up to 0.82). These results demonstrate the feasibility of our approach to accurately predict affective states based only on touch data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {affective computing, smartphone, deep learning, classification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376264,
author = {Seymour, William and Kraemer, Martin J. and Binns, Reuben and Van Kleek, Max},
title = {Informing the Design of Privacy-Empowering Tools for the Connected Home},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376264},
doi = {10.1145/3313831.3376264},
abstract = {Connected devices in the home represent a potentially grave new privacy threat due to their unfettered access to the most personal spaces in people's lives. Prior work has shown that despite concerns about such devices, people often lack sufficient awareness, understanding, or means of taking effective action. To explore the potential for new tools that support such needs directly we developed Aretha, a privacy assistant technology probe that combines a network disaggregator, personal tutor, and firewall, to empower end-users with both the knowledge and mechanisms to control disclosures from their homes. We deployed Aretha in three households over six weeks, with the aim of understanding how this combination of capabilities might enable users to gain awareness of data disclosures by their devices, form educated privacy preferences, and to block unwanted data flows. The probe, with its novel affordances-and its limitations-prompted users to co-adapt, finding new control mechanisms and suggesting new approaches to address the challenge of regaining privacy in the connected home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {technology probe, privacy-empowering technology, network disaggregator},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376141,
author = {Damen, Ida and Lallemand, Carine and Brankaert, Rens and Brombacher, Aarnout and van Wesemael, Pieter and Vos, Steven},
title = {Understanding Walking Meetings: Drivers and Barriers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376141},
doi = {10.1145/3313831.3376141},
abstract = {There is increased interest in reducing sedentary behavior of office workers to combat the negative health effects of prolonged sitting. Walking meetings offer a promising solution to this problem as they facilitate a physically active way of working. To inform future development of technologies supporting these type of meetings, in-depth qualitative insights into people's experiences of walking meetings are needed. We conducted semi-structured walking interviews (N=16) to identify key drivers and barriers for walking meetings in a living lab setting by using the 'WorkWalk'. The 'WorkWalk' is a 1.8 km walking route indicated by a dotted blue line with outdoor meeting points, integrated into the room booking system. Our findings provide insights into how walking meetings are experienced and affect the set-up and social dynamics of meetings. We offer design recommendations for the development of future technologies and service design elements to support walking meetings and active ways of working.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {walking meetings, office workers, design research, physical activity, field study, sedentary behavior},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376510,
author = {Stawarz, Katarzyna and Preist, Chris and Tallon, Deborah and Thomas, Laura and Turner, Katrina and Wiles, Nicola and Kessler, David and Shafran, Roz and Coyle, David},
title = {Integrating the Digital and the Traditional to Deliver Therapy for Depression: Lessons from a Pragmatic Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376510},
doi = {10.1145/3313831.3376510},
abstract = {Traditional approaches to psychotherapy emphasise face-to-face contact between patients and therapists. In contrast, current computerised approaches tend to minimise this contact. This can limit the range of mental health difficulties for which computerised approaches are effective. Here, we explore an alternative approach that integrates face-to-face contact, electronic contact, online collaboration, and support for between-session activities. Our discussion is grounded in the design of a platform to deliver psychotherapy for depression. We report findings of an 11-month pragmatic study in which 17 patients received treatment for depression via the platform. Results show how design decisions had a significant impact on the dynamics of therapeutic sessions and the establishment of patient-therapist relationships. For example, the use of instant messaging for synchronous, in-session contact slowed communication, but also provided a valuable space for reflection and helped to maintain session focus. We discuss the impact of flexibility and the potential of integrated approaches to both enhance and reduce patient engagement.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {blended therapy, cognitive behavioural therapy, health technology, patient-therapist communication, mental health, cbt, depression, integrated approach},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376720,
author = {B\"{u}ttner, Sebastian and Prilla, Michael and R\"{o}cker, Carsten},
title = {Augmented Reality Training for Industrial Assembly Work - Are Projection-Based AR Assistive Systems an Appropriate Tool for Assembly Training?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376720},
doi = {10.1145/3313831.3376720},
abstract = {Augmented Reality (AR) systems are on their way to industrial application, e.g. projection-based AR is used to enhance assembly work. Previous studies showed advantages of the systems in permanent-use scenarios, such as faster assembly times. In this paper, we investigate whether such systems are suitable for training purposes. Within an experiment, we observed the training with a projection-based AR system over multiple sessions and compared it with a personal training and a paper manual training. Our study shows that projection-based AR systems offer only small benefits in the training scenario. While a systematic mislearning of content is prevented through immediate feedback, our results show that the AR training does not reach the personal training in terms of speed and recall precision after 24 hours. Furthermore, we show that once an assembly task is properly trained, there are no differences in the long-term recall precision, regardless of the training method.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {training, empirical study, projection-based augmented reality, assistive system, industrial augmented reality, assembly, experiment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376568,
author = {Bennett, Cynthia L. and Rosner, Daniela K. and Taylor, Alex S.},
title = {The Care Work of Access},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376568},
doi = {10.1145/3313831.3376568},
abstract = {Current approaches to AI and Assistive Technology (AT) often foreground task completion over other encounters such as expressions of care. Our paper challenges and complements such task-completion approaches by attending to the care work of access-the continual affective and emotional adjustments that people make by noticing and attending to one another. We explore how this work impacts encounters among people with and without vision impairments who complete tasks together. We find that bound up in attempts to get things done are concerns for one another and how well people are doing together. Reading this work through emerging disability studies and feminist STS scholarship, we account for two important forms of work that give rise to access: (1) mundane attunements and (2) non-innocent authorizations. Together these processes work as sensitizing concepts to help HCI scholars account for the ways that intelligent ATs both produce access while sometimes subverting people with disabilities.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {assistance, blind, care, interdependence, disability, vision impaired, artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376879,
author = {Rohani, Darius A. and Quemada Lopategui, Andrea and Tuxen, Nanna and Faurholt-Jepsen, Maria and Kessing, Lars V. and Bardram, Jakob E.},
title = {MUBS: A Personalized Recommender System for Behavioral Activation in Mental Health},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376879},
doi = {10.1145/3313831.3376879},
abstract = {Depression is a leading cause of disability worldwide, which has inspired the design of mobile health (mHealth) applications for disease monitoring, prediction, and diagnosis. Less mHealth research has, however, focused on the treatment of depressive disorders. Clinical evidence shows that depressive symptoms can be reduced through a behavior change method known as Behavioral Activation (BA). This paper presents MUBS; a smartphone-based system for BA, which specifically contributes a personalized content-based activity recommendation model using a unique list of validated activities. An 8-week feasibility study with 17 depressive patients provided detailed insight into how MUBS provided inspiration and motivation for planning and engaging in more pleasant activities, thereby facilitating the core components of BA. Based on this study, the paper discusses how recommender technology can be used in the design of mHealth technology for BA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {recommendation, mental health, smartphone, planning, behavioral activation, well-being, depression, activities},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376873,
author = {Lai, Vivian and Liu, Han and Tan, Chenhao},
title = {"Why is 'Chicago' Deceptive?" Towards Building Model-Driven Tutorials for Humans},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376873},
doi = {10.1145/3313831.3376873},
abstract = {To support human decision making with machine learning models, we often need to elucidate patterns embedded in the models that are unsalient, unknown, or counterintuitive to humans. While existing approaches focus on explaining machine predictions with real-time assistance, we explore model-driven tutorials to help humans understand these patterns in a train- ing phase. We consider both tutorials with guidelines from scientific papers, analogous to current practices of science communication, and automatically selected examples from training data with explanations. We use deceptive review detection as a testbed and conduct large-scale, randomized human-subject experiments to examine the effectiveness of such tutorials. We find that tutorials indeed improve human performance, with and without real-time assistance. In particular, although deep learning provides superior predictive performance than simple models, tutorials and explanations from simple models are more useful to humans. Our work suggests future directions for human-centered tutorials and explanations towards a synergy between humans and AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {explanations, deception detection, interpretable machine learning, tutorials},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376825,
author = {Agrawal, Ankit and Abraham, Sophia J. and Burger, Benjamin and Christine, Chichi and Fraser, Luke and Hoeksema, John M. and Hwang, Sarah and Travnik, Elizabeth and Kumar, Shreya and Scheirer, Walter and Cleland-Huang, Jane and Vierhauser, Michael and Bauer, Ryan and Cox, Steve},
title = {The Next Generation of Human-Drone Partnerships: Co-Designing an Emergency Response System},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376825},
doi = {10.1145/3313831.3376825},
abstract = {The use of semi-autonomous Unmanned Aerial Vehicles (UAV) to support emergency response scenarios, such as fire surveillance and search and rescue, offers the potential for huge societal benefits. However, designing an effective solution in this complex domain represents a "wicked design" problem, requiring a careful balance between trade-offs associated with drone autonomy versus human control, mission functionality versus safety, and the diverse needs of different stakeholders. This paper focuses on designing for situational awareness (SA) using a scenario-driven, participatory design process. We developed SA cards describing six common design-problems, known as SA demons, and three new demons of importance to our domain. We then used these SA cards to equip domain experts with SA knowledge so that they could more fully engage in the design process. We designed a potentially reusable solution for achieving SA in multi-stakeholder, multi-UAV, emergency response applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {unmanned aerial vehicles, participatory design, emergency response, situational awareness, human-CPS interactions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376571,
author = {Mohaddesi, Omid and Sun, Yifan and Azghandi, Rana and Doroudi, Rozhin and Snodgrass, Sam and Ergun, Ozlem and Griffin, Jacqueline and Kaeli, David and Marsella, Stacy and Harteveld, Casper},
title = {Introducing Gamettes: A Playful Approach for Capturing Decision-Making for Informing Behavioral Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376571},
doi = {10.1145/3313831.3376571},
abstract = {Agent-based simulations are widely used for modeling human behavior in various contexts. However, such simulations may oversimplify human decision-making. We propose the use of Gamettes to extract rich data on human decision-making and help in improving the human behavioral aspects of models underlying agent-based simulations. We show how Gamettes are designed and provide empirical validation for using Gamettes in an experimental supply chain setting to study human decision-making. Our results show that Gamettes are successful in capturing the expected behaviors and patterns in supply chain decisions, and, thus, we find evidence for the capability of Gamettes to inform behavioral models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {decision-making, beer game, human behavior, agent-based model, supply chain, gamette, simulation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376665,
author = {Kuzminykh, Anastasia and Sun, Jenny and Govindaraju, Nivetha and Avery, Jeff and Lank, Edward},
title = {Genie in the Bottle: Anthropomorphized Perceptions of Conversational Agents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376665},
doi = {10.1145/3313831.3376665},
abstract = {This paper presents a qualitative multi-phase study seeking to identify patterns in users' anthropomorphized perceptions of conversational agents. Through a comparative analysis of behavioral perceptions and visual conceptions of three agents - Alexa, Google Assistant, and Siri - we first show that the perceptions of an agent's character are structured according to five categories: approachability, sentiment toward a user, professionalism, intelligence, and individuality. We then explore visualizations of the agents' appearance and discuss the specifics assigned to each agent. Finally, we analyze associative explanations for these perceptions. We demonstrate that the anthropomorphized behavioral and visual perceptions of agents yield structural consistency and discuss how these perceptions are linked with each other and system features.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {conversational agents, user perception, visual, personification, anthropomorphism, behavioral, interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376370,
author = {Honary, Mahsa and Bell, Beth and Clinch, Sarah and Vega, Julio and Kroll, Leo and Sefi, Aaron and McNaney, Roisin},
title = {Shaping the Design of Smartphone-Based Interventions for Self-Harm},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376370},
doi = {10.1145/3313831.3376370},
abstract = {Self-harm is a prevalent issue amongst young people, yet it is thought around 40% will never seek professional help due to stigma surrounding it. It is generally a way of coping with emotional distress and can have a range of triggers which are highly heterogeneous to the individual. In a move towards enhancing the accessibility of personalized interventions for self-harm, we undertook a three-stage study. We first conducted interviews with 4 counsellors in self-harm to understand how they clinically respond to self-harm triggers. We then ran a survey with 37 young people, to explore perceptions of mobile sensing, and current and future uses for smartphone-based interventions. Finally, we ran a workshop with 11 young people to further explore how a context-aware self-management application might be used to support them. We contribute an in-depth understanding of how triggers for self-harm might be identified and subsequently predicted and prevented using mobile-sensing technology.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mobile sensing, situation-aware app, intervention, trust, mental health, non-suicidal self-injury, self-harm, co-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376295,
author = {Gadiraju, Vinitha and Muehlbradt, Annika and Kane, Shaun K.},
title = {BrailleBlocks: Computational Braille Toys for Collaborative Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376295},
doi = {10.1145/3313831.3376295},
abstract = {Braille literacy has fallen in recent years, and many blind children now grow up without learning Braille. However, learning Braille can increase employment chances and improve literacy skills. We introduce BrailleBlocks, a system to help visually impaired children learn and practice Braille alongside a sighted parent. BrailleBlocks comprises a set of tangible blocks and pegs, each block representing a Braille cell, and an associated application with games. The system automatically tracks and recognizes the blocks so that parents can follow along even if they cannot read Braille. We conducted a user study to test BrailleBlocks with five families, with five parents and six visually impaired children. The contributions of this work are a novel approach to Braille education toys, observations of how visually impaired children and sighted parents used this system together, their insights on current issues with Braille educational tools, and actionable feedback for future Braille-based learning tools.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {blind, visually impaired, collaboration, education, children, braille, accessibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376550,
author = {Bai, Huidong and Sasikumar, Prasanth and Yang, Jing and Billinghurst, Mark},
title = {A User Study on Mixed Reality Remote Collaboration with Eye Gaze and Hand Gesture Sharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376550},
doi = {10.1145/3313831.3376550},
abstract = {Supporting natural communication cues is critical for people to work together remotely and face-to-face. In this paper we present a Mixed Reality (MR) remote collaboration system that enables a local worker to share a live 3D panorama of his/her surroundings with a remote expert. The remote expert can also share task instructions back to the local worker using visual cues in addition to verbal communication. We conducted a user study to investigate how sharing augmented gaze and gesture cues from the remote expert to the local worker could affect the overall collaboration performance and user experience. We found that by combing gaze and gesture cues, our remote collaboration system could provide a significantly stronger sense of co-presence for both the local and remote users than using the gaze cue alone. The combined cues were also rated significantly higher than the gaze in terms of ease of conveying spatial actions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {scene reconstruction, augmented reality, hand gesture, 3d panorama, remote collaboration, eye gaze, virtual reality, mixed reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376314,
author = {Williams, Kristin and Pulivarthy, Rajitha and Hudson, Scott E. and Hammer, Jessica},
title = {The Upcycled Home: Removing Barriers to Lightweight Modification of the Home's Everyday Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376314},
doi = {10.1145/3313831.3376314},
abstract = {The Internet-of-things (IoT) embeds computing in everyday objects, but has largely focused on new devices while ignoring the home's many existing possessions. We present a field study with 10 American families to understand how these possessions could be included in the smart home through upcycling. We describe three patterns for how families collaborate around home responsibilities; we explore families' mental models of home that may be in tension with existing IoT systems; and we identify ways that families can more easily imagine a smart home that includes their existing possessions. These insights can help us design an upcycled approach to IoT that supports users in reconfiguring objects (and social roles as mediated by objects) in a way that is sensitive to what will be displaced, discarded, or made obsolete. Our findings inform the design of future lightweight systems for the upcycled home.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smart home, intersectionality, family coordination, division of labor, sustainability, iot, internet-of-things, personal inventories, upcycle},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376442,
author = {Drosos, Ian and Barik, Titus and Guo, Philip J. and DeLine, Robert and Gulwani, Sumit},
title = {Wrex: A Unified Programming-by-Example Interaction for Synthesizing Readable Code for Data Scientists},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376442},
doi = {10.1145/3313831.3376442},
abstract = {Data wrangling is a difficult and time-consuming activity in computational notebooks, and existing wrangling tools do not fit the exploratory workflow for data scientists in these environments. We propose a unified interaction model based on programming-by-example that generates readable code for a variety of useful data transformations, implemented as a Jupyter notebook extension called Wrex. User study results demonstrate that data scientists are significantly more effective and efficient at data wrangling with Wrex over manual programming. Qualitative participant feedback indicates that Wrex was useful and reduced barriers in having to recall or look up the usage of various data transform functions. The synthesized code allowed data scientists to verify the intended data transformation, increased their trust and confidence in Wrex, and fit seamlessly within their cell-based notebook workflows. This work suggests that presenting readable code to professional data scientists is an indispensable component of offering data wrangling tools in notebooks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {program synthesis, computational notebooks, data science},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376548,
author = {Hua, Yiqing and Naaman, Mor and Ristenpart, Thomas},
title = {Characterizing Twitter Users Who Engage in Adversarial Interactions against Political Candidates},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376548},
doi = {10.1145/3313831.3376548},
abstract = {Social media provides a critical communication platform for political figures, but also makes them easy targets for harassment. In this paper, we characterize users who adversarially interact with political figures on Twitter using mixed-method techniques. The analysis is based on a dataset of 400 thousand users' 1.2 million replies to 756 candidates for the U.S. House of Representatives in the two months leading up to the 2018 midterm elections. We show that among moderately active users, adversarial activity is associated with decreased centrality in the social graph and increased attention to candidates from the opposing party. When compared to users who are similarly active, highly adversarial users tend to engage in fewer supportive interactions with their own party's candidates and express negativity in their user profiles. Our results can inform the design of platform moderation mechanisms to support political figures countering online harassment.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {user behavior, twitter, online harassment, political candidates},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376731,
author = {Arawjo, Ian},
title = {To Write Code: The Cultural Fabrication of Programming Notation and Practice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376731},
doi = {10.1145/3313831.3376731},
abstract = {Writing and its means have become detached. Unlike written and drawn practices developed prior to the 20th century, notation for programming computers developed in concert and conflict with discretizing infrastructure such as the shift-key typewriter and data processing pipelines. In this paper, I recall the emergence of high-level notation for representing computation. I show how the earliest inventors of programming notations borrowed from various written cultural practices, some of which came into conflict with the constraints of digitizing machines, most prominently the typewriter. As such, I trace how practices of "writing code" were fabricated along social, cultural, and material lines at the time of their emergence. By juxtaposing early visions with the modern status quo, I question long-standing terminology, dichotomies, and epistemological tendencies in the field of computer programming. Finally, I argue that translation work is a fundamental property of the practice of writing code by advancing an intercultural lens on programming practice rooted in history.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {programming, materiality, culture, infrastructure, notation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376714,
author = {Dehesa, Javier and Vidler, Andrew and Lutteroth, Christof and Padget, Julian},
title = {Touch\'{e}: Data-Driven Interactive Sword Fighting in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376714},
doi = {10.1145/3313831.3376714},
abstract = {VR games offer new freedom for players to interact naturally using motion. This makes it harder to design games that react to player motions convincingly. We present a framework for VR sword fighting experiences against a virtual character that simplifies the necessary technical work to achieve a convincing simulation. The framework facilitates VR design by abstracting from difficult details on the lower "physical" level of interaction, using data-driven models to automate both the identification of user actions and the synthesis of character animations. Designers are able to specify the character's behaviour on a higher "semantic" level using parameterised building blocks, which allow for control over the experience while minimising manual development work. We conducted a technical evaluation, a questionnaire study and an interactive user study. Our results suggest that the framework produces more realistic and engaging interactions than simple hand-crafted interaction logic, while supporting a controllable and understandable behaviour design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {virtual reality, machine learning, animation, sword fighting, gesture recognition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376640,
author = {Gorichanaz, Tim},
title = {Engaging with Public Art: An Exploration of the Design Space},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376640},
doi = {10.1145/3313831.3376640},
abstract = {At its best, public art can promote moral learning in individuals and societies, and digital technology can help achieve this value. As a first step in creating such systems, this paper presents a probe study exploring the design space of reflective engagement with public art. The probe took the form of a mural journal, which was distributed to participants in Philadelphia. The findings show how public art journaling can be integrated into one's life, both logistically and psychologically, and the value of art journaling for introspection, cultivating attention and having fun. This study surfaces a number of tensions in the design space that designers must navigate, such as the question of reflecting with public art on site (now) versus at home (later). This work provides designers with the grounds for informed inspiration to ideate systems that deepen people's experiences with public art.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design probe, reflection, public art, moral learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376672,
author = {Lyngs, Ulrik and Lukoff, Kai and Slovak, Petr and Seymour, William and Webb, Helena and Jirotka, Marina and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
title = { 'I Just Want to Hack Myself to Not Get Distracted': Evaluating Design Interventions for Self-Control on Facebook},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376672},
doi = {10.1145/3313831.3376672},
abstract = {Beyond being the world's largest social network, Facebook is for many also one of its greatest sources of digital distraction. For students, problematic use has been associated with negative effects on academic achievement and general wellbeing. To understand what strategies could help users regain control, we investigated how simple interventions to the Facebook UI affect behaviour and perceived control. We assigned 58 university students to one of three interventions: goal reminders, removed newsfeed, or white background (control). We logged use for 6 weeks, applied interventions in the middle weeks, and administered fortnightly surveys. Both goal reminders and removed newsfeed helped participants stay on task and avoid distraction. However, goal reminders were often annoying, and removing the newsfeed made some fear missing out on information. Our findings point to future interventions such as controls for adjusting types and amount of available information, and flexible blocking which matches individual definitions of 'distraction'.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {facebook, self-control, addiction, problematic use, distraction, ict non-use, focus, interruptions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376885,
author = {Bowen, Simon and Wright, Peter and Wilson, Alexander and Dow, Andy and Bartindale, Tom and Anderson, Robert},
title = {Metro Futures: Experience-Centred Co-Design at Scale},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376885},
doi = {10.1145/3313831.3376885},
abstract = {This paper discusses how characteristics of experience-centred and collaborative design can be translated to larger scales. We describe Metro Futures, a region-wide public consultation on the design of new light rail trains, where we followed an experience-centred co-design approach supported by digital media and tools to develop findings with a core group of 20 ?co-researchers' and ~4000 public participants. The paper discusses how the characteristics of a focus on experience, and collaborative design exploration were achieved with co-researchers and, at scale, through online and face-to-face interactions using various digital media and tools. Whilst not at the depth of smaller scales, there are opportunities to retain characteristics of experience-centred co-design at scale to produce findings that can usefully inform ensuing design work, and avoid the averaging of public contributions often evident in large scale public consultations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {public transport, experience-centred design, large-scale design, co-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376668,
author = {Rutten, Isa and Geerts, David},
title = {Better Because It's New: The Impact of Perceived Novelty on the Added Value of Mid-Air Haptic Feedback},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376668},
doi = {10.1145/3313831.3376668},
abstract = {Mid-air haptic (MAH) feedback, providing touch feedback through ultrasound, has been considered an attractive substitute for the absence of physical touch during gesture-based interaction. Although the impact of MAH feedback on workload has already received some attention, the impact on other qualities of the user experience, including general attractiveness and experienced pleasure have been less investigated. In this preregistered study, involving 32 participants, we observed an added value of MAH feedback, on top of visual feedback, by increasing the attractiveness and experienced pleasure during gesture-based interaction, but not by decreasing workload. The added value regarding pleasure and attractiveness disappeared however after statistically controlling for perceived novelty. This paper highlights the importance of statistically controlling for novelty when testing the user experience of new technology during first-time use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {pleasure, gesture-based interaction, mid-air haptic feedback, workload, user experience, novelty, attractiveness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376256,
author = {Michael, Alexander and Lutteroth, Christof},
title = {Race Yourselves: A Longitudinal Exploration of Self-Competition Between Past, Present, and Future Performances in a VR Exergame},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376256},
doi = {10.1145/3313831.3376256},
abstract = {Participating in competitive races can be a thrilling experience for athletes, involving a rush of excitement and sensations of flow, achievement, and self-fulfilment. However, for non-athletes, the prospect of competition is often a scary one which affects intrinsic motivation negatively, especially for less fit, less competitive individuals. We propose a novel method making the positive racing experience accessible to non-athletes using a high-intensity cycling VR exergame: by recording and replaying all their previous gameplay sessions simultaneously, including a projected future performance, players can race against a crowd of "ghost" avatars representing their individual fitness journey. The experience stays relevant and exciting as every race adds a new competitor. A longitudinal study over four weeks and a cross-sectional study found that the new method improves physical performance, intrinsic motivation, and flow compared to a non-competitive exergame. Additionally, the longitudinal study provides insights into the longer-term effects of VR exergames.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {ghosts, intrinsic motivation, self-competition, longitudinal, performance, exergame, virtual reality (vr)},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376647,
author = {Gautam, Aakash and Tatar, Deborah and Harrison, Steve},
title = {Crafting, Communality, and Computing: Building on Existing Strengths To Support a Vulnerable Population},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376647},
doi = {10.1145/3313831.3376647},
abstract = {In Nepal, sex-trafficking survivors and the organizations that support them have limited resources to assist the survivors in their on-going journey towards reintegration. We take an asset-based approach wherein we identify and build on the strengths possessed by such groups. In this work, we present reflections from introducing a voice-annotated web application to a group of survivors. The web application tapped into and built upon two elements of pre-existing strengths possessed by the survivors — the social bond between them and knowledge of crafting as taught to them by the organization. Our findings provide insight into the array of factors influencing how the survivors act in relation to one another as they created novel use practices and adapted the technology. Experience with the application seemed to open knowledge of computing as a potential source of strength. Finally, we articulate three design desiderata that could help promote communal spaces: make activity perceptible to the group, create appropriable steps, and build in fun choices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {asset-based, sensitive setting, communal space, global south, hci4d, ictd},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376889,
author = {Sanches, Pedro and Tsaknaki, Vasiliki and Rostami, Asreen and Brown, Barry},
title = {Under Surveillance: Technology Practices of Those Monitored by the State},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376889},
doi = {10.1145/3313831.3376889},
abstract = {This paper documents the experiences of those living under state surveillance. We interviewed our participants about how they lived under threat, and how it changed their technology practices. Our participants spanned three groups - journalists who reported from countries where their activities were illegal; activists who took part in civil disobedience, and individuals who worked in illegal activities that would have likely led to prosecution. In our analysis we cover four themes: first, 'the imagined surveillant'. Second, the danger and dependencies of technology use, third, their coping strategies, and lastly how belonging to a group can protect but also expose. In our discussion we cover how we can design for dissidents, and how to deal with the difficult questions this raises. We conclude by advocating for research that takes into account a critical view of the state in HCI and more broadly for an anti-surveillance stance in the design of technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {state, surveillance, dissidents},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376308,
author = {Morreale, Fabio and Eriksson, Maria},
title = {"My Library Has Just Been Obliterated": Producing New Norms of Use Via Software Update},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376308},
doi = {10.1145/3313831.3376308},
abstract = {Software updates are commonly perceived as tools for fixing flaws and improving functionality. In this paper, we problematise this view by showing how software updates may also be used by vendors to create new norms of use that control user behaviour and reduce their agency. We explore the nature and aftermath of a controversial software update that was released by Spotify in June 2019. By analysing almost 3,500 reactions to this update, we show how it removed and modified several features in ways that severely affected users' capability to organise, navigate, and maintain their music libraries, while it pushed modes of listening that delegate song selection to Spotify. Elaborating upon our results, we discuss how updates may be used as political tools that privilege certain forms of behaviour while restricting others. We also portray updates as sites where ongoing struggles and negotiations regarding user agency and digital ownership take place.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {critical computing, spotify, protocological power, music streaming, psychological ownership, normative affordances},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376691,
author = {Alrashed, Tarfah and Almahmoud, Jumana and Zhang, Amy X. and Karger, David R.},
title = {ScrAPIr: Making Web Data APIs Accessible to End Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376691},
doi = {10.1145/3313831.3376691},
abstract = {Users have long struggled to extract and repurpose data from websites by laboriously copying or scraping content from web pages. An alternative is to write scripts that pull data through APIs. This provides a cleaner way to access data than scraping; however, APIs are effortful for programmers and nigh-impossible for non-programmers to use. In this work, we empower users to access APIs without programming. We evolve a schema for declaratively specifying how to interact with a data API. We then develop ScrAPIr: a standard query GUI that enables users to fetch data through any API for which a specification exists, and a second GUI that lets users author and share the specification for a given API. From a lab evaluation, we find that even non-programmers can access APIs using ScrAPIr, while programmers can access APIs 3.8 times faster on average using ScrAPIr than using programming.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {web scraping, web apis, api description language},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376533,
author = {Liu, Yang and Althoff, Tim and Heer, Jeffrey},
title = {Paths Explored, Paths Omitted, Paths Obscured: Decision Points &amp; Selective Reporting in End-to-End Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376533},
doi = {10.1145/3313831.3376533},
abstract = {Drawing reliable inferences from data involves many, sometimes arbitrary, decisions across phases of data collection, wrangling, and modeling. As different choices can lead to diverging conclusions, understanding how researchers make analytic decisions is important for supporting robust and replicable analysis. In this study, we pore over nine published research studies and conduct semi-structured interviews with their authors. We observe that researchers often base their decisions on methodological or theoretical concerns, but subject to constraints arising from the data, expertise, or perceived interpretability. We confirm that researchers may experiment with choices in search of desirable results, but also identify other reasons why researchers explore alternatives yet omit findings. In concert with our interviews, we also contribute visualizations for communicating decision processes throughout an analysis. Based on our results, we identify design opportunities for strengthening end-to-end analysis, for instance via tracking and meta-analysis of multiple decision paths.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interview study, analytic decision making, garden of forking paths, reproducibility, multiverse analysis, data analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376589,
author = {Duan, Peitong and Wierzynski, Casimir and Nachman, Lama},
title = {Optimizing User Interface Layouts via Gradient Descent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376589},
doi = {10.1145/3313831.3376589},
abstract = {Automating parts of the user interface (UI) design process has been a longstanding challenge. We present an automated technique for optimizing the layouts of mobile UIs. Our method uses gradient descent on a neural network model of task performance with respect to the model's inputs to make layout modifications that result in improved predicted error rates and task completion times. We start by extending prior work on neural network based performance prediction to 2-dimensional mobile UIs with an expanded interaction space. We then apply our method to two UIs, including one that the model had not been trained on, to discover layout alternatives with significantly improved predicted performance. Finally, we confirm these predictions experimentally, showing improvements up to 9.2 percent in the optimized layouts. This demonstrates the algorithm's efficacy in improving the task performance of a layout, and its ability to generalize and improve layouts of new interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {optimization, mobile interfaces, lstm, gradient descent, deep learning, data-driven design, performance modeling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376208,
author = {Varghese, Delvin and Rainey, Jay and Montague, Kyle and Bartindale, Tom and Olivier, Patrick and Baillie Smith, Matt},
title = {Utilizing Participant Voice in Volunteer Training},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376208},
doi = {10.1145/3313831.3376208},
abstract = {Delivering training to volunteers is a huge challenge for non-governmental organisations (NGOs). Traditional classroom-based approaches that dominate training are problematic due to the limited participation they offer to trainees. Peer-led approaches however, have shown promise in helping NGOs utilise trainee experiences within training. Although technologies are playing an increasing role in training, their benefits are not well understood. We describe our experience of designing peer-led training for community volunteers in rural India. Working alongside an NGO involved in community regeneration and social action, we collaboratively delivered a ten-day training workshop, deploying audio technologies to engage the participants in sharing lived experiences. We draw on reflections from trainers and trainees on how utilising participant voice can enhance training. We highlight opportunities around the usage of audio technologies for engaging with participant voice, including the ability to reclaim trainee agency within training and to work within cultural barriers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {organizational training, audio technologies, ictd, ngo, hci4d, learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376603,
author = {Bardzell, Jeffrey and Freeman, Guo and Bardzell, Shaowen and Chen, Pei-Ying},
title = {Join.Love: A Sociotechnical Genealogy of the Legalization of Same-Sex Marriage},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376603},
doi = {10.1145/3313831.3376603},
abstract = {HCI researchers interested in enhancing democracy have introduced methods and technologies that support democratic political processes, such as voting, and more broadly on empowering people to more fully participate in an increasingly technologized world. The aspiration for technologies to support meaningful democratic outcomes is not misplaced. In 2019, headlines around the world announced that Taiwan had become the first Asian country to legalize same-sex marriage, an impressive political achievement. But it was also an impressive technical achievement, the outcome of a concerted effort to develop responsive and impactful direct democracy platforms. We offer a sociotechnical genealogy of the process, informed by theory of deliberative democracy. We identify three opportunities for future HCI contributions: supporting less visible consensus-es, developing civic journeys, and engaging in deliberative experience design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sociotechnical ecology, same-sex marriage, deliberative experience design, deliberative democracy, citizen journeys},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376408,
author = {Tsai, Hsin-Ruey and Hung, Ching-Wen and Wu, Tzu-Chun and Chen, Bing-Yu},
title = {ElastOscillation: 3D Multilevel Force Feedback for Damped Oscillation on VR Controllers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376408},
doi = {10.1145/3313831.3376408},
abstract = {Force feedback from damped oscillation is a common effect in our daily lives, especially when shaking an elastic object, an object hanging or containing other stuff, or a container with liquid, e.g., casting with a fishing pole or wine-swirling. Such a force, affected by complex physical variations and collisions, is difficult to properly simulate using current force feedback methods. Therefore, we propose ElastOscillation on a virtual reality (VR) controller to provide 3D multilevel force feedback for damped oscillation to enhance VR experiences. ElastOscillation consists of a proxy, six elastic bands and DC motors. It leverages the motors to control the bands' elasticity to restrain the movement of the proxy, which is connected with the bands. Therefore, when users shake the ElastOscillation device, the proxy shakes or moves in corresponding ranges of movement. The users then perceive the force from oscillation at different levels. In addition, elastic force from the bands further reinforces the oscillation force feedback. We conducted a force perception study to understand users' distinguishability for perceiving oscillation forces in 1D and 2D movement, respectively. Based on the results, we performed a VR experience study to show that the force feedback provided by ElastOscillation enhances VR realism.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {haptic feedback, elastic force, oscillation, virtual reality, force feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376837,
author = {Cibrian, Franceli L. and Lakes, Kimberley D. and Tavakoulnia, Arya and Guzman, Kayla and Schuck, Sabrina and Hayes, Gillian R.},
title = {Supporting Self-Regulation of Children with ADHD Using Wearables: Tensions and Design Challenges},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376837},
doi = {10.1145/3313831.3376837},
abstract = {The design of wearable applications supporting children with Attention Deficit Hyperactivity Disorders (ADHD) requires a deep understanding not only of what is possible from a clinical standpoint but also how the children might understand and orient towards wearable technologies, such as a smartwatch. Through a series of participatory design workshops with children with ADHD and their caregivers, we identified tensions and challenges in designing wearable applications supporting the self-regulation of children with ADHD. In this paper, we describe the specific challenges of smartwatches for this population, the balance between self-regulation and co-regulation, and tensions when receiving notifications on a smartwatch in various contexts. These results indicate key considerations-from both the child and caregiver viewpoints-for designing technological interventions supporting children with ADHD.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smartwatch, design tensions, wearable, children, adhd},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376307,
author = {Clarke, Rachel Ivy and Schoonmaker, Sayward},
title = {The Critical Catalog: Library Information Systems, Tricksterism, and Social Justice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376307},
doi = {10.1145/3313831.3376307},
abstract = {In this paper, we describe the Critical Catalog, a grant-funded research through design project intended to investigate metadata elements, values, and organizational structures necessary to intentionally advocate for diversity and expose library users to resources from populations traditionally marginalized in literature and publishing. Drawing on principles from critical design, the prototype functions as a critical intervention intended to raise questions and stimulate debate, rather than a purely technical fix to deeply social concerns. A detailed reflective discussion of the design process reveals how existing infrastructural constraints shaped design decisions that led to increased advocacy and a stronger activist standpoint. We discuss the use of metadata as design material for social justice, the application of tricksterism in HCI, and how both practical limitations from professional contexts and imposed limitations based on identities and positions of power can lead to surprising places, meanings, and questions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tricksterism, library catalogs, research through design, whiteness, metadata},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376803,
author = {Lange, Daniel and Stratmann, Tim Claudius and Gruenefeld, Uwe and Boll, Susanne},
title = {HiveFive: Immersion Preserving Attention Guidance in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376803},
doi = {10.1145/3313831.3376803},
abstract = {Recent advances in Virtual Reality (VR) technology, such as larger fields of view, have made VR increasingly immersive. However, a larger field of view often results in a user focusing on certain directions and missing relevant content presented elsewhere on the screen. With HiveFive, we propose a technique that uses swarm motion to guide user attention in VR. The goal is to seamlessly integrate directional cues into the scene without losing immersiveness. We evaluate HiveFive in two studies. First, we compare biological motion (from a prerecorded swarm) with non-biological motion (from an algorithm), finding further evidence that humans can distinguish between these motion types and that, contrary to our hypothesis, non-biological swarm motion results in significantly faster response times. Second, we compare HiveFive to four other techniques and show that it not only results in fast response times but also has the smallest negative effect on immersion.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {eye-tracking, particle swarms, immersion, user studies, virtual reality, attention guidance},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376732,
author = {Wambsganss, Thiemo and Niklaus, Christina and Cetto, Matthias and S\"{o}llner, Matthias and Handschuh, Siegfried and Leimeister, Jan Marco},
title = {AL: An Adaptive Learning Support System for Argumentation Skills},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376732},
doi = {10.1145/3313831.3376732},
abstract = {Recent advances in Natural Language Processing (NLP) bear the opportunity to analyze the argumentation quality of texts. This can be leveraged to provide students with individual and adaptive feedback in their personal learning journey. To test if individual feedback on students' argumentation will help them to write more convincing texts, we developed AL, an adaptive IT tool that provides students with feedback on the argumentation structure of a given text. We compared AL with 54 students to a proven argumentation support tool. We found students using AL wrote more convincing texts with better formal quality of argumentation compared to the ones using the traditional approach. The measured technology acceptance provided promising results to use this tool as a feedback application in different learning settings. The results suggest that learning applications based on NLP may have a beneficial use for developing better writing and reasoning for students in traditional learning settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {argumentation learning, adaptive learning, educational applications, pedagogical systems},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376700,
author = {Tseng, Wen-Jie and Lee, Yi-Chen and Peiris, Roshan Lalintha and Chan, Liwei},
title = {A Skin-Stroke Display on the Eye-Ring Through Head-Mounted Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376700},
doi = {10.1145/3313831.3376700},
abstract = {We present the Skin-Stroke Display, a system mounted on the lens inside the head-mounted display, which exerts subtle yet recognizable tactile feedback on the eye-ring using a motorized air jet. To inform our design of noticeable air-jet haptic feedback, we conducted a user study to identify absolute detection thresholds. Our results show that the tactile sensation had different sensitivity around the eyes, and we determined a standard intensity (8 mbar) to prevent turbulent airflow blowing into the eyes. In the second study, we asked participants to adjust the intensity around the eye for equal sensation based on standard intensity. Next, we investigated the recognition of point and stroke stimuli with or without inducing cognitive load on eight directions on the eye-ring. Our longStroke stimulus can achieve an accuracy of 82.6% without cognitive load and 80.6% with cognitive load simulated by the Stroop test. Finally, we demonstrate example applications using the skin-stroke display as the off-screen indicator, tactile I/O progress display, and tactile display.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {air jet, eye-ring, head-mounted display, virtual reality, skin-stroke display, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376635,
author = {E, Jane L. and Fried, Ohad and Lu, Jingwan and Zhang, Jianming and Mech, Radom\'{\i}r and Echevarria, Jose and Hanrahan, Pat and Landay, James A.},
title = {Adaptive Photographic Composition Guidance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376635},
doi = {10.1145/3313831.3376635},
abstract = {Photographic composition is often taught as alignment with composition grids-most commonly, the rule of thirds. Professional photographers use more complex grids, like the harmonic armature, to achieve more diverse dynamic compositions. We are interested in understanding whether these complex grids are helpful to amateurs.In a formative study, we found that overlaying the harmonic armature in the camera can help less experienced photographers discover and achieve different compositions, but it can also be overwhelming due to the large number of lines. Photographers actually use subsets of lines from the armature to explain different aspects of composition. However, this occurs mainly offline to analyze existing images. We propose bringing this mental model into the camera-by adaptively highlighting relevant lines to the current scene and point of view. We describe a saliency-based algorithm for selecting these lines and present an evaluation of the system that shows that photographers found the proposed adaptive armatures helpful for capturing more well-composed images.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {photography, composition, camera interfaces, dynamic symmetry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376555,
author = {Bossauer, Paul and Neifer, Thomas and Stevens, Gunnar and Pakusch, Christina},
title = {Trust versus Privacy: Using Connected Car Data in Peer-to-Peer Carsharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376555},
doi = {10.1145/3313831.3376555},
abstract = {Trust is the lubricant of the sharing economy. This is true especially in peer-to-peer carsharing, in which one leaves a highly valuable good to a stranger in the hope of getting it back unscathed. Nowadays, ratings of other users are major mechanisms for establishing trust. To foster uptake of peer-to-peer carsharing, connected car technology opens new possibilities to support trust-building, e.g., by adding driving behavior statistics to users' profiles. However, collecting such data intrudes into rentees' privacy. To explore the tension between the need for trust and privacy demands, we conducted three focus group and eight individual interviews. Our results show that connected car technologies can increase trust for car owners and rentees not only before but also during and after rentals. The design of such systems must allow a differentiation between information in terms of type, the context, and the negotiability of information disclosure.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {privacy, trust, connected car, peer-to-peer carsharing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376328,
author = {Pretorius, Claudette and McCashin, Darragh and Kavanagh, Naoise and Coyle, David},
title = {Searching for Mental Health: A Mixed-Methods Study of Young People's Online Help-Seeking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376328},
doi = {10.1145/3313831.3376328},
abstract = {Seeking help is often an important step in addressing mental health difficulties. Evidence suggests that positive help-seeking experiences contribute to an increased likelihood of future help-seeking and achieving improved outcomes. However, help-seeking is a complex process. Alongside traditional sources, digital technologies offer many pathways to help. Using a mixed methods approach across two studies, this paper explores key design factors for online mental health resources that can support young people's help-seeking. First, a large online survey (n=1308) highlighted challenges and identified common help-seeking scenarios, including information-seeking, person-centred approaches and crisis situations. Using survey data, personas were developed to represent different help-seekers - each characterised by a particular help-seeking scenario. The personas were then used in co-design workshops to facilitate further exploration of help-seeking needs. Four key design considerations were identified: connectedness, accessible information, personalisation, and immediacy. Based on our findings, we provide design recommendations that are grounded in existing theories of help-seeking.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {behaviour, co-design, help-seeking, mental health, mixed methods, personas, search, young people},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376760,
author = {Trajkova, Milka and Martin-Hammond, Aqueasha},
title = {"Alexa is a Toy": Exploring Older Adults' Reasons for Using, Limiting, and Abandoning Echo},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376760},
doi = {10.1145/3313831.3376760},
abstract = {Intelligent voice assistants (IVAs) have the potential to support older adults' independent living. However, despite a growing body of research focusing on IVA use, we know little about why older adults become IVA non-users. This paper examines the reasons older adults use, limit, and abandon IVAs (i.e., Amazon Echo) in their homes. We conducted eight focus groups, with 38 older adults residing in a Life Plan Community. Thirty-six participants owned an Echo for at least a year, and two were considering adoption. Over time, most participants became non-users due to their difficulty finding valuable uses, beliefs associated with ability and IVA use, or challenges with use in shared spaces. However, we also found that participants saw the potential for future IVA support. We contribute a better understanding of the reasons older adults do not engage with IVAs and how IVAs might better support aging and independent living in the future.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {older adults, focus group, voice assistants, smart environments, technology non-use, life plan community},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376784,
author = {Geeng, Christine and Yee, Savanna and Roesner, Franziska},
title = {Fake News on Facebook and Twitter: Investigating How People (Don't) Investigate},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376784},
doi = {10.1145/3313831.3376784},
abstract = {With misinformation proliferating online and more people getting news from social media, it is crucial to understand how people assess and interact with low-credibility posts. This study explores how users react to fake news posts on their Facebook or Twitter feeds, as if posted by someone they follow. We conducted semi-structured interviews with 25 participants who use social media regularly for news, temporarily caused fake news to appear in their feeds with a browser extension unbeknownst to them, and observed as they walked us through their feeds. We found various reasons why people do not investigate low-credibility posts, including taking trusted posters' content at face value, as well as not wanting to spend the extra time. We also document people's investigative methods for determining credibility using both platform affordances and their own ad-hoc strategies. Based on our findings, we present design recommendations for supporting users when investigating low-credibility posts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {twitter, trust, misinformation, fake news, social media, disinformation, verification, Facebook},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376464,
author = {Johnson, Ian G. and Al-Shahrabi, Dalya and Vines, John},
title = {From Creating Spaces for Civic Discourse to Creating Resources for Action},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376464},
doi = {10.1145/3313831.3376464},
abstract = {In this paper, we investigate the role of technology to address the concerns of a civil society group carrying out community-level consultation on the allocation of £1 million of community funds. We explore issues of devolved decision-making through the evaluation of a sociodigital system designed to foster deliberative virtues. We describe the ways in which this group used our system in their consultation practices. Our findings highlight how they adopted our technology to privilege specific forms of expression, ascertain issues in their community, make use of and make sense of community data, and create resources for action within their existing practices. Based on related fieldwork we discuss the impacts of structuring and configuring tools for 'talk-based' consultation in order to turn attention to the potential pitfalls and prospects for designing civic technologies that create resources for action for civil society.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {deliberation, sociodigital systems, digital civics, civic technology, civil society, civic participation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376275,
author = {Dove, Graham and Fayard, Anne-Laure},
title = {Monsters, Metaphors, and Machine Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376275},
doi = {10.1145/3313831.3376275},
abstract = {Machine learning (ML) poses complex challenges for user experience (UX) designers. Typically unpredictable and opaque, it may produce unforeseen outcomes detrimental to particular groups or individuals, yet simultaneously promise amazing breakthroughs in areas as diverse as medical diagnosis and universal translation. This results in a polarized view of ML, which is often manifested through a technology-as-monster metaphor. In this paper, we acknowledge the power and potential of this metaphor by resurfacing historic complexities in human-monster relations. We (re)introduce these liminal and ambiguous creatures, and discuss their relation to ML. We offer a background to designers' use of metaphor, and show how the technology-as-monster metaphor can generatively probe and (re)frame the questions ML poses. We illustrate the effectiveness of this approach through a detailed discussion of an early-stage generative design workshop inquiring into ML approaches to supporting student mental health and well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {ux design, monster theory, generative metaphor, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376734,
author = {Dechant, Martin and Poeller, Susanne and Johanson, Colby and Wiley, Katelyn and Mandryk, Regan L.},
title = {In-Game and Out-of-Game Social Anxiety Influences Player Motivations, Activities, and Experiences in MMORPGs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376734},
doi = {10.1145/3313831.3376734},
abstract = {Socializing is an important part of why people choose to play games and is at the core of many game mechanics. Anxiety and fear about social interactions can lead to withdrawal from socializing in the physical world, yet players with social anxiety preferentially choose MMORPGs — a highly social genre — raising questions of whether social anxiety expresses differently during in-game interactions. In the present study (N=181), we explore whether and how social anxiety translates into MMORPGs. By developing a measure of in-game social anxiety, we find that although fear and apprehension of socializing in the physical and game worlds are related, they differently affect preferences, behaviours, and experiences. Social anxiety in the physical world drives reasons for playing, whereas in-game anxiety affects behaviours, reducing participation in activities related to socializing and difficult in-game challenges. Our findings can inform the design of social games and the links between social anxiety and social gaming.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {socializing, MMORPG, social anxiety, online gaming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376766,
author = {Kosch, Thomas and Schmidt, Albrecht and Thanheiser, Simon and Chuang, Lewis L.},
title = {One Does Not Simply RSVP: Mental Workload to Select Speed Reading Parameters Using Electroencephalography},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376766},
doi = {10.1145/3313831.3376766},
abstract = {Rapid Serial Visual Presentation (RSVP) has gained popularity as a method for presenting text on wearable devices with limited screen space. Nonetheless, it remains unclear how to calibrate RSVP display parameters, such as spatial alignments or presentation rates, to suit the reader's information processing ability at high presentation speeds. Existing methods rely on comprehension and subjective workload scores, which are influenced by the user's knowledge base and subjective perception. Here, we use electroencephalography (EEG) to directly determine how individual information processing varies with changes in RSVP display parameters. Eighteen participants read text excerpts with RSVP in a repeated-measures design that manipulated the Text Alignment and Presentation Speed of text representation. We evaluated how predictive EEG metrics were of gains in reading speed, subjective workload, and text comprehension. We found significant correlations between EEG and increasing Presentation Speeds and propose how EEG can be used for dynamic selection of RSVP parameters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cognitive load, workload-aware interfaces, electroencephalography, working memory, rsvp},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376819,
author = {Do, Seungwon and Lee, Byungjoo},
title = {Improving Reliability of Virtual Collision Responses: A Cue Integration Technique},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376819},
doi = {10.1145/3313831.3376819},
abstract = {In virtual reality (VR), a user's virtual avatar can interact with a virtual object by colliding with it. If collision responses do not occur in the direction that the user expects, the user experiences degradation of accuracy and precision in applications such as VR sports games. In determining the response of a virtual collision, existing physics engines have not considered the direction in which the user perceived and estimated the collision. Based on the cue integration theory, this study presents a statistical model explaining how users estimate the direction of a virtual collision from their body's orientation and velocity vectors. The accuracy and precision of virtual collisions can be improved by 8.77% and 30.29%, respectively, by setting the virtual collision response in the direction that users perceive.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual reality, collision response, cue integration theory},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376729,
author = {Chattopadhyay, Souti and Prasad, Ishita and Henley, Austin Z. and Sarma, Anita and Barik, Titus},
title = {What's Wrong with Computational Notebooks? Pain Points, Needs, and Design Opportunities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376729},
doi = {10.1145/3313831.3376729},
abstract = {Computational notebooks - such as Azure, Databricks, and Jupyter - are a popular, interactive paradigm for data scientists to author code, analyze data, and interleave visualizations, all within a single document. Nevertheless, as data scientists incorporate more of their activities into notebooks, they encounter unexpected difficulties, or pain points, that impact their productivity and disrupt their workflow. Through a systematic, mixed-methods study using semi-structured interviews (n=20) and survey (n=156) with data scientists, we catalog nine pain points when working with notebooks. Our findings suggest that data scientists face numerous pain points throughout the entire workflow - from setting up notebooks to deploying to production - across many notebook environments. Our data scientists report essential notebook requirements, such as supporting data exploration and visualization. The results of our study inform and inspire the design of computational notebooks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {challenges, interviews, data science, pain points, survey, computational notebooks},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376827,
author = {Nguyen, Josef and Ruberg, Bonnie},
title = {Challenges of Designing Consent: Consent Mechanics in Video Games as Models for Interactive User Agency},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376827},
doi = {10.1145/3313831.3376827},
abstract = {This paper argues for a conceptual framework that treats user consent in interactive technologies as a design challenge necessitating careful, culturally-informed consideration. We draw on recent work in HCI as well as queer and feminist theory that understands consent as rooted in negotiating agency in order to frame our exploration of unique difficulties and potential solutions to meaningful opportunities for user consent in the design of computational technologies. Through a critical analysis of three video games that offer different models of consent-each of which communicates different values through its design-we introduce the concept of consent mechanics. Consent mechanics describe designed interactions that allow players to consent to or opt out of in-game experiences, often those related to sexuality or intimacy. Here, we approach video games as windows onto design considerations surrounding interactive technologies more broadly, suggesting crucial questions and tactics for how to design user agency ethically into computational systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {queerness, sexuality, video games, critical approaches, design, consent, ethics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376326,
author = {Tomlinson, Bill and Silberman, M. Six and Torrance, Andrew W. and Squire, Kurt and Atwal, Paramdeep S. and Mandalik, Ameya N. and Railkar, Sahil and Black, Rebecca W.},
title = {A Participatory Simulation of the Accountable Capitalism Act},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376326},
doi = {10.1145/3313831.3376326},
abstract = {Interactive computing systems increasingly allow for experimental evaluations of fundamental issues in law, government, and society. In this paper, we describe a participatory simulation of the Accountable Capitalism Act, a bill proposed in 2018 by US Senator Elizabeth Warren. We present findings from an empirical study conducted using this system, relating to the impact of 1) interactive visualization and 2) the Accountable Capitalism Act legal framework on the behavior of participants acting as corporate directors. From this study, we draw lessons about research possibilities at the juncture of HCI and legal and policy studies. This study contributes an analysis and evaluation of a design probe used to investigate potential impacts of the Accountable Capitalism Act, experimental evidence from a study conducted using the design probe, and guidance for future participatory simulations that seek to inform the design of social institutions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {participatory simulation, law, corporations, business},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376501,
author = {Chiang, Yi-Shyuan and Chang, Ruei-Che and Chuang, Yi-Lin and Chou, Shih-Ya and Lee, Hao-Ping and Lin, I-Ju and Jiang Chen, Jian-Hua and Chang, Yung-Ju},
title = {Exploring the Design Space of User-System Communication for Smart-Home Routine Assistants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376501},
doi = {10.1145/3313831.3376501},
abstract = {AI-enabled smart-home agents that automate household routines are increasingly viable, but the design space of how and what such systems should communicate with their users remains underexplored. Through a user-enactment study, we identified various interpretations of and feelings toward such a system's confidence in its automated acts. That confidence and their own mental models influenced what and how the participants wanted the system to communicate, as well as how they would assess, diagnose, and subsequently improve it. Automated acts resulted from false predictions were not generally considered improper, provided that they were perceived as reasonable or potentially useful. The participants' improvement strategies were of four general types, all of which will be discussed. Factors affecting their preferred levels of involvement in automated acts and their interest in system confidence were also identified. We conclude by making practical design recommendations for the user-system communication design spaces of smart-home routine assistants.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {intelligent agent, routine assistant, user enactment, smart-home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376263,
author = {Lu, Min and Wang, Chufeng and Lanir, Joel and Zhao, Nanxuan and Pfister, Hanspeter and Cohen-Or, Daniel and Huang, Hui},
title = {Exploring Visual Information Flows in Infographics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376263},
doi = {10.1145/3313831.3376263},
abstract = {Infographics are engaging visual representations that tell an informative story using a fusion of data and graphical elements. The large variety of infographic design poses a challenge for their high-level analysis. We use the concept of Visual Information Flow (VIF), which is the underlying semantic structure that links graphical elements to convey the information and story to the user. To explore VIF, we collected a repository of over 13K infographics. We use a deep neural network to identify visual elements related to information, agnostic to their various artistic appearances. We construct the VIF by automatically chaining these visual elements together based on Gestalt principles. Using this analysis, we characterize the VIF design space by a taxonomy of 12 different design patterns. Exploring in a real-world infographic dataset, we discuss the design space and potentials of VIF in light of this taxonomy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {infographics, visual information flow, design analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376843,
author = {Shi, Weiyan and Wang, Xuewei and Oh, Yoo Jung and Zhang, Jingwen and Sahay, Saurav and Yu, Zhou},
title = {Effects of Persuasive Dialogues: Testing Bot Identities and Inquiry Strategies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376843},
doi = {10.1145/3313831.3376843},
abstract = {Intelligent conversational agents, or chatbots, can take on various identities and are increasingly engaging in more human-centered conversations with persuasive goals. However, little is known about how identities and inquiry strategies influence the conversation's effectiveness. We conducted an online study involving 790 participants to be persuaded by a chatbot for charity donation. We designed a two by four factorial experiment (two chatbot identities and four inquiry strategies) where participants were randomly assigned to different conditions. Findings showed that the perceived identity of the chatbot had significant effects on the persuasion outcome (i.e., donation) and interpersonal perceptions (i.e., competence, confidence, warmth, and sincerity). Further, we identified interaction effects among perceived identities and inquiry strategies. We discuss the findings for theoretical and practical implications for developing ethical and effective persuasive chatbots. Our published data, codes, and analyses serve as the first step towards building competent ethical persuasive chatbots.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {behavior change, crowdsourced, text/speech/language, empirical study that tells us about people},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376638,
author = {De-Arteaga, Maria and Fogliato, Riccardo and Chouldechova, Alexandra},
title = {A Case for Humans-in-the-Loop: Decisions in the Presence of Erroneous Algorithmic Scores},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376638},
doi = {10.1145/3313831.3376638},
abstract = {The increased use of algorithmic predictions in sensitive domains has been accompanied by both enthusiasm and concern. To understand the opportunities and risks of these technologies, it is key to study how experts alter their decisions when using such tools. In this paper, we study the adoption of an algorithmic tool used to assist child maltreatment hotline screening decisions. We focus on the question: Are humans capable of identifying cases in which the machine is wrong, and of overriding those recommendations? We first show that humans do alter their behavior when the tool is deployed. Then, we show that humans are less likely to adhere to the machine's recommendation when the score displayed is an incorrect estimate of risk, even when overriding the recommendation requires supervisory approval. These results highlight the risks of full automation and the importance of designing decision pipelines that provide humans with autonomy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {decision support, child welfare, algorithm assisted decision making, human-in-the-loop, automation bias, algorithm aversion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376457,
author = {Abbott, Jacob and Patil, Sameer},
title = {How Mandatory Second Factor Affects the Authentication User Experience},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376457},
doi = {10.1145/3313831.3376457},
abstract = {Recent years have seen growing organizational adoption of two-factor authentication as organizations seek to limit the damage caused by password breaches. However, research on the user experience of two-factor authentication in a real-world setting is relatively scant. To fill this gap, we conducted multiple waves of an online survey of users at a large public university during its multi-phase rollout of mandatory two-factor authentication for faculty, staff, and students. In addition, we examined multiple months of logs of all authentication events at the university. We found no significant changes in user experience and acceptance of two-factor authentication when it was mandatory for select systems that dealt with sensitive information. However, these factors degraded when users were forced to use two-factor authentication for logging into every single university resource. Our findings can serve as important guidance for the implementation of two-factor authentication in organizations in a way that can help achieve a balance between security and user experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {2fa, login, multi-factor authentication, two-factor authentication, university it, user experience, ux, security},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376798,
author = {Head, Andrew and Jiang, Jason and Smith, James and Hearst, Marti A. and Hartmann, Bj\"{o}rn},
title = {Composing Flexibly-Organized Step-by-Step Tutorials from Linked Source Code, Snippets, and Outputs},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376798},
doi = {10.1145/3313831.3376798},
abstract = {Programming tutorials are a pervasive, versatile medium for teaching programming. In this paper, we report on the content and structure of programming tutorials, the pain points authors experience in writing them, and a design for a tool to help improve this process. An interview study with 12 experienced tutorial authors found that they construct documents by interleaving code snippets with text and illustrative outputs. It also revealed that authors must often keep related artifacts of source programs, snippets, and outputs consistent as a program evolves. A content analysis of 200 frequently-referenced tutorials on the web also found that most tutorials contain related artifacts—duplicate code and outputs generated from snippets—that an author would need to keep consistent with each other. To address these needs, we designed a tool called Torii with novel authoring capabilities. An in-lab study showed that tutorial authors can successfully use the tool for the unique affordances identified, and provides guidance for designing future tools for tutorial authoring.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {code editors, consistency, authoring, code evolution, programming tutorials, literate programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376730,
author = {Sterman, Sarah and Huang, Evey and Liu, Vivian and Paulos, Eric},
title = {Interacting with Literary Style through Computational Tools},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376730},
doi = {10.1145/3313831.3376730},
abstract = {Style is an important aspect of writing, shaping how audiences interpret and engage with literary works. However, for most people style is difficult to articulate precisely. While users frequently interact with computational word processing tools with well-defined metrics, such as spelling and grammar checkers, style is a significantly more nuanced concept. In this paper, we present a computational technique to help surface style in written text. We collect a dataset of crowdsourced human judgments of style, derive a model of style by training a neural net on this data, and present novel applications for visualizing and browsing style across broad bodies of literature, as well as an interactive text editor with real-time style feedback. We study these interactive style applications with users and discuss implications for enabling this novel approach to style.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {humanities, creativity support, artifact or system, text/speech/language},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376799,
author = {Newman, Anelise and McNamara, Barry and Fosco, Camilo and Zhang, Yun Bin and Sukhum, Pat and Tancik, Matthew and Kim, Nam Wook and Bylinskii, Zoya},
title = {TurkEyes: A Web-Based Toolbox for Crowdsourcing Attention Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376799},
doi = {10.1145/3313831.3376799},
abstract = {Eye movements provide insight into what parts of an image a viewer finds most salient, interesting, or relevant to the task at hand. Unfortunately, eye tracking data, a commonly-used proxy for attention, is cumbersome to collect. Here we explore an alternative: a comprehensive web-based toolbox for crowdsourcing visual attention. We draw from four main classes of attention-capturing methodologies in the literature. ZoomMaps is a novel zoom-based interface that captures viewing on a mobile phone. CodeCharts is a self-reporting methodology that records points of interest at precise viewing durations. ImportAnnots is an "annotation" tool for selecting important image regions, and cursor-based BubbleView lets viewers click to deblur a small area. We compare these methodologies using a common analysis framework in order to develop appropriate use cases for each interface. This toolbox and our analyses provide a blueprint for how to gather attention data at scale without an eye tracker.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {crowdsourcing, interaction techniques, attention, eye tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376694,
author = {Varghese, Delvin and Olivier, Patrick and Bartindale, Tom and Baillie Smith, Matt},
title = {Towards Participatory Video 2.0},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376694},
doi = {10.1145/3313831.3376694},
abstract = {Participatory video (PV) is an established practice for enabling communities to "speak truth to power" and has been widely used by local, national and international Non-Governmental Organizations (NGOs). However, the digital media landscape has changed dramatically since PV became widely accessible with the rise of the camcorder in the 1980s. Current media practices have evolved considerably since, yet PV remains essentially unchanged. We report on an investigation of current PV practices and reflect on these in terms of what the future for PV holds. We conducted interviews with staff at a global humanitarian network who directly and indirectly engage in community story capture; and explore their reflections on the potentials and barriers to PV use. We propose a new vision for PV that draws on current visual media production, consumption and distribution technologies and practices, and propose principles on which PV 2.0, a new generation of Participatory Video can be founded.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {international development, participatory video, participatory film-making, iDocs, object based media, ICTD, HCI4D},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376722,
author = {Ashtari, Narges and Bunt, Andrea and McGrenere, Joanna and Nebeling, Michael and Chilana, Parmit K.},
title = {Creating Augmented and Virtual Reality Applications: Current Practices, Challenges, and Opportunities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376722},
doi = {10.1145/3313831.3376722},
abstract = {Augmented Reality (AR) and Virtual Reality (VR) devices are becoming easier to access and use, but the barrier to entry for creating AR/VR applications remains high. Although the recent spike in HCI research on novel AR/VR tools is promising, we lack insights into how AR/VR creators use today's state-of-the-art authoring tools as well as the types of challenges that they face. We interviewed 21 AR/VR creators, which we grouped into hobbyists, domain experts, and professional designers. Despite having a variety of motivations and skillsets, they described similar challenges in designing and building AR/VR applications. We synthesize 8 key barriers that AR/VR creators face nowadays, starting from prototyping the initial experiences to dealing with "the many unknowns" during implementation, to facing difficulties in testing applications. Based on our analysis, we discuss the importance of considering end-user developers as a growing population of AR/VR creators, how we can build learning opportunities into AR/VR tools, and the need for building AR/VR toolchains that integrate debugging and testing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {AR/VR development, AR/VR design, end-user development, AR/VR authoring, augmented reality, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376690,
author = {Ahmad, Wajeeha and Liccardi, Ilaria},
title = {Addressing Anonymous Abuses: Measuring the Effects of Technical Mechanisms on Reported User Behaviors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376690},
doi = {10.1145/3313831.3376690},
abstract = {Anonymous networks intended to enhance privacy and evade censorship are also being exploited for abusive activities. Technical schemes have been proposed to selectively revoke the anonymity of abusive users, or simply limit them from anonymously accessing online service providers. We designed an empirical survey study to assess the effects of deploying these schemes on 75 users of the Tor anonymous network. We evaluated proposed schemes based on examples of the intended or abusive use cases they may address, their technical implementation and the types of entities responsible for enforcing them. Our results show that revocable anonymity schemes would particularly deter the intended uses of anonymous networks. We found a lower reported decrease in usage for schemes addressing spam than those directly compromising free expression. However, participants were concerned that all technical mechanisms for addressing anonymous abuses could be exploited beyond their intended goals (51.7%) to harm users (43.8%). Participants were distrustful of the enforcing entities involved (43.8%) and concerned about being unable to verify (49.3%) how particular mechanisms were applied.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {empirical study, anonymous networks, trust, abuse, tor},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376190,
author = {Han, Teng and Bansal, Shubhi and Shi, Xiaochen and Chen, Yanjun and Quan, Baogang and Tian, Feng and Wang, Hongan and Subramanian, Sriram},
title = {HapBead: On-Skin Microfluidic Haptic Interface Using Tunable Bead},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376190},
doi = {10.1145/3313831.3376190},
abstract = {On-skin haptic interfaces using soft elastomers which are thin and flexible have significantly improved in recent years. Many are focused on vibrotactile feedback that requires complicated parameter tuning. Another approach is based on mechanical forces created via piezoelectric devices and other methods for non-vibratory haptic sensations like stretching, twisting. These are often bulky with electronic components and associated drivers are complicated with limited control of timing and precision. This paper proposes HapBead, a new on-skin haptic interface that is capable of rendering vibration like tactile feedback using microfluidics. HapBead leverages a microfluidic channel to precisely and agilely oscillate a small bead via liquid flow, which then generates various motion patterns in channel that creates highly tunable haptic sensations on skin. We developed a proof-of-concept design to implement thin, flexible and easily affordable HapBead platform, and verified its haptic rendering capabilities via attaching it to users' fingertips. A study was carried out and confirmed that participants could accurately tell six different haptic patterns rendered by HapBead. HapBead enables new wearable display applications with multiple integrated functionalities such as on-skin haptic doodles, visuo-haptic displays and haptic illusions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {fluid flow, microfluidics, wearable devices, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376554,
author = {Blaga, Andreea Dalia and Frutos-Pascual, Maite and Creed, Chris and Williams, Ian},
title = {Too Hot to Handle: An Evaluation of the Effect of Thermal Visual Representation on User Grasping Interaction in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376554},
doi = {10.1145/3313831.3376554},
abstract = {Influence of interaction fidelity and rendering quality on perceived user experience have been largely explored in Virtual Reality (VR). However, differences in interaction choices triggered by these rendering cues have not yet been explored. We present a study analysing the effect of thermal visual cues and contextual information on 50 participants' approach to grasp and move a virtual mug. This study comprises 3 different temperature cues (baseline empty, hot and cold) and 4 contextual representations; all embedded in a VR scenario. We evaluate 2 different hand representations (abstract and human) to assess grasp metrics. Results show temperature cues influenced grasp location, with the mug handle being predominantly grasped with a smaller grasp aperture for the hot condition, while the body and top were preferred for baseline and cold conditions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {hand interaction, virtual reality, grasping metrics, hand tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376717,
author = {Dillahunt, Tawanna R. and Hsiao, Joey Chiao-Yin},
title = {Positive Feedback and Self-Reflection: Features to Support Self-Efficacy among Underrepresented Job Seekers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376717},
doi = {10.1145/3313831.3376717},
abstract = {Technologies play a key role in finding employment in today's job market. However, the majority of those who are unemployed, e.g., individuals who have limited education or who are racial and ethnic minorities, are not well supported by existing digital employment tools. Therefore, we conducted an 8-month randomized field experiment to evaluate two tools-Review-Me and Interview4-designed to address these job seekers' key employment needs. We used the Theory of Planned Behavior to examine the tools' effects on three factors influencing job seekers' job search intention: job search self-efficacy, subjective norms, and job search attitudes. Our interview data suggested that the tools positively affected all factors, but our survey results were mixed. Interview results suggest that these trends were caused by positive feedback and self-reflection. We contribute ways to integrate these two features into future tools for, and techniques to increase study retention among, underrepresented job seekers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {underrepresented job seekers, employment, theory of planned behavior},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376253,
author = {Ma'ayan, Dor and Ni, Wode and Ye, Katherine and Kulkarni, Chinmay and Sunshine, Joshua},
title = {How Domain Experts Create Conceptual Diagrams and Implications for Tool Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376253},
doi = {10.1145/3313831.3376253},
abstract = {Conceptual diagrams are used extensively to understand abstract relationships, explain complex ideas, and solve difficult problems. To illustrate concepts effectively, experts find appropriate visual representations and translate concepts into concrete shapes. This translation step is not supported explicitly by current diagramming tools. This paper investigates how domain experts create conceptual diagrams via semi-structured interviews with 18 participants from diverse backgrounds. Our participants create, adapt, and reuse visual representations using both sketches and digital tools. However, they had trouble using current diagramming tools to transition from sketches and reuse components from earlier diagrams. Our participants also expressed frustration with the slow feedback cycles and barriers to automation of their tools. Based on these results, we suggest four opportunities of diagramming tools — exploration support, representation salience, live engagement, and vocabulary correspondence — that together enable a natural diagramming experience. Finally, we discuss possibilities to leverage recent research advances to develop natural diagramming tools.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {information visualization, conceptual diagramming, diagram authoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376373,
author = {Adams, Alexander T. and Mandel, Ilan and Shats, Anna and Robin, Alina and Choudhury, Tanzeem},
title = {PuffPacket: A Platform for Unobtrusively Tracking the Fine-Grained Consumption Patterns of E-Cigarette Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376373},
doi = {10.1145/3313831.3376373},
abstract = {The proliferation of e-cigarettes and portable vaporizers presents new opportunities for accurately and unobtrusively tracking e-cigarette use. PuffPacket is a hardware and soft-ware research platform that leverages the technology built into vaporizers, e-cigarettes and other electronic drug delivery devices to ubiquitously track their usage. The system piggybacks on the signals these devices use to directly measure and track the nicotine consumed by users. PuffPacket augments e-cigarettes with Bluetooth to calculate the frequency, intensity, and duration of each inhalation. This information is augmented with smartphone-based location and activity information to help identify potential contextual triggers. Puff-Packet is generalizable to a wide variety of electronic nicotine,THC, and other drug delivery devices currently on the mar-ket. The hardware and software for PuffPacket is open-source so it can be expanded upon and leveraged for mobile health tracking research.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {e-cigarettes, addiction, health, sud, ends, research platform, topology, mobile sensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376622,
author = {Mentis, Helena M. and Feng, Yuanyuan and Semsar, Azin and Ponsky, Todd A.},
title = {Remotely Shaping the View in Surgical Telementoring},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376622},
doi = {10.1145/3313831.3376622},
abstract = {Distributed collaboration on physical tasks is a social process that involves all actors iteratively proposing, assessing and modifying the view of a shared workspace. In this paper, we describe the ways in which a view of a shared workspace is shaped by a remote expert to weave their expertise into the accomplishment of a complex physical task during surgical telementoring. We focus on the communicative functions of talk and actions used by the remote experts and local workers and identify strategies the experts employ to remotely shape the view. This analysis reveals the possibility for collaborative shaping of a view in surgical telementoring as well as other mechanism for a remote expert to craft and present a view of the shared workspace.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {distributed, tele-conferencing, video, surgery training, instruction, telestration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376788,
author = {Niforatos, Evangelos and Palma, Adam and Gluszny, Roman and Vourvopoulos, Athanasios and Liarokapis, Fotis},
title = {Would You Do It?: Enacting Moral Dilemmas in Virtual Reality for Understanding Ethical Decision-Making},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376788},
doi = {10.1145/3313831.3376788},
abstract = {A moral dilemma is a decision-making paradox without unambiguously acceptable or preferable options. This paper investigates if and how the virtual enactment of two renowned moral dilemmas---the Trolley and the Mad Bomber---influence decision-making when compared with mentally visualizing such situations. We conducted two user studies with two gender-balanced samples of 60 participants in total that compared between paper-based and virtual-reality (VR) conditions, while simulating 5 distinct scenarios for the Trolley dilemma, and 4 storyline scenarios for the Mad Bomber's dilemma. Our findings suggest that the VR enactment of moral dilemmas further fosters utilitarian decision-making, while it amplifies biases such as sparing juveniles and seeking retribution. Ultimately, we theorize that the VR enactment of renowned moral dilemmas can yield ecologically-valid data for training future Artificial Intelligence (AI) systems on ethical decision-making, and we elicit early design principles for the training of such systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {moral dilemmas, decision-making, ethical AI, ethics, VR},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376606,
author = {Tanenbaum, Theresa Jean and Hartoonian, Nazely and Bryan, Jeffrey},
title = {"How Do I Make This Thing Smile?": An Inventory of Expressive Nonverbal Communication in Commercial Social Virtual Reality Platforms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376606},
doi = {10.1145/3313831.3376606},
abstract = {Despite the proliferation of platforms for social Virtual Reality (VR) communicating emotional expression via an avatar remains a significant design challenge. In order to better understand the design space for expressive Nonverbal Communication (NVC) in social VR we undertook an inventory of the ten most prominent social VR platforms. Our inventory identifies the dominant design strategies for movement, facial control, and gesture in commercial VR applications, and identifies opportunities and challenges for future design and research into social expression in VR. Specifically, we highlight the paucity of interaction paradigms for facial expression and the near nonexistence of meaningful control over ambient aspects of nonverbal communication such as posture, pose, and social status.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, nonverbal communication, social interactions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376385,
author = {Bitton, Ron and Boymgold, Kobi and Puzis, Rami and Shabtai, Asaf},
title = {Evaluating the Information Security Awareness of Smartphone Users},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376385},
doi = {10.1145/3313831.3376385},
abstract = {Information security awareness (ISA) is a practice focused on the set of skills which help a user successfully mitigate social engineering (SE) attacks. Evaluating the ISA of users is crucial, since early identification of users who are more vulnerable to SE attacks improves system security. Previous studies for evaluating the ISA of smartphone users rely on subjective data sources (questionnaires) and do not address the differences between classes of SE attacks. This paper presents a framework for evaluating the ISA of smartphone users for specific attack classes. In addition to questionnaires, we utilize objective data sources: a mobile agent, a network traffic monitor, and cybersecurity challenges. We evaluated the framework by conducting a long-term user study involving 162 users. The results show that: the self-reported behavior of users differs significantly from their actual behavior and the ISA level derived from the actual behavior of users is highly correlated with their ability to mitigate SE attacks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social engineering, human factors, mobile devices, information security awareness},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376490,
author = {Neate, Timothy and Roper, Abi and Wilson, Stephanie and Marshall, Jane and Cruice, Madeline},
title = {CreaTable Content and Tangible Interaction in Aphasia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376490},
doi = {10.1145/3313831.3376490},
abstract = {Multimedia digital content (combining pictures, text and music) is ubiquitous. The process of creating such content using existing tools typically requires complex, language-laden interactions which pose a challenge for users with aphasia (a language impairment following brain injury). Tangible interactions offer a potential means to address this challenge, however, there has been little work exploring their potential for this purpose. In this paper, we present CreaTable a platform that enables us to explore tangible interaction as a means of supporting digital content creation for people with aphasia. We report details of the co-design of CreaTable and findings from a digital creativity workshop. Workshop findings indicated that CreaTable enabled people with aphasia to create something they would not otherwise have been able to. We report how users' aphasia profiles affected their experience, describe tensions in collaborative content creation and provide insight into more accessible content creation using tangibles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {content creation, creativity, creativity support, accessibility, aphasia, multimedia, tangibles, co-design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376401,
author = {Kepplinger, Daniel and Wallner, G\"{u}nter and Kriglstein, Simone and Lankes, Michael},
title = {See, Feel, Move: Player Behaviour Analysis through Combined Visualization of Gaze, Emotions, and Movement},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376401},
doi = {10.1145/3313831.3376401},
abstract = {Playtesting of games often relies on a mixed-methods approach to obtain more holistic insights about and, in turn, improve the player experience. However, triangulating the different data sources and visualizing them in an integrated manner such that they contextualize each other still proves challenging. Despite its potential value for gauging player behaviour, this area of research continues to be underexplored. In this paper, we propose a visualization approach that combines commonly tracked movement data with - from a visualization perspective rarely considered - gaze behaviour and emotional responses. We evaluated our approach through a qualitative expert study with five professional game developers. Our results show that both the individual visualization of gaze, emotions, and movement but especially their combination are valuable to understand and form hypotheses about player behaviour. At the same time, our results stress that careful attention needs to be paid to ensure that the visualization remains legible and does not obfuscate information.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {playtesting, gaze, movement analysis, visual game analytics, emotions, information visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376443,
author = {Lai, Chufan and Lin, Zhixian and Jiang, Ruike and Han, Yun and Liu, Can and Yuan, Xiaoru},
title = {Automatic Annotation Synchronizing with Textual Description for Visualization},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376443},
doi = {10.1145/3313831.3376443},
abstract = {In this paper, we propose a technique for automatically annotating visualizations according to the textual description. In our approach, visual elements in the target visualization, along with their visual properties, are identified and extracted with a Mask R-CNN model. Meanwhile, the description is parsed to generate visual search requests. Based on the identification results and search requests, each descriptive sentence is displayed beside the described focal areas as annotations. Different sentences are presented in various scenes of the generated animation to promote a vivid step-by-step presentation. With a user-customized style, the animation can guide the audience's attention via proper highlighting such as emphasizing specific features or isolating part of the data. We demonstrate the utility and usability of our method through a user study with use cases.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {natural language interface, machine learning, visualization, annotation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376621,
author = {Yildirim, Nur and McCann, James and Zimmerman, John},
title = {Digital Fabrication Tools at Work: Probing Professionals' Current Needs and Desired Futures},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376621},
doi = {10.1145/3313831.3376621},
abstract = {Digital fabrication tools have transformed how people work in micro- and small-scale manufacturing settings. While increasing efficiency and precision, these tools raise concerns around user agency and control. This paper describes an exploratory study investigating the felt work experience and desired futures of professionals who use fabrication tools. We conducted co-design workshops with 23 professionals who use 3D printers, laser cutters, and CNC routers. We probed about current practices; machine awareness and autonomy; and user agency. Our findings reveal that current tools are not very professional. They are unreliable and untrustworthy. Participants desired smarter tools that can actively prevent errors and perform self-calibration and self-maintenance. They had few concerns that more intelligence would impact agency. They desired tools that could negotiate trade-offs between time, cost, and quality; and that can operate as super-human shop assistants. We discuss the implications of these findings as opportunities for research that can improve professionals' work experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {cnc, user experience, digital fabrication, intelligent systems, future of work, laser cutting, co-design, 3d printing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376880,
author = {Lin, Halden and Moritz, Dominik and Heer, Jeffrey},
title = {Dziban: Balancing Agency &amp; Automation in Visualization Design via Anchored Recommendations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376880},
doi = {10.1145/3313831.3376880},
abstract = {Visualization recommender systems attempt to automate design decisions spanning choices of selected data, transformations, and visual encodings. However, across invocations such recommenders may lack the context of prior results, producing unstable outputs that override earlier design choices. To better balance automated suggestions with user intent, we contribute Dziban, a visualization API that supports both ambiguous specification and a novel anchoring mechanism for conveying desired context. Dziban uses the Draco knowledge base to automatically complete partial specifications and suggest appropriate visualizations. In addition, it extends Draco with chart similarity logic, enabling recommendations that also remain perceptually similar to a provided "anchor" chart. Existing APIs for exploratory visualization, such as ggplot2 and Vega-Lite, require fully specified chart definitions. In contrast, Dziban provides a more concise and flexible authoring experience through automated design, while preserving predictability and control through anchored recommendations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {recommendation, language, anchoring, visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376655,
author = {Chang, Zekun and Ta, Tung D. and Narumi, Koya and Kim, Heeju and Okuya, Fuminori and Li, Dongchi and Kato, Kunihiro and Qi, Jie and Miyamoto, Yoshinobu and Saito, Kazuya and Kawahara, Yoshihiro},
title = {Kirigami Haptic Swatches: Design Methods for Cut-and-Fold Haptic Feedback Mechanisms},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376655},
doi = {10.1145/3313831.3376655},
abstract = {Kirigami Haptic Swatches demonstrate how kirigami and origami based structures enable sophisticated haptic feedback through simple cut-and-fold fabrication techniques. We leverage four types of geometric patterns: rotational erection system (RES), split-fold waterbomb (SFWB), the overlaid structure of SFWB and RES (SFWB+RES), and cylindrical origami, to render different sets of haptic feedback (i.e. linear, bistable, bouncing snap-through, and rotational force behaviors, respectively). In each structure, not only the form factor but also the force feedback properties can be tuned through geometric parameters. We experimentally analyzed and modeled the structures, and implemented software to automatically generate 2D patterns for desired haptic properties. We also demonstrate five example applications including an assistive custom keyboard, rotational switch, multi-sensory toy, task checklist, and phone accessories. We believe the Kirigami Haptic Swatches helps tinkerers, designers, and even researchers to create interactions that enrich our haptic experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {Kirigami structure, design methods, computational fabrication, paper button, haptics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376688,
author = {Cao, Yuanzhi and Qian, Xun and Wang, Tianyi and Lee, Rachel and Huo, Ke and Ramani, Karthik},
title = {An Exploratory Study of Augmented Reality Presence for Tutoring Machine Tasks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376688},
doi = {10.1145/3313831.3376688},
abstract = {Machine tasks in workshops or factories are often a compound sequence of local, spatial, and body-coordinated human-machine interactions. Prior works have shown the merits of video-based and augmented reality (AR) tutoring systems for local tasks. However, due to the lack of a bodily representation of the tutor, they are not as effective for spatial and body-coordinated interactions. We propose avatars as an additional tutor representation to the existing AR instructions. In order to understand the design space of tutoring presence for machine tasks, we conduct a comparative study with 32 users. We aim to explore the strengths/limitations of the following four tutor options: video, non-avatar-AR, half-body+AR, and full-body+AR. The results show that users prefer the half-body+AR overall, especially for the spatial interactions. They have a preference for the full-body+AR for the body-coordinated interactions and the non-avatar-AR for the local interactions. We further discuss and summarize design recommendations and insights for future machine task tutoring systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {machine task, exploratory study, avatar tutor, augmented reality, tutoring system design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376297,
author = {Li, Guozheng and Tian, Min and Xu, Qinmei and McGuffin, Michael J. and Yuan, Xiaoru},
title = {GoTree: A Grammar of Tree Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376297},
doi = {10.1145/3313831.3376297},
abstract = {We present GoTree, a declarative grammar allowing users to instantiate tree visualizations by specifying three aspects: visual elements, layout, and coordinate system. Within the set of all possible tree visualization techniques, we identify a subset of techniques that are both "unit-decomposable" and "axis-decomposable" (terms we define). For tree visualizations within this subset, GoTree gives the user flexible and fine-grained control over the parameters of the techniques, supporting both explicit and implicit tree visualizations. We developed Tree Illustrator, an interactive authoring tool based on GoTree grammar. Tree Illustrator allows users to create a considerable number of tree visualizations, including not only existing techniques but also undiscovered and hybrid visualizations. We demonstrate the expressiveness and generative power of GoTree with a gallery of examples and conduct a qualitative study to validate the usability of Tree Illustrator.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {"tree visualization, declarative grammar, authoring tool, hierarchical data visualization"},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376185,
author = {Khovanskaya, Vera and Sengers, Phoebe and Dombrowski, Lynn},
title = {Bottom-Up Organizing with Tools from On High: Understanding the Data Practices of Labor Organizers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376185},
doi = {10.1145/3313831.3376185},
abstract = {This paper provides insight into the use of data tools in the American labor movement by analyzing the practices of staff employed by unions to organize alongside union members. We interviewed 23 field-level staff organizers about how they use data tools to evaluate membership. We find that organizers work around and outside of these tools to develop access to data for union members and calibrate data representations to meet local needs. Organizers mediate between local and central versions of the data, and draw on their contextual knowledge to challenge campaign strategy. We argue that networked data tools can compound field organizers' lack of discretion, making it more difficult for unions to assess and act on the will of union membership. We show how the use of networked data tools can lead to less accurate data, and discuss how bottom-up approaches to data gathering can support more accurate membership assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {activism, data-driven workplace, critical data studies, unions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376855,
author = {Wang, Weichen and Mirjafari, Shayan and Harari, Gabriella and Ben-Zeev, Dror and Brian, Rachel and Choudhury, Tanzeem and Hauser, Marta and Kane, John and Masaba, Kizito and Nepal, Subigya and Sano, Akane and Scherer, Emily and Tseng, Vincent and Wang, Rui and Wen, Hongyi and Wu, Jialing and Campbell, Andrew},
title = {Social Sensing: Assessing Social Functioning of Patients Living with Schizophrenia Using Mobile Phone Sensing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376855},
doi = {10.1145/3313831.3376855},
abstract = {Impaired social functioning is a symptom of mental illness (e.g., depression, schizophrenia) and a wide range of other conditions (e.g., cognitive decline in the elderly, dementia). Today, assessing social functioning relies on subjective evaluations and self assessments. We propose a different approach and collect detailed social functioning measures and objective mobile sensing data from N=55 outpatients living with schizophrenia to study new methods of passively accessing social functioning. We identify a number of behavioral patterns from sensing data, and discuss important correlations between social function sub-scales and mobile sensing features. We show we can accurately predict the social functioning of outpatients in our study including the following sub-scales: prosocial activities (MAE = 7.79, r = 0.53), which indicates engagement in common social activities; interpersonal behavior (MAE = 3.39, r = 0.57), which represents the number of friends and quality of communications; and employment/occupation (MAE = 2.17, r = 0.62), which relates to engagement in productive employment or a structured program of daily activity. Our work on automatically inferring social functioning opens the way to new forms of assessment and intervention across a number of areas including mental health and aging in place.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {social functioning, mobile sensing, health, social sensing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376469,
author = {Diana, Nicholas and Stamper, John and Koedinger, Ken},
title = {Towards Value-Adaptive Instruction: A Data-Driven Method for Addressing Bias in Argument Evaluation Tasks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376469},
doi = {10.1145/3313831.3376469},
abstract = {As the media landscape is increasingly populated by less than reputable sources of information, educators have turned to argument evaluation training as a potential solution. Unfortunately, the bias literature suggests that our ability to objectively evaluate an argument is, to a large extent, determined by the relationship between our own beliefs and the beliefs latent in the argument we are evaluating. If the argument supports our worldview, we are much more likely to overlook logical errors. Teachers recognize this need to adapt argument evaluation instruction to the specific beliefs of students. For instance, a teacher might intentionally assign a student an argument that the student disagrees with. Unfortunately, this kind of value-adaptive instruction is infrequent due to its unscalability. We propose a novel method for data-driven value-adaptive instruction in instructional technologies. This method can be used to combat bias in real-world contexts and support human reasoning during media consumption.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {adaptive instruction, civic education, civic technology, educational technology, human-computer interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376451,
author = {Wu, Tongshuang and Wongsuphasawat, Kanit and Ren, Donghao and Patel, Kayur and DuBois, Chris},
title = {Tempura: Query Analysis with Structural Templates},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376451},
doi = {10.1145/3313831.3376451},
abstract = {Analyzing queries from search engines and intelligent assistants is difficult. A key challenge is organizing queries into interpretable, context-preserving, representative, and flexible groups. We present structural templates, abstract queries that replace tokens with their linguistic feature forms, as a query grouping method. The templates allow analysts to create query groups with structural similarity at different granularities. We introduce Tempura, an interactive tool that lets analysts explore a query dataset with structural templates. Tempura summarizes a query dataset by selecting a representative subset of templates to show the query distribution. The tool also helps analysts navigate the template space by suggesting related templates likely to yield further explorations. Our user study shows that Tempura helps analysts examine the distribution of a query dataset, find labeling errors, and discover model error patterns and outliers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {natural language processing, error analysis, query analysis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376478,
author = {Murnane, Elizabeth L. and Jiang, Xin and Kong, Anna and Park, Michelle and Shi, Weili and Soohoo, Connor and Vink, Luke and Xia, Iris and Yu, Xin and Yang-Sammataro, John and Young, Grace and Zhi, Jenny and Moya, Paula and Landay, James A.},
title = {Designing Ambient Narrative-Based Interfaces to Reflect and Motivate Physical Activity},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376478},
doi = {10.1145/3313831.3376478},
abstract = {Numerous technologies now exist for promoting more active lifestyles. However, while quantitative data representations (e.g., charts, graphs, and statistical reports) typify most health tools, growing evidence suggests such feedback can not only fail to motivate behavior but may also harm self-integrity and fuel negative mindsets about exercise. Our research seeks to devise alternative, more qualitative schemes for encoding personal information. In particular, this paper explores the design of data-driven narratives, given the intuitive and persuasive power of stories. We present WhoIsZuki, a smartphone application that visualizes physical activities and goals as components of a multi-chapter quest, where the main character's progress is tied to the user's. We report on our design process involving online surveys, in-lab studies, and in-the-wild deployments, aimed at refining the interface and the narrative and gaining a deep understanding of people's experiences with this type of feedback. From these insights, we contribute recommendations to guide future development of narrative-based applications for motivating healthy behavior.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mobile health, narrative feedback, ambient display},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376663,
author = {Vella, Kellie and Oliver, Jessica L. and Dema, Tshering and Brereton, Margot and Roe, Paul},
title = {Ecology Meets Computer Science: Designing Tools to Reconcile People, Data, and Practices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376663},
doi = {10.1145/3313831.3376663},
abstract = {Ecoacoustics draws together computer scientists and ecologists to achieve an understanding of ecosystems and wildlife using acoustic recordings of the environment. Computer scientists are challenged to manage increasingly large datasets while developing analytic and visualisation tools. Ecologists struggle to find and use tools that answer highly heterogeneous research questions. These two fields are naturally drawn together at the tool interface, however, less attention has been paid to how their practices influence tool design and use. We interviewed and collected email correspondence from four computer scientists and eight ecologists to learn how their practices indicate opportunities for reconciling difference through design. We found that different temporal rhythms, relationships to data, and data-driven questions demand tool configuration, data integration, and standardisation. This research outlines interfacing opportunities for new ecological research utilising large acoustic datasets, and also contributes to evolving HCI approaches in areas making use of big data and human-in-the-loop processes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interface, human-computer interaction, interdisciplinary, ecoacoustics, computer science, ecology, design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376573,
author = {Petelka, Justin and Van Kleunen, Lucy and Albright, Liam and Murnane, Elizabeth and Voida, Stephen and Snyder, Jaime},
title = {Being (In)Visible: Privacy, Transparency, and Disclosure in the Self-Management of Bipolar Disorder},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376573},
doi = {10.1145/3313831.3376573},
abstract = {Research in personal informatics (PI) calls for systems to sup- port social forms of tracking, raising questions about how privacy can and should support intentionally sharing sensitive health information. We focus on the case of personal data related to the self-tracking of bipolar disorder (BD) in order to explore the ways in which disclosure activities intersect with other privacy experiences. While research in HCI of- ten discusses privacy as a disclosure activity, this does not reflect the ways in which privacy can be passively experienced. In this paper we broaden conceptions of privacy by defining transparency experiences and contributing factors in contrast to disclosure activities and preferences. Next, we ground this theoretical move in empirical analysis of personal narratives shared by people managing BD. We discuss the resulting emer- gent model of transparency in terms of implications for the design of socially-enabled PI systems. CAUTION: This paper contains references to experiences of mental illness, including self-harm, depression, suicidal ideation, etc.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {bipolar disorder, serious mental illness, privacy, personal informatics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376661,
author = {Koulouris, Jordan and Jeffery, Zoe and Best, James and O'Neill, Eamonn and Lutteroth, Christof},
title = {Me vs. Super(Wo)Man: Effects of Customization and Identification in a VR Exergame},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376661},
doi = {10.1145/3313831.3376661},
abstract = {Customised avatars are a powerful tool to increase identification, engagement and intrinsic motivation in digital games. We investigated the effects of customisation in a self-competitive VR exergame by modelling players and their previous performance in the game with customised avatars. In a first study we found that, similar to non-exertion games, customisation significantly increased identification and intrinsic motivation, as well as physical performance in the exergame. In a second study we identified a more complex relationship with the customisation style: idealised avatars increased wishful identification but decreased exergame performance compared to realistic avatars. In a third study, we found that 'enhancing' realistic avatars with idealised characteristics increased wishful identification, but did not have any adverse effects. We discuss the findings based on feedforward and self-determination theory, proposing notions of intrinsic identification (fostering a sense of self) and extrinsic identification (drawing away from the self) to explain the results.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {exergaming, identification, virtual reality, avatar customisation, feedforward},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376459,
author = {Chivukula, Shruthi Sai and Watkins, Chris Rhys and Manocha, Rhea and Chen, Jingle and Gray, Colin M.},
title = {Dimensions of UX Practice That Shape Ethical Awareness},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376459},
doi = {10.1145/3313831.3376459},
abstract = {HCI researchers are increasingly interested in describing the complexity of design practice, including ethical, organizational, and societal concerns. Recent studies have identified individual practitioners as key actors in driving the design process and culture within their respective organizations, and we build upon these efforts to reveal practitioner concerns regarding ethics on their own terms. In this paper, we report on the results of an interview study with eleven UX practitioners, capturing their experiences that highlight dimensions of design practice that impact ethical awareness and action. Using a bottom-up thematic analysis, we identified five dimensions of design complexity that influence ethical outcomes and span individual, collaborative, and methodological framing of UX activity. Based on these findings, we propose a set of implications for the creation of ethically-centered design methods that resonate with this complexity and inform the education of future UX practitioners.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {values, UX practice, practice-led research, ethics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376465,
author = {Pendse, Sachin R. and Lalani, Faisal M. and De Choudhury, Munmun and Sharma, Amit and Kumar, Neha},
title = {"Like Shock Absorbers": Understanding the Human Infrastructures of Technology-Mediated Mental Health Support},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376465},
doi = {10.1145/3313831.3376465},
abstract = {Significant research in HCI and beyond has sought to understand end-user needs in formal and informal technology-mediated mental health support (TMMHS) systems. However, little work has been done to understand the experiences and needs of the individuals who power or support these systems, particularly in the Global South. We present a qualitative study of one of the most accessible forms of mental health care in India — helplines. Through in-depth interviews conducted with 12 helpline volunteers, we research the human infrastructure responsible for the functioning of helplines. We foreground the often invisible labor involved in erecting and maintaining the institutional, interpersonal, and individual boundaries that are critical to realizing the goals of these helplines. Finally, we discuss the implications of our research for future work examining human infrastructures, particularly in mental health settings, and for the design of future TMMHS systems that deliver on-demand care to diverse, underserved, and stigmatized populations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {India, mental health, help-seeking, HCI4D, helplines},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376797,
author = {Hastings, Emily M. and Alamri, Albatool and Kuznetsov, Andrew and Pisarczyk, Christine and Karahalios, Karrie and Marinov, Darko and Bailey, Brian P.},
title = {LIFT: Integrating Stakeholder Voices into Algorithmic Team Formation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376797},
doi = {10.1145/3313831.3376797},
abstract = {Team formation tools assume instructors should configure the criteria for creating teams, precluding students from participating in a process affecting their learning experience. We propose LIFT, a novel learner-centered workflow where students propose, vote for, and weigh the criteria used as inputs to the team formation algorithm. We conducted an experiment (N=289) comparing LIFT to the usual instructor-led process, and interviewed participants to evaluate their perceptions of LIFT and its outcomes. Learners proposed novel criteria not included in existing algorithmic tools, such as organizational style. They avoided criteria like gender and GPA that instructors frequently select, and preferred those promoting efficient collaboration. LIFT led to team outcomes comparable to those achieved by the instructor-led approach, and teams valued having control of the team formation process. We provide instructors and designers with a workflow and evidence supporting giving learners control of the algorithmic process used for grouping them into teams.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {crowdsourcing, catme, learning, algorithms, team formation, learnersourcing, team composition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376740,
author = {Wang, April Yi and Wu, Zihan and Brooks, Christopher and Oney, Steve},
title = {Callisto: Capturing the "Why" by Connecting Conversations with Computational Narratives},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376740},
doi = {10.1145/3313831.3376740},
abstract = {When teams of data scientists collaborate on computational notebooks, their discussions often contain valuable insight into their design decisions. These discussions not only explain analysis in the current notebook but also alternative paths, which are often poorly documented. However, these discussions are disconnected from the notebooks for which they could provide valuable context. We propose Callisto, an extension to computational notebooks that captures and stores contextual links between discussion messages and notebook elements with minimal effort from users. Callisto allows notebook readers to better understand the current notebook content and the overall problem-solving process that led to it, by making it possible to browse the discussions and code history relevant to any part of the notebook. This is particularly helpful for onboarding new notebook collaborators to avoid misinterpretations and duplicated work, as we found in a two-stage evaluation with 32 data science students.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {collaborative systems, computational notebooks, literate programming, datascience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376406,
author = {Goodman, Steven and Kirchner, Susanne and Guttman, Rose and Jain, Dhruv and Froehlich, Jon and Findlater, Leah},
title = {Evaluating Smartwatch-Based Sound Feedback for Deaf and Hard-of-Hearing Users Across Contexts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376406},
doi = {10.1145/3313831.3376406},
abstract = {We present a qualitative study with 16 deaf and hard of hearing (DHH) participants examining reactions to smartwatch-based visual + haptic sound feedback designs. In Part 1, we conducted a Wizard-of-Oz (WoZ) evaluation of three smartwatch feedback techniques (visual alone, visual + simple vibration, and visual + tacton) and investigated vibrational patterns (tactons) to portray sound loudness, direction, and identity. In Part 2, we visited three public or semi-public locations where we demonstrated sound feedback on the smartwatch in situ to examine contextual influences and explore sound filtering options. Our findings characterize uses for vibration in multimodal sound awareness, both for push notification and for immediately actionable sound information displayed through vibrational patterns (tactons). In situ experiences caused participants to request sound filtering - particularly to limit haptic feedback - as a method for managing soundscape complexity. Additional concerns arose related to learnability, possibility of distraction, and system trust. Our findings have implications for future portable sound awareness systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {smartwatches, sound awareness, deaf and hard of hearing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376529,
author = {Huang, Yue and Obada-Obieh, Borke and Beznosov, Konstantin (Kosta)},
title = {Amazon vs. My Brother: How Users of Shared Smart Speakers Perceive and Cope with Privacy Risks},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376529},
doi = {10.1145/3313831.3376529},
abstract = {With the rapid adoption of smart speakers in people's homes, there is a corresponding increase in users' privacy and security concerns. In contrast to previous studies of users' concerns about smart speakers' divulging private information to their manufacturers, our study focused on investigating users' concerns with regard to housemates and external entities. We conducted semi-structured interviews with 26 participants living in 21 households. Our results suggest that users often have an inadequate understanding of what data their smart speakers makes available to all users and what is kept private. Although participants expressed different privacy concerns about their housemates and external entities, they adopted similar, yet suboptimal, risk management strategies. We provide recommendations for future speaker design to support more optimal coping with the perceived risks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mitigation strategies, shared smart speaker, security and privacy concerns},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376258,
author = {Lin, Yuyu and Guo, Jiahao and Chen, Yang and Yao, Cheng and Ying, Fangtian},
title = {It Is Your Turn: Collaborative Ideation With a Co-Creative Robot through Sketch},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376258},
doi = {10.1145/3313831.3376258},
abstract = {Co-creative systems have been widely explored in the field of computational creativity. However, existing AI partners of these systems are mostly virtual agents. As sketching on paper with embodied robots could be more engaging for designers' early-stage ideation and collaborative practices, we envision the possibility of Cobbie, a mobile robot that ideates iteratively with designers by generating creative and diverse sketches. To evaluate the differences in co-creativity and user experience between the co-creative robots and virtual agents, we conducted a comparative experiment and analyzed the data collected from quantitative scales, observation, and semi-structured interview. The results reveal that Cobbie is more satisfying in motivating exploration, provoking unexpected ideas and engaging designers in the collaborative ideation process. Based on these findings, we discussed the prospects of co-creative robots for future developments of human-AI collaborative systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {early-stage design, ideation, co-creative system, human-ai collaboration, creative robot},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376686,
author = {Saksono, Herman and Castaneda-Sceppa, Carmen and Hoffman, Jessica and Morris, Vivien and Seif El-Nasr, Magy and Parker, Andrea G.},
title = {Storywell: Designing for Family Fitness App Motivation by Using Social Rewards and Reflection},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376686},
doi = {10.1145/3313831.3376686},
abstract = {Physical activity (PA) is critical for reducing the risk of obesity, a prevalent health concern that burdens low-socioeconomic status (SES) households. While self-tracking apps can increase PA, encouraging app engagement remains a challenge, thus limiting the app's efficacy. To understand how to better support caregiver's motivation to use family health apps, we designed and evaluated Storywell?a mobile app for promoting family PA. Guided by Self-Determination Theory, Storywell provides social rewards (e.g., storybooks with interactive reflective questions) aimed at supporting relatedness and motivation. Our 3-month qualitative study with 18 families revealed satisfying moments that can affect caregiver's motivation. We contribute new knowledge on designing satisfying moments that heighten the motivation to use health apps, especially for low-SES families who face many barriers to using such systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {motivation, health, self-tracking, gamification, family, self-determination theory, physical activity, children},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376768,
author = {Tahaei, Mohammad and Vaniea, Kami and Saphra, Naomi},
title = {Understanding Privacy-Related Questions on Stack Overflow},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376768},
doi = {10.1145/3313831.3376768},
abstract = {We analyse Stack Overflow (SO) to understand challenges and confusions developers face while dealing with privacy-related topics. We apply topic modelling techniques to 1,733 privacy-related questions to identify topics and then qualitatively analyse a random sample of 315 privacy-related questions. Identified topics include privacy policies, privacy concerns, access control, and version changes. Results show that developers do ask SO for support on privacy-related issues. We also find that platforms such as Apple and Google are defining privacy requirements for developers by specifying what "sensitive" information is and what types of information developers need to communicate to users (e.g. privacy policies). We also examine the accepted answers in our sample and find that 28% of them link to official documentation and more than half are answered by SO users without references to any external resources.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {stack overflow, software developers, usable privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376223,
author = {Pfau, Johannes and Smeddinck, Jan David and Bikas, Ioannis and Malaka, Rainer},
title = {Bot or Not? User Perceptions of Player Substitution with Deep Player Behavior Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376223},
doi = {10.1145/3313831.3376223},
abstract = {Many online games suffer when players drop off due to lost connections or quitting prematurely, which leads to match terminations or game-play imbalances. While rule-based outcome evaluations or substitutions with bots are frequently used to mitigate such disruptions, these techniques are often perceived as unsatisfactory. Deep learning methods have successfully been used in deep player behavior modelling (DPBM) to produce non-player characters or bots which show more complex behavior patterns than those modelled using traditional AI techniques. Motivated by these findings, we present an investigation of the player-perceived awareness, believability and representativeness, when substituting disconnected players with DPBM agents in an online-multiplayer action game. Both quantitative and qualitative outcomes indicate that DPBM agent substitutes perform similarly to human players and that players were unable to detect substitutions. Notably, players were in fact able to detect substitution with agents driven by more traditional heuristics.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {deep learning, games user research, player modeling, game disruption prevention, player substitution, games, neural networks},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376279,
author = {Stewart, Angela E.B. and Amon, Mary Jean and Duran, Nicholas D. and D'Mello, Sidney K.},
title = {Beyond Team Makeup: Diversity in Teams Predicts Valued Outcomes in Computer-Mediated Collaborations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376279},
doi = {10.1145/3313831.3376279},
abstract = {In an increasingly globalized and service-oriented economy, people need to engage in computer-mediated collaborative problem solving (CPS) with diverse teams. However, teams routinely fail to live up to expectations, showcasing the need for technologies that help develop effective collaboration skills. We take a step in this direction by investigating how different dimensions of team diversity (demographic, personality, attitudes towards teamwork, prior domain experience) predict objective (e.g. effective solutions) and subjective (e.g. positive perceptions) collaborative outcomes. We collected data from 96 triads who engaged in a 30-minute CPS task via videoconferencing. We found that demographic diversity and differing attitudes towards teamwork predicted impressions of positive engagement, while personality diversity predicted learning outcomes. Importantly, these relationships were maintained after accounting for team makeup. None of the diversity measures predicted task performance. We discuss how our findings can be incorporated into technologies that aim to help diverse teams develop CPS skills.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {collaborative problem solving, team makeup, learning technologies, diversity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376884,
author = {Hou, Ming and Mahadevan, Karthik and Somanath, Sowmya and Sharlin, Ehud and Oehlberg, Lora},
title = {Autonomous Vehicle-Cyclist Interaction: Peril and Promise},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376884},
doi = {10.1145/3313831.3376884},
abstract = {Autonomous vehicles (AVs) will redefine interactions between road users. Presently, cyclists and drivers communicate through implicit cues (vehicle motion) and explicit but imprecise signals (hand gestures, horns). Future AVs could consistently communicate awareness and intent and other feedback to cyclists based on their sensor data. We present an exploration of AV-cyclist interaction, starting with preliminary design studies which informed the implementation of an immersive VR AV-cyclist simulator, and the design and evaluation of a number of AV-cyclist interfaces. Our findings suggest that AV-cyclist interfaces can improve rider confidence in lane merging scenarios. We contribute an AV-cyclist immersive simulator, insights on trade-offs of various aspects of AV-cyclist interaction design including modalities, location, and complexity, and positive results suggesting improved rider confidence due to AV-cyclist interaction. While we are encouraged by the potential positive impact AV-cyclist interfaces can have on cyclist culture, we also emphasize the risks over-reliance can pose to cyclists.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {interfaces for communicating intent and awareness, autonomous vehicle cyclist interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376824,
author = {Gray, Stuart and Hahn, Rachel and Cater, Kirsten and Watson, Debbie and Williams, Keir and Metcalfe, Tom and Meineck, Chloe},
title = {Towards A Design For Life: Redesigning For Reminiscence With Looked After Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376824},
doi = {10.1145/3313831.3376824},
abstract = {For 'looked-after' and adopted children, physical objects are often the only remaining link to their pasts; a portal to stories of former families, homes, and events. The act of reminiscence, known as 'life story work', can help children to process their pasts and overcome trauma. This paper describes the user-centred redesign of Trove, a digital and physical memory box for storing and curating stories about precious objects. We describe our redesign process, synthesising the insights from previous Trove evaluations with looked-after and adopted children, and three re-design workshops with 4 looked-after children at a therapeutic residential school. Our findings advocate for prioritisation of Trove's digital and physical security, the sustainability of its companionship, and the provision of multimedia storytelling to encourage the construction of identity narratives. Inspired by this, we present and discuss the redeveloped Trove, before analysing our participatory design approach with these complex and under-represented groups.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {storytelling, participatory design, children, reminiscence, life story work, social care, memory boxes},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376173,
author = {Ghosh, Debjyoti and Foong, Pin Sym and Zhao, Shengdong and Liu, Can and Janaka, Nuwan and Erusu, Vinitha},
title = {EYEditor: Towards On-the-Go Heads-Up Text Editing Using Voice and Manual Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376173},
doi = {10.1145/3313831.3376173},
abstract = {On-the-go text-editing is difficult, yet frequently done in everyday lives. Using smartphones for editing text forces users into a heads-down posture which can be undesirable and unsafe. We present EYEditor, a heads-up smartglass-based solution that displays the text on a see-through peripheral display and allows text-editing with voice and manual input. The choices of output modality (visual and/or audio) and content presentation were made after a controlled experiment, which showed that sentence-by-sentence visual-only presentation is best for optimizing users' editing and path-navigation capabilities. A second experiment formally evaluated EYEditor against the standard smartphone-based solution for tasks with varied editing complexities and navigation difficulties. The results showed that EYEditor outperformed smartphones as either the path OR the task became more difficult. Yet, the advantage of EYEditor became less salient when both the editing and navigation was difficult. We discuss trade-offs and insights gained for future heads-up text-editing solutions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {re-speaking, manual-input, eyeditor, text editing, voice interaction, mobile interaction, smart glass, wearable interaction, heads-up interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376588,
author = {Barrios, Liliana and Oldrati, Pietro and Lindlbauer, David and Hilty, Marc and Hayward-Koennecke, Helen and Holz, Christian and Lutterotti, Andreas},
title = {A Rapid Tapping Task on Commodity Smartphones to Assess Motor Fatigability},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376588},
doi = {10.1145/3313831.3376588},
abstract = {Fatigue is a common debilitating symptom of many autoimmune diseases, including multiple sclerosis. It negatively impacts patients' every-day life and productivity. Despite its prevalence, fatigue is still poorly understood. Its subjective nature makes quantification challenging and it is mainly assessed by questionnaires, which capture the magnitude of fatigue insufficiently. Motor fatigability, the objective decline of performance during a motor task, is an underrated aspect in this regard. Currently, motor fatigability is assessed using a handgrip dynamometer. This approach has been proven valid and accurate but requires special equipment and trained personnel. We propose a technique to objectively quantify motor fatigability using a commodity smartphone. The method comprises a simple exertion task requiring rapid alternating tapping. Our study with 20 multiple sclerosis patients and 35 healthy participants showed a correlation of rho = 0.8 with the baseline handgrip method. This smartphone-based approach is a first step towards ubiquitous, more frequent, and remote monitoring of fatigability and disease progression.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {fatigability, smartphones, mobile health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376269,
author = {Shahmiri, Fereshteh and Dietz, Paul H.},
title = {ShArc: A Geometric Technique for Multi-Bend/Shape Sensing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376269},
doi = {10.1145/3313831.3376269},
abstract = {We present ShArc, a precision, geometric measurement technique for building multi-bend/shape sensors. ShArc sensors are made from flexible strips that can be dynamically formed into complex curves in a plane. They measure local curvature by noting the relative shift between the inner and outer layers of the sensor at many points and model shape as a series of connected arcs. Unlike jointed systems where angular errors sum with each joint measured, ShArc sensors do not accumulate angular error as more measurement points are added. This allows for inexpensive, robust sensors that can accurately model curves with multiple bends. To demonstrate the efficacy of this technique, we developed a capacitive ShArc sensor and evaluated its performance. We conclude with examples of how ShArc sensors can be employed in applications like gesture input devices, user interface controllers, human motion tracking and angular measurement of free-form objects.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {capacitive, bend, sharc, multi-bend, sensor, shape},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376828,
author = {Gallo, Danilo and Shreepriya, Shreepriya and Willamowski, Jutta},
title = {RunAhead: Exploring Head Scanning Based Navigation for Runners},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376828},
doi = {10.1145/3313831.3376828},
abstract = {Navigation systems for runners commonly provide turn-by-turn directions via voice and/or map-based visualizations. While voice directions require permanent attention, map-based guidance requires regular consultation. Both disrupt the running activity. To address this, we designed RunAhead, a navigation system using head scanning to query for navigation feedback, and we explored its suitability for runners in an outdoor experiment. In our design, we provide the runner with simple and intuitive navigation feedback on the path s/he is looking at through three different feedback modes: haptic, music and audio cues. In our experiment, we compare the resulting three versions of RunAhead with a baseline voice-based navigation system. We find that demand and error are equivalent across all four conditions. However, the head scanning based haptic and music conditions are preferred over the baseline and these preferences are impacted by runners' habits. With this study we contribute insights for designing navigation support for runners.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {audio feedback, head scanning, haptic feedback, navigation for running},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376159,
author = {Gibson, Ryan Colin and Dunlop, Mark D. and Bouamrane, Matt-Mouley and Nayar, Revathy},
title = {Designing Clinical AAC Tablet Applications with Adults Who Have Mild Intellectual Disabilities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376159},
doi = {10.1145/3313831.3376159},
abstract = {Patients with mild intellectual disabilities (ID) face significant communication barriers within primary care services. This has a detrimental effect on the quality of treatment being provided, meaning the consultation process could benefit from augmentative and alternative communication (AAC) technologies. However, little research has been conducted in this area beyond that of paper-based aids. We address this by extracting design requirements for a clinical AAC tablet application from n=10 adults with mild ID. Our results show that such technologies can promote communication between general practitioners (GPs) and patients with mild ID by extracting symptoms in advance of the consultation via an accessible questionnaire. These symptoms act as a referent and assist in raising the awareness of conditions commonly overlooked by GPs. Furthermore, the application can support people with ID in identifying and accessing healthcare services. Finally, the participants identified 6 key factors that affect the clarity of medical images.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {accessibility, mobile applications, augmentative and alternative communication, intellectual disabilities, primary health care},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376251,
author = {Shapiro, Ben Rydal and Meng, Amanda and O'Donnell, Cody and Lou, Charlotte and Zhao, Edwin and Dankwa, Bianca and Hostetler, Andrew},
title = {Re-Shape: A Method to Teach Data Ethics for Data Science Education},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376251},
doi = {10.1145/3313831.3376251},
abstract = {Data has become central to the technologies and services that human-computer interaction (HCI) designers make, and the ethical use of data in and through these technologies should be given critical attention throughout the design process. However, there is little research on ethics education in computer science that explicitly addresses data ethics. We present and analyze Re-Shape, a method to teach students about the ethical implications of data collection and use. Re-Shape, as part of an educational environment, builds upon the idea of cultivating care and allows students to collect, process, and visualize their physical movement data in ways that support critical reflection and coordinated classroom activities about data, data privacy, and human-centered systems for data science. We also use a case study of Re-Shape in an undergraduate computer science course to explore prospects and limitations of instructional designs and educational technology such as Re-Shape that leverage personal data to teach data ethics.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interaction geography slicer, data literacy, care ethics, data science education, computer science education, re-shape, data privacy, information visualization, data ethics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376849,
author = {Baughan, Amanda and August, Tal and Yamashita, Naomi and Reinecke, Katharina},
title = {Keep It Simple: How Visual Complexity and Preferences Impact Search Efficiency on Websites},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376849},
doi = {10.1145/3313831.3376849},
abstract = {We conducted an online study with 165 participants in which we tested their search efficiency and information recall. We confirm that the visual complexity of a website has a significant negative effect on search efficiency and information recall. However, the search efficiency of those who preferred simple websites was more negatively affected by highly complex websites than those who preferred high visual complexity. Our results suggest that diverse visual preferences need to be accounted for when assessing search response time and information recall in HCI experiments, testing software, or A/B tests.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {design, user interface, usability, visual appeal, search efficiency, visual complexity, information recall},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376701,
author = {Cheema, Noshaba and Frey-Law, Laura A. and Naderi, Kourosh and Lehtinen, Jaakko and Slusallek, Philipp and H\"{a}m\"{a}l\"{a}inen, Perttu},
title = {Predicting Mid-Air Interaction Movements and Fatigue Using Deep Reinforcement Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376701},
doi = {10.1145/3313831.3376701},
abstract = {A common problem of mid-air interaction is excessive arm fatigue, known as the "Gorilla arm" effect. To predict and prevent such problems at a low cost, we investigate user testing of mid-air interaction without real users, utilizing biomechanically simulated AI agents trained using deep Reinforcement Learning (RL). We implement this in a pointing task and four experimental conditions, demonstrating that the simulated fatigue data matches human fatigue data. We also compare two effort models: 1) instantaneous joint torques commonly used in computer animation and robotics, and 2) the recent Three Compartment Controller (3CC-) model from biomechanical literature. 3CC- yields movements that are both more efficient and relaxed, whereas with instantaneous joint torques, the RL agent can easily generate movements that are quickly tiring or only reach the targets slowly and inaccurately. Our work demonstrates that deep RL combined with the 3CC- provides a viable tool for predicting both interaction movements and user experiencein silico, without users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {biomechanical simulation, reinforcement learning, user modeling, computational interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376567,
author = {Anjani, Laurensia and Mok, Terrance and Tang, Anthony and Oehlberg, Lora and Goh, Wooi Boon},
title = {Why Do People Watch Others Eat Food? An Empirical Study on the Motivations and Practices of Mukbang Viewers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376567},
doi = {10.1145/3313831.3376567},
abstract = {We present a mixed-methods study of viewers on their practices and motivations around watching mukbang — video streams of people eating large quantities of food. Viewers' experiences provide insight on future technologies for multisensorial video streams and technology-supported commensality (eating with others). We surveyed 104 viewers and interviewed 15 of them about their attitudes and reflections on their mukbang viewing habits, their physiological aspects of watching someone eat, and their perceived social relationship with mukbangers. Based on our findings, we propose design implications for remote commensality, and for synchronized multisensorial video streaming content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {mukbang, video streams},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376508,
author = {Melfi, Giuseppe and M\"{u}ller, Karin and Schwarz, Thorsten and Jaworek, Gerhard and Stiefelhagen, Rainer},
title = {Understanding What You Feel: A Mobile Audio-Tactile System for Graphics Used at Schools with Students with Visual Impairment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376508},
doi = {10.1145/3313831.3376508},
abstract = {A lot of information is nowadays presented graphically. However, students with blindness do not have access to visual information. Providing an alternative text is not always the appropriate solution as exploring graphics to discover information independently is a fundamental part of the learning process. In this work, we introduce a mobile audio-tactile learning environment, which facilitates the incorporation of real educational material. We evaluate our system by comparing three methods of interaction with tactile graphics: A tactile graphic augmented by (1) a document with key index information in Braille, (2) a digital document with key index information and (3) the TPad system, an audio-tactile solution meeting the specific needs within the school context. Our study shows that the TPad system is suitable for educational environments. Moreover, compared to the other methods TPad is faster to explore tactile graphics and it suggests a promising effect on the memorization of information.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {access technology, touch screen devices, blind, visually impaired, tactile graphics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376725,
author = {Park, Eunji and Lee, Byungjoo},
title = {An Intermittent Click Planning Model},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376725},
doi = {10.1145/3313831.3376725},
abstract = {Pointing is the task of tracking a target with a pointer and confirming the target selection through a click action when the pointer is positioned within the target. Little is known about the mechanism by which users plan and execute the click action in the middle of the target tracking process. The Intermittent Click Planning model proposed in this study describes the process by which users plan and execute optimal click actions, from which the model predicts the pointing error rates. In two studies in which users pointed to a stationary target and a moving target, the model proved to accurately predict the pointing error rates (R2 = 0.992 and 0.985, respectively). The model has also successfully identified differences in cognitive characteristics among first-person shooter game players.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {click model, cue integration, pointing, intermittent control, internal clock, temporal pointing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376383,
author = {Im, Jane and Tandon, Sonali and Chandrasekharan, Eshwar and Denby, Taylor and Gilbert, Eric},
title = {Synthesized Social Signals: Computationally-Derived Social Signals from Account Histories},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376383},
doi = {10.1145/3313831.3376383},
abstract = {Social signals are crucial when we decide if we want to interact with someone online. However, social signals are typically limited to the few that platform designers provide, and most can be easily manipulated. In this paper, we propose a new idea called synthesized social signals (S3s): social signals computationally derived from an account's history, and then rendered into the profile. Unlike conventional social signals such as profile bios, S3s use computational summarization to reduce receiver costs and raise the cost of faking signals. To demonstrate and explore the concept, we built Sig, an extensible Chrome extension that computes and visualizes S3s. After a formative study, we conducted a field deployment of Sig on Twitter, targeting two well-known problems on social media: toxic accounts and misinformation. Results show that Sig reduced receiver costs, added important signals beyond conventionally available ones, and that a few users felt safer using Twitter as a result. We conclude by reflecting on the opportunities and challenges S3s provide for augmenting interaction on social platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {social platform, social media, social signals, social computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376748,
author = {Kors, Martijn J.L. and van der Spek, Erik D. and Bopp, Julia A. and Millenaar, Karel and van Teutem, Rutger L. and Ferri, Gabriele and Schouten, Ben A.M.},
title = {The Curious Case of the Transdiegetic Cow, or a Mission to Foster Other-Oriented Empathy Through Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376748},
doi = {10.1145/3313831.3376748},
abstract = {Socially aware persuasive games that use immersive technologies often appeal to empathy, prompting users to feel and understand the struggles of another. However, the often sought-after standing in another's shoes' experience, in which users virtually inhabit another in distress, may complicate other-oriented empathy. Following a Research through Design approach, we designed for other-oriented empathy - focusing on a partaker-perspective and diegetic reflection - which resulted in Permanent; a virtual reality game designed to foster empathy towards evacuees from the 2011 Fukushima Daiichi nuclear disaster. We deployed Permanent 'in the wild' and carried out a qualitative study with 78 participants in the Netherlands and Japan to capture user experiences. Content Analysis of the data showed a predominance of other-oriented empathy across countries, and in our Thematic Analysis, we identified the themes of 'Spatial, Other, and Self -Awareness', 'Personal Accounts', 'Ambivalence', and 'Transdiegetic Items', resulting in design insights for fostering other-oriented empathy through virtual reality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, interactive narrative, empathy, game},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376840,
author = {Katsini, Christina and Abdrabou, Yasmeen and Raptis, George E. and Khamis, Mohamed and Alt, Florian},
title = {The Role of Eye Gaze in Security and Privacy Applications: Survey and Future HCI Research Directions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376840},
doi = {10.1145/3313831.3376840},
abstract = {For the past 20 years, researchers have investigated the use of eye tracking in security applications. We present a holistic view on gaze-based security applications. In particular, we canvassed the literature and classify the utility of gaze in security applications into a) authentication, b) privacy protection, and c) gaze monitoring during security critical tasks. This allows us to chart several research directions, most importantly 1) conducting field studies of implicit and explicit gaze-based authentication due to recent advances in eye tracking, 2) research on gaze-based privacy protection and gaze monitoring in security critical tasks which are under-investigated yet very promising areas, and 3) understanding the privacy implications of pervasive eye tracking. We discuss the most promising opportunities and most pressing challenges of eye tracking for security that will shape research in gaze-based security applications for the next decade.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–21},
numpages = {21},
keywords = {literature survey, human-centered security, gaze interaction, security, eye tracking, privacy, survey, usable security},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376387,
author = {Zhang, Hechuan and Chen, Zhiyong and Guo, Shihui and Lin, Juncong and Shi, Yating and Liu, Xiangyang and Ma, Yong},
title = {Sensock: 3D Foot Reconstruction with Flexible Sensors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376387},
doi = {10.1145/3313831.3376387},
abstract = {Capturing 3D foot models is important for applications such as manufacturing customized shoes and creating clubfoot orthotics. In this paper, we propose a novel prototype, Sensock, to offer a fully wearable solution for the task of 3D foot reconstruction. The prototype consists of four soft stretchable sensors, made from silk fibroin yarn. We identify four characteristic foot girths based on the existing knowledge of foot anatomy, and measure their lengths with the resistance value of the stretchable sensors. A learning-based model is trained offline and maps the foot girths to the corresponding 3D foot shapes. We compare our method with existing solutions using red-green-blue (RGB) or RGBD (RGB-depth) cameras, and show the advantages of our method in terms of both efficiency and accuracy. In the user experiment, we find that the relative error of Sensock is lower than 0.55%. It performs consistently across different trials and is considered comfortable and suitable for long-term wearing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {foot modeling, 3d reconstruction, flexible sensors},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376742,
author = {Osmers, Niklas and Prilla, Michael},
title = {Getting out of Out of Sight: Evaluation of AR Mechanisms for Awareness and Orientation Support in Occluded Multi-Room Settings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376742},
doi = {10.1145/3313831.3376742},
abstract = {Augmented Reality can provide orientation and awareness in situations in which objects or people are occluded by physical structures. This is relevant for many situations in the workplace, where objects are scattered across rooms and people are out of sight. While several AR mechanisms have been proposed to provide awareness and orientation in these situations, little is known about their effect on people's performance when searching objects and coordinating with each other. In this paper, we compare three AR based mechanisms (map, x-ray, compass) according to their utility, usability, social presence, task load and users' preferences. 48 participants had to work together in groups of four to find people and objects located around different rooms. Results show that map and x-ray performed best but provided least social presence among participants. We discuss these and other observations as well as potential impacts on designing AR awareness and orientation support.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {coordination, awareness, ar, social presence, orientation support, cooperation, occlusion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376160,
author = {Leiva, Germ\'{a}n and Nguyen, Cuong and Kazi, Rubaiat Habib and Asente, Paul},
title = {Pronto: Rapid Augmented Reality Video Prototyping Using Sketches and Enaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376160},
doi = {10.1145/3313831.3376160},
abstract = {Designers have limited tools to prototype AR experiences rapidly. Can lightweight, immediate tools let designers prototype dynamic AR interactions while capturing the nuances of a 3D experience? We interviewed three AR experts and identified several recurring issues in AR design: creating and positioning 3D assets, handling the changing user position, and orchestrating multiple animations. We introduce PROJECT PRONTO, a tablet-based video prototyping system that combines 2D video with 3D manipulation. PRONTO supports four intertwined activities: capturing 3D spatial information alongside a video scenario, positioning and sketching 2D drawings in a 3D world, and enacting animations with physical interactions. An observational study with professional designers shows that participants can use PRONTO to prototype diverse AR experiences. All participants performed two tasks: replicating a sample non-trivial AR experience and prototyping their open-ended designs. All participants completed the replication task and found PRONTO easy to use. Most participants found that PRONTO encourages more exploration of designs than their current practices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {video prototyping, design by enaction, sketching, ar},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376372,
author = {Kontogiorgos, Dimosthenis and van Waveren, Sanne and Wallberg, Olle and Pereira, Andre and Leite, Iolanda and Gustafson, Joakim},
title = {Embodiment Effects in Interactions with Failing Robots},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376372},
doi = {10.1145/3313831.3376372},
abstract = {The increasing use of robots in real-world applications will inevitably cause users to encounter more failures in interactions. While there is a longstanding effort in bringing human-likeness to robots, how robot embodiment affects users' perception of failures remains largely unexplored. In this paper, we extend prior work on robot failures by assessing the impact that embodiment and failure severity have on people's behaviours and their perception of robots. Our findings show that when using a smart-speaker embodiment, failures negatively affect users' intention to frequently interact with the device, however not when using a human-like robot embodiment. Additionally, users significantly rate the human-like robot higher in terms of perceived intelligence and social presence. Our results further suggest that in higher severity situations, human-likeness is distracting and detrimental to the interaction. Drawing on quantitative findings, we discuss benefits and drawbacks of embodiment in robot failures that occur in guided tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {smart-speakers, time pressure, common ground, guided tasks, conversational failures, social robots},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376793,
author = {Das Swain, Vedant and Saha, Koustuv and Reddy, Manikanta D. and Rajvanshy, Hemang and Abowd, Gregory D. and De Choudhury, Munmun},
title = {Modeling Organizational Culture with Workplace Experiences Shared on Glassdoor},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376793},
doi = {10.1145/3313831.3376793},
abstract = {Organizational culture (OC) encompasses the underlying beliefs, values, and practices that are unique to an organization. However, OC is inherently subjective and a coarse construct, and therefore challenging to quantify. Alternatively, self-initiated workplace reviews on online platforms like Glassdoor provide the opportunity to leverage the richness of language to understand OC. In as much, first, we use multiple job descriptors to operationalize OC as a word vector representation. We validate this construct with language used in 650k different Glassdoor reviews. Next, we propose a methodology to apply our construct on Glassdoor reviews to quantify the OC of employees by sector. We validate our measure of OC on a dataset of 341 employees by providing empirical evidence that it helps explain job performance. We discuss the implications of our work in guiding tailored interventions and designing tools for improving employee functioning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {glassdoor, social media, wordvector, organizational culture},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376570,
author = {Zou, Yixin and Roundy, Kevin and Tamersoy, Acar and Shintre, Saurabh and Roturier, Johann and Schaub, Florian},
title = {Examining the Adoption and Abandonment of Security, Privacy, and Identity Theft Protection Practices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376570},
doi = {10.1145/3313831.3376570},
abstract = {Users struggle to adhere to expert-recommended security and privacy practices. While prior work has studied initial adoption of such practices, little is known about the subsequent implementation and abandonment. We conducted an online survey (n=902) examining the adoption and abandonment of 30 commonly recommended practices. Security practices were more widely adopted than privacy and identity theft protection practices. Manual and fully automatic practices were more widely adopted than practices requiring recurring user interaction. Participants' gender, education, technical background, and prior negative experience are correlated with their levels of adoption. Furthermore, practices were abandoned when they were perceived as low-value, inconvenient, or when users overrode them with subjective judgment. We discuss how security, privacy, and identity theft protection recommendations and tools can be better aligned with user needs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {risk perception, user behavior, adoption, abandonment, technology non-use, usable security and privacy, security and privacy decision-making},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376649,
author = {Glowacki, David R. and Wonnacott, Mark D. and Freire, Rachel and Glowacki, Becca R. and Gale, Ella M. and Pike, James E. and de Haan, Tiu and Chatziapostolou, Mike and Metatla, Oussama},
title = {Isness: Using Multi-Person VR to Design Peak Mystical Type Experiences Comparable to Psychedelics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376649},
doi = {10.1145/3313831.3376649},
abstract = {Studies combining psychotherapy with psychedelic drugs (Ds) have demonstrated positive outcomes that are often associated with 'Ds' ability to induce 'mystical-type' experiences (MTEs) i.e., subjective experiences whose characteristics include a sense of connectedness, transcendence, and ineffability. We suggest that both PsiDs and virtual reality can be situated on a broader spectrum of psychedelic technologies. To test this hypothesis, we used concepts, methods, and analysis strategies from D research to design and evaluate 'Isness', a multi-person VR journey where participants experience the collective emergence, fluctuation, and dissipation of their bodies as energetic essences. A study (N=57) analyzing participant responses to a commonly used D experience questionnaire (MEQ30) indicates that Isness participants reported MTEs comparable to those reported in double-blind clinical studies after high doses of psilocybin and LSD. Within a supportive setting and conceptual framework, VR phenomenology can create the conditions for MTEs from which participants derive insight and meaning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {meaning in HCI, psychedelic drugs, altered states, mystical-type experiences, virtual reality, user experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376556,
author = {Schroeder, Kay and Ajdadilish, Batoul and Henkel, Alexander P. and Calero Valdez, Andr\'{e}},
title = {Evaluation of a Financial Portfolio Visualization Using Computer Displays and Mixed Reality Devices with Domain Experts},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376556},
doi = {10.1145/3313831.3376556},
abstract = {With the advent of mixed reality devices such as the Microsoft HoloLens, developers have been faced with the challenge to utilize the third dimension in information visualization effectively. Research on stereoscopic devices has shown that three-dimensional representation can improve accuracy in specific tasks (e.g., network visualization). Yet, so far the field has remained mute on the underlying mechanism. Our study systematically investigates the differences in user perception between a regular monitor and a mixed reality device. In a real-life within-subject experiment in the field with twenty-eight investment bankers, we assessed subjective and objective task performance with two- and three-dimensional systems, respectively. We tested accuracy with regard to position, size, and color using single and combined tasks. Our results do not show a significant difference in accuracy between mixed-reality and standard 2D monitor visualizations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {information visualization, hololens, mixed reality displays, UX study, user study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376439,
author = {Gao, Ge and Sun, Yuling and Zhang, Yongle},
title = {Engaging the Commons in Participatory Sensing: Practice, Problems, and Promise in the Context of Dockless Bikesharing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376439},
doi = {10.1145/3313831.3376439},
abstract = {Participatory sensing refers to the sensing paradigm where human participants use personal mobile devices to generate and share data from their surroundings. It holds the promise of providing information that is otherwise challenging to access, which sets the stage for understanding and resolving various social issues. However, difficulties in engaging participants often hinder the fulfillment of this promise. The current paper presents a qualitative study in the context of dockless bikesharing, where participatory sensing constitutes a backbone of the bike status monitoring system. We conducted in-depth interviews with 30 participants. These participants came from different emergent groups who took part in filing status reports for shared bikes. Our analysis indicated close associations among participants' models of engagement, their perceived (dis)connections with the sensing data, and their situated interpretation of the incentives. Based on these findings, we propose ways to engage the commons in participatory sensing for dockless bikesharing and beyond.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {smart city, engagement, dockless bikesharing, participatory sensing, urban transportation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376186,
author = {Trajkova, Milka and Alhakamy, A'aeshah and Cafaro, Francesco and Mallappa, Rashmi and Kankara, Sreekanth R.},
title = {Move Your Body: Engaging Museum Visitors with Human-Data Interaction},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376186},
doi = {10.1145/3313831.3376186},
abstract = {Museums have embraced embodied interaction: its novelty generates buzz and excitement among their patrons, and it has enormous educational potential. Human-Data Interaction (HDI) is a class of embodied interactions that enables people to explore large sets of data using interactive visualizations that users control with gestures and body movements. In museums, however, HDI installations have no utility if visitors do not engage with them. In this paper, we present a quasi-experimental study that investigates how different ways of representing the user ("mode type") next-to a data visualization alters the way in which people engage with a HDI system. We consider four mode types: avatar, skeleton, camera overlay, and control. Our findings indicate that the mode type impacts the number of visitors that interact with the installation, the gestures that people do, and the amount of time that visitors spend observing the data on display and interacting with the system.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {public displays, museums, human-data interaction, informal learning, embodied interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376775,
author = {Noguchi, Yohei and Tanaka, Fumihide},
title = {OMOY: A Handheld Robotic Gadget That Shifts Its Weight to Express Emotions and Intentions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376775},
doi = {10.1145/3313831.3376775},
abstract = {A robotic gadget that is equipped with a movable weight inside its body is developed. By controlling the movement of the internal weight together with other robotic behaviors such as hand gestures or speech dialogues, it is expected that emotional and/or intentional messaging between users is enhanced. To gain knowledge for designing effective weight shifts, an elicitation study was conducted to investigate how users holding this gadget in their hand interpreted its 36 weight shift patterns generated by setting four basic movement parameters (target position, trajectory, speed, and repetition). Results present mappings between these parameters and the emotional perception of the users. Furthermore, specific weight shift patterns that can express certain human emotions and intentions are revealed. These findings will be useful for designing effective weight shifts to enhance emotional and intentional messaging between users. This study attempts to open a new dimension for the expression capability of robotic gadgets.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {emotional/intentional messaging, expression, weight shift, elicitation study, social mediator robot, communication agent},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376639,
author = {Zindulka, Tim and Bachynskyi, Myroslav and M\"{u}ller, J\"{o}rg},
title = {Performance and Experience of Throwing in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376639},
doi = {10.1145/3313831.3376639},
abstract = {Throwing is a fundamental movement in many sports and games. Given this, accurate throwing in VR applications today is surprisingly difficult. In this paper we explore the nature of the difficulties of throwing in VR in more detail. We present the results of a user study comparing throwing in VR and in the physical world. In a short pre-study with 3 participants we determine an optimal number of throwing repetitions for the main study by exploring the learning curve and subjective fatigue of throwing in VR. In the main study, with 12 participants, we find that throwing precision and accuracy in VR are lower particularly in the distance and height dimensions. It also requires more effort and exhibits different kinematic patterns.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {throwing, virtual reality, user study},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376593,
author = {Swearngin, Amanda and Wang, Chenglong and Oleson, Alannah and Fogarty, James and Ko, Amy J.},
title = {Scout: Rapid Exploration of Interface Layout Alternatives through High-Level Design Constraints},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376593},
doi = {10.1145/3313831.3376593},
abstract = {Although exploring alternatives is fundamental to creating better interface designs, current processes for creating alternatives are generally manual, limiting the alternatives a designer can explore. We present Scout, a system that helps designers rapidly explore alternatives through mixed-initiative interaction with high-level constraints and design feedback. Prior constraint-based layout systems use low-level spatial constraints and generally produce a single design. Tosupport designer exploration of alternatives, Scout introduces high-level constraints based on design concepts (e.g.,~semantic structure, emphasis, order) and formalizes them into low-level spatial constraints that a solver uses to generate potential layouts. In an evaluation with 18 interface designers, we found that Scout: (1) helps designers create more spatially diverse layouts with similar quality to those created with a baseline tool and (2) can help designers avoid a linear design process and quickly ideate layouts they do not believe they would have thought of on their own.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interface design, program synthesis, alternatives, constraints},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376240,
author = {Cobb, Camille and Simko, Lucy and Kohno, Tadayoshi and Hiniker, Alexis},
title = {User Experiences with Online Status Indicators},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376240},
doi = {10.1145/3313831.3376240},
abstract = {Online status indicators (OSIs) improve online communication by helping users convey and assess availability, but they also let users infer potentially sensitive information about one another. We surveyed 200 smartphone users to understand the extent to which users are aware of information shared via OSIs and the extent to which this shapes their behavior. Despite familiarity with OSIs, participants misunderstand many aspects of OSIs, and they describe carefully curating and seeking to control their self-presentation via OSIs. Some users further report leveraging OSI-conveyed information for problematic and malicious purposes. Drawing on existing constructs of app dependence (i.e., when users contort their behavior to meet an app's demands) and app enablement (i.e., when apps enable users to engage in behaviors they feel good about), we demonstrate that current OSI design patterns promote app dependence, and we call for a shift toward OSI designs that are more enabling for users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {online status, social computing, mobile apps, privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376806,
author = {Brooks, Jas and Nagels, Steven and Lopes, Pedro},
title = {Trigeminal-Based Temperature Illusions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376806},
doi = {10.1145/3313831.3376806},
abstract = {We explore a temperature illusion that uses low-powered electronics and enables the miniaturization of simple warm and cool sensations. Our illusion relies on the properties of certain scents, such as the coolness of mint or hotness of peppers. These odors trigger not only the olfactory bulb, but also the nose's trigeminal nerve, which has receptors that respond to both temperature and chemicals. To exploit this, we engineered a wearable device based on micropumps and an atomizer that emits up to three custom-made "thermal" scents directly to the user's nose. Breathing in these scents causes the user to feel warmer or cooler. We demonstrate how our device renders warmth and cooling sensations in virtual experiences. In our first study, we evaluated six candidate "thermal" scents. We found two hot-cold pairs, with one pair being less identifiable by odor. In our second study, pParticipants rated VR experiences with our device trigeminal stimulants as significantly warmer or cooler than the baseline conditions. Lastly, we believe this offers an alternative to existing thermal feedback devices, which unfortunately rely on power-hungry heat-lamps or Peltier-elements.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {trigeminal, haptics, illusion, thermal, smell, vr},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376380,
author = {Yen, Yu-Chun Grace and Kim, Joy O. and Bailey, Brian P.},
title = {Decipher: An Interactive Visualization Tool for Interpreting Unstructured Design Feedback from Multiple Providers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376380},
doi = {10.1145/3313831.3376380},
abstract = {Feedback from diverse audiences can vary in focus, differ in structure, and contradict each other, making it hard to interpret and act on. While prior work has explored generating quality feedback, our work helps a designer interpret that feedback. Through a formative study with professional designers (N=10), we discovered that the interpretation process includes categorizing feedback, identifying valuable feedback, and prioritizing which feedback to incorporate in a revision. We also found that designers leverage feedback topic and sentiment, and the status of the provider to aid interpretation. Based on the findings, we created a new tool (Decipher) that enables designers to visualize and navigate a collection of feedback using its topic and sentiment structure. In a preliminary evaluation (N=20), we found that Decipher helped users feel less overwhelmed during feedback interpretation tasks and better attend to critical issues and conflicting opinions compared to using a typical document-editing tool.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sense-making, creativity support tools, feedback, creativity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376154,
author = {Shin, Donghoon and Song, Jaeyoon and Song, Seokwoo and Park, Jisoo and Lee, Joonhwan and Jun, Soojin},
title = {TalkingBoogie: Collaborative Mobile AAC System for Non-Verbal Children with Developmental Disabilities and Their Caregivers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376154},
doi = {10.1145/3313831.3376154},
abstract = {Augmentative and alternative communication (AAC) technologies are widely used to help non-verbal children enable communication. For AAC-aided communication to be successful, caregivers should support children with consistent intervention strategies in various settings. As such, caregivers need to continuously observe and discuss children's AAC usage to create a shared understanding of these strategies. However, caregivers often find it challenging to effectively collaborate with one another due to a lack of family involvement and the unstructured process of collaboration. To address these issues, we present TalkingBoogie, which consists of two mobile apps: TalkingBoogie-AAC for caregiver-child communication, and TalkingBoogie-coach supporting caregiver collaboration. Working together, these applications provide contextualized layouts for symbol arrangement, scaffold the process of sharing and discussing observations, and induce caregivers' balanced participation. A two-week deployment study with four groups (N=11) found that TalkingBoogie helped increase mutual understanding of strategies and encourage balanced participation between caregivers with reduced cognitive loads.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {caregiver collaboration, developmental disability, aac, accessibility, assistive technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376245,
author = {Jensen, Rikke Bjerg and Coles-Kemp, Lizzie and Talhouk, Reem},
title = {When the Civic Turn Turns Digital: Designing Safe and Secure Refugee Resettlement},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376245},
doi = {10.1145/3313831.3376245},
abstract = {Across Europe, refugees are required to engage with the "civic turn" -- a process of integrating refugees into the social and cultural aspects of the new land. Over a two-year period, we engaged 89 refugees settling in Sweden, to explore how accelerated and digitalised resettlement processes shape the civic turn. Framed within wider literature on transitioning and everyday insecurities, we show how this "digital turn" exacerbates existing barriers to resettlement experienced by refugees. By critically analysing these barriers, we reveal how the civic turn rests upon a series of everyday social and cultural practices and relations, which are largely ignored in digital service design. We show how this leads to a "vacuum" for our participants. We call on the HCI community to engage with this vacuum and understand resettlement as encompassing multiple digitally-mediated transitional phases of citizenry. We do so by focusing on the digitalisation processes shaping these transitions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {everyday security, resettlement, digital, refugees, transition},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376304,
author = {Chen, Yuxin and Li, Huiying and Teng, Shan-Yuan and Nagels, Steven and Li, Zhijing and Lopes, Pedro and Zhao, Ben Y. and Zheng, Haitao},
title = {Wearable Microphone Jamming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376304},
doi = {10.1145/3313831.3376304},
abstract = {We engineered a wearable microphone jammer that is capable of disabling microphones in its user's surroundings, including hidden microphones. Our device is based on a recent exploit that leverages the fact that when exposed to ultrasonic noise, commodity microphones will leak the noise into the audible range.Unfortunately, ultrasonic jammers are built from multiple transducers and therefore exhibit blind spots, i.e., locations in which transducers destructively interfere and where a microphone cannot be jammed. To solve this, our device exploits a synergy between ultrasonic jamming and the naturally occur- ring movements that users induce on their wearable devices (e.g., bracelets) as they gesture or walk. We demonstrate that these movements can blur jamming blind spots and increase jamming coverage. Moreover, current jammers are also directional, requiring users to point the jammer to a microphone; instead, our wearable bracelet is built in a ring-layout that al- lows it to jam in multiple directions. This is beneficial in that it allows our jammer to protect against microphones hidden out of sight.We evaluated our jammer in a series of experiments and found that: (1) it jams in all directions, e.g., our device jams over 87% of the words uttered around it in any direction, while existing devices jam only 30% when not pointed directly at the microphone; (2) it exhibits significantly less blind spots; and, (3) our device induced a feeling of privacy to participants of our user study. We believe our wearable provides stronger privacy in a world in which most devices are constantly eavesdropping on our conversations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {privacy, ultrasound, wearable, jamming, microphone},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376495,
author = {Bourdeau, Simon and Lesage, Annemarie and Couturier Caron, B\'{e}atrice and L\'{e}ger, Pierre-Majorique},
title = {When Design Novices and LEGO® Meet: Stimulating Creative Thinking for Interface Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376495},
doi = {10.1145/3313831.3376495},
abstract = {Design thinking is an iterative, human-centered approach to innovation. Its success rests on collaboration within a multidisciplinary project team going through cycles of divergent and convergent ideations. In these teams, nondesigners risk diminishing the divergent reach because they are generally reluctant to sketch, thus missing out on theambiguous, imprecise early conceptual divergent phases. We hypothesized that LEGO® could advantageously be a substitute to sketching. In this comparative study, 44 nondesigners randomly paired in 22 dyads did two conceptual ideations of healthcare landing pages, one using pen/paper (spontaneously writing words on sticky notes) and the other using LEGO, assessed through Torrance and Guilford frameworks for divergent thinking. Results show that LEGO interfaces gathered significantly higher divergent thinking scores because their concepts were significantly more elaborated. Furthermore, when using LEGO, teams who generated more elements were likely to also generate more ideas, more categories of ideas and more original ideas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {design methods, user experience design, creativity support, tangibles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376133,
author = {Dai, Jiamin and Moffatt, Karyn},
title = {Making Space for Social Sharing: Insights from a Community-Based Social Group for People with Dementia},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376133},
doi = {10.1145/3313831.3376133},
abstract = {People with dementia face major challenges in maintaining active social interaction. Designing digital tools for social sharing within families and care facilities has been well explored by HCI research, but comparatively less work has considered community settings. Situated in a community-based program for storytelling and socializing, our field observations and semi-structured interviews with people living with early-middle stage dementia, family caregivers, and program facilitators illustrate both positive and challenging aspects of social activities. We contribute a nuanced understanding of participants' social lives and identify four factors that aid in achieving positive outcomes: effective agencies for social interaction, normalized and friendly environments, collaboration and teamwork, and mediating social cues and communication. Finally, we examine our findings through the lens of past HCI work and offer insights for designing new social technologies to diversify the range of social spaces in community settings, through expanding peer collaboration, leveraging physical and virtual spaces, creating open-ended experiences, and developing flexible platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {dementia, social sharing, community, social interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376785,
author = {Kim, Soomin and Eun, Jinsu and Oh, Changhoon and Suh, Bongwon and Lee, Joonhwan},
title = {Bot in the Bunch: Facilitating Group Chat Discussion by Improving Efficiency and Participation with a Chatbot},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376785},
doi = {10.1145/3313831.3376785},
abstract = {Although group chat discussions are prevalent in daily life, they have a number of limitations. When discussing in a group chat, reaching a consensus often takes time, members contribute unevenly to the discussion, and messages are unorganized. Hence, we aimed to explore the feasibility of a facilitator chatbot agent to improve group chat discussions. We conducted a needfinding survey to identify key features for a facilitator chatbot. We then implemented GroupfeedBot, a chatbot agent that could facilitate group discussions by managing the discussion time, encouraging members to participate evenly, and organizing members' opinions. To evaluate GroupfeedBot, we performed preliminary user studies that varied for diverse tasks and different group sizes. We found that the group with GroupfeedBot appeared to exhibit more diversity in opinions even though there were no differences in output quality and message quantity. On the other hand, GroupfeedBot promoted members' even participation and effective communication for the medium-sized group.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {consensus, group chat, online communication, chatbot, conversational agent, discussion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376179,
author = {Lambton-Howard, Daniel and Olivier, Patrick and Vlachokyriakos, Vasilis and Celina, Hanna and Kharrufa, Ahmed},
title = {Unplatformed Design: A Model for Appropriating Social Media Technologies for Coordinated Participation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376179},
doi = {10.1145/3313831.3376179},
abstract = {Using existing social media technologies as a resource for design offers significant potential for sustainable and scalable ways of coordinating participation. We look at three exemplar projects in three distinct domains that have successfully coordinated participation through the configuration and augmentation of existing social media technologies: participatory future forecasting, participatory health research, and connectivist learning. In this paper we conceptualise social media technologies as material for design, that is, as the raw material with which coordinated participation is realized. From this we develop a model that proposes four material qualities of social media technologies, morphology, role, representation of activity and permeability, and point to how they can be productively employed in the design of coordination of participation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {social media, design of participation, materiality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376764,
author = {Subramanian, Krishna and Maas, Johannes and Borchers, Jan},
title = {TRACTUS: Understanding and Supporting Source Code Experimentation in Hypothesis-Driven Data Science},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376764},
doi = {10.1145/3313831.3376764},
abstract = {Data scientists experiment heavily with their code, compromising code quality to obtain insights faster. We observed ten data scientists perform hypothesis-driven data science tasks, and analyzed their coding, commenting, and analysis practice. We found that they have difficulty keeping track of their code experiments. When revisiting exploratory code to write production code later, they struggle to retrace their steps and capture the decisions made and insights obtained, and have to rerun code frequently. To address these issues, we designed TRACTUS, a system extending the popular RStudio IDE, that detects, tracks, and visualizes code experiments in hypothesis-driven data science tasks. TRACTUS helps recall decisions and insights by grouping code experiments into hypotheses, and structuring information like code execution output and documentation. Our user studies show how TRACTUS improves data scientists' workflows, and suggest additional opportunities for improvement. TRACTUS is available as an open source RStudio IDE addin at http://hci.rwth-aachen.de/tractus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {data science, programming ide, observational study, information visualization, exploratory programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376624,
author = {Smith-Renner, Alison and Fan, Ron and Birchfield, Melissa and Wu, Tongshuang and Boyd-Graber, Jordan and Weld, Daniel S. and Findlater, Leah},
title = {No Explainability without Accountability: An Empirical Study of Explanations and Feedback in Interactive ML},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376624},
doi = {10.1145/3313831.3376624},
abstract = {Automatically generated explanations of how machine learning (ML) models reason can help users understand and accept them. However, explanations can have unintended consequences: promoting over-reliance or undermining trust. This paper investigates how explanations shape users' perceptions of ML models with or without the ability to provide feedback to them: (1) does revealing model flaws increase users' desire to "fix" them; (2) does providing explanations cause users to believe - wrongly - that models are introspective, and will thus improve over time. Through two controlled experiments - varying model quality - we show how the combination of explanations and user feedback impacted perceptions, such as frustration and expectations of model improvement. Explanations without opportunity for feedback were frustrating with a lower quality model, while interactions between explanation and feedback for the higher quality model suggest that detailed feedback should not be requested without explanation. Users expected model correction, regardless of whether they provided feedback or received explanations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interactive machine learning, explainable machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376270,
author = {Metatla, Oussama and Bardot, Sandra and Cullen, Clare and Serrano, Marcos and Jouffrais, Christophe},
title = {Robots for Inclusive Play: Co-Designing an Educational Game With Visually Impaired and Sighted Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376270},
doi = {10.1145/3313831.3376270},
abstract = {Despite being included in mainstream schools, visually impaired children still face barriers to social engagement and participation. Games could potentially help, but games that cater for both visually impaired and sighted players are scarce. We used a co-design approach to design and evaluate a robot-based educational game that could be inclusive of both visually impaired and sighted children in the context of mainstream education. We ran a focus group discussion with visual impairment educators to understand barriers to inclusive play. And then a series of co-design workshops to engage visually impaired and sighted children and educators in learning about robot technology and exploring its potential to support inclusive play experiences. We present design guidelines and an evaluation workshop of a game prototype, demonstrating group dynamics conducive to collaborative learning experiences, including shared goal setting/execution, closely coupled division of labour, and interaction symmetry.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {co-design, games, education, inclusion, visual impairment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376461,
author = {Chin, Hyojin and Molefi, Lebogang Wame and Yi, Mun Yong},
title = {Empathy Is All You Need: How a Conversational Agent Should Respond to Verbal Abuse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376461},
doi = {10.1145/3313831.3376461},
abstract = {With the popularity of AI-infused systems, conversational agents (CAs) are becoming essential in diverse areas, offering new functionality and convenience, but simultaneously, suffering misuse and verbal abuse. We examine whether conversational agents' response styles under varying abuse types influence those emotions found to mitigate peoples' aggressive behaviors, involving three verbal abuse types (Insult, Threat, Swearing) and three response styles (Avoidance, Empathy, Counterattacking). Ninety-eight participants were assigned to one of the abuse type conditions, interacted with the three spoken (voice-based) CAs in turn, and reported their feelings about guiltiness, anger, and shame after each session. The results show that the agent's response style has a significant effect on user emotions. Participants were less angry and more guilty with the empathy agent than the other two agents. Furthermore, we investigated the current status of commercial CAs' responses to verbal abuse. Our study findings have direct implications for the design of conversational agents.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {intelligent personal assistant, virtual assistant, conversational agent, verbal abuse, smart speaker, agent abuse},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376400,
author = {Razi, Afsaneh and Badillo-Urquiola, Karla and Wisniewski, Pamela J.},
title = {Let's Talk about Sext: How Adolescents Seek Support and Advice about Their Online Sexual Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376400},
doi = {10.1145/3313831.3376400},
abstract = {We conducted a thematic content analysis of 4,180 posts by adolescents (ages 12-17) on an online peer support mental health forum to understand what and how adolescents talk about their online sexual interactions. Youth used the platform to seek support (83%), connect with others (15%), and give advice (5%) about sexting, their sexual orientation, sexual abuse, and explicit content. Females often received unwanted nudes from strangers and struggled with how to turn down sexting requests from people they knew. Meanwhile, others who sought support complained that they received unwanted sexual solicitations while doing so-to the point that adolescents gave advice to one another on which users to stay away from. Our research provides insight into the online sexual experiences of adolescents and how they seek support around these issues. We discuss how to design peer-based social media platforms to support the well-being and safety of youth.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {sexting, online sexual experiences, peer support, adolescent online safety, social support seeking, sexual risks},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376423,
author = {Pfau, Johannes and Smeddinck, Jan David and Malaka, Rainer},
title = {Enemy Within: Long-Term Motivation Effects of Deep Player Behavior Models for Dynamic Difficulty Adjustment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376423},
doi = {10.1145/3313831.3376423},
abstract = {Balancing games and producing content that remains interesting and challenging is a main cost factor in the design and maintenance of games. Dynamic difficulty adjustments (DDA) can successfully tune challenge levels to player abilities, but when implemented with classic heuristic parameter tuning (HPT) often turns out to be very noticeable, e.g. as "rubber-banding". Deep learning techniques can be employed for deep player behavior modeling (DPBM), enabling more complex adaptivity, but effects over frequent and longer-lasting game engagements, as well as how it compares to HPT has not been empirically investigated. We present a situated study of the effects of DDA via DPBM as compared to HPT on intrinsic motivation, perceived challenge and player motivation in a real-world MMORPG. The results indicate that DPBM can lead to significant improvements in intrinsic motivation and players prefer game experience episodes featuring DPBM over experience episodes with classic difficulty management.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {MMORPGs, player modeling, games, dynamic difficulty adjustment, neural networks, deep learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376547,
author = {Michaelis, Joseph E. and Siebert-Evenstone, Amanda and Shaffer, David Williamson and Mutlu, Bilge},
title = {Collaborative or Simply Uncaged? Understanding Human-Cobot Interactions in Automation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376547},
doi = {10.1145/3313831.3376547},
abstract = {Collaborative robots, or cobots, represent a breakthrough technology designed for high-level (e.g. collaborative) interactions between workers and robots with capabilities for flexible deployment in industries such as manufacturing. Understanding how workers and companies use and integrate cobots is important to inform the future design of cobot systems and educational technologies that facilitate effective worker-cobot interaction. Yet, little is known about typical training for collaboration and the application of cobots in manufacturing. To close this gap, we interviewed nine experts in manufacturing about their experience with cobots. Our thematic analysis revealed that, contrary to the envisioned use, experts described most cobot applications as only low-level (e.g. pressing start/stop buttons) interactions with little flexible deployment, and experts felt traditional robotics skills were needed for collaborative and flexible interaction with cobots. We conclude with design recommendations for improved future robots, including programming and interface designs, and educational technologies to support collaborative use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {technology adoption, human-robot interaction (hri), end-user programming, collaborative robots, human-robot collaboration, educational technology},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376517,
author = {Williford, Blake and Runyon, Matthew and Li, Wayne and Linsey, Julie and Hammond, Tracy},
title = {Exploring the Potential of an Intelligent Tutoring System for Sketching Fundamentals},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376517},
doi = {10.1145/3313831.3376517},
abstract = {Sketching is a practical and useful skill that can benefit communication and problem solving. However, it remains a difficult skill to learn because of low confidence and motivation among students and limited availability for instruction and personalized feedback among teachers. There is an need to improve the educational experience for both groups, and we hypothesized that integrating technology could provide a variety of benefits. We designed and developed an intelligent tutoring system for sketching fundamentals called Sketchtivity, and deployed it in to six existing courses at the high school and university level during the 2017-2018 school year. 268 students used the tool and produced more than 116,000 sketches of basic primitives. We conducted semi-structured interviews with the six teachers who implemented the software, as well as nine students from a course where the tool was used extensively. Using grounded theory, we found ten categories which unveiled the benefits and limitations of integrating an intelligent tutoring system for sketching fundamentals in to existing pedagogy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-computer interaction, drawing, sketching, art education, sketch recognition, intelligent tutoring system, design education, user experience design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376247,
author = {Dillen, Nicole and Ilievski, Marko and Law, Edith and Nacke, Lennart E. and Czarnecki, Krzysztof and Schneider, Oliver},
title = {Keep Calm and Ride Along: Passenger Comfort and Anxiety as Physiological Responses to Autonomous Driving Styles},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376247},
doi = {10.1145/3313831.3376247},
abstract = {Autonomous vehicles have been rapidly progressing towards full autonomy using fixed driving styles, which may differ from individual passenger preferences. Violating these preferences may lead to passenger discomfort or anxiety. We studied passenger responses to different driving style parameters in a physical autonomous vehicle. We collected galvanic skin response, heart rate, and eye-movement patterns from 20 participants, along with self-reported comfort and anxiety scores. Our results show that the presence and proximity of a lead vehicle not only raised the level of all measured physiological responses, but also exaggerated the existing effect of the longitudinal acceleration and jerk parameters. Skin response was also found to be a significant predictor of passenger comfort and anxiety. By using multiple independent events to isolate different driving style parameters, we demonstrate a method to control and analyze such parameters in future studies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {driving style, physiological sensing, affective computing, passengers, empirical study, comfort, autonomous vehicles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376698,
author = {Li, Nianlong and Han, Teng and Tian, Feng and Huang, Jin and Sun, Minghui and Irani, Pourang and Alexander, Jason},
title = {Get a Grip: Evaluating Grip Gestures for VR Input Using a Lightweight Pen},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376698},
doi = {10.1145/3313831.3376698},
abstract = {The use of Virtual Reality (VR) in applications such as data analysis, artistic creation, and clinical settings requires high precision input. However, the current design of handheld controllers, where wrist rotation is the primary input approach, does not exploit the human fingers' capability for dexterous movements for high precision pointing and selection. To address this issue, we investigated the characteristics and potential of using a pen as a VR input device. We conducted two studies. The first examined which pen grip allowed the largest range of motion---we found a tripod grip at the rear end of the shaft met this criterion. The second study investigated target selection via 'poking' and ray-casting, where we found the pen grip outperformed the traditional wrist-based input in both cases. Finally, we demonstrate potential applications enabled by VR pen input and grip postures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {handheld controller, finger and wrist dexterity, pen input, grip postures, spatial target selection, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376205,
author = {Rule, Adam and Goldstein, Isaac H. and Chiang, Michael F. and Hribar, Michelle R.},
title = {Clinical Documentation as End-User Programming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376205},
doi = {10.1145/3313831.3376205},
abstract = {As healthcare providers have transitioned from paper to electronic health records they have gained access to increasingly sophisticated documentation aids such as custom note templates. However, little is known about how providers use these aids. To address this gap, we examine how 48 ophthalmologists and their staff create and use content-importing phrases — a customizable and composable form of note template — to document office visits across two years. In this case study, we find 1) content-importing phrases were used to document the vast majority of visits (95%), 2) most content imported by these phrases was structured data imported by data-links rather than boilerplate text, and 3) providers primarily used phrases they had created while staff largely used phrases created by other people. We conclude by discussing how framing clinical documentation as end-user programming can inform the design of electronic health records and other documentation systems mixing data and narrative text.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {text input, end-user programming, electronic health record},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376724,
author = {Ruvimova, Anastasia and Kim, Junhyeok and Fritz, Thomas and Hancock, Mark and Shepherd, David C.},
title = {"Transport Me Away": Fostering Flow in Open Offices through Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376724},
doi = {10.1145/3313831.3376724},
abstract = {Open offices are cost-effective and continue to be popular. However, research shows that these environments, brimming with distractions and sensory overload, frequently hamper productivity. Our research investigates the use of virtual reality (VR) to mitigate distractions in an open office setting and improve one's ability to be in flow. In a lab study, 35 participants performed visual programming tasks in four combinations of physical (open or closed office) and virtual environments (beach or virtual office). While participants both preferred and were in flow more in a closed office without VR, in an open office, the VR environments outperformed the no VR condition in all measures of flow, performance, and preference. Especially considering the recent rapid advancements in VR, our findings illustrate the potential VR has to improve flow and satisfaction in open offices.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {work, open offices, flow, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376362,
author = {Lattie, Emily G. and Kornfield, Rachel and Ringland, Kathryn E. and Zhang, Renwen and Winquist, Nathan and Reddy, Madhu},
title = {Designing Mental Health Technologies That Support the Social Ecosystem of College Students},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376362},
doi = {10.1145/3313831.3376362},
abstract = {The last decade has seen increased reports of mental health problems among college students, with college counseling centers struggling to keep up with the demand for services. Digital mental health tools offer a potential solution to expand the reach of mental health services for college students. In this paper, we present findings from a series of design activities conducted with college students and counseling center staff aimed at identifying needs and preferences for digital mental health tools. Results emphasize the social ecosystems and social support networks in a college student's life. Our findings highlight the predominant role of known peers, and the ancillary roles of unknown peers and non-peers (e.g., faculty, family) in influencing the types of digital mental health tools students desire, and the ways in which they want to learn about mental health tools. We identify considerations for designing digital mental health tools for college students that take into account the identified social factors and roles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {co-design, user centered design, support technology, college students, mental health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376763,
author = {Wendt, Nicola and Jensen, Rikke Bjerg and Coles-Kemp, Lizzie},
title = {Civic Empowerment through Digitalisation: The Case of Greenlandic Women},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376763},
doi = {10.1145/3313831.3376763},
abstract = {This paper explores the disruptive and transformative effects of digital technology on gendered security asymmetries in Greenland. Through ethnographic fieldwork conducted in Greenland and Denmark, research findings emerged through in-depth interviews, collaborative mappings and field observations with 51 participants. Employing a critical feminist lens, the paper identifies how Greenlandic women develop digital security practices to respond to Greenland's ecologically, politically and socially induced transformation processes. By connecting individual security concerns of Greenlandic women with the broader regional context, the findings highlight how digital technology has created transitory spaces in which collective security is cultivated, shaped and challenged. The contribution to HCI scholarship is therefore threefold: (1) identification and acknowledgement of gendered effects of increased usage of digital technology in remote and hard-to-reach communities, (2) a broader conceptualisation of digital security and (3) a recommendation for more contextualised, pluralistic digitalisation policies and design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {indigenous identity, digital security, Greenland, women empowerment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376261,
author = {Liebling, Daniel J. and Lahav, Michal and Evans, Abigail and Donsbach, Aaron and Holbrook, Jess and Smus, Boris and Boran, Lindsey},
title = {Unmet Needs and Opportunities for Mobile Translation AI},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376261},
doi = {10.1145/3313831.3376261},
abstract = {Translation apps and devices are often presented in the context of providing assistance while traveling abroad. However, the spectrum of needs for cross-language communication is much wider. To investigate these needs, we conducted three studies with populations spanning socioeconomic status and geographic regions: (1) United States-based travelers, (2) migrant workers in India, and (3) immigrant populations in the United States. We compare frequent travelers' perception and actual translation needs with those of the two migrant communities. The latter two, with low language proficiency, have the greatest translation needs to navigate their daily lives. However, current mobile translation apps do not meet these needs. Our findings provide new insights on the usage practices and limitations of mobile translation tools. Finally, we propose design implications to help apps better serve these unmet needs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {emerging markets, migrants, machine translation, speech, immigrants, mobile},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376325,
author = {Dey, Debargha and Habibovic, Azra and Pfleging, Bastian and Martens, Marieke and Terken, Jacques},
title = {Color and Animation Preferences for a Light Band EHMI in Interactions Between Automated Vehicles and Pedestrians},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376325},
doi = {10.1145/3313831.3376325},
abstract = {In this paper, we report user preferences regarding color and animation patterns to support the interaction between Automated Vehicles (AVs) and pedestrians through an external Human-Machine-Interface (eHMI). Existing concepts of eHMI differ -- among other things -- in their use of colors or animations to express an AV's yielding intention. In the absence of empirical research, there is a knowledge gap regarding which color and animation leads to highest usability and preferences in traffic negotiation situations. We conducted an online survey (N=400) to investigate the comprehensibility of a light band eHMI with a combination of 5 color and 3 animation patterns for a yielding AV. Results show that cyan is considered a neutral color for communicating a yielding intention. Additionally, a uniformly flashing or pulsing animation is preferred compared to any pattern that animates sideways. These insights can contribute in the future design and standardization of eHMIs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {vru, animation, interface, color, ehmi, automated vehicles, pedestrians, autonomous vehicles},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376172,
author = {Zhang, Jiayi Eris and Sultanum, Nicole and Bezerianos, Anastasia and Chevalier, Fanny},
title = {DataQuilt: Extracting Visual Elements from Images to Craft Pictorial Visualizations},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376172},
doi = {10.1145/3313831.3376172},
abstract = {Recent years have seen an increasing interest in the authoring and crafting of personal visualizations. Mainstream data analysis and authoring tools lack the flexibility for customization and personalization, whereas tools from the research community either require creativity and drawing skills, or are limited to simple vector graphics. We present DataQuilt, a novel system that enables visualization authors to iteratively design pictorial visualizations as collages. Real images (e.g., paintings, photographs, sketches) act as both inspiration and as a resource of visual elements that can be mapped to data. The creative pipeline involves the semi-guided extraction of relevant elements of an image (arbitrary regions, regular shapes, color palettes, textures) aided by computer vision techniques; the binding of these graphical elements and their features to data in order to create meaningful visualizations; and the iterative refinement of both features and visualizations through direct manipulation. We demonstrate the usability of DataQuilt in a controlled study and its expressiveness through a collection of authored visualizations from a second open-ended study.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {collage, creativity, pictorial visualization, graphic design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376586,
author = {Guillou, Hayley and Chow, Kevin and Fritz, Thomas and McGrenere, Joanna},
title = {Is Your Time Well Spent? Reflecting on Knowledge Work More Holistically},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376586},
doi = {10.1145/3313831.3376586},
abstract = {The modern workplace is more demanding than ever before. Yet, since the industrial age, productivity measures have predominantly stayed narrowly focused on the output of the work, and not accounted for the big shift in the cognitive demands placed on the workers or the interleaving of work and life that is so common today. We posit that a more holistic conceptualization of Time Well Spent (TWS) at work could mitigate this issue. In our 1-week study, 40 knowledge workers used the experience sampling method (ESM) to rate their TWS and then define TWS at the end of the week. Our work contributes a preliminary characterization of TWS and empirical evidence that this term can capture a more holistic notion of work that also includes the worker's feelings and well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {productivity, productivity tools, time tracking, well-being, experience sampling method, knowledge worker},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376544,
author = {Moorthy, K. L. Bhanu and Kumar, Moneish and Subramanian, Ramanathan and Gandhi, Vineet},
title = {GAZED– Gaze-Guided Cinematic Editing of Wide-Angle Monocular Video Recordings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376544},
doi = {10.1145/3313831.3376544},
abstract = {We present GAZED– eye GAZe-guided EDiting for videos captured by a solitary, static, wide-angle and high-resolution camera. Eye-gaze has been effectively employed in computational applications as a cue to capture interesting scene content; we employ gaze as a proxy to select shots for inclusion in the edited video. Given the original video, scene content and user eye-gaze tracks are combined to generate an edited video comprising cinematically valid actor shots and shot transitions to generate an aesthetic and vivid representation of the original narrative. We model cinematic video editing as an energy minimization problem over shot selection, whose constraints capture cinematographic editing conventions. Gazed scene locations primarily determine the shots constituting the edited video. Effectiveness of GAZED against multiple competing methods is demonstrated via a psychophysical study involving 12 users and twelve performance videos.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {static wide-angle recording, cinematic video editing, gaze potential, stage performance, eye gaze, dynamic programming, shot selection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376757,
author = {Miri, Pardis and Jusuf, Emily and Uusberg, Andero and Margarit, Horia and Flory, Robert and Isbister, Katherine and Marzullo, Keith and Gross, James J.},
title = {Evaluating a Personalizable, Inconspicuous Vibrotactile(PIV) Breathing Pacer for In-the-Moment Affect Regulation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376757},
doi = {10.1145/3313831.3376757},
abstract = {Given the prevalence and adverse impact of anxiety, there is considerable interest in using technology to regulate anxiety. Evaluating the efficacy of such technology in terms of both the average effect (the intervention efficacy) and the heterogeneous effect (for whom and in what context the intervention was effective) is of paramount importance. In this paper, we demonstrate the efficacy of PIV, a personalized breathing pacer, in reducing anxiety in the presence of a cognitive stressor. We also quantify the relation between our specific stressor and PIV-user engagement. To our knowledge, this is the first mixed-design study of a vibrotactile affect regulation technology which accounts for a specific stressor and for individual differences in relation to the technology's efficacy. Guidelines in this paper can be applied for designing and evaluating other affect regulation technologies.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {shapley values, slow-paced breathing, linear mixed model, wearable, machine learning, vibrotactile, affect regulation, affect, pacer, respiration, xgboost, haptic, anxiety},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376580,
author = {Maye, Laura and Robinson, Sarah and Pantidi, Nadia and Ganea, Liana and Ganea, Oana and Linehan, Conor and McCarthy, John},
title = {Considerations for Implementing Technology to Support Community Radio in Rural Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376580},
doi = {10.1145/3313831.3376580},
abstract = {Rural communities often lack platforms to support civic engagement and local deliberation. Community radio is intended to facilitate such functions, yet, radio technologies can be expensive and complex to use. To tackle this challenge, low-barrier radio technologies are becoming available. We argue that technology to support civic engagement and local deliberation are important, and design of such platforms must take into consideration specific community needs. We contribute by exploring the needs of three rural European communities. Findings indicate that communities are now distributed beyond place. Platforms for deliberation must include both hyper-local and geographically dispersed populations. Rural values of accountability, reliability and maintaining social harmony are important design considerations. Community radio platforms should support geographically distributed community connections, sharing of health and emergency information, preservation of heritage and as a space for advocacy and civic action.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {community media, rural, community radio},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376355,
author = {Porfirio, David and Saupp\'{e}, Allison and Albarghouthi, Aws and Mutlu, Bilge},
title = {Transforming Robot Programs Based on Social Context},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376355},
doi = {10.1145/3313831.3376355},
abstract = {Social robots have varied effectiveness when interacting with humans in different interaction contexts. A robot programmed to escort individuals to a different location, for instance, may behave more appropriately in a crowded airport than a quiet library, or vice versa. To address these issues, we exploit ideas from program synthesis and propose an approach to transforming the structure of hand-crafted interaction programs that uses user-scored execution traces as input, in which end users score their paths through the interaction based on their experience. Additionally, our approach guarantees that transformations to a program will not violate task and social expectations that must be maintained across contexts. We evaluated our approach by adapting a robot program to both real-world and simulated contexts and found evidence that making informed edits to the robot's program improves user experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {model checking, interaction adaptation, human-robot interaction, program repair},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376397,
author = {Park, Sun Young and Seo, Woosuk and Berry, Andrew B.L. and Kim, Hyeryoung and Verma, Sanya and Choi, Sung Won and Buyuktur, Ayse G.},
title = {Learning from Positive Adaptations of Pediatric Cancer Patients to Design Health Technologies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376397},
doi = {10.1145/3313831.3376397},
abstract = {The diagnosis of cancer brings about significant changes in the life of a child. In addition to physical pain, pediatric patients face psychological and social challenges. At the same time, some patients also have positive experiences with and attitudes toward their illness and treatment. Drawing on 19 semi-structured interviews with pairs of pediatric cancer patients and their parental caregivers, we examined patients' perspectives on their experience of living with cancer. We identified four salient themes in patients' positive experiences: future-oriented thinking, developing strong personal bonds and relationships, gaining knowledge and life experience, and developing self-management and coping skills. Collectively, the patients' positive experiences indicate that they adapt to their new lives through an evolving process. Based on this process, we provide design implications for health technologies to support and promote positive experiences during illness and treatment.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {positive experience, health technology, pediatric patient, adaptation, cancer},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376375,
author = {Huffaker, Jordan S. and Kummerfeld, Jonathan K. and Lasecki, Walter S. and Ackerman, Mark S.},
title = {Crowdsourced Detection of Emotionally Manipulative Language},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376375},
doi = {10.1145/3313831.3376375},
abstract = {Detecting rhetoric that manipulates readers' emotions requires distinguishing intrinsically emotional content (IEC; e.g., a parent losing a child) from emotionally manipulative language (EML; e.g., using fear-inducing language to spread anti-vaccine propaganda). However, this remains an open classification challenge for both automatic and crowdsourcing approaches. Machine Learning approaches only work in narrow domains where labeled training data is available, and non-expert annotators tend to conflate IEC with EML. We introduce an approach, anchor comparison, that leverages workers' ability to identify and remove instances of EML in text to create a paraphrased "anchor text", which is then used as a comparison point to classify EML in the original content. We evaluate our approach with a dataset of news-style text snippets and show that precision and recall can be tuned for system builders' needs. Our contribution is a crowdsourcing approach that enables non-expert disentanglement of social references from content.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {emotion, crowdsourcing, media manipulation, rhetoric},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376347,
author = {Pierce, James and Wong, Richmond Y. and Merrill, Nick},
title = {Sensor Illumination: Exploring Design Qualities and Ethical Implications of Smart Cameras and Image/Video Analytics},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376347},
doi = {10.1145/3313831.3376347},
abstract = {Drawing analogies between smart cameras and electric lighting, we highlight and extrapolate design trends towards always-on sensing in intimate contexts, and the functional expansion of smart cameras as general-purpose and multi-functional devices. Employing a research through design (RtD) approach, we extrapolate these trends using speculative scenarios, materialize the scenarios by designing and constructing lighting-inspired smart camera fixtures, and self-experiment with these fixtures to introduce and exacerbate privacy and security issues, and inspire creative workarounds and design opportunities for sensor-level regulation. We synthesize our insights by presenting 8 smart camera sensing design qualities for addressing privacy, security, and related social and ethical issues.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–19},
numpages = {19},
keywords = {privacy, research through design, security, iot, smart home},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376607,
author = {Foong, Pin Sym and Lim, Charis Anne and Wong, Joshua and Lim, Chang Siang and Perrault, Simon Tangi and Koh, Gerald CH},
title = {"You Cannot Offer Such a Suggestion": Designing for Family Caregiver Input in Home Care Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376607},
doi = {10.1145/3313831.3376607},
abstract = {Previous work has looked closely at the challenges of using patient-generated data to enable remote assessment and monitoring by healthcare professionals. In this paper, we examine family caregivers who act as proxies for patients who may not have the capacity of capturing the necessary data. We worked with occupational therapists to develop an application for remote assessment of the safety of patients' homes by occupational therapists with the assistance of family caregivers. We evaluated the application with family caregivers and found two features unique to communication between family caregivers and healthcare professionals: Caregivers want to be able to direct healthcare professionals' attention to support problem-solving at home, and they include their perspective on how to best meet the patient's health needs. We discuss the importance of these findings for home systems in the domain of long-term chronic care.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {chronic care, healthcare, informatics, caregivers},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376386,
author = {Bellini, Rosanna and Forrest, Simon and Westmarland, Nicole and Jackson, Dan and Smeddinck, Jan David},
title = {Choice-Point: Fostering Awareness and Choice with Perpetrators in Domestic Violence Interventions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376386},
doi = {10.1145/3313831.3376386},
abstract = {Learning about alternatives to violence is an essential part of change work with domestic violence perpetrators. This is complex work, seeking to tackle a sensitive issue by involving the development of deep, embodied learning for perpetrators who may lack perspective on their behaviour. Interactive storytelling has been providing users with the opportunity to explore speculative scenarios in a controlled environment. We discuss the design of Choice-Point: a web-based application that allows perpetrators adopt the role of different fictional characters in an abusive scenario for conveying the essential skill of perspective-taking. We evaluated Choice-Point through trials with three groups of perpetrators, a support group of victim-survivors and an expert critique from support workers. We discuss challenges in using such technologies - such as our system - for engagement; the value of perpetrator agency in supporting non-violent behaviours, and the potential to positively shape perpetrators' journeys to non-violence within social care settings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {third-sector, intimate partner violence, batterers intervention programmes, domestic violence, domestic violence prevention programmes, family violence, interactive storytelling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376854,
author = {Sundar, S. Shyam and Kim, Jinyoung and Rosson, Mary Beth and Molina, Maria D.},
title = {Online Privacy Heuristics That Predict Information Disclosure},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376854},
doi = {10.1145/3313831.3376854},
abstract = {Online users' attitudes toward privacy are context-dependent. Studies show that contextual cues are quite influential in motivating users to disclose personal information. Increasingly, these cues are embedded in the interface, but the mechanisms of their effects (e.g., unprofessional design contributing to more disclosure) are not fully understood. We posit that each cue triggers a specific "cognitive heuristic" that provides a rationale for decision-making. Using a national survey (N = 786) that elicited participants' disclosure intentions in common online scenarios, we identify 12 distinct heuristics relevant to privacy, and demonstrate that they are systematically associated with information disclosure. Data show that those with a higher accessibility to a given heuristic are more likely to disclose information. Design implications for protection of online privacy and security are discussed.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {cognitive heuristics, information privacy, information disclosure, online decision-making},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376679,
author = {Edwards, Gregory W. and Gonzales, Michael J. and Sullivan, Marc A.},
title = {Robocalling: STIRRED AND SHAKEN! - An Investigation of Calling Displays on Trust and Answer Rates},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376679},
doi = {10.1145/3313831.3376679},
abstract = {Billions of robocalls annually have undermined the public's trust in the entire phone system. New functionality, called STIR/SHAKEN (S/S), hopes to help fix this issue by detecting whether a call is coming from the number it says it is. However, due to the nature of the system, at first only a portion of calls would go through the S/S system. This led us to question whether presenting this information would confuse users more than help. In this paper, we detail the results of online surveys, in-person interviews, and a lab-based simulation. The research recommends "Valid Number" for the label on the display and found that even with only 30% of calls being validated, S/S increased trust, answer frequency and consumer satisfaction. Based on these results, the launch of S/S could positively affect the current phone system and re-establish consumer trust.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {UX research, spoofing, lab simulation, robocalling, survey},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376520,
author = {Shi, Yang and Cao, Nan and Ma, Xiaojuan and Chen, Siji and Liu, Pei},
title = {EmoG: Supporting the Sketching of Emotional Expressions for Storyboarding},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376520},
doi = {10.1145/3313831.3376520},
abstract = {Storyboarding is an important ideation technique that uses sequential art to depict important scenarios of user experience. Existing data-driven support for storyboarding focuses on constructing user stories, but fail to address its benefit as a graphic narrative device. Instead, we propose to develop a data-driven design support tool that increases the expressiveness of user stories by facilitating sketching storyboards. To explore this, we focus on supporting the sketching of emotional expressions of characters in storyboards. In this paper, we present EmoG, an interactive system that generates sketches of characters with emotional expressions based on input strokes from the user. We evaluated EmoG with 21 participants in a controlled user study. The results showed that our tool has significantly better performance in usefulness, ease of use, and quality of results than the baseline system.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {creativity support tools, data-driven design, emotional expression generation, storyboarding},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376693,
author = {Bellini, Rosanna and Forrest, Simon and Westmarland, Nicole and Smeddinck, Jan David},
title = {Mechanisms of Moral Responsibility: Rethinking Technologies for Domestic Violence Prevention Work},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376693},
doi = {10.1145/3313831.3376693},
abstract = {This paper provides a critical examination of how digital systems within a charitable organisation in the North of England are being used to both support and challenge male perpetrators of domestic violence. While there exists a range of digital tools to support the victim-survivors of domestic violence, no tools are available to challenge the abusive and harmful behaviours of perpetrators. Through this work, we uncovered the compelling moral responsibilities intrinsic within interactions with technological systems between perpetrators and support workers. As such, we highlight four spaces of negotiation concerning a person's responsibility in changing their abusive behaviour, which we have coined as mechanisms to represent their fundamental and interconnected nature. These mechanisms include self-awareness, acknowledging the extent of harms, providing peer support and respecting authorities. These insights are the basis for offering some practical considerations for HCI scholars, policymakers and intervention designers in their work with perpetrators of violence.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {third sector, domestic violence, social care, civic technology, violence prevention, moral responsibility},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376552,
author = {Yasu, Kentaro},
title = {MagneLayer: Force Field Fabrication by Layered Magnetic Sheets},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376552},
doi = {10.1145/3313831.3376552},
abstract = {Magnets are very useful for the rapid prototyping of haptic interactions. However, it is difficult to arrange fine and complex magnetic fields rapidly. Therefore, we invented a method for fabricating complex geometric magnetic patterns by overlaying multiple magnetic rubber sheets. This method resolves the tradeoff between magnetized pattern complexity and the time required for magnetization. By layering multiple magnetic sheets that have simple magnetic patterns, various types of geometric magnetic patterns, such as checkered and diamond ones, can be generated on the top surface. By applying superposed magnetic fields, various types of tactile stimuli and haptic interaction can be created rapidly. Furthermore, the superposed magnetic fields can be changed dynamically by rotating the layered magnetic sheets. In this paper, we clarify the material requirements and describe the design method for creating these geometric magnetic patterns. We also demonstrate several of their applications.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {magnet, rapid prototyping, tactile, diy, haptic, fabrication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376274,
author = {Wang, Ding and Kale, Santosh D. and O'Neill, Jacki},
title = {Please Call the Specialism: Using WeChat to Support Patient Care in China},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376274},
doi = {10.1145/3313831.3376274},
abstract = {We examine how WeChat has been adopted to support nurse-patient communication in an IVF clinic in China. In this setting, the biggest challenge to delivering high-quality patient-centred care is the large number of patients. Nurses typically spend less than five minutes with each patient during clinical visits. To compensate for such minimal in-person consultation, nurse-facilitated patient groups were created on WeChat, to extend medical care and facilitate peer support. Through an ethnographic study, we examined how these groups fit into the clinic's communication ecosystem, and the challenges they raise for nurse-facilitators who receive thousands of messages daily. We propose a set of design suggestions aiming to make the work of the nurse-facilitator easier and more effective. In highlighting the opportunities and challenges of using chat to extend care beyond the clinic, we contribute to a burgeoning discussion of how chat can support patient care in the Global South.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {ethnography, nurse-patient communication, healthcare, wechat, peer support, chat apps},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376754,
author = {Votipka, Daniel and Abrokwa, Desiree and Mazurek, Michelle L.},
title = {Building and Validating a Scale for Secure Software Development Self-Efficacy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376754},
doi = {10.1145/3313831.3376754},
abstract = {Security is an essential component of the software development lifecycle. Researchers and practitioners have developed educational interventions, guidelines, security analysis tools, and new APIs aimed at improving security. However, measuring any resulting improvement in secure development skill is challenging. As a proxy for skill, we propose to measure self-efficacy, which has been shown to correlate with skill in other contexts. Here, we present a validated scale measuring secure software-development self-efficacy (SSD-SES). We first reviewed popular secure-development frameworks and surveyed 22 secure-development experts to identify 58 unique tasks. Next, we asked 311 developers - over multiple rounds - to rate their skill at each task. We iteratively updated our questions to ensure they were easily understandable, showed adequate variance between participants, and demonstrated reliability. Our final 15-item scale contains two sub-scales measuring belief in ability to perform vulnerability identification and mitigation as well as security communications tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–20},
numpages = {20},
keywords = {secure development, scale development},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376214,
author = {Coles-Kemp, Lizzie and Jensen, Rikke Bjerg and Heath, Claude P. R.},
title = {Too Much Information: Questioning Security in a Post-Digital Society},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376214},
doi = {10.1145/3313831.3376214},
abstract = {Whilst user- and people-centered design are accepted routes for digital services, they are less commonly used in the design of technologies that control access to data and the security of information. The ubiquity of both technology and programmes such as "digital by default" as well as the weaving of digital systems into the everyday fabric of society, create an environment in which people and technology become enmeshed. Such an environment might be termed "post-digital" and its security is dependent on a people-centered approach to its design. In this paper we present a study that uses critical design techniques coupled with critical security analysis to examine how security might be approached in a post-digital context. We call for a paradigm shift towards a people-centered security practice and using a case study then make practical recommendations as to how this shift might be achieved.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {critical security design, post-digital security, post-digital, lived experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376189,
author = {Marky, Karola and Schmitz, Martin and Zimmermann, Verena and Herbers, Martin and Kunze, Kai and M\"{u}hlh\"{a}user, Max},
title = {3D-Auth: Two-Factor Authentication with Personalized 3D-Printed Items},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376189},
doi = {10.1145/3313831.3376189},
abstract = {Two-factor authentication is a widely recommended security mechanism and already offered for different services. However, known methods and physical realizations exhibit considerable usability and customization issues. In this paper, we propose 3D-Auth, a new concept of two-factor authentication. 3D-Auth is based on customizable 3D-printed items that combine two authentication factors in one object. The object bottom contains a uniform grid of conductive dots that are connected to a unique embedded structure inside the item. Based on the interaction with the item, different dots turn into touch-points and form an authentication pattern. This pattern can be recognized by a capacitive touchscreen. Based on an expert design study, we present an interaction space with six categories of possible authentication interactions. In a user study, we demonstrate the feasibility of 3D-Auth items and show that the items are easy to use and the interactions are easy to remember.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {capacitive sensing, 3d printing, two-factor authentication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376579,
author = {Sengupta, Korok and Bhattarai, Sabin and Sarcar, Sayan and MacKenzie, I. Scott and Staab, Steffen},
title = {Leveraging Error Correction in Voice-Based Text Entry by Talk-and-Gaze},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376579},
doi = {10.1145/3313831.3376579},
abstract = {We present the design and evaluation of Talk-and-Gaze (TaG), a method for selecting and correcting errors with voice and gaze. TaG uses eye gaze to overcome the inability of voice-only systems to provide spatial information. The user's point of gaze is used to select an erroneous word either by dwelling on the word for 800 ms (D-TaG) or by uttering a "select" voice command (V-TaG). A user study with 12 participants compared D-TaG, V-TaG, and a voice-only method for selecting and correcting words. Corrections were performed more than 20% faster with D-TaG compared to the V-TaG or voice-only methods. As well, D-TaG was observed to require 24% less selection effort than V-TaG and 11% less selection effort than voice-only error correction. D-TaG was well received in a subjective assessment with 66% of users choosing it as their preferred choice for error correction in voice-based text entry.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {eye tracking, text entry, usability, multimodal, voice, interaction design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376719,
author = {Hoppe, Matthias and Rossmy, Beat and Neumann, Daniel Peter and Streuber, Stephan and Schmidt, Albrecht and Machulla, Tonja-Katrin},
title = {A Human Touch: Social Touch Increases the Perceived Human-Likeness of Agents in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376719},
doi = {10.1145/3313831.3376719},
abstract = {Virtual Reality experiences and games present believable virtual environments based on graphical quality, spatial audio, and interactivity. The interaction with in-game characters, controlled by computers (agents) or humans (avatars), is an important part of VR experiences. Pre-captured motion sequences increase the visual humanoid resemblance. However, this still precludes realistic social interactions (eye contact, imitation of body language), particularly for agents. We aim to make social interaction more realistic via social touch. Social touch is non-verbal, conveys feelings and signals (coexistence, closure, intimacy). In our research, we created an artificial hand to apply social touch in a repeatable and controlled fashion to investigate its effect on the perceived human-likeness of avatars and agents. Our results show that social touch is effective to further blur the boundary between computer- and human-controlled virtual characters and contributes to experiences that closely resemble human-to-human interactions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {social touch, human-likeness, agency, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376651,
author = {Gabriele, Sandra and Chiasson, Sonia},
title = {Understanding Fitness Tracker Users' Security and Privacy Knowledge, Attitudes and Behaviours},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376651},
doi = {10.1145/3313831.3376651},
abstract = {Personal data collected by fitness trackers can leave users open to security and privacy threats, often without their knowledge. Using an online survey with 212 fitness tracker users, we asked questions to understand participants' knowledge, attitudes and behaviours related to security and privacy, associated with the use of their fitness trackers. We found that users do little to protect their data. While they seem confident about the type of data being collected, they are unsure about how it is being used. Understandably, users are more comfortable sharing their data with friends and work colleagues. We also found that users differentiate between the types of data they are willing to share, suggesting a need for improved sharing preferences. When considering scenarios describing data uses with security and privacy implications, participants recognized that many scenarios were plausible but frequently felt that the scenarios were unlikely to occur. Overall, our findings lead us to believe that fitness tracker users require a greater awareness of the collection, ownership, storage, and sharing practices related to the tracking of their data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {survey, fitness trackers, privacy, online, data sharing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376175,
author = {Lee, Yi-Chieh and Yamashita, Naomi and Huang, Yun and Fu, Wai},
title = {"I Hear You, I Feel You": Encouraging Deep Self-Disclosure through a Chatbot},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376175},
doi = {10.1145/3313831.3376175},
abstract = {Chatbots have great potential to serve as a low-cost, effective tool to support people's self-disclosure. Prior work has shown that reciprocity occurs in human-machine dialog; however, whether reciprocity can be leveraged to promote and sustain deep self-disclosure over time has not been systematically studied. In this work, we design, implement and evaluate a chatbot that has self-disclosure features when it performs small talk with people. We ran a study with 47 participants and divided them into three groups to use different chatting styles of the chatbot for three weeks. We found that chatbot self-disclosure had a reciprocal effect on promoting deeper participant self-disclosure that lasted over the study period, in which the other chat styles without self-disclosure features failed to deliver. Chatbot self-disclosure also had a positive effect on improving participants' perceived intimacy and enjoyment over the study period. Finally, we reflect on the design implications of chatbots where deep self-disclosure is needed over time.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {chatbot, self-disclosure, mental well-being, conversation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376643,
author = {Frey, J\'{e}r\'{e}my and Ostrin, Gilad and Grabli, May and Cauchard, Jessica R.},
title = {Physiologically Driven Storytelling: Concept and Software Tool},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376643},
doi = {10.1145/3313831.3376643},
abstract = {We put forth Physiologically Driven Storytelling, a new approach to interactive storytelling where narratives adaptively unfold based on the reader's physiological state. We first describe a taxonomy framing how physiological signals can be used to drive interactive systems both as input and output. We then propose applications to interactive storytelling and describe the implementation of a software tool to create Physiological Interactive Fiction (PIF). The results of an online study (N=140) provided guidelines towards augmenting the reading experience. PIF was then evaluated in a lab study (N=14) to determine how physiological signals can be used to infer a reader's state. Our results show that breathing, electrodermal activity, and eye tracking can help differentiate positive from negative tones, and monotonous from exciting events. This work demonstrates how PIF can support storytelling in creating engaging content and experience tailored to the reader. Moreover, it opens the space to future physiologically driven systems within broader application areas.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {physiological computing, storytelling, physiology, interactive fiction, taxonomy, affective computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376310,
author = {Reitmaier, Thomas and Robinson, Simon and Pearson, Jennifer and Kalarikalayil Raju, Dani and Jones, Matt},
title = {An Honest Conversation: Transparently Combining Machine and Human Speech Assistance in Public Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376310},
doi = {10.1145/3313831.3376310},
abstract = {There is widespread concern over the ways speech assistant providers currently use humans to listen to users' queries without their knowledge. We report two iterations of the TalkBack smart speaker, which transparently combines machine and human assistance. In the first, we created a prototype to investigate whether people would choose to forward their questions to a human answerer if the machine was unable to help. Longitudinal deployment revealed that most users would do so when given the explicit choice. In the second iteration we extended the prototype to draw upon spoken answers from previous deployments, combining machine efficiency with human richness. Deployment of this second iteration shows that this corpus can help provide relevant, human-created instant responses. We distil lessons learned for those developing conversational agents or other AI-infused systems about how to appropriately enlist human-in-the-loop information services to benefit users, task workers and system performance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {speech appliances, emergent users, conversational agents, public space interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376814,
author = {Kim, Lawrence H. and Drew, Daniel S. and Domova, Veronika and Follmer, Sean},
title = {User-Defined Swarm Robot Control},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376814},
doi = {10.1145/3313831.3376814},
abstract = {A swarm of robots can accomplish more than the sum of its parts, and swarm systems will soon see increased use in applications ranging from tangible interfaces to search and rescue teams. However, effective human control of robot swarms has been shown to be demonstrably more difficult than controlling a single robot, and swarm-specific interactions methodologies are relatively underexplored. As we envision even non-expert users will have more daily in-person encounters with different numbers of robots in the future, we present a user-defined set of control interactions for tabletop swarm robots derived from an elicitation study. We investigated the effects of number of robots and proximity on the user's interaction and found significant effects. For instance, participants varied between using 1-2 fingers, one hand, and both hands depending on the group size. We also provide general design guidelines such as preferred interaction modality, common strategies, and a high-agreement interaction set.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {swarm robotics, swarm user interface, elicitation study, swarm robot control, multi-robot control},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376427,
author = {Yang, Jackie (Junrui) and Banerjee, Gaurab and Gupta, Vishesh and Lam, Monica S. and Landay, James A.},
title = {Soundr: Head Position and Orientation Prediction Using a Microphone Array},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376427},
doi = {10.1145/3313831.3376427},
abstract = {Although state-of-the-art smart speakers can hear a user's speech, unlike a human assistant these devices cannot figure out users' verbal references based on their head location and orientation. Soundr presents a novel interaction technique that leverages the built-in microphone array found in most smart speakers to infer the user's spatial location and head orientation using only their voice. With that extra information, Soundr can figure out users references to objects, people, and locations based on the speakers' gaze, and also provide relative directions. To provide training data for our neural network, we collected 751 minutes of data (50x that of the best prior work) from human speakers leveraging a virtual reality headset to accurately provide head tracking ground truth. Our results achieve an average positional error of 0.31m and an orientation angle accuracy of 34.3° for each voice command. A user study to evaluate user preferences for controlling IoT appliances by talking at them found this new approach to be fast and easy to use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {machine learning, smart speakers, acoustic source localization, internet of things},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376646,
author = {Menon, Sanju and Zhang, Weiyu and Perrault, Simon T.},
title = {Nudge for Deliberativeness: How Interface Features Influence Online Discourse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376646},
doi = {10.1145/3313831.3376646},
abstract = {Cognitive load is a significant challenge to users for being deliberative. Interface design has been used to mitigate this cognitive state. This paper surveys literature on the anchoring effect, partitioning effect and point-of-choice effect, based on which we propose three interface nudges, namely, the word-count anchor, partitioning text fields, and reply choice prompt. We then conducted a 2\texttimes{}2\texttimes{}2 factorial experiment with 80 participants (10 for each condition), testing how these nudges affect deliberativeness. The results showed a significant positive impact of the word-count anchor. There was also a significant positive impact of the partitioning text fields on the word count of response. The reply choice prompt showed a surprisingly negative affect on the quantity of response, hinting at the possibility that the reply choice prompt induces a fear of evaluation, which could in turn dampen the willingness to reply.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {deliberativeness, reply choice prompt, word count, portioning text fields, nudges, online discussion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376703,
author = {Arakawa, Riku and Yakura, Hiromu},
title = {INWARD: A Computer-Supported Tool for Video-Reflection Improves Efficiency and Effectiveness in Executive Coaching},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376703},
doi = {10.1145/3313831.3376703},
abstract = {Video-Reflection is a common approach to realize reflection in the field of executive coaching for professional development, which presents a video recording of the coaching session to a coachee in order to make the coachee reflectively think about oneself. However, it requires a great deal of time to watch the full length of the video and is highly dependent on the skills of the coach. We expect that the quality and efficiency of video-reflection can be improved with the support of computers. In this paper, we introduce INWARD, a computational tool that leverages human behavior analysis and video-based interaction techniques. The results of a user study involving 20 coaching sessions with five coaches indicate that INWARD enables efficient video-reflection and, by leveraging meta-reflection, realizes the ameliorated outcome of executive coaching. Moreover, discussions based on comments from the participants support the effectiveness of INWARD and suggest further possibilities of computer-supported approaches.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {executive coaching, meta-reflection, video-reflection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376213,
author = {Yaqub, Waheeb and Kakhidze, Otari and Brockman, Morgan L. and Memon, Nasir and Patil, Sameer},
title = {Effects of Credibility Indicators on Social Media News Sharing Intent},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376213},
doi = {10.1145/3313831.3376213},
abstract = {In recent years, social media services have been leveraged to spread fake news stories. Helping people spot fake stories by marking them with credibility indicators could dissuade them from sharing such stories, thus reducing their amplification. We carried out an online study (N = 1,512) to explore the impact of four types of credibility indicators on people's intent to share news headlines with their friends on social media. We confirmed that credibility indicators can indeed decrease the propensity to share fake news. However, the impact of the indicators varied, with fact checking services being the most effective. We further found notable differences in responses to the indicators based on demographic and personal characteristics and social media usage frequency. Our findings have important implications for curbing the spread of misinformation via social media platforms.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {fake news, facebook, disinformation, social media, news sharing, news headlines, misinformation, fact-check indicators},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376137,
author = {Jensen, Rikke Bjerg and Coles-Kemp, Lizzie and Wendt, Nicola and Lewis, Makayla},
title = {Digital Liminalities: Understanding Isolated Communities on the Edge},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376137},
doi = {10.1145/3313831.3376137},
abstract = {This paper brings together three distinct case studies to explore how social isolation and notions of liminality shape ontological security within communities on "the edge" of society. Each case study exemplifies the differing nature of liminality in everyday contexts and the extent to which increased digitalisation perturbs it in multiple ways. Taking an ethnographic approach, the research engaged with seafarers onboard container ships in European waters, communities in Greenland and welfare claimants in the North East of England. It posits that technological innovation must attend to the routinisation of everyday life through which people establish ontological security if such innovation is to be supportive. The paper thus moves beyond existing HCI scholarship by foregrounding the contextual and relational aspects of social isolation rather than the technological. It does so by advocating a ground-up design process that considers ontological security in relation to notions of liminality among communities on the edge.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {communities, liminality: ontological security, isolation, design principles, ethnography},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376402,
author = {Carros, Felix and Meurer, Johanna and L\"{o}ffler, Diana and Unbehaun, David and Matthies, Sarah and Koch, Inga and Wieching, Rainer and Randall, Dave and Hassenzahl, Marc and Wulf, Volker},
title = {Exploring Human-Robot Interaction with the Elderly: Results from a Ten-Week Case Study in a Care Home},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376402},
doi = {10.1145/3313831.3376402},
abstract = {Ageing societies and the associated pressure on the care systems are major drivers for new developments in socially assistive robotics. To understand better the real-world potential of robot-based assistance, we undertook a 10-week case study in a care home involving groups of residents, caregivers and managers as stakeholders. We identified both, enablers and barriers to the potential implementation of robot systems. The study employed the robot platform Pepper, which was deployed with a view to understanding better multi-domain interventions with a robot supporting physical activation, cognitive training and social facilitation. We employed the robot in a group setting in a care facility over the course of 10 weeks and 20 sessions, observing how stakeholders, including residents and caregivers, appropriated, adapted to, and perceived the robot. We also conducted interviews with 11 residents and caregivers. Our results indicate that the residents were positively engaged in the training sessions that were moderated by the robot. The study revealed that such humanoid robots can work in a care home but that there is a moderating person needed, that is in control of the robot.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {ethics, social robots, user studies, elderly care},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376409,
author = {Paneva, Viktorija and Bachynskyi, Myroslav and M\"{u}ller, J\"{o}rg},
title = {Levitation Simulator: Prototyping Ultrasonic Levitation Interfaces in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376409},
doi = {10.1145/3313831.3376409},
abstract = {We present the Levitation Simulator, a system that enables researchers and designers to iteratively develop and prototype levitation interface ideas in Virtual Reality. This includes user tests and formal experiments. We derive a model of the movement of a levitating particle in such an interface. Based on this, we develop an interactive simulation of the levitation interface in VR, which exhibits the dynamical properties of the real interface. The results of a Fitts' Law pointing study show that the Levitation Simulator enables performance, comparable to the real prototype. We developed the first two interactive games, dedicated for levitation interfaces: LeviShooter and BeadBounce, in the Levitation Simulator, and then implemented them on the real interface. Our results indicate that participants experienced similar levels of user engagement when playing the games, in the two environments. We share our Levitation Simulator as Open Source, thereby democratizing levitation research, without the need for a levitation apparatus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {virtual prototyping, simulation, ultrasonic levitation, vr, modeling},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376434,
author = {Browne, Kieran and Swift, Ben and Nurmikko-Fuller, Terhi},
title = {Camera Adversaria},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376434},
doi = {10.1145/3313831.3376434},
abstract = {In this paper we introduce Camera Adversaria; a mobile app designed to disrupt the automatic surveillance of personal photographs by technology companies. The app leverages the brittleness of deep neural networks with respect to high-frequency signals, adding generative adversarial perturbations to users' photographs. These perturbations confound image classification systems but are virtually imperceptible to human viewers. Camera Adversaria builds on methods developed by machine learning researchers as well as a growing body of work, primarily from art and design, which transgresses contemporary surveillance systems. We map the design space of responses to surveillance and identify an under-explored region where our project is situated. Finally we show that the language typically used in the adversarial perturbation literature serves to affirm corporate surveillance practices and malign resistance. This raises significant questions about the function of the research community in countenancing systems of surveillance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {adversarial examples, surveillance capitalism, critical design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376801,
author = {Bomfim, Marcela C. C. and Kirkpatrick, Sharon I. and Nacke, Lennart E. and Wallace, James R.},
title = {Food Literacy While Shopping: Motivating Informed Food Purchasing Behaviour with a Situated Gameful App},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376801},
doi = {10.1145/3313831.3376801},
abstract = {Establishing healthy eating patterns early in life is critical and has implications for lifelong health. Situated interventions are a promising approach to improve eating patterns. However, HCI research has emphasized calorie control and weight loss, potentially leading consumers to prioritize caloric intake over healthy eating patterns. To support healthy eating more holistically, we designed a gameful app called Pirate Bri's Grocery Adventure (PBGA) that seeks to improve food literacy—meaning the interconnected combination of food-related knowledge, skills, and behaviours that empower an individual to make informed food choices— through a situated approach to grocery shopping. Findings from our three-week field study revealed that PBGA was effective for improving players' nutrition knowledge and motivation for healthier food choices and reducing their impulse purchases. Our findings highlight that nutrition apps should promote planning and shopping based on balance, variety, and moderation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {healthy eating, grocery shopping, situated app, nutrition, food literacy, gameful design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376749,
author = {Brul\'{e}, Emeline and Tomlinson, Brianna J. and Metatla, Oussama and Jouffrais, Christophe and Serrano, Marcos},
title = {Review of Quantitative Empirical Evaluations of Technology for People with Visual Impairments},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376749},
doi = {10.1145/3313831.3376749},
abstract = {Addressing the needs of visually impaired people is of continued interest in Human Computer Interaction (HCI) research. Yet, one of the major challenges facing researchers in this field continues to be how to design adequate quantitative empirical evaluation for these users in HCI. In this paper, we analyse a corpus of 178 papers on technologies designed for people with visual impairments, published since 1988, and including at least one quantitative empirical evaluation (243 evaluations in total). To inform future research in this area, we provide an overview, historic trends and a unified terminology to design and report quantitative empirical evaluations. We identify open issues and propose a set of guidelines to address them. Our analysis aims to facilitate and stimulate future research on this topic.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visual impairments, assistive technology, literature review, evaluation methods, education, experiments},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376823,
author = {Kamikubo, Rie and Kato, Naoya and Higuchi, Keita and Yonetani, Ryo and Sato, Yoichi},
title = {Support Strategies for Remote Guides in Assisting People with Visual Impairments for Effective Indoor Navigation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376823},
doi = {10.1145/3313831.3376823},
abstract = {People with visual impairments often require mobility assistance of sighted guides but they are not always available. Recent technological strides have opened up new directions for sighted guidance services, assigning guides from a network of remote workers to provide real-time assistance via audio/video communication. However, little has been known regarding desirable support characteristics of remote guides or challenges experienced in guide practices without the requisite expertise. To recommend support strategies that contribute to facilitating a successful platform for remote sighted guidance, this paper presents a comparative study of the performance of trained and untrained sighted guides who are recruited for a remote scenario in assisting people with visual impairments in indoor navigation. As an outcome of this research, we provide a deeper understanding of design opportunities for HCI to scaffold requirements of remote guides, such that their collaborative efforts and environmental knowledge influence the user experience. Based on our empirical insights, we suggest to develop the expertise of remote guides through: a) preliminary guidance cooperation awareness b) guidelines for verbal description methods, and c) approaches to compensate for the lack of environmental knowledge.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visual impairment, remote assistance, indoor navigation, collaboration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376309,
author = {Kornfield, Rachel and Zhang, Renwen and Nicholas, Jennifer and Schueller, Stephen M. and Cambo, Scott A. and Mohr, David C. and Reddy, Madhu},
title = {"Energy is a Finite Resource": Designing Technology to Support Individuals across Fluctuating Symptoms of Depression},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376309},
doi = {10.1145/3313831.3376309},
abstract = {While the HCI field increasingly examines how digital tools can support individuals in managing mental health conditions, it remains unclear how these tools can accommodate these conditions' temporal aspects. Based on weekly interviews with five individuals with depression, conducted over six weeks, this study identifies design opportunities and challenges related to extending technology-based support across fluctuating symptoms. Our findings suggest that participants perceive events and contexts in daily life to have marked impact on their symptoms. Results also illustrate that ebbs and flows in symptoms profoundly affect how individuals practice depression self-management. While digital tools often aim to reach individuals while they feel depressed, we suggest they should also engage individuals when they are less symptomatic, leveraging their energy and motivation to build habits, establish plans and goals, and generate and organize content to prepare for symptom onset.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {digital interventions, temporality, motivation, depression, personalization, tailoring, mental health},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376318,
author = {Santhanam, Sashank and Karduni, Alireza and Shaikh, Samira},
title = {Studying the Effects of Cognitive Biases in Evaluation of Conversational Agents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376318},
doi = {10.1145/3313831.3376318},
abstract = {Humans quite frequently interact with conversational agents. The rapid advancement in generative language modeling through neural networks has helped advance the creation of intelligent conversational agents. Researchers typically evaluate the output of their models through crowdsourced judgments, but there are no established best practices for conducting such studies. Moreover, it is unclear if cognitive biases in decision-making are affecting crowdsourced workers' judgments when they undertake these tasks. To investigate, we conducted a between-subjects study with 77 crowdsourced workers to understand the role of cognitive biases, specifically anchoring bias, when humans are asked to evaluate the output of conversational agents. Our results provide insight into how best to evaluate conversational agents. We find increased consistency in ratings across two experimental conditions may be a result of anchoring bias. We also determine that external factors such as time and prior experience in similar tasks have effects on inter-rater consistency.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {experiment design, human evaluation, conversational agents, anchoring bias},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376667,
author = {Gelsomini, Mirko and Leonardi, Giulia and Garzotto, Franca},
title = {Embodied Learning in Immersive Smart Spaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376667},
doi = {10.1145/3313831.3376667},
abstract = {This paper presents the design and evaluation of IMAGINE, a novel interactive immersive smart space for embodied learning. In IMAGINE children use full-body movements and gestures to interact with multimedia educational contents projected on the wall and on the floor, while synchronized light effects enhance immersivity. A controlled study performed at a primary school with 48 children aged 6-8 highlights the educational potential of an immersive embodied solution, also compared to traditional teaching methods, and draws some implications for smart-space technology adoption in educational contexts.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {kinect, education, smart spaces, children, immersive environment, primary school, embodied learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376878,
author = {Liu, Wanyu and Gori, Julien and Rioul, Olivier and Beaudouin-Lafon, Michel and Guiard, Yves},
title = {How Relevant is Hick's Law for HCI?},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376878},
doi = {10.1145/3313831.3376878},
abstract = {Hick's law is a key quantitative law in Psychology that relates reaction time to the logarithm of the number of stimulus-response alternatives in a task. Its application to HCI is controversial: Some believe that the law does not apply to HCI tasks, others regard it as the cornerstone of interface design. The law, however, is often misunderstood. We review the choice-reaction time literature and argue that: (1) Hick's law speaks against, not for, the popular principle that 'less is better'; (2) logarithmic growth of observed temporal data is not necessarily interpretable in terms of Hick's law; (3) the stimulus-response paradigm is rarely relevant to HCI tasks, where choice-reaction time can often be assumed to be constant; and (4) for user interface design, a detailed examination of the effects on choice-reaction time of psychological processes such as visual search and decision making is more fruitful than a mere reference to Hick's law.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {convexity, stimulus-response, choice reaction time, logarithm, uncertainty, the hick-hyman law, information, hick's law},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376572,
author = {Mim, Nusrat Jahan and Ahmed, Syed Ishtiaque},
title = {Others' Images: Online Social Media, Architectural Improvisations, and Spatial Marginalization in Bangladesh},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376572},
doi = {10.1145/3313831.3376572},
abstract = {This paper joins the growing body of work in postcolonial computing in HCI, and critically examines the impacts of online social media on the urban architecture in the Global South. Based on our nine-month long ethnography at eight residential areas in Dhaka, Bangladesh, this paper reports how online fame drives local users to produce digital images of their houses mimicking various Western standards, which in turn, brings changes to the organization, aesthetics, and functions of domestic spaces. This paper also describes how such digital image mediated transformations to local architecture are diminishing traditional spaces, altering their usual functions, and limiting the movement of many women inside their home. Drawing from a rich body of literature in postcolonialism, critical image theory, architecture, and Islamic feminism, we explain how these practices demonstrate a subaltern experience of using social media in the Global South. We further discuss design implications to both HCI and architecture to address these issues, and connect our findings to the broader agendas of HCI around social justice and global development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {global south, social media, architecture, image sharing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376346,
author = {Mohamed, Reham and Chametka, Paulina and Chiasson, Sonia},
title = {The Influence of Decaying the Representation of Older Social Media Content on Simulated Hiring Decisions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376346},
doi = {10.1145/3313831.3376346},
abstract = {Decaying representations gradually make social media content less visible to readers over time, which can help users disassociate from past online activities. We explore whether shrinking, one decaying representation, influences managers' assessments and simulated hiring decisions of job candidates, compared to seeing a full profile or an empty profile with no posts. Our 3 x 2 between-subjects crowdsourced survey (N = 360 US managers) shows that shrunk or empty profiles led to more positive decisions than profiles in their original full format. However, shrunk profiles also further contributed to more positive impressions of the candidates. Shrinking did not help the candidate of either gender more than the other and demographics of managers had limited impact on their assessment. Further, our managers regularly search job candidates' social media profiles in real life, suggesting that shrinking could support users' privacy. We finally present implications for individuals' privacy on social media.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–19},
numpages = {19},
keywords = {online reputation management, hiring context, online privacy, online social networks, decaying representations},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376224,
author = {Yamagami, Momona and Steele, Katherine M. and Burden, Samuel A.},
title = {Decoding Intent With Control Theory: Comparing Muscle Versus Manual Interface Performance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376224},
doi = {10.1145/3313831.3376224},
abstract = {Manual device interaction requires precise coordination which may be difficult for users with motor impairments. Muscle interfaces provide alternative interaction methods that may enhance performance, but have not yet been evaluated for simple (eg. mouse tracking) and complex (eg. driving) continuous tasks. Control theory enables us to probe continuous task performance by separating user input into intent and error correction to quantify how motor impairments impact device interaction. We compared the effectiveness of a manual versus a muscle interface for eleven users without and three users with motor impairments performing continuous tasks. Both user groups preferred and performed better with the muscle versus the manual interface for the complex continuous task. These results suggest muscle interfaces and algorithms that can detect and augment user intent may be especially useful for future design of interfaces for continuous tasks.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {user intent, interaction, motor impairments, control theory, electromyography, accessibility, muscle interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376625,
author = {Rajcic, Nina and McCormack, Jon},
title = {Mirror Ritual: An Affective Interface for Emotional Self-Reflection},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376625},
doi = {10.1145/3313831.3376625},
abstract = {This paper introduces a new form of real-time affective interface that engages the user in a process of conceptualisation of their emotional state. Inspired by Barrett's Theory of Constructed Emotion, 'Mirror Ritual' aims to expand upon the user's accessible emotion concepts, and to ultimately provoke emotional reflection and regulation. The interface uses classified emotions – obtained through facial expression recognition -- as a basis for dynamically generating poetry. The perceived emotion is used to seed a poetry generation system based on OpenAI's GPT-2 model, fine-tuned on a specially curated corpus. We evaluate the device's ability to foster a personalised, meaningful experience for individual users over a sustained period. A qualitative analysis revealed that participants were able to affectively engage with the mirror, with each participant developing a unique interpretation of its poetry in the context of their own emotional landscape.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {emotion, computational creativity, affective computing, theory of constructed emotion, affective interface, generative networks, poetry},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376511,
author = {Habib, Hana and Pearman, Sarah and Wang, Jiamin and Zou, Yixin and Acquisti, Alessandro and Cranor, Lorrie Faith and Sadeh, Norman and Schaub, Florian},
title = {"It's a Scavenger Hunt": Usability of Websites' Opt-Out and Data Deletion Choices},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376511},
doi = {10.1145/3313831.3376511},
abstract = {We conducted an in-lab user study with 24 participants to explore the usefulness and usability of privacy choices offered by websites. Participants were asked to find and use choices related to email marketing, targeted advertising, or data deletion on a set of nine websites that differed in terms of where and how these choices were presented. They struggled with several aspects of the interaction, such as selecting the correct page from a site's navigation menu and understanding what information to include in written opt-out requests. Participants found mechanisms located in account settings pages easier to use than options contained in privacy policies, but many still consulted help pages or sent email to request assistance. Our findings indicate that, despite their prevalence, privacy choices like those examined in this study are difficult for consumers to exercise in practice. We provide design and policy recommendations for making these website opt-out and deletion choices more useful and usable for consumers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {email marketing, privacy, privacy controls, targeted advertising, data deletion, usability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376163,
author = {Sarsenbayeva, Zhanna and Marini, Gabriele and van Berkel, Niels and Luo, Chu and Jiang, Weiwei and Yang, Kangning and Wadley, Greg and Dingler, Tilman and Kostakos, Vassilis and Goncalves, Jorge},
title = {Does Smartphone Use Drive Our Emotions or Vice Versa? A Causal Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376163},
doi = {10.1145/3313831.3376163},
abstract = {In this paper, we demonstrate the existence of a bidirectional causal relationship between smartphone application use and user emotions. In a two-week long in-the-wild study with 30 participants we captured 502,851 instances of smartphone application use in tandem with corresponding emotional data from facial expressions. Our analysis shows that while in most cases application use drives user emotions, multiple application categories exist for which the causal effect is in the opposite direction. Our findings shed light on the relationship between smartphone use and emotional states. We furthermore discuss the opportunities for research and practice that arise from our findings and their potential to support emotional well-being.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {mobile application use, emotions, emotional well-being, smartphones, emotion detection, mobile interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376239,
author = {Silva, In\^{e}s Santos and Guerreiro, Jo\~{a}o and Rosa, Marlene and Campos, Joana and Pascoal, Augusto Gil and Pinto, Sofia and Nicolau, Hugo},
title = {Investigating the Opportunities for Technologies to Enhance QoL with Stroke Survivors and Their Families},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376239},
doi = {10.1145/3313831.3376239},
abstract = {There are over 80 million stroke survivors globally, making it the main cause of long-term disability worldwide. Not only do the challenges associated with stroke affect the quality of life (QoL) of survivors, but also of their families. To explore these challenges and define design opportunities for technologies to improve the QoL of both stakeholders, we conducted semi-structured interviews with 10 survivors and one of their family members. We uncovered three major interlinked themes: strategies to cope with technological barriers, the (in)adequacy of assistive technologies, and limitations of the rehabilitation process. Findings highlight multiple design opportunities, including the need for meaningful patient-centered tools and methods to improve rehabilitation effectiveness, emotion-aware computing for family emotional support, and re-thinking the nature of assistive technologies to consider the perception of transitory stroke-related disabilities. We thus argue for a new class of dual-purpose technologies that fit survivors' abilities while promoting the regain of function.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {stroke rehabilitation, assistive technologies, quality of life},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376736,
author = {Okuya, Yujiro and Gladin, Olivier and Ladev\`{e}ze, Nicolas and Fleury, C\'{e}dric and Bourdot, Patrick},
title = {Investigating Collaborative Exploration of Design Alternatives on a Wall-Sized Display},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376736},
doi = {10.1145/3313831.3376736},
abstract = {Industrial design review is an iterative process which mainly relies on two steps involving many stakeholders: design discussion and CAD data adjustment. We investigate how a wall-sized display could be used to merge these two steps by allowing multidisciplinary collaborators to simultaneously generate and explore design alternatives. We designed ShapeCompare based on the feedback from a usability study. It enables multiple users to compute and distribute CAD data with touch interaction. To assess the benefit of the wall-sized display in such context, we ran a controlled experiment which aims to compare ShapeCompare with a visualization technique suitable for standard screens. The results show that pairs of participants performed a constraint solving task faster and used more deictic instructions with ShapeCompare. From these findings, we draw generic recommendations for collaborative exploration of alternatives.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {collaboration, wall-sized display, computer-aided design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376414,
author = {Mahmud, Shareen and Alvina, Jessalyn and Chilana, Parmit K. and Bunt, Andrea and McGrenere, Joanna},
title = {Learning Through Exploration: How Children, Adults, and Older Adults Interact with a New Feature-Rich Application},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376414},
doi = {10.1145/3313831.3376414},
abstract = {Feature-rich applications such as word processors and spreadsheets are not only being used by adults but increasingly by children and older adults as well. Learning these applications is challenging as they offer hundreds of commands throughout the interface. We investigate how newcomers from different age groups explore the user interface of a feature-rich application to determine, locate, and use relevant features. We conducted an in-lab observational study with 10 children (10-12), 10 adults (20-35) and 10 older adults (60-75) who were first-time users of Microsoft OneNote. Our results illustrate key exploration differences across age groups, including that children were careful and performed as efficiently as the adults, whereas older adults spent a longer time and repeated sequences of failed selections. Further, their exploration style was negatively influenced by their past knowledge of similar applications. We discuss design interventions to accommodate these exploration differences and to improve software onboarding for newcomers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {newcomers' exploration strategies, desktop/laptop gui, lab study, age-related differences},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376280,
author = {Kim, Erin and Schneider, Oliver},
title = {Defining Haptic Experience: Foundations for Understanding, Communicating, and Evaluating HX},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376280},
doi = {10.1145/3313831.3376280},
abstract = {Haptic technology is maturing, with expectations and evidence that it will contribute to user experience (UX). However, we have very little understanding about how haptic technology can influence people's experience. Researchers and designers need a way to understand, communicate, and evaluate haptic technology's effect on UX. From a literature review and two studies - one with haptics novices, the other with expert hapticians - we developed a theoretical model of the factors that constitute a good haptic experience (HX). We define HX and propose its constituent factors: design parameters of Timeliness, Density, Intensity, and Timbre; the cross-cutting concern of Personalization; usability requirements of Utility, Causality, Consistency, and Saliency; and experiential factors of Harmony, Expressivity, Autotelics, Immersion, and Realism as guiding constructs important for haptic experience. This model will help guide design and research of haptic systems, inform language around haptics, and provide the basis for evaluative instruments, such as checklists, heuristics, or questionnaires.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {scale development, design, vibrotactile, haptics, user experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376864,
author = {Kuosmanen, Elina and Kan, Valerii and Visuri, Aku and Hosio, Simo and Ferreira, Denzil},
title = {Let's Draw: Detecting and Measuring Parkinson's Disease on Smartphones},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376864},
doi = {10.1145/3313831.3376864},
abstract = {Spiral drawing has been utilized for years as a clinical tool to observe tremors and other abnormal movements in the assessment of different movement disorders. Specifically, in Parkinson's Disease (PD), patients' motor functionalities are measured by various tests, and spiral drawing is one of the proven techniques for assessing the severity of PD motor symptoms. Traditionally, this test is performed on pen and paper, and visually assessed by a clinician. There have been successful efforts for digitizing this test on tablets. Here, we describe a smartphone-based digitized version of the spiral drawing test. Moreover, we introduce a square-shaped drawing to solve an identified challenge of a smaller screen estate: finger occlusion while drawing. Both approaches are evaluated with 8 Parkinson's Disease patients and 6 age-matching control participants. Based on earlier studies and our data, we select suitable motion parameters for quantifying the task. Our results show an observable, statistically difference in performance between users with Parkinson's Disease and the control group in drawing accuracy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {motor assessment, spiral analysis, parkinson's disease, smartphone, archimedean spiral},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376286,
author = {Wang, Yuntao and Chen, Zichao (Tyson) and Li, Hanchuan and Cao, Zhengyi and Luo, Huiyi and Zhang, Tengxiang and Ou, Ke and Raiti, John and Yu, Chun and Patel, Shwetak and Shi, Yuanchun},
title = {MoveVR: Enabling Multiform Force Feedback in Virtual Reality Using Household Cleaning Robot},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376286},
doi = {10.1145/3313831.3376286},
abstract = {Haptic feedback can significantly enhance the realism and immersiveness of virtual reality (VR) systems. In this paper, we propose MoveVR, a technique that enables realistic, multiform force feedback in VR leveraging commonplace cleaning robots. MoveVR can generate tension, resistance, impact and material rigidity force feedback with multiple levels of force intensity and directions. This is achieved by changing the robot's moving speed, rotation, position as well as the carried proxies. We demonstrated the feasibility and effectiveness of MoveVR through interactive VR gaming. In our quantitative and qualitative evaluation studies, participants found that MoveVR provides more realistic and enjoyable user experience when compared to commercially available haptic solutions such as vibrotactile haptic systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {vr, human-robot interaction, virtual reality, cleaning robot, haptic feedback, robotics, force feedback},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376584,
author = {Daskalova, Nediyana and Yoon, Jina and Wang, Yibing and Araujo, Cintia and Beltran, Guillermo and Nugent, Nicole and McGeary, John and Williams, Joseph Jay and Huang, Jeff},
title = {SleepBandits: Guided Flexible Self-Experiments for Sleep},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376584},
doi = {10.1145/3313831.3376584},
abstract = {Self-experiments allow people to explore what behavioral changes lead to improved health and wellness. However, it is challenging to run such experiments in a scientifically valid way that is also flexible and able to accommodate the realities of daily life. We present a set of design principles for guided self-experiments that aim to lower this barrier to self-experimentation. We demonstrate the value of the principles by implementing them in SleepBandits, an integrated system that includes a smartphone application for sleep experiments. SleepBandits guides users through the steps of a single-case experiment, automatically collecting data from the built-in sensors and user input and calculating and presenting results in real-time. We released SleepBandits to the Google Play Store and people voluntarily downloaded and used it. Based on the data from 365 active users from this in-the-wild study, we discuss opportunities and challenges with the design principles and the SleepBandits system.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {personal informatics, self-experiments, sleep tracking},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376800,
author = {Baig, Khadija and Mohamed, Reham and Theus, Anna-Lena and Chiasson, Sonia},
title = {"I'm Hoping They're an Ethical Company That Won't Do Anything That I'll Regret": Users Perceptions of At-Home DNA Testing Companies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376800},
doi = {10.1145/3313831.3376800},
abstract = {At-home DNA testing has become increasingly popular due to the ability to be able to gain both ancestry and health information, as well as connect with others who share your DNA. Do users have reasonable mental models of how these systems work? Do users have privacy concerns and what do they understand as the benefits and risks involved? We conducted 27 interviews with Canadian users of at-home DNA testing companies. Our interviews covered perceived and desired data use, data management, data sharing practices, control over data, and any regrets. Our qualitative analysis revealed that many users have inconsistencies in their mental models and liken their DNA data to their data stored with existing technologies, such as social media, rather than health data. They are generally either dismissive of privacy concerns towards themselves or their relatives or they had not considered privacy in their choice. We discuss our findings and propose possible future work in this area.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {interviews, at home DNA-testing, privacy},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376654,
author = {G\'{o}mez-Zar\'{a}, Diego and Guo, Mengzi and DeChurch, Leslie A. and Contractor, Noshir},
title = {The Impact of Displaying Diversity Information on the Formation of Self-Assembling Teams},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376654},
doi = {10.1145/3313831.3376654},
abstract = {Despite the benefits of team diversity, individuals often choose to work with similar others. Online team formation systems have the potential to help people assemble diverse teams. Systems can connect people to collaborators outside their networks, and features can quantify and raise the salience of diversity to users as they search for prospective teammates. But if we build a feature indicating diversity into the tool, how will people react to it? Two experiments manipulating the presence or absence of a "diversity score" feature within a teammate recommender demonstrate that, when present, individuals avoid collaborators who would increase team diversity in favor of those who lower team diversity. These results have important practical implications. Though the increased access to diverse teammates provided by recommender systems may benefit diversity, designers are cautioned against creating features that raise the salience of diversity as this information may undermine diversity.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {social recommenders, team formation, diversity, teams, mixed-effect logistic regressions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376804,
author = {Han, Han L. and Renom, Miguel A. and Mackay, Wendy E. and Beaudouin-Lafon, Michel},
title = {Textlets: Supporting Constraints and Consistency in Text Documents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376804},
doi = {10.1145/3313831.3376804},
abstract = {Writing technical documents frequently requires following constraints and consistently using domain-specific terms. We interviewed 12 legal professionals and found that they all use a standard word processor, but must rely on their memory to manage dependencies and maintain consistent vocabulary within their documents. We introduce Textlets, interactive objects that reify text selections into persistent items. We show how Textlets help manage consistency and constraints within the document, including selective search and replace, word count, and alternative wording. Eight participants tested a search-and-replace Textlet as a technology probe. All successfully interacted directly with the Textlet to perform advanced tasks; and most (6/8) spontaneously generated a novel replace-all-then-correct strategy. Participants suggested additional ideas, such as supporting collaborative editing over time by embedding a Textlet into the document to flag forbidden words. We argue that Textlets serve as a generative concept for creating powerful new tools for document editing.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {document processing, reification, text editing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376226,
author = {Weitekamp, Daniel and Harpstead, Erik and Koedinger, Ken R.},
title = {An Interaction Design for Machine Teaching to Develop AI Tutors},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376226},
doi = {10.1145/3313831.3376226},
abstract = {Intelligent tutoring systems (ITSs) have consistently been shown to improve the educational outcomes of students when used alone or combined with traditional instruction. However, building an ITS is a time-consuming process which requires specialized knowledge of existing tools. Extant authoring methods, including the Cognitive Tutor Authoring Tools' (CTAT) example-tracing method and SimStudent's Authoring by Tutoring, use programming-by-demonstration to allow authors to build ITSs more quickly than they could by hand programming with model-tracing. Yet these methods still suffer from long authoring times or difficulty creating complete models. In this study, we demonstrate that Simulated Learners built with the Apprentice Learner (AL) Framework can be combined with a novel interaction design that emphasizes model transparency, input flexibility, and problem solving control to enable authors to achieve greater model completeness in less time than existing authoring methods.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {simulated learners, intelligent tutoring systems, machine teaching, interaction design, programming-by-demonstration},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376382,
author = {Zhang, Tianyi and Hartmann, Bj\"{o}rn and Kim, Miryung and Glassman, Elena L.},
title = {Enabling Data-Driven API Design with Community Usage Data: A Need-Finding Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376382},
doi = {10.1145/3313831.3376382},
abstract = {APIs are becoming the fundamental building block of modern software and their usability is crucial to programming efficiency and software quality. Yet API designers find it hard to gather and interpret user feedback on their APIs. To close the gap, we interviewed 23 API designers from 6 companies and 11 open-source projects to understand their practices and needs. The primary way of gathering user feedback is through bug reports and peer reviews, as formal usability testing is prohibitively expensive to conduct in practice. Participants expressed a strong desire to gather real-world use cases and understand users' mental models, but there was a lack of tool support for such needs. In particular, participants were curious about where users got stuck, their workarounds, common mistakes, and unanticipated corner cases. We highlight several opportunities to address those unmet needs, including developing new mechanisms that systematically elicit users' mental models, building mining frameworks that identify recurring patterns beyond shallow statistics about API usage, and exploring alternative design choices made in similar libraries.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {information needs, tool support, community, api design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376565,
author = {Mostajeran, Fariba and Steinicke, Frank and Ariza Nunez, Oscar Javier and Gatsios, Dimitrios and Fotiadis, Dimitrios},
title = {Augmented Reality for Older Adults: Exploring Acceptability of Virtual Coaches for Home-Based Balance Training in an Aging Population},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376565},
doi = {10.1145/3313831.3376565},
abstract = {Balance training has been shown to be effective in reducing risks of falling, which is a major concern for older adults. Usually, exercise programs are individually prescribed and monitored by physiotherapeutic or medical experts. Unfortunately, supervision and motivation of older adults during home-based exercises cannot be provided on a large scale, in particular, considering an ageing population. Augmented reality (AR) in combination with virtual coaches could provide a reasonable solution to this challenge.We present a first investigation of the acceptance of an AR coaching system for balance training, which can be performed at home. In a human-centered design approach we developed several mock-ups and prototypes, and evaluated them with 76 older adults. The results suggest that older adults find the system encouraging and stimulating. The virtual coach is perceived as an alive, calm, intelligent, and friendly human. However, usability of the entire AR system showed a significant negative correlation with participants' age.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {older adults, augmented reality, balance training, health and well-being},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376609,
author = {Lee, Sung-Chul and Song, Jaeyoon and Ko, Eun-Young and Park, Seongho and Kim, Jihee and Kim, Juho},
title = {SolutionChat: Real-Time Moderator Support for Chat-Based Structured Discussion},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376609},
doi = {10.1145/3313831.3376609},
abstract = {Online chat is an emerging channel for discussing community problems. It is common practice for communities to assign dedicated moderators to maintain a structured discussion and enhance the problem-solving experience. However, due to the synchronous nature of online chat, moderators face a high managerial overhead in tasks like discussion stage management, opinion summarization, and consensus-building support. To assist moderators with facilitating a structured discussion for community problem-solving, we introduce SolutionChat, a system that (1) visualizes discussion stages and featured opinions and (2) recommends contextually appropriate moderator messages. Results from a controlled lab study (n=55, 12 groups) suggest that participants' perceived discussion trackability was significantly higher with SolutionChat than without. Also, moderators provided better summarization with less effort and better managerial support using system-generated messages with SolutionChat than without. With SolutionChat, we envision untrained moderators to effectively facilitate chat-based discussions of important community matters.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {structured discussion, computer mediated communication, moderator, online discussion},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376144,
author = {Putze, Susanne and Alexandrovsky, Dmitry and Putze, Felix and H\"{o}ffner, Sebastian and Smeddinck, Jan David and Malaka, Rainer},
title = {Breaking The Experience: Effects of Questionnaires in VR User Studies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376144},
doi = {10.1145/3313831.3376144},
abstract = {Questionnaires are among the most common research tools in virtual reality (VR) evaluations and user studies. However, transitioning from virtual worlds to the physical world to respond to VR experience questionnaires can potentially lead to systematic biases. Administering questionnaires in VR (inVRQs) is becoming more common in contemporary research. This is based on the intuitive notion that inVRQs may ease participation, reduce the Break in Presence (BIP) and avoid biases. In this paper, we perform a systematic investigation into the effects of interrupting the VR experience through questionnaires using physiological data as a continuous and objective measure of presence. In a user study (n=50), we evaluated question-asking procedures using a VR shooter with two different levels of immersion. The users rated their player experience with a questionnaire either inside or outside of VR. Our results indicate a reduced BIP for the employed inVRQ without affecting the self-reported player experience.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {invrqs, user studies, biosignals, research methods, virtual reality, break in presence, surveys, in-vr questionnaires, vr},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376857,
author = {Price, Thomas W. and Williams, Joseph Jay and Solyst, Jaemarie and Marwan, Samiha},
title = {Engaging Students with Instructor Solutions in Online Programming Homework},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376857},
doi = {10.1145/3313831.3376857},
abstract = {Students working on programming homework do not receive the same level of support as in the classroom, relying primarily on automated feedback from test cases. One low-effort way to provide more support is by prompting students to compare their solution to an instructor's solution, but it is unclear the best way to design such prompts to support learning. We designed and deployed a randomized controlled trial during online programming homework, where we provided students with an instructor's solution, and randomized whether they were prompted to compare their solution to the instructor's, to fill in the blanks for a written explanation of the instructor's solution, to do both, or neither. Our results suggest that these prompts can effectively engage students in reflecting on instructor solutions, although the results point to design trade-offs between the amount of effort that different prompts require from students and instructors, and their relative impact on learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {comparison, computing education, programming, self-explanation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376483,
author = {Lewis, Blaine and d'Eon, Greg and Cockburn, Andy and Vogel, Daniel},
title = {KeyMap: Improving Keyboard Shortcut Vocabulary Using Norman's Mapping},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376483},
doi = {10.1145/3313831.3376483},
abstract = {We introduce a new shortcut interface called KeyMap that is designed to leverage Norman's principle of natural mapping. Rather than displaying shortcut command labels in linear menus, KeyMap displays a virtual keyboard with command labels displayed directly on its keys. A crowdsourced experiment compares KeyMap to Malacria et al.'s ExposeHK using an extension of their protocol to also test recall. Results show KeyMap users remembered 1 more shortcut than ExposeHK immediately after training, and this advantage increased to 4.5 more shortcuts when tested again after 24 hours. KeyMap users also incidentally learned more shortcuts that they had never practised. We demonstrate how KeyMap can be added to existing web-based applications using a Chrome extension.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {keyboard shortcuts, interaction techniques, learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376232,
author = {Epstein, Ziv and Pennycook, Gordon and Rand, David},
title = {Will the Crowd Game the Algorithm? Using Layperson Judgments to Combat Misinformation on Social Media by Downranking Distrusted Sources},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376232},
doi = {10.1145/3313831.3376232},
abstract = {How can social media platforms fight the spread of misinformation? One possibility is to use newsfeed algorithms to downrank content from sources that users rate as untrustworthy. But will laypeople be handicapped by motivated reasoning or lack of expertise, and thus unable to identify misinformation sites? And will they "game" this crowdsourcing mechanism in order to promote content that aligns with their partisan agendas? We conducted a survey experiment in which =984 Americans indicated their trust in numerous news sites. To study the tendency of people to game the system, half of the participants were told their responses would inform social media ranking algorithms. Participants trusted mainstream sources much more than hyper-partisan or fake news sources, and their ratings were highly correlated with professional fact-checker judgments. Critically, informing participants that their responses would influence ranking algorithms did not diminish these results, despite the manipulation increasing the political polarization of trust ratings.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {social media, misinformation, crowdsourcing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376636,
author = {Sabie, Dina and Sabie, Samar and Ahmed, Syed Ishtiaque},
title = {Memory through Design: Supporting Cultural Identity for Immigrants through a Paper-Based Home Drafting Tool},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376636},
doi = {10.1145/3313831.3376636},
abstract = {Current research in HCI with immigrants predominantly focuses on their practical needs and little attention is given to their cultural identities. As such, we aim to understand how newcomers reflect their cultural values within domestic settings. We explore this by provoking memories immigrants associate with physical spaces inside their homes. Hence, we built "Our Home Sketcher": a paper-based home drafting tool that allows novice users to design their homes by sketching and implicitly expressing their space, light, and privacy preferences. The collected drawings are then fed into a computer algorithm that produces 3D models of the sketched houses. This process of design acts as an artifact-driven storytelling for heritage sharing and rapport building within migrant communities. We engage 13 Middle Eastern newcomers in Canada with the tool and use Halbwachs' [44] theory of collective memory to frame how home sketching provokes former experiences. Our findings show a strong longing for reclaiming the past, narrating space-related oral history, and designing beyond current limitations.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {house design, 2d sketching, hci, ictd, culture, memory, immigrants},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376168,
author = {Albakry, Sara and Vaniea, Kami and Wolters, Maria K.},
title = {What is This URL's Destination? Empirical Evaluation of Users' URL Reading},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376168},
doi = {10.1145/3313831.3376168},
abstract = {Common anti-phishing advice tells users to mouse over links, look at the URL, and compare to the expected destination, implicitly assuming that they are able to read the URL. To test this assumption, we conducted a survey with 1929 participants recruited from the Amazon Mechanical Turk and Prolific Academic platforms. Participants were shown 23 URLs with various URL structures. For each URL, participants were asked via a multiple choice question where the URL would lead and how safe they feel clicking on it would be. Using latent class analysis, participants were stratified by self-reported technology use. Participants were strongly biased towards answering that the URL would lead to the website of the organization whose name appeared in the URL, regardless of its position in the URL structure. The group with the highest technology use was only minorly better at URL reading.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {phishing, technology usage, link destination, uniform resource locators, online security, web literacy, url readability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376604,
author = {Lilija, Klemen and Pohl, Henning and Hornb\ae{}k, Kasper},
title = {Who Put That There? Temporal Navigation of Spatial Recordings by Direct Manipulation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376604},
doi = {10.1145/3313831.3376604},
abstract = {Spatial recordings allow viewers to move within them and freely choose their viewpoint. However, such recordings make it easy to miss events and difficult to follow moving objects when skipping through the recording. To alleviate these problems we present the Who Put That There system that allows users to navigate through time by directly manipulating objects in the scene. By selecting an object, the user can navigate to moments where the object changed. Users can also view trajectories of objects that changed location and directly manipulate them to navigate. We evaluated the system with a set of sensemaking questions in a think-aloud study. Participants understood the system and found it useful for finding events of interest, while being present and engaged in the recording.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {temporal navigation, virtual reality, spatial recordings, navigation techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376398,
author = {Lee, Kyungjun and Sato, Daisuke and Asakawa, Saki and Kacorri, Hernisa and Asakawa, Chieko},
title = {Pedestrian Detection with Wearable Cameras for the Blind: A Two-Way Perspective},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376398},
doi = {10.1145/3313831.3376398},
abstract = {Blind people have limited access to information about their surroundings, which is important for ensuring one's safety, managing social interactions, and identifying approaching pedestrians. With advances in computer vision, wearable cameras can provide equitable access to such information. However, the always-on nature of these assistive technologies poses privacy concerns for parties that may get recorded. We explore this tension from both perspectives, those of sighted passersby and blind users, taking into account camera visibility, in-person versus remote experience, and extracted visual information. We conduct two studies: an online survey with MTurkers (N=206) and an in-person experience study between pairs of blind (N=10) and sighted (N=40) participants, where blind participants wear a working prototype for pedestrian detection and pass by sighted participants. Our results suggest that both of the perspectives of users and bystanders and the several factors mentioned above need to be carefully considered to mitigate potential social tensions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pedestrian detection, crowdsourcing, face recognition, accessibility, social acceptance, wearable camera},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376260,
author = {Alexandrovsky, Dmitry and Putze, Susanne and Bonfert, Michael and H\"{o}ffner, Sebastian and Michelmann, Pitt and Wenig, Dirk and Malaka, Rainer and Smeddinck, Jan David},
title = {Examining Design Choices of Questionnaires in VR User Studies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376260},
doi = {10.1145/3313831.3376260},
abstract = {Questionnaires are among the most common research tools in virtual reality (VR) user studies. Transitioning from virtuality to reality for giving self-reports on VR experiences can lead to systematic biases. VR allows to embed questionnaires into the virtual environment which may ease participation and avoid biases. To provide a cohesive picture of methods and design choices for questionnaires in VR (inVRQ), we discuss 15 inVRQ studies from the literature and present a survey with 67 VR experts from academia and industry. Based on the outcomes, we conducted two user studies in which we tested different presentation and interaction methods of inVRQs and evaluated the usability and practicality of our design. We observed comparable completion times between inVRQs and questionnaires outside VR (nonVRQs) with higher enjoyment but lower usability for inVRQs. These findings advocate the application of inVRQs and provide an overview of methods and considerations that lay the groundwork for inVRQ design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–21},
numpages = {21},
keywords = {invrqs, user studies, in-vr questionnaires, research methods, vr, virtual reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376428,
author = {Hong, Jonggi and Lee, Kyungjun and Xu, June and Kacorri, Hernisa},
title = {Crowdsourcing the Perception of Machine Teaching},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376428},
doi = {10.1145/3313831.3376428},
abstract = {Teachable interfaces can empower end-users to attune machine learning systems to their idiosyncratic characteristics and environment by explicitly providing pertinent training examples. While facilitating control, their effectiveness can be hindered by the lack of expertise or misconceptions. We investigate how users may conceptualize, experience, and reflect on their engagement in machine teaching by deploying a mobile teachable testbed in Amazon Mechanical Turk. Using a performance-based payment scheme, Mechanical Turkers (N=100) are called to train, test, and re-train a robust recognition model in real-time with a few snapshots taken in their environment. We find that participants incorporate diversity in their examples drawing from parallels to how humans recognize objects independent of size, viewpoint, location, and illumination. Many of their misconceptions relate to consistency and model capabilities for reasoning. With limited variation and edge cases in testing, the majority of them do not change strategies on a second training attempt.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {object recognition, interactive machine learning, teachable interfaces, personalization, crowdsourcing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376687,
author = {Wentzel, Johann and d'Eon, Greg and Vogel, Daniel},
title = {Improving Virtual Reality Ergonomics Through Reach-Bounded Non-Linear Input Amplification},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376687},
doi = {10.1145/3313831.3376687},
abstract = {Input amplification enables easier movement in virtual reality (VR) for users with mobility issues or in confined spaces. However, current techniques either do not focus on maintaining feelings of body ownership, or are not applicable to general VR tasks. We investigate a general purpose non-linear transfer function that keeps the user's reach within reasonable bounds to maintain body ownership. The technique amplifies smaller movements from a user-definable neutral point into the expected larger movements using a configurable Hermite curve. Two experiments evaluate the approach. The first establishes that the technique has comparable performance to the state-of-the-art, increasing physical comfort while maintaining task performance and body ownership. The second explores the characteristics of the technique over a wide range of amplification levels. Using the combined results, design and implementation recommendations are provided with potential applications to related VR transfer functions.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {input re-mapping, interaction techniques, ergonomics},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376656,
author = {Uhde, Alarith and Schlicker, Nadine and Wallach, Dieter P. and Hassenzahl, Marc},
title = {Fairness and Decision-Making in Collaborative Shift Scheduling Systems},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376656},
doi = {10.1145/3313831.3376656},
abstract = {The strains associated with shift work decrease healthcare workers' well-being. However, shift schedules adapted to their individual needs can partially mitigate these problems. From a computing perspective, shift scheduling was so far mainly treated as an optimization problem with little attention given to the preferences, thoughts, and feelings of the healthcare workers involved. In the present study, we explore fairness as a central, human-oriented attribute of shift schedules as well as the scheduling process. Three in-depth qualitative interviews and a validating vignette study revealed that while on an abstract level healthcare workers agree on equality as the guiding norm for a fair schedule, specific scheduling conflicts should foremost be resolved by negotiating the importance of individual needs. We discuss elements of organizational fairness, including transparency and team spirit. Finally, we present a sketch for fair scheduling systems, summarizing key findings for designers in a readily usable way.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {healthcare, shift scheduling, allocation norms, roster, equality, need, work-life balance, hospital, shift work, fairness, conflict resolution, organizational justice, interview, equity, nurse scheduling problem},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376193,
author = {Poeller, Susanne and Baumann, Nicola and Mandryk, Regan L.},
title = {Power Play: How the Need to Empower or Overpower Other Players Predicts Preferences in League of Legends},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376193},
doi = {10.1145/3313831.3376193},
abstract = {The power motive describes our need to have an impact on others. Relevant in contexts such as sports, politics, and business, the power motive could help explain experiences and behaviours in digital games. We present four studies connecting the power motive to role and champion type choices in the MOBA game League of Legends (LoL). In Study1 we demonstrate that overall power motive does not predict role preferences. In Study2 we develop a 6-item-scale distinguishing between two facets of power in game settings: prosociality (empowering others) and dominance (overpowering others). In Study3 we show that prosociality and dominance uniquely predict role preferences for Support and Top Lane. In Study4 we demonstrate that champion type choice (tank, fighter, slayer, controller) is uniquely predicted by dominance and prosociality. We provide insight on how the wish for vertical interactions with other players-the power motive-can influence player interactions in multiplayer games.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {player types, player preferences, motive disposition theory, explicit motives, power motive, digital games},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376421,
author = {Lin, Ying-Ju and Punpongsanon, Parinya and Wen, Xin and Iwai, Daisuke and Sato, Kosuke and Obrist, Marianna and Mueller, Stefanie},
title = {FoodFab: Creating Food Perception Illusions Using Food 3D Printing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376421},
doi = {10.1145/3313831.3376421},
abstract = {Personalization of eating such that everyone consumes only what they need allows improving our management of food waste. In this paper, we explore the use of food 3D printing to create perceptual illusions for controlling the level of perceived satiety given a defined amount of calories. We present FoodFab, a system that allows users to control their food intake through modifying a food's internal structure via two 3D printing parameters: infill pattern and infill density. In two experiments with a total of 30 participants, we studied the effect of these parameters on users' chewing time that is known to affect people's feeling of satiety. Our results show that we can indeed modify the chewing time by varying infill pattern and density, and thus control perceived satiety. Based on the results, we propose two computational models and integrate them into a user interface that simplifies the creation of personalized food structures.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {food 3D printer, personal fabrication, food-interaction design, food perception, fabrication techniques},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376296,
author = {Henderson, Jay and Malacria, Sylvain and Nancel, Mathieu and Lank, Edward},
title = {Investigating the Necessity of Delay in Marking Menu Invocation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376296},
doi = {10.1145/3313831.3376296},
abstract = {Delayed display of menu items is a core design component of marking menus, arguably to prevent visual distraction and foster the use of mark mode. We investigate these assumptions, by contrasting the original marking menu design with immediately-displayed marking menus. In three controlled experiments, we fail to reveal obvious and systematic performance or usability advantages to using delay and mark mode. Only in very constrained settings – after significant training and only two items to learn – did traditional marking menus show a time improvement of about 260~ms. Otherwise, we found an overall decrease in performance with delay, whether participants exhibited practiced or unpracticed behaviour. Our final study failed to demonstrate that an immediately-displayed menu interface is more visually disrupting than a delayed menu. These findings inform the costs and benefits of incorporating delay in marking menus, and motivate guidelines for situations in which its use is desirable.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {marking menu, delay},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376882,
author = {Yeckehzaare, Iman and Barghi, Tirdad and Resnick, Paul},
title = {QMaps: Engaging Students in Voluntary Question Generation and Linking},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376882},
doi = {10.1145/3313831.3376882},
abstract = {Generating multiple-choice questions is known to improve students' critical thinking and deep learning. Visualizing relationships between concepts enhances meaningful learning, students' ability to relate new concepts to previously learned concepts. We designed and deployed a collaborative learning process through which students generate multiple-choice questions and represent the prerequisite knowledge structure between questions as visual links in a shared map, using a variation of Concept Maps that we call "QMap." We conducted a four-month study with 19 undergraduate students. Students sustained voluntary contributions, creating 992 good questions, and drawing 1,255 meaningful links between the questions. Through analyzing self-reports, observations, and usage data, we report on the technical and social design features that led students to sustain their motivation.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {intrinsic motivation, learnersourcing, collaborative learning, learner-centered design, cscl, question generation, concept mapping},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376818,
author = {Pine, Kathleen H. and Chen, Yunan},
title = {Right Information, Right Time, Right Place: Physical Alignment and Misalignment in Healthcare Practice},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376818},
doi = {10.1145/3313831.3376818},
abstract = {Implementation of new health information systems such as Electronic Health Records (EHR) is expected to reap many benefits. However, the transition from one information system to another is often associated with inefficiency, ineffectiveness, and patient safety hazards. These negative consequences are difficult to predict and avoid before system transitions take place. The changed physical form of information remains an unexamined facet of healthcare system transitions. Using ethnographic methods in two clinical sites, we discovered a recurrent set of problems that emerged due to physical disconnections between information and practice predicated on implementation of new information systems. "Physical misalignments" are instances where workers cannot bring information sources to hand in the precise time and place in which they are needed. We identify three types of physical misalignments, then discuss how physical misalignments can be proactively identified and corrected before, during, and after implementation of new health information systems.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {unintended consequences, electronic health records, ethnography, health information systems, implementation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376776,
author = {Alaimi, Mehdi and Law, Edith and Pantasdo, Kevin Daniel and Oudeyer, Pierre-Yves and Sauzeon, H\'{e}l\`{e}ne},
title = {Pedagogical Agents for Fostering Question-Asking Skills in Children},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376776},
doi = {10.1145/3313831.3376776},
abstract = {Question asking is an important tool for constructing academic knowledge, and a self-reinforcing driver of curiosity. However, research has found that question asking is infrequent in the classroom and children's questions are often superficial, lacking deep reasoning. In this work, we developed a pedagogical agent that encourages children to ask divergent-thinking questions, a more complex form of questions that is associated with curiosity. We conducted a study with 95 fifth grade students, who interacted with an agent that encourages either convergent-thinking or divergent-thinking questions. Results showed that both interventions increased the number of divergent-thinking questions and the fluency of question asking, while they did not significantly alter children's perception of curiosity despite their high intrinsic motivation scores. In addition, children's curiosity trait has a mediating effect on question asking under the divergent-thinking agent, suggesting that question-asking interventions must be personalized to each student based on their tendency to be curious.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {question-asking, educational application, epistemic curiosity, divergent vs convergent thinking, pedagogical agents},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376669,
author = {Haimson, Oliver L. and Gorrell, Dykee and Starks, Denny L. and Weinger, Zu},
title = {Designing Trans Technology: Defining Challenges and Envisioning Community-Centered Solutions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376669},
doi = {10.1145/3313831.3376669},
abstract = {Transgender and non-binary people face substantial challenges in the world, ranging from social inequities and discrimination to lack of access to resources. Though technology cannot fully solve these problems, technological solutions may help to address some of the challenges trans people and communities face. We conducted a series of participatory design sessions (total N = 21 participants) to understand trans people's most pressing challenges and to involve this population in the design process. We detail four types of technologies trans people envision: technologies for changing bodies, technologies for changing appearances / gender expressions, technologies for safety, and technologies for finding resources. We found that centering trans people in the design process enabled inclusive technology design that primarily focused on sharing community resources and prioritized connection between community members.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {non-binary, lgbtq+, transgender, safety, community, technology design, resources, participatory design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376202,
author = {Dogan, Mustafa Doga and Faruqi, Faraz and Churchill, Andrew Day and Friedman, Kenneth and Cheng, Leon and Subramanian, Sriram and Mueller, Stefanie},
title = {G-ID: Identifying 3D Prints Using Slicing Parameters},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376202},
doi = {10.1145/3313831.3376202},
abstract = {We present G-ID, a method that utilizes the subtle patterns left by the 3D printing process to distinguish and identify objects that otherwise look similar to the human eye. The key idea is to mark different instances of a 3D model by varying slicing parameters that do not change the model geometry but can be detected as machine-readable differences in the print. As a result, G-ID does not add anything to the object but exploits the patterns appearing as a by-product of slicing, an essential step of the 3D printing pipeline.We introduce the G-ID slicing and labeling interface that varies the settings for each instance, and the G-ID mobile app, which uses image processing techniques to retrieve the parameters and their associated labels from a photo of the 3D printed object. Finally, we evaluate our method's accuracy under different lighting conditions, when objects were printed with different filaments and printers, and with pictures taken from various positions and angles.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {making, 3d printing, personal fabrication, identification, tags},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376559,
author = {Masson, Damien and Malacria, Sylvain and Lank, Edward and Casiez, G\'{e}ry},
title = {Chameleon: Bringing Interactivity to Static Digital Documents},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376559},
doi = {10.1145/3313831.3376559},
abstract = {Documents such as presentations, instruction manuals, and research papers are disseminated using various file formats, many of which barely support the incorporation of interactive content. To address this lack of interactivity, we present Chameleon, a system-wide tool that combines computer vision algorithms used for image identification with an open database format to allow for the layering of dynamic content. Using Chameleon, static documents can be easily upgraded by layering user-generated interactive content on top of static images, all while preserving the original static document format and without modifying existing applications. We describe the development of Chameleon, including the design and evaluation of vision-based image replacement algorithms, the new document-creation pipeline as well as a user study evaluating Chameleon.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {augmented documents, feature matching, interactivity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376389,
author = {Colnago, Jessica and Feng, Yuanyuan and Palanivel, Tharangini and Pearman, Sarah and Ung, Megan and Acquisti, Alessandro and Cranor, Lorrie Faith and Sadeh, Norman},
title = {Informing the Design of a Personalized Privacy Assistant for the Internet of Things},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376389},
doi = {10.1145/3313831.3376389},
abstract = {Internet of Things (IoT) devices create new ways through which personal data is collected and processed by service providers. Frequently, end users have little awareness of, and even less control over, these devices' data collection. IoT Personalized Privacy Assistants (PPAs) can help overcome this issue by helping users discover and, when available, control the data collection practices of nearby IoT resources. We use semi-structured interviews with 17 participants to explore user perceptions of three increasingly more autonomous potential implementations of PPAs, identifying benefits and issues associated with each implementation. We find that participants weigh the desire for control against the fear of cognitive overload. We recommend solutions that address users' differing automation preferences and reduce notification overload. We discuss open issues related to opting out from public data collections, automated consent, the phenomenon of user resignation, and designing PPAs with at-risk communities in mind.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {inteviews, internet of things, personalized privacy assistants},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376285,
author = {Pilzer, Jan and Rosenast, Raphael and Meyer, Andr\'{e} N. and Huang, Elaine M. and Fritz, Thomas},
title = {Supporting Software Developers' Focused Work on Window-Based Desktops},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376285},
doi = {10.1145/3313831.3376285},
abstract = {Software developers, like other information workers, continuously switch tasks and applications to complete their work on their computer. Given the high fragmentation and complexity of their work, staying focused on the relevant pieces of information can become quite challenging in today's window-based environments, especially with the ever increasing monitor screen-size. To support developers in staying focused, we conducted a formative study with 18 professionals in which we examined their computer based and eye-gaze interaction with the window environment and devised a relevance model of open windows. Based on the results, we developed a prototype to dim irrelevant windows and reduce distractions, and evaluated it in a user study. Our results indicate that our model was able to predict relevant open windows with high accuracy and participants felt that integrating visual prominence into the desktop environment reduces clutter and distraction, which results in reduced window switching and an increase in focus.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {productivity, window relevance, user interfaces, window management, focus},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376539,
author = {Hauser, Sabrina and Suto, Melinda J. and Holsti, Liisa and Ranger, Manon and MacLean, Karon E.},
title = {Designing and Evaluating Calmer, a Device for Simulating Maternal Skin-to-Skin Holding for Premature Infants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376539},
doi = {10.1145/3313831.3376539},
abstract = {We describe the design and deployment of Calmer, a technology that simulates key aspects of maternal skin-to-skin holding for prematurely born infants: its inspiration, approach, physical design, and introduction into the Neonatal Intensive Care Unit. Maternal skin-to-skin holding can mitigate neonatal pain during medical procedures by as much as 50%, which can improve weight gain, sleep and later development. However, parents cannot always be present, and some infants are too fragile to be held. Interventions targeting this gap could be perceived as supplanting the mother in this intimate role, exposing her to depression and endangering her maternal bond. Over 10 years, we iteratively developed Calmer and demonstrated infant health benefit in a randomized clinical trial. Here, we report and reflect on pursuing this goal in a socially and technologically complex context: constraints, strategies, features, reception of the device, and surprises, such as leading to mothers feeling channeled rather than replaced.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {pain reduction, neonatal intensive care, research through design, parents, premature infants, automation, nicu},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376853,
author = {Kulp, Leah and Sarcevic, Aleksandra and Zheng, Yinan and Cheng, Megan and Alberto, Emily and Burd, Randall},
title = {Checklist Design Reconsidered: Understanding Checklist Compliance and Timing of Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376853},
doi = {10.1145/3313831.3376853},
abstract = {We examine the association between user interactions with a checklist and task performance in a time-critical medical setting. By comparing 98 logs from a digital checklist for trauma resuscitation with activity logs generated by video review, we identified three non-compliant checklist use behaviors: failure to check items for completed tasks, falsely checking items when tasks were not performed, and inaccurately checking items for incomplete tasks. Using video review, we found that user perceptions of task completion were often misaligned with clinical practices that guided activity coding, thereby contributing to non-compliant check-offs. Our analysis of associations between different contexts and the timing of check-offs showed longer delays when (1) checklist users were absent during patient arrival, (2) patients had penetrating injuries, and (3) resuscitations were assigned to the highest acuity. We discuss opportunities for reconsidering checklist designs to reduce non-compliant checklist use.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {video review, mixed methods, checklist design, trauma resuscitation, medical checklist, dynamic checklist},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376735,
author = {Kim, Sunjun and Lee, Byungjoo and van Gemert, Thomas and Oulasvirta, Antti},
title = {Optimal Sensor Position for a Computer Mouse},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376735},
doi = {10.1145/3313831.3376735},
abstract = {Computer mice have their displacement sensors in various locations (center, front, and rear). However, there has been little research into the effects of sensor position or on engineering approaches to exploit it. This paper first discusses the mechanisms via which sensor position affects mouse movement and reports the results from a study of a pointing task in which the sensor position was systematically varied. Placing the sensor in the center turned out to be the best compromise: improvements over front and rear were in the 11-14% range for throughput and 20--23% for path deviation. However, users varied in their personal optima. Accordingly, variable-sensor-position mice are then presented, with a demonstration that high accuracy can be achieved with two static optical sensors. A virtual sensor model is described that allows software-side repositioning of the sensor. Individual-specific calibration should yield an added 4% improvement in throughput over the default center position.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {pointing performance, computer, optimization, mouse, virtual sensor position, sensor position},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376616,
author = {Luo, Yuhan and Lee, Bongshin and Choe, Eun Kyoung},
title = {TandemTrack: Shaping Consistent Exercise Experience by Complementing a Mobile App with a Smart Speaker},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376616},
doi = {10.1145/3313831.3376616},
abstract = {Smart speakers such as Amazon Echo present promising opportunities for exploring voice interaction in the domain of in-home exercise tracking. In this work, we examine if and how voice interaction complements and augments a mobile app in promoting consistent exercise. We designed and developed TandemTrack, which combines a mobile app and an Alexa skill to support exercise regimen, data capture, feedback, and reminder. We then conducted a four-week between-subjects study deploying TandemTrack to 22 participants who were instructed to follow a short daily exercise regimen: one group used only the mobile app and the other group used both the app and the skill. We collected rich data on individuals' exercise adherence and performance, and their use of voice and visual interactions, while examining how TandemTrack as a whole influenced their exercise experience. Reflecting on these data, we discuss the benefits and challenges of incorporating voice interaction to assist daily exercise, and implications for designing effective multimodal systems to support self-tracking and promote consistent exercise.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multimodal interaction, mobile app, smart speaker, field deployment study, self-tracking, exercise},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376336,
author = {Huang, Jin and Tian, Feng and Fan, Xiangmin and Tu, Huawei and Zhang, Hao and Peng, Xiaolan and Wang, Hongan},
title = {Modeling the Endpoint Uncertainty in Crossing-Based Moving Target Selection},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376336},
doi = {10.1145/3313831.3376336},
abstract = {Modeling the endpoint uncertainty of moving target selection with crossing is essential to understand factors such as speed-accuracy trade-off and interaction efficiency in crossing-based user interfaces with dynamic contents. However, there have been few studies looking into this research topic in the HCI field. This paper presents a Quaternary-Gaussian model to quantitatively measure the endpoint uncertainty in crossing-based moving target selection. To validate this model, we conducted an experiment with discrete crossing tasks on five factors, i.e., initial distance, size, speed, orientation, and moving direction. Results showed that our model fit the data of μ and σ accurately with adjusted R2 of 0.883 and 0.920. We also demonstrated the validity of our model in predicting error rates in crossing-based moving target selection. We concluded with a set of implications for future designs.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {error rate, endpoint distribution, crossing-based selection, moving target selection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376276,
author = {Madaio, Michael A. and Yarzebinski, Evelyn and Kamath, Vikram and Zinszer, Benjamin D. and Hannon-Cropp, Joelle and Tanoh, Fabrice and Akpe, Yapo Hermann and Seri, Axel Blahoua and Jasi\'{n}ska, Kaja K. and Ogan, Amy},
title = {Collective Support and Independent Learning with a Voice-Based Literacy Technology in Rural Communities},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376276},
doi = {10.1145/3313831.3376276},
abstract = {Access to literacy is critical to children's futures, but formal education may be insufficient for fostering early literacy, especially in low-resource contexts. Educational technologies used at home may be able to help, but it is unclear whether or how children (and families) will use such technologies at home in rural communities, particularly in low-literate families. In this paper, we investigate these questions with a voice-based literacy technology deployed with families in 8 rural communities in C\^{o}te d'Ivoire for 4 months. We use interviews and observations with 37 families to investigate motivations, methods, and barriers for rural families' engagement with a literacy technology accessible via feature phones. We contribute insights into how families view digital literacy as a learning goal, leverage networks of supporters, and over time, transition from explicit to implicit support for children's learning.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {educational technology, literacy, ictd, ivr, hci4d},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376134,
author = {Kianzad, Soheil and Huang, Yuxiang and Xiao, Robert and MacLean, Karon E.},
title = {Phasking on Paper: Accessing a Continuum of PHysically Assisted SKetchING},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376134},
doi = {10.1145/3313831.3376134},
abstract = {When sketching, we must choose between paper (expressive ease, ruler and eraser) and computational assistance (parametric support, a digital record). PHysically Assisted SKetching provides both, with a pen that displays force constraints with which the sketcher interacts as they draw on paper. Phasking provides passive, "bound" constraints (like a ruler); or actively "brings" the sketcher along a commanded path (e.g., a curve), which they can violate for creative variation. The sketcher modulates constraint strength (control sharing) by bearing down on the pen-tip. Phasking requires untethered, graded force-feedback, achieved by modifying a ballpoint drive that generates force through rolling surface contact. To understand phasking's viability, we implemented its interaction concepts, related them to sketching tasks and measured device performance. We assessed the experience of 10 sketchers, who could understand, use and delight in phasking, and who valued its control-sharing and digital twinning for productivity, creative control and learning to draw.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {haptics, stylus interaction, sketching, force-feedback, computer aided drawing, shared control drawing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376289,
author = {Mohr, Peter and Mori, Shohei and Langlotz, Tobias and Thomas, Bruce H. and Schmalstieg, Dieter and Kalkofen, Denis},
title = {Mixed Reality Light Fields for Interactive Remote Assistance},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376289},
doi = {10.1145/3313831.3376289},
abstract = {Remote assistance represents an important use case for mixed reality. With the rise of handheld and wearable devices, remote assistance has become practical in the wild. However, spontaneous provisioning of remote assistance requires an easy, fast and robust approach for capturing and sharing of unprepared environments. In this work, we make a case for utilizing interactive light fields for remote assistance. We demonstrate the advantages of object representation using light fields over conventional geometric reconstruction. Moreover, we introduce an interaction method for quickly annotating light fields in 3D space without requiring surface geometry to anchor annotations. We present results from a user study demonstrating the effectiveness of our interaction techniques, and we provide feedback on the usability of our overall system.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {mixed reality, annotations, telepresence, 3d user interfaces, augmented reality, light field, remote assistance, interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376772,
author = {Elkin, Lisa A. and Beau, Jean-Baptiste and Casiez, G\'{e}ry and Vogel, Daniel},
title = {Manipulation, Learning, and Recall with Tangible Pen-Like Input},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376772},
doi = {10.1145/3313831.3376772},
abstract = {We examine two key human performance characteristics of a pen-like tangible input device that executes a different command depending on which corner, edge, or side contacts a surface. The manipulation time when transitioning between contacts is examined using physical mock-ups of three representative device sizes and a baseline pen mock-up. Results show the largest device is fastest overall and minimal differences with a pen for equivalent transitions. Using a hardware prototype able to sense all 26 different contacts, a second experiment evaluates learning and recall. Results show almost all 26 contacts can be learned in a two-hour session with an average of 94% recall after 24 hours. The results provide empirical evidence for the practicality, design, and utility for this type of tangible pen-like input.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {pen input, tangible interfaces, learning, command selection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376374,
author = {Jiang, Xinlong and Chen, Yiqiang and Huang, Wuliang and Zhang, Teng and Gao, Chenlong and Xing, Yunbing and Zheng, Yi},
title = {WeDA: Designing and Evaluating A Scale-Driven Wearable Diagnostic Assessment System for Children with ADHD},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376374},
doi = {10.1145/3313831.3376374},
abstract = {Attention Deficit Hyperactivity Disorder (ADHD) is one of the most common mental disorders affecting children. Because the etiology of ADHD is complex and its symptoms are not specific, there is a lack of feasible quantitative diagnostic methods. Pursuing objective and non-invasive detection methods and standards is of great practical significance to prevent the development of the disease. In this study, we aim to address one specific concern about the objectivity and quantification of ADHD diagnosis. Over a year, we iteratively designed and tested WeDA, a scale-driven wearable diagnostic assessment system. This system contains an Android computer machine with a large touchscreen, a suite of 3D printed interactive devices, and six wearable motion sensors. We implement ten diagnostic tasks drawing on the symptoms of ADHD based on DSM-5. The experimental results of classifying children with ADHD and typically developing children and subjective evaluations from doctors, parents, and children validate the effectiveness and acceptability of WeDA.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {scale-driven, neurodevelopmental disorder, attention deficit hyperactivity disorder (adhd), wearable computing, diagnostic assessment},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376139,
author = {Gupta, Aakar and Lin, Bo Rui and Ji, Siyi and Patel, Arjav and Vogel, Daniel},
title = {Replicate and Reuse: Tangible Interaction Design for Digitally-Augmented Physical Media Objects},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376139},
doi = {10.1145/3313831.3376139},
abstract = {Technology has transformed our physical interactions into infinitely more scalable and flexible digital ones. We can peruse an infinite number of photos, news articles, and books. However, these digital experiences lack the physical experience of paging through an album, reading a newspaper, or meandering through a bookshelf. Overlaying physical objects with digital content using augmented reality is a promising avenue towards bridging this gap. In this paper, we investigate the interaction design for such digital-overlaid physical objects and their varying levels of tangibility. We first conduct a user evaluation of a physical photo album that uses tangible interactions to support physical and digital operations. We further prototype multiple objects including bookshelves and newspapers and probe users on their usage, capabilities, and interactions. We then conduct a qualitative investigation of three interaction designs with varying tangibility that use three different input modalities. Finally, we discuss the insights from our investigations and recommend design guidelines.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {design, tangible interaction, physical objects, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376200,
author = {Matthews, Ben and Salisbury, Isaac and Schlosser, Paul and Smith, Francine and Sanderson, Penelope},
title = {High Tempo Work: Design Challenges for Head-Worn Displays in Quick Service Restaurants},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376200},
doi = {10.1145/3313831.3376200},
abstract = {Quick service restaurants (QSRs) are high tempo work environments that require collaboration and communication between crew. In a number of respects, head-worn displays (HWDs) might seem a promising technology to support QSR crew, but on close inspection they raise challenging issues for design. We conducted fieldwork studies at two large QSRs to understand how work is organised, how existing systems are used, and how information is displayed to and communicated between crew. We observed the crew working both routinely and with improvisation, collaboratively and individually, physically and digitally. From our analysis of the field study, we identify tentative use cases for HWDs, but with these also design tensions-that is, opportunities coupled with challenges that appear difficult to circumvent even with modest design proposals. These tensions would require careful consideration if HWDs were to be deployed in in QSRs, given that HWDs are ubiquitous, potentially private, digital, mobile, and able to collect behavioural data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {head-worn display (hwd), smart glasses, design tensions, quick service restaurant, fast food, fieldwork},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376361,
author = {Sas, Corina and Davies, Nigel and Clinch, Sarah and Shaw, Peter and Mikusz, Mateusz and Steeds, Madeleine and Nohrer, Lukas},
title = {Supporting Stimulation Needs in Dementia Care through Wall-Sized Displays},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376361},
doi = {10.1145/3313831.3376361},
abstract = {Beside reminiscing, the increasing cognitive decline in dementia can also be addressed through sensory stimulation allowing the immediate, nonverbal engagement with the world through one's senses. Much HCI work has prioritized cognitive stimulation for reminiscing or personhood often on small screens, while less research has explored sensory stimulation like the one enabled by large displays. We describe a year-long deployment in a residential care home of a wall-sized display, and explored its domestication through 24 contextual interviews. Findings indicate strong engagement and attachment to the display which has inspired four psychosocial interventions using online generic content. We discuss the value of these findings for personhood through residents' exercise of choices, the tension between generic/personal content and its public/private use, the importance of participatory research approach to domestication, and the infrastructure-based prototype, illustrated by the DementiaWall and its generative quality.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–16},
numpages = {16},
keywords = {memory technologies, wall-sized displays, dementia, reminiscing, stimulation, psychosocial informal interventions},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376218,
author = {Wang, Wenting and Arya, Deeksha and Novielli, Nicole and Cheng, Jinghui and Guo, Jin L.C.},
title = {ArguLens: Anatomy of Community Opinions On Usability Issues Using Argumentation Models},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376218},
doi = {10.1145/3313831.3376218},
abstract = {In open-source software (OSS), the design of usability is often influenced by the discussions among community members on platforms such as issue tracking systems (ITSs). However, digesting the rich information embedded in issue discussions can be a major challenge due to the vast number and diversity of the comments. We propose and evaluate ArguLens, a conceptual framework and automated technique leveraging an argumentation model to support effective understanding and consolidation of community opinions in ITSs. Through content analysis, we anatomized highly discussed usability issues from a large, active OSS project, into their argumentation components and standpoints. We then experimented with supervised machine learning techniques for automated argument extraction. Finally, through a study with experienced ITS users, we show that the information provided by ArguLens supported the digestion of usability-related opinions and facilitated the review of lengthy issues. ArguLens provides the direction of designing valuable tools for high-level reasoning and effective discussion about usability.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {issue discussion analysis, argumentation analysis, online communities, open source software, usability},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376537,
author = {Draxler, Fiona and Labrie, Audrey and Schmidt, Albrecht and Chuang, Lewis L.},
title = {Augmented Reality to Enable Users in Learning Case Grammar from Their Real-World Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376537},
doi = {10.1145/3313831.3376537},
abstract = {Augmented Reality (AR) provides a unique opportunity to situate learning content in one's environment. In this work, we investigated how AR could be developed to provide an interactive context-based language learning experience. Specifically, we developed a novel handheld-AR app for learning case grammar by dynamically creating quizzes, based on real-life objects in the learner's surroundings. We compared this to the experience of learning with a non-contextual app that presented the same quizzes with static photographic images. Participants found AR suitable for use in their everyday lives and enjoyed the interactive experience of exploring grammatical relationships in their surroundings. Nonetheless, Bayesian tests provide substantial evidence that the interactive and context-embedded AR app did not improve case grammar skills, vocabulary retention, and usability over the experience with equivalent static images. Based on this, we propose how language learning apps could be designed to combine the benefits of contextual AR and traditional approaches.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {contextual learning, language learning, self-directed learning, grammar, augmented reality},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376319,
author = {Wehbe, Rina R. and Dickson, Terence and Kuzminykh, Anastasia and Nacke, Lennart E. and Lank, Edward},
title = {Personal Space in Play: Physical and Digital Boundaries in Large-Display Cooperative and Competitive Games},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376319},
doi = {10.1145/3313831.3376319},
abstract = {As multi-touch displays grow in size and shrink in price, they are more commonly used as gaming devices. When co-located users play games on a single, large display, establishing and maintaining their physical and digital territories poses a social challenge to their interaction. To gain insight into the mechanisms of establishing and maintaining users' physical and digital territories, we analyze territorial interactions in cooperative and competitive multiplayer gameplay. Participants reported weighing each game interaction based on perceived intent to determine how socially acceptable they deemed each behaviour. In light of our observations, we contribute and discuss implications for the design of multi-user, large display, co-located, touchscreen games that consider display properties, digital and physical space, permeability of boundaries, and asymmetry of play to create interactions between players.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {shared spaces, large displays, digital territory, physical territory, collaboration and group work, games and entertainment software, loosely-coupled interaction},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376204,
author = {Vanderheiden, Gregg and Lazar, Jonathan and Jordan, J. Bern and Ding, Yao and Wood, Rachel E.},
title = {Morphic: Auto-Personalization on a Global Scale},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376204},
doi = {10.1145/3313831.3376204},
abstract = {Users frequently have trouble finding and changing technology settings, even when adjusting those settings to personalize their technology devices may significantly improve their user experience. This paper describes the Morphic project, a cloud-based auto-personalization tool. Primarily designed for improving accessibility, the auto-personalization in Morphic may also help a broader audience. This paper describes: 1) the technical infrastructure needed to support cloud-based auto-personalization, 2) the interaction design approaches necessary to support users during the personalization of their settings, and 3) which settings and modifications have been most frequently used. This paper presents the evolution of the Morphic project, the building of the infrastructure, the formative evaluation of various interaction design approaches (NFC cards, physical keypads, on-screen buttons, and menus), and implications for researchers and developers. It also includes preliminary findings from six technology probes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {universal usability, screen reader, users with disabilities, auto-personalization, public computing, shared devices, internationalization, accessibility, screen magnification},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376298,
author = {Reynolds, Joshua and Kumar, Deepak and Ma, Zane and Subramanian, Rohan and Wu, Meishan and Shelton, Martin and Mason, Joshua and Stark, Emily and Bailey, Michael},
title = {Measuring Identity Confusion with Uniform Resource Locators},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376298},
doi = {10.1145/3313831.3376298},
abstract = {Uniform Resource Locators (URLs) unambiguously specify host identity on the web. URLs are syntactically complex, and although software can accurately parse identity from URLs, users are frequently exposed to URLs and expected to do the same. Unfortunately, incorrect assessment of identity from a URL can expose users to attacks, such as typosquatting and phishing. Our work studies how well users can correctly determine the host identity of real URLs from common services and obfuscated "look-alike" URLs. We observe that participants employ a wide range of URL parsing strategies, and can identify real URLs 93% of time. However, only 40% of obfuscated URLs were identified correctly. These mistakes highlighted several ways in which URLs were confusing to users and why their existing URL parsing strategies fall short. We conclude with future research directions for reliably conveying website identity to users.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {server identity, url, usable security, authentication, url readability, phishing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376611,
author = {Jeong, Rebecca and Chiasson, Sonia},
title = { 'Lime', 'Open Lock', and 'Blocked': Children's Perception of Colors, Symbols, and Words in Cybersecurity Warnings},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376611},
doi = {10.1145/3313831.3376611},
abstract = {Cybersecurity warnings are frequently ignored or misinterpreted by even experienced adults. While studies have been conducted to examine warning design for adults, there is little data to establish recommendations for children. We conducted user studies with 22 children (ages 10-12) and with 22 adults. We compare their risk perception of warning design parameters (signal colors, symbols, words) via card sorting and ranking activities followed by interviews. While our findings suggest similarities in how both groups interpret the design parameters (e.g., red, skull, and fatal convey danger), we also uncovered potential concerns with items currently used as security indicators (e.g., both groups had mixed interpretations of the open lock and police officer symbols). Individual risk perception, particularly for children, appears dependent on personal preferences and experience. Our findings suggest implications and future research directions for the design of cybersecurity warnings for children.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {children, cybersecurity warnings, risk perception},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376812,
author = {Tennent, Paul and Marshall, Joe and Tsaknaki, Vasiliki and Windlin, Charles and H\"{o}\"{o}k, Kristina and Alfaras, Miquel},
title = {Soma Design and Sensory Misalignment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376812},
doi = {10.1145/3313831.3376812},
abstract = {We report on a workshop bringing together researchers working in soma design and sensory misalignment. Creating experiences that make use of sensory misalignment has become increasingly common, often associated with virtual reality research. However, little attention has been paid to how to design such experiences. We argue that the practice of soma design is a relevant candidate method for designing misalignment experiences, since soma design brings with it concepts such as estrangement and disrupting the habitual as a path to design. We further argue that sensory misalignment may in turn extend soma design methods, adding methods for explicitly disrupting sensory perception using technology interventions. Finally, we draw on the findings of that workshop to discuss the ideas of: pluralism in experience; orchestration of overall experience; as well as the broader intersection of soma design and sensory misalignment approaches.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {sensory misalignment, soma design, bodily sensation},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376412,
author = {Burnell, Edward and Damen, Nicole B. and Hoburg, Warren},
title = {GPkit: A Human-Centered Approach to Convex Optimization in Engineering Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376412},
doi = {10.1145/3313831.3376412},
abstract = {We present GPkit, a Python toolkit for Geometric and Signomial Programming that prioritizes explainability and incremental complexity. GPkit was designed through an ethnographic approach in the firms, classrooms, and research labs where it became part of the fabric of daily engineering work. Organizations have approached GPkit both in ways which centralize and in ways which distribute design work, usecases which emerged from and inspired new toolkit features. This two-way flow between mathematical structure and practitioner knowledge resulted in several novel contributions to the formulation and interpretation of convex programs and to our understanding of early-stage engineering design. For example, dual solutions (often considered incidental) can be more valuable to a design process than the "optimal design" itself, and we present novel algorithms and design methods based on this insight.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {toolkits, human-centered design, modeling languages, convex optimization, design models, geometric programming},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376321,
author = {Nouwens, Midas and Liccardi, Ilaria and Veale, Michael and Karger, David and Kagal, Lalana},
title = {Dark Patterns after the GDPR: Scraping Consent Pop-Ups and Demonstrating Their Influence},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376321},
doi = {10.1145/3313831.3376321},
abstract = {New consent management platforms (CMPs) have been introduced to the web to conform with the EU's General Data Protection Regulation, particularly its requirements for consent when companies collect and process users' personal data. This work analyses how the most prevalent CMP designs affect people's consent choices. We scraped the designs of the five most popular CMPs on the top 10,000 websites in the UK (n=680). We found that dark patterns and implied consent are ubiquitous; only 11.8% meet our minimal requirements based on European law. Second, we conducted a field experiment with 40 participants to investigate how the eight most common designs affect consent choices. We found that notification style (banner or barrier) has no effect; removing the opt-out button from the first page increases consent by 22-23 percentage points; and providing more granular controls on the first page decreases consent by 8-20 percentage points. This study provides an empirical basis for the necessary regulatory action to enforce the GDPR, in particular the possibility of focusing on the centralised, third-party CMP services as an effective way to increase compliance.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {notice and consent, gdpr, dark patterns, controlled experiment, consent management platforms, web scraper},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376399,
author = {Miranda, Fabio and Hosseini, Maryam and Lage, Marcos and Doraiswamy, Harish and Dove, Graham and Silva, Cl\'{a}udio T.},
title = {Urban Mosaic: Visual Exploration of Streetscapes Using Large-Scale Image Data},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376399},
doi = {10.1145/3313831.3376399},
abstract = {Urban planning is increasingly data driven, yet the challenge of designing with data at a city scale and remaining sensitive to the impact at a human scale is as important today as it was for Jane Jacobs. We address this challenge with Urban Mosaic, a tool for exploring the urban fabric through a spatially and temporally dense data set of 7.7 million street-level images from New York City, captured over the period of a year. Working in collaboration with professional practitioners, we use Urban Mosaic to investigate questions of accessibility and mobility, and preservation and retrofitting. In doing so, we demonstrate how tools such as this might provide a bridge between the city and the street, by supporting activities such as visual comparison of geographically distant neighborhoods, and temporal analysis of unfolding urban development.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {urban data, urban planning, data analysis, interactive visualization},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376242,
author = {Mueller, Florian Floyd and Lopes, Pedro and Strohmeier, Paul and Ju, Wendy and Seim, Caitlyn and Weigel, Martin and Nanayakkara, Suranga and Obrist, Marianna and Li, Zhuying and Delfa, Joseph and Nishida, Jun and Gerber, Elizabeth M. and Svanaes, Dag and Grudin, Jonathan and Greuter, Stefan and Kunze, Kai and Erickson, Thomas and Greenspan, Steven and Inami, Masahiko and Marshall, Joe and Reiterer, Harald and Wolf, Katrin and Meyer, Jochen and Schiphorst, Thecla and Wang, Dakuo and Maes, Pattie},
title = {Next Steps for Human-Computer Integration},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376242},
doi = {10.1145/3313831.3376242},
abstract = {Human-Computer Integration (HInt) is an emerging paradigm in which computational and human systems are closely interwoven. Integrating computers with the human body is not new. however, we believe that with rapid technological advancements, increasing real-world deployments, and growing ethical and societal implications, it is critical to identify an agenda for future research. We present a set of challenges for HInt research, formulated over the course of a five-day workshop consisting of 29 experts who have designed, deployed and studied HInt systems. This agenda aims to guide researchers in a structured way towards a more coordinated and conscientious future of human-computer integration.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {integration, augmentation, implants, fusion, bodily extension, cyborg, symbiosis},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376711,
author = {Jiang, Xinhui and Li, Yang and Jokinen, Jussi P.P. and Hirvola, Viet Ba and Oulasvirta, Antti and Ren, Xiangshi},
title = {How We Type: Eye and Finger Movement Strategies in Mobile Typing},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376711},
doi = {10.1145/3313831.3376711},
abstract = {Relatively little is known about eye and finger movement in typing with mobile devices. Most prior studies of mobile typing rely on log data, while data on finger and eye movements in typing come from studies with physical keyboards. This paper presents new findings from a transcription task with mobile touchscreen devices. Movement strategies were found to emerge in response to sharing of visual attention: attention is needed for guiding finger movements and detecting typing errors. In contrast to typing on physical keyboards, visual attention is kept mostly on the virtual keyboard, and glances at the text display are associated with performance. When typing with two fingers, although users make more errors, they manage to detect and correct them more quickly. This explains part of the known superiority of two-thumb typing over one-finger typing. We release the extensive dataset on everyday typing on smartphones.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {mobile device, eye movement, finger movement, text input, eye-hand coordination},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376220,
author = {Klamka, Konstantin and Dachselt, Raimund and Steimle, J\"{u}rgen},
title = {Rapid Iron-On User Interfaces: Hands-on Fabrication of Interactive Textile Prototypes},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376220},
doi = {10.1145/3313831.3376220},
abstract = {Rapid prototyping of interactive textiles is still challenging, since manual skills, several processing steps, and expert knowledge are involved. We present Rapid Iron-On User Interfaces, a novel fabrication approach for empowering designers and makers to enhance fabrics with interactive functionalities. It builds on heat-activated adhesive materials consisting of smart textiles and printed electronics, which can be flexibly ironed onto the fabric to create custom interface functionality. To support rapid fabrication in a sketching-like fashion, we developed a handheld dispenser tool for directly applying continuous functional tapes of desired length as well as discrete patches. We introduce versatile compositions techniques that allow for creating complex circuits, utilizing commodity textile accessories and sketching custom-shaped I/O modules. We further contribute a comprehensive library of components for input, output, wiring and computing. Three example applications, results from technical experiments and expert reviews demonstrate the functionality, versatility and potential of this approach.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {e-textile, prototyping, fabrication, wearable ui, iron-on},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376366,
author = {Nittala, Aditya Shekhar and Khan, Arshad and Kruttwig, Klaus and Kraus, Tobias and Steimle, J\"{u}rgen},
title = {PhysioSkin: Rapid Fabrication of Skin-Conformal Physiological Interfaces},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376366},
doi = {10.1145/3313831.3376366},
abstract = {Advances in rapid prototyping platforms have made physiological sensing accessible to a wide audience. However, off-the-shelf electrodes commonly used for capturing biosignals are typically thick, non-conformal and do not support customization. We present PhysioSkin, a rapid, do-it-yourself prototyping method for fabricating custom multi-modal physiological sensors, using commercial materials and a commodity desktop inkjet printer. It realizes ultrathin skin-conformal patches (~1μm) and interactive textiles that capture sEMG, EDA and ECG signals. It further supports fabricating devices with custom levels of thickness and stretchability. We present detailed fabrication explorations on multiple substrate materials, functional inks and skin adhesive materials. Informed from the literature, we also provide design recommendations for each of the modalities. Evaluation results show that the sensor patches achieve a high signal-to-noise ratio. Example applications demonstrate the functionality and versatility of our approach for prototyping a next generation of physiological devices that intimately couple with the human body.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {wearable devices, rapid prototyping, physiological sensing, electronic skin, fabrication, ink-jet printing, e-textile},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376449,
author = {B\^{a}ce, Mihai and Staal, Sander and Bulling, Andreas},
title = {Quantification of Users' Visual Attention During Everyday Mobile Device Interactions},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376449},
doi = {10.1145/3313831.3376449},
abstract = {We present the first real-world dataset and quantitative evaluation of visual attention of mobile device users in-situ, i.e. while using their devices during everyday routine. Understanding user attention is a core research challenge in mobile HCI but previous approaches relied on usage logs or self-reports that are only proxies and consequently do neither reflect attention completely nor accurately. Our evaluations are based on Everyday Mobile Visual Attention (EMVA) – a new 32-participant dataset containing around 472 hours of video snippets recorded over more than two weeks in real life using the front-facing camera as well as associated usage logs, interaction events, and sensor data. Using an eye contact detection method, we are first to quantify the highly dynamic nature of everyday visual attention across users, mobile applications, and usage contexts. We discuss key insights from our analyses that highlight the potential and inform the design of future mobile attentive user interfaces.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {in-the-wild study, visual attention, eye contact detection, attentive user interfaces, mobile devices},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376553,
author = {Dayama, Niraj Ramesh and Todi, Kashyap and Saarelainen, Taru and Oulasvirta, Antti},
title = {GRIDS: Interactive Layout Design with Integer Programming},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376553},
doi = {10.1145/3313831.3376553},
abstract = {Grid layouts are used by designers to spatially organise user interfaces when sketching and wireframing. However, their design is largely time consuming manual work. This is challenging due to combinatorial explosion and complex objectives, such as alignment, balance, and expectations regarding positions. This paper proposes a novel optimisation approach for the generation of diverse grid-based layouts. Our mixed integer linear programming (MILP) model offers a rigorous yet efficient method for grid generation that ensures packing, alignment, grouping, and preferential positioning of elements. Further, we present techniques for interactive diversification, enhancement, and completion of grid layouts. These capabilities are demonstrated using GRIDS, a wireframing tool that provides designers with real-time layout suggestions. We report findings from a ratings study (N = 13) and a design study (N = 16), lending evidence for the benefit of computational grid generation during early stages of design.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {optimisation, creativity support, mixed-initiative, grid layouts, design tools, computational design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376796,
author = {M\"{a}kel\"{a}, Ville and Radiah, Rivu and Alsherif, Saleh and Khamis, Mohamed and Xiao, Chong and Borchert, Lisa and Schmidt, Albrecht and Alt, Florian},
title = {Virtual Field Studies: Conducting Studies on Public Displays in Virtual Reality},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376796},
doi = {10.1145/3313831.3376796},
abstract = {Field studies on public displays can be difficult, expensive, and time-consuming. We investigate the feasibility of using virtual reality (VR) as a test-bed to evaluate deployments of public displays. Specifically, we investigate whether results from virtual field studies, conducted in a virtual public space, would match the results from a corresponding real-world setting. We report on two empirical user studies where we compared audience behavior around a virtual public display in the virtual world to audience behavior around a real public display. We found that virtual field studies can be a powerful research tool, as in both studies we observed largely similar behavior between the settings. We discuss the opportunities, challenges, and limitations of using virtual reality to conduct field studies, and provide lessons learned from our work that can help researchers decide whether to employ VR in their research and what factors to account for if doing so.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {research methods, virtual reality, field studies, public displays},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376176,
author = {Dmitrenko, Dmitrijs and Maggioni, Emanuela and Brianza, Giada and Holthausen, Brittany E. and Walker, Bruce N. and Obrist, Marianna},
title = {CARoma Therapy: Pleasant Scents Promote Safer Driving, Better Mood, and Improved Well-Being in Angry Drivers},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376176},
doi = {10.1145/3313831.3376176},
abstract = {Driving is a task that is often affected by emotions. The effect of emotions on driving has been extensively studied. Anger is an emotion that dominates in such investigations. Despite the knowledge on strong links between scents and emotions, few studies have explored the effect of olfactory stimulation in a context of driving. Such an outcome provides HCI practitioners very little knowledge on how to design for emotions using olfactory stimulation in the car. We carried out three studies to select scents of different valence and arousal levels (i.e. rose, peppermint, and civet) and anger eliciting stimuli (i.e. affective pictures and on-road events). We used this knowledge to conduct the fourth user study investigating how the selected scents change the emotional state, well-being, and driving behaviour of drivers in an induced angry state. Our findings enable better decisions on what scents to choose when designing interactions for angry drivers.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {perception, odour stimulation, multimodal interfaces, smell, emotions, notification systems, in-car user interfaces},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376422,
author = {Larsen-Ledet, Ida and Korsgaard, Henrik and B\o{}dker, Susanne},
title = {Collaborative Writing Across Multiple Artifact Ecologies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376422},
doi = {10.1145/3313831.3376422},
abstract = {Research focusing on how collaborative writing takes place across multiple applications and devices and over longer projects is sparse. We respond to this gap by presenting the results of a qualitative study of longer-term academic writing projects, showing how co-writers employ multiple tools when working on a common text. We identify three patterns of multi-application collaboration as well as four common types of motivations for transitions between applications. We also extend existing taxonomies of collaborative writing by proposing a categorization of the functions served by the text as object and backbone of the collaboration. Together, these contributions offer a framing for understanding transitions within and across artifact ecologies in work around a common object. Our findings highlight ways in which features like concurrent editing may in fact challenge the collaborative writing process, and we point to opportunities for alternative application models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {potential artifact ecology, artifact ecology, personal artifact ecology, collaboration, text function, computer-supported cooperative work, sharelatex, overleaf, collaborative writing, collaborative academic writing, github, cscw, aligned artifact ecology, academic writing, latex, google docs},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

