@inproceedings{10.1145/1054972.1054974,
author = {Carroll, John M. and Rosson, Mary Beth and Zhou, Jingying},
title = {Collective Efficacy as a Measure of Community},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054974},
doi = {10.1145/1054972.1054974},
abstract = {As human-computer interaction increasingly focuses on mediated interactions among groups of individuals, there is a need to develop techniques for measurement and analysis of groups that have been scoped at the level of the group. Bandura's construct of perceived self-efficacy has been used to understand individual behavior as a function of domain-specific beliefs about personal capacities. The construct of collective efficacy extends self-efficacy to organizations and groups, referring to beliefs about collective capacities in specific domains. We describe the development and refinement of a collective efficacy scale, the factor analysis of the construct, and its external validation in path models of community-oriented attitudes, beliefs, and behaviors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {collective efficacy, evaluation, community computing, community informatics, CSCW},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@dataset{10.1145/review-1054972.1054974_R40088,
author = {Tettegah, Sharon},
title = {Review ID:R40088 for DOI: 10.1145/1054972.1054974},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1054972.1054974_R40088}
}

@inproceedings{10.1145/3249443,
author = {Olson, Gary},
title = {Session Details: Large Communities},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249443},
doi = {10.1145/3249443},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054975,
author = {Cosley, Dan and Frankowski, Dan and Kiesler, Sara and Terveen, Loren and Riedl, John},
title = {How Oversight Improves Member-Maintained Communities},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054975},
doi = {10.1145/1054972.1054975},
abstract = {Online communities need regular maintenance activities such as moderation and data input, tasks that typically fall to community owners. Communities that allow all members to participate in maintenance tasks have the potential to be more robust and valuable. A key challenge in creating member-maintained communities is building interfaces, algorithms, and social structures that encourage people to provide high-quality contributions. We use Karau and Williams' collective effort model to predict how peer and expert editorial oversight affect members' contributions to a movie recommendation website and test these predictions in a field experiment with 87 contributors. Oversight increased both the quantity and quality of contributions while reducing antisocial behavior, and peers were as effective at oversight as experts. We draw design guidelines and suggest avenues for future work from our results.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {online communities, oversight, participation, member-maintained, contribution, collective effort model, quality},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054976,
author = {Birnholtz, Jeremy P. and Finholt, Thomas A. and Horn, Daniel B. and Bae, Sung Joo},
title = {Grounding Needs: Achieving Common Ground via Lightweight Chat in Large, Distributed, Ad-Hoc Groups},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054976},
doi = {10.1145/1054972.1054976},
abstract = {This paper reports on the emergent use of lightweight text chat to provide important grounding and facilitation information in a large, distributed, ad-hoc group of researchers participating in a live experiment. The success of chat in this setting suggests a critical re-examination and extension of Clark and Brennan's work on grounding in communication. Specifically, it is argued that there are some settings characterized by reduced information and clarification needs, where the use of extremely lightweight tools (such as basic text chat) can be sufficient for achieving common ground - even when conversational participants are unknown to each other. Theoretical and design implications are then presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {21–30},
numpages = {10},
keywords = {common ground, cyberinfrastructure, cyberscience, instant messaging, distributed groups, chat, collaboratories},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249444,
author = {Chi, Ed},
title = {Session Details: Web Interactions},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249444},
doi = {10.1145/3249444},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054978,
author = {Blackmon, Marilyn Hughes and Kitajima, Muneo and Polson, Peter G.},
title = {Tool for Accurately Predicting Website Navigation Problems, Non-Problems, Problem Severity, and Effectiveness of Repairs},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054978},
doi = {10.1145/1054972.1054978},
abstract = {The Cognitive Walkthrough for the Web (CWW) is a partially automated usability evaluation method for identifying and repairing website navigation problems. Building on five earlier experiments [3,4], we first conducted two new experiments to create a sufficiently large dataset for multiple regression analysis. Then we devised automatable problem-identification rules and used multiple regression analysis on that large dataset to develop a new CWW formula for accurately predicting problem severity. We then conducted a third experiment to test the prediction formula and refined CWW against an independent dataset, resulting in full cross-validation of the formula. We conclude that CWW has high psychological validity, because CWW gives us (a) accurate measures of problem severity, (b) high success rates for repairs of identified problems (c) high hit rates and low false alarms for identifying problems, and (d) high rates of correct rejections and low rates of misses for identifying non-problems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {31–40},
numpages = {10},
keywords = {LSA, repairs, cognitive walkthrough for the web, coLiDeS, cognitive model, user model, usability problems, link labels, latent semantic analysis, usability evaluation method, information scent, CWW, heading labels},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054979,
author = {Mankoff, Jennifer and Fait, Holly and Tran, Tu},
title = {Is Your Web Page Accessible? A Comparative Study of Methods for Assessing Web Page Accessibility for the Blind},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054979},
doi = {10.1145/1054972.1054979},
abstract = {Web access for users with disabilities is an important goal and challenging problem for web content developers and designers. This paper presents a comparison of different methods for finding accessibility problems affecting users who are blind. Our comparison focuses on techniques that might be of use to Web developers without accessibility experience, a large and important group that represents a major source of inaccessible pages. We compare a laboratory study with blind users to an automated tool, expert review by web designers with and without a screen reader, and remote testing by blind users. Multiple developers, using a screen reader, were most consistently successful at finding most classes of problems, and tended to find about 50% of known problems. Surprisingly, a remote study with blind users was one of the least effective methods. All of the techniques, however, had different, complementary strengths and weaknesses.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {41–50},
numpages = {10},
keywords = {evaluation, disability, web accessibility, assistive technologies},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054980,
author = {Kaur, Ishwinder and Hornof, Anthony J.},
title = {A Comparison of LSA, WordNet and PMI-IR for Predicting User Click Behavior},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054980},
doi = {10.1145/1054972.1054980},
abstract = {A predictive tool to simulate human visual search behavior would help interface designers inform and validate their design. Such a tool would benefit from a semantic component that would help predict search behavior even in the absence of exact textual matches between goal and target. This paper discusses a comparison of three semantic systems-LSA, WordNet and PMI-IR-to evaluate their performance in predicting the link that people would select given an information goal and a webpage. PMI-IR best predicted human performance as observed in a user study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {51–60},
numpages = {10},
keywords = {PMI, semantic relatedness, LSA, wordNet, computational linguistics, semantic similarity},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249445,
author = {Guiard, Yves},
title = {Session Details: Basic Level Interaction Techniques},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249445},
doi = {10.1145/3249445},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054982,
author = {Ahlstr\"{o}m, David},
title = {Modeling and Improving Selection in Cascading Pull-down Menus Using Fitts' Law, the Steering Law and Force Fields},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054982},
doi = {10.1145/1054972.1054982},
abstract = {Selecting a menu item in a cascading pull-down menu is a frequent but time consuming and complex GUI task. This paper describes an approach aimed to support the user during selection in cascading pull-down menus when using an indirect pointing device. By enhancing such a cascading pull-down menu with "force fields", the cursor is attracted toward a certain direction, e.g. toward the right hand side within a menu item, which opens up a sub-menu, making the cursor steering task easier and faster. The experiment described here shows that the force fields can decrease selection times, on average by 18%, when a mouse, a track point, or touch pad is used as input device. The results also suggest that selection times in cascading pull-down menus can be modeled using a combination of Fitts' law and the steering law. The proposed model proved to hold for all three devices, in both standard and in enhanced cascading pull-down menus, with correlations better than r2=0.90.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {61–70},
numpages = {10},
keywords = {ascading pull-down menus, menu navigation, force fields, Fitts' law, input devices, selection, steering law},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054983,
author = {Cockburn, Andy and Savage, Joshua and Wallace, Andrew},
title = {Tuning and Testing Scrolling Interfaces That Automatically Zoom},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054983},
doi = {10.1145/1054972.1054983},
abstract = {Speed dependent automatic zooming (SDAZ) is a promising refinement to scrolling in which documents are automatically zoomed-out as the scroll rate increases. By automatically zooming, the visual flow rate is reduced enabling rapid scrolling without motion blur. In order to aid SDAZ calibration we theoretically and empirically scrutinise human factors of the speed/zoom relationship. We then compare user performance with four alternative text-document scrolling systems, two of which employ automatic zooming. One of these systems, which we term 'DDAZ', is based on van Wijk and Nuij's recent and important theory that calculates optimal pan/zoom paths between known locations in 2D space. van Wijk and Nuij suggested that their theory could be applied to scrolling, but did not implement or test their formulaic suggestions. Participants in our evaluation (n=27) completed scrolling tasks most rapidly when using SDAZ, followed by DDAZ, normal scrollbars, and traditional rate-based scrolling. Workload assessments and preferences strongly favoured SDAZ. We finish by examining issues for consideration in commercial deployments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {71–80},
numpages = {10},
keywords = {scrolling, rate control, visual flow, automatic zooming},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249446,
author = {Hong, Jason},
title = {Session Details: Privacy 1},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249446},
doi = {10.1145/3249446},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054985,
author = {Consolvo, Sunny and Smith, Ian E. and Matthews, Tara and LaMarca, Anthony and Tabert, Jason and Powledge, Pauline},
title = {Location Disclosure to Social Relations: Why, When, &amp; What People Want to Share},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054985},
doi = {10.1145/1054972.1054985},
abstract = {Advances in location-enhanced technology are making it easier for us to be located by others. These new technologies present a difficult privacy tradeoff, as disclosing one's location to another person or service could be risky, yet valuable. To explore whether and what users are willing to disclose about their location to social relations, we conducted a three-phased formative study. Our results show that the most important factors were who was requesting, why the requester wanted the participant's location, and what level of detail would be most useful to the requester. After determining these, participants were typically willing to disclose either the most useful detail or nothing about their location. From our findings, we reflect on the decision process for location disclosure. With these results, we hope to influence the design of future location-enhanced applications and services.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {81–90},
numpages = {10},
keywords = {privacy classification, ubiquitous computing, experience sampling, social relations, privacy, location-enhanced computing},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054986,
author = {Iachello, Giovanni and Abowd, Gregory D.},
title = {Privacy and Proportionality: Adapting Legal Evaluation Techniques to Inform Design in Ubiquitous Computing},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054986},
doi = {10.1145/1054972.1054986},
abstract = {We argue that an analytic proportionality assessment balancing usefulness and burden on individual or group privacy must be conducted throughout the design process to create acceptable ubiquitous computing (ubicomp) applications and services. We introduce the principle of proportionality, which originates within the legal and data protection communities. Inspired by this principle, we develop a design method for ubicomp applications, based on our own experience, and aimed at HCI practitioners and designers. We discuss the method in relation to real-world examples, user inquiry techniques and requirements engineering models. Finally, we report a sample application of the method, involving a ubiquitous, personal memory aid tool.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {91–100},
numpages = {10},
keywords = {proportionality, sensing technology, ubiquitous computing, social issues, data protection, privacy},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054987,
author = {Patil, Sameer and Lai, Jennifer},
title = {Who Gets to Know What When: Configuring Privacy Permissions in an Awareness Application},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054987},
doi = {10.1145/1054972.1054987},
abstract = {We report on a study (N=36) of user preferences for balancing awareness with privacy. Participants defined permissions for sharing of location, availability, calendar information and instant messaging (IM) activity within an application called mySpace. MySpace is an interactive visualization of the physical workplace that provides dynamic information about people, places and equipment. We found a significant preference for defining privacy permissions at the group level. While "family" received high levels of awareness sharing, interestingly, "team" was granted comparable levels during business hours at work. Surprisingly, presenting participants with a detailed list of all pieces of personal context to which the system had access, did not result in more conservative privacy settings. Although location was the most sensitive aspect of awareness, participants were comfortable disclosing room-level location information to their team members at work. Our findings suggest utilizing grouping mechanisms to balance privacy control with configuration burden, and argue for increased system transparency to build trust.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {101–110},
numpages = {10},
keywords = {awareness, privacy, information disclosure, permission structures, contextual communication, context-aware computing},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249447,
author = {Nakakoji, Kumiyo},
title = {Session Details: Document Interaction},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249447},
doi = {10.1145/3249447},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054989,
author = {Marshall, Catherine C. and Bly, Sara},
title = {Saving and Using Encountered Information: Implications for Electronic Periodicals},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054989},
doi = {10.1145/1054972.1054989},
abstract = {As part of a focus on electronic publications, we undertook an exploratory study of how people saved and used the information they encountered while reading. In particular, we wanted to understand the role of clipping and whether it would be a necessary form of interaction with electronic publications. We interviewed 20 diverse individuals at home and at work, bringing together narrative accounts and physical and digital examples to investigate how people currently collect and use clippings from their everyday reading. All study participants had examples of materials they had deliberately saved from periodicals, ranging from ads torn from newspapers and URLs received in email messages to large stacks of magazines. Participants rarely read periodicals specifically to clip but rather recognized items of interest when they were encountered. The work highlights the importance of encountering information as an activity distinct from task-focused browsing and searching and reveals design implications for online reading and clipping technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {111–120},
numpages = {10},
keywords = {reading, digital libraries, electronic publications, field study, design, clipping},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054990,
author = {Bondarenko, Olha and Janssen, Ruud},
title = {Documents at Hand: Learning from Paper to Improve Digital Technologies},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054990},
doi = {10.1145/1054972.1054990},
abstract = {In this paper the results of a two-year ethnographic study of the personal document management of 28 information workers is described. Both the paper and digital domain were taken into account during the study. The results reaffirmed that document management is strongly related to task management. Digital tools do not adequately support two important user needs related to task management, namely that documents should be embedded within meaningful (task-related) context information, and that they should be easily accessible for regrouping as the task goes on. In contrast, paper supports these needs very well. Following a discussion of personal document management using paper, email, and digital file folder structures, six implications are outlined for the design of digital document management systems that combine the advantages of both domains.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {121–130},
numpages = {10},
keywords = {document management, email, ethnography, paper-digital integration, paper},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054991,
author = {K\"{a}ki, Mika},
title = {Findex: Search Result Categories Help Users When Document Ranking Fails},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054991},
doi = {10.1145/1054972.1054991},
abstract = {Long web search result lists can be hard to browse. We demonstrated experimentally, in a previous study, the usefulness of a categorization algorithm and filtering interface. However, the nature of interaction in real settings is not known from an experiment in laboratory settings. To address this problem, we provided our categorizing web search user interface to 16 users for a two month period. The interactions with the system were logged and the users' opinions were elicited with two questionnaires. The results show that categories are successfully used as part of users' search habits. They are helpful when the result ranking of the search engine fails. In those cases, the users are able to access results that locate far in the rank order list with the categories. Users can also formulate simpler queries and find needed results with the help of the categories. In addition, the categories are beneficial when more than one result is needed like in an exploratory or undirected search task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {131–140},
numpages = {10},
keywords = {clustering, search user interfaces, categorization, web search, information access},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249448,
author = {R\"{a}ih\"{a}, Kari-Jouko},
title = {Session Details: Eyes on Interaction},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249448},
doi = {10.1145/3249448},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054993,
author = {Sadasivan, Sajay and Greenstein, Joel S. and Gramopadhye, Anand K. and Duchowski, Andrew T.},
title = {Use of Eye Movements as Feedforward Training for a Synthetic Aircraft Inspection Task},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054993},
doi = {10.1145/1054972.1054993},
abstract = {Aircraft inspection is a vital element in assuring safety and reliability of the air transportation system. The human inspector performing visual inspection of an aircraft is the backbone of this process and training is an effective strategy for improving their inspection performance. Previous studies have shown offline feedback training to be effective in improving subsequent visual inspection performance. Because experienced inspectors are known to adopt a better inspection strategy than novices, providing visualization of experts' cognitive processes a priori can accelerate novices' adoption of the experts' strategy. Using eye tracking equipment, we record the point of regard of an expert inspector performing an inspection task in a virtual reality simulator. Analysis of their eye movements leads to a visualization of their scanpaths and allows us to display the inspector's visual search (hence cognitive) strategy. We show how providing this type of scanpath-based feedforward training of novices leads to improved accuracy performance in the simulator coupled with an observed speed-accuracy tradeoff. We contend that the tradeoff results from trained novices adopting a slower paced strategy through increased fixation durations, suggesting trained novices learn a more deliberate target search/discrimination strategy that requires more time to execute.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {141–149},
numpages = {9},
keywords = {visual search, virtual reality, eye tracking},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054994,
author = {Fono, David and Vertegaal, Roel},
title = {EyeWindows: Evaluation of Eye-Controlled Zooming Windows for Focus Selection},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054994},
doi = {10.1145/1054972.1054994},
abstract = {In this paper, we present an attentive windowing technique that uses eye tracking, rather than manual pointing, for focus window selection. We evaluated the performance of 4 focus selection techniques: eye tracking with key activation, eye tracking with automatic activation, mouse and hotkeys in a typing task with many open windows. We also evaluated a zooming windowing technique designed specifically for eye-based control, comparing its performance to that of a stan-dard tiled windowing environment. Results indicated that eye tracking with automatic activation was, on average, about twice as fast as mouse and hotkeys. Eye tracking with key activation was about 72% faster than manual conditions, and preferred by most participants. We believe eye input performed well because it allows manual input to be provided in parallel to focus selection tasks. Results also suggested that zooming windows outperform static tiled windows by about 30%. Furthermore, this performance gain scaled with the number of windows used. We conclude that eye-controlled zooming windows with key activation pro-vides an efficient and effective alternative to current focus window selection techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {151–160},
numpages = {10},
keywords = {attentive user interfaces, alternative input, eye tracking},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054995,
author = {Hornof, Anthony J. and Cavender, Anna},
title = {EyeDraw: Enabling Children with Severe Motor Impairments to Draw with Their Eyes},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054995},
doi = {10.1145/1054972.1054995},
abstract = {EyeDraw is a software program that, when run on a computer with an eye tracking device, enables children with severe motor disabilities to draw pictures by just moving their eyes. This paper discusses the motivation for building the software, how the program works, the iterative development of two versions of the software, user testing of the two versions by people with and without disabilities, and modifications to the software based on user testing. Feedback from both children and adults with disabilities, and from their caregivers, was especially helpful in the design process. The project identifies challenges that are unique to controlling a computer with the eyes, and unique to writing software for children with severe motor impairments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {161–170},
numpages = {10},
keywords = {universal access, children, art, eye tracking, drawing, interaction techniques, input devices},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249449,
author = {Konstan, Joseph},
title = {Session Details: Personal Technologies},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249449},
doi = {10.1145/3249449},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054997,
author = {Voida, Amy and Mynatt, Elizabeth D.},
title = {Six Themes of the Communicative Appropriation of Photographic Images},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054997},
doi = {10.1145/1054972.1054997},
abstract = {In this paper, we explore the use of digital photographs in computer-mediated communication. We present Lascaux, an instant messaging client that serves as a research platform for studying visual communication with digital photographs. Through a combined analysis of the uses of images in Lascaux as well as the uses of images in other communicative contexts, we arrived at six themes of appropriation: the image as amplification, the image as narrative, the image as awareness, the image as local expression, the image as invitation, and the image as object/instrument. For each theme, we explore the ways in which a medium may be designed to support that class of appropriation. Finally, we reflect on the relationship between literacy, mastery, and appropriation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {171–180},
numpages = {10},
keywords = {instant messaging, computer-mediated communication, networked digital photography, image-mediated communication, visual communication},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054998,
author = {Aoki, Paul M. and Woodruff, Allison},
title = {Making Space for Stories: Ambiguity in the Design of Personal Communication Systems},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054998},
doi = {10.1145/1054972.1054998},
abstract = {Pervasive personal communication technologies offer the potential for important social benefits for individual users, but also the potential for significant social difficulties and costs. In research on face-to-face social interaction, ambiguity is often identified as an important resource for resolving social difficulties. In this paper, we discuss two design cases of personal communication systems, one based on fieldwork of a commercial system and another based on an unrealized design concept. The cases illustrate how user behavior concerning a particular social difficulty, unexplained unresponsiveness, can be influenced by technological issues that result in interactional ambiguity. The cases also highlight the need to balance the utility of ambiguity against the utility of usability and communicative clarity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {181–190},
numpages = {10},
keywords = {mediated communication, leases, face-work, ambiguity, push-to-talk},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1054999,
author = {Voida, Amy and Grinter, Rebecca E. and Ducheneaut, Nicolas and Edwards, W. Keith and Newman, Mark W.},
title = {Listening in: Practices Surrounding ITunes Music Sharing},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1054999},
doi = {10.1145/1054972.1054999},
abstract = {This paper presents a descriptive account of the social practices surrounding the iTunes music sharing of 13 participants in one organizational setting. Specifically, we characterize adoption, critical mass, and privacy; impression management and access control; the musical impressions of others that are created as a result of music sharing; the ways in which participants attempted to make sense of the dynamic system; and implications of the overlaid technical, musical, and corporate topologies. We interleave design implications throughout our results and relate those results to broader themes in a music sharing design space.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {191–200},
numpages = {10},
keywords = {iTunes, music sharing, discovery},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249450,
author = {Golovchinsky, Gene},
title = {Session Details: Small Devices 1},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249450},
doi = {10.1145/3249450},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055001,
author = {Karlson, Amy K. and Bederson, Benjamin B. and SanGiovanni, John},
title = {AppLens and LaunchTile: Two Designs for One-Handed Thumb Use on Small Devices},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055001},
doi = {10.1145/1054972.1055001},
abstract = {We present two interfaces to support one-handed thumb use for PDAs and cell phones. Both use Scalable User Interface (ScUI) techniques to support multiple devices with different resolutions and aspect ratios. The designs use variations of zooming interface techniques to provide multiple views of application data: AppLens uses tabular fisheye to access nine applications, while LaunchTile uses pure zoom to access thirty-six applications. We introduce two sets of thumb gestures, each representing different philosophies for one-handed interaction. We conducted two studies to evaluate our designs. In the first study, we explored whether users could learn and execute the AppLens gesture set with minimal training. Participants performed more accurately and efficiently using gestures for directional navigation than using gestures for object interaction. In the second study, we gathered user reactions to each interface, as well as comparative preferences. With minimal exposure to each design, most users favored AppLens's tabular fisheye interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {201–210},
numpages = {10},
keywords = {gestures, thumb navigation, one-handed, mobile devices, zoomable user interfaces (ZUIs), piccolo, notification},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055002,
author = {Gong, Jun and Tarasewich, Peter},
title = {Alphabetically Constrained Keypad Designs for Text Entry on Mobile Devices},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055002},
doi = {10.1145/1054972.1055002},
abstract = {The creation of text will remain a necessary part of human-computer interaction with mobile devices, even as they continue to shrink in size. On mobile phones, text is often entered using keypads and predictive text entry techniques, which attempt to minimize the effort (e.g., number of key presses) needed to enter words. This research presents results from the design and testing of alphabetically-constrained keypads, optimized on various word lists, for predictive text entry on mobile devices. Complete enumeration and Genetic Algorithm-based heuristics were used to find keypad designs based on different numbers of keys. Results show that alphabetically-constrained designs can be found that are close to unconstrained designs in terms of performance. User testing supports the hypothesis that novice ease of learning, usability, and performance is greater for constrained designs when compared to unconstrained designs. The effect of different word lists on keypad design and performance is also discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {211–220},
numpages = {10},
keywords = {novice learning and usability, mobile device user interface design, predictive keypad text entry},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249451,
author = {Jacob, Robert},
title = {Session Details: Eye Gaze and Multimodal Integration Patterns},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249451},
doi = {10.1145/3249451},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055004,
author = {Qvarfordt, Pernilla and Zhai, Shumin},
title = {Conversing with the User Based on Eye-Gaze Patterns},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055004},
doi = {10.1145/1054972.1055004},
abstract = {Motivated by and grounded in observations of eye-gaze patterns in human-human dialogue, this study explores using eye-gaze patterns in managing human-computer dialogue. We developed an interactive system, iTourist, for city trip planning, which encapsulated knowledge of eye-gaze patterns gained from studies of human-human collaboration systems. User study results show that it was possible to sense users' interest based on eye-gaze patterns and manage computer information output accordingly. Study participants could successfully plan their trip with iTourist and positively rated their experience of using it. We demonstrate that eye-gaze could play an important role in managing future multimodal human-computer dialogues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {221–230},
numpages = {10},
keywords = {multimodal interaction, dialogue systems, eye tracking, interest detection},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055005,
author = {Ou, Jiazhi and Oh, Lui Min and Yang, Jie and Fussell, Susan R.},
title = {Effects of Task Properties, Partner Actions, and Message Content on Eye Gaze Patterns in a Collaborative Task},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055005},
doi = {10.1145/1054972.1055005},
abstract = {Helpers providing guidance for collaborative physical tasks shift their gaze between the workspace, supply area, and instructions. Understanding when and why helpers gaze at each area is important both for a theoretical understanding of collaboration on physical tasks and for the design of automated video systems for remote collaboration. In a laboratory experiment using a collaborative puzzle task, we recorded helpers' gaze while manipulating task complexity and piece differentiability. Helpers gazed toward the pieces bay more frequently when pieces were difficult to differentiate and less frequently over repeated trials. Preliminary analyses of message content show that helpers tend to look at the pieces bay when describing the next piece and at the workspace when describing where it goes. The results are consistent with a grounding model of communication, in which helpers seek visual evidence of understanding unless they are confident that they have been understood. The results also suggest the feasibility of building automated video systems based on remote helpers' shifting visual requirements.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {231–240},
numpages = {10},
keywords = {gesture, computer-supported, video mediated communication, conversational analysis, eye-tracking, collaborative work, video conferencing, empirical studies},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055006,
author = {Oviatt, Sharon and Lunsford, Rebecca and Coulston, Rachel},
title = {Individual Differences in Multimodal Integration Patterns: What Are They and Why Do They Exist?},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055006},
doi = {10.1145/1054972.1055006},
abstract = {Techniques for information fusion are at the heart of multimodal system design. To develop new user-adaptive approaches for multimodal fusion, the present research investigated the stability and underlying cause of major individual differences that have been documented between users in their multimodal integration pattern. Longitudinal data were collected from 25 adults as they interacted with a map system over six weeks. Analyses of 1,100 multimodal constructions revealed that everyone had a dominant integration pattern, either simultaneous or sequential, which was 95-96% consistent and remained stable over time. In addition, coherent behavioral and linguistic differences were identified between these two groups. Whereas performance speed was comparable, sequential integrators made only half as many errors and excelled during new or complex tasks. Sequential integrators also had more precise articulation (e.g., fewer disfluencies), although their speech rate was no slower. Finally, sequential integrators more often adopted terse and direct command-style language, with a smaller and less varied vocabulary, which appeared focused on achieving error-free communication. These distinct interaction patterns are interpreted as deriving from fundamental differences in reflective-impulsive cognitive style. Implications of these findings are discussed for the design of adaptive multimodal systems with substantially improved performance characteristics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {241–249},
numpages = {9},
keywords = {individual differences, commands, simultaneous or sequential input, disfluencies, impulsive-reflective cognitive style, conversations, multimodal integration patterns, errors},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249452,
author = {Fels, Sidney},
title = {Session Details: Touch &amp; Such},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249452},
doi = {10.1145/3249452},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055008,
author = {Ayatsuka, Yuji and Rekimoto, Jun},
title = {TranSticks: Physically Manipulatable Virtual Connections},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055008},
doi = {10.1145/1054972.1055008},
abstract = {A virtually connected medium called tranStick is described that functions both as a "virtual wire" and as a "memory card" containing a shared space. A user can connect two networked devices by simply placing one of a pair of tranSticks with the same identifier into each device. The tranSticks provide feedback indicating that the devices are connected; the connection to be closed or changed in the same way it would be if the devices were connected by a physical cable. A user can also access to a shared space on a network as if the space were in the tranStick. Since tranSticks contain long secret keys, the process of finding another tranStick with the same identifier can be encrypted. The tranStick approach differs from other approaches in that it provides feedback from the connection as well as serving as a medium for establishing a connection, and it enables disconnection and switchover to be done intuitively because the operations are reversible.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {251–260},
numpages = {10},
keywords = {tangible user interface, connection control},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055009,
author = {Gnanayutham, Paul and Bloor, Chris and Cockton, Gilbert},
title = {Discrete Acceleration and Personalised Tiling as Brain?Body Interface Paradigms for Neurorehabilitation},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055009},
doi = {10.1145/1054972.1055009},
abstract = {We present two studies that have advanced the design of brain-body interfaces for use in the rehabilitation of individuals with severe neurological impairment due to traumatic brain injury. We first developed and evaluated an adaptive cursor acceleration algorithm based on screen areas. This improved the initial design, but was too inflexible to let users make the most of their highly varied abilities. Only some individuals were well served by this adaptive interface. We therefore developed and evaluated an approach based on personalized tile layouts. The rationales for both designs are presented, along with details of their implementation. Evaluation studies for each are reported, which show that we have extended the user population who can use our interfaces relative to previous studies. We have also extended the usable functionality for some of our user group. We thus claim that personalized tiling with discrete acceleration has allowed us to extend the usable functionality of brain-body interfaces to a wider population with traumatic brain injury, thus creating new options for neurorehabiliation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {261–270},
numpages = {10},
keywords = {input devices, neurorehabiliation, cyberlink\"{a}, brain-body interfaces, assistive technology, accessibility},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055010,
author = {Lindeman, Robert W. and Sibert, John L. and Mendez-Mendez, Erick and Patil, Sachin and Phifer, Daniel},
title = {Effectiveness of Directional Vibrotactile Cuing on a Building-Clearing Task},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055010},
doi = {10.1145/1054972.1055010},
abstract = {This paper presents empirical results to support the use of vibrotactile cues as a means of improving user performance on a spatial task. In a building-clearing exercise, directional vibrotactile cues were employed to alert subjects to areas of the building that they had not yet cleared, but were currently exposed to. Compared with performing the task without vibrotactile cues, subjects were exposed to uncleared areas a smaller percentage of time, and cleared more of the overall space, when given the added vibrotactile stimulus. The average length of each exposure was also significantly less when vibrotactile cues were present.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {271–280},
numpages = {10},
keywords = {virtual reality, vibrotactile, user study, tactile &amp; haptic UIs},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249453,
author = {Feiner, Steven},
title = {Session Details: Smart Interaction Techniques 1},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249453},
doi = {10.1145/3249453},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055012,
author = {Grossman, Tovi and Balakrishnan, Ravin},
title = {The Bubble Cursor: Enhancing Target Acquisition by Dynamic Resizing of the Cursor's Activation Area},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055012},
doi = {10.1145/1054972.1055012},
abstract = {We present the bubble cursor - a new target acquisition technique based on area cursors. The bubble cursor improves upon area cursors by dynamically resizing its activation area depending on the proximity of surrounding targets, such that only one target is selectable at any time. We also present two controlled experiments that evaluate bubble cursor performance in 1D and 2D target acquisition tasks, in complex situations with multiple targets of varying layout densities. Results show that the bubble cursor significantly outperforms the point cursor and the object pointing technique [7], and that bubble cursor performance can be accurately modeled and predicted using Fitts' law.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {281–290},
numpages = {10},
keywords = {bubble cursor, area cursor, target acquisition, Fitts' law},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055013,
author = {Po, Barry A. and Fisher, Brian D. and Booth, Kellogg S.},
title = {Comparing Cursor Orientations for Mouse, Pointer, and Pen Interaction},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055013},
doi = {10.1145/1054972.1055013},
abstract = {Most graphical user interfaces provide visual cursors to facilitate interaction with input devices such as mice, pointers, and pens. These cursors often include directional cues that could influence the stimulus-response compatibility of user input. We conducted a controlled evaluation of four cursor orientations and an orientation-neutral cursor in a circular menu selection task. Mouse interaction on a desktop, pointer (i.e. wand) interaction on a large screen, and pen interaction on a Tablet PC were evaluated. Our results suggest that choosing appropriate cursors is especially important for pointer interaction, but may be less important for mice or pens. Cursors oriented toward the lower-right corner of a display yielded the poorest performance overall while orientation-neutral cursors were generally the best. Advantages were found for orientations aligned with the direction of movement. We discuss these results and suggest guidelines for the appropriate use of cursors in various input and display configurations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {291–300},
numpages = {10},
keywords = {pens, mice, large screens, desktops, cursors, styli, wands, small screens, pointing},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055014,
author = {Baudisch, Patrick and Cutrell, Edward and Hinckley, Ken and Eversole, Adam},
title = {Snap-and-Go: Helping Users Align Objects without the Modality of Traditional Snapping},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055014},
doi = {10.1145/1054972.1055014},
abstract = {Snapping is a widely used technique that helps users position graphical objects precisely, e.g., to align them with a grid or other graphical objects. Unfortunately, whenever users want to position a dragged object close to such an aligned location, they first need to deactivate snapping. We propose snap-and-go, a snapping technique that overcomes this limitation. By merely stopping dragged objects at aligned positions, rather than "warping" them there, snap-and-go helps users align objects, yet still allows placing dragged objects anywhere else. While this approach of inserting additional motor space renders snap-and-go slightly slower than traditional snapping, snap-and-go simplifies the user interface by eliminating the need for a deactivation option and thereby allows introducing snapping to application scenarios where traditional snapping is inapplicable. In our user studies, participants were able to align objects up to 138% (1D) and 231% (2D) faster with snap-and-go than without and snap-and-go proved robust against the presence of distracting snap targets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {301–310},
numpages = {10},
keywords = {pseudo haptics, snap-dragging, alignment, snapping, mouse input},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249454,
author = {Thomas, John C.},
title = {Session Details: Take a Number, Stand in Line (Interruptions &amp; Attention 1)},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249454},
doi = {10.1145/3249454},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055016,
author = {Iqbal, Shamsi T. and Adamczyk, Piotr D. and Zheng, Xianjun Sam and Bailey, Brian P.},
title = {Towards an Index of Opportunity: Understanding Changes in Mental Workload during Task Execution},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055016},
doi = {10.1145/1054972.1055016},
abstract = {To contribute to systems that reason about human attention, our work empirically demonstrates how a user's mental workload changes during task execution. We conducted a study where users performed interactive, hierarchical tasks while mental workload was measured through the use of pupil size. Results show that (i) different types of subtasks impose different mental workload, (ii) workload decreases at subtask boundaries, (iii) workload decreases more at boundaries higher in a task model and less at boundaries lower in the model, (iv) workload changes among subtask boundaries within the same level of a task model, and (v) effective understanding of why changes in workload occur requires that the measure be tightly coupled to a validated task model. From the results, we show how to map mental workload onto a computational Index of Opportunity that systems can use to better reason about human attention.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {311–320},
numpages = {10},
keywords = {interruption, task models, pupil size, attention},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055017,
author = {Mark, Gloria and Gonzalez, Victor M. and Harris, Justin},
title = {No Task Left behind? Examining the Nature of Fragmented Work},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055017},
doi = {10.1145/1054972.1055017},
abstract = {We present data from detailed observation of 24 information workers that shows that they experience work fragmentation as common practice. We consider that work fragmentation has two components: length of time spent in an activity, and frequency of interruptions. We examined work fragmentation along three dimensions: effect of collocation, type of interruption, and resumption of work. We found work to be highly fragmented: people average little time in working spheres before switching and 57% of their working spheres are interrupted. Collocated people work longer before switching but have more interruptions. Most internal interruptions are due to personal work whereas most external interruptions are due to central work. Though most interrupted work is resumed on the same day, more than two intervening activities occur before it is. We discuss implications for technology design: how our results can be used to support people to maintain continuity within a larger framework of their working spheres.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {321–330},
numpages = {10},
keywords = {interruptions, attention management, information overload, multi-tasking, empirical study},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055018,
author = {Fogarty, James and Ko, Andrew J. and Aung, Htet Htet and Golden, Elspeth and Tang, Karen P. and Hudson, Scott E.},
title = {Examining Task Engagement in Sensor-Based Statistical Models of Human Interruptibility},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055018},
doi = {10.1145/1054972.1055018},
abstract = {The computer and communication systems that office workers currently use tend to interrupt at inappropriate times or unduly demand attention because they have no way to determine when an interruption is appropriate. Sensor?based statistical models of human interruptibility offer a potential solution to this problem. Prior work to examine such models has primarily reported results related to social engagement, but it seems that task engagement is also important. Using an approach developed in our prior work on sensor?based statistical models of human interruptibility, we examine task engagement by studying programmers working on a realistic programming task. After examining many potential sensors, we implement a system to log low?level input events in a development environment. We then automatically extract features from these low?level event logs and build a statistical model of interruptibility. By correctly identifying situations in which programmers are non?interruptible and minimizing cases where the model incorrectly estimates that a programmer is non?interruptible, we can support a reduction in costly interruptions while still allowing systems to convey notifications in a timely manner.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {331–340},
numpages = {10},
keywords = {managing human attention, machine learning, sensor-based interfaces, context-aware computing, situationally appropriate interaction, interruptibility},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@dataset{10.1145/review-1054972.1055018_R41250,
author = {Haller, Michael},
title = {Review ID:R41250 for DOI: 10.1145/1054972.1055018},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1054972.1055018_R41250}
}

@inproceedings{10.1145/3249455,
author = {Zellweger, Polle},
title = {Session Details: Design Thoughts &amp; Methods},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249455},
doi = {10.1145/3249455},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055020,
author = {Paulos, Eric and Jenkins, Tom},
title = {Urban Probes: Encountering Our Emerging Urban Atmospheres},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055020},
doi = {10.1145/1054972.1055020},
abstract = {Urban Atmospheres captures a unique, synergistic moment - expanding urban populations, rapid adoption of Bluetooth mobile devices, tiny ad hoc sensor networks, and the widespread influence of wireless technologies across our growing urban landscapes. The United Nations recently reported that 48 percent of the world's population current live in urban areas and that this number is expected to exceed the 50 percent mark world wide by 2007 [1]. In developed nations the number of urban dwellers is even more dramatic - expected to exceed 75%. Current studies project Bluetooth-enabled devices to reach 5.4 billion units by 2005 - five times the number of mobile phones or Internet connections [2]. Mobile phone penetration already exceeds 80% of the population in places like the European Union (EU) and parts of Asia [3]. WiFi hardware is being deployed at the astonishing rate of one every 4 seconds globally [4]. We argue that now is the time to initiate inspirational research into the very essence of these newly emerging technological urban spaces. We desire to move towards an improved understanding of the emotional experience of urban life. This paper describes Urban Probes - a lightweight, provocative, intervention methodology designed to rapidly deconstruct urban situations, reveal new opportunities for technology in urban spaces, and guide future long term research in urban computing. We also describe a completed Urban Probe exploring urban trash.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {341–350},
numpages = {10},
keywords = {urban computing, trash, cultural probes, technology probes, d\'{e}rive, d\'{e}tournement, urban atmospheres},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055021,
author = {Jung, Younghee and Persson, Per and Blom, Jan},
title = {DeDe: Design and Evaluation of a Context-Enhanced Mobile Messaging System},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055021},
doi = {10.1145/1054972.1055021},
abstract = {This paper presents the design, implementation and validation of an enhanced mobile phone messaging system (DeDe), allowing the sender to define the context in which the message will be delivered to the recipient. A field trial among a socially tight group of teenagers showed that the DeDe feature was incorporated as part of the participants' existing messaging culture. 11,4% of their total messaging output made use of the DeDe feature. The most frequently used context parameters were location (based on network cell-ID) and time. Novel message practices emerged, as compared to 'normal' messaging, both in terms of timing of message sending, as well as creating content that specifically exploited the DeDe feature. Some use barriers were recognized, the most important being the sender's uncertainty of delivery success. Implications for design are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {351–360},
numpages = {10},
keywords = {location-based messaging, field trial, mediated communication, mobile messaging, context},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@dataset{10.1145/review-1054972.1055021_R39918,
author = {Hair, D.C. Charles},
title = {Review ID:R39918 for DOI: 10.1145/1054972.1055021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1054972.1055021_R39918}
}

@inproceedings{10.1145/3249456,
author = {Czerwinski, Mary},
title = {Session Details: Smart Interaction Techniques 2},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249456},
doi = {10.1145/3249456},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055023,
author = {Bezerianos, Anastasia and Balakrishnan, Ravin},
title = {The Vacuum: Facilitating the Manipulation of Distant Objects},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055023},
doi = {10.1145/1054972.1055023},
abstract = {We present the design and evaluation of the vacuum, a new interaction technique that enables quick access to items on areas of a large display that are difficult for a user to reach without significant physical movement. The vacuum is a circular widget with a user controllable arc of influence that is centered at the widget's point of invocation and spans out to the edges of the display. Far away objects residing inside this influence arc are brought closer to the widget's centre in the form of proxies that can be manipulated in lieu of the original. We conducted two experiments which compare the vacuum to direct picking and an existing technique called drag-and-pick [2]. Results show that the vacuum outperforms existing techniques when selecting multiple targets in a sequence, performs similarly to existing techniques when selecting single targets located moderately far away, and slightly worse with single targets located very far away in the presence of distracter targets along the path.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {361–370},
numpages = {10},
keywords = {large displays, distance reaching},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055024,
author = {Nacenta, Miguel A. and Aliakseyeu, Dzmitry and Subramanian, Sriram and Gutwin, Carl},
title = {A Comparison of Techniques for Multi-Display Reaching},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055024},
doi = {10.1145/1054972.1055024},
abstract = {Recent advances in multi-user collaboration have seen a proliferation of interaction techniques for moving digital objects from one device to another. However, little is known about how these techniques work in realistic situations, or how they compare to one another. We conducted a study to compare the efficiency of six techniques for moving objects from a tablet to a tabletop display. We compared the techniques in four different distance ranges and with three movement directions. We found that techniques like the Radar View and Pick-and-Drop, that have a control-to-display ratio of 1, are significantly faster for object movement than techniques that have smaller control-to-display ratios. We also found that using spatial manipulation of objects was faster than pressure-based manipulation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {371–380},
numpages = {10},
keywords = {pen-based interaction techniques, ubiquitous computing, co-located collaboration, tabletop interaction},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055025,
author = {Hudson, Scott E. and Mankoff, Jennifer and Smith, Ian},
title = {Extensible Input Handling in the SubArctic Toolkit},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055025},
doi = {10.1145/1054972.1055025},
abstract = {The subArctic user interface toolkit has extensibility as one of its central goals. It seeks not only to supply a powerful library of reusable interactive objects, but also make it easy to create new, unusual, and highly customized interactions tailored to the needs of particular interfaces or task domains. A central part of this extensibility is the input model used by the toolkit. The subArctic input model provides standard reusable components that implement many typical input handling patterns for the programmer, allows inputs to be handled in very flexible ways, and allows the details of how inputs are handled to be modified to meet custom needs. This paper will consider the structure and operation of the subArctic input handling mechanism. It will demonstrate the flexibility of the system through a series of examples, illustrating techniques that it enables - many of which would be very difficult to implement in most toolkits.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {381–390},
numpages = {10},
keywords = {GUI toolkits, interaction techniques, event handling},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249457,
author = {Newman, William},
title = {Session Details: Methods &amp; Usability},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249457},
doi = {10.1145/3249457},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055027,
author = {Hornb\ae{}k, Kasper and Fr\o{}kj\ae{}r, Erik},
title = {Comparing Usability Problems and Redesign Proposals as Input to Practical Systems Development},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055027},
doi = {10.1145/1054972.1055027},
abstract = {Usability problems predicted by evaluation techniques are useful input to systems development; it is uncertain whether redesign proposals aimed at alleviating those problems are likewise useful. We present a study of how developers of a large web application assess usability problems and redesign proposals as input to their systems development. Problems and redesign proposals were generated by 43 evaluators using an inspection technique and think aloud testing. Developers assessed redesign proposals to have higher utility in their work than usability problems. In interviews they explained how redesign proposals gave them new ideas for tackling well known problems. Redesign proposals were also seen as constructive and concrete input. Few usability problems were new to developers, but the problems supported prioritizing ongoing development of the application and taking design decisions. No developers, however, wanted to receive only problems or redesigns. We suggest developing and using redesign proposals as an integral part of usability evaluation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {391–400},
numpages = {10},
keywords = {metaphors of human thinking, usability inspection, redesign, usability evaluation, think aloud, empirical study},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055028,
author = {Sauro, Jeff and Kindlund, Erika},
title = {A Method to Standardize Usability Metrics into a Single Score},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055028},
doi = {10.1145/1054972.1055028},
abstract = {Current methods to represent system or task usability in a single metric do not include all the ANSI and ISO defined usability aspects: effectiveness, efficiency &amp; satisfaction. We propose a method to simplify all the ANSI and ISO aspects of usability into a single, standardized and summated usability metric (SUM). In four data sets, totaling 1860 task observations, we show that these aspects of usability are correlated and equally weighted and present a quantitative model for usability. Using standardization techniques from Six Sigma, we propose a scalable process for standardizing disparate usability metrics and show how Principal Components Analysis can be used to establish appropriate weighting for a summated model. SUM provides one continuous variable for summative usability evaluations that can be used in regression analysis, hypothesis testing and usability reporting.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {401–409},
numpages = {9},
keywords = {six sigma, usability, measurement, principal components analysis, standardization},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055029,
author = {Tollinger, Irene and Lewis, Richard L. and McCurdy, Michael and Tollinger, Preston and Vera, Alonso and Howes, Andrew and Pelton, Laura},
title = {Supporting Efficient Development of Cognitive Models at Multiple Skill Levels: Exploring Recent Advances in Constraint-Based Modeling},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055029},
doi = {10.1145/1054972.1055029},
abstract = {This paper presents X-PRT, a new cognitive modeling tool supporting activities ranging from interface design to basic cognitive research. X-PRT provides a graphical model development environment for the CORE constraint-based cognitive modeling engine [7,13,21]. X-PRT comprises a novel feature set: (a) it supports the automatic generation of predictive models at multiple skill levels from a single task-specification, (b) it supports a comprehensive set of modeling activities, and (c) it supports compositional reuse of existing cognitive/perceptual/motor skills by transforming high-level, hierarchical task descriptions into detailed performance predictions. Task hierarchies play a central role in X-PRT, serving as the organizing construct for task knowledge, the locus for compositionality, and the cognitive structures over which the learning theory is predicated. Empirical evidence supports the role of task hierarchies in routine skill acquisition.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {411–420},
numpages = {10},
keywords = {user modeling, tools for usability evaluationm},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249458,
author = {Kandogan, Eser},
title = {Session Details: Interactive Information Visualization},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249458},
doi = {10.1145/3249458},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055031,
author = {Heer, Jeffrey and Card, Stuart K. and Landay, James A.},
title = {Prefuse: A Toolkit for Interactive Information Visualization},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055031},
doi = {10.1145/1054972.1055031},
abstract = {Although information visualization (infovis) technologies have proven indispensable tools for making sense of complex data, wide-spread deployment has yet to take hold, as successful infovis applications are often difficult to author and require domain-specific customization. To address these issues, we have created prefuse, a software framework for creating dynamic visualizations of both structured and unstructured data. prefuse provides theoretically-motivated abstractions for the design of a wide range of visualization applications, enabling programmers to string together desired components quickly to create and customize working visualizations. To evaluate prefuse we have built both existing and novel visualizations testing the toolkit's flexibility and performance, and have run usability studies and usage surveys finding that programmers find the toolkit usable and effective.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {421–430},
numpages = {10},
keywords = {information visualization, interaction, 2D graphics, graphs, user interfaces, trees, navigation, toolkits},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055032,
author = {Robertson, George G. and Czerwinski, Mary P. and Churchill, John E.},
title = {Visualization of Mappings between Schemas},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055032},
doi = {10.1145/1054972.1055032},
abstract = {In this paper we describe a novel approach to the visualization of the mapping between two schemas. Current approaches to visually defining such a mapping fail when the schemas or maps become large. The new approach uses various information visualization techniques to simplify the view, making it possible for users to effectively deal with much larger schemas and maps. A user study verifies that the new approach is useful, usable, and effective. The primary contribution is a demonstration of novel ways to effectively present highly complex information.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {431–439},
numpages = {9},
keywords = {hierarchy visualization, XSLT, schema mapping, interaction techniques, XML, visualization},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055033,
author = {Aragon, Cecilia R. and Hearst, Marti A.},
title = {Improving Aviation Safety with Information Visualization: A Flight Simulation Study},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055033},
doi = {10.1145/1054972.1055033},
abstract = {Many aircraft accidents each year are caused by encounters with invisible airflow hazards. Recent advances in aviation sensor technology offer the potential for aircraft-based sensors that can gather large amounts of airflow velocity data in real-time. With this influx of data comes the need to study how best to present it to the pilot - a cognitively overloaded user focused on a primary task other than that of information visualization.We focus on one particular aviation application, but the results may be relevant to user interfaces in other operationally stressful environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {441–450},
numpages = {10},
keywords = {augmented reality, information visualization, airflow hazards, flight-deck displays, human factors in aviation, presentation of safety-critical information, helicopters},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249459,
author = {Oviatt, Sharon},
title = {Session Details: Pen-Based Interfaces},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249459},
doi = {10.1145/3249459},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055035,
author = {Hinckley, Ken and Baudisch, Patrick and Ramos, Gonzalo and Guimbretiere, Francois},
title = {Design and Analysis of Delimiters for Selection-Action Pen Gesture Phrases in Scriboli},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055035},
doi = {10.1145/1054972.1055035},
abstract = {We present a quantitative analysis of delimiters for pen gestures. A delimiter is "something different" in the input stream that a computer can use to determine the structure of input phrases. We study four techniques for delimiting a selection-action gesture phrase consisting of lasso selection plus marking-menu-based command activation. Pigtail is a new technique that uses a small loop to delimit lasso selection from marking (Fig. 1). Handle adds a box to the end of the lasso, from which the user makes a second stroke for marking. Timeout uses dwelling with the pen to delimit the lasso from the mark. Button uses a button press to signal when to delimit the gesture. We describe the role of delimiters in our Scriboli pen interaction testbed, and show how Pigtail supports scope selection, command activation, and direct manipulation all in a single fluid pen gesture.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {451–460},
numpages = {10},
keywords = {pen input, delimiters, gestures, tablets, marking},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055036,
author = {Li, Yang and Hinckley, Ken and Guan, Zhiwei and Landay, James A.},
title = {Experimental Analysis of Mode Switching Techniques in Pen-Based User Interfaces},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055036},
doi = {10.1145/1054972.1055036},
abstract = {Inking and gesturing are two central tasks in pen-based user interfaces. Switching between modes for entry of uninterpreted ink and entry of gestures is required by many pen-based user interfaces. Without an appropriate mode switching technique, pen-based interactions in such situations may be inefficient and cumbersome. In this paper, we investigate five techniques for switching between ink and gesture modes in pen interfaces, including a pen-pressure based mode switching technique that allows implicit mode transition. A quantitative experimental study was conducted to evaluate the performance of these techniques. The results suggest that pressing a button with the non-preferred hand offers the fastest performance, while the technique of holding the pen still is significantly slower and more prone to error than the other techniques. Pressure, while promising, did not perform as well as the non-preferred hand button with our current implementation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {461–470},
numpages = {10},
keywords = {ink, pen interfaces, gestures, mode switching, mode errors},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249460,
author = {Mark, Gloria},
title = {Session Details: Affect and Intimacy},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249460},
doi = {10.1145/3249460},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055038,
author = {Vetere, Frank and Gibbs, Martin R. and Kjeldskov, Jesper and Howard, Steve and Mueller, Florian 'Floyd' and Pedell, Sonja and Mecoles, Karen and Bunyan, Marcus},
title = {Mediating Intimacy: Designing Technologies to Support Strong-Tie Relationships},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055038},
doi = {10.1145/1054972.1055038},
abstract = {Intimacy is a crucial element of domestic life, and many interactive technologies designed for other purposes have been appropriated for use within intimate relationships. However, there is a deficit in current understandings of how technologies are used within intimate relationships, and how to design technologies to support intimate acts. In this paper we report on work that has addressed these deficits. We used cultural probes and contextual interviews and other ethnographically informed techniques to investigate how interactive technologies are used within intimate relationships. From this empirical work we generated a thematic understanding of intimacy and the use of interactional technologies to support intimate acts. We used this understanding to inform the design of intimate technologies. A selection of our design concepts is also presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {471–480},
numpages = {10},
keywords = {participatory design, ethnography, cultural probes, intimate technology, intimacy, tactile interfaces},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055039,
author = {Costanza, Enrico and Inverso, Samuel A. and Allen, Rebecca},
title = {Toward Subtle Intimate Interfaces for Mobile Devices Using an EMG Controller},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055039},
doi = {10.1145/1054972.1055039},
abstract = {Using a mobile device in a social context should not cause embarrassment and disruption to the immediate environment. Interaction with mobile and wearable devices needs to be subtle, discreet and unobtrusive. Therefore, we promote the idea of "intimate interfaces": discrete interfaces that allow control of mobile devices through subtle gestures in order to gain social acceptance. To achieve this goal, we present an electromyogram (EMG) based wearable input device which recognizes isometric muscular activity: activity related to very subtle or no movement at all. In the online experiment reported, the EMG device, worn on an armband around the bicep, was able to reliably recognize a motionless gesture without calibration or training across users with different muscle volumes. Hence, EMG-based input devices can provide an effective solution for designing mobile interfaces that are subtle and intimate, and therefore socially acceptable.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {481–489},
numpages = {9},
keywords = {electromyogram, wearable computing, mobile computing, subtle interaction, intimate interface, social acceptance},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055040,
author = {Anttonen, Jenni and Surakka, Veikko},
title = {Emotions and Heart Rate While Sitting on a Chair},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055040},
doi = {10.1145/1054972.1055040},
abstract = {New methods for unobtrusive monitoring of computer users' emotion psychophysiology are very much needed in human-computer interaction research. The present aim was to study heart rate changes during emotionally provocative stimulation. Six-second long auditory, visual, and audiovisual emotionally negative, neutral, and positive stimuli were presented to 24 participants. Heart rate responses were measured with a regular office chair embedded with electromechanical film (the EMFi chair) and with traditional earlobe photoplethysmography (PPG). Ratings of the stimuli were also collected. The results showed that the two heart rate measurements were significantly correlated, r = 0.99. In line with other studies the results showed that, in general, heart rate decelerated in response to emotional stimulation and it decelerated the most in response to negative stimuli as compared with responses to positive and neutral stimuli. Especially, emotional stimulation caused significant changes in heart rate at the 6th second from the stimulus onset. We suggest that the EMFi chair could be used in human-computer interaction for unobtrusive measurement of the user's emotional reactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {491–499},
numpages = {9},
keywords = {physiological user interfaces, psychophysiology, emotion, wireless monitoring, affective computing, human-computer interaction},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249461,
author = {Winograd, Terry},
title = {Session Details: Assistive Applications},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249461},
doi = {10.1145/3249461},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055042,
author = {Tee, Kimberly and Moffatt, Karyn and Findlater, Leah and MacGregor, Eve and McGrenere, Joanna and Purves, Barbara and Fels, Sidney S.},
title = {A Visual Recipe Book for Persons with Language Impairments},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055042},
doi = {10.1145/1054972.1055042},
abstract = {Cooking is a daily activity for many people. However, traditional text recipes are often prohibitively difficult to follow for people with language disorders, such as aphasia. We have developed a multi-modal application that leverages the retained ability of aphasic individuals to recognize image-based representations of objects, providing a presentation format that can be more easily followed than a traditional text recipe. Through a systematic approach to developing a visual language for cooking, and the subsequent case study evaluation of a prototype developed according to this language, we show that a combination of visual instructions and navigational structure can help individuals with relatively large language deficits to cook more independently.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {501–510},
numpages = {10},
keywords = {aphasia, assistive technology, heuristics, multi-modal interfaces},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055043,
author = {Wu, Mike and Baecker, Ron and Richards, Brian},
title = {Participatory Design of an Orientation Aid for Amnesics},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055043},
doi = {10.1145/1054972.1055043},
abstract = {We present the participatory design and evaluation of an orientation aid for individuals who have anterograde amnesia. Our design team included six amnesics who have extreme difficulty storing new memories. We describe the methods we used to enable the participation of individuals with such severe cognitive impairments. Through this process, we have conceived, designed, and developed the OrientingTool, a software application for Personal Digital Assistants that can be used by amnesics to orient themselves when feeling lost or disoriented. Two complementary studies were conducted to evaluate the effectiveness of this tool in ecologically valid contexts. Our findings suggest that the OrientingTool can improve an amnesic's independence and confidence in managing situations when disoriented, and that participatory design may be productively used with participants who have significant cognitive disabilities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {511–520},
numpages = {10},
keywords = {participatory design, cognitive prosthetics, personal digital assistants, anterograde amnesia, users with disabilities, orientation aids, assistive technologies},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055044,
author = {Rowan, Jim and Mynatt, Elizabeth D.},
title = {Digital Family Portrait Field Trial: Support for Aging in Place},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055044},
doi = {10.1145/1054972.1055044},
abstract = {A growing social problem in the U.S., and elsewhere, is enabling older adults to continue living independently, as opposed to moving to an institutional care setting. One key part of this complex problem is providing awareness of senior adults day-to-day activities, promoting "peace of mind" for extended family members. The Digital Family Portrait (DFP) is one approach to providing peace of mind that has shown promise. To date, research on the DFP has been limited to wizard-of-oz based experiments over short periods of time. This paper describes a DFP field trial in which a private home was instrumented with sensors rather than relying on input from wizard-of-oz technology. This field trial was conducted over a period of one year between an aging parent living alone in her own home and her adult child living 50 miles distant. From this field trial we find that even though there was no critical reason for the adult child to be concerned about his mother, all involved parties found utility in the presence of the DFP, even those family members who were not directly involved in the field trial itself.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {521–530},
numpages = {10},
keywords = {qualitative research, mobile data services, culture},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249462,
author = {Mackay, Wendy},
title = {Session Details: Educational &amp; Help Systems},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249462},
doi = {10.1145/3249462},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055046,
author = {Kam, Matthew and Wang, Jingtao and Iles, Alastair and Tse, Eric and Chiu, Jane and Glaser, Daniel and Tarshish, Orna and Canny, John},
title = {Livenotes: A System for Cooperative and Augmented Note-Taking in Lectures},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055046},
doi = {10.1145/1054972.1055046},
abstract = {We describe Livenotes, a shared whiteboard system and educational practice that uses wireless communication and tablet computing to support real-time conversations within small groups of students during lectures, independent of class size. We present an interface design that enables group members to interact with one another by taking lecture notes cooperatively, as well as to augment student note-taking by providing instructor slides in the background to annotate over. Livenotes was designed to facilitate more efficient, stimulating modes of learning that other collaborative approaches do not. We report how the system impacts cooperative learning in an undergraduate class and how students interacted with background slides in the workspace. We conclude with directions for improving the system and learning practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {531–540},
numpages = {10},
keywords = {education, collaborative learning, computer-supported collaborative learning (CSCL), cooperative note-taking, augmented note-taking, tablet PC, peer instruction, e-learning, small group learning, shared whiteboard, cooperative learning},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055047,
author = {Kelleher, Caitlin and Pausch, Randy},
title = {Stencils-Based Tutorials: Design and Evaluation},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055047},
doi = {10.1145/1054972.1055047},
abstract = {Users of traditional tutorials and help systems often have difficulty finding the components described or pictured in the procedural instructions. Users also unintentionally miss steps, and perform actions that the documentation's authors did not intend, moving the application into an unknown state. We introduce Stencils, an interaction technique for presenting tutorials that uses translucent colored stencils containing holes that direct the user's attention to the correct interface component and prevent the user from interacting with other components. Sticky notes on the stencil's surface provide necessary tutorial material in the context of the application. In a user study comparing a Stencils-based and paper-based version of the same tutorial in Alice, a complex software application designed to teach introductory computer programming, we found that users of a Stencils-based tutorial were able complete the tutorial 26% faster, with fewer errors, and less reliance on human assistance. Users of the Stencils-based and paper-based tutorials attained statistically similar levels of learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {541–550},
numpages = {10},
keywords = {interaction technique, transparent overlay, tutorials, user interface design},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055048,
author = {Yee, Susan and Park, Kat S.},
title = {StudioBRIDGE: Using Group, Location, and Event Information to Bridge Online and Offline Encounters for Co-Located Learning Groups},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055048},
doi = {10.1145/1054972.1055048},
abstract = {StudioBRIDGE is an awareness system, based on instant messaging (IM), developed for students working in open studio spaces in the Architecture Department at the Massachusetts Institute of Technology (MIT). The goal of StudioBRIDGE is to help students initiate online and offline interactions by giving them an awareness of nearby people, groups, locations, and events of the community. Even when students are working in close proximity to each other, they are often not aware of the activities and expertise of their colleagues nearby. We believe that this integrated awareness could lead to increased peer learning and expertise sharing by encouraging informal social communication, particularly in groups whose members have existing social and physical ties. In this paper, we describe the user community and the motivation, design, and initial pilot deployment of StudioBRIDGE.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {551–560},
numpages = {10},
keywords = {informal interactions, opportunistic interfaces, awareness, computer-mediated communication},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249463,
author = {Nass, Clifford},
title = {Session Details: In-Vehicle Interfaces},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249463},
doi = {10.1145/3249463},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055050,
author = {Schneider, Mike and Kiesler, Sara},
title = {Calling While Driving: Effects of Providing Remote Traffic Context},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055050},
doi = {10.1145/1054972.1055050},
abstract = {Cell phone conversations distract drivers. This research explores the possibility of reducing distracting by providing callers with remote information about the driver's traffic. We asked whether providing such contextual information would change the caller's conversation such that drivers would be less distracted. In Experiment 1 we examined this question in a low-fidelity driving simulator; in Experiment 2 we examined this question in a higher fidelity simulator. In both experiments, remote callers and passengers were distracting. Providing traffic information to the remote caller significantly reduced crashes in the low fidelity tests and significantly reduced passing in the high fidelity tests, compared with the control conditions. We consider the implications for development of remote displays or signals to promote driving safety.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {561–569},
numpages = {9},
keywords = {contextual displays, distraction, cell phones, interruption, cognitive load, attention, contextual information, driving},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055051,
author = {Lee, Joonhwan and Forlizzi, Jodi and Hudson, Scott E.},
title = {Studying the Effectiveness of MOVE: A Contextually Optimized in-Vehicle Navigation System},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055051},
doi = {10.1145/1054972.1055051},
abstract = {In-vehicle navigation has changed substantially in recent years, due to the advent of computer generated maps and directions. However, these maps are still problematic, due to a mismatch between the complexity of the maps and the attentional demands of driving. In response to this problem, we are developing the MOVE (Maps Optimized for Vehicular Environments) system. This system will provide situationally appropriate map information by presenting information that uses appropriate amounts of the driver's attention. In this paper, we describe our findings of studies to help shape the design of the MOVE system, including studies on map reading and in-vehicle navigation, and studies on the effectiveness of a variety of contextually optimized route map visualizations in a simulated driving context.Results show that contextually optimized displays designed for the MOVE system should significantly reduce perceptual load in the context of driving. In our laboratory experiment there was a six-fold decrease in the total map display fixation time and nearly threefold decrease in the number of glances needed to interpret the contextually optimized display compared to a static display.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {571–580},
numpages = {10},
keywords = {dynamic displays, maps, visualization, in-car navigation systems, perceptual optimization, human attention},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055052,
author = {Salvucci, Dario D. and Zuber, Mark and Beregovaia, Ekaterina and Markley, Daniel},
title = {Distract-R: Rapid Prototyping and Evaluation of in-Vehicle Interfaces},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055052},
doi = {10.1145/1054972.1055052},
abstract = {As driver distraction from in-vehicle devices increasingly becomes a concern on our roadways, researchers have searched for better scientific understanding of distraction along with better engineering tools to build less distracting devices. This paper presents a new system, Distract-R, that allows designers to rapidly prototype and evaluate new in-vehicle interfaces. The core engine of the system relies on a rigorous cognitive model of driver performance, which the system integrates with models of behavior on the prototyped interfaces to generate predictions of distraction. Distract-R allows a designer to prototype basic interfaces, demonstrate possible tasks on these interfaces, specify relevant driver characteristics and driving scenarios, and finally simulate, visualize, and analyze the resulting behavior as generated by the cognitive model. The paper includes two sample studies that demonstrate the system's ability to account for effects of input modality and driver age on performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {581–589},
numpages = {9},
keywords = {distraction, driving, cognitive modeling},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249464,
author = {Beaudouin-Lafon, Michel},
title = {Session Details: Physical Interaction},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249464},
doi = {10.1145/3249464},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055054,
author = {Holman, David and Vertegaal, Roel and Altosaar, Mark and Troje, Nikolaus and Johns, Derek},
title = {Paper Windows: Interaction Techniques for Digital Paper},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055054},
doi = {10.1145/1054972.1055054},
abstract = {In this paper, we present Paper Windows, a prototype windowing environment that simulates the use of digital paper displays. By projecting windows on physical paper, Paper Windows allows the capturing of physical affordances of paper in a digital world. The system uses paper as an input device by tracking its motion and shape with a Vicon Motion Capturing System. We discuss the design of a number of interaction techniques for manipulating information on paper displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {591–599},
numpages = {9},
keywords = {ubiquitous computing, digital paper interfaces, flexible displays},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055055,
author = {Kruger, Russell and Carpendale, Sheelagh and Scott, Stacey D. and Tang, Anthony},
title = {Fluid Integration of Rotation and Translation},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055055},
doi = {10.1145/1054972.1055055},
abstract = {Previous research has shown that rotation and orientation of items plays three major roles during collaboration: comprehension, coordination and communication. Based on these roles of orientation and advice from kinesiology research, we have designed the Rotate'N Translate (RNT) interaction mechanism, which provides integrated control of rotation and translation using only a single touch-point for input. We present an empirical evaluation comparing RNT to a common rotation mechanism that separates control of rotation and translation. Results of this study indicate RNT is more efficient than the separate mechanism and better supports the comprehension, coordination and communication roles of orientation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {601–610},
numpages = {10},
keywords = {tabletop collaboration, roles of orientation, fluid interactions, translation, communicative gestures, rotation, orientation},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055056,
author = {Voida, Stephen and Podlaseck, Mark and Kjeldsen, Rick and Pinhanez, Claudio},
title = {A Study on the Manipulation of 2D Objects in a Projector/Camera-Based Augmented Reality Environment},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055056},
doi = {10.1145/1054972.1055056},
abstract = {Are the object manipulation techniques traditionally used in head-mounted displays (HMDs) applicable to augmented reality based projection systems? This paper examines the differences between HMD- and projector/camera-based AR interfaces in the light of a manipulation task involving documents and applications projected on common office surfaces such as tables, walls, cabinets, and floor. We report a Wizard of Oz study where subjects were first asked to create gesture/voice commands to move 2D objects on those surfaces and then exposed to gestures created by the authors. Among the options, subjects could select the object to be manipulated using voice command; touching, pointing, and grabbing gesture; or a virtual mouse. The results show a strong preference for a manipulation interface based on pointing gestures using small hand movements and involving minimal body movement. Direct touching of the object was also common when the object being manipulated was within the subjects' arm reach. Based on these results, we expect that the preferred interface resembles, in many ways, the egocentric model traditionally used in AR.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {611–620},
numpages = {10},
keywords = {user-centered design, augmented reality, Wizard of Oz study, augmented workspaces},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249465,
author = {H\"{o}\"{o}k, Kristina},
title = {Session Details: Technology in the Home},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249465},
doi = {10.1145/3249465},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055058,
author = {Shklovski, Irina A. and Mainwaring, Scott D.},
title = {Exploring Technology Adoption and Use through the Lens of Residential Mobility},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055058},
doi = {10.1145/1054972.1055058},
abstract = {One of the outcomes of massive adoption of technology is that much of daily technology use and consumption is embedded into "unremarkable" daily life routines. Occasionally, these routines undergo major shifts, often in conjunction with major life events such as marriage, birth of a child, or a residential move. We propose a model of settling into a new location as a function of balance between the pull of the things left behind and the demands of the new and unknown. It is through this experience of being unsettled that we explore the processes of behavior adjustment and re-evaluation of old patterns of technology use as it relates to the old location and the demands of the new location.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {621–630},
numpages = {10},
keywords = {ethnography, behavioral science, technology adoption, social relationships, residential mobility},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055059,
author = {Arroyo, Ernesto and Bonanni, Leonardo and Selker, Ted},
title = {Waterbot: Exploring Feedback and Persuasive Techniques at the Sink},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055059},
doi = {10.1145/1054972.1055059},
abstract = {This paper presents an exploration of user interfaces, persuasive interfaces and feedback techniques in the domain of the sink. Waterbot is a system to inform and motivate behavior at the sink for the purpose of increasing safety and functionality and ultimately motivating behavior change. Waterbot can be adapted to many current sink scenarios and demonstrates the breadth of interaction possible at the point of use of water. It functions as a platform for experimenting with safety, hygiene and water conservation in a sink. This paper presents the feedback and persuasion techniques of augmented physical interfaces with value-added design, automation, just-in-time prompts, positive and negative reinforcement, social validation and adaptive interfaces. Four design iterations are presented to affect behavior at the increasing cognitive levels of safety, functionality and behavior change.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {631–639},
numpages = {9},
keywords = {ubiquitous computing, captology, product design, water conservation, behavior change, persuasive environments, context-aware computing},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055060,
author = {Taylor, Alex S. and Swan, Laurel},
title = {Artful Systems in the Home},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055060},
doi = {10.1145/1054972.1055060},
abstract = {In this paper we introduce the idea of organizing systems. Through a number of examples from an ongoing ethnographic study of family life, we suggest that organizing systems come about through the artful design and use of informational artifacts in the home, such as calendars, paper notes, to-do lists, etc. These systems are not only seen to organize household routines and schedules, but also, crucially, to shape the social relations between family members. Drawing attention to the material properties of informational artifacts and how assemblies of these artifacts come to make up organizing systems, we discuss some general implications for designing information technology for the home. Most importantly, we suggest that technologies must be designed to accommodate the rich and diverse ways in which people organize their homes, providing them with the resources to artfully construct their own systems rather than enforcing ones that are removed from their own experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {641–650},
numpages = {10},
keywords = {ethnography, information devices, ubiquitous computing, home life, mothers' work, domestic life},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249466,
author = {van der Veer, Gerrit},
title = {Session Details: Safety in a Complex World},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249466},
doi = {10.1145/3249466},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055062,
author = {Johnson, C. W.},
title = {Applying the Lessons of the Attack on the World Trade Center, 11th September 2001, to the Design and Use of Interactive Evacuation Simulations},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055062},
doi = {10.1145/1054972.1055062},
abstract = {The collapse of buildings, such as terminal 2E at Paris' Charles de Gaule Airport, and of fires, such as the Rhode Island, Station Night Club tragedy, has focused public attention on the safety of large public buildings. Initiatives in the United States and in Europe have led to the development of interactive simulators that model evacuation from these buildings. The tools avoid some of the ethical and legal problems from simulating evacuations; many people were injured during the 1993 evacuation of the World Trade Center (WTC) complex. They also use many concepts that originate within the CHI communities. For instance, some simulators use simple task models to represent the occupants' goal structures as they search for an available exit. However, the recent release of the report from the National Commission on Terrorist Attacks upon the United States (the '9/11 commission') has posed serious questions about the design and use of this particular class of interactive systems. This paper argues that simulation research needs to draw on insights from the CHI communities in order to meet some the challenges identified by the 9/11 commission.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {651–660},
numpages = {10},
keywords = {safety, evacuation, user modeling, simulation},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249467,
author = {Bederson, Ben},
title = {Session Details: Small Devices 2},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249467},
doi = {10.1145/3249467},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055064,
author = {Choi, Boreum and Lee, Inseong and Kim, Jinwoo and Jeon, Yunsuk},
title = {A Qualitative Cross-National Study of Cultural Influences on Mobile Data Service Design},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055064},
doi = {10.1145/1054972.1055064},
abstract = {As the use of mobile data services has spread across the globe, the effect of cultural differences on user requirements has become important issue. To date, however, little research has been conducted on the role cultural factors play in the design of mobile data services. This paper proposes a set of critical design attributes for mobile data services that takes cross-cultural differences into account. To determine these attributes, we devised a qualitative method and conducted in-depth long interviews in Korea, Japan, and Finland. We found 52 attributes considered important by mobile data service users, and 11 critical attributes that showed a clear correlation with characteristics of the user's culture. The paper concludes with a discussion of limitations and of implications for developers of mobile data services.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {661–670},
numpages = {10},
keywords = {qualitative research, mobile data services, culture},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055065,
author = {Xie, Xing and Liu, Hao and Goumaz, Simon and Ma, Wei-Ying},
title = {Learning User Interest for Image Browsing on Small-Form-Factor Devices},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055065},
doi = {10.1145/1054972.1055065},
abstract = {Mobile devices which can capture and view pictures are becoming increasingly common in our life. The limitation of these small-form-factor devices makes the user experience of image browsing quite different from that on desktop PCs. In this paper, we first present a user study on how users interact with a mobile image browser with basic functions. We found that on small displays, users tend to use more zooming and scrolling actions in order to view interesting regions in detail. From this fact, we designed a new method to detect user interest maps and extract user attention objects from the image browsing log. This approach is more efficient than image-analysis based methods and can better represent users' actual interest. A smart image viewer was then developed based on user interest analysis. A second experiment was carried out to study how users behave with such a viewer. Experimental results demonstrate that the new smart features can improve the browsing efficiency and are a good compliment to traditional image browsers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {671–680},
numpages = {10},
keywords = {small display, mobile image browsing, attention model},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055066,
author = {Lam, Heidi and Baudisch, Patrick},
title = {Summary Thumbnails: Readable Overviews for Small Screen Web Browsers},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055066},
doi = {10.1145/1054972.1055066},
abstract = {In order to display web pages designed for desktop-sized monitors, some small-screen web browsers provide single-column or thumbnail views. Both have limitations. Single-column views affect page layouts and require users to scroll significantly more. Thumbnail views tend to reduce contained text beyond readability, so differentiating visually similar areas requires users to zoom. In this paper, we present Summary Thumbnails-thumbnail views enhanced with readable text fragments. Summary Thumbnails help users identify viewed material and distinguish between visually similar areas. In our user study, participants located content in web pages about 41% faster and with 71% lower error rates when using the Summary Thumbnail interface than when using the Single-Column interface, and zoomed 59% less than when using the Thumbnail interface. Nine of the eleven participants preferred Summary Thumbnails over both the Thumbnail and Single-Column interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {681–690},
numpages = {10},
keywords = {overview, semantic zoomingblutwurst, web browsing, thumbnail view, PDA, small screen device},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249468,
author = {Bellotti, Victoria},
title = {Session Details: Email and Security},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249468},
doi = {10.1145/3249468},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055068,
author = {Dabbish, Laura A. and Kraut, Robert E. and Fussell, Susan and Kiesler, Sara},
title = {Understanding Email Use: Predicting Action on a Message},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055068},
doi = {10.1145/1054972.1055068},
abstract = {Email consumes significant time and attention in the workplace. We conducted an organizational survey to understand how and why people attend to incoming email messages. We examined people's ratings of message importance and the actions they took on specific email messages, based on message characteristics and characteristics of receivers and senders. Respondents kept half of their new messages in the inbox and replied to about a third of them. They rated messages as important if they were about work and required action. Importance, in turn, had a modest impact on whether people replied to their incoming messages and whether they saved them. The results indicate that factors other than message importance (e.g., their social nature) also determine how people handle email. Overall, email usage reflects attentional differences due both to personal propensities and to work demands and relationships.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {691–700},
numpages = {10},
keywords = {filtering, intelligent agents, computer-mediated, email, electronic mail, communication, messaging},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055069,
author = {Garfinkel, Simson L. and Margrave, David and Schiller, Jeffrey I. and Nordlander, Erik and Miller, Robert C.},
title = {How to Make Secure Email Easier to Use},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055069},
doi = {10.1145/1054972.1055069},
abstract = {Cryptographically protected email has a justly deserved reputation of being difficult to use. Based on an analysis of the PEM, PGP and S/MIME standards and a survey of 470 merchants who sell products on Amazon.com, we argue that the vast majority of Internet users can start enjoying digitally signed email today. We present suggestions for the use of digitally signed mail in e-commerce and simple modifications to webmail systems that would significantly increase integrity, privacy and authorship guarantees that those systems make. We then show how to use the S/MIME standard to extend such protections Internet-wide. Finally, we argue that software vendors must make minor changes to the way that mail clients store email before unsophisticated users can safely handle mail that is sealed with encryption.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {701–710},
numpages = {10},
keywords = {e-commerce, user interaction design, user studies},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055070,
author = {Chellapilla, Kumar and Larson, Kevin and Simard, Patrice and Czerwinski, Mary},
title = {Designing Human Friendly Human Interaction Proofs (HIPs)},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055070},
doi = {10.1145/1054972.1055070},
abstract = {HIPs, or Human Interactive Proofs, are challenges meant to be easily solved by humans, while remaining too hard to be economically solved by computers. HIPs are increasingly used to protect services against automatic script attacks. To be effective, a HIP must be difficult enough to discourage script attacks by raising the computation and/or development cost of breaking the HIP to an unprofitable level. At the same time, the HIP must be easy enough to solve in order to not discourage humans from using the service. Early HIP designs have successfully met these criteria [1]. However, the growing sophistication of attackers and correspondingly increasing profit incentives have rendered most of the currently deployed HIPs vulnerable to attack [2,7,12]. Yet, most companies have been reluctant to increase the difficulty of their HIPs for fear of making them too complex or unappealing to humans. The purpose of this study is to find the visual distortions that are most effective at foiling computer attacks without hindering humans. The contribution of this research is that we discovered that 1) automatically generating HIPs by varying particular distortion parameters renders HIPs that are too easy for computer hackers to break, yet humans still have difficulty recognizing them, and 2) it is possible to build segmentation-based HIPs that are extremely difficult and expensive for computers to solve, while remaining relatively easy for humans.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {711–720},
numpages = {10},
keywords = {visual letter recognition, completely automated public turing tests to tell computers and humans apart (CAPTCHAs), evaluation, human perception, computer vision, human interaction proofs (HIPs)},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249469,
author = {Erickson, Tom},
title = {Session Details: Public Life},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249469},
doi = {10.1145/3249469},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055072,
author = {Benford, Steve and Rowland, Duncan and Flintham, Martin and Drozd, Adam and Hull, Richard and Reid, Josephine and Morrison, Jo and Facer, Keri},
title = {Life on the Edge: Supporting Collaboration in Location-Based Experiences},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055072},
doi = {10.1145/1054972.1055072},
abstract = {We study a collaborative location-based game in which groups of 'lions' hunt together on a virtual savannah that is overlaid on an open playing field. The game implements a straight-forward approach to location-based triggering in which players must be in the same spatial locale in order to share information and act together. Comparison of video recordings of physical play with system recordings of game events reveals subtle and complex interactions between highly dynamic player behavior and the underlying technology. While players exhibit a fluid approach to group formation, the system embodies a more rigid view, leading to difficulties with sharing context and coordinating actions, most notably when groups of players span virtual locale boundaries or initiate actions while on the move. We propose techniques for extending locales to support more flexible grouping and also discuss the broader implications of our findings for location-based applications in general.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {721–730},
numpages = {10},
keywords = {ubiquitous, collaborative, education, games, mobile, location-based, shared-context, study},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055073,
author = {Lee, Eric and Wolf, Marius and Borchers, Jan},
title = {Improving Orchestral Conducting Systems in Public Spaces: Examining the Temporal Characteristics and Conceptual Models of Conducting Gestures},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055073},
doi = {10.1145/1054972.1055073},
abstract = {Designing interactive conducting exhibits for public spaces poses unique challenges, primarily because the conceptual model of conducting music varies amongst users. In a user study, we compared how conductors and non-conductors place their beats when conducting to a fixed orchestral recording of Radetzky March, and found significant differences between these two groups. Conductors lead the actual music beat with their gestures by an average of 150 ms, compared to 50 ms for non-conductors; non-conductors also vary their placement of the beat 50% more than conductors. Furthermore, we found differences in how users conceptually mapped their gestures to the music, such as conducting to the musical rhythm rather than to the beat. We are incorporating these results into an upcoming conducting system for public spaces to increase its usability; we believe they also apply to a more general class of musical gestures such as dance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {731–740},
numpages = {10},
keywords = {gestures, conceptual models, exhibits, empirical study, music interfaces, conducting},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055074,
author = {Reeves, Stuart and Benford, Steve and O'Malley, Claire and Fraser, Mike},
title = {Designing the Spectator Experience},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055074},
doi = {10.1145/1054972.1055074},
abstract = {Interaction is increasingly a public affair, taking place in our theatres, galleries, museums, exhibitions and on the city streets. This raises a new design challenge for HCI - how should spectators experience a performer's interaction with a computer? We classify public interfaces (including examples from art, performance and exhibition design) according to the extent to which a performer's manipulations of an interface and their resulting effects are hidden, partially revealed, fully revealed or even amplified for spectators. Our taxonomy uncovers four broad design strategies: 'secretive,' where manipulations and effects are largely hidden; 'expressive,' where they tend to be revealed enabling the spectator to fully appreciate the performer's interaction; 'magical,' where effects are revealed but the manipulations that caused them are hidden; and finally 'suspenseful,' where manipulations are apparent but effects are only revealed as the spectator takes their turn.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {741–750},
numpages = {10},
keywords = {spectators, public experiences, performance, museums, magic, art, galleries, expression, design framework},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@dataset{10.1145/review-1054972.1055074_R40951,
author = {Podolsky, Joe L.},
title = {Review ID:R40951 for DOI: 10.1145/1054972.1055074},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1054972.1055074_R40951}
}

@inproceedings{10.1145/3249470,
author = {Farnham, Shelly},
title = {Session Details: Social Behaviors},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249470},
doi = {10.1145/3249470},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055076,
author = {Flanagan, Mary and Howe, Daniel C. and Nissenbaum, Helen},
title = {Values at Play: Design Tradeoffs in Socially-Oriented Game Design},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055076},
doi = {10.1145/1054972.1055076},
abstract = {Significant work in the CHI community has focused on designing systems that support human values. Designers and engineers have also become increasingly aware of ways in which the artifacts they create can embody political, social, and ethical values. Despite such an awareness, there has been little work towards producing practical methodologies that systematically incorporate values into the design process. Many designers struggle to find a balance between their own values, those of users and other stakeholders, and those of the surrounding culture. In this paper, we present the RAPUNSEL project as a case study of game design in a values-rich context and describe our efforts toward navigating the complexities this entails. Additionally, we present initial steps toward the development of a systematic methodology for discovery, analysis, and integration of values in technology design in the hope that others may both benefit from and build upon this work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {751–760},
numpages = {10},
keywords = {programming pedagogy, gender and computing, values, social issues},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249471,
author = {Olsen, Dan},
title = {Session Details: Display},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249471},
doi = {10.1145/3249471},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055078,
author = {Rosenholtz, Ruth and Li, Yuanzhen and Mansfield, Jonathan and Jin, Zhenlan},
title = {Feature Congestion: A Measure of Display Clutter},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055078},
doi = {10.1145/1054972.1055078},
abstract = {Management of clutter is an important factor in the design of user interfaces and information visualizations, allowing improved usability and aesthetics. However, clutter is not a well defined concept. In this paper, we present the Feature Congestion measure of display clutter. This measure is based upon extensive modeling of the saliency of elements of a display, and upon a new operational definition of clutter. The current implementation is based upon two features: color and luminance contrast. We have tested this measure on maps that observers ranked by perceived clutter. Results show good agreement between the observers' rankings and our measure of clutter. Furthermore, our measure can be used to make design suggestions in an automated UI critiquing tool.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {761–770},
numpages = {10},
keywords = {clutter, information density, feature congestion, visualization, recommender systems, visual interfaces, display design},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055079,
author = {Skopik, Amy and Gutwin, Carl},
title = {Improving Revisitation in Fisheye Views with Visit Wear},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055079},
doi = {10.1145/1054972.1055079},
abstract = {The distortion caused by an interactive fisheye lens can make it difficult for people to remember items and locations in the data space. In this paper we introduce the idea of visit wear - a visual representation of the places that the user has previously visited - as a way to improve navigation in spaces affected by distortion. We outline the design dimensions of visit wear, and report on two studies. The first shows that increasing the distortion of a fisheye view does significantly reduce people's ability to remember object locations. The second study looks at the effects of visit wear on performance in revisitation tasks, and shows that both completion time and error rates are significantly improved when visit wear is present. Visit wear works by changing the revisitation problem from one of memory to one of visual search. Although there are limitations to the technique, visit wear has the potential to substantially improve the usability both of fisheye views and of graphical information spaces more generally.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {771–780},
numpages = {10},
keywords = {spatial memory, edit wear, visit wear, focus+context techniques, memorability, fisheye views, fisheye usability},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249472,
author = {Russell, Daniel},
title = {Session Details: Enhancing Virtual Spaces and Large Displays},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249472},
doi = {10.1145/3249472},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055081,
author = {H\"{a}m\"{a}l\"{a}inen, Perttu and Ilmonen, Tommi and H\"{o}ysniemi, Johanna and Lindholm, Mikko and Nyk\"{a}nen, Ari},
title = {Martial Arts in Artificial Reality},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055081},
doi = {10.1145/1054972.1055081},
abstract = {This paper presents Kick Ass Kung-Fu, a martial arts game installation where the player fights virtual enemies with kicks and punches as well as acrobatic moves such as cartwheels. Using real-time image processing and computer vision, the video image of the user is embedded inside 3D graphics. Compared to previous work, our system uses a profile view and two displays, which allows an improved view of many martial arts techniques. We also explore exaggerated motion and dynamic slow-motion effects to transform the aesthetic of kung-fu movies into an interactive, embodied experience. The system is described and analyzed based on results from testing the game in a theater, in a television show, and in a user study with 46 martial arts practitioners.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {781–790},
numpages = {10},
keywords = {kung-fu, computer vision, artificial reality, martial arts},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055082,
author = {Khan, Azam and Matejka, Justin and Fitzmaurice, George and Kurtenbach, Gordon},
title = {Spotlight: Directing Users' Attention on Large Displays},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055082},
doi = {10.1145/1054972.1055082},
abstract = {We describe a new interaction technique, called a spotlight, for directing the visual attention of an audience when viewing data or presentations on large wall-sized displays. A spotlight is simply a region of the display where the contents are displayed normally while the remainder of the display is somewhat darkened. In this paper we define the behavior of spotlights, show unique affordances of the technique, and discuss design characteristics. We also report on experiments that show the benefit of using the spotlight a large display and standard desktop configuration. Our results suggest that the spotlight is preferred over the standard cursor and outperforms it by a factor of 3.4 on a wall-sized display.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {791–798},
numpages = {8},
keywords = {user study, field of view, large displays, attention},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249473,
author = {Stone, Maria},
title = {Session Details: Look},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249473},
doi = {10.1145/3249473},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055084,
author = {Nguyen, David and Canny, John},
title = {MultiView: Spatially Faithful Group Video Conferencing},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055084},
doi = {10.1145/1054972.1055084},
abstract = {MultiView is a new video conferencing system that supports collaboration between remote groups of people. MultiView accomplishes this by being spatially faithful. As a result, MultiView preserves a myriad of nonverbal cues, includ-ing gaze and gesture, in a way that should improve com-munication. Previous systems fail to support many of these cues because a single camera perspective warps spatial char-acteristics in group-to-group meetings. In this paper, we present a formal definition of spatial faithfulness. We then apply a metaphor-based design methodology to help us spec-ify and evaluate MultiView's support of spatial faithfulness. We then present results from a low-level user study to mea-sure MultiView's effectiveness at conveying gaze and ges-ture perception. MultiView is the first practical solution to spatially faithful group-to-group conferencing, one of the most common applications of video conferencing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {799–808},
numpages = {10},
keywords = {eye contact, video conferencing, deixis, gaze, spatial faithfulness},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249474,
author = {Hinckley, Ken},
title = {Session Details: Papers on Presenting Papers},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249474},
doi = {10.1145/3249474},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055086,
author = {Wang, QianYing and Nass, Clifford},
title = {Less Visible and Wireless: Two Experiments on the Effects of Microphone Type on Users' Performance and Perception},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055086},
doi = {10.1145/1054972.1055086},
abstract = {When devices become less visible and recede to the background, what kinds of influences would they have on users'? This paper presents two experiments (N=48 and N=96) that examine the effects of four different types of microphones (and voice vs. text output) on user's behaviors and attitudes. The microphones differ with respect to their visibility and users' mobility. Participants performed two different tasks: a standard creativity task and a standard disclosure task. Mobility facilitated creativity and disclosure of personal information. Recording reminder discouraged creativity and disclosure. Output modality had no significant effect. Implications for ubiquitous computing and voice user interfaces are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {809–818},
numpages = {10},
keywords = {device visibility, wireless device, recording reminder, creativity, output modality, voice I/O, mobility, uniqueness, microphone array, fluency, ubiquitous computing, flexibility, disclosure},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249475,
author = {Inkpen, Kori},
title = {Session Details: Designing for and with Kids},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249475},
doi = {10.1145/3249475},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055088,
author = {Williams, Morris and Jones, Owain and Fleuriot, Constance and Wood, Lucy},
title = {Children and Emerging Wireless Technologies: Investigating the Potential for Spatial Practice},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055088},
doi = {10.1145/1054972.1055088},
abstract = {In this paper, we describe design work with 36 children aged 9 and 10 in Bristol, United Kingdom. The design work was conducted using emerging mobile and wireless technology which has the potential to impact on the problematic issue of children's access to, use of, and safety within the wider urban environment. A series of workshops are described in which children were encouraged to think about their use of an outdoor space before their introduction to the technology. The children designed and created "soundscapes" in the outdoor environment. The future potential impact of the technology on children's spatial practice is discussed and the concept of children "tagging" environmental hazards is raised.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {819–828},
numpages = {10},
keywords = {augmented reality, safety, design workshops, soundscapes, children, urban, mobility},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055089,
author = {Chiasson, Sonia and Gutwin, Carl},
title = {Testing the Media Equation with Children},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055089},
doi = {10.1145/1054972.1055089},
abstract = {Designers of children's technology are often more interested in user motivation than those who design systems for adults. Since children's technology often has aims such as education or practice, keeping the user engaged and interested is an important objective. The Media Equation - the idea that people respond socially to computers - shows potential for improving engagement and motivation. Studies have shown that people are more positive about both themselves and the computer when software exhibits certain social characteristics. To explore the possible value of the Media Equation as a design concept for children's software, we replicated two of the original Media Equation studies, concerning the effects of praise and team formation. Our results, however, were contrary to our expectations: we did not find evidence that children were significantly affected by social characteristics in software, and adults were influenced in only a few cases. These results raise questions about using the Media Equation as a design principle for children's software.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {829–838},
numpages = {10},
keywords = {media equation, children's technology, CASA},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055090,
author = {Lamberty, K. K. and Kolodner, Janet L.},
title = {Camera Talk: Making the Camera a Partial Participant},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055090},
doi = {10.1145/1054972.1055090},
abstract = {In this paper, we describe how encouraging children to talk to the camera can structure their behavior and provide them opportunity for reflection. Encouraging "camera talk," interactions directed at the camera, can effectively elicit verbal comments from children participants. We describe a study in which children participants were told that they could tell the camera anything they wanted to about the designs they were making using a piece of educational software, but not to behave in a disruptive manner for the camera. By allowing children to interact with the camera in a particular way, rather than encouraging them to ignore its presence, we were able to elicit information about some children's design activities, thoughts, and struggles. The camera became an integral part of the socio-technical system for some children. This method may be useful to researchers interested in what children are thinking about in-the-moment as they work with software.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {839–848},
numpages = {10},
keywords = {children, video data, data collection method, educational software, learning through design, reflection},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249476,
author = {Canny, John},
title = {Session Details: Educational Issues},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249476},
doi = {10.1145/3249476},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055092,
author = {Louca, Loucas},
title = {The Syntax or the Story behind It? A Usability Study of Student Work with Computer-Based Programming Environments in Elementary Science},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055092},
doi = {10.1145/1054972.1055092},
abstract = {This is a descriptive case study investigating the use of two computer-based programming environments (CPEs), MicroWorlds™ Logo (MW) and Stagecast Creator™ (SC) for collaborative scientific modeling. The purpose of the study was to investigate and comparatively describe student approaches to scientific modeling through the use of textual or graphical program languages (PL). I analyzed student activities and conversations in two after-school clubs, one working with MW and the other with SC, using contextual inquiry, analysis of student conversation and artifact analysis. The findings suggest that student work with CPEs differed between different PL. Students used SC to create games (focusing on the overall story) whereas MW students used MW through a frame of formal programming. Programming in SC was much easier than MW, whereas reading code in MW was more tangible. Findings suggest that differences in student approaches to scientific modeling through programming need to be considered by educators seeking to engage students in such activities and software developers seeking to develop CPEs for young learners.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {849–858},
numpages = {10},
keywords = {computer-based programming environments, object-oriented interface, procedural programming, scientific modeling},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055093,
author = {Zuckerman, Oren and Arida, Saeed and Resnick, Mitchel},
title = {Extending Tangible Interfaces for Education: Digital Montessori-Inspired Manipulatives},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055093},
doi = {10.1145/1054972.1055093},
abstract = {This paper introduces a new framework for thinking about tangible interfaces in education, with specific focus on abstract problem domains.Manipulatives are physical objects specifically designed to foster learning. We offer a new classification of Manipulatives: "Froebel-inspired Manipulatives" (FiMs) and "Montessori-inspired Manipulatives" (MiMs). We argue that FiMs are design materials, fostering modeling of real-world structures, while MiMs foster modeling of more abstract structures. We show that our classification extends to computationally enhanced versions of manipulatives.We present Digital MiMs - computationally enhanced building blocks. We describe two prototypical members of the Digital MiMs class: FlowBlocks and SystemBlocks, physical, modular interactive systems that serve as general-purpose modeling and simulation tools for dynamic behavior. We present findings from qualitative studies, and conclude that digital MiMs are accessible to young children, engaging, and encourage learning of abstract structures of dynamic behavior through an iterative process of hands-on modeling, simulating, and analogizing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {859–868},
numpages = {10},
keywords = {education, simulation, digital manipulatives, TUI, toys},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055094,
author = {Beckwith, Laura and Burnett, Margaret and Wiedenbeck, Susan and Cook, Curtis and Sorte, Shraddha and Hastings, Michelle},
title = {Effectiveness of End-User Debugging Software Features: Are There Gender Issues?},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055094},
doi = {10.1145/1054972.1055094},
abstract = {Although gender differences in a technological world are receiving significant research attention, much of the research and practice has aimed at how society and education can impact the successes and retention of female computer science professionals-but the possibility of gender issues within software has received almost no attention. If gender issues exist with some types of software features, it is possible that accommodating them by changing these features can increase effectiveness, but only if we know what these issues are. In this paper, we empirically investigate gender differences for end users in the context of debugging spreadsheets. Our results uncover significant gender differences in self-efficacy and feature acceptance, with females exhibiting lower self-efficacy and lower feature acceptance. The results also show that these differences can significantly reduce females' effectiveness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {869–878},
numpages = {10},
keywords = {gender, debugging, surprise-explain-reward, end-user programming, end-user software engineering},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249477,
author = {Jeffries, Robin},
title = {Session Details: Understanding Users and Usage Patterns},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249477},
doi = {10.1145/3249477},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055096,
author = {Millen, David R. and Muller, Michael J. and Geyer, Werner and Wilcox, Eric and Brownholtz, Beth},
title = {Patterns of Media Use in an Activity-Centric Collaborative Environment},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055096},
doi = {10.1145/1054972.1055096},
abstract = {This paper describes a new collaboration technology that is based on the support of lightweight, informally structured, opportunistic activities featuring heterogeneous threads of shared items with dynamic membership. We introduce our design concepts, and we provide a detailed analysis of user behavior during a five month field study. We present the patterns of media use that we observed, using a variety of analytical methods including thread clustering and analysis. Major findings include four patterns of media use: communicating, exchanging mixed objects, coordinating, (e.g., of status reports), and semi-archival filing. We observed differential use of various media including highly variable use of chats and surprisingly informal uses of files. We discuss the implications for the design of mixed media collaborative tools to support the work activities of small to medium sized work teams.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {879–888},
numpages = {10},
keywords = {computer-mediated communication, CSCW, user study, synchronous/asynchronous collaboration, activity-cen-tric collaboration},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055097,
author = {Brush, A.J. Bernheim and Wang, Xiaoqing and Turner, Tammara Combs and Smith, Marc A.},
title = {Assessing Differential Usage of Usenet Social Accounting Meta-Data},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055097},
doi = {10.1145/1054972.1055097},
abstract = {We describe a usage study of NetscanTech, a system that generates and publishes daily a range of social metrics across three dimensions: newsgroup, author, and thread, for a set of approximately 15,000 technical newsgroups in Usenet. We bring together three interlinked datasets: survey data, usage log data and social accounting data from Usenet participation, to triangulate the relationship between various user roles and differential usage of social metrics in NetscanTech. We found our most frequent users focused on information related to individual authors far more than any other information provided. In contrast, users that visited less frequently focused more on information related to newsgroups and viewing newsgroup metrics. Our results suggest features that designers and developers of online communities may wish to include in their interfaces to support the cultivation of different community roles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {889–898},
numpages = {10},
keywords = {social accounting metrics, newsgroups, reporting tools, authors, threaded discussions, posters, usenet, community, assessment, posts},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055098,
author = {Carter, Scott and Mankoff, Jennifer},
title = {When Participants Do the Capturing: The Role of Media in Diary Studies},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055098},
doi = {10.1145/1054972.1055098},
abstract = {In this paper, we investigate how the choice of media for capture and access affects the diary study method. The diary study is a method of understanding participant behavior and intent in situ that minimizes the effects of observers on participants. We first situate diary studies within a framework of field studies and review related literature. We then report on three diary studies we conducted that involve photographs, audio recordings, location information and tangible artifacts. We then analyze our findings, specifically addressing the following questions: How do context information and episodic memory prompts captured by participants vary with media? In what way do different media "jog" memory? How do different media affect the diary study process? These questions are particularly important for diary studies because they can be especially useful as compared to other methods when a participant intends to do an action but does not or when actions are particularly difficult to sense. We also built and tested a tool based on participant and researcher frustrations with the method. Our contribution includes suggested modifications to traditional diary techniques that enable annotation and review of captured media; a new variation on the diary study appropriate for researchers using digital capture media; and a lightweight tool to support it, motivated by past work and findings from our studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {899–908},
numpages = {10},
keywords = {qualitative methods, diary studies},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/3249478,
author = {Tang, John},
title = {Session Details: Interruptions and Attention 2: Attending to Interruptions},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3249478},
doi = {10.1145/3249478},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055100,
author = {Ho, Joyce and Intille, Stephen S.},
title = {Using Context-Aware Computing to Reduce the Perceived Burden of Interruptions from Mobile Devices},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055100},
doi = {10.1145/1054972.1055100},
abstract = {The potential for sensor-enabled mobile devices to proactively present information when and where users need it ranks among the greatest promises of ubiquitous computing. Unfortunately, mobile phones, PDAs, and other computing devices that compete for the user's attention can contribute to interruption irritability and feelings of information overload. Designers of mobile computing interfaces, therefore, require strategies for minimizing the perceived interruption burden of proactively delivered messages. In this work, a context-aware mobile computing device was developed that automatically detects postural and ambulatory activity transitions in real time using wireless accelerometers. This device was used to experimentally measure the receptivity to interruptions delivered at activity transitions relative to those delivered at random times. Messages delivered at activity transitions were found to be better received, thereby suggesting a viable strategy for context-aware message delivery in sensor-enabled mobile computing devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {909–918},
numpages = {10},
keywords = {mobile computing, context-aware computing, interruption, human-computer interface},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1054972.1055101,
author = {Oulasvirta, Antti and Tamminen, Sakari and Roto, Virpi and Kuorelahti, Jaana},
title = {Interaction in 4-Second Bursts: The Fragmented Nature of Attentional Resources in Mobile HCI},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055101},
doi = {10.1145/1054972.1055101},
abstract = {When on the move, cognitive resources are reserved partly for passively monitoring and reacting to contexts and events, and partly for actively constructing them. The Re-source Competition Framework (RCF), building on the Multiple Resources Theory, explains how psychosocial tasks typical of mobile situations compete for cognitive resources and then suggests that this leads to the depletion of resources for task interaction and eventually results in the breakdown of fluent interaction. RCF predictions were tested in a semi-naturalistic field study measuring attention during the performance of assigned Web search tasks on mobile phone while moving through nine varied but typical urban situations. Notably, we discovered up to eight-fold differentials between micro-level measurements of atten-tional resource fragmentation, for example from spans of over 16 seconds in a laboratory condition dropping to bursts of just a few seconds in difficult mobile situations. By cali-brating perceptual sampling, reducing resources from tasks of secondary importance, and resisting the impulse to switch tasks before finalization, participants compensated for the resource depletion. The findings are compared to previous studies in office contexts. The work is valuable in many areas of HCI dealing with mobility.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {919–928},
numpages = {10},
keywords = {cognition, multi-modal interfaces, interruptions, attention, context, semi-naturalistic field study, mobile browsers, mobile HCI, multitasking},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

