@inproceedings{10.1145/3030024.3030026,
author = {Dugan, Casey and Brusilovsky, Peter and Daly, Elizabeth and O'Donovan, John},
title = {AWARE: Workshop on Awareness Interfaces and Interactions},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3030026},
doi = {10.1145/3030024.3030026},
abstract = {Awareness is a key user interface and interaction paradigm. Choosing what to make the user aware of, at what time, and how, has a critical impact on system usage and overall perception. In this workshop, we will bring together those from academia and industry to share their own work in this area, debate key topics, and brainstorm possible future collaborations or papers.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {1–3},
numpages = {3},
keywords = {information overload, alerts, recommender systems, visualizations, awareness},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040245,
author = {Friedman, Doron and Brouwer, Anne-Marie and Nijholt, Anton},
title = {BCIforReal: An Application-Oriented Approach to BCI Out of the Laboratory},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040245},
doi = {10.1145/3030024.3040245},
abstract = {In principle, brain-computer interfaces (BCIs) hold the promise for being the ultimate intelligent interfaces ? what could surpass an interface that is able to interpret your thoughts and preferences, in real time, and behave accordingly? In practice, it is still not quite clear if and how BCIs can contribute to or replace existing interaction paradigms. In the last 10- 20 years BCI research focused on providing patients who lost their ability to communicate through the usual channels (speech) with ways of communication that are directly based on brain signals. While a lot of progress has been made, very few patients actually use BCI in their daily life. Moreover, it is not clear whether BCI has any advantage for non-clinical applications and for able-bodied individuals.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {5–7},
numpages = {3},
keywords = {FNIRs, EEG, brain computer interface},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040246,
author = {Glowacka, Dorota and Milios, Evangelos and Soto, Axel J. and Paulovich, Fernando},
title = {Exploratory Search and Interactive Data Analytics},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040246},
doi = {10.1145/3030024.3040246},
abstract = {In recent years there has been a growing interest in developing new methods and systems that allow users to interactively explore large volumes of data, such as document collections, multimedia collections or biomedical datasets. There are various approaches to support users in this interactive environment ranging from the development of new algorithms through visualisation methods to specialised interfaces. The overarching goal of this workshop is to bring together a group of researchers spanning across multiple facets of exploratory search and data analytics to discuss, and outline research challenges for this novel area.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {9–11},
numpages = {3},
keywords = {interactive information retrieval, data analytics, exploratory search},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040247,
author = {Graus, Mark and Ferwerda, Bruce and Schedl, Markus and Tkalcic, Marko and Willemsen, Martijn and Germanakos, Panagiotis},
title = {IUI'17 Companion-Workshop Summary for HUMANIZE'17},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040247},
doi = {10.1145/3030024.3040247},
abstract = {The first workshop on Theory-Informed User Modeling for Tailoring and Personalizing Interfaces (HUMANIZE) took place in conjunction with the 22nd annual meeting of the intelligent user interfaces (IUI) community in Limassol, Cyprus on March 13, 2017. The goal of the workshop was to attract researchers from different fields by accepting contributions on the intersection of practical data mining methods and theoretical knowledge for personalization. A total of six papers were accepted for this edition of the workshop.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {13–15},
numpages = {3},
keywords = {data mining, user interfaces, psychological theories, workshop summary, personalization},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040248,
author = {Celik, Ilknur and Torre, Ilaria},
title = {IUI'17 Workshop Summary for SmartLearn: Intelligent Interfaces for Ubiquitous and Smart Learning},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040248},
doi = {10.1145/3030024.3040248},
abstract = {New technologies are changing the way we learn and teach. Emerging technologies such as social semantic web, cloud computing, and the growing popularity of mobile devices, embedded devices and adaptive context-aware technologies are leading to a paradigm shift in the way educational services are provided. Through technologies and approaches such as ubiquitous and adaptive learning, learning becomes personalized, flexible, and suitable to meet diverse and rapidly changing technologies, environments and learner needs, while opening unprecedented possibilities for education. The aim of the "Intelligent Interfaces for Ubiquitous and Smart Learning" workshop has been to bring together researchers from industry and academia to address the challenges of the intelligent user interfaces and smart learning fields, discuss new ideas and present their research to the scientific community in order to enhance the methodologies and techniques for intelligent learning environments for the 21st century. The workshop program, program committee and further details are available on the website (http://smartlearn.dibris.unige.it/).},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {17–19},
numpages = {3},
keywords = {mobile learning, user modelling, social and semantic technologies, ubiquitous learning, interactive learning environments, personalized interaction, cloud technologies, technology-enhanced learning, recommender systems, user-adapted systems, intelligent tutoring systems, intelligent interfaces, smart educational interfaces, workshop},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040249,
author = {Schnelle-Walka, Dirk and M\"{u}ller, Florian and Grosse-Puppendahl, Tobias and Luyten, Kris and M\"{u}hlh\"{a}user, Max and Brdiczka, Oliver},
title = {SmartObjects: Fifth Workshop on Interacting with Smart Objects},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040249},
doi = {10.1145/3030024.3040249},
abstract = {The increasing number of smart objects in our everyday life radically changes how we interact with everyday objects. In this workshop, we discuss how the interaction with these smart objects should be designed from various perspectives.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {21–23},
numpages = {3},
keywords = {HCI, novel interaction, embodied interaction, tangible interaction, multimodal and adapter interaction, context-awareness, smart objects, enabling techologies},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3030027,
author = {Jannach, Dietmar and Nunes, Ingrid and Jugovac, Michael},
title = {Interacting with Recommender Systems},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3030027},
doi = {10.1145/3030024.3030027},
abstract = {Automated recommendations have become a common feature of modern online services and mobile apps. In many practical applications, the means provided for users to interact with recommender systems (e.g., to state explicit preferences or to provide feedback on the recommendations) are, however, very limited. In order to improve such systems and consequently user satisfaction, much research work has been done over the years to build richer and more intelligent user interfaces for recommender systems. In this tutorial, we provide a comprehensive overview of existing approaches to user interaction aspects of recommender systems, with a special focus on explanation interfaces. We also provide examples of real-world systems that implement advanced interaction mechanisms and discuss open challenges in the field.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {25–27},
numpages = {3},
keywords = {recommender systems, interaction design},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3030028,
author = {Callaway, Charles B.},
title = {Creating Custom Wearable Electronics: From Design to Fabrication to Experimentation},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3030028},
doi = {10.1145/3030024.3030028},
abstract = {Wearables offer an attractive platform for interacting intelligently with our environment and ourselves. Commercially available wearables are not aimed at the academic/research environment. They have proprietary protocols, do not willingly share recorded data or information on how it was processed and filtered, and do not have the right combinations of sensors or actuators in the desired positions or sensitivity. Given the scarce resources that academic groups have, their wearables have rarely progressed past a very bulky prototype stage. But it is now possible to create a complete custom wearable within a month at very low cost.This tutorial will teach the skills necessary to design and fabricate a Bluetooth based wrist or ring wearable that can wirelessly send sensor data to a smartphone or computer for data analysis and receive wireless commands to actuate sensors. Given the basic schematics for a circuit, you will learn how to choose and source components, lay out and route a circuit board, send the design off to a local fabrication house, and create the finished device when the printed circuit boards return a week later. I will introduce helpful open source software, teach basic industry standards and the properties of various sensors and actuators, and describe features that are especially useful for wearables.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {29–31},
numpages = {3},
keywords = {hardware fabrication, hardware design, sensors},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3030029,
author = {Karpouzis, Kostas},
title = {Affective and Gameful Interfaces},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3030029},
doi = {10.1145/3030024.3030029},
abstract = {The advent of ubiquitous and wearable sensors and computing power and, especially, natural interfaces in the form of speech-based commands or hand-held devices enables users to interact with computers, gaming consoles, and portable devices in a human-like fashion, surpassing the conventional paradigm of keyboards, mice and hand-held controllers. This emerging paradigm opens up new means of non-verbal communication: users can shrug their shoulders to indicate indifference to the options presented to them, nod when agreeing or shout when angry, thus producing feedback which computing systems can take advantage of to provide a truly natural and personalized experience. In addition to this, both seasoned gamers and casual users can interact with computer and console games in the same manner as they would when playing a conventional physical or mental game. In the framework of human-computer interaction, this opens up an opportunity to explore those games as a research medium: the Flow Theory of Optimal Experience, developed by Csikszentmihalyi, gets its name from the way so many people have described a peculiar state of extreme happiness and satisfaction, being so engaged and absorbed by certain activities that they seem to 'flow' along with them in a spontaneous and almost automatic manner, being ?carried by the flow? of the activity. As a result, play becomes not the opposite of work, as is sometimes considered, but is actually sometimes synonymous to it: for instance, children seem to learn infinitely easier when the learning objectives are achieved through play than when forced into the conventional study paradigms. This tutorial aims to introduce games not as a leisure or entertainment activity, but as a means to educate children and adults. Natural interaction and expressivity, personalization (starting from the user interface, all the way down to producing individual content based on what players enjoy), along with accessible computing and aesthetic emotions constitute concepts which can benefit from studying user behaviour and expressivity when playing games. It order to bridge the gap from low-level observed signals (audio, video or even biosignals) to affective and behavioural cues, one needs to map extracted features or cues to user characteristics, taking into account background information or user and environment context, e.g. a smile from the user may be interpreted as positive feedback by a gaming environment, while a frown may indicate that the user did not get what he/she expected to or has a hard time with the particular game stage. Knowledge technologies can be of great assistance here, offering useful qualities, such as alignment and consistency checking, while concepts from cognitive theories, e.g. Theory of Mind, can prove valuable when trying to reason about the beliefs, desires and intentions of the user. As a result, research and development of games are not confined to one single discipline, but instead compose an exciting and challenging inter-disciplinary field.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {33–34},
numpages = {2},
keywords = {computational intelligence, machine learning, games research, human-machine interaction, affective computing, natural interfaces},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040982,
author = {Bader, Nadeem and Mokryn, Osnat and Lanir, Joel},
title = {Exploring Emotions in Online Movie Reviews for Online Browsing},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040982},
doi = {10.1145/3030024.3040982},
abstract = {A restaurant review is a reflection of the reviewer?s experience and attitude towards the restaurant. The same applies to a review of a new phone or a review on any other online merchandize. Films, however, are created with the intended purpose to evoke an emotional response in the viewer. This emotional response does not necessarily correspond with the viewer's attitude towards the film. Thus, the question we try to address is, would the emotions expressed in a film?s online reviews also reflect the emotions elicited during the film? In this work, we take a first step in the investigation of this question, by studying the role of emotions in movie reviews as expressed in a large dataset of millions of online reviews for over 9000 movies, that appeared in IMDb from 1972 to 2015. Our results show that we can extract emotions elicited by the film from its reviews, and create an emotional signature of a film, and of a genre. This is a first step towards an Emotion-based Film Browser UI system that will enable users to browse films according to the emotions they evoke.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {35–38},
numpages = {4},
keywords = {emotional signature, emotions, movie reviews},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038264,
author = {Haim, Bar and Menahem, Eitan and Wolfsthal, Yaron and Meenan, Christopher},
title = {Visualizing Insider Threats: An Effective Interface for Security Analytics},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038264},
doi = {10.1145/3030024.3038264},
abstract = {With the ever-growing volume of cyber-attacks on organizations, security analysts require effective visual interfaces and interaction techniques to detect security breaches and, equally importantly, to efficiently share threat information. To support this need, we present a tool called ?User Behavior Analytics? (UBA) that conducts continuous analysis of individuals' usage of their organizational IT networks, and effectively visualizes the associated security exposures of the organization. The UBA tool was developed as an extension of IBM?s security analytics environment, and incorporates a risk-focused dashboard that highlights anomalous user behaviors and the aggregated risk levels associated with individual users, user groups, and overall system security state. Moreover, the tool?s dashboard has been designed to facilitate rapid review of security incidents and correlate them with data from various sources such as user directory and HR systems. In doing so, the tool presents busy security analysts with an effective means to visually identify and respond to cyber threats on the organization's crown jewels.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {39–42},
numpages = {4},
keywords = {anomaly detection, insider threat, user behavior analytics},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038265,
author = {Yao, Yuan and Chiu, Po-Tsung and Fu, Wai-Tat},
title = {A Gestural Interface for Practicing Children's Spatial Skills},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038265},
doi = {10.1145/3030024.3038265},
abstract = {We present a novel gestural interface for an educational 3D construction game that helps children practice and learn spatial reasoning skills. Previous research shows that having well-developed spatial reasoning skills is crucial to the success in the STEM fields. Our game requires the player to create a number of 3D target objects by moving, rotating, and assembling smaller pieces in the right way through a gestural interface. The gestures were designed with enhancing the user experience and effectiveness of learning in mind, by having a congruent mapping between hand gestures and spatial operations. The initial results of the preliminary study we conducted with the children show that the interface has the potential to be used for practicing spatial reasoning skills with the game. We also discuss how the study can lead to the development of a theoretical framework for designing gestural interfaces for educational games that leverage the benefit of embodied interactions.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {43–47},
numpages = {5},
keywords = {3D interaction, children, spatial reasoning, video game, gestural interface},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040983,
author = {Theocharous, Georgios and Vlassis, Nikos and Wen, Zheng},
title = {An Interactive Points of Interest Guidance System},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040983},
doi = {10.1145/3030024.3040983},
abstract = {In this paper we propose an intelligent user interface for a Point-of-Interest (POI) recommendation system. Our approach solves many challenges, such as learning from passive data, sequential real-time recommendations, Inferring the user's propensity to listen to a recommendation, and minimizing recommendation fatigue. We demonstrate our approach on a real world POI data set from Flicker.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {49–52},
numpages = {4},
keywords = {Thompson sampling, personalization, MDPs, POIs},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038266,
author = {Dwivedi, Utkarsh and Ahuja, Karan and Islam, Rahul and Barbhuiya, Ferdous A. and Nagar, Seema and Dey, Kuntal},
title = {EyamKayo: Interactive Gaze and Facial Expression Captcha},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038266},
doi = {10.1145/3030024.3038266},
abstract = {This paper introduces {it EyamKayo}, a first-of-its-kind interactive CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart), using eye gaze and facial expression based human interactions, to better distinguish humans from software robots. Our system generates a sequence of instructions, asking the user to follow a controlled sequence of gaze points, and generate a controlled sequence of facial expressions. We evaluate user comfort and system usability, and validate using usability tests.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {53–56},
numpages = {4},
keywords = {emotion, interactive captcha, facial expression, gaze},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038267,
author = {Augstein, Mirjam and Neumayr, Thomas and Kern, Daniel and Kurschl, Werner and Altmann, Josef and Burger, Thomas},
title = {An Analysis and Modeling Framework for Personalized Interaction},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038267},
doi = {10.1145/3030024.3038267},
abstract = {Personalization has been discussed in a number of domains and it also plays an important role in the area of human-computer interaction as users' interaction abilities and preferences vary drastically. Considering these individual characteristics can contribute to better user experience and also accessibility of interactive settings. This extended abstract describes a framework that enables personalized interaction based on analyzing and modeling users' interaction abilities.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {57–60},
numpages = {4},
keywords = {user modeling, personalization, interaction analysis},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038268,
author = {Vergani Dambros, Gustavo and Ungewiss, Judith and K\"{u}bler, Thomas and Kasneci, Enkelejda and Sp\"{u}ler, Martin},
title = {Monitoring Response Quality During Campimetry Via Eye-Tracking},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038268},
doi = {10.1145/3030024.3038268},
abstract = {In a variety of use-cases, deriving information on user's fatigue is an important step for content adaptation. In this work, we investigate which eye tracking related measures can predict the error rate (as a proxy of subject's fatigue)during a visual experiment. Data was collected during a 40 minutes campimetric task, where the user has to detect visual stimuli (i.e., dots) of different contrast. We found that eye-tracking measures can be used to train a machine learning model to predict the error rate of a user with an average correlation of 0.72±0.17. The results show that this method can be used to measure the user?s response quality.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {61–64},
numpages = {4},
keywords = {campimetry, pupil diameter, eye-tracking, blink rate, vigilance, fatigue},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040984,
author = {Sheidin, Julia and Lanir, Joel and Kuflik, Tsvi and Bak, Peter},
title = {Visualizing Spatial-Temporal Evaluation of News Stories},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040984},
doi = {10.1145/3030024.3040984},
abstract = {News today are generated and distributed online by a multitude of sources all over the world. Easy and efficient monitoring and analysis of news stories is of interest to both professional analysts and the general public. One interesting aspect is the magnitude and impact of a story as well as its evolution over time. In this work we introduce an idea and a system that presents temporal and spatial evolution of news world-wide, in two different levels, to help users quickly understand and act upon the large amount of data. An overview option shows a general split of the reported news, and a more detailed view provides interactive options for deeper analysis of a single news episode. We demonstrate our system on data from news events generated by the Europe Media Monitor (EMM), an online news aggregator platform.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {65–68},
numpages = {4},
keywords = {news visualization, spatio-temporal visualization, news},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038269,
author = {Eivazi, Shahram and Fuhl, Wolfgang and Kasneci, Enkelejda},
title = {Towards Intelligent Surgical Microscope: Micro-Surgeons' Gaze and Instrument Tracking},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038269},
doi = {10.1145/3030024.3038269},
abstract = {After many decades of research, the presence of intelligent user interfaces is unquestionable in any modern operating room (OR). For the first time, we aim to bring proactive intelligent systems into microsurgery OR. The first step towards an intelligent surgical microscope is to design an activity-aware microscope. In this paper, we present a novel system that we have built to record both eyes and instruments movements of surgeons while operating with a surgical microscope. We present a case study in micro-neurosurgery to show how the system monitors the surgeon's activities. We achieved about 1 mm accuracy for gaze and instrument tracking. Now real-time ecologically valid data can be used to design, for example, a self-adjustable microscope.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {69–72},
numpages = {4},
keywords = {intelligent surgical microscope, hands-free, eye tracking},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040985,
author = {Eivazi, Shahram and Slupina, Michael and Fuhl, Wolfgang and Afkari, Hoorieh and Hafez, Ahmad and Kasneci, Enkelejda},
title = {Towards Automatic Skill Evaluation in Microsurgery},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040985},
doi = {10.1145/3030024.3040985},
abstract = {In the past decade, eye tracking has emerged as a promising answer to the increasing needs of understanding surgical expertise. The implicit desire is to design an intelligent user interface (IUI) to monitor and assess the competency of surgical trainees. In this paper, for the first time in microsurgery, we explore the potential for a surgical automatic skill assessment through a combination of machine learning techniques, computational modeling, and eye tracking. We present primary findings from a random forest classification method where we achieved about 70% recognition rate for the detection of expert and novice group. This leads us to a conclusion that prediction of the micro-surgeon performance is possible, can be automated, and that the eye movement data carry important information about the skills of micro-surgeons.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {73–76},
numpages = {4},
keywords = {machine learning, skill assessment, eye tracking, micro-neurosurgery},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038270,
author = {Constantinou, Vaso and Lanitis, Andreas and Ioannou, Andri},
title = {Using Virtual Reality to Train Designers to Develop Friendly Interfaces for Achromatic Vision Patients},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038270},
doi = {10.1145/3030024.3038270},
abstract = {An investigation in the use of Virtual Reality as a means of training designers to design interfaces accessible to achromatic vision patients is presented. Within this context virtual environments incorporating real life environments are visualised through the eyes of achromatic vision patients and designers are given the opportunity to navigate and interact with the virtual environment using different types of interaction schemes. Through the process designers assess the applicability of different interaction methods adjusted to the needs of achromatic vision patients. According to the results of an experimental investigation, the idea of using Virtual Reality-based training is deemed effective.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {77–80},
numpages = {4},
keywords = {deuteranopia, tritanopia, achomatic vision, protanopia, virtual reality, accessibility},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040986,
author = {Josekutty Thomas, Rosemary and Masthoff, Judith and Oren, Nir},
title = {Personalising Healthy Eating Messages to Age, Gender and Personality: Using Cialdini's Principles and Framing},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040986},
doi = {10.1145/3030024.3040986},
abstract = {We examine how persuasive messages can be used to promote and encourage healthy eating based on personality. After a personality assessment, participants assessed the persuasiveness of messages designed using Cialdini's principles of persuasion. The results of our study indicate that 'Authority' messages were most influential. In addition, we observed that positively framed messages were significantly more persuasive than negatively framed ones. Furthermore, personality had a significant influence on the best message type, with agreeable subjects being more inclined to persuasion than others.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {81–84},
numpages = {4},
keywords = {gender, personality, virtual agent, framing, personalisation, healthy eating, persuasion, age},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038271,
author = {Mouzouras, Nikos and Pogiatzis, Andreas and Kleanthous, Styliani and Samaras, George},
title = {DermaTrack: A Skin Cancer Tracking Intelligent Application},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038271},
doi = {10.1145/3030024.3038271},
abstract = {Although, one in five humans living in high risk areas will develop skin cancer during a lifetime, there is currently no mechanism to help humans track the development of skin moles. DermaTrack, the application described in this paper offers an innovative mechanism, using a mobile application, for i) tracking skin cancer over time, and ii) share the data recorded with a specialized doctor. In this paper, we are providing an evaluation of the prototype mobile application interface developed.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {85–88},
numpages = {4},
keywords = {usability evaluation, mobile application evaluation, interface evaluation},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040987,
author = {Renner, Patrick and Pfeiffer, Thies},
title = {Evaluation of Attention Guiding Techniques for Augmented Reality-Based Assistance in Picking and Assembly Tasks},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040987},
doi = {10.1145/3030024.3040987},
abstract = {Intelligent personal assistance systems for manual tasks may support users on multiple levels. A general function is guiding the visual attention of the user towards the item relevant for the next action. This is a challenging task, as the user may be in arbitrary positions and orientations relative to the target. Optical see-through head-mounted-displays (HMDs) present an additional challenge, as the target may be already visible for the user but lie outside the field-of-view of the augmented reality (AR) display. In the context of a smart glasses-based assistance system for a manual assembly station, we evaluated five different visual attention guidance techniques for optical see-through devices. We found that combined directional and positional in-situ guidance performs best overall, but that performance depends on target location. The study is our first realization of a simulated AR methodology in which we create a repeatable and highly-controlled experimental design using a virtual reality (VR) HMD setup.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {89–92},
numpages = {4},
keywords = {visualizations, augmented reality, prompting, visual search},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040988,
author = {Costales, Fernando G. and Carro, Rosa M.},
title = {SilverTouch: Game-Based Training for Children with Myoelectric Prostheses},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040988},
doi = {10.1145/3030024.3040988},
abstract = {In the context of Medicine, technology facilitates the design and development of prostheses that make it possible for patients to recover specific movements. Myoelectric prostheses connect to the patient nerves directly and allow limb movements via electric impulses generated by the nervous system. However, the use of these prostheses requires intensive training, which can be hard and tiring, especially for children. The use of games can make training much more enjoyable. In this paper, we describe SilverTouch, an application to help children to train the use of myoelectric prostheses by means of three different types of multi-touch games. The games are dynamically generated for each user according to his needs and performance at runtime. We have designed them following the advice of experts in Medicine, Physiotherapy, Therapy and Education. The results are promising: the final users agreed that SilverTouch is a good tool for training the use of prostheses, while the experts confirmed its potential to be widely utilized for that purpose.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {93–96},
numpages = {4},
keywords = {game-based training, children, myoelectric prostheses, multi-touch surfaces},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038272,
author = {Dragunova, Maria and Moro, Robert and Bielikova, Maria},
title = {Measuring Visual Search Ability on the Web},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038272},
doi = {10.1145/3030024.3038272},
abstract = {Findability belongs to key aspects of a webpage usability. When testing findability, the measured task times result not only from the design of a web page, but are influenced also by the individual differences in the participants? abilities, such as their visual search ability. In order to measure this ability, we designed a calibration procedure consisting of a visual search task containing Web icons. In this poster paper, we present results of a quantitative eye tracking study with 45 participants comparing the designed visual search task to the standard conjunction search with respect to the reaction time, number of fixations as well as the used search strategies. The results show that searching for icons is a harder task eliciting more fixations and longer reaction times. In addition, it allows us to differentiate the visual search ability of the users as indicated by the differences in reaction times and search strategies.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {97–100},
numpages = {4},
keywords = {usability, eye tracking, user experience, findability, personalization, user study, visual search, web},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038274,
author = {Ko, Eunjeong and Kim, Eun Yi and Yu, Yaohui},
title = {Summarizing Social Image Search Results Using Human Affects},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038274},
doi = {10.1145/3030024.3038274},
abstract = {In this paper, we propose the selection of representative images based on human affects. For this, the images are first transformed into the affective space using convolutional neural network (CNN). Thereafter, images are clustered on affective space and then the resulting clusters are ranked based on the proposed three properties ? coverage, affective coherence and distinctiveness. Finally, some representative images are selected from top-ranked clusters. The experiments conducted on Flickr images showed the effectiveness of the proposed method.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {101–104},
numpages = {4},
keywords = {social image, human affects, ranking model, convolutional neural network, image summarization},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040989,
author = {Dwivedi, Utkarsh and Rajput, Nitendra and Dey, Prasenjit and Varkey, Blessin},
title = {VisualMath: An Automated Visualization System for Understanding Math Word-Problems},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040989},
doi = {10.1145/3030024.3040989},
abstract = {Math word problems are difficult for students to start with since they involve understanding the problem?s context and abstracting out its underlying mathematical operations. A visual understanding of the problem at hand can be very useful for the comprehension of the problem. We present a system VisualMath that uses machine learning tools and crafted visual logic to automatically generate appropriate visualizations from the text of the word-problems and solve it. We demonstrate the improvements in the understanding of math word-problems by conducting a user study and learning of meaning of relevant new words by students.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {105–108},
numpages = {4},
keywords = {natural language processing, automated visualization},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040201,
author = {Zamora, Jennifer},
title = {Rise of the Chatbots: Finding A Place for Artificial Intelligence in India and US},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040201},
doi = {10.1145/3030024.3040201},
abstract = {This research study explores how chatbots can find a place in routine daily lives. Chatbot development has increased while in many cases its purpose still remains loosely defined. Due to its novel and relatively new technology, there is an opportunity to create meaningful experiences with chatbots in a typical person?s life. Qualitative insights were collected from 54 participants in India and the US over the course of two weeks. To identify opportunities for chatbots, we must understand how these programs are perceived and what needs exist for people. The research objectives include understanding the following: 1) anticipations for chatbots 2) preferred input modalities 3) opportunities for chatbots based on user needs.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {109–112},
numpages = {4},
keywords = {input, mobile, India, artificial intelligence, chatbots},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040975,
author = {Salo, Kari and Zinin, Vallo and Bauters, Merja and Mikkonen, Tommi},
title = {Modular Audio Story Platform for Museums},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040975},
doi = {10.1145/3030024.3040975},
abstract = {Museums are seeking different ways to attract and engage audiences. Digital stories in various forms have been utilized as one approach to increase audience experience. This paper presents how to bring audio stories as a part of museum?s activities by developing a modular audio story platform. Most of the functionality is included in Android applications, which allow visitors to attach stories with emotions to artifacts, share stories with other visitors and enrich existing stories with sounds. All the audio files, linking of the artifacts and related audio files are managed by audio digital asset management system. Our platform supports curated audio stories, but the main emphasis is in the visitors? audio stories. We differentiate from the other digital storytelling systems by attaching emotions onto the visitor stories, and combining the soundscapes and audio stories as visitor modified audio stories.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {113–116},
numpages = {4},
keywords = {android, mobile sound mixing, user generated content, museum, soundscape, audio story, emotions},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040976,
author = {Sararit, Nat and Haddawy, Peter and Suebnukarn, Siriwan},
title = {A VR Simulator for Emergency Management in Endodontic Surgery},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040976},
doi = {10.1145/3030024.3040976},
abstract = {We present a virtual reality simulator for teaching emergency management decision-making in endodontic surgery. Objectives of the simulator are to 1) teach how to correctly respond to a variety of emergency situations, 2) acclimate students to making decisions in stressful emergency situations and 3) teach students the situation awareness skills required to rapidly recognize and respond to emergencies. To meet these objectives, we present a simulator that permits emergency situations to be dynamically inserted at various points in the procedure and that is immersive. The simulator also allows a teacher to observe and review a session in real-time or post session. Preliminary evaluation of face and content validity shows that the simulation is sufficiently realistic and the system is a promising teaching tool.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {117–120},
numpages = {4},
keywords = {virtual reality, endodontic, decision making, root canal treatment, emergency management},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038259,
author = {Sengupta, Korok and Menges, Raphael and Kumar, Chandan and Staab, Steffen},
title = {GazeTheKey: Interactive Keys to Integrate Word Predictions for Gaze-Based Text Entry},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038259},
doi = {10.1145/3030024.3038259},
abstract = {In the conventional keyboard interfaces for eye typing, the functionalities of the virtual keys are static, i.e., user?s gaze at a particular key simply translates the associated letter as user's input. In this work we argue the keys to be more dynamic and embed intelligent predictions to support gaze-based text entry. In this regard, we demonstrate a novel "GazeTheKey" interface where a key not only signifies the input character, but also predict the relevant words that could be selected by user's gaze utilizing a two-step dwell time.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {121–124},
numpages = {4},
keywords = {eye typing, text entry, eye tracking, dwell time, gaze input, visual feedback},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038260,
author = {Sandbank, Tommy and Shmueli-Scheuer, Michal and Herzig, Jonathan and Konopnicki, David and Shaul, Rottem},
title = {EHCTool: Managing Emotional Hotspots for Conversational Agents},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038260},
doi = {10.1145/3030024.3038260},
abstract = {Building conversational agents is becoming easier thanks to the profusion of designated platforms. Integrating emotional intelligence in such agents contributes to positive user satisfaction. Currently, this integration is implemented using calls to an emotion analysis service. In this demonstration we present EHCTool that aims to detect and notify the conversation designer about problematic conversation states where emotions are likely to be expressed by the user. Using its exploration view, the tool assists the designer to manage and define appropriate responses in these cases.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {125–128},
numpages = {4},
keywords = {emotions, conversational agent, tooling},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038261,
author = {Madaan, Nishtha and Karanam, Hima and Gupta, Ankush and Jain, Nitisha and Kumar, Arun and Tamilselvam, Srikanth},
title = {Visual Exploration of Unstructured Regulatory Documents},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038261},
doi = {10.1145/3030024.3038261},
abstract = {Governmental authorities publish rules and directives that govern the operations of an industry. These documents, called regulations, are meant to safeguard the interests of consumers. With increasing number, size and complexity of such documents, companies face an uphill task to comply with them. We present a cognitive system, called Cogpliance, for exploring and understanding regulatory documents with the goal of assisting compliance officers in attaining regulatory compliance. Cogpliance automatically reads natural language regulatory documents, extracts key concepts and presents an interactive information exploration user interface for answering compliance officers queries.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {129–132},
numpages = {4},
keywords = {SQL, SOLR, user interfaces, none},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040977,
author = {Afyouni, Imad and Qamar, Ahmad Muaz and Hussain, Syed Osama and Ur Rehman, Faizan and Sadiq, Bilal and Murad, Abdullah},
title = {Motion-Based Serious Games for Hand Assistive Rehabilitation},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040977},
doi = {10.1145/3030024.3040977},
abstract = {Cerebral Palsy, trauma, and strokes are common causes for the loss of hand movements and the decrease in muscle strength for both children and adults. Improving fine motor skills usually involves the synchronization of wrists and fingers by performing appropriate tasks and activities. This demo introduces a novel patient-centered framework for the gamification of hand therapies in order to facilitate and encourage the rehabilitation process. This framework consists of an adaptive therapy-driven 3D environment augmented with our motion-based natural user interface. An intelligent game generator is developed, which translates the patient's gestures into navigational movements with therapy-driven goals, while adapting the level of difficulty based on the patient profile and real-time performance. A comprehensive evaluation and clinical-based assessments were conducted in a local children disability center, and highlights of the results are presented.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {133–136},
numpages = {4},
keywords = {hand therapy, leap motion, gesture recognition, serious games},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040978,
author = {Chen, Jun and Jacucci, Giulio and Chen, Yueguo and Ruotsalo, Tuukka},
title = {SEED: Entity Oriented Information Search and Exploration},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040978},
doi = {10.1145/3030024.3040978},
abstract = {Entity search and exploration can enrich search user interfaces by presenting relevant information instantly and offering relevant exploration pointers to users. Previous research has demonstrated that large Knowledge Graphs allow exploitation and recommendation of explicit links between the entities and other information to improve information access and ranking. However, less attention has been devoted to user interfaces for effectively presenting results, recommending related entities and explaining relations between entities. We introduce a system called SEED which is designed to support entity search and exploration in large Knowledge Graphs. We demonstrate SEED using a dataset of hundreds of thousands of movie related entities from the DBpedia Knowledge Graph. The system utilizes a graph embedding model for ranking entities and their relations, recommending related entities, and explaining their interrelations.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {137–140},
numpages = {4},
keywords = {embedding model, knowledge representation, knowledge graph, exploratory search},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038262,
author = {Barria-Pineda, Jordan and Guerra, Julio and Huang, Yun and Brusilovsky, Peter},
title = {Concept-Level Knowledge Visualization For Supporting Self-Regulated Learning},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038262},
doi = {10.1145/3030024.3038262},
abstract = {Mastery Grids is an intelligent interface that provides access to different kinds of practice content for an introductory programming course. A distinctive feature of the interface is a parallel topic-level visualization of student progress and the progress of their peers. This contribution presents an extended version of the original system that features a fine-grained visualization of student knowledge on the level of the detailed concepts that are associated with the course. The student model is based on a Bayesian-network which is built using students performance history in the learning activities.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {141–144},
numpages = {4},
keywords = {competency visualization, student modeling, social comparison, open student model, information visualization},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040979,
author = {Vijayaraghavan, Prashanth and Vosoughi, Soroush and Yuan, Ann and Roy, Deb},
title = {TweetVista: An AI-Powered Interactive Tool for Exploring Conversations on Twitter},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040979},
doi = {10.1145/3030024.3040979},
abstract = {We present TweetVista, an interactive web-based tool for mapping the conversation landscapes on Twitter. TweetVista is an intelligent and interactive desktop web application for exploring the conversation landscapes on Twitter. Given a dataset of tweets, the tool uses advanced NLP techniques using deep neural networks and a scalable clustering algorithm to map out coherent conversation clusters. The interactive visualization engine then enables the users to explore these clusters. We ran three case studies using datasets about the 2016 US presidential election and the summer 2016 Orlando shooting. Despite the enormous size of these datasets, using TweetVista users were able to quickly and clearly make sense of the various conversation topics around these datasets.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {145–148},
numpages = {4},
keywords = {semantic clusters, twitter, conversation clusters, tweet2vec, interactive tool},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038263,
author = {Peltonen, Jaakko and Belorustceva, Kseniia and Ruotsalo, Tuukka},
title = {Improving Search Result Comprehension by Topic-Relevance Map Visualization},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038263},
doi = {10.1145/3030024.3038263},
abstract = {We introduce topic-relevance map, an interactive search result visualization that assists rapid information comprehension across a large ranked set of results. The topic-relevance map visualizes a topical overview of the search result space as keywords with respect to two essential information retrieval measures: relevance and topical similarity. Non-linear dimensionality reduction is used to embed high-dimensional keyword representations of search result data into angles on a radial layout. Relevance of keywords is estimated by a ranking method and visualized as radiuses on the layout. Similar keywords are modeled by nearby points and more relevant keywords are closer to the center of the radial display. We evaluated the effect of the topic-relevance map in a search result comprehension task where 24 participants were summarizing search results and produced a conceptualization of the result space. Topic-relevance map significantly improves participants' comprehension capability compared to a ranked list.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {149–152},
numpages = {4},
keywords = {sense-making, visualization, exploratory search},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040980,
author = {Wecker, Alan J. and Kuflik, Tsvi and Stock, Oliviero},
title = {AMuse: Connecting Indoor and Outdoor Cultural Heritage Experiences},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040980},
doi = {10.1145/3030024.3040980},
abstract = {The following discusses a demo for an application that serves as a museum guide, which after the visit gives advice on additional cultural heritage sites to visit. The demo simulates the implementation at the Tower of David in Jerusalem. The system uses behavior to determine both preferences and characteristics.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {153–156},
numpages = {4},
keywords = {mobile museum guide, cultural heritage experience, connecting indoor and outdoor},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040981,
author = {Harteveld, Casper and Manning, Nolan and Abu-Arja, Farah and Menasce, Rick and Thurston, Dean and Smith, Gillian and Sutherland, Steven C.},
title = {Design of Playful Authoring Tools for Social and Behavioral Science},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040981},
doi = {10.1145/3030024.3040981},
abstract = {Playful environments are increasingly being used for conducting research. This makes a game platform for authoring research studies and teaching about how to conduct research a necessary progression. In this paper, we discuss Mad Science, a playful platform that is being created to allow users to create behavioral experiments. We discuss iterations of the authoring tools, including lessons learned, and the need for AI assistance to guide and teach users.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {157–160},
numpages = {4},
keywords = {experiments, authoring tools, playful, interface design},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038273,
author = {Verbert, Katrien and Brusilovsky, Peter and Wongchokprasitti, Chirayu and Parra, Denis and Cardoso, Bruno},
title = {Supporting Conference Attendees with Visual Decision Making Interfaces},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038273},
doi = {10.1145/3030024.3038273},
abstract = {Recent efforts in recommender systems research focus increasingly on human factors affecting recommendation acceptance, such as transparency and user control. In this paper, we present IntersectionExplorer, a scalable visualization to interleave the output of several recommender engines with user-contributed relevance information, such as bookmarks and tags. Two user studies at conferences indicate that this approach is well suited for technical audiences in smaller venues, and allowed the identification of applicability limitations for less technical audiences attending larger events.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {161–164},
numpages = {4},
keywords = {recommender systems, set visualization, interactive visualization},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038277,
author = {Jahani-Fariman, Hessam},
title = {Developing a User-Defined Interface for In-Vehicle Mid-Air Gestural Interactions},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038277},
doi = {10.1145/3030024.3038277},
abstract = {Despite the recent developments in gesture-driven technologies facilitating multi-touch and mid-air gesture recognition, there has been little formal user evaluation and analysis of these systems for in-vehicle interfaces. Mid-air gesture-based interfaces can provide a less cumbersome in-vehicle interface for safer driving. Recent developments in gesture-driven technologies have facilitated multi-touch and mid-air gesture recognition. However, for in-vehicle interfaces, research needs to be conducted on the most efficient gesture vocabulary for performing secondary tasks. Following the Interaction Design process user requirements need to be explored, followed by evaluation of characteristics and functions. Then, the outcomes of user evaluation study can be used to develop an efficient in-vehicle gestural interface.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {165–168},
numpages = {4},
keywords = {gesture recognition, gestural interface, user-elicitation, driving simulator, in-vehicle interface},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038278,
author = {Kalloori, Saikishore},
title = {Pairwise Preferences and Recommender Systems},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038278},
doi = {10.1145/3030024.3038278},
abstract = {Most of the present research and application of Recommender Systems is based on the usage of preferences derived from absolute evaluations, such as user ratings or clicks. However, this type of preferences has few disadvantages, e.g., if most of the user rated items are 5 stars, then it is difficult to understand which item the user prefers among them. In this research work, we focus on pairwise preferences as an alternative way for modeling user preferences and compute recommendations. In our scenario, users provide pair scores for a set of item pairs, indicating which item, and to what extent, is preferred. In this Ph.D research, we aim at developing intelligent user interfaces that optimally combine ratings with pairwise preferences. Furthermore, we aim at identifying specific conditions/situations where pairwise preferences elicitation is meaningful and beneficial.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {169–172},
numpages = {4},
keywords = {pairwise preferences, ratings, recommender systems},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038280,
author = {Schneider, Hanna},
title = {Adapting at Run-Time: Exploring the Design Space of Personalized Fitness Coaches},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038280},
doi = {10.1145/3030024.3038280},
abstract = {Personal health and fitness technologies, such as activity trackers, bear the potential to impact health behaviors globally. However, most users abandon these technology quickly. Possible reasons are that provided feedback (often consisting of raw data) is not actionable, not relevant, or the provided advice is not easy to integrate into people's lives. One approach to tackle this problem, is to develop personalized or adaptive digital coaches that take users' individual differences and situation into account. Even though the first prototypes of personalized coaches have been presented and evaluated, this research is still in its infancy. In my thesis, I want to extend this research by (a) investigating the influences of individual differences on behaviors and motivations to use a digital fitness coach, (2) mapping and conceptually exploring the design space of personalized digital fitness coaches, (3) and iteratively prototyping and testing adaptations of personalized fitness coaches in a user-centered design process.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {173–176},
numpages = {4},
keywords = {personalization, fitness coach, design space},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038281,
author = {Donoso-Guzm\'{a}n, Ivania},
title = {EpistAid: An Interactive Intelligent System for Evidence-Based Health Care},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038281},
doi = {10.1145/3030024.3038281},
abstract = {Evidence-based health care (EBHC) is an important practice of medicine which provides systematic scientific evidence to answer clinical questions. Epistemonikos is one of the most important online systems in the field. Currently, many tasks within this system require a large amount of manual effort, which could be improved by leveraging human-in-the-loop machine learning techniques. In this article we propose a system called EpistAid, which combines machine learning, relevance feedback and an interactive user interface to support Epistemonikos users' on EBHC information filtering tasks.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {177–180},
numpages = {4},
keywords = {information filtering, evidence-based health care, visualization, intelligent user interfaces},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038282,
author = {Mauro, Noemi},
title = {Intelligent and Personalized Community Maps},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038282},
doi = {10.1145/3030024.3038282},
abstract = {My PhD project focuses on Participatory GIS (PGIS). In the project I analyze two methodologies to offer personalized search results in community maps and a natural interaction with the system. The first consists of automatically gathering the terms according to which the users express their information needs, in order to enrich the domain conceptualization of a PGIS, giving common definitions for places. The second concerns the creation of ontology-based user models that reflect the interests, lexicon and modality of expression adopted by each person, mapped to the domain ontology adopted by the PGIS. In the project I also analyze how these techniques may be jointly used during the query expansion process to retrieve more accurate and relevant search results.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {181–184},
numpages = {4},
keywords = {linked data, ontologies, personalization, ontology-based user model, semantic search, participatory GIS},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038283,
author = {Carcangiu, Alessandro},
title = {Gesture Recognition through Declarative and Classifier Approach},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038283},
doi = {10.1145/3030024.3038283},
abstract = {Now, users can easily provide input relying on body movements through the newest tracking devices. The available solutions have a mismatch: on one hand, classifiers offer a high precision, but their structure is difficult to inspect for providing feedback and feedforward. On the other hand, compositional approaches for gesture definition support decomposition, but with a low recognition precision. We introduce DEICTIC, a compositional and declarative gesture description that allows creating Hidden Markov Models (HMMs) for recognizing a gesture precisely, while providing information on its sub-components.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {185–188},
numpages = {4},
keywords = {hidden Markov models, classification, gestures, compositional, declarative},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038284,
author = {Oraby, Shereen},
title = {Characterizing and Modeling Linguistic Style in Dialogue for Intelligent Social Agents},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038284},
doi = {10.1145/3030024.3038284},
abstract = {With increasing interest in the development of intelligent agents capable of learning, proficiently automating tasks, and gaining world knowledge, the importance of integrating the ability to converse naturally with users is more crucial now than ever before. This thesis aims to understand and characterize different aspects of social language to facilitate the development of intelligent agents that are socially aware and able to engage users to a level that was not previously possible with language generation systems. Using various machine learning algorithms and data-driven approaches to model the nuances of social language in dialogue, such as factual and emotional expression, sarcasm and humor and the related subclasses of rhetorical questions and hyperbole, we can come closer to modeling the characteristics of the social language that allows us to express emotion and knowledge, and thereby exhibit these styles in the agents we develop.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {189–192},
numpages = {4},
keywords = {intelligent agents, dialogue, argument, sarcasm},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038285,
author = {Su Yin, Myat},
title = {Automated Formative Feedback in a Virtual Reality (VR) Dental Surgery Simulator},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038285},
doi = {10.1145/3030024.3038285},
abstract = {Fine motor skill is indispensable for a dentist. As in many other medical fields of study, the traditional surgical master apprentice model is widely adopted in dental education. Recently, virtual reality (VR) simulators have been employed as supplementary components to the traditional skill-training curriculum, and numerous dental VR systems have been developed academically and commercially. However, the full promise of such systems has yet to be realized due to the lack of sufficient support for formative feedback. Without such a mechanism, evaluation still demands dedicated time of experts in scarce supply. With the aim to fill the gap of formative assessment using VR simulators in skill training in dentistry, we propose a framework to objectively assess the surgical skill and generate feedback automatically. The core concept of the framework is to generate the feedback by correlating the portion of the procedure responsible with the error in the outcome. Assessment of outcome and the procedure, pedagogical models, and multiple modalities to provide feedback are the integral components of this research.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {193–196},
numpages = {4},
keywords = {surgical simulation, intelligent tutoring system, formative assessment, virtual reality, multimodal feedback},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038286,
author = {Wauck, Helen},
title = {Game Features and Individual Differences: What Makes a Spatial Skill Training Video Game Effective?},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038286},
doi = {10.1145/3030024.3038286},
abstract = {This document gives an overview of my current research project investigating how children develop spatial reasoning skills through video game training. I describe the motivation and goals of the project and the progress made so far.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {197–200},
numpages = {4},
keywords = {learning, education, video games, spatial reasoning, children, cognitive science},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038287,
author = {Wu, Wen},
title = {Implicit Acquisition of User Personality for Augmenting Recommender Systems},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038287},
doi = {10.1145/3030024.3038287},
abstract = {In recent years, user personality has been increasingly recognized as a valuable resource being incorporated into the process of generating recommendations. However, the effort of explicitly acquiring users' personality traits via psychological questionnaire is unavoidably high, which may impede the application of personality-based recommenders in real life. My PhD research aims to investigate how to derive users' personality from their implicit behavior and further improve the existing recommender systems. For this purpose, we first identify significant features through experimental validation. We then build inference model to unify these features for determining users' Big-Five personality traits. We further develop personalized recommender systems by incorporating the inferred personality. Our study would indicate an effective solution to boost the applicability of personality-based recommender systems in the online environment.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {201–204},
numpages = {4},
keywords = {implicit acquisition, user personality, recommender systems},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038288,
author = {Sararit, Nat},
title = {Emergency Management Integration in an Endodontic Surgery VR Simulator},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038288},
doi = {10.1145/3030024.3038288},
abstract = {We present the design and prototype implementation of a virtual reality simulator for teaching emergency management decision-making in endodontic surgery. The simulator aims to teach how to correctly respond to a variety of emergency situations and teach students the situation awareness skills required to rapidly recognize and respond to emergencies. We present results of an initial evaluation of face and content validity of the prototype and describe the design of a more comprehensive evaluation including evaluating the knowledge gain in emergency management of students trained with the system as well as the effectiveness of simulator in inducing a feeling of stress in students.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {205–208},
numpages = {4},
keywords = {endodontics, virtual reality, emergency management, root canal treatment, decision making},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038289,
author = {Tresser, Sarit},
title = {Personalization of Virtual Games for Children with Cerebral Palsy},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038289},
doi = {10.1145/3030024.3038289},
abstract = {The purpose of the current work is to explore the potential of a personalized virtual gaming system capable of dynamically adjusting game parameters in accordance with the abilities and therapeutic needs of children with Cerebral Palsy (CP). The study includes three stages: Defining user characteristics and identifying user requirements of children with CP in order to create a user model via interviews and focus groups; Developing a prototype of a personalized virtual gaming system for rehabilitation of children with CP and; Evaluating the prototype with typically developing children and children with CP. Initial results from the first stage identified the benefits and potential of personalized virtual gaming for treating children with CP from both the therapist?s and child?s viewpoints. Iterative prototyping and testing of the personalization algorithm are currently in progress.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {209–212},
numpages = {4},
keywords = {virtual reality (VR), video games, personalization, cerebral palsy (CP), user modeling, rehabilitation},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038290,
author = {Gao, Mingkun},
title = {A Framework of Health Information Retrieval for Aging Population},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038290},
doi = {10.1145/3030024.3038290},
abstract = {Aging populations have a huge demand of searching health information online. However, for their relatively worse physical ability and cognitive ability, normal searching interface may not be able to fulfill aging people's special demands. In our work, we point out the problem which aging populations are facing when they use the normal online searching system. Then, we propose our interactive health information retrieval framework for aging populations using actual pages from the WebMD.com, a popular website where people search for health information. There are three phases in our proposed framework: the retrieval model design, the interface design and the evaluation design. We hope our interface could help aging users obtain better experience when they search for healthcare information online.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {213–216},
numpages = {4},
keywords = {information retrieval, healthcare information, aging population},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3040991,
author = {Do, Hyo Jin},
title = {Intelligent Interface for Seeing the World Through Different Lenses},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3040991},
doi = {10.1145/3030024.3040991},
abstract = {Despite the explosive growth of online social media where people can easily share their thoughts, our current society is more divided than before, gridlocked over society, culture, race, and gender issues. Selective exposure, a confirmatory bias of individuals that favors preexisting opinions while avoiding attitude-inconsistent views, impedes the balanced insight of a controversial issue, which thereby would account for the societal division. In this research proposal, we introduce an intelligent interface that automatically clusters and visualizes diverse opinions about a controversial topic. First, we collect controversial posts from Facebook and its comments. Then, the comments are automatically clustered using a machine-learning algorithm based on features that reflect its contents and the writer's stance. Lastly, we propose an intelligent user interface with controversial posts and opinion clusters where users would be motivated to hunt for opinion groups that are different from their own perspective.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {217–220},
numpages = {4},
keywords = {machine-learning, intelligent user interface, social opinion},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038291,
author = {di Sciascio, Cecilia},
title = {Advanced User Interfaces and Hybrid Recommendations for Exploratory Search},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038291},
doi = {10.1145/3030024.3038291},
abstract = {Exploring large volumes of data with learning or investigative purposes is often regarded as exploratory search. Rather than plain question answering, exploratory search is an iterative process of information seeking and sensemaking. My focus is the development of an interactive intelligent tool that assists the search task and the study of user behavior and experience. More specifically, I combine recommender systems with advanced user interfaces to maximize what Hearst calls "recognition over recall".},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {221–224},
numpages = {4},
keywords = {user experience, recommender systems, exploratory search, advanced user interfaces},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

@inproceedings{10.1145/3030024.3038292,
author = {Tsai, Chun-Hua},
title = {An Interactive and Interpretable Interface for Diversity in Recommender Systems},
year = {2017},
isbn = {9781450348935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030024.3038292},
doi = {10.1145/3030024.3038292},
abstract = {Offering diversity in the output of a recommender system is an active research question. Most of the current approaches focus on Top-N optimization, which results in poor user insight and accuracy trade-off. However, little is known about how an interactive interface can help with this issue. This pilot study shows that a multidimensional visualization promotes diversity among the recommended items. This finding motivated future work to provide diversity in recommender system by visualizing multivariate data through an interpretable and interactive interface.},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion},
pages = {225–228},
numpages = {4},
keywords = {recommender system, HCI, diversity},
location = {Limassol, Cyprus},
series = {IUI '17 Companion}
}

