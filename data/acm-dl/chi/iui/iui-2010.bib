@inproceedings{10.1145/1719970.1719972,
author = {Park, Jaeyoung and Kim, Kee-Eung and Jo, Sungho},
title = {A POMDP Approach to P300-Based Brain-Computer Interfaces},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719972},
doi = {10.1145/1719970.1719972},
abstract = {Most of the previous work on non-invasive brain-computer interfaces (BCIs) has been focused on feature extraction and classification algorithms to achieve high performance for the communication between the brain and the computer. While significant progress has been made in the lower layer of the BCI system, the issues in the higher layer have not been sufficiently addressed. Existing P300-based BCI systems, for example the P300 speller, use a random order of stimulus sequence for eliciting P300 signal for identifying users' intentions. This paper is about computing an optimal sequence of stimulus in order to minimize the number of stimuli, hence improving the performance. To accomplish this, we model the problem as a partially observable Markov decision process (POMDP), which is a model for planning in partially observable stochastic environments. Through simulation and human subject experiments, we show that our approach achieves a significant performance improvement in terms of the success rate and the bit rate.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {1–10},
numpages = {10},
keywords = {brain-computer interface (bci), partially observable markov decision process (pomdp), P300},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719973,
author = {Hurst, Amy and Hudson, Scott E. and Mankoff, Jennifer},
title = {Automatically Identifying Targets Users Interact with during Real World Tasks},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719973},
doi = {10.1145/1719970.1719973},
abstract = {Information about the location and size of the targets that users interact with in real world settings can enable new innovations in human performance assessment and soft-ware usability analysis. Accessibility APIs provide some information about the size and location of targets. How-ever this information is incomplete because it does not sup-port all targets found in modern interfaces and the reported sizes can be inaccurate. These accessibility APIs access the size and location of targets through low-level hooks to the operating system or an application. We have developed an alternative solution for target identification that leverages visual affordances in the interface, and the visual cues produced as users interact with targets. We have used our novel target identification technique in a hybrid solution that combines machine learning, computer vision, and accessibility API data to find the size and location of targets users select with 89% accuracy. Our hybrid approach is superior to the performance of the accessibility API alone: in our dataset of 1355 targets covering 8 popular applications, only 74% of the targets were correctly identified by the API alone.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {11–20},
numpages = {10},
keywords = {target identification, pointing input, usability analysis, computer accessibility},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719974,
author = {Legaspi, Roberto and Fukui, Ken-ichi and Moriyama, Koichi and Kurihara, Satoshi and Numao, Masayuki and Suarez, Merlin},
title = {Addressing the Problems of Data-Centric Physiology-Affect Relations Modeling},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719974},
doi = {10.1145/1719970.1719974},
abstract = {Data-centric affect modeling may render itself restrictive in practical applications for three reasons, namely, it falls short of feature optimization, infers discrete affect classes, and deals with relatively small to average sized datasets. Though it seems practical to use the feature combinations already associated to commonly investigated sensors, there may be other potentially optimal features that can lead to new relations. Secondly, although it seems more realistic to view affect as continuous, it requires using continuous labels that will increase the difficulty of modeling. Lastly, although a large scale dataset reflects a more precise range of values for any given feature, it severely hinders computational efficiency. We address these problems when inferring physiology-affect relations from datasets that contain 2-3 million feature vectors, each with 49 features and labelled with continuous affect values. We employ automatic feature selection to acquire near optimal feature subsets and a fast approximate kNN algorithm to solve the regression problem and cope with the challenge of a large scale dataset. Our results show that high estimation accuracy may be achieved even when the selected feature subset is only about 7% of the original features. May the results here motivate the HCI community to pursue affect modeling without being deterred by large datasets and further the discussions on acquiring optimal features for accurate continuous affect approximation.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {21–30},
numpages = {10},
keywords = {affective computing, pattern recognition, machine learning},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719976,
author = {Liu, Jiahui and Dolan, Peter and Pedersen, Elin R\o{}nby},
title = {Personalized News Recommendation Based on Click Behavior},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719976},
doi = {10.1145/1719970.1719976},
abstract = {Online news reading has become very popular as the web provides access to news articles from millions of sources around the world. A key challenge of news websites is to help users find the articles that are interesting to read. In this paper, we present our research on developing personalized news recommendation system in Google News. For users who are logged in and have explicitly enabled web history, the recommendation system builds profiles of users' news interests based on their past click behavior. To understand how users' news interests change over time, we first conducted a large-scale analysis of anonymized Google News users click logs. Based on the log analysis, we developed a Bayesian framework for predicting users' current news interests from the activities of that particular user and the news trends demonstrated in the activity of all users. We combine the content-based recommendation mechanism which uses learned user profiles with an existing collaborative filtering mechanism to generate personalized news recommendations. The hybrid recommender system was deployed in Google News. Experiments on the live traffic of Google News website demonstrated that the hybrid method improves the quality of news recommendation and increases traffic to the site.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {31–40},
numpages = {10},
keywords = {user modeling, personalization, news trend},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719977,
author = {Park, Souneil and Lee, SangJeong and Song, Junehwa},
title = {Aspect-Level News Browsing: Understanding News Events from Multiple Viewpoints},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719977},
doi = {10.1145/1719970.1719977},
abstract = {Aspect-level news browsing provides readers with a classified view of news articles with different viewpoints. It facilitates active interactions with which readers easily discover and compare diverse existing biased views over a news event. As such, it effectively helps readers understand the event from a plural of viewpoints and formulate their own, more balanced viewpoints free from specific biased views. Realizing aspect-level browsing raises important challenges, mainly due to the lack of semantic knowledge with which to abstract and classify the intended salient aspects of articles. We first demonstrate the feasibility of aspect-level news browsing through user studies. We then deeply look into the news article production process and develop framing cycle-aware clustering. The evaluation results show that the developed method performs classification more accurately than other methods.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {41–50},
numpages = {10},
keywords = {aspect-level classification, aspect-level news browsing, media bias},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719978,
author = {Ehara, Yo and Shimizu, Nobuyuki and Ninomiya, Takashi and Nakagawa, Hiroshi},
title = {Personalized Reading Support for Second-Language Web Documents by Collective Intelligence},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719978},
doi = {10.1145/1719970.1719978},
abstract = {Novel intelligent interface eases the browsing of Web documents written in the second languages of users. It automatically predicts words unfamiliar to the user by collective intelligence and glosses them with their meaning in advance. If the prediction succeeds, the user does not need to consult a dictionary; even if it fails, the user can correct the prediction. The correction data are collected and used to improve the accuracy of further predictions. The prediction is personalized in that every user's language ability is estimated by a state-of-the-art language testing model, which is trained in a practical response time with only a small sacrifice of prediction accuracy. Evaluation results for the system in terms of prediction accuracy are encouraging.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {51–60},
numpages = {10},
keywords = {collective intelligence, reading support, glossing system, web page, item response theory},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719980,
author = {Faulring, Andrew and Myers, Brad and Mohnkern, Ken and Schmerl, Bradley and Steinfeld, Aaron and Zimmerman, John and Smailagic, Asim and Hansen, Jeffery and Siewiorek, Daniel},
title = {Agent-Assisted Task Management That Reduces Email Overload},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719980},
doi = {10.1145/1719970.1719980},
abstract = {RADAR is a multiagent system with a mixed-initiative user interface designed to help office workers cope with email overload. RADAR agents observe experts to learn models of their strategies and then use the models to assist other people who are working on similar tasks. The agents' assistance helps a person to transition from the normal email-centric workflow to a more efficient task-centric workflow. The Email Classifier learns to identify tasks contained within emails and then inspects new emails for similar tasks. A novel task-management user interface displays the found tasks in a to-do list, which has integrated support for performing the tasks. The Multitask Coordination Assistant learns a model of the order in which experts perform tasks and then suggests a schedule to other people who are working on similar tasks. A novel Progress Bar displays the suggested schedule of incomplete tasks as well as the completed tasks. A large evaluation demonstrated that novice users confronted with an email overload test performed significantly better (a 37% better overall score with a factor of four fewer errors) when assisted by the RADAR agents.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {61–70},
numpages = {10},
keywords = {task management, radar, email classification, learning, email overload, intelligent planning, agents},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719981,
author = {Krzywicki, Alfred and Wobcke, Wayne and Wong, Anna},
title = {An Adaptive Calendar Assistant Using Pattern Mining for User Preference Modelling},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719981},
doi = {10.1145/1719970.1719981},
abstract = {In this paper, we present SmartCal, a calendar assistant that suggests appointment attributes, such as time, day, duration, etc., given any combination of initial user input attributes. SmartCal uses closed pattern mining to discover patterns in past appointment data in order to represent user preferences and adapt to changing user preferences over time. The SmartCal interface is designed to be minimally intrusive: users are free to choose or ignore suggestions, which are dynamically updated as users enter new information. The user model as a collection of patterns is intuitive and transparent: users can view and edit existing patterns or create new patterns based on existing appointments. SmartCal was evaluated in a user study with four users over a four week period. The user study shows that pattern mining makes appointment creation more efficient and users regarded the appointment suggestion feature favourably.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {71–80},
numpages = {10},
keywords = {calendar management, data mining, personal assistants},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719982,
author = {Iacobelli, Francisco and Birnbaum, Larry and Hammond, Kristian J.},
title = {Tell Me More, Not Just "More of the Same"},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719982},
doi = {10.1145/1719970.1719982},
abstract = {The Web makes it possible for news readers to learn more about virtually any story that interests them. Media outlets and search engines typically augment their information with links to similar stories. It is up to the user to determine what new information is added by them, if any. In this paper we present Tell Me More, a system that performs this task automatically: given a seed news story, it mines the web for similar stories reported by different sources and selects snippets of text from those stories which offer new information beyond the seed story. New content may be classified as supplying: additional quotes, additional actors, additional figures and additional information depending on the criteria used to select it. In this paper we describe how the system identifies new and informative content with respect to a news story. We also how that providing an explicit categorization of new information is more useful than a binary classification (new/not-new). Lastly, we show encouraging results from a preliminary evaluation of the system that validates our approach and encourages further study.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {81–90},
numpages = {10},
keywords = {new information detection, information retrieval, dimensions of similarity},
location = {Hong Kong, China},
series = {IUI '10}
}

@dataset{10.1145/review-1719970.1719982_R45989,
author = {Bradford, James H.},
title = {Review ID:R45989 for DOI: 10.1145/1719970.1719982},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1719970.1719982_R45989}
}

@inproceedings{10.1145/1719970.1719984,
author = {Baur, Dominikus and Boring, Sebastian and Butz, Andreas},
title = {Rush: Repeated Recommendations on Mobile Devices},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719984},
doi = {10.1145/1719970.1719984},
abstract = {We present rush as a recommendation-based interaction and visualization technique for repeated item selection from large data sets on mobile touch screen devices. Proposals and choices are intertwined in a continuous finger gesture navigating a two-dimensional canvas of recommended items. This provides users with more flexibility for the resulting selections. Our design is based on a formative user study regarding orientation and occlusion aspects. Subsequently, we implemented a version of rush for music playlist creation. In an experimental evaluation we compared different types of recommendations based on similarity, namely the top 5 most similar items, five random selections from the list of similar items and a hybrid version of the two. Participants had to create playlists using each condition. Our results show that top 5 was too restricting, while random and hybrid suggestions had comparable results.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {91–100},
numpages = {10},
keywords = {recommender systems, mobile, interaction technique},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719985,
author = {Church, Karen and Neumann, Joachim and Cherubini, Mauro and Oliver, Nuria},
title = {SocialSearchBrowser: A Novel Mobile Search and Information Discovery Tool},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719985},
doi = {10.1145/1719970.1719985},
abstract = {The mobile Internet offers anytime, anywhere access to a wealth of information to billions of users across the globe. However, the mobile Internet represents a challenging information access platform due to the inherent limitations of mobile environments, limitations that go beyond simple screen size and network issues. Mobile users often have information needs which are impacted by contexts such as location and time. Furthermore, human beings are social creatures that often seek out new strategies for sharing knowledge and information in mobile settings. To investigate the social aspect of mobile search, we have developed SocialSearchBrowser (SSB), a novel proof-of-concept interface that incorporates social networking capabilities with key mobile contexts to improve the search and information discovery experience of mobile users. In this paper, we present the results of an exploratory field study of SSB and outline key implications for the design of next generation mobile information access services.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {101–110},
numpages = {10},
keywords = {social search, context, mobile search, social networks, location-based services, user evaluation, field study},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719986,
author = {Gunawardana, Asela and Paek, Tim and Meek, Christopher},
title = {Usability Guided Key-Target Resizing for Soft Keyboards},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719986},
doi = {10.1145/1719970.1719986},
abstract = {Soft keyboards offer touch-capable mobile and tabletop devices many advantages such as multiple language support and room for larger displays. On the other hand, because soft keyboards lack haptic feedback, users often produce more typing errors. In order to make soft keyboards more robust to noisy input, researchers have developed key-target resizing algorithms, where underlying target areas for keys are dynamically resized based on their probabilities. In this paper, we describe how overly aggressive key-target resizing can sometimes prevent users from typing their desired text, violating basic user expectations about keyboard functionality. We propose an anchored key-target method which incorporates usability principles so that soft keyboards can remain robust to errors while respecting usability principles. In an empirical evaluation, we found that using anchored dynamic key-targets significantly reduce keystroke errors as compared to the state-of-the-art.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {111–118},
numpages = {8},
keywords = {source-channel key-target resizing, touch model, language model},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719988,
author = {Jiang, Yingying and Tian, Feng and Wang, Hongan and Zhang, Xiaolong and Wang, Xugang and Dai, Guozhong},
title = {Intelligent Understanding of Handwritten Geometry Theorem Proving},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719988},
doi = {10.1145/1719970.1719988},
abstract = {Computer-based geometry systems have been widely used for teaching and learning, but largely based on mouse-and-keyboard interaction, these systems usually require users to draw figures by following strict task structures defined by menus, buttons, and mouse and keyboard actions. Pen-based designs offer a more natural way to develop geometry theorem proofs with hand-drawn figures and scripts. This paper describes a pen-based geometry theorem proving system that can effectively recognize hand-drawn figures and hand-written proof scripts, and accurately establish the correspondence between geometric components and proof steps. Our system provides dynamic and intelligent visual assistance to help users understand the process of proving and allows users to manipulate geometric components and proof scripts based on structures rather than strokes. The results from evaluation study show that our system is well perceived and users have high satisfaction with the accuracy of sketch recognition, the effectiveness of visual hints, and the efficiency of structure-based manipulation.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {119–128},
numpages = {10},
keywords = {hand-written proof scripts, hand-drawn figures, recognition, geometry theorem proving, structure based manipulation},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719989,
author = {Hui, Pui-Yu and Lo, Wai-Kit and Meng, Helen},
title = {Usage Patterns and Latent Semantic Analyses for Task Goal Inference of Multimodal User Interactions},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719989},
doi = {10.1145/1719970.1719989},
abstract = {This paper describes our work in usage pattern analysis and development of a latent semantic analysis framework for interpreting multimodal user input consisting speech and pen gestures. We have designed and collected a multimodal corpus of navigational inquiries. Each modality carries semantics related to domain-specific task goal. Each inquiry is annotated manually with a task goal based on the semantics. Multimodal input usually has a simpler syntactic structure than unimodal input and the order of semantic constituents is different in multimodal and unimodal inputs. Therefore, we proposed to use semantic analysis to derive the latent semantics from the multimodal inputs using latent semantic modeling (LSM). In order to achieve this, we parse the recognized Chinese spoken input for the spoken locative references (SLR). These SLRs are then aligned with their corresponding pen gesture(s). Then, we characterized the cross-modal integration pattern as 3-tuple multimodal terms with SLR, pen gesture type and their temporal relation. The inquiry-multimodal term matrix is then decomposed using singular value decomposition (SVD) to derive the latent semantics automatically. Task goal inference based on the latent semantics shows that the task goal inference accuracy on a disjoint test set is of 99%.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {129–138},
numpages = {10},
keywords = {pen gesture, multimodal input, task goal inference, spoken input, singular value decomposition, latent semantic modeling},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719990,
author = {Nakano, Yukiko I. and Ishii, Ryo},
title = {Estimating User's Engagement from Eye-Gaze Behaviors in Human-Agent Conversations},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719990},
doi = {10.1145/1719970.1719990},
abstract = {In face-to-face conversations, speakers are continuously checking whether the listener is engaged in the conversation and change the conversational strategy if the listener is not fully engaged in the conversation. With the goal of building a conversational agent that can adaptively control conversations with the user, this study analyzes the user's gaze behaviors and proposes a method for estimating whether the user is engaged in the conversation based on gaze transition 3-gram patterns. First, we conduct a Wizard-of-Oz experiment to collect the user's gaze behaviors. Based on the analysis of the gaze data, we propose an engagement estimation method that detects the user's disengagement gaze patterns. The algorithm is implemented as a real-time engagement-judgment mechanism and is incorporated into a multimodal dialogue manager in a conversational agent. The agent estimates the user's conversational engagement and generates probing questions when the user is distracted from the conversation. Finally, we conduct an evaluation experiment using the proposed engagement-sensitive agent and demonstrate that the engagement estimation function improves the user's impression of the agent and the interaction with the agent. In addition, probing performed with proper timing was also found to have a positive effect on user's verbal/nonverbal behaviors in communication with the conversational agent.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {139–148},
numpages = {10},
keywords = {eye-gaze, dialogue management, conversational agent, conversational engagement},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719992,
author = {Liu, Qiong and Liao, Chunyuan and Wilcox, Lynn and Dunnigan, Anthony and Liew, Bee},
title = {Embedded Media Markers: Marks on Paper That Signify Associated Media},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719992},
doi = {10.1145/1719970.1719992},
abstract = {Embedded Media Markers, or simply EMMs, are nearly transparent iconic marks printed on paper documents that signify the existence of media associated with that part of the document. EMMs also guide users' camera operations for media retrieval. Users take a picture of an EMM-signified document patch using a cell phone, and the media associated with the EMM-signified document location is displayed on the phone. Unlike bar codes, EMMs are nearly transparent and thus do not interfere with the document appearance. Retrieval of media associated with an EMM is based on image local features of the captured EMM-signified document patch. This paper describes a technique for semi-automatically placing an EMM at a location in a document, in such a way that it encompasses sufficient identification features with minimal disturbance to the original document.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {149–158},
numpages = {10},
keywords = {barcode, augmented paper, marker on paper, document recognition, vision-based paper interface, camera phone},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719993,
author = {Liu, Shenwei and Tajima, Keishi},
title = {WildThumb: A Web Browser Supporting Efficient Task Management on Wide Displays},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719993},
doi = {10.1145/1719970.1719993},
abstract = {Nowadays the Web and Web browsers have become the most important and universal platform for people to search, view, process, and exchange various kinds of information. Consequently, today's users usually open many Web pages simultaneously in order to perform multiple tasks in parallel, which makes Web browsers crucial in our daily task management. However, no existing Web browser provides users with sufficient support for the management of many tabs or windows of opened pages. On the other hand, wide displays have become more affordable and prevalent, while extra space on those displays is not utilized effectively in Web browsing. In this paper, we propose a new Web browser interface aiming to support efficient task management in Web browsing on wide displays. In order to help users switch between opened Web pages, we show thumbnails of the pages in the extra space around the currently focused page. In the page thumbnails, we emphasize distinctive elements in each page in order to make the selection of the thumbnails easier. In addition, we calculate the relevance between pages based on users' switching history, and emphasize pages relevant to the current page by adjusting the size or opacity of the thumbnails. This further helps users find the thumbnails of needed pages, and also helps users get the overview of the page set related to the current task.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {159–168},
numpages = {10},
keywords = {multitask, site logo, task switching, tab-browser, window system, task grouping, augmented thumbnail, working set},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719994,
author = {Mahmud, Jalal and Lau, Tessa},
title = {Lowering the Barriers to Website Testing with CoTester},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719994},
doi = {10.1145/1719970.1719994},
abstract = {In this paper, we present CoTester, a system designed to decrease the difficulty of testing web applications. CoTester allows testers to create test scripts that are represented in an easy-to-understand scripting language rather than a complex programming language, which allows tests to be created rapidly and by non-developers. CoTester improves the management of test scripts by grouping sequences of lowlevel actions into subroutines, such as "log in" or "check out shopping cart", which help testers visualize test structure and make bulk modifications. A key innovation in CoTester is its ability to automatically identify these subroutines using a machine learning algorithm. Our algorithm is able to achieve 91% accuracy at recognizing a set of 7 representative subroutines commonly found in test scripts.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {169–178},
numpages = {10},
keywords = {instruction, subroutine, test script, website testing},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719996,
author = {McNally, Kevin and O'Mahony, Michael P. and Smyth, Barry and Coyle, Maurice and Briggs, Peter},
title = {Towards a Reputation-Based Model of Social Web Search},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719996},
doi = {10.1145/1719970.1719996},
abstract = {While web search tasks are often inherently collaborative in nature, many search engines do not explicitly support collaboration during search. In this paper, we describe HeyStaks (www.heystaks.com), a system that provides a novel approach to collaborative web search. Designed to work with mainstream search engines such as Google, HeyStaks supports searchers by harnessing the experiences of others as the basis for result recommendations. Moreover, a key contribution of our work is to propose a reputation system for HeyStaks to model the value of individual searchers from a result recommendation perspective. In particular, we propose an algorithm to calculate reputation directly from user search activity and we provide encouraging results for our approach based on a preliminary analysis of user activity and reputation scores across a sample of HeyStaks users.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {179–188},
numpages = {10},
keywords = {collaborative web search, reputation model, heystaks},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719997,
author = {Girgensohn, Andreas and Shipman, Frank and Chen, Francine and Wilcox, Lynn},
title = {DocuBrowse: Faceted Searching, Browsing, and Recommendations in an Enterprise Context},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719997},
doi = {10.1145/1719970.1719997},
abstract = {Browsing and searching for documents in large, online enterprise document repositories are common activities. While internet search produces satisfying results for most user queries, enterprise search has not been as successful because of differences in document types and user requirements. To support users in finding the information they need in their online enterprise repository, we created DocuBrowse, a faceted document browsing and search system. Search results are presented within the user-created document hierarchy, showing only directories and documents matching selected facets and containing text query terms. In addition to file properties such as date and file size, automatically detected document types, or genres, serve as one of the search facets. Highlighting draws the user's attention to the most promising directories and documents while thumbnail images and automatically identified keyphrases help select appropriate documents. DocuBrowse utilizes document similarities, browsing histories, and recommender system techniques to suggest additional promising documents for the current facet and content filters.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {189–198},
numpages = {10},
keywords = {faceted search, document recommendation, document visualization, document management, document retrieval},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719998,
author = {Fu, Wai-Tat and Kannampallil, Thomas G. and Kang, Ruogu},
title = {Facilitating Exploratory Search by Model-Based Navigational Cues},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719998},
doi = {10.1145/1719970.1719998},
abstract = {We present an extension of a computational cognitive model of social tagging and exploratory search called the semantic imitation model. The model assumes a probabilistic representation of semantics for both internal and external knowledge, and utilizes social tags as navigational cues during exploratory search. We used the model to generate a measure of information scent that controls exploratory search behavior, and simulated the effects of multiple presentations of navigational cues on both simple information retrieval and exploratory search performance based on a previous model called SNIF-ACT. We found that search performance can be significantly improved by these model-based presentations of navigational cues for both experts and novices. The result suggested that exploratory search performance depends critically on the match between internal knowledge (domain expertise) and external knowledge structures (folksonomies). Results have significant implications on how social information systems should be designed to facilitate knowledge exchange among users with different background knowledge.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {199–208},
numpages = {10},
keywords = {exploratory learning, SNIF-ACT, social tagging, semantic imitation, knowledge exchange},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1719999,
author = {Bergman, Lawrence and Lu, Jie and Konuru, Ravi and MacNaught, Julie and Yeh, Danny},
title = {Outline Wizard: Presentation Composition and Search},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1719999},
doi = {10.1145/1719970.1719999},
abstract = {Presentation material is a commonly-performed task. Yet current tools provide inadequate support - search tools are unable to return individual slides, and the linear model employed by presentation creation tools lacks structure and context. We propose a novel method for presentation creation, implemented in a tool called Outline Wizard, which enables outline-based composition and search. An Outline Wizard user enters a hierarchically-structured outline of a presentation; using that structure, the tool extracts user requests to formulate contextual queries, matches them against presentations within a repository, taking into account both content and structures of the presentations, and presents the user with sets of slides that are appropriate for each outline topic. At the heart of Outline Wizard is an outline-based search technique, which conducts content search within the context derived from the hierarchical structures of both user requests and presentations. We present a heuristic outline-extraction technique, which is used to reverse engineer the structures of presentations, thereby making the structures available for our search engine. Evaluations show that the outline extraction technique and outline-based search both perform well, and that users report a satisfying experience when using Outline Wizard to compose presentations from libraries of existing material.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {209–218},
numpages = {10},
keywords = {presentation search, context-sensitive information retrieval, outline-based search, presentation composition},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720001,
author = {Gross, Paul A. and Herstand, Micah S. and Hodges, Jordana W. and Kelleher, Caitlin L.},
title = {A Code Reuse Interface for Non-Programmer Middle School Students},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720001},
doi = {10.1145/1719970.1720001},
abstract = {We describe a code reuse tool for use in the Looking Glass IDE, the successor to Storytelling Alice [17], which enables middle school students with little to no programming experience to reuse functionality they find in programs written by others. Users (1) record a feature to reuse, (2) find code responsible for the feature, (3) abstract the code into a reusable Actionscript by describing object "roles," and (4) integrate the Actionscript into another program. An exploratory study with middle school students indicates they can successfully reuse code. Further, 36 of the 47 users appropriated new programming constructs through the process of reuse.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {219–228},
numpages = {10},
keywords = {code reuse, non-programmer, end user, looking glass, middle school, storytelling alice},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720002,
author = {Ruiz, Jaime and Lank, Edward},
title = {Speeding Pointing in Tiled Widgets: Understanding the Effects of Target Expansion and Misprediction},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720002},
doi = {10.1145/1719970.1720002},
abstract = {Target expansion is a pointing facilitation technique where the user's target, typically an interface widget, is dynamically enlarged to speed pointing in interfaces. However, with densely packed (tiled) arrangements of widgets, interfaces cannot expand all potential targets; they must, instead, predict the user's desired target. As a result, mispredictions will occur which may disrupt the pointing task. In this paper, we present a model describing the cost/benefit of expanding multiple targets using the probability distribution of a given predictor. Using our model, we demonstrate how the model can be used to infer the accuracy required by target prediction techniques. The results of this work are another step toward pointing facilitation techniques that allow users to outperform Fitts' Law in realistic pointing tasks.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {229–238},
numpages = {10},
keywords = {human performance, Fitts' law, target expansion, tiled targets, pointing},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720004,
author = {Cao, Yujia and Mahr, Angela and Castronovo, Sandro and Theune, Mari\"{e}t and Stahl, Christoph and M\"{u}ller, Christian A.},
title = {Local Danger Warnings for Drivers: The Effect of Modality and Level of Assistance on Driver Reaction},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720004},
doi = {10.1145/1719970.1720004},
abstract = {Local danger warning is an important function of Advanced Driver Assistance Systems (ADAS) to improve the safety of driving. The user interface (the warning presentation) is particularly crucial to a successful danger avoidance. We present a user study investigating various warning presentations using a scenario of emergent road obstacles. Two presentation factors were selected: modality and level of assistance. The modality factor had 4 variants: speech warning, visual and speech warning, visual warning with blinking cue, and visual warning with sound cue. The level of assistance varied between with or without action suggestions (AS). In accordance with the ISO usability model, a total of 6 measurements were derived to assess the effectiveness and efficiency of the warnings and the drivers' satisfaction. Results indicate that the combination of speech and visual modality leads to the best performance as well as the highest satisfaction. In contrast, purely auditory and purely visual modalities were both insufficient for presenting high-priority warnings. AS generally improved the usability of the warnings especially when they were accompanied by supporting information so that drivers could validate the suggestions.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {239–248},
numpages = {10},
keywords = {car2car communication, automotive, multimodal intefaces},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720005,
author = {Amin, Alia and Hildebrand, Michiel and van Ossenbruggen, Jacco and Hardman, Lynda},
title = {Designing a Thesaurus-Based Comparison Search Interface for Linked Cultural Heritage Sources},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720005},
doi = {10.1145/1719970.1720005},
abstract = {Comparison search is an information seeking task where a user examines individual items or sets of items for similarities and differences. While this is a known information need among experts and knowledge workers, appropriate tools are not available. In this paper, we discuss comparison search in the cultural heritage domain, a domain characterized by large, rich and heterogeneous data sets, where different organizations deploy different schemata and terminologies to describe their artifacts. This diversity makes meaningful comparison difficult. We developed a thesaurus-based comparison search application called LISA, a tool that allows a user to search, select and compare sets of artifacts. Different visualizations allow users to use different comparison strategies to cope with the underlying heterogeneous data and the complexity of the search tasks. We conducted two user studies. A preliminary study identifies the problems experts face while performing comparison search tasks. A second user study examines the effectiveness of LISA in helping to solve comparison search tasks. The main contribution of this paper is to establish design guidelines for the data and interface of a comparison search application. Moreover, we offer insights into when thesauri and metadata are appropriate for use in such applications.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {249–258},
numpages = {10},
keywords = {cultural heritage, thesauri, comparison search},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720006,
author = {Rosenthal, Stephanie L. and Dey, Anind K.},
title = {Towards Maximizing the Accuracy of Human-Labeled Sensor Data},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720006},
doi = {10.1145/1719970.1720006},
abstract = {We present two studies that evaluate the accuracy of human responses to an intelligent agent's data classification questions. Prior work has shown that agents can elicit accurate human responses, but the applications vary widely in the data features and prediction information they provide to the labelers when asking for help. In an initial analysis of this work, we found the five most popular features, namely uncertainty, amount and level of context, prediction of an answer, and request for user feedback. We propose that there is a set of these data features and prediction information that maximizes the accuracy of labeler responses. In our first study, we compare accuracy of users of an activity recognizer labeling their own data across the dimensions. In the second study, participants were asked to classify a stranger's emails into folders and strangers' work activities by interruptibility. We compared the accuracy of the responses to the users' self-reports across the same five dimensions. We found very similar combinations of information (for users and strangers) that led to very accurate responses as well as more feedback that the agents could use to refine their predictions. We use these results for insight into the information that help labelers the most.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {259–268},
numpages = {10},
keywords = {active learning, labeling sensor data},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720008,
author = {Balagtas-Fernandez, Florence and Tafelmayer, Max and Hussmann, Heinrich},
title = {Mobia Modeler: Easing the Creation Process of Mobile Applications for Non-Technical Users},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720008},
doi = {10.1145/1719970.1720008},
abstract = {The development of mobile applications has now extended from mobile network providers into the hands of ordinary people as organizations and companies encourage people to come up with their own software masterpieces by opening up APIs and tools. However, as of the moment, these APIs and tools are only usable by people with programming skills. There is a scarcity of tools that enable users without programming experience to easily build customized mobile applications. We present in this paper a tool and its underlying framework that would enable non-technical people to create their own domain-specific mobile applications. As a proof of concept, we focus on the creation of applications in the domain of mobile health monitoring. In the future, we would like to extend our work to cover other domains as well.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {269–272},
numpages = {4},
keywords = {modeling tools, mobile application, user-centered design, domain-specific modeling},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720009,
author = {Berkovsky, Shlomo and Coombe, Mac and Helmer, Richard},
title = {Activity Interface for Physical Activity Motivating Games},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720009},
doi = {10.1145/1719970.1720009},
abstract = {Contemporary lifestyle is becoming increasingly sedentary with no or little physical activity. We propose a novel design for physical activity motivating games that leverages engagement with games in order to motivate users to perform physical activity as part of traditionally sedentary playing. This paper focuses on the wearable activity interface for physical activity motivating games. We discuss the activity interface design considerations, present physical activity processing details, and analyse some observations of user interaction with the activity interface.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {273–276},
numpages = {4},
keywords = {serious games, physical activity, wearable interface},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720010,
author = {Biswas, Pradipta and Robinson, Peter},
title = {Evaluating the Design of Inclusive Interfaces by Simulation},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720010},
doi = {10.1145/1719970.1720010},
abstract = {We have developed a simulator to help with the design and evaluation of assistive interfaces. The simulator can predict possible interaction patterns when undertaking a task using a variety of input devices, and estimate the time to complete the task in the presence of different dis-abilities. In this paper, we have presented a study to evaluate the simulator by considering a representative application being used by able-bodied, visually impaired and mobility impaired people. The simulator predicted task completion times for all three groups with statistically significant accuracy. The simulator also predicted the effects of different interface designs on task completion time accurately.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {277–280},
numpages = {4},
keywords = {human computer interaction, usability evaluation, assistive technology, simulator, user model},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720011,
author = {Brdiczka, Oliver and Su, Norman Makoto and Begole, James Bo},
title = {Temporal Task Footprinting: Identifying Routine Tasks by Their Temporal Patterns},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720011},
doi = {10.1145/1719970.1720011},
abstract = {This paper introduces a new representation for describing routine tasks, called temporal task footprints. Routines are characterized by their temporal regularity or rhythm. Temporal pattern analysis (T-patterns) can be used to isolate frequent recurrent patterns in routine tasks that appear repeatedly in the same temporal configuration. Using tf-idf statistics, each task can then be defined in terms of its temporal task footprint, a ranked list of temporal patterns along with their typical frequencies. Experimental evaluations using data of 29 days observing and logging 10 subjects showed that temporal task footprints of application windows, email and document usage outperform decision tree and SVMs in recognizing the subjects' tasks.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {281–284},
numpages = {4},
keywords = {t-patterns, task footprint, temporal patterns, routine task representation},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720012,
author = {Brdiczka, Oliver},
title = {From Documents to Tasks: Deriving User Tasks from Document Usage Patterns},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720012},
doi = {10.1145/1719970.1720012},
abstract = {A typical knowledge worker is involved in multiple tasks and switches frequently between them every work day. These frequent switches become expensive because each task switch requires some recovery time as well as the reconstitution of task context. First task management support systems have been proposed in recent years in order to assist the user during these switches. However, these systems still need a fairly big amount of investment from the user side in order to either learn to use or train such a system. In order to reduce the necessary amount of training, this paper proposes a new approach for automatically estimating a user's tasks from document interactions in an unsupervised manner. While most previous approaches to task detection look at the content of documents or window titles, which might raise confidentiality and privacy issues, our approach only requires document identifiers and the temporal switch history between them as input. Our prototype system monitors a user's desktop activities and logs documents that have focus on the user's desktop by attributing a unique identifier to each of these documents. Retrieved documents are filtered by their dwell times and a document similarity matrix is estimated based on document frequencies and switches. A spectral clustering algorithm then groups documents into tasks using the derived similarity matrix. The described prototype system has been evaluated on user data of 29 days from 10 different subjects in a corporation. Obtained results indicate that the approach is better than previous approaches that use content.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {285–288},
numpages = {4},
keywords = {document clustering, user task modeling, automatic task identification},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720013,
author = {Cheema, Salman and LaViola, Joseph J.},
title = {Towards Intelligent Motion Inferencing in Mathematical Sketching},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720013},
doi = {10.1145/1719970.1720013},
abstract = {We present a new approach for creating dynamic illustrations to assist in the understanding of concepts in physics and mathematics using pen-based interaction. Our approach builds upon mathematical sketching by combining the ability to make associations between handwritten mathematics and free-form drawings with an underlying physics engine. This combination lets users create animations without having to directly specify object behavior with position functions through time, yet still supports writing the mathematics needed to formulate a problem. This functionality significantly expands the capabilities of mathematical sketching to support a wider variety of dynamic illustrations. We describe our approach to creating this mathematical sketching/physics engine fusion and discuss how it provides a foundation for using mathematical sketching in intelligent tutoring systems.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {289–292},
numpages = {4},
keywords = {pen-based interfaces, sketch parsing, mathematical sketching, sketch inferencing},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720014,
author = {Chen, Jiajian and Xiao, Jun and Gao, Yuli},
title = {ISlideShow: A Content-Aware Slideshow System},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720014},
doi = {10.1145/1719970.1720014},
abstract = {We present an intelligent photo slideshow system that automatically analyzes thematic information about the photo collection and utilizes such information to generate compositions and transitions in two modes: story-telling mode and person-highlighting mode. In the story-telling mode the system groups photos by a theme-based clustering algorithm and multiple photos in each theme cluster are seamlessly tiled on a slide. Multiple tiling layouts are generated for each theme cluster and the slideshow is animated by intra-cluster transitions. In the person-highlighting mode, the system first recognizes faces from photos and creates photo clusters for individuals. It then uses face areas as ROI (Regions of Interests) and creates various content-based transitions to highlight individuals in a cluster. With an emphasis on photo content, our system creates slideshows with more fluid, dynamic and meaningful structure compared to existing systems.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {293–296},
numpages = {4},
keywords = {theme clustering, GPU, content-based transition, slideshow},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720015,
author = {Chen, Li},
title = {Social Influence of Product Popularity on Consumer Decisions: Usability Study of Flickr Camera Finder},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720015},
doi = {10.1145/1719970.1720015},
abstract = {"Product popularity" is in-depth explored in this paper, regarding its practical role within a consumer's decision process. Specifically, the usability evaluation of a novel product finder service (Flickr Camera Finder) shows that users more frequently consulted it, rather than a standard shopping site, to locate popular products. User comments further revealed their credibility concerns and tendency to trust the "popularity" from social resources. Design implications from the experiment are summarized at the end, indicating suggestive directions to integrate social media data to boost current e-commerce decision tools.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {297–300},
numpages = {4},
keywords = {e-commerce, usability study, social influence, consumer decision behavior, product popularity, Flickr camera finder},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720016,
author = {Chi, Pei-Yu and Lieberman, Henry},
title = {Raconteur: From Intent to Stories},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720016},
doi = {10.1145/1719970.1720016},
abstract = {When editing a story from a large collection of media, such as photos and video clips captured from daily life, it is not always easy to understand how particular scenes fit into the intent for the overall story. Especially for novice editors, there is often a lack of coherent connections between scenes, making it difficult for the viewers to follow the story.In this paper, we present Raconteur, a story editing system that helps users assemble coherent stories from media elements, each annotated with a sentence or two in unrestricted natural language. It uses a Commonsense knowledge base, and the AnalogySpace Commonsense reasoning technique. Raconteur focuses on finding story analogies - different elements illustrating the same overall "point", or independent stories exhibiting similar narrative structures.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {301–304},
numpages = {4},
keywords = {storytelling, commonsense computing, video, photograph, media editing, story goal, story analogy},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720017,
author = {Creswick, Eugene R. and Novstrup, Aaron M.},
title = {Error-Tolerant Version Space Algebra},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720017},
doi = {10.1145/1719970.1720017},
abstract = {Application customization has been extensively researched in the field of Programming by Demonstration (PBD), and Version Space Algebra has proven itself to be a viable means of quickly learning precise action sequences from user demonstrations. However, this technique is not capable of handling user error in domains with actions that depend on parameters that accept myriad values. Activities such as image, audio and video editing require user actions that are difficult for users to precisely replicate in different circumstances. Demonstrations that are off by a single pixel or a split-second cause traditional composite Version Spaces to collapse.We present a method of incorporating error tolerance into Version Space algebra. This approach, termed Error-Tolerant Version Spaces, adapts Version Space Algebra to domains where the tactile capabilities of the user have a much greater chance of prematurely collapsing the hypothesis space that is being learned. The resulting framework is capable of quickly learning in domains where perfectly consistent user input can not be expected. We have successfully applied our technique in the domain of image redaction, allowing our users to quickly specify redactions that can be reliably applied to many images without the entry of explicit parameters.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {305–308},
numpages = {4},
keywords = {smart environments, version spaces, error tolerance, programming by demonstration},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720018,
author = {Dim, Eyal and Kuflik, Tsvi},
title = {Social Signal Processing: Detecting Small Group Interaction in Leisure Activity},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720018},
doi = {10.1145/1719970.1720018},
abstract = {Social Signal Processing of small groups enables detection of their social context. Monitoring of the social context may be based on position proximity (as a pre-condition for conversation), and on voice communication (an evidence for interaction). Understanding of the social context of a group may allow a system to intervene at the right moment and to suggest relevant services/information. This, in turn, may enhance the group members' experience during leisure activity. This study focuses on assessing the possibility of automatic detection of intra group interaction in a museum environment. It presents analysis and tools that intend to set the foundation for computer aided group interaction during leisure activities.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {309–312},
numpages = {4},
keywords = {ubiquitous computing, social signal processing, group modeling, interrupt management},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720019,
author = {Dong, Wei and Fu, Wai-Tat},
title = {Toward a Cultural-Sensitive Image Tagging Interface},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720019},
doi = {10.1145/1719970.1720019},
abstract = {Do people from different cultures tag digital images differently? The current study examined the relationship between the position and content of tags for digital images created by participants from two cultural groups (European Americans and Chinese). In line with previous findings on cultural differences in attentional patterns, we found cultural differences in the order of the parts of images people chose to tag. European Americans tended to tag main objects first, and tag background objects and overall properties in the images later; in contrast, Chinese tended to tag the overall properties first, and tag the main and background objects later. Based on findings of the current study, we discuss implications on developing a cultural-sensitive algorithm to facilitate the tagging and search process of digital media and data-mining tools to identify user profiles based on their cultural origins.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {313–316},
numpages = {4},
keywords = {attention, perception, tagging, cultural difference, annotation, image tagging, algorithm},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720020,
author = {Felfernig, Alexander and Mandl, Monika and Tiihonen, Juha and Schubert, Monika and Leitner, Gerhard},
title = {Personalized User Interfaces for Product Configuration},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720020},
doi = {10.1145/1719970.1720020},
abstract = {Configuration technologies are well established as a foundation of mass customization which is a production paradigm that supports the manufacturing of highly-variant products under pricing conditions similar to mass production. A side-effect of the high diversity of products offered by a configurator is that the complexity of the alternatives may outstrip a user's capability to explore them and make a buying decision. In order to improve the quality of configuration processes, we combine knowledge-based configuration with collaborative and content-based recommendation algorithms. In this paper we present configuration techniques that recommend personalized default values to users. Results of an empirical study show improvements in terms of, for example, user satisfaction or the quality of the configuration process.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {317–320},
numpages = {4},
keywords = {configuration systems, model-based diagnosis, recommender systems},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720021,
author = {Freyne, Jill and Berkovsky, Shlomo},
title = {Intelligent Food Planning: Personalized Recipe Recommendation},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720021},
doi = {10.1145/1719970.1720021},
abstract = {As the obesity epidemic takes hold across the world many medical professionals are referring users to online systems aimed at educating and persuading users to alter their lifestyle. The challenge for many of these systems is to increase initial adoption and sustain participation for sufficient time to have real impact on the life of its users. In this work we present some preliminary investigation into the design of a recipe recommender, aimed at educating and sustaining user participation, which makes tailored recommendations of healthy recipes. We concentrate on the two initial dimensions of food recommendations: data capture and food-recipe relationships and present a study into the suitability of varying recommender algorithms for the recommendation of recipes.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {321–324},
numpages = {4},
keywords = {food, recommender systems, personalization, collaborative filtering, recipe},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720022,
author = {Han, Yong-Jin and Noh, Tae-Gil and Park, Seong-Bae and Park, Se Young and Lee, Sang-Jo},
title = {A Natural Language Interface of Thorough Coverage by Concordance with Knowledge Bases},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720022},
doi = {10.1145/1719970.1720022},
abstract = {One of the critical problems in natural language interfaces is the discordance between the expressions covered by the interface and those by the knowledge base. In the graph-based knowledge base such as an ontology, all possible queries can be prepared in advance. As a solution of the discordance problem in natural language interfaces, this paper proposes a method that translates a natural language query into a formal language query such as SPARQL. In this paper, a user query is translated into a formal language by choosing the most appropriate query from the prepared queries. The experimental results show a high accuracy and coverage for the given knowledge base.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {325–328},
numpages = {4},
keywords = {natural language interface, ontology, knowledge concordance, knowledge base},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720023,
author = {Kang, Ruogu and Fu, Wai-Tat},
title = {Exploratory Information Search by Domain Experts and Novices},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720023},
doi = {10.1145/1719970.1720023},
abstract = {The arising popularity of social tagging system has the potential to transform traditional web search into a new era of social search. Based on the finding that domain expertise could influence search behavior in traditional search engines, we hypothesized and tested the idea that domain expertise would have similar influence on search behavior in a social tagging system. We conducted an experiment comparing search behavior of experts and novices when they searched using a tradition search engine and a social tagging system. Results from our experiment showed that experts relied more on their own domain knowledge to generate search queries, while novices were influenced more by social cues in the social tagging system. Experts were also found to conform to each other more than novices in their choice of bookmarks and tags. Implications on the design of future social information systems are discussed.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {329–332},
numpages = {4},
keywords = {domain expertise, social search, exploratory search},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720024,
author = {Khawaja, M. Asif and Chen, Fang and Marcus, Nadine},
title = {Using Language Complexity to Measure Cognitive Load for Adaptive Interaction Design},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720024},
doi = {10.1145/1719970.1720024},
abstract = {An adaptive interaction system, which is aware of the users' current cognitive load, can change its response, presentation and interaction flow to improve users' experience and their task performance. In this paper, we propose a novel speech content analysis approach for measuring users' cognitive load, based on their language and dialogue complexity. We have analysed the transcribed speech of operators working in computerized incident control rooms and involved in highly complex bushfire management tasks in Australia. The resulting patterns of language complexity show significant differences between the speech from cognitively low load and high load tasks. We also discuss the value of using this approach of cognitive load measurement for user interface evaluation and interaction design improvement.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {333–336},
numpages = {4},
keywords = {language complexity measures, interaction design, measurement, cognitive load},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720025,
author = {Kimani, Stephen and Berkovsky, Shlomo and Smith, Greg and Freyne, Jill and Baghaei, Nilufar and Bhandari, Dipak},
title = {Activity Awareness in Family-Based Healthy Living Online Social Networks},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720025},
doi = {10.1145/1719970.1720025},
abstract = {Social relationships and family involvement play an important role in health management, whereas activity awareness is useful in decision-making and stimulating motivation and action. In this paper, we propose a novel activity awareness user interface for family-oriented healthy living social networks. It is intended to increase family members' interaction with healthy living social networks. A user study showed that the activity awareness interface can add value to specific aspects of interaction with family-based healthy living social applications. The interface increased interaction with the underlying healthy living content and led to higher level of learning about healthy living and impact on specific healthy living activities. There was also significant appreciation of and interaction with the activity awareness user interface elements.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {337–340},
numpages = {4},
keywords = {activity awareness, evaluation, online social networks, user interface, healthy living, families, user interaction},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720026,
author = {Kratz, Sven and Rohs, Michael},
title = {A $3 Gesture Recognizer: Simple Gesture Recognition for Devices Equipped with 3D Acceleration Sensors},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720026},
doi = {10.1145/1719970.1720026},
abstract = {We present the $3 Gesture Recognizer, a simple but robust gesture recognition system for input devices featuring 3D acceleration sensors. The algorithm is designed to be implemented quickly in prototyping environments, is intended to be device-independent and does not require any special toolkits or frameworks. It relies solely on simple trigonometric and geometric calculations. A user evaluation of our system resulted in a correct gesture recognition rate of 80%, when using a set of 10 unique gestures for classification. Our method requires significantly less training data than other gesture recognizers and is thus suited to be deployed and to deliver results rapidly.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {341–344},
numpages = {4},
keywords = {classifier, user interfaces, rapid prototyping, 3D gestures, gesture recognition, recognition rates},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720027,
author = {Li, Shanqing and Jia, Yunde},
title = {A Multimodal Labeling Interface for Wearable Computing},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720027},
doi = {10.1145/1719970.1720027},
abstract = {Under wearable environments, it is not convenient to label an object with portable keyboards and mice. This paper presents a multimodal labeling interface to solve this problem with natural and efficient operations. Visual and audio modalities cooperate with each other: an object is encircled by visual tracking of a pointing gesture, and meanwhile its name is obtained by speech recognition. In this paper, we propose a concept of virtual touchpad based on stereo vision techniques. With the touchpad, the object encircling task is achieved by drawing a closed curve on a transparent blackboard. The touch events and movements of a pointing gesture are robustly detected for natural gesture interactions. The experimental results demonstrate the efficiency and usability of our multimodal interface.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {345–348},
numpages = {4},
keywords = {virtual touchpad, wearable computing, multimodal labeling},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720028,
author = {Mahmud, Jalal and Huang, Yun-Wu and Ponzo, John and Pollak, Roger},
title = {Avara: A System to Improve User Experience in Web and Virtual World},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720028},
doi = {10.1145/1719970.1720028},
abstract = {3D virtual world software is becoming a popular medium for entertainment, social interaction and commerce. To the best of our knowledge, there is no system available to facilitate the bridging between Web applications and virtual world systems in the form of information sharing, data collection and control propagation. As a result, user experience in a Web interface is not sensitive to state changes of virtual world avatars or objects. Similarly, a virtual world environment does not provide Web context-rich user experience. We address this issue and propose a bridging and context sharing architecture between the Web and virtual world applications such that Web applications can control, monitor and collect information from artifacts in the virtual worlds, and vice versa. We also implemented this architecture using existing Web and virtual world technologies. Based on this implementation, we illustrate some novel applications and present a user study to illustrate the value of the system.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {349–352},
numpages = {4},
keywords = {3D web, second life, virtual world, bridging},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720029,
author = {Mao, Yuqing and Shen, Haifeng and Sun, Chengzheng},
title = {Supporting Exploratory Information Seeking by Epistemology-Based Social Search},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720029},
doi = {10.1145/1719970.1720029},
abstract = {Formulating proper keywords and evaluating search results are common difficulties in exploratory information seeking. Reusing and refining others' successful searches are pragmatic directions to tackle these difficulties. In this paper, we present a novel epistemology-based social search solution, where search epistemologies are effectively shared, reused, and refined by others with the same or similar search interests through novel user interfaces. We have developed a prototype system Baijia and experimental results show that an epistemology-based social search system outperforms a conventional search engine in supporting exploratory information seeking.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {353–356},
numpages = {4},
keywords = {epistemology-based social search, exploratory information seeking, world wide web},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720030,
author = {Martino, Mauro and Calabrese, Francesco and Di Lorenzo, Giusy and Andris, Clio and Liang, Liu and Ratti, Carlo},
title = {Ocean of Information: Fusing Aggregate &amp; Individual Dynamics for Metropolitan Analysis},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720030},
doi = {10.1145/1719970.1720030},
abstract = {In this paper, we propose a tool to explore human movement dynamics in a Metropolitan Area. By analyzing a mass of individual cell phone traces, we build a Human-City Interaction System for understanding urban mobility patterns at different user-controlled temporal and geographic scales. We solve the problems that are found in available tools for spatio-temporal analysis, by allowing seamless manipulability and introducing a simultaneousmulti-scale visualization of individual and aggregate flows. Our tool is built to support the exploration and discovery of urban mobility patterns and the daily interactions of millions of people. Moreover, we implement an intelligent algorithm to evaluate the level of mobility homophily of people moving from place to place.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {357–360},
numpages = {4},
keywords = {graph visualization, intelligent human information interaction, cellphone data analysi, exploratory spatial data analysis, visual analysis},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720031,
author = {Nikolova, Sonya and Ma, Xiaojuan and Tremaine, Marilyn and Cook, Perry},
title = {Vocabulary Navigation Made Easier},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720031},
doi = {10.1145/1719970.1720031},
abstract = {It is challenging to search a dictionary consisting of thousands of entries in order to select appropriate words for building written communication. This is true both for people trying to communicate in a foreign language who have not developed a full vocabulary, for school children learning to write, for authors who wish to be more precise and expressive, and especially for people with lexical access disorders. We make vocabulary navigation and word finding easier by augmenting a basic vocabulary with links between words based on human judgments of semantic similarity. In this paper, we report the results from a user study evaluating how our system named ViVA performs compared to a widely used assistive vocabulary in which words are organized hierarchically into common categories.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {361–364},
numpages = {4},
keywords = {visual vocabularies, assistive communication, adaptive user interfaces, semantic networks},
location = {Hong Kong, China},
series = {IUI '10}
}

@dataset{10.1145/review-1719970.1720031_R45970,
author = {Damova, Mariana},
title = {Review ID:R45970 for DOI: 10.1145/1719970.1720031},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1719970.1720031_R45970}
}

@inproceedings{10.1145/1719970.1720032,
author = {Pang, Wai-Man},
title = {An Intuitive Texture Picker},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720032},
doi = {10.1145/1719970.1720032},
abstract = {Color and texture are basic elements in digital graphics. Selection of color with a picker is convenient in many of the image editing softwares. However, more organized and intelligent GUI for texture pattern selection is still missing. In this paper, we attempt to fill this gap with the introduction of several robust techniques in building an intuitive texture picking GUI.By arranging patterns according to their visual similarities, texture picker with plane and circular layout are presented. Additional functionality include content-based texture searching which can quickly find similar patterns of given sample. Preliminary response to the proposed interface is positive in general, while further improvements are required, for example, on building a hierarchy to facilitate high to low level selection for huge amount of texture patterns.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {365–368},
numpages = {4},
keywords = {multidimensional scaling, texture similarity, texture pattern picker, texture selection GUI},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720033,
author = {Pedersen, Elin R\o{}nby and Gyllstrom, Karl and Gu, Shengyin and Hong, Peter Jin},
title = {Automatic Generation of Research Trails in Web History},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720033},
doi = {10.1145/1719970.1720033},
abstract = {We propose the concept of research trails to help web users create and reestablish context across fragmented research processes without requiring them to explicitly structure and organize the material. A research trail is an ordered sequence of web pages that were accessed as part of a larger investigation; they are automatically constructed by filtering and organizing users' activity history, using a combination of semantic and activity based criteria for grouping similar visited web pages. The design was informed by an ethnographic study of ordinary people doing research on the web, emphasizing a need to support research processes that are fragmented and where the research question is still in formation. This paper motivates and describes our algorithms for generating research trails.Research trails can be applied in several situations: as the underlying mechanism for a research task browser, or as feed to an ambient display of history information while searching. A prototype was built to assess the utility of the first option, a research trail browser.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {369–372},
numpages = {4},
keywords = {task browser, semantic clustering, ethnography, automatic clustering, activity based computing, web history},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720034,
author = {Serrano, Nicol\'{a}s and Sanchis, Albert and Juan, Alfons},
title = {Balancing Error and Supervision Effort in Interactive-Predictive Handwriting Recognition},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720034},
doi = {10.1145/1719970.1720034},
abstract = {An effective approach to transcribe handwritten text documents is to follow an interactive-predictive paradigm in which both, the system is guided by the user, and the user is assisted by the system to complete the transcription task as efficiently as possible. This approach has been recently implemented in a system prototype called GIDOC, in which standard speech technology is adapted to handwritten text (line) images: HMM-based text image modeling, n-gram language modeling, and also confidence measures on recognized words. Confidence measures are used to assist the user in locating possible transcription errors, and thus validate system output after only supervising those (few) words for which the system is not highly confident. However, a certain degree of supervision is required for proper model adaptation from partially supervised transcriptions. Here, we propose a simple yet effective method to find an optimal balance between recognition error and supervision effort.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {373–376},
numpages = {4},
keywords = {confidence measures, document analysis, handwriting recognition, computer-assisted text transcription},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720035,
author = {Smith, Dustin A. and Lieberman, Henry},
title = {The Why UI: Using Goal Networks to Improve User Interfaces},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720035},
doi = {10.1145/1719970.1720035},
abstract = {People interact with interfaces to accomplish goals, and knowledge about human goals can be useful for building intelligent user interfaces. We suggest that modeling high, human-level goals like "repair my credit score", is especially useful for coordinating workflows between interfaces, automated planning, and building introspective applications.We analyzed data from 43Things.com, a website where users share and discuss goals and plans in natural language, and constructed a goal network that relates what goals people have with how people solve them. We then label goals with specific details, such as where the goal typically is met and how long it takes to achieve, facilitating plan and goal recognition. Lastly, we demonstrate a simple application of goal networks, deploying it in a mobile, location-aware to-do list application, ToDoGo, which uses goal networks to help users plan where and when to accomplish their desired goals.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {377–380},
numpages = {4},
keywords = {goal networks, learning goal networks, plan recognition, to-do list},
location = {Hong Kong, China},
series = {IUI '10}
}

@dataset{10.1145/review-1719970.1720035_R45653,
author = {Leon, Alexis},
title = {Review ID:R45653 for DOI: 10.1145/1719970.1720035},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1719970.1720035_R45653}
}

@inproceedings{10.1145/1719970.1720036,
author = {Sonntag, Daniel and M\"{o}ller, Manuel},
title = {A Multimodal Dialogue Mashup for Medical Image Semantics},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720036},
doi = {10.1145/1719970.1720036},
abstract = {This paper presents a multimodal dialogue mashup where different users are involved in the use of different user interfaces for the annotation and retrieval of medical images. Our solution is a mashup that integrates a multimodal interface for speech-based annotation of medical images and dialogue-based image retrieval with a semantic image annotation tool for manual annotations on a desktop computer. A remote RDF repository connects the annotation and querying task into a common framework and serves as the semantic backend system for the advanced multimodal dialogue a radiologist can use.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {381–384},
numpages = {4},
keywords = {design, collaborative environments, touchscreen interface},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720037,
author = {Speer, Robyn and Havasi, Catherine and Treadway, K. Nichole and Lieberman, Henry},
title = {Finding Your Way in a Multi-Dimensional Semantic Space with Luminoso},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720037},
doi = {10.1145/1719970.1720037},
abstract = {In AI, we often need to make sense of data that can be measured in many different dimensions -- thousands of dimensions or more -- especially when this data represents natural language semantics. Dimensionality reduction techniques can make this kind of data more understandable and more powerful, by projecting the data into a space of many fewer dimensions, which are suggested by the computer. Still, frequently, these results require more dimensions than the human mind can grasp at once to represent all the meaningful distinctions in the data.We present Luminoso, a tool that helps researchers to visualize and understand a multi-dimensional semantic space by exploring it interactively. It also streamlines the process of creating such a space, by inputting text documents and optionally including common-sense background information. This interface is based on the fundamental operation of "grabbing" a point, which simultaneously allows a user to rotate their view using that data point, view associated text and statistics, and compare it to other data points. This also highlights the point's neighborhood of semantically-associated points, providing clues for reasons as to why the points were classified along the dimensions they were. We show how this interface can be used to discover trends in a text corpus, such as free-text responses to a survey.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {385–388},
numpages = {4},
keywords = {common sense, n-dimensional visualization, natural language processing, SVD},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720038,
author = {Vallet, David and Halvey, Martin and Hannah, David and Jose, Joemon M.},
title = {A Multi Faceted Recommendation Approach for Explorative Video Retrieval Tasks},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720038},
doi = {10.1145/1719970.1720038},
abstract = {In this paper we examine the use of multi faceted recommendations to aid users while carrying out exploratory video retrieval tasks. These recommendations are integrated into ViGOR (Video Grouping, Organisation and Retrieval), a system which employs grouping techniques to facilitate video retrieval tasks. Two types of recommendations based on past usage history are utilised, the first attempts to couple the multi-faceted nature of explorative video retrieval tasks with the current user interests in order to provide global recommendations, while the second exploits the organisational features of ViGOR in order to provide recommendations based on a specific aspect of the user's task.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {389–392},
numpages = {4},
keywords = {video, exploratory, collaborative, search, recommendation},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720039,
author = {van Schooten, Boris W. and van Dijk, Betsy M.A.G. and Nijholt, Anton and Reiber, Johan H.C.},
title = {Evaluating Automatic Warning Cues for Visual Search in Vascular Images},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720039},
doi = {10.1145/1719970.1720039},
abstract = {Visual search is a task that is performed in various application areas. Search can be aided by an automatic warning system, which highlights the sections that may contain targets and require the user's attention. The effect of imperfect automatic warnings on overall performance ultimately depends on the interplay between the user and the automatic warning system. While various user studies exist, the different studies differ in several experimental variables including the nature of the visualisation itself. Studies in the medical area remain relatively rare, even though there is a growing interest in medical screening systems. We describe an experiment where users had to perform a visual search on a vascular structure, traversing a particular vessel linearly in search of possible errors made in an automatic segmentation. We find that only the case in which the warning system generates only false positives improves user time and error performance. We discuss this finding in relation to the findings of other studies.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {393–396},
numpages = {4},
keywords = {magnetic resonance angiography, image segmentation, automatic warning system, visual search},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720040,
author = {Waldner, Manuela and Pirchheim, Christian and Kruijff, Ernst and Schmalstieg, Dieter},
title = {Automatic Configuration of Spatially Consistent Mouse Pointer Navigation in Multi-Display Environments},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720040},
doi = {10.1145/1719970.1720040},
abstract = {Multi-display environments combine displays of various form factors into a common interaction space. Cross-display navigation techniques have to provide transitions to move the mouse pointer across display boundaries to reach distant display locations. A spatially consistent description of display relationships thereby supports fluid cross-display navigation. In this paper, we present two spatially consistent navigation techniques for seamless cross-display navigation in multi-user multi-display environments. These navigation techniques are automatically configured from a spatial model of the environment, which is generated in a camera-assisted calibration step. We describe the implementation in a distributed system and present results of a comparative experiment.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {397–400},
numpages = {4},
keywords = {multi-display environment, cross-display mouse navigation},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720042,
author = {Berger, Arne},
title = {User Interface for Filtering Videos Interconnecting High Level and Intellectual Metadata},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720042},
doi = {10.1145/1719970.1720042},
abstract = {We present a user interface that combines the requirements needed for information search in a professional environment with the possibilities for multimedial queries based on automatically generated fuzzy high level metadata.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {401–402},
numpages = {2},
keywords = {filtering, user interface, interactive information retrieval},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720043,
author = {Berkovsky, Shlomo and Coombe, Mac and Freyne, Jill and Bhandari, Dipak},
title = {Isn't It Great? You Can PLAY, MATE!},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720043},
doi = {10.1145/1719970.1720043},
abstract = {The addictive nature of game playing contributes to an increasingly sedentary lifestyle. In this demonstration we showcase PLAY, MATE!, a novel mixed reality game design that motivates players to perform physical activity as part of playing. According to the PLAY, MATE! design, players gain virtual game rewards in return for the real physical activity they perform. We demonstrate the application of the PLAY, MATE! design to an open source game and allow participants to experience physical activity motivating games in person.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {403–404},
numpages = {2},
keywords = {bodily interface, game interaction, activity motivation},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720044,
author = {Burel, Gr\'{e}goire and Cano, Amparo Elizabeth},
title = {Understanding Web Documents Using Semantic Overlays},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720044},
doi = {10.1145/1719970.1720044},
abstract = {The Ozone Browser is a platform independent tool that enables users to visually augment the knowledge presented in a web document in an unobtrusive way. This tool supports the user comprehension of Web documents through the use of Semantic Overlays. This tool uses linked data and lightweight semantics for getting relevant information within a document. The current implementation uses a JavaScript bookmarklet.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {405–406},
numpages = {2},
keywords = {semantic web, semantic overlays, web augmentation},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720045,
author = {Elahi, Mehdi},
title = {Context-Aware Intelligent Recommender System},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720045},
doi = {10.1145/1719970.1720045},
abstract = {This demo paper presents a context-aware recommendation system. The system mines data from user's web searches and other sources to improve the presentation of content on visited web pages. While user is browsing the internet, a memory resident agent records and analyzes the content of the webpages that were either searched for or visited in order to identify topic preferences. Then, based on such information, the content of requested web page is ranked and classified with different styles. The demo shows how a music weblog can be modified automatically based on user's affinities.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {407–408},
numpages = {2},
keywords = {recommenders, active learning, context-aware, recommendation systems, fuzzy logic, classification},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720046,
author = {Freyne, Jill and Bhandari, Dipak and Berkovsky, Shlomo and Borlyse, Lyle and Campbell, Chris and Chau, Steve},
title = {Mobile Mentor: Weight Management Platform},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720046},
doi = {10.1145/1719970.1720046},
abstract = {In recent years health care professionals have been investigating the use of ICT technologies in order to influence the general public to change their attitude and behaviour toward a healthier lifestyle. We present Mobile Mentor, a platform aimed at supporting individuals on goal driven programs through personalized mobile technology. This demonstration focuses on a weight loss prototype, Weight Management Mentor, which supports self regulation through the collection of real time diet and exercise data, self reflection and awareness through its graphical feedback mechanisms, and interaction with a health practitioner or advisor through a central server.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {409–410},
numpages = {2},
keywords = {mobile, health, diet},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720047,
author = {Goto, Jun and Sumiyoshi, Hideki and Miyazaki, Masaru and Tanaka, Hideki and Shibata, Masahiro and Aizawa, Akiko},
title = {Relevant TV Program Retrieval Using Broadcast Summaries},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720047},
doi = {10.1145/1719970.1720047},
abstract = {On-demand services for TV program, which provide users with past programs on demand, are becoming popular. It is therefore necessary to find a means of efficiently searching for programs that users want to view, from huge program archives. This paper proposes an automatic method of retrieving programs related to the one being viewed by the user. To that end, we compute similarity between program summaries and closed captions obtained from broadcasting by weighting significant words such as compound words and named entities. Additionally our method provides inter-program relationship labels to indicate why the results of relevant programs were chosen. The results of an evaluation showed that the method recommended relevant programs with higher accuracy than baseline methods and indicated appropriate relationship labels for related programs.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {411–412},
numpages = {2},
keywords = {TV program retrieval, n-gram, named entity, relationship},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720048,
author = {Ketabdar, Hamed and Y\"{u}ksel, Kamer Ali and Roshandel, Mehran},
title = {MagiTact: Interaction with Mobile Devices Based on Compass (Magnetic) Sensor},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720048},
doi = {10.1145/1719970.1720048},
abstract = {In this work, we present a new technique for efficient use of 3D space around a mobile device for interaction with the device. Around Device Interaction (ADI) enables extending interaction space of small mobile and tangible devices beyond their physical boundary. Our proposed method is based on using compass (magnetic field) sensor integrated in mobile devices (e.g. iPhone 3GS, G1 Android). In this method, a properly shaped permanent magnet (e.g. in the shape of a rod, pen or a ring) is used for interaction. The user makes coarse gestures in the 3D space around the device using the magnet. Movement of the magnet affects the magnetic field sensed by the compass sensor integrated in the device. The temporal pattern of the gesture is then used as a basis for sending different interaction commands to the mobile device. Zooming, turning pages, accepting/rejecting calls, clicking items, controlling a music player, and game interaction are some example use cases. The proposed method does not impose changes in hardware specifications of the mobile device, and unlike optical methods is not limited by occlusion problems.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {413–414},
numpages = {2},
keywords = {magnet, compass (magnetic) sensor, around device interaction, movement-based gestures, mobile devices},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720049,
author = {Ketabdar, Hamed and Y\"{u}ksel, Kamer Ali},
title = {Smart Ring: Controlling Call Alert Functionality Based on Audio and Movement Analysis},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720049},
doi = {10.1145/1719970.1720049},
abstract = {In this work, we present a method for controlling call alert functionality in mobile phones. It has happened for almost everybody experiencing a situation that call alert functionality is not proper for actual ambient context, leading to missing a phone call or disturbing others by a loud ring. In this work, we use audio and physical movement analysis to distinguish between different situations in which a mobile phone may ring, and adjust the call alert functionality accordingly. Considering the fact that mobile phones are usually carried in a pocket or bag, capturing ambient audio is not usually practically perfect. The novelty in our work is using information about physical movements of user of mobile device in addition to analysis of ambient audio. Analysis of user movements is based on information captured by acceleration sensors integrated in mobile phone. The call alert functionality is then adjusted based on a combination of ambient audio level and physical activities of user.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {415–416},
numpages = {2},
keywords = {call alert functionality, physical movements, ambient audio, ambient context, acceleration sensors},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720050,
author = {Ketabdar, Hamed and Lyra, Matti},
title = {ActivityMonitor: Assisted Life Using Mobile Phones},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720050},
doi = {10.1145/1719970.1720050},
abstract = {In this work, we present a system and methodology for using mobile phones for monitoring physical activities of a user, and its applications in assisting elderly and people with need for special care and monitoring. The method is based on processing acceleration data provided by accelerometers integrated in mobile phones. This information is sent to a monitoring server, analyzed and presented as different health related factors for assistance, monitoring and healthcare purposes. A monitoring agent can use a desktop application to observe pattern of physical activities of several users in a live manner, and receive warnings in case of unexpected physical conditions. The data can be also stored offline for longer term analysis of physical behaviour and health. The desktop application also provides different options for managing, browsing, and searching activity related data.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {417–418},
numpages = {2},
keywords = {health related factors, acceleration sensor, live activity monitoring, mobile phones, desktop application, assisted life},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720051,
author = {Kratz, Sven and Rohs, Michael},
title = {The $3 Recognizer: Simple 3D Gesture Recognition on Mobile Devices},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720051},
doi = {10.1145/1719970.1720051},
abstract = {We present the $3 Gesture Recognizer, a simple but robust gesture recognition system for input devices featuring 3D acceleration sensors. The algorithm is designed to be implemented quickly in prototyping environments, is intended to be device-independent and does not require any special toolkits or frameworks, but relies solely on simple trigonometric and geometric calculations. Our method requires significantly less training data than other gesture recognizers and is thus suited to be deployed and to deliver results rapidly.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {419–420},
numpages = {2},
keywords = {3D gestures, recognition rates, rapid prototyping, gesture recognition, classifier, user interfaces},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720052,
author = {Lohmann, Steffen and Heim, Philipp and Stegemann, Timo and Ziegler, J\"{u}rgen},
title = {The RelFinder User Interface: Interactive Exploration of Relationships between Objects of Interest},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720052},
doi = {10.1145/1719970.1720052},
abstract = {Being aware of the relationships that exist between objects of interest is crucial in many situations. The RelFinder user interface helps to get an overview: Even large amounts of relationships can be visualized, filtered, and analyzed by the user. Common concepts of knowledge representation are exploited in order to support interactive exploration both on the level of global filters and single relationships. The RelFinder is easy-to-use and works on every RDF knowledge base that provides standardized SPARQL access},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {421–422},
numpages = {2},
keywords = {relationship discovery, sparql, decision support, dbpedia, graph visualization, semantic user interfaces, linked data, semantic web, relationship web, visual exploration},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720053,
author = {Ortiz-Mart\'{\i}nez, Daniel and Leiva, Luis A. and Alabau, Vicent and Casacuberta, Francisco},
title = {Interactive Machine Translation Using a Web-Based Architecture},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720053},
doi = {10.1145/1719970.1720053},
abstract = {In this paper we present a new way of translating documents by using a Web-based system. An interactive approach is proposed as an alternative to post-editing the output of a machine translation system. In this approach, the user's feedback is used to validate or to correct parts of the system output that allow the generation of improved versions of the rest of the output.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {423–424},
numpages = {2},
keywords = {interactive machine translation, computer assisted translation, statistical machine translation},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720054,
author = {Rhienmora, Phattanapon and Gajananan, Kugamoorthy and Haddawy, Peter and Suebnukarn, Siriwan and Dailey, Matthew N. and Supataratarn, Ekarin and Shrestha, Poonam},
title = {Haptic Augmented Reality Dental Trainer with Automatic Performance Assessment},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720054},
doi = {10.1145/1719970.1720054},
abstract = {We developed an augmented reality (AR) dental training simulator utilizing a haptic (force feedback) device. A number of dental procedures such as crown preparation and opening access to the pulp can be simulated with various shapes of dental drill. The system allows students to practise surgery in the correct postures as in the actual environment by combining 3D tooth and tool models upon the real-world view and displaying the result through a video see-through head mounted display (HMD). The system monitors the important features such as applied forces and tool movement that characterize the quality of the procedure. Automatic performance assessment is achieved by comparing outcome and process features of a student with the best matching expert. Moreover, we incorporated kinematic feedback and hand guidance by haptic device. The result from an initial evaluation shows that the simulator is promising for supplemental training.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {425–426},
numpages = {2},
keywords = {automatic performance assessment, dental surgical training, augmented reality, haptic device},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720055,
author = {Smeddinck, Jan and Wajda, Kamila and Naveed, Adeel and Touma, Leen and Chen, Yuting and Hasan, Muhammad Abu and Latif, Muhammad Waqas and Porzel, Robert},
title = {QuickWoZ: A Multi-Purpose Wizard-of-Oz Framework for Experiments with Embodied Conversational Agents},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720055},
doi = {10.1145/1719970.1720055},
abstract = {Herein we describe the QuickWoZ system, a Wizard-of-Oz (WoZ) tool that allows for the remote control of the behavior of animated characters in a 3D environment. The complete scene, character, behaviors and sounds can be defined in simple XML documents, which are parsed at runtime, so that setting up an experiment can be done without programming expertise. Quick selection lists and buttons enable the wizard to easily control the agents' behavior and allow for fast reactions to the subjects' input.The system is tailored for experiments with embodied conversational agents (ECAs) featuring multimodal interaction and was designed as a rapid prototyping system for evaluating the impact of an agent's behavior on the user.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {427–428},
numpages = {2},
keywords = {embodiment, HCI, evaluation, conversational agents},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720056,
author = {Yu, Han and Cai, Yundong and Shen, Zhiqi and Tao, Xuehong and Miao, Chunyan},
title = {Agents as Intelligent User Interfaces for the Net Generation},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720056},
doi = {10.1145/1719970.1720056},
abstract = {Riding on the back of the rapid expansion of the Internet, online virtual worlds which combine the prowess of interactive digital media and social networks have attained a high level of acceptance among the Net Generation users. This development prompted researchers to look into the potential of embedding learning contents into virtual worlds to create virtual learning environments (VLEs) that suit the need of the Net Generation learners. However, the special characteristics of virtual worlds that make them popular also pose great challenges to educators who wish to leverage their power. These challenges call for more sophisticated human computer interaction (HCI) mechanisms to assist learners to navigate the intriguing landscape of VLEs. In this paper, we demonstrate a teachable remembrance agent which acts as an intelligent user interface to provide innovative ways for students to interact with VLEs.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {429–430},
numpages = {2},
keywords = {teachable agent, interface agent, virtual world, virtual learning environment, remembrance agent},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720058,
author = {Andr\'{e}, Elisabeth and Chai, Joyce Y.},
title = {Workshop: Eye Gaze in Intelligent Human Machine Interaction},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720058},
doi = {10.1145/1719970.1720058},
abstract = {This workshop brought researchers from academia and industry together to share recent advances and discuss research directions and opportunities for next generation of intelligent human machine interaction that incorporate eye gaze.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {431–432},
numpages = {2},
keywords = {eye gaze, intelligent human machine interaction},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720059,
author = {Guy, Ido and Chen, Li and Zhou, Michelle X.},
title = {Workshop on Social Recommender Systems},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720059},
doi = {10.1145/1719970.1720059},
abstract = {This workshop brought researchers from academia and industry together to share recent advances and discuss research directions for recommender systems in social media and Web 2.0. With social media sites becoming ubiquitous, the challenges and opportunities for recommendation technologies become greater, setting the grounds for new research and innovation.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {433–434},
numpages = {2},
keywords = {web 2.0, recommender systems, social web, social media},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720060,
author = {Handschuh, Siegfried and Heath, Tom and Thai, VinhTuan and Dickinson, Ian and Aroyo, Lora and Presutti, Valentina},
title = {Visual Interfaces to the Social and Semantic Web (VISSW 2010)},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720060},
doi = {10.1145/1719970.1720060},
abstract = {Recent innovations in the Social and Semantic Web fields have resulted in large amounts of data created, published and consumed by users of the Web. This vast amount of data exists in a variety of formats, from the traditional ones such as text, image, video to the more recent additions such as streams of status information from Twitter and Facebook. The ability to easily integrate such vast amounts of data raises significant and exciting research challenges, not least of which how to provide effective access to and navigation across heterogeneous data sources on different platforms (e.g. computers, mobile devices, set-top boxes). Building on the success of the VISSW2009 workshop, the IUI2010 workshop on Visual Interfaces to the Social and Semantic Web aims to bring together researchers and practitioners from different fields to discuss the latest research results and challenges in designing, implementing, and evaluating intelligent interfaces supporting access, navigation and publishing of different types of contents on the Social and Semantic Web. This paper outlines the context of the workshop and provides an overview of the research to be presented at the event.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {435–436},
numpages = {2},
keywords = {visual interfaces, social and semantic web},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720061,
author = {Hussein, Tim and Lukosch, Stephan G. and Ziegler, Juergen and Dix, Alan},
title = {1st International Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS 2010)},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720061},
doi = {10.1145/1719970.1720061},
abstract = {The International Workshop on Semantic Models for Adaptive Interactive Systems (SEMAIS 2010) aims to identify emerging trends in interactive system design using semantic models.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {437–438},
numpages = {2},
keywords = {semantic models, interface design, adaptive interactive systems, usability, model-driven user interfaces},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720062,
author = {Liu, Shixia and Zhou, Michelle X. and Carenini, Giuseppe and Qu, Huamin},
title = {Workshop on Intelligent Visual Interfaces for Text Analysis},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720062},
doi = {10.1145/1719970.1720062},
abstract = {This workshop brought together researchers and practitioners from both text analytics and interactive visualization communities to explore, define, and develop intelligent visual interfaces that help enhance the consumption and quality of complex text analysis results. Using this workshop as a starting point, we aim to foster closer, interdisciplinary relationships among researchers from text analytics and interactive visualization communities, so they can combine their expertise together to better tackle the difficult problems that face the text analytics community today.},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {439–440},
numpages = {2},
keywords = {text analytics, interactie visualization, visual analytics},
location = {Hong Kong, China},
series = {IUI '10}
}

@inproceedings{10.1145/1719970.1720063,
author = {Feld, Michael and M\"{u}ller, Christian A. and Schwartz, Tim},
title = {2nd Multimodal Interfaces for Automotive Applications (MIAA 2010)},
year = {2010},
isbn = {9781605585154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1719970.1720063},
doi = {10.1145/1719970.1720063},
abstract = {This paper summarizes the main objectives of the 2nd IUI workshop on multimodal interfaces for automotive applications (MIAA 2010).},
booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
pages = {441–442},
numpages = {2},
keywords = {human-machine-interaction, automotive applications, multimodal interfaces},
location = {Hong Kong, China},
series = {IUI '10}
}

