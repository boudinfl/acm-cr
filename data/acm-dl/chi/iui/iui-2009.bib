@inproceedings{10.1145/1502650.1502652,
author = {Darrell, Trevor},
title = {Invited Talk: Image Recognition for Intelligent Interfaces},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502652},
doi = {10.1145/1502650.1502652},
abstract = {When interaction concerns the physical world, interfaces should do their best to search for information using direct observation. Image-based interfaces have been tried in the past, but generally required artificial barcode tags to be affixed to each viewed object or surface. Recent advances in computer vision and content-based image retrieval have enabled fast and robust indexing from images of individual objects--CD covers, book jackets, magazine advertisements, etc.--even on relatively low-power platforms such as camera-equipped mobile phones. I'll review the relevant algorithms and design of such systems, and discuss what types of image recognition interfaces are feasible in the near term. I'll describe very recent work on multimodal question answering interfaces, which combine image and text query matching with human-in-the-loop interaction. I'll close with a discussion of the anticipated future progress on category-level visual recognition, and what classes of interfaces it may enable.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {1–2},
numpages = {2},
keywords = {object recognition, user interfaces, computer vision},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502653,
author = {Rekimoto, Jun},
title = {Sensonomy: Intelligence Penetrating into the Real Space},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502653},
doi = {10.1145/1502650.1502653},
abstract = {Recent commoditization of mobile digital devices and net-working brought us to use them as a very large-scale sensing platform. We call this possibility "Sensonmoy", which is an integration of collective intelligence (also known as "folk-sonomy") and pervasive sensing. As many users own mobile devices with sensing facilities, a collection of sensing data from these devices becomes quite important, and integration of them can be used in a very different manner. Such feature could be a new way to create intelligent systems and inter-faces. In this talk, I am going to discuss a possibility of con-necting a large number of simple devices to produce intelligent interactions. As a realistic example of them, I will introduce a city-scale indoor and outdoor positioning system that we have developed, and how its database can be evolved by using the idea of Sensonomy. I would also like to discuss computer-augmented memory and lifelong computing based on our platform.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {3–4},
numpages = {2},
keywords = {sensonomy, lifelong computing, location aware computing},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502654,
author = {Halevy, Alon Y.},
title = {User-Focused Database Management},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502654},
doi = {10.1145/1502650.1502654},
abstract = {This talk describes two projects whose over goal is to make database management systems usable by a wider audience. Dataspaces aim to eliminate the upfront effort involved in creating a database. Data mangement for collaboration attempts to shift the focus of data mangement to supporting users in their natural environments and workflow.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {5–6},
numpages = {2},
keywords = {collaboration systems, dataspaces, user interfaces, databaase management},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502656,
author = {Xu, Songhua and Jiang, Hao and Lau, Francis C.M.},
title = {User-Oriented Document Summarization through Vision-Based Eye-Tracking},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502656},
doi = {10.1145/1502650.1502656},
abstract = {We propose a new document summarization algorithm which is personalized. The key idea is to rely on the attention (reading) time of individual users spent on single words in a document as the essential clue. The prediction of user attention over every word in a document is based on the user's attention during his previous reads, which is acquired via a vision-based commodity eye-tracking mechanism. Once the user's attentions over a small collection of words are known, our algorithm can predict the user's attention over every word in the document through word semantics analysis. Our algorithm then summarizes the document according to user attention on every individual word in the document. With our algorithm, we have developed a document summarization prototype system. Experiment results produced by our algorithm are compared with the ones manually summarized by users as well as by commercial summarization software, which clearly demonstrates the advantages of our new algorithm for user-oriented document summarization.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {7–16},
numpages = {10},
keywords = {user attention, personalized discourse abstract, commodity eye-tracking, user-oriented document summarization, implicit user feedback},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502657,
author = {Hsueh, Pei-Yun and Moore, Johanna D.},
title = {Improving Meeting Summarization by Focusing on User Needs: A Task-Oriented Evaluation},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502657},
doi = {10.1145/1502650.1502657},
abstract = {Advances in multimedia technologies have enabled the creation of huge archives of audio-video recordings of meetings, and there is burgeoning interest in developing meeting browsers to help users better leverage these archives. A recent study has shown that extractive summaries provide a more efficient way of navigating meeting content than simply reading through the transcript and using the audio-video record, or navigating via keyword search (Murray, 2007). The extractive summary technique identifies informative dialogue acts to generate general purpose summaries. These summaries can still be lengthy. Recently, we have developed a decision-focused summarization system that presents only 1-2% of the recordings related to decision making. In this paper, we describe a task-based evaluation in which we compare the decision-focused summaries to the general purpose summaries. Our results indicate that the more focused summaries help users perform the decision debriefing task more effectively and improve perceived efficiency. In addition, this study also investigates the effect of automatic summaries and transcription on task effectiveness, report quality, and users' perceptions of task success.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {17–26},
numpages = {10},
keywords = {meeting browser, automatic summarization, task-oriented evaluation, multimedia information retrieval, user study.},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502658,
author = {Wagner, Earl J. and Liu, Jiahui and Birnbaum, Larry and Forbus, Kenneth D.},
title = {Rich Interfaces for Reading News on the Web},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502658},
doi = {10.1145/1502650.1502658},
abstract = {Using content-specific models to guide information retrieval and extraction can provide richer interfaces to end-users for both understanding the context of news events and navigating related news articles. In this paper we discuss a system, Brussell, that uses semantic models to organize retrieval and extraction results, generating both storylines explaining how news event situations unfold and also biographical sketches of the situation participants. We generalize these models to introduce a new category of knowledge representation, an explanatory structure, that can scale up to include information from hundreds of documents, yet still provide model-based UI support to end-users. An informal survey of business news suggests the broad prevalence of news event situations indicating Brussell's potential utility, while an evaluation quantifies its performance in finding kidnapping situations.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {27–36},
numpages = {10},
keywords = {explanatory structures},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502659,
author = {Tucker, Simon and Whittaker, Steve},
title = {Have a Say over What You See: Evaluating Interactive Compression Techniques},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502659},
doi = {10.1145/1502650.1502659},
abstract = {We all encounter many documents on a daily basis that we do not have time to process in their entirety. Nevertheless, we lack good tools to rapidly skim and identify key information from within such documents. This paper develops and evaluates Interactive Compression (IC) techniques that allow users to dynamically configure the amount of information they view in a document, e.g. by automatically removing unimportant information from view (Excision) or by making important information more salient (Highlighting). We explore IC techniques in the context of meeting transcripts that are typically unstructured - making it difficult to isolate relevant regions and extract key information. We demonstrate the superiority of IC compared with an unmodified text control. In contrast to traditional summaries, our results show extensive use of interactive, as opposed to fixed compression level, summarization. They also show the value of word- as opposed to utterance-based compression. There are also trade-offs between different IC designs. Excision allows users to scan documents faster than Highlighting but at the expense of overlooking relevant sections of the document.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {37–46},
numpages = {10},
keywords = {reading, gist, scanning, meetings, interactive compression, summary},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502661,
author = {Vig, Jesse and Sen, Shilad and Riedl, John},
title = {Tagsplanations: Explaining Recommendations Using Tags},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502661},
doi = {10.1145/1502650.1502661},
abstract = {While recommender systems tell users what items they might like, explanations of recommendations reveal why they might like them. Explanations provide many benefits, from improving user satisfaction to helping users make better decisions. This paper introduces tagsplanations, which are explanations based on community tags. Tagsplanations have two key components: tag relevance, the degree to which a tag describes an item, and tag preference, the user's sentiment toward a tag. We develop novel algorithms for estimating tag relevance and tag preference, and we conduct a user study exploring the roles of tag relevance and tag preference in promoting effective tagsplanations. We also examine which types of tags are most useful for tagsplanations.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {47–56},
numpages = {10},
keywords = {tagging, recommender systems, explanations},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502662,
author = {Bonnin, Geoffray and Brun, Armelle and Boyer, Anne},
title = {A Low-Order Markov Model Integrating Long-Distance Histories for Collaborative Recommender Systems},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502662},
doi = {10.1145/1502650.1502662},
abstract = {Recommender systems provide users with pertinent resources according to their context and their profiles, by applying statistical and knowledge discovery techniques. This paper describes a new approach of generating suitable recommendations based on the active user's navigation stream, by considering long and short-distance resources in the history with a tractable model.The Skipping Based Recommender we propose uses Markov models inspired from the ones used in language modeling while integrating skipping techniques to handle noise during navigation. Weighting schemes are also used to alleviate the importance of distant resources. This recommender has also the characteristic to be anytime.It has been tested on a browsing dataset extracted from Intranet logs provided by a French bank. Results show that the use of exponential decay weighting schemes when taking into account non contiguous resources to compute recommendations enhances the accuracy. Moreover, the skipping variant we propose provides a high accuracy while being less complex than state of the art variants.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {57–66},
numpages = {10},
keywords = {skipping, recommender systems, markov models, weighting schemes},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502663,
author = {Hijikata, Yoshinori and Shimizu, Takuya and Nishida, Shogo},
title = {Discovery-Oriented Collaborative Filtering for Improving User Satisfaction},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502663},
doi = {10.1145/1502650.1502663},
abstract = {Many recommender systems employed in commercial web sites use collaborative filtering. The main goal of traditional collaborative filtering techniques is improvement of the accuracy of recommendation. Nevertheless, such techniques present the problem that they include many items that the user already knows. These recommendations appear to be good when we consider accuracy alone. On the other hand, when we consider users' satisfaction, they are not necessarily good because of the lack of discovery. In our work, we infer items that a user does not know by calculating the similarity of users or items based on information about what items users already know. We seek to recommend items that the user would probably like and does not know by combining the above method and the most popular method of collaborative filtering.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {67–76},
numpages = {10},
keywords = {novelty, discovery ratio, profile of acquaintance, collaborative filtering},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502664,
author = {Guy, Ido and Ronen, Inbal and Wilcox, Eric},
title = {Do You Know? Recommending People to Invite into Your Social Network},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502664},
doi = {10.1145/1502650.1502664},
abstract = {In this paper we describe a novel UI and system for providing users with recommendations of people to invite into their explicit enterprise social network. The recommendations are based on aggregated information collected from various sources across the organization and are displayed in a widget, which is part of a popular enhanced employee directory. Recommended people are presented one by one, with detailed reasoning as for why they were recommended. Usage results are presented for a period of four months that indicate an extremely significant impact on the number of connections created in the system. Responses in the organization's blogging system, a survey with over 200 participants, and a set of interviews we conducted shed more light on the way the widget is used and implications of the design choices made.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {77–86},
numpages = {10},
keywords = {recommender systems, social networks, people recommendations, sns},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502666,
author = {Sen, Shilad and Vig, Jesse and Riedl, John},
title = {Learning to Recognize Valuable Tags},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502666},
doi = {10.1145/1502650.1502666},
abstract = {Many websites use tags as a mechanism for improving item metadata through collective user effort. Users of tagging systems often apply far more tags to an item than a system can display. These tags can range in quality from tags that capture a key facet of an item, to those that are subjective, irrelevant, or misleading. In this paper we explore tag selection algorithms that choose the tags that sites display. Based on 225,000 ratings and survey responses, we conduct offline analyses of 21 tag selection algorithms. We select the three best performing algorithms from our offline analysis, and deploy them live on the MovieLens website to 5,695 users for three months. Based on our results, we offer tagging system designers advice about tag selection algorithms.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {87–96},
numpages = {10},
keywords = {user interfaces, moderation, tagging},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502667,
author = {Lin, James and Wong, Jeffrey and Nichols, Jeffrey and Cypher, Allen and Lau, Tessa A.},
title = {End-User Programming of Mashups with Vegemite},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502667},
doi = {10.1145/1502650.1502667},
abstract = {Mashups are an increasingly popular way to integrate data from multiple web sites to fit a particular need, but it often requires substantial technical expertise to create them. To lower the barrier for creating mashups, we have extended the CoScripter web automation tool with a spreadsheet-like environment called Vegemite. Our system uses direct-manipulation and programming-by-demonstration tech-niques to automatically populate tables with information collected from various web sites. A particular strength of our approach is its ability to augment a data set with new values computed by a web site, such as determining the driving distance from a particular location to each of the addresses in a data set. An informal user study suggests that Vegemite may enable a wider class of users to address their information needs.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {97–106},
numpages = {10},
keywords = {web, programming by demonstration, end-user programming, automation, mashup, data integration},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502668,
author = {Cheng, Wen-Huang and Gotz, David},
title = {Context-Based Page Unit Recommendation for Web-Based Sensemaking Tasks},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502668},
doi = {10.1145/1502650.1502668},
abstract = {Sensemaking tasks require that users gather and comprehend information from many sources to answer complex questions. Such tasks are common and include, for example, researching vacation destinations or performing market analysis. In this paper, we present an algorithm and interface which provides context-based page unit recommendation to assist in connection discovery during sensemaking tasks. We exploit the natural note-taking activity common to sensemaking behavior as the basis for a task-specific context model. Our algorithm then dynamically analyzes each web page visited by a user to determine which page units are most relevant to the user's task. We present the details of our recommendation algorithm, describe the user interface, and present the results of a user study which show the effectiveness of our approach.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {107–116},
numpages = {10},
keywords = {recommendation, www, sensemaking, search},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502670,
author = {Shen, Jianqiang and Irvine, Jed and Bao, Xinlong and Goodman, Michael and Kolibaba, Stephen and Tran, Anh and Carl, Fredric and Kirschner, Brenton and Stumpf, Simone and Dietterich, Thomas G.},
title = {Detecting and Correcting User Activity Switches: Algorithms and Interfaces},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502670},
doi = {10.1145/1502650.1502670},
abstract = {The TaskTracer system allows knowledge workers to define a set of activities that characterize their desktop work. It then associates with each user-defined activity the set of resources that the user accesses when performing that activity. In order to correctly associate resources with activities and provide useful activity-related services to the user, the system needs to know the current activity of the user at all times. It is often convenient for the user to explicitly declare which activity he/she is working on. But frequently the user forgets to do this. TaskTracer applies machine learning methods to detect undeclared activity switches and predict the correct activity of the user. This paper presents TaskPredictor2, a complete redesign of the activity predictor in TaskTracer and its notification user interface. TaskPredictor2 applies a novel online learning algorithm that is able to incorporate a richer set of features than our previous predictors. We prove an error bound for the algorithm and present experimental results that show improved accuracy and a 180-fold speedup on real user data. The user interface supports negotiated interruption and makes it easy for the user to correct both the predicted time of the task switch and the predicted activity.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {117–126},
numpages = {10},
keywords = {resource management, online learning, activity recognition},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502671,
author = {Lu, Jie and Zhou, Michelle X.},
title = {An Interactive, Smart Notepad for Context-Sensitive Information Seeking},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502671},
doi = {10.1145/1502650.1502671},
abstract = {We are building an interactive, smart notepad system where users enter brief notes to drive a dynamic information-seeking process. In this paper, we focus on describing our work from two aspects: 1) dynamic interpretation of user notes in context to infer a user's information needs, and 2) automatic generation of data queries to satisfy the inferred user needs. Compared to existing information systems, our work offers three unique contributions. First, our system allows users to focus on what to retrieve instead of how, since users can use brief notes to express their information needs without worrying about specific retrieval details. Second, users can use notes to efficiently request multiple pieces of information at once instead of issuing one query at a time. Third, users can easily update any part of their notes to obtain new or updated information. Whenever a user's notes are modified, our system automatically detects and evaluates all affected note sections to retrieve new or updated information. Our preliminary evaluation shows the promise of this work.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {127–136},
numpages = {10},
keywords = {automatic query formulation, context-sensitive information seeking, note-driven information retrieval},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502672,
author = {Speer, Robyn and Krishnamurthy, Jayant and Havasi, Catherine and Smith, Dustin and Lieberman, Henry and Arnold, Kenneth},
title = {An Interface for Targeted Collection of Common Sense Knowledge Using a Mixture Model},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502672},
doi = {10.1145/1502650.1502672},
abstract = {We present a game-based interface for acquiring common sense knowledge. In addition to being interactive and entertaining, our interface guides the knowledge acquisition process to learn about the most salient characteristics of a particular concept. We use statistical classification methods to discover the most informative characteristics in the Open Mind Common Sense knowledge base, and use these characteristics to play a game of 20 Questions with the user. Our interface also allows users to enter knowledge more quickly than a more traditional knowledge-acquisition interface. An evaluation showed that users enjoyed the game and that it increased the speed of knowledge acquisition.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {137–146},
numpages = {10},
keywords = {human computation, common sense reasoning, knowledge acquisition, hierarchical bayes model},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502673,
author = {Gyllstrom, Karl},
title = {<i>Passages through Time</i>: Chronicling Users' Information Interaction History by Recording When and What They Read},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502673},
doi = {10.1145/1502650.1502673},
abstract = {The Passages system enhances information management by maintaining a detailed chronicle of all the text the user ever reads or edits, and making this chronicle available for rich temporal queries about the user's information workspace. Passages enables queries like, "which papers and web pages did I read when writing the 'related work' section of this paper?", and, "which of the emails in this folder have I skimmed, but not yet read in detail?" As time and interaction history are important attributes in users' recall of their personal information, effectively supporting them creates useful possibilities for information retrieval. We present methods to collect and make sense of the large volume of text with which the user interacts. We show through user evaluation the accuracy of Passages in building interaction history, and illustrate its capacity to both improve existing retrieval systems and enable novel ways to characterize document activity across time.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {147–156},
numpages = {10},
keywords = {time-machine computing, context, information retrieval},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502675,
author = {Gervasio, Melinda T. and Murdock, Janet L.},
title = {What Were You Thinking? Filling in Missing Dataflow through Inference in Learning from Demonstration},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502675},
doi = {10.1145/1502650.1502675},
abstract = {Recent years have seen a resurgence of interest in programming by demonstration. As end users have become increasingly sophisticated, computer and artificial intelligence technology has also matured, making it feasible for end users to teach long, complex procedures. This paper addresses the problem of learning from demonstrations involving unobservable (e.g., mental) actions. We explore the use of knowledge base inference to complete missing dataflow and investigate the approach in the context of the CALO cognitive personal desktop assistant. We experiment with the Pathfinder utility, which efficiently finds all the relationships between any two objects in the CALO knowledge base. Pathfinder often returns too many paths to present to the user and its default shortest path heuristic sometimes fails to identify the correct path. We develop a set of filtering techniques for narrowing down the results returned by Pathfinder and present experimental results showing that these techniques effectively reduce the alternative paths to a small, meaningful set suitable for presentation to a user.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {157–166},
numpages = {10},
keywords = {end-user programming, programming by example, programming by demonstration, knowledge-base inference, task learning},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502676,
author = {Ritter, Alan and Basu, Sumit},
title = {Learning to Generalize for Complex Selection Tasks},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502676},
doi = {10.1145/1502650.1502676},
abstract = {Selection tasks are common in modern computer interfaces: we are often required to select a set of files, emails, data entries, and the like. File and data browsers have sorting and block selection facilities to make these tasks easier, but for complex selections there is little to aid the user without writing complex search queries. We propose an interactive machine learning solution to this problem called "smart selection," in which the user selects and deselects items as inputs to a selection classifier which attempts at each step to correctly generalize to the user's target state. Furthermore, we take advantage of our data on how users perform selection tasks over many sessions, and use it to train a label regressor that models their generalization behavior: we call this process learning to generalize. We then combine the user's explicit labels as well the label regressor outputs in the selection classifier to predict the user's desired selections. We show that the selection classifier alone takes dramatically fewer mouse clicks than the standard file browser, and when used in conjunction with the label regressor, the predictions of the classifier are significantly more accurate with respect to the target selection state.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {167–176},
numpages = {10},
keywords = {learning to generalize, meta-learning, learning user models, learning by example, transfer learning, interactive selection, programming by demonstration, file selection, user modeling},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502677,
author = {Bigham, Jeffrey P. and Lau, Tessa and Nichols, Jeffrey},
title = {Trailblazer: Enabling Blind Users to Blaze Trails through the Web},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502677},
doi = {10.1145/1502650.1502677},
abstract = {For blind web users, completing tasks on the web can be frustrating. Each step can require a time-consuming linear search of the current web page to find the needed interactive element or piece of information. Existing interactive help systems and the playback components of some programming-by-demonstration tools identify the needed elements of a page as they guide the user through predefined tasks, obviating the need for a linear search on each step. We introduce TrailBlazer, a system that provides an accessible, non-visual interface to guide blind users through existing how-to knowledge. A formative study indicated that participants saw the value of TrailBlazer but wanted to use it for tasks and web sites for which no existing script was available. To address this, TrailBlazer offers suggestion-based help created on-the-fly from a short, user-provided task description and an existing repository of how-to knowledge. In an evaluation on 15 tasks, the correct prediction was contained within the top 5 suggestions 75.9% of the time.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {177–186},
numpages = {10},
keywords = {blind users, suggestions, non-visual interfaces, web accessibility, programming-by-demonstration},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502678,
author = {Kulesza, Todd and Wong, Weng-Keen and Stumpf, Simone and Perona, Stephen and White, Rachel and Burnett, Margaret M. and Oberst, Ian and Ko, Andrew J.},
title = {Fixing the Program My Computer Learned: Barriers for End Users, Challenges for the Machine},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502678},
doi = {10.1145/1502650.1502678},
abstract = {The results of a machine learning from user behavior can be thought of as a program, and like all programs, it may need to be debugged. Providing ways for the user to debug it matters, because without the ability to fix errors users may find that the learned program's errors are too damaging for them to be able to trust such programs. We present a new approach to enable end users to debug a learned program. We then use an early prototype of our new approach to conduct a formative study to determine where and when debugging issues arise, both in general and also separately for males and females. The results suggest opportunities to make machine-learned programs more effective tools.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {187–196},
numpages = {10},
keywords = {debugging, machine learning, end-user programming},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502680,
author = {Bee, Nikolaus and Falk, Bernhard and Andr\'{e}, Elisabeth},
title = {Simplified Facial Animation Control Utilizing Novel Input Devices: A Comparative Study},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502680},
doi = {10.1145/1502650.1502680},
abstract = {Editing facial expressions of virtual characters is quite a complex task. The face is made up of many muscles, which are partly activated concurrently. Virtual faces with human expressiveness are usually designed with a limited amount of facial regulators. Such regulators are derived from the facial muscle parts that are concurrently activated. Common tools for editing such facial expressions use slider-based interfaces where only a single input at a time is possible. Novel input devices, such as gamepads or data gloves, which allow parallel editing, could not only speed up editing, but also simplify the composition of new facial expressions. We created a virtual face with 23 facial controls and connected it with a slider-based GUI, a gamepad, and a data glove. We first conducted a survey with professional graphics designers to find out how the latter two new input devices would be received in a commercial context. A second comparative study with 17 subjects was conducted to analyze the performance and quality of these two new input devices using subjective and objective measurements.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {197–206},
numpages = {10},
keywords = {virtual avatar, gamepad, data glove, input device, facial expression},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502681,
author = {Stoiber, Nicolas and Seguier, Renaud and Breton, Gaspard},
title = {Automatic Design of a Control Interface for a Synthetic Face},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502681},
doi = {10.1145/1502650.1502681},
abstract = {Getting synthetic faces to display natural facial expressions is essential to enhance the interaction between human users and virtual characters. Yet traditional facial control techniques provide precise but complex sets of control parameters, which are not adapted for non-expert users. In this article, we present a system that generates a simple, 2-Dimensional interface that offers an efficient control over the facial expressions of any synthetic character. The interface generation process relies on the analysis of the deformation of a real human face. The principal geometrical and textural variation patterns of the real face are detected and automatically reorganized onto a low-dimensional space. This control space can then be easily adapted to pilot the deformations of synthetic faces. The resulting virtual character control interface makes it easy to produce varied emotional facial expressions, both extreme and subtle. In addition, the continuous nature of the interface allows the production of coherent temporal sequences of facial animation.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {207–216},
numpages = {10},
keywords = {aam, facial animation, user interface, avatar, traveling salesman problem, virtual character},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502682,
author = {Schwartz, Lane and Nguyen, Luan and Exley, Andrew and Schuler, William},
title = {Positive Effects of Redundant Descriptions in an Interactive Semantic Speech Interface},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502682},
doi = {10.1145/1502650.1502682},
abstract = {Spoken language interfaces based on interactive semantic language models allow probabilities for hypothesized words to be conditioned on the semantic interpretation of these words in the context of some interfaced application environment. This conditioning may allow users to avoid recognition errors in an intuitive way, by adding extra, possibly redundant description. This paper evaluates the effect on error reduction of redundant descriptions in an interactive semantic language model. In order to evaluate the effect in natural use, the model is run on rich domains, supporting references to sets of individuals (instead of just individuals themselves) arranged in multiple continuous dimensions (a 2-D floorplan scene). Results of these experiments suggest that an interactive semantic language model allows users to achieve significantly higher recognition accuracy by providing additional redundant spoken description.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {217–226},
numpages = {10},
keywords = {spoken language interfaces, semantics, speech recognition, interactive semantics},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502683,
author = {Nichols, Eric and Morris, Dan and Basu, Sumit},
title = {Data-Driven Exploration of Musical Chord Sequences},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502683},
doi = {10.1145/1502650.1502683},
abstract = {We present data-driven methods for supporting musical creativity by capturing the statistics of a musical database. Specifically, we introduce a system that supports users in exploring the high-dimensional space of musical chord sequences by parameterizing the variation among chord sequences in popular music. We provide a novel user interface that exposes these learned parameters as control axes, and we propose two automatic approaches for defining these axes. One approach is based on a novel clustering procedure, the other on principal components analysis. A user study compares our approaches for defining control axes both to each other and to an approach based on manually-assigned genre labels. Results show that our automatic methods for defining control axes provide a subjectively better user experience than axes based on manual genre labeling.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {227–236},
numpages = {10},
keywords = {pca, creativity, clustering, music, chords, genre, transition matrix, hmms},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502685,
author = {Vertanen, Keith and Kristensson, Per Ola},
title = {Parakeet: A Continuous Speech Recognition System for Mobile Touch-Screen Devices},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502685},
doi = {10.1145/1502650.1502685},
abstract = {We present Parakeet, a system for continuous speech recognition on mobile touch-screen devices. The design of Parakeet was guided by computational experiments and validated by a user study. Participants had an average text entry rate of 18 words-per-minute (WPM) while seated indoors and 13 WPM while walking outdoors. In an expert pilot study, we found that speech recognition has the potential to be a highly competitive mobile text entry method, particularly in an actual mobile setting where users are walking around while entering text.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {237–246},
numpages = {10},
keywords = {word confusion network, text input, touch-screen interface, speech input, predictive keyboard, error correction, mobile text entry, continuous speech recognition},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502686,
author = {Church, Karen and Smyth, Barry},
title = {Understanding the Intent behind Mobile Information Needs},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502686},
doi = {10.1145/1502650.1502686},
abstract = {Mobile phones are becoming increasingly popular as a means of information access while on-the-go. Mobile users are likely to be interested in locating different types of content. However, the mobile space presents a number of key challenges, many of which go beyond issues with device characteristics such as screen-size and input capabilities. In particular, changing contexts such as location, time, activity and social interactions are likely to impact on the types of information needs that arise. In order to offer personalized, effective mobile services we need to understand mobile users in more detail. Thus we carried out a four-week diary study of mobile information needs, looking in particular at the goal/intent behind mobile information needs, the topics users are interested in and the impact of mobile contexts such as location and time on user needs.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {247–256},
numpages = {10},
keywords = {context, intent, mobile, information needs, diary study},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502687,
author = {Shani, Guy and Meek, Christopher and Paek, Tim and Thiesson, Bo and Venolia, Gina Danielle},
title = {Searching Large Indexes on Tiny Devices: Optimizing Binary Search with Character Pinning},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502687},
doi = {10.1145/1502650.1502687},
abstract = {The small physical size of mobile devices imposes dramatic restrictions on the user interface (UI). With the ever increasing capacity of these devices as well as access to large online stores it becomes increasingly important to help the user select a particular item efficiently. Thus, we propose binary search with character pinning, where users can constrain their search to match selected prefix characters while making simple binary decisions about the position of their intended item in the lexicographic order. The underlying index for our method is based on a ternary search tree that is optimal under certain user-oriented constraints. To better scale to larger indexes, we analyze several heuristics that rapidly construct good trees. A user study demonstrates that our method helps users conduct rapid searches, using less keystrokes, compared to other methods.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {257–266},
numpages = {10},
keywords = {optimal binary search tree, binary search},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502688,
author = {Brombach, Benjamin and Bruns, Erich and Bimber, Oliver},
title = {Subobject Detection through Spatial Relationships on Mobile Phones},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502688},
doi = {10.1145/1502650.1502688},
abstract = {We present a novel image classification technique for detecting multiple objects (called subobjects) in a single image. In addition to image classifiers, we apply spatial relationships among the subobjects to verify and to predict the locations of detected and undetected subobjects, respectively. By continuously refining the spatial relationships throughout the detection process, even locations of completely occluded exhibits can be determined. This approach is applied in the context of PhoneGuide, an adaptive museum guidance system for camera-equipped mobile phones.Laboratory tests as well as a field experiment reveal recognition rates and performance improvements when compared to related approaches.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {267–276},
numpages = {10},
keywords = {mobile computing, subobject detection, image classification, spatial relationships, museum guidance application},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@dataset{10.1145/review-1502650.1502688_R45075,
author = {Poullis, Charalambos},
title = {Review ID:R45075 for DOI: 10.1145/1502650.1502688},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1502650.1502688_R45075}
}

@inproceedings{10.1145/1502650.1502690,
author = {Shen, Jianqiang and Fitzhenry, Erin and Dietterich, Thomas G.},
title = {Discovering Frequent Work Procedures from Resource Connections},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502690},
doi = {10.1145/1502650.1502690},
abstract = {Intelligent desktop assistants could provide more help for users if they could learn models of the users' workflows. However, discovering desktop workflows is difficult because they unfold over extended periods of time (days or weeks) and they are interleaved with many other workflows because of user multi-tasking. This paper describes an approach to discovering desktop workflows based on rich instrumentation of information flow actions such as copy/paste, SaveAs, file copy, attach file to email message, and save attachment. These actions allow us to construct a graph whose nodes are files, email messages, and web pages and whose edges are these information flow actions. A class of workflows that we call work procedures can be discovered by applying graph mining algorithms to find frequent subgraphs. This paper describes an algorithm for mining frequent closed connected subgraphs and then describes the results of applying this method to data collected from a group of real users.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {277–286},
numpages = {10},
keywords = {provenance, workflow, data mining, resource management, intelligent interfaces, automated assistance},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502691,
author = {Hui, Bowen and Partridge, Grant and Boutilier, Craig},
title = {A Probabilistic Mental Model for Estimating Disruption},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502691},
doi = {10.1145/1502650.1502691},
abstract = {Adaptive software systems are intended to modify their appearance, performance or functionality to the needs and preferences of different users. A key bottleneck in building effective adaptive systems is accounting for the cost of disruption to a user's mental model of the application caused by the system's adaptive behaviour. In this work, we propose a probabilistic approach to modeling the cost of disruption. This allows an adaptive system to tradeoff disruption cost with expected savings (or other benefits) induced by a potential adaptation in a principled, decision-theoretic fashion. We conducted two experiments with 48 participants to learn model parameters in an adaptive menu selection environment. We demonstrate the utility of our approach in simulation and usability studies. Usability results with 8 participants suggest that our approach is competitive with other adaptive menus w.r.t. task performance, while providing the ability to reduce disruption and adapt to user preferences.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {287–296},
numpages = {10},
keywords = {user modeling, decision-theoretic systems, disruption, probabilistic mental model},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502692,
author = {Scaffidi, Christopher and Myers, Brad and Shaw, Mary},
title = {Intelligently Creating and Recommending Reusable Reformatting Rules},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502692},
doi = {10.1145/1502650.1502692},
abstract = {When users combine data from multiple sources into a spreadsheet or dataset, the result is often a mishmash of different formats, since phone numbers, dates, course numbers and other string-like kinds of data can each be written in many different formats. Although spreadsheets provide features for reformatting numbers and a few specific kinds of string data, they do not provide any support for the wide range of other kinds of string data encountered by users. We describe a user interface where a user can describe the formats of each kind of data. We provide an algorithm that uses these formats to automatically generate reformatting rules that transform strings from one format to another. In effect, our system enables users to create a small expert system called a "tope" that can recognize and reformat instances of one kind of data. Later, as the user is working with a spreadsheet, our system recommends appropriate topes for validating and reformatting the data. With a recall of over 80% for a query time of under 1 second, this algorithm is accurate enough and fast enough to make useful recommendations in an interactive setting. A laboratory experiment shows that compared to manual typing, users can reformat sample spreadsheet data more than twice as fast by creating and using topes.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {297–306},
numpages = {10},
keywords = {spreadsheets, consistent data format, end-user programming},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502693,
author = {Ju, Jin Sun and Shin, Yunhee and Kim, Eun Yi},
title = {Intelligent Wheelchair (IW) Interface Using Face and Mouth Recognition},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502693},
doi = {10.1145/1502650.1502693},
abstract = {between the user and the wheelchair. To facilitate a wide variety of user abilities, the proposed system uses faceinclination and mouth-shape information as user's intention, where the direction of an IW is determined by the inclination of the user's face, while proceeding and stopping are determined by the shape of the user's mouth. This mechanism requires minimal motion, thereby making the system more comfortable and adaptable for the severely disabled. Furthermore, to fully guarantee user's safety, the 10 range-sensors are used to detect obstacles in environment and avoid them. To assess the effectiveness of the proposed IW, it was tested with 34 users and the results show that it can provide a user unable to drive a standard joystick with friendly and convenient system},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {307–314},
numpages = {8},
keywords = {intelligent interface, adaboost, vision based interface, intelligent wheelchair, k-means clustering, facial feature recogition},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502695,
author = {Gotz, David and Wen, Zhen},
title = {Behavior-Driven Visualization Recommendation},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502695},
doi = {10.1145/1502650.1502695},
abstract = {We present a novel approach to visualization recommendation that monitors user behavior for implicit signals of user intent to provide more effective recommendation. This is in contrast to previous approaches which are either insensitive to user intent or require explicit, user specified task information. Our approach, called Behavior-Driven Visualization Recommendation (BDVR), consists of two distinct phases: (1) pattern detection, and (2) visualization recommendation. In the first phase, user behavior is analyzed dynamically to find semantically meaningful interaction patterns using a library of pattern definitions developed through observations of real-world visual analytic activity. In the second phase, our BDVR algorithm uses the detected patterns to infer a user's intended visual task. It then automatically suggests alternative visualizations that support the inferred visual task more directly than the user's current visualization. We present the details of BDVR and describe its implementation within our lab's prototype visual analysis system. We also present study results that demonstrate that our approach shortens task completion time and reduces error rates when compared to behavior-agnostic recommendation.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {315–324},
numpages = {10},
keywords = {information visualization, visualization recommendation, user behavior modeling, intelligent visualization},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502696,
author = {Carenini, Giuseppe and Rizoli, Lucas},
title = {A Multimedia Interface for Facilitating Comparisons of Opinions},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502696},
doi = {10.1145/1502650.1502696},
abstract = {Written opinion on products and other entities can be important to consumers and researchers, but expensive and difficult to analyze. We present a multimedia interface designed to facilitate the analysis of opinions on multiple entities, which could be beneficial to many individuals and organizations. It integrates an information visualization and an intelligent system that selects notable comparisons in the data and summarizes them in text. This system applies a set of statistics for comparing opinions across entities. We conducted a study of our interface with 36 subjects. Subjects liked the visualization overall and our system's selections overlapped with those of subjects more than did the selections of baseline systems. Given the choice, subjects often changed their selections to be more consistent with those of our system. This suggests that system selections were valuable to them.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {325–334},
numpages = {10},
keywords = {information visualization, opinion mining, evaluative text, user study, automatic summarization},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502697,
author = {Cao, Yujia and Theune, Mari\"{e}t and Nijholt, Anton},
title = {Modality Effects on Cognitive Load and Performance in High-Load Information Presentation},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502697},
doi = {10.1145/1502650.1502697},
abstract = {In this study, we argue that modality planning in multimodal presentation systems needs to consider the modality characteristics at not only the presentational level but also the cognitive level, especially in a situation where the information load is high and the user task is time-critical. As a first step towards automatic cognitive-aware modality planning, we integrated the effect of different modalities on cognitive load and performance, using a high-load information presentation scenario. Mainly based on modality-related psychology theories, we selected five modality conditions (text, image, text+image, text+speech, and text+sound) and made hypotheses about their effects on cognitive load. Modality effects were evaluated by two cognitive load measurements and two performance measurements. Results confirmed most of the predicted modality effects, and showed that these effects become significant when the information load and the task demand are high. The findings of this study suggest that it is highly necessary to encode modality-related principles of human cognition into the modality planning procedure for systems that support high-load human-computer interaction.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {335–344},
numpages = {10},
keywords = {heart rate variability, performance, cognitive load, modality effect, high-load information presentation},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502698,
author = {Puerta, Angel and Hu, Martin},
title = {UI Fin: A Process-Oriented Interface Design Tool},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502698},
doi = {10.1145/1502650.1502698},
abstract = {Even though over the years a multitude of user interface design tools have been created, designers in practice find themselves limited to a small set of realistic options. These options include interface builders that are attached to development environments, or general-purpose tools such as Microsoft Visio. We claim that the inability of many user interface tools to find their way into a designer's toolbox is due in great part to their failure to support the process of designing a user interface. In this paper, we introduce UI Fin, a user interface design tool that: (a) fits within and supports a common process for user interface design, (b) enables user-centered, as opposed to widget-centered, screen design, (c) provides decision-support for designers, and (d) bridges the transitions between the multiple actors in the design and engineering of a user interface. UI Fin has been used in real-world interface design projects and it appears to improve the efficiency of the design process, to enable multiple types of users to create design artifacts, and to present a relatively low barrier for novice users to become productive with the tool.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {345–354},
numpages = {10},
keywords = {model-based interface design, user-interface description languages, knowledge-based interface design tools, user-interface tools},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502700,
author = {Atrash, Amin and Pineau, Joelle},
title = {A Bayesian Reinforcement Learning Approach for Customizing Human-Robot Interfaces},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502700},
doi = {10.1145/1502650.1502700},
abstract = {Personal robots are becoming increasingly prevalent, which raises a number of interesting issues regarding the design and customization of interfaces to such platforms. The particular problem addressed by this paper is the use of learning methods to improve the quality and effectiveness of human-machine interaction onboard a robotic wheelchair. In support of this, we present a method for learning and adapting probabilistic models with the aid of a human operator. We use a Bayesian reinforcement learning framework, that allows us to mix learning and execution, as well as take advantage of prior information about the world. We address the problems of learning, handling a partially observable environment, and limiting the number of action requests. We demonstrate empirical feasibility of our approach on an interface for an autonomous wheelchair.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {355–360},
numpages = {6},
keywords = {activity &amp; plan recognition, intelligent assistants, intelligent interfaces for ubiquitous computing},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502701,
author = {Morita, Daisuke and Ishida, Toru},
title = {Collaborative Translation by Monolinguals with Machine Translators},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502701},
doi = {10.1145/1502650.1502701},
abstract = {In this paper, we present the concept for collaborative translation, where two non-bilingual people who use different languages collaborate to perform the task of translation using machine translation (MT) services, whose quality is imperfect in many cases. The key idea of this model is that one person, who handles the source language (source lan-guage side) and another person, who handles the target language (target language side), play different roles: the target language side modifies the translated sentence to improve its fluency, and the source language side evaluates its adequacy. We demonstrated the effectiveness and the practicality of this model in a tangible way.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {361–366},
numpages = {6},
keywords = {machine translation, intercultural collaboration, computer-mediated communication},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502702,
author = {Hu, Rong and Pu, Pearl},
title = {A Comparative User Study on Rating vs. Personality Quiz Based Preference Elicitation Methods},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502702},
doi = {10.1145/1502650.1502702},
abstract = {We conducted a user study evaluating two preference elicitation approaches based on ratings and personality quizzes respectively. Three criteria were used in this comparative study: perceived accuracy, user effort and user loyalty. Results from our study show that the perceived accuracy in two systems is not significantly different. However, users expended significantly less effort, both perceived cognitive effort and actual task time, to complete the preference profile establishing process in the personality quiz-based system than in the rating-based system. Additionally, users expressed stronger intention to reuse the personality quiz-based system and introduce it to their friends. After using these two systems, 53% of users preferred the personality quiz-based system vs. 13% of users preferred the rating-based system, since most users thought the former is easier to use.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {367–372},
numpages = {6},
keywords = {preference elicitation, user study, personality quiz, recommender systems, rating-based},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@dataset{10.1145/review-1502650.1502702_R45729,
author = {Kurfess, Franz J},
title = {Review ID:R45729 for DOI: 10.1145/1502650.1502702},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1502650.1502702_R45729}
}

@inproceedings{10.1145/1502650.1502703,
author = {Yang, Fan and Heeman, Peter A.},
title = {Context Restoration in Multi-Tasking Dialogue},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502703},
doi = {10.1145/1502650.1502703},
abstract = {In this paper we conduct an exploratory experiment on context restoration in multi-tasking dialogue and report our preliminary findings. We examine a corpus of human-human dialogues, in which pairs of conversants, using speech, work on an ongoing task while occasionally completing real-time tasks. We investigate whether the conversants, when returning to the ongoing task, make any effort to restore the context. First, we identify two types of actions, utterance restatement and information review, as possible restorations. Second, from a statistical analysis, we find that these actions are used more often when returning to the ongoing task, and hence seem to play a role in context restoration. Our findings will help to build a foundation for future speech interfaces that support multi-tasking dialogue.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {373–378},
numpages = {6},
keywords = {multi-tasking dialogue, context restoration},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502704,
author = {Hupfer, Susanne C. and Ross, Steven I. and Rasmussen, Jamie C. and Christensen, James E. and Levy, Stephen E. and Gruen, Daniel M. and Patterson, John F.},
title = {Crafting an Environment for Collaborative Reasoning},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502704},
doi = {10.1145/1502650.1502704},
abstract = {We motivate the need for new environments for collaborative reasoning and describe the foundations of our approach, namely collaboration, semantics, and adaptability. We describe the CRAFT collaborative reasoning interface and infrastructure that we are developing to explore this approach.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {379–382},
numpages = {4},
keywords = {collective intelligence, semantics, collaborative reasoning environment, ontology, sensemaking, computer-supported cooperative work, intelligent interface},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502705,
author = {L\'{o}pez-Jaquero, V\'{\i}ctor and Montero, Francisco and Real, Fernando},
title = {Designing User Interface Adaptation Rules with T: XML},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502705},
doi = {10.1145/1502650.1502705},
abstract = {The specification of model adaptation and generation rules is a topic of great interest for the user interface development community, since there are more and more approaches supporting the model-based approach. The ubiquitousness in interaction and the different user profiles are not the only challenges when designing interactive systems. Furthermore, the context of use evolves over time. In this situation, there is a strong need to provide a set of adaptation rules to make the user interface evolve according to the context of use evolution. This paper contributes a metamodel for the definition of adaptation rules in a systematic approach, pursuing engineer adaptation. Moreover, a tool called T:XML is presented that supports the specification of adaptation rules using a visual notation that greatly simplifies the process of designing adaptation for model-based user interface environments.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {383–388},
numpages = {6},
keywords = {user interface adaptation, t:xml tool, user interface development environment},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502706,
author = {Spaulding, Aaron and Blythe, Jim and Haines, Will and Gervasio, Melinda},
title = {From Geek to Sleek: Integrating Task Learning Tools to Support End Users in Real-World Applications},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502706},
doi = {10.1145/1502650.1502706},
abstract = {Numerous techniques exist to help users automate repetitive tasks; however, none of these methods fully support end-user creation, use, and modification of the learned tasks. We present an integrated task learning system (ITL) that learns executable procedures based on user demonstration and instruction, constituting a first step toward a broader solution for procedure management. We discuss our deployment of ITL into a collaborative command-and-control system. In this complex domain, ITL's performance with end users doing real tasks indicates that providing multiple, integrated learning techniques both extends functionality and improves user experience. Our experience in integrat-ing this system also provides key insights for future designs of domain-independent task learning systems, specifically in supporting users' ability to understand and edit lengthy procedures.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {389–394},
numpages = {6},
keywords = {interaction design, task learning, end user programming, reasoning about actions, programming by demonstration},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502707,
author = {Hsiao, Chuan-Heng and Huang, Wei-Chia and Chen, Kuan-Wen and Chang, Li-Wei and Hung, Yi-Ping},
title = {Generating Pictorial-Based Representation of Mental Images for Video Monitoring},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502707},
doi = {10.1145/1502650.1502707},
abstract = {Multi-camera systems have been widely used in many video surveillance applications. When an event happens and is monitored across multiple cameras, it is easy for an expert to generate the corresponding spatial representation to comprehend the series of event. However, it is not trivial for users new to the environment. With support from psychological evidences, we propose an approach to mimic generating pictorial-based representation of mental images when a target is moving across the views of cameras. First we conduct a ball-rolling experiment to compare this approach with others. The empirical results demonstrate that the performance of users with this approach is significantly better than others. We suggest that it is because this approach is better for users to preserve spatial representation of the environment while transiting views between cameras. Then we propose a framework to realize this approach. The demonstrations in different situations indicate the validity of such framework.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {395–400},
numpages = {6},
keywords = {surveillance, mental images, intelligent visualization, user study},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502708,
author = {Zhang, Xu and Chen, Xiang and Wang, Wen-hui and Yang, Ji-hai and Lantz, Vuokko and Wang, Kong-qiao},
title = {Hand Gesture Recognition and Virtual Game Control Based on 3D Accelerometer and EMG Sensors},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502708},
doi = {10.1145/1502650.1502708},
abstract = {This paper describes a novel hand gesture recognition system that utilizes both multi-channel surface electromyogram (EMG) sensors and 3D accelerometer (ACC) to realize user-friendly interaction between human and computers. Signal segments of meaningful gestures are determined from the continuous EMG signal inputs. Multi-stream Hidden Markov Models consisting of EMG and ACC streams are utilized as decision fusion method to recognize hand gestures. This paper also presents a virtual Rubik's Cube game that is controlled by the hand gestures and is used for evaluating the performance of our hand gesture recognition system. For a set of 18 kinds of gestures, each trained with 10 repetitions, the average recognition accuracy was about 91.7% in real application. The proposed method facilitates intelligent and natural control based on gesture interaction.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {401–406},
numpages = {6},
keywords = {electromyogram, gesture recognition, accelerometer, human computer interaction},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502709,
author = {Yu, Zhiyong and Yu, Zhiwen and Zhou, Xingshe and Nakamura, Yuichi},
title = {Handling Conditional Preferences in Recommender Systems},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502709},
doi = {10.1145/1502650.1502709},
abstract = {In this paper, we propose an approach to handle conditional preferences in recommender systems. A quantitative conditional preference model based on domain knowledge is introduced. The inheritance property in concept trees and bipolar property in preference statements are adopted when interpreting conditional preference rules. Group preferences are merged from personal preferences with consideration of manipulability. A graphical user interface is developed for visualization of domain knowledge, conditional preference rules, personal and group preferences.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {407–412},
numpages = {6},
keywords = {conditional preference, recommender system},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502710,
author = {Chang, Ana Ram\'{\i}rez and Canny, John},
title = {Illuminac: Simultaneous Naming and Configuration for Workspace Lighting Control},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502710},
doi = {10.1145/1502650.1502710},
abstract = {We explore natural and calm interfaces for configuring ubiquitous computing environments. A natural interface should enable the user to name a desired configuration and have the system enact that configuration. Users should be able to use familiar names for configurations without learning, which implies the mapping from names to configurations is many-to-one. Instead of users learning the environment's command language, the system simultaneously learns common configurations and infers the keywords that are most salient to them. We call this the SNAC problem (Simultaneous Naming and Configuration). As a case study, we design a speech interface for workspace lighting control on a large array of individually-controllable lights. We present an approach to the SNAC problem and demonstrate its applicability through an evaluation of our system, Illuminac.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {413–418},
numpages = {6},
keywords = {environment control, natural speech interfaces, non-negative matrix factorization},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502711,
author = {Girgensohn, Andreas and Shipman, Frank and Wilcox, Lynn and Turner, Thea and Cooper, Matthew},
title = {MediaGLOW: Organizing Photos in a Graph-Based Workspace},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502711},
doi = {10.1145/1502650.1502711},
abstract = {We designed an interactive visual workspace, MediaGLOW, that supports users in organizing personal and shared photo collections. The system interactively places photos with a spring layout algorithm using similarity measures based on visual, temporal, and geographic features. These similarity measures are also used for the retrieval of additional photos. Unlike traditional spring-based algorithms, our approach provides users with several means to adapt the layout to their tasks. Users can group photos in stacks that in turn attract neighborhoods of similar photos. Neighborhoods partition the workspace by severing connections outside the neighborhood. By placing photos into the same stack, users can express a desired organization that the system can use to learn a neighborhood-specific combination of distances.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {419–424},
numpages = {6},
keywords = {photo organization, photo sharing, photo retrieval},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502712,
author = {Micire, Mark and Drury, Jill L. and Keyes, Brenden and Yanco, Holly A.},
title = {Multi-Touch Interaction for Robot Control},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502712},
doi = {10.1145/1502650.1502712},
abstract = {Recent developments in multi-touch technologies have exposed fertile ground for research in enriched human-robot interaction. Although multi-touch technologies have been used for virtual 3D applications, to the authors' knowledge, ours is the first study to explore the use of a multi-touch table with a physical robot agent. This baseline study explores the control of a single agent with a multi-touch table using an adapted, previously studied, joystick-based interface. We performed a detailed analysis of users' interaction styles with two complex functions of the multi-touch interface and isolated mismatches between user expectations and interaction functionality.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {425–428},
numpages = {4},
keywords = {human-robot interaction, interaction styles, multi-touch interaction},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502713,
author = {Chen, Ya-Xi and Butz, Andreas},
title = {Musicsim: Integrating Audio Analysis and User Feedback in an Interactive Music Browsing Ui},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502713},
doi = {10.1145/1502650.1502713},
abstract = {In music information retrieval (MIR), there are two main research directions, which are based either on a folder hierarchy and metadata, or on the actual acoustic content. We believe that both content-based and hierarchy-based retrieval have their respective strengths for browsing and organizing music collections, and that the integration of content analysis techniques in metadata-based media UIs can lead to more powerful UIs. In this paper we present a prototype, in which audio analysis techniques and user feedback are integrated into an interactive UI for browsing and organizing large music collections. We also provide visual assistance to support non-visual perception of music. We discussed our system with test users and received encouragement as well as valuable suggestions for future re-search.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {429–434},
numpages = {6},
keywords = {user feedback, playlist generation, music information retrieval, audio analysis, music browser},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@dataset{10.1145/review-1502650.1502713_R44976,
author = {van den Broek, Egon L.},
title = {Review ID:R44976 for DOI: 10.1145/1502650.1502713},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1502650.1502713_R44976}
}

@inproceedings{10.1145/1502650.1502714,
author = {Nurmi, Petteri and Forsblom, Andreas and Flor\'{e}en, Patrik and Peltonen, Peter and Saarikko, Petri},
title = {Predictive Text Input in a Mobile Shopping Assistant: Methods and Interface Design},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502714},
doi = {10.1145/1502650.1502714},
abstract = {The fundamental nature of grocery shopping makes it an interesting domain for intelligent mobile assistants. Even though the central role of shopping lists is widely recognized, relatively little attention has been paid to facilitating shopping list creation and management. In this paper we introduce a predictive text input technique that is based on association rules and item frequencies. We also describe an interface design for integrating the predictive text input with a web-based mobile shopping assistant. In a user study we compared two interfaces, one with text input support and one without. Our results indicate that, even though shopping list entries are typically short, our technique makes text input significantly faster, decreases typing error rates and increases overall user satisfaction.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {435–438},
numpages = {4},
keywords = {recommendations, user interface, adaptive, usability},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502715,
author = {Baur, Dominikus and Butz, Andreas},
title = {Pulling Strings from a Tangle: Visualizing a Personal Music Listening History},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502715},
doi = {10.1145/1502650.1502715},
abstract = {The history of songs, to which a person has listened, is a very personal piece of information. It is a rich data set that comes as a byproduct of the use of digital music players and can be obtained without interfering with the user.In this paper, we present three visualizations for this data set and a mechanism for generating new playlists from the user's own listening history, based on a navigation metaphor. First, temporal proximity is interpreted as a simple similarity measure to lay out the entire history on a two-dimensional plane. Closed listening sessions are then used to make chronological relations visible.The generated playlists mimic the user's previous listening behavior, and the visualizations make the automatic choices understandable, as they share visual properties with the history. In this sense, our visualizations provide a visual vocabulary for listening behaviors and bring scrutability to automatic playlist generation.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {439–444},
numpages = {6},
keywords = {visualization, listening history, navigation metaphor, playlist creation},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502716,
author = {Groth, Paul T. and Gil, Yolanda},
title = {A Scientific Workflow Construction Command Line},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502716},
doi = {10.1145/1502650.1502716},
abstract = {Workflows have emerged as a common tool for scientists to express their computational analyses. While there are a multitude of visual data flow editors for workflow construction, to date there are none that support the input of workflows using natural language. This work presents the design of a hybrid system that combines natural language input through a command line with a visual editor.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {445–450},
numpages = {6},
keywords = {scientific workflows, command line, natural language},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502717,
author = {Sun, Yong and Shi, Yu and Chen, Fang and Chung, Vera},
title = {Skipping Spare Information in Multimodal Inputs during Multimodal Input Fusion},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502717},
doi = {10.1145/1502650.1502717},
abstract = {In a multimodal interface, a user can use multiple modalities, such as speech, gesture, and eye gaze etc., to communicate with a system. As a critical component in a multimodal interface, multimodal input fusion explores the ways to effectively interpret the combined semantic interpretation of user's multimodal inputs. Although multimodal inputs may contain spare information, few multimodal input fusion approaches have tackled how to deal with spare information in multimodal inputs. This paper proposes a novel multimodal input fusion approach to flexibly skip spare information in multimodal inputs and derive semantic interpretation of them. The evaluation about the proposed approach confirms that the approach makes human-computer interaction more natural and smooth.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {451–456},
numpages = {6},
keywords = {processing of multimodal input, spare information in multimodal input},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502718,
author = {Jiang, Yingying and Tian, Feng and Wang, Xugang and Zhang, Xiaolong and Dai, Guozhong and Wang, Hongan},
title = {Structuring and Manipulating Hand-Drawn Concept Maps},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502718},
doi = {10.1145/1502650.1502718},
abstract = {Concept maps are an important tool to knowledge organization, representation, and sharing. Most current concept map tools do not provide full support for hand-drawn concept map creation and manipulation, largely due to the lack of methods to recognize hand-drawn concept maps. This paper proposes a structure recognition method. Our algorithm can extract node blocks and link blocks of a hand-drawn concept map by combining dynamic programming and graph partitioning and then build a concept-map structure by relating extracted nodes and links. We also introduce structure-based intelligent manipulation technique of hand-drawn concept maps. Evaluation shows that our method has high structure recognition accuracy in real time, and the intelligent manipulation technique is efficient and effective.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {457–462},
numpages = {6},
keywords = {graph partition, structure recognition, hand-drawn concept map, dynamic programming},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502719,
author = {Lowd, Daniel and Kushmerick, Nicholas},
title = {Using Salience to Segment Desktop Activity into Projects},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502719},
doi = {10.1145/1502650.1502719},
abstract = {Knowledge workers must manage large numbers of simultaneous, ongoing projects that collectively involve huge numbers of resources (documents, emails, web pages, calendar items, etc). An activity database that captures the relationships among projects, resources, and time can drive a variety of tools that save time and increase productivity. To maximize net time savings, we would prefer to build such a database automatically, or with as little user effort as possible. In this paper, we present several sets of features and algorithms for predicting the project associated with each action a user performs on the desktop. Key to our methods is salience, the notion that more recent activity is more informative. By developing novel features that represent salience, we were able to learn models that outperform both a simple benchmark and an expert system tuned specifically for this task on real-world data from five users.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {463–468},
numpages = {6},
keywords = {time tracking, interruption recovery, logistic regression, activity recognition, information workers, machine learning},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502720,
author = {San Pedro, Jose and Kalnikaite, Vaiva and Whittaker, Steve},
title = {You Can Play That Again: Exploring Social Redundancy to Derive Highlight Regions in Videos},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502720},
doi = {10.1145/1502650.1502720},
abstract = {Identifying highlights in multimedia content such as video and audio is currently a very difficult technical problem. We present and evaluate a novel algorithm that identifies highlights by combining content analysis with Web 2.0 data mining techniques. We exploit the fact that popular content tends to be redundantly uploaded onto community sharing sites. Our "social summarization" technique first identifies overlaps in uploaded scenes and then uses the upload frequency of each video scene to compute that scene's importance in the complete video. Our user evaluation shows the reliability of the technique: scenes automatically selected by our method are agreed by experts to be the most relevant.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {469–474},
numpages = {6},
keywords = {video content analysis, summarization, social network, community},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502722,
author = {Falb, J\"{u}ergen and Kavaldjian, Sevan and Popp, Roman and Raneburger, David and Arnautovic, Edin and Kaindl, Hermann},
title = {Fully Automatic User Interface Generation from Discourse Models},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502722},
doi = {10.1145/1502650.1502722},
abstract = {Automatic generation of user interfaces (UIs) has made some progress, but it still faces many challenges, especially when starting from high-level models. We developed an approach and a supporting tool for modeling discourses, from which the tool can generate WIMP (window, icon, menu, pointer) UIs automatically. This involves several complex steps, most of which we have been able to implement using model-driven transformations. When given specific target platform specifications, UIs for a variety of devices such as PCs, mobile phones and PDAs can be generated automatically.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {475–476},
numpages = {2},
keywords = {interaction design, model-driven ui generation},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502723,
author = {Romero, Ver\'{o}nica and Leiva, Luis A. and Toselli, Alejandro H. and Vidal, Enrique},
title = {Interactive Multimodal Transcription of Text Images Using a Web-Based Demo System},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502723},
doi = {10.1145/1502650.1502723},
abstract = {This document introduces a web based demo of an interactive framework for transcription of handwritten text, where the user feedback is provided by means of pen strokes on a touchscreen. Here, the automatic handwriting text recognition system and the user both cooperate to generate the final transcription.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {477–478},
numpages = {2},
keywords = {interactive framework, web, handwritten recognition, hci},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502724,
author = {Thai, Vinh Tuan and Handschuh, Siegfried},
title = {IVEA: Toward a Personalized Visual Interface for Exploring Text Collections},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502724},
doi = {10.1145/1502650.1502724},
abstract = {In this paper we present IVEA, a personalized visual interface which enables users to explore text collections from different perspectives and levels of detail. This work explores the use of a personal ontology, which encapsulates users' entities of interest, as an anchor for the exploration process. This, in effect, simplifies the comprehension of visual representation of text collections by helping users to focus on aspects that they are particularly concerned with.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {479–480},
numpages = {2},
keywords = {visual exploration, text collections},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502725,
author = {Roscher, Dirk and Blumendorf, Marco and Albayrak, Sahin},
title = {A Meta User Interface to Control Multimodal Interaction in Smart Environments},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502725},
doi = {10.1145/1502650.1502725},
abstract = {Smart environments bring together multiple users, (interaction) resources and services. This creates complex and unpredictable interactive computing environments that are hard to understand. Users thus have difficulties to build up their mental model of such interactive systems. To address this issue users need possibilities to evaluate the state of these systems and to adapt them according to their needs. In this work we present our implementation of the functionalities to evaluate and control multimodal interaction in smart environments, which is accessible for users through a meta user interface.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {481–482},
numpages = {2},
keywords = {multimodal interaction, meta user interfaces, human-computer interaction, smart environments, model-based user interfaces},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502726,
author = {Vertanen, Keith and Kristensson, Per Ola},
title = {Parakeet: A Demonstration of Speech Recognition on a Mobile Touch-Screen Device},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502726},
doi = {10.1145/1502650.1502726},
abstract = {We demonstrate Parakeet -- a continuous speech recognition system for mobile touch-screen devices. Parakeet's interface is designed to make correcting errors easy on a handheld device while on the move. Users correct errors using a touch-screen to either select alternative words from a word confusion network or by typing on a predictive software keyboard. Our interface design was guided by computational experiments. We conducted a user study to validate our design. We found novices entered text at 18 WPM while seated indoors and 13 WPM while walking outdoors.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {483–484},
numpages = {2},
keywords = {error correction, mobile continuous speech recognition, word confusion network, speech input, touch-screen interface},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502727,
author = {Dawkins, Shane\'{e} and Sullivan, Tony and Rogers, Greg and Cross, E. Vincent and Hamilton, Lauren and Gilbert, Juan E.},
title = {Prime III: An Innovative Electronic Voting Interface},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502727},
doi = {10.1145/1502650.1502727},
abstract = {Voting technology today has not addressed the issues that disabled voters are confronted with at the polls. Because approximately 17% of the voting population is disabled, their issues should be handled with a solution geared towards their needs. Disabled voters need to be able to cast their vote without the assistance of others. The Prime III multimodal voting system [2] addresses these issues. This demonstration will illustrate the use of the Prime III system, a virtual reality (VR) version (Prime V), and a similar version created using a voice user interface (VUI).},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {485–486},
numpages = {2},
keywords = {multimodal user interaction, universal access, e-voting},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502728,
author = {Rzepka, Rafal and Shi, Wenhan and Ptaszynski, Michal and Dybala, Pawel and Higuchi, Shinsuke and Araki, Kenji},
title = {Serious Processing for Frivolous Purpose: A Chatbot Using Web-Mining Supported Affect Analysis and Pun Generation},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502728},
doi = {10.1145/1502650.1502728},
abstract = {By our demonstration we want to introduce our achievements in combining different purpose algorithms to build a chatbot which is able to keep a conversation on any topic. It uses snippets of Internet search results to stay within a context, Nakamura's Emotion Dictionary to detect an emotional load existence and categorization of a textual utterance and a causal consequences retrieval algorithm when emotive features are not found. It is also able to detect a possibility to make a pun by analyzing the input sentence and create one if timing is adequate.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {487–488},
numpages = {2},
keywords = {pun generation, affect analysis, chatbot, web-mining},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502729,
author = {J\"{a}ndel, Magnus and Elahi, Mehdi},
title = {Tribal Taste: Mobile Multiagent Recommender System},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502729},
doi = {10.1145/1502650.1502729},
abstract = {We demonstrate a system for filtering media streams according to the collective taste of a leader-less informal clan of users. Applications on mobile devices receive streams of content items that are assessed by local software agents. The agents learn the collective preferences of the tribe by forming a distributed multi-agent society that shares data on the behavior of all users. The underlying artificial intelligence is based on support vector machines that cooperate by broadcasting new support vectors. The demo shows micro-blog readers on cell phones running support vector machine agents with text kernels and communicating over IP Multimedia System networks.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {489–490},
numpages = {2},
keywords = {recommender system, multiagent, mobile application, ip multimedia subsystem, support vector machine},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502731,
author = {Havasi, Catherine and Lieberman, Henry and Mueller, Erik T.},
title = {CSIUI 2009: Story Understanding and Generation for Aware and Interactive Interface Design},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502731},
doi = {10.1145/1502650.1502731},
abstract = {In order to be helpful to people, the intelligent interfaces of the future will have to acquire, represent, and infer simple knowledge about everyday life and activities. While much work in AI has represented this knowledge at the word, sentence, and logical assertion level, we see a growing need to understand it at a larger granularity, that of stories.The workshop, like its predecessors, had the goal of bringing together researchers in common sense reasoning with researchers in intelligent interfaces. Each year our workshop has a different focus in addition to these two areas and this year's workshop focused on the acquisition, understanding and creation of stories.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {491–492},
numpages = {2},
keywords = {knowledge collection, events, story understanding, common sense reasoning, intelligent user interfaces},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502732,
author = {M\"{u}ller, Christian and Friedland, Gerald},
title = {Multimodal Interfaces for Automotive Applications (MIAA)},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502732},
doi = {10.1145/1502650.1502732},
abstract = {This paper summarizes the main objectives of the IUI workshop W2 on multimodal interfaces for automotive applications.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {493–494},
numpages = {2},
keywords = {multimodal interfaces, human-machine-interaction, automotive applications},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502733,
author = {Johnson, Peter and Middup, Christopher Paul and Hourizi, Rachid and Maybury, Mark},
title = {IUI'09 Workshop Summary: Human Interaction with Intelligent &amp; Networked Systems},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502733},
doi = {10.1145/1502650.1502733},
abstract = {This workshop brings together a community of researchers and practitioners to identify and develop the research agenda needed to enhance human interaction with increasingly powerful and independent intelligent systems e.g. sensors networks, autonomous systems, agents and robotic systems. These systems have applications in many domains including health, transport, environment, emergency situations and defense. Aspects of these systems give rise to properties found in loose federations, collaborations and dynamic coalitions. The research questions include awareness, joint working, decision-making, intentionality, coordination, task-allocation, and planning. The workshop brings together researchers from different disciplines to discuss and develop research and to provide a focus for interdisciplinary research in this area.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {495–496},
numpages = {2},
keywords = {intelligent systems, awareness, decision-making, autonomous systems, coordination, agents, sensor networks, robotic systems, collaboration, planning},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502734,
author = {Jameson, Anthony and Gabrielli, Silvia and Oulasvirta, Antti},
title = {Users' Preferences Regarding Intelligent User Interfaces: Differences among Users and Changes over Time},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502734},
doi = {10.1145/1502650.1502734},
abstract = {The goal of this full-day workshop is to arrive at a synthesis of knowledge that will help people who work with intelligent user interfaces to predict and explain how users' attitudes and behavior toward aspects of such systems (a) differ from one user to the next and (b) change over time.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {497–498},
numpages = {2},
keywords = {user preferences, longitudinal studies, individual differences},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502735,
author = {Handschuh, Siegfried and Heath, Tom and Thai, VinhTuan},
title = {Visual Interfaces to the Social and the Semantic Web (VISSW 2009)},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502735},
doi = {10.1145/1502650.1502735},
abstract = {Recent developments in the Social and Semantic Web fields have resulted in large amounts of data created, published and consumed by users of the Web. The ability to easily integrate such vast amounts of data raises significant and exciting research challenges, not least of which how to provide effective access to and navigation across heterogeneous data sources. The IUI2009 workshop on Visual Interfaces to the Social and the Semantic Web aims to bring together researchers and practitioners from different fields to discuss the latest research results and challenges in designing, implementing, and evaluating intelligent interfaces supporting access, navigation and publishing of different types of contents on the Social and Semantic Web. This paper outlines the context of the workshop and provides an overview of the research to be presented at the event.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {499–500},
numpages = {2},
keywords = {social web, semantic web, visual interfaces},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502736,
author = {Hammond, Tracy Anne},
title = {IUI'09 Workshop Summary: Sketch Recognition},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502736},
doi = {10.1145/1502650.1502736},
abstract = {This paper describes the IUI'09 workshop on Sketch Recognition.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {501–502},
numpages = {2},
keywords = {cad, sketch recognition, sketching, pen input computing, sketch understanding, document processing},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

@inproceedings{10.1145/1502650.1502737,
author = {Meixner, Gerrit and G\"{o}rlich, Daniel and Breiner, Kai and Hu\ss{}mann, Heinrich and Pleu\ss{}, Andreas and Sauer, Stefan and Van den Bergh, Jan},
title = {Fourth International Workshop on Model Driven Development of Advanced User Interfaces},
year = {2009},
isbn = {9781605581682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1502650.1502737},
doi = {10.1145/1502650.1502737},
abstract = {Model Driven Development (MDD) is an important para-digm in Software Engineering. In MDD, applications are specified systematically using abstract, platform independent models. The models are then transformed into executable code for different platforms and target devices. Model-driven techniques become ever more prominent in any kind of application, such as multimedia and Web, ubiquitous and automotive applications.},
booktitle = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {503–504},
numpages = {2},
keywords = {task model, mdd, mbuid, hci},
location = {Sanibel Island, Florida, USA},
series = {IUI '09}
}

