@inproceedings{10.1145/1124772.1124774,
author = {Cockburn, Andy and Gutwin, Carl and Alexander, Jason},
title = {Faster Document Navigation with Space-Filling Thumbnails},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124774},
doi = {10.1145/1124772.1124774},
abstract = {Scrolling is the standard way to navigate through many types of digital documents. However, moving more than a few pages can be slow because all scrolling techniques constrain visual search to only a small document region. To improve document navigation, we developed Space-Filling Thumbnails (SFT), an overview display that eliminates most scrolling. SFT provides two views: a standard page view for reading, and a thumbnail view that shows all pages. We tested SFT in three experiments that involved finding pages in documents. The first study (n=13) compared seven current scrolling techniques, and showed that SFT is significantly faster than the other methods. The second and third studies (n=32 and n=14) were detailed comparisons of SFT with thumbnail-enhanced scrollbars (TES), which performed well in the first experiment. SFT was faster than TES across all document types and lengths, particularly when tasks involved revisitation. In addition, SFT was strongly preferred by participants.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {scrolling, thumbnails, document navigation, zooming},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124775,
author = {Nekrasovski, Dmitry and Bodnar, Adam and McGrenere, Joanna and Guimbreti\`{e}re, Fran\c{c}ois and Munzner, Tamara},
title = {An Evaluation of Pan &amp; Zoom and Rubber Sheet Navigation with and without an Overview},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124775},
doi = {10.1145/1124772.1124775},
abstract = {We present a study that evaluates conventional Pan and Zoom Navigation and Rubber Sheet Navigation, a rectilinear Focus+Context technique. Each of the two navigation techniques was evaluated both with and without an overview. All interfaces guaranteed that regions of interest would remain visible, at least as a compressed landmark, independent of navigation actions. Interfaces implementing these techniques were used by 40 subjects to perform a task that involved navigating a large hierarchical tree dataset and making topological comparisons between nodes in the tree. Our results show that Pan and Zoom Navigation was significantly faster and required less mental effort than Rubber Sheet Navigation, independent of the presence or absence of an overview. Also, overviews did not appear to improve performance, but were still perceived as beneficial by users. We discuss the implications of our task and guaranteed visibility on the results and the limitations of our study, and we propose preliminary design guidelines and recommendations for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {focus+context, overview, guaranteed visibility, evaluation, navigation, information visualization},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124776,
author = {Appert, Caroline and Fekete, Jean-Daniel},
title = {OrthoZoom Scroller: 1D Multi-Scale Navigation},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124776},
doi = {10.1145/1124772.1124776},
abstract = {This article introduces the OrthoZoom Scroller, a novel interaction technique that improves target acquisition in very large one-dimensional spaces. The OrthoZoom Scroller requires only a mouse to perform panning and zooming in a 1D space. Panning is performed along the slider dimension while zooming is performed along the orthogonal one. We present a controlled experiment showing that the OrthoZoom Scroller is about twice as fast as Speed Dependant Automatic Zooming to perform pointing tasks whose index of difficulty is in the 10-30 bits range. We also present an application to browse large textual documents with the OrthoZoom Scroller that uses semantic zooming and snapping on the structure.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {21–30},
numpages = {10},
keywords = {scrolling task, pointing task, multi-scale navigation, interaction technique},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124778,
author = {Halvey, Martin and Keane, Mark T. and Smyth, Barry},
title = {Time Based Patterns in Mobile-Internet Surfing},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124778},
doi = {10.1145/1124772.1124778},
abstract = {In this paper we investigate environmental factors that can result in users having different preferences and behaviors at different times of the day. An analysis is carried out of a large sample of user data for Wireless Application Protocol (WAP) browsing to determine whether user surfing patterns vary depending on time. We examine traffic on an hourly and daily basis, and show that accesses to particular categories of pages vary relative to time. We also build Markov models, which are temporal; to predict user navigation, and illustrate those predictive models are more accurate and beneficial to mobile Internet users than traditional methods. This analysis provides insight into improving the effectiveness and efficiency of navigation prediction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {31–34},
numpages = {4},
keywords = {WAP, log file analysis, user modeling, mobile, WWW, navigation prediction},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124779,
author = {Roto, Virpi and Popescu, Andrei and Koivisto, Antti and Vartiainen, Elina},
title = {Minimap: A Web Page Visualization Method for Mobile Phones},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124779},
doi = {10.1145/1124772.1124779},
abstract = {The Web has become available even on mobile phones, but the current methods to view large pages on small screens have not been highly usable. Current mobile phone browsers reformat Web pages to a single column that fits the screen width. Because not all content is comprehensible in this format, browsers provide a second mode for viewing pages in the same layout as on a PC. We have developed a modeless Web page visualization method called Minimap that shows pages in a modified Original layout. We conducted a long-term usability study with 20 participants to compare the state-of-the-art mobile phone browser with this new method. 18 participants preferred the new method, and it also scored better in more detailed usability ratings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {35–44},
numpages = {10},
keywords = {Minimap, usability, field study, narrow layout, small screen, information visualization, mobile Web browser},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124780,
author = {McAtamney, Gerard and Parker, Caroline},
title = {An Examination of the Effects of a Wearable Display on Informal Face-to-Face Communication},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124780},
doi = {10.1145/1124772.1124780},
abstract = {Wearable computers have the potential to support our memory, facilitate our creativity, our communication and augment our physical senses [15] but, like email and cell-phones, they also have the potential to interrupt, displace or downgrade our social interactions. This paper presents the results of a simple laboratory-based study which examines the impact of a xybernaut head-mounted Shimadzu display on conversation between two people. We hypothesized that the wearable, by reducing eye-contact and attention in the wearer would have a detrimental effect. Pairs of friends discussed pre-defined topics under three conditions, no wearable, wearable present but inactive, wearable present and active. Likert scale statements were used to record the wearer's level of attention, concentration, listening, eye contact, naturalness and relaxation, and the impact of the wearable. The presence of the wearable without an active display did not have an effect on the conversation. The quality of the interaction was however impaired in the active wearable condition and eye-contact was effected. This effect may be the result of the nature of the information type, the interface used, the characteristics of its presentation or the novelty of the display to the user. Additional research to identify design implications is discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {45–54},
numpages = {10},
keywords = {attention, eye-contact, conversation, information, displays, social computing, wearables, wearer vs non-wearer},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124782,
author = {von Ahn, Luis and Liu, Ruoran and Blum, Manuel},
title = {Peekaboom: A Game for Locating Objects in Images},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124782},
doi = {10.1145/1124772.1124782},
abstract = {We introduce Peekaboom, an entertaining web-based game that can help computers locate objects in images. People play the game because of its entertainment value, and as a side effect of them playing, we collect valuable image metadata, such as which pixels belong to which object in the image. The collected data could be applied towards constructing more accurate computer vision algorithms, which require massive amounts of training and testing data not currently available. Peekaboom has been played by thousands of people, some of whom have spent over 12 hours a day playing, and thus far has generated millions of data points. In addition to its purely utilitarian aspect, Peekaboom is an example of a new, emerging class of games, which not only bring people together for leisure purposes, but also exist to improve artificial intelligence. Such games appeal to a general audience, while providing answers to problems that computers cannot yet solve.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {55–64},
numpages = {10},
keywords = {object segmentation, web-based games, object recognition, computer vision, distributed knowledge acquisition},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124783,
author = {Wiley, Keith and Williams, Lance R.},
title = {Representation of Interwoven Surfaces in 2 1/2 D Drawing},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124783},
doi = {10.1145/1124772.1124783},
abstract = {The state-of-the-art in computer drawing programs is based on a number of concepts that are over two decades old. One such concept is the use of layers for ordering the surfaces in a drawing from top to bottom. Unfortunately, the use of layers unnecessarily imposes a partial ordering on the depths of the surfaces and prevents the user from creating a large class of potential drawings, e.g., of Celtic knots and interwoven surfaces. In this paper we describe a novel approach which only requires local depth ordering of segments of the boundaries of surfaces in a drawing rather than a global depth relation between entire surfaces. Our program provides an intuitive user interface which allows a novice to create complex drawings of interwoven surfaces that would be difficult and time-consuming to create with standard drawing programs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {65–74},
numpages = {10},
keywords = {layers, computational topology, knot diagrams, surfaces, braids, drawing programs, constraint propagation},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124784,
author = {von Ahn, Luis and Kedia, Mihir and Blum, Manuel},
title = {Verbosity: A Game for Collecting Common-Sense Facts},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124784},
doi = {10.1145/1124772.1124784},
abstract = {We address the problem of collecting a database of ""common-sense facts"" using a computer game. Informally, a common-sense fact is a true statement about the world that is known to most humans: ""milk is white,"" ""touching hot metal hurts,"" etc. Several efforts have been devoted to collecting common-sense knowledge for the purpose of making computer programs more intelligent. Such efforts, however, have not succeeded in amassing enough data because the manual process of entering these facts is tedious. We therefore introduce Verbosity, a novel interactive system in the form of an enjoyable game. People play Verbosity because it is fun, and as a side effect of them playing, we collect accurate common-sense knowledge. Verbosity is an example of a game that not only brings people together for leisure, but also collects useful data for computer science.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {75–78},
numpages = {4},
keywords = {distributed knowledge acquisition, web-based games, common-sense reasoning},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124785,
author = {von Ahn, Luis and Ginosar, Shiry and Kedia, Mihir and Liu, Ruoran and Blum, Manuel},
title = {Improving Accessibility of the Web with a Computer Game},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124785},
doi = {10.1145/1124772.1124785},
abstract = {Images on the Web present a major accessibility issue for the visually impaired, mainly because the majority of them do not have proper captions. This paper addresses the problem of attaching proper explanatory text descriptions to arbitrary images on the Web. To this end, we introduce Phetch, an enjoyable computer game that collects explanatory descriptions of images. People play the game because it is fun, and as a side effect of game play we collect valuable information. Given any image from the World Wide Web, Phetch can output a correct annotation for it. The collected data can be applied towards significantly improving Web accessibility. In addition to improving accessibility, Phetch is an example of a new class of games that provide entertainment in exchange for human processing power. In essence, we solve a typical computer vision problem with HCI tools alone.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {79–82},
numpages = {4},
keywords = {distributed knowledge acquisition, accessibility, web-based games},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124787,
author = {Karat, Clare-Marie and Karat, John and Brodie, Carolyn and Feng, Jinjuan},
title = {Evaluating Interfaces for Privacy Policy Rule Authoring},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124787},
doi = {10.1145/1124772.1124787},
abstract = {Privacy policy rules are often written in organizations by a team of people in different roles. Currently, people in these roles have no technological tools to guide the creation of clear and implementable high-quality privacy policy rules. High-quality privacy rules can be the basis for verifiable automated privacy access decisions. An empirical study was conducted with 36 users who were novices in privacy policy authoring to evaluate the quality of rules created and user satisfaction with two experimental privacy authoring tools and a control condition. Results show that users presented with scenarios were able to author significantly higher quality rules using either the natural language with a privacy rule guide tool or a structured list tool as compared to an unguided natural language control condition. The significant differences in quality were found in both user self-ratings of rule quality and objective quality scores. Users ranked the two experimental tools significantly higher than the control condition. Implications of the research and future research directions are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {83–92},
numpages = {10},
keywords = {natural language interfaces, privacy, design process, privacy policies, social and legal issues},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124788,
author = {Tang, Karen P. and Keyani, Pedram and Fogarty, James and Hong, Jason I.},
title = {Putting People in Their Place: An Anonymous and Privacy-Sensitive Approach to Collecting Sensed Data in Location-Based Applications},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124788},
doi = {10.1145/1124772.1124788},
abstract = {The emergence of location-based computing promises new and compelling applications, but raises very real privacy risks. Existing approaches to privacy generally treat people as the entity of interest, often using a fidelity tradeoff to manage the costs and benefits of revealing a person's location. However, these approaches cannot be applied in some applications, as a reduction in precision can render location information useless. This is true of a category of applications that use location data collected from multiple people to infer such information as whether there is a traffic jam on a bridge, whether there are seats available in a nearby coffee shop, when the next bus will arrive, or if a particular conference room is currently empty. We present hitchhiking, a new approach that treats locations as the primary entity of interest. Hitchhiking removes the fidelity tradeoff by preserving the anonymity of reports without reducing the precision of location disclosures. We can therefore support the full functionality of an interesting class of location-based applications without introducing the privacy concerns that would otherwise arise.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {93–102},
numpages = {10},
keywords = {location-based computing, hitchhiking, privacy, anonymity},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124789,
author = {Boehner, Kirsten and Hancock, Jeffrey T.},
title = {Advancing Ambiguity},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124789},
doi = {10.1145/1124772.1124789},
abstract = {Ambiguity is an important concept for HCI because of its pervasiveness in everyday life, yet its emergent nature challenges the role of design. We examine these difficulties with regards to Aoki and Woodruff's [1] proposal to use ambiguity as a resource for designing space for stories in personal communication systems. We challenge certain assumptions about ambiguity and propose a set of design and evaluation guidelines that flow from this re-conceptualization of ambiguity and design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {103–106},
numpages = {4},
keywords = {interpretation, ambiguity, information interfaces and presentation, design, face saving, CMC},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124790,
author = {March, Wendy and Fleuriot, Constance},
title = {Girls, Technology and Privacy: "Is My Mother Listening?"},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124790},
doi = {10.1145/1124772.1124790},
abstract = {This paper describes a study undertaken to explore the ways in which older teenage girls use technology to construct and maintain a sense of private space while living at home with parents. The study used blogging as an experimental and integral part of the research, in order to facilitate ongoing communication between researcher and participant.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {107–110},
numpages = {4},
keywords = {mobility, blogs, phones, privacy, teenage girls},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124792,
author = {Millen, David R. and Feinberg, Jonathan and Kerr, Bernard},
title = {Dogear: Social Bookmarking in the Enterprise},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124792},
doi = {10.1145/1124772.1124792},
abstract = {We describe a social bookmarking service de-signed for a large enterprise. We discuss design principles addressing online identity, privacy, information discovery (including search and pivot browsing), and service extensi-bility based on a web-friendly architectural style. In addi-tion we describe the key design features of our implementa-tion. We provide the results of an eight week field trial of this enterprise social bookmarking service, including a de-scription of user activities, based on log file analysis. We share the results of a user survey focused on the benefits of the service. The feedback from the user trial, comprising survey results, log file analysis and informal communica-tions, is quite positive and suggests several promising en-hancements to the service. Finally, we discuss potential extension and integration of social bookmarking services with other corporate collaborative applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {111–120},
numpages = {10},
keywords = {folksonomies, social software, social bookmarking, tags},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124793,
author = {Pu, Pearl and Viappiani, Paolo and Faltings, Boi},
title = {Increasing User Decision Accuracy Using Suggestions},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124793},
doi = {10.1145/1124772.1124793},
abstract = {The internet presents people with an increasingly bewildering variety of choices. Online consumers have to rely on computerized search tools to find the most preferred option in a reasonable amount of time. Recommender systems address this problem by searching for options based on a model of the user's preferences. We consider example critiquing as a methodology for mixed-initiative recommender systems. In this technique, users volunteer their preferences as critiques on examples. It is thus important to stimulate their preference expression by selecting the proper examples, called suggestions. We describe the look-ahead principle for suggestions and describe several suggestion strategies based on it. We compare them in simulations and, for the first time, report a set of user studies which prove their effectiveness in increasing users' decision accuracy by up to 75%.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {121–130},
numpages = {10},
keywords = {consumer decision support, example / critiquing interfaces, recommender systems, user evaluation of interfaces},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124794,
author = {Zheng, Qixing and Booth, Kellogg and McGrenere, Joanna},
title = {Co-Authoring with Structured Annotations},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124794},
doi = {10.1145/1124772.1124794},
abstract = {Most co-authoring tools support basic annotations, such as edits and comments that are anchored at specific locations in the document. However, they do not support meta-commentary about a document (such as an author's summary of modifications) which gets separated from the document, often in the body of email messages. This causes unnecessary overhead in the write-review-edit workflow inherent in co-authoring. We present document-embedded structured annotations called "bundles" that incorporate the meta-commentary into a unified annotation model that meets a set of annotation requirements we identified through a small field investigation. A usability study with 20 subjects evaluated the annotation reviewing stage of co-authoring and showed that annotation bundles in our high-fidelity prototype reduced reviewing time and increased accuracy, compared to a system that only supports edits and comments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {131–140},
numpages = {10},
keywords = {collaborative authoring, structured annotation, usability study, collaborative writing, workflow},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124796,
author = {Neustaedter, Carman and Bernheim Brush, A. J.},
title = {"LINC-Ing" the Family: The Participatory Design of an Inkable Family Calendar},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124796},
doi = {10.1145/1124772.1124796},
abstract = {Families must continually organize, plan, and stay aware of the activities of their households in order to coordinate everyday life. Despite having organization schemes, many people still feel overwhelmed when it comes to family coordination. To help overcome this, we present our research efforts on LINC: an inkable family calendar designed for the kitchen. LINC was developed using a participatory design process involving interviews, paper prototyping, and a formative evaluation. Our work outlines key implications for digital family calendars and family coordination systems in general. We found that coordination is not typically done through the family calendar; rather, the family calendar is a tool that provides family members with an awareness of activities and changes that in turn enables coordination. Thus, digital family calendars should provide tools that enable families to use their own coordination routines which leverage the social affordances prominent in existing paper calendars.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {141–150},
numpages = {10},
keywords = {awareness, home, families, coordination, calendars},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124797,
author = {Boyd-Graber, Jordan L. and Nikolova, Sonya S. and Moffatt, Karyn A. and Kin, Kenrick C. and Lee, Joshua Y. and Mackey, Lester W. and Tremaine, Marilyn M. and Klawe, Maria M.},
title = {Participatory Design with Proxies: Developing a Desktop-PDA System to Support People with Aphasia},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124797},
doi = {10.1145/1124772.1124797},
abstract = {In this paper, we describe the design and preliminary evaluation of a hybrid desktop-handheld system developed to support individuals with aphasia, a disorder which impairs the ability to speak, read, write, or understand language. The system allows its users to develop speech communication through images and sound on a desktop computer and download this speech to a mobile device that can then support communication outside the home. Using a desktop computer for input addresses some of this population's difficulties interacting with handheld devices, while the mobile device addresses stigma and portability issues. A modified participatory design approach was used in which proxies, that is, speech-language pathologists who work with aphasic individuals, assumed the role normally filled by users. This was done because of the difficulties in communicating with the target population and the high variability in aphasic disorders. In addition, the paper presents a case study of the proxy-use participatory design process that illustrates how different interview techniques resulted in different user feedback.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {151–160},
numpages = {10},
keywords = {aphasia, participatory design, assistive technology, multi-modal interfaces},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124798,
author = {Kristensen, Margit and Kyng, Morten and Palen, Leysia},
title = {Participatory Design in Emergency Medical Service: Designing for Future Practice},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124798},
doi = {10.1145/1124772.1124798},
abstract = {We describe our research-its approach, results and products-on Danish emergency medical service (EMS) field or "pre-hospital" work in minor and major incidents. We discuss how commitments to participatory design and attention to the qualitative differences between minor and major incidents address challenges identified by disaster sociolo-gists when designing for major incidents. Through qualitative research and participatory design, we have examined the features of EMS work and technology use in different emergency situations from the perspective of multiple actors. We conceptualize victims in incidents-and particularly in major incidents, where on-site medical as-sessments is highly incomplete-as boundary objects over which the complex and imperfect work of coordination is done. As an outcome of our participatory design approach, we describe a set of designs in support of future EMS work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {161–170},
numpages = {10},
keywords = {major incidents, medical response, participatory design, technology design, victim as boundary object, minor incidents, Future Lab, wireless biomonitor, emergency response},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124800,
author = {Luk, Joseph and Pasquero, Jerome and Little, Shannon and MacLean, Karon and Levesque, Vincent and Hayward, Vincent},
title = {A Role for Haptics in Mobile Interaction: Initial Design Using a Handheld Tactile Display Prototype},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124800},
doi = {10.1145/1124772.1124800},
abstract = {Mobile interaction can potentially be enhanced with well-designed haptic control and display. However, advances have been limited by a vicious cycle whereby inadequate haptic technology obstructs inception of vitalizing applications. We present the first stages of a systematic design effort to break that cycle, beginning with specific usage scenarios and a new handheld display platform based on lateral skin stretch. Results of a perceptual device characterization inform mappings between device capabilities and specific roles in mobile interaction, and the next step of hardware re-engineering.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {171–180},
numpages = {10},
keywords = {mobile, multimodal, lateral skin stretch, haptic, handheld interaction, display, design process, tactile},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124801,
author = {Hinckley, Ken and Guimbretiere, Francois and Baudisch, Patrick and Sarin, Raman and Agrawala, Maneesh and Cutrell, Ed},
title = {The Springboard: Multiple Modes in One Spring-Loaded Control},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124801},
doi = {10.1145/1124772.1124801},
abstract = {Modes allow a few inputs to invoke many operations, yet if a user misclassifies or forgets the state of a system, modes can result in errors. Spring-loaded modes (quasimodes) maintain a mode while the user holds a control such as a button or key. The Springboard is an interaction technique for tablet computers that extends quasimodes to encompass multiple tool modes in a single spring-loaded control. The Springboard allows the user to continue holding down a nonpreferred-hand command button after selecting a tool from a menu as a way to repeatedly apply the same tool. We find the Springboard improves performance for both a local marking menu and for a non-local marking menu ("lagoon") at the lower left corner of the screen. Despite the round-trip costs incurred to move the pen to a tool lagoon, a keystroke-level analysis of the true cost of each technique reveals the local marking menu is not significantly faster.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {181–190},
numpages = {10},
keywords = {marking menus, keystroke-level model, pen, modes, tablet, subtraction methodology, command selection},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124802,
author = {Froehlich, Bernd and Hochstrate, Jan and Skuk, Verena and Huckauf, Anke},
title = {The GlobeFish and the GlobeMouse: Two New Six Degree of Freedom Input Devices for Graphics Applications},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124802},
doi = {10.1145/1124772.1124802},
abstract = {We introduce two new six degree of freedom desktop input devices based on the key concept of combining forceless isotonic rotational input with force-requiring elastic translational input. The GlobeFish consists of a custom three degrees of freedom trackball which is elastically connected to a frame. The trackball is accessible from the top and bottom and can be moved slightly in all spatial directions by using force. The GlobeMouse device works in a similar way. Here the trackball is placed on top of a movable base, which requires to change the grip on the device to switch between rotating the trackball and moving the base.Our devices are manipulated with the fingertips allowing precise interaction with virtual objects. The elastic translation allows uniform input for all three axes and the isotonic trackball provides a natural mapping for rotations. Our user study revealed that the new devices perform significantly better in a docking task in comparison to the SpaceMouse, an integrated six degrees of freedom controller. Subjective data confirmed these results.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {191–199},
numpages = {9},
keywords = {input devices, user interface hardware, human factors, interaction techniques},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124804,
author = {Landgren, Jonas},
title = {Making Action Visible in Time-Critical Work},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124804},
doi = {10.1145/1124772.1124804},
abstract = {This paper presents descriptive accounts from an ethnographic study of time-critical work in the domain of emergency response and the operative work of fire crews. The verbal communication as part of such work creates difficulties in providing accountability of the fire crew's actions. The concept of work rhythms and temporal structures is used as an analytical framework. Design implications are presented suggesting that verbal communication should be made persistent, visible and accessible in order to support accountability. These design implications are discussed in relation to the fire crew's work practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {201–210},
numpages = {10},
keywords = {firemen, ethnography, emergency response, time-critical work, collaborative work},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124805,
author = {Bardram, Jakob and Bunde-Pedersen, Jonathan and Soegaard, Mads},
title = {Support for Activity-Based Computing in a Personal Computing Operating System},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124805},
doi = {10.1145/1124772.1124805},
abstract = {Research has shown that computers are notoriously bad at supporting the management of parallel activities and interruptions, and that mobility increases the severity of these problems. This paper presents activity-based computing (ABC) which supplements the prevalent data- and application-oriented computing paradigm with technologies for handling multiple, parallel and mobile work activities. We present the design and implementation of ABC support embedded in the Windows XP operating system. This includes replacing the Windows Taskbar with an Activity Bar, support for handling Windows applications, a zoomable user interface, and support for moving activities across different computers. We report an evaluation of this Windows XP ABC system which is based on a multi-method approach, where perceived ease-of-use and usefulness was evaluated together with rich interview material. This evaluation showed that users found the ABC XP extension easy to use and likely to be useful in their own work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {211–220},
numpages = {10},
keywords = {task management, ubiquitous computing, user evaluation, ABC, activity-based computing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124806,
author = {Voida, Stephen and Edwards, W. Keith and Newman, Mark W. and Grinter, Rebecca E. and Ducheneaut, Nicolas},
title = {Share and Share Alike: Exploring the User Interface Affordances of File Sharing},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124806},
doi = {10.1145/1124772.1124806},
abstract = {With the rapid growth of personal computer networks and the Internet, sharing files has become a central activity in computer use. The ways in which users control the what, how, and with whom of sharing are dictated by the tools they use for sharing; there are a wide range of sharing practices, and hence a wide range of tools to support these practices. In practice, users' requirements for certain sharing features may dictate their choice of tool, even though the other affordances available through that tool may not be an ideal match to the desired manner of sharing.In this paper, we explore users' current practices in file sharing and examine the tools used to share files. Based on our findings, we unpack the features and affordances of these tools into a set of dimensions along which sharing tools can be characterized. Then, we present the set of user interface features we have prototyped in an interface called a sharing palette, which provides a platform for exploration and experimentation with new modalities of sharing. We briefly present the tool as a whole and then focus on the individual features of the sharing palette that support reported styles of sharing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {221–230},
numpages = {10},
keywords = {computer-supported cooperative work (CSCW), user interface design, file sharing, sharing, user agency},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124808,
author = {Beckwith, Laura and Kissinger, Cory and Burnett, Margaret and Wiedenbeck, Susan and Lawrance, Joseph and Blackwell, Alan and Cook, Curtis},
title = {Tinkering and Gender in End-User Programmers' Debugging},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124808},
doi = {10.1145/1124772.1124808},
abstract = {Earlier research on gender effects with software features intended to help problem-solvers in end-user debugging environments has shown that females are less likely to use unfamiliar software features. This poses a serious problem because these features may be key to helping them with debugging problems. Contrasting this with research documenting males' inclination for tinkering in unfamiliar environments, the question arises as to whether encouraging tinkering with new features would help females overcome the factors, such as low self-efficacy, that led to the earlier results. In this paper, we present an experiment with males and females in an end-user debugging setting, and investigate how tinkering behavior impacts several measures of their debugging success. Our results show that the factors of tinkering, reflection, and self-efficacy, can combine in multiple ways to impact debugging effectiveness differently for males than for females.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {231–240},
numpages = {10},
keywords = {end-user programming, surprise-explain-reward, self-efficacy, gender, debugging, end-user software engineering, tinkering},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124809,
author = {Prabaker, Madhu and Bergman, Lawrence and Castelli, Vittorio},
title = {An Evaluation of Using Programming by Demonstration and Guided Walkthrough Techniques for Authoring and Utilizing Documentation},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124809},
doi = {10.1145/1124772.1124809},
abstract = {Much existing documentation is informal and serves to communicate "how-to" knowledge among restricted working groups. Using current practices, such documentation is both difficult to maintain and difficult to use properly.In this paper, we propose a documentation system, called DocWizards, that uses programming by demonstration to support low-cost authoring and guided walkthrough techniques to improve document usability.We report a comparative study between the use of DocWizards and traditional techniques for authoring and following documentation. The study participants showed significant gains in efficiency and reduction in error rates when using DocWizards. In addition, they expressed a clear preference for using the DocWizards tool, both for authoring and for following documentation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {241–250},
numpages = {10},
keywords = {guided-walkthrough, documentation authoring, programming by demonstration},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124810,
author = {Gweon, Gahgene and Rose, Carolyn and Carey, Regan and Zaiss, Zachary},
title = {Providing Support for Adaptive Scripting in an On-Line Collaborative Learning Environment},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124810},
doi = {10.1145/1124772.1124810},
abstract = {This paper describes results from a series of experimental studies to explore issues related to structuring productive group dynamics for collaborative learning using an adaptive support mechanism. The first study provides evidence in favor of the feasibility of the endeavor by demonstrating with a tightly controlled study that even without adaptive support, problem solving in pairs is significantly more effective for learning than problem solving alone. The results from a second study offer guidelines for strategic matching of students with learning partners. Furthermore, the results reveal specific areas for needed support. Based on the results from the second study, we present the design of an adaptive support mechanism, which we evaluate in a third study. The results from the third study provide evidence that certain aspects of our design for adaptive support in the form of strategic prompts are effective for manipulating student behavior in productive ways and for supporting learning. These results also motivate specific modifications to the original design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {251–260},
numpages = {10},
keywords = {adaptive support, collaborative learning, computer mediated communication},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124812,
author = {Cutrell, Edward and Robbins, Daniel and Dumais, Susan and Sarin, Raman},
title = {Fast, Flexible Filtering with Phlat},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124812},
doi = {10.1145/1124772.1124812},
abstract = {Systems for fast search of personal information are rapidly becoming ubiquitous. Such systems promise to dramatically improve personal information management, yet most are modeled on Web search in which users know very little about the content that they are searching. We describe the design and deployment of a system called Phlat that optimizes search for personal information with an intuitive interface that merges search and browsing through a variety of associative and contextual cues. In addition, Phlat supports a unified tagging (labeling) scheme for organizing personal content across storage systems (files, email, etc.). The system has been deployed to hundreds of employees within our organization. We report on both quantitative and qualitative aspects of system use. Phlat is available as a free download at http://research.microsoft.com/adapt/phlat.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {261–270},
numpages = {10},
keywords = {personal information management, interactive information retrieval, tagging, user interfaces, PIM, search interface},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124813,
author = {Bergman, Ofer and Beyth-Marom, Ruth and Nachmias, Rafi},
title = {The Project Fragmentation Problem in Personal Information Management},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124813},
doi = {10.1145/1124772.1124813},
abstract = {The project fragmentation problem in personal information management occurs when someone who is working on a single project stores and retrieves information items relating to that project from separate format-related collections (documents, emails and favorite Web sites). This study was aimed to test empirically users' working habits in order to shed light on the project fragmentation problem. Twenty personal computer users participated in the study. Data collection tools included an interview, screen captures and a questionnaire. Results indicate that users tend to store and retrieve project-related information items based on different formats in one project folder when the interface design encourages it. However, they store and retrieve project- related information items in different folders (documents, emails and favorite Web sites) when the design encourages such fragmentation. Two types of attempts to solve the project fragmentation problem are reviewed and a new possible solution is suggested.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {271–274},
numpages = {4},
keywords = {email, personal information management, favorites, projects, folder hierarchies, documents, fragmentation, integration},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124814,
author = {Kaye, Joseph 'Jofish' and Vertesi, Janet and Avery, Shari and Dafoe, Allan and David, Shay and Onaga, Lisa and Rosero, Ivan and Pinch, Trevor},
title = {To Have and to Hold: Exploring the Personal Archive},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124814},
doi = {10.1145/1124772.1124814},
abstract = {The personal archive is not only about efficient storage and retrieval of information. This paper describes a study of forty-eight academics and the techniques and tools they use to manage their digital and material archiving of papers, emails, documents, internet bookmarks, correspondence, and other artifacts. We present two sets of results: we first discuss rationales behind subjects' archiving, which go beyond information retrieval to include creating a legacy, sharing resources, confronting fears and anxieties, and identity construction. We then show how these rationales were mapped into our subjects' physical, social and electronic spaces, and discuss implications for development of digital tools that allow for personal archiving.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {275–284},
numpages = {10},
keywords = {archiving, email, identity, filing, bookmarks, ethnography},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124815,
author = {Hsieh, Gary and Wood, Kenneth and Sellen, Abigail},
title = {Peripheral Display of Digital Handwritten Notes},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124815},
doi = {10.1145/1124772.1124815},
abstract = {We present a system for the peripheral display of digital handwritten notes, motivated by the joint observation that people seldom refer back to their notes and that these notes often contain useful information. We describe the user-led design of the system, incorporating interviews, paper prototypes, and interactive prototypes. A preliminary field trial of the system indicates that users derive value from the system both for low-distraction reminding and for serendipitous idea generation. These promising initial results suggest significant scope for future work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {285–288},
numpages = {4},
keywords = {digital ink, reminders, handwritten notes, Tablet PC, ambient display, peripheral display},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124817,
author = {Nacenta, Miguel A. and Sallam, Samer and Champoux, Bernard and Subramanian, Sriram and Gutwin, Carl},
title = {Perspective Cursor: Perspective-Based Interaction for Multi-Display Environments},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124817},
doi = {10.1145/1124772.1124817},
abstract = {Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {289–298},
numpages = {10},
keywords = {laser pointing, multi-display interaction techniques, direct-manipulation interfaces, multi-monitor environments},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124818,
author = {Irani, Pourang and Gutwin, Carl and Yang, Xing Dong},
title = {Improving Selection of Off-Screen Targets with Hopping},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124818},
doi = {10.1145/1124772.1124818},
abstract = {Many systems provide the user with a limited viewport of a larger graphical workspace. In these systems, the user often needs to find and select targets that are in the workspace, but not visible in the current view. Standard methods for navigating to the off-screen targets include scrolling, panning, and zooming; however, these are laborious when users cannot see a target's direction or distance. Techniques such as halos can provide awareness of targets, but actually getting to the target is still slow with standard navigation. To improve off-screen target selection, we developed a new technique called hop, which combines halos with a teleportation mechanism that shows proxies of distant objects. Hop provides both awareness of off-screen targets and fast navigation to the target context. A study showed that users are significantly faster at selecting off-screen targets with hopping than with two-level zooming or grab-and-drag panning, and it is clear that hop will be faster than either halos or proxy-based techniques (like drag-and-pop or vacuum filtering) by themselves. Hop both improves on halo-based navigation and extends the value of proxies to small-screen environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {299–308},
numpages = {10},
keywords = {proxy targets, drag-and-pop, vacuum filtering, graphical workspaces, navigation, halo, off-screen targets},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124819,
author = {Wigdor, Daniel and Shen, Chia and Forlines, Clifton and Balakrishnan, Ravin},
title = {Effects of Display Position and Control Space Orientation on User Preference and Performance},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124819},
doi = {10.1145/1124772.1124819},
abstract = {In many environments, it is often the case that input is made to displays that are positioned non-traditionally relative to one or more users. This typically requires users to perform interaction tasks under transformed input-display spatial mappings, and the literature is unclear as to how such transformations affect performance. We present two experiments that explore the impact of display space position and input control space orientation on user's subjective preference and objective performance in a docking task. Our results provide guidelines as to optimal display placement and control orientation in collaborative computing environments with one or more shared displays.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {309–318},
numpages = {10},
keywords = {display position, input-output mappings, input control space orientation, spatial transformation, performance},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124821,
author = {Yin, Min and Zhai, Shumin},
title = {The Benefits of Augmenting Telephone Voice Menu Navigation with Visual Browsing and Search},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124821},
doi = {10.1145/1124772.1124821},
abstract = {Automatic interactive voice response (IVR) based telephone routing has long been recognized as a frustrating interaction experience. This paper presents a series of experiments examining the benefits of augmenting telephone voice menus with coordinated visual displays and keyword search. The first experiment qualitatively studied callers' experience of having a visual menu on a screen in synchronization with the telephone voice menu tree navigation. The second experiment quantitatively measured callers' performance in time and accuracy with and without visual display augmentation. The third experiment tested keyword search in comparison to visual browsing of telephone menu trees. Study participants uniformly and enthusiastically liked the visual augmentation of voice menus. On average with visual augmentation callers could navigate phone trees 36% faster with 75% fewer errors, and made choices ahead of the voice menu over 60% of the time. Search vs. browsing had similar navigation performance but offered different and complementary user experiences. Overall our studies conclude that telephone voice menu navigation can be significantly improved with a visual channel augmentation, resulting in both business cost reduction and user experience satisfaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {319–328},
numpages = {10},
keywords = {visual manual browsing, integrated user experience, multi-modal interaction, telephone, instant messaging, voice menu, keyword search},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124822,
author = {Tucker, Simon and Whittaker, Steve},
title = {Time is of the Essence: An Evaluation of Temporal Compression Algorithms},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124822},
doi = {10.1145/1124772.1124822},
abstract = {Although speech is a potentially rich information source, a major barrier to exploiting speech archives is the lack of useful tools for efficiently accessing lengthy speech recordings. This paper develops and evaluates techniques for temporal compression - reducing the time people take to listen to a recording while still extracting critical information. We first describe an exploratory study that identifies novel excision techniques that remove unimportant words or utterances from the recording. We then develop a new method for evaluating how well temporal compression supports users in forming a general understanding of a recording. Applying this method, we demonstrate that excision techniques are generally more effective than standard compression techniques that simply speed up the entire recording.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {329–338},
numpages = {10},
keywords = {meetings interfaces, audio interfaces, speech summary, speed-up, speech manipulation, temporal compression, speech-as-data, excision, summarization, evaluation methods},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124823,
author = {Burke, Moira and Amento, Brian and Isenhour, Philip},
title = {Error Correction of Voicemail Transcripts in SCANMail},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124823},
doi = {10.1145/1124772.1124823},
abstract = {Despite its widespread use, voicemail presents numerous usability challenges: People must listen to messages in their entirety, they cannot search by keywords, and audio files do not naturally support visual skimming. SCANMail overcomes these flaws by automatically generating text transcripts of voicemail messages and presenting them in an email-like interface. Transcripts facilitate quick browsing and permanent archive. However, errors from the automatic speech recognition (ASR) hinder the usefulness of the transcripts. The work presented here specifically addresses these problems by evaluating user-initiated error correction of transcripts. User studies of two editor interfaces-a grammar-assisted menu and simple replacement by typing-reveal reduced audio playback times and an emphasis on editing important words with the menu, suggesting its value in mobile environments where limited input capabilities are the norm and user privacy is essential. The study also adds to the scarce body of work on ASR confidence shading, suggesting that shading may be more helpful than previously reported.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {339–348},
numpages = {10},
keywords = {confidence shading, error correction, editor interfaces, speech recognition, voicemail},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124825,
author = {Latulipe, Celine and Mann, Stephen and Kaplan, Craig S. and Clarke, Charlie L. A.},
title = {SymSpline: Symmetric Two-Handed Spline Manipulation},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124825},
doi = {10.1145/1124772.1124825},
abstract = {We introduce symSpline: a symmetric, dual-mouse technique for the manipulation of spline curves. In symSpline, two cursors control the positions of the ends of the tangent to an edit point. By moving the tangent with both mice, the tangent and the edit point can be translated while the curvature of the spline is adjusted simultaneously, according to the length and angle of the tangent. We compare the symSpline technique to two asymmetric dual-mouse spline manipulation techniques and to a standard single-mouse technique. In a spline matching experiment, symSpline outperformed the two asymmetric dual-mouse techniques and all three dual-mouse techniques proved to be faster than the single-mouse technique. Additionally, symSpline was the technique most preferred by test participants.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {349–358},
numpages = {10},
keywords = {two-handed interaction, symmetric interaction, splines, spline manipulation},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124826,
author = {Marentakis, Georgios N. and Brewster, Stephen A.},
title = {Effects of Feedback, Mobility and Index of Difficulty on Deictic Spatial Audio Target Acquisition in the Horizontal Plane},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124826},
doi = {10.1145/1124772.1124826},
abstract = {We present the results of an empirical study investigating the effect of feedback, mobility and index of difficulty on a deictic spatial audio target acquisition task in the horizontal plane in front of a user. With audio feedback, spatial audio display elements are found to enable usable deictic interac-tion that can be described using Fitts law. Feedback does not affect perceived workload or preferred walking speed compared to interaction without feedback. Mobility is found to degrade interaction speed and accuracy by 20%. Participants were able to perform deictic spatial audio target acquisition when mobile while walking at 73% of their pre-ferred walking speed. The proposed feedback design is ex-amined in detail and the effects of variable target widths are quantified. Deictic interaction with a spatial audio display is found to be a feasible solution for future interface designs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {359–368},
numpages = {10},
keywords = {spatial audio target acquisition, 3D audio, Fitts' Law, mobile interaction, gestures},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124827,
author = {Blasko, Gabor and Narayanaswami, Chandra and Feiner, Steven},
title = {Prototyping Retractable String-Based Interaction Techniques for Dual-Display Mobile Devices},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124827},
doi = {10.1145/1124772.1124827},
abstract = {Accessing information on mobile and wearable devices often requires the user's visual attention, and the precise operation of virtual or physical widgets. However, these interactions may sometimes be too time-consuming and socially inappropriate. To address this, we introduce a novel input/output device that is based on the manipulation of a retractable string in a polar coordinate frame. Depending on how the user pulls the string from its enclosure--to a particular length, at a particular angle--various system features may be directly accessed. Furthermore, we present our concept for a 1D pixel array, embedded in the string that may be used as a secondary 1D display. Since it is possible to unwind the display itself and trigger functionality with a single pull, information may be accessed and presented quickly, and perceived at a glance. We present scenarios for how the string input/output device may be used in conjunc-tion with the mobile device's primary 2D display and describe our augmented reality proof-of-concept prototype.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {369–372},
numpages = {4},
keywords = {mobile computing, mobile interaction, retractable string-based input, pixel-array displays, wearable computing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124828,
author = {Plouznikoff, Alexandre and Plouznikoff, Nicolas and Robert, Jean-Marc and Desmarais, Michel},
title = {Enhancing Human-Machine Interactions: Virtual Interface Alteration through Wearable Computers},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124828},
doi = {10.1145/1124772.1124828},
abstract = {This paper studies a novel approach advocating the virtual alteration of real-world interfaces through a form of augmented reality. Following an introduction reminding the need for easy to use and more consistent interfaces across our many day to day devices, this paper makes the case for using wearable computers to enhance the interactions between humans and conventional appliances. We present the rationale behind our research and summarize our current prototype's functionalities, architecture and implementation. Preliminary results suggest that virtually altering the interface of real world devices improves execution times for simple tasks using these devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {373–376},
numpages = {4},
keywords = {wearable computer, virtual interface alteration, interaction enhancement, augmented reality},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124830,
author = {Jakobsen, Mikkel R. and Hornb\ae{}k, Kasper},
title = {Evaluating a Fisheye View of Source Code},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124830},
doi = {10.1145/1124772.1124830},
abstract = {Navigating and understanding the source code of a program are highly challenging activities. This paper introduces a fisheye view of source code to a Java programming environment. The fisheye view aims to support a programmer's navigation and understanding by displaying those parts of the source code that have the highest degree of interest given the current focus. An experiment was conducted which compared the usability of the fisheye view with a common, linear presentation of source code. Sixteen participants performed tasks significantly faster with the fisheye view, although results varied dependent on the task type. The participants generally preferred the interface with the fisheye view. We analyse participants' interaction with the fisheye view and suggest how to improve its performance. In the calculation of the degree of interest, we suggest to emphasize those parts of the source code that are semantically related to the programmer's current focus.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {377–386},
numpages = {10},
keywords = {user study, Eclipse, information visualization, fisheye view, programming},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124831,
author = {Ko, Andrew J. and Myers, Brad A.},
title = {Barista: An Implementation Framework for Enabling New Tools, Interaction Techniques and Views in Code Editors},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124831},
doi = {10.1145/1124772.1124831},
abstract = {Recent advances in programming environments have focused on improving programmer productivity by utilizing the inherent structure in computer programs. However, because these environments represent code as plain text, it is difficult and sometimes impossible to embed interactive tools, annotations, and alternative views in the code itself. Barista is an implementation framework that enables the creation of such user interfaces by simplifying the implementation of editors that represent code internally as an abstract syntax tree and maintain a corresponding, fully structured visual representation on-screen. Barista also provides designers of editors with a standard text-editing interaction technique that closely mimics that of conventional text editors, overcoming a central usability issue of previous structured code editors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {387–396},
numpages = {10},
keywords = {structured editors, end-user software engineering, programming environments},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124832,
author = {Myers, Brad A. and Weitzman, David A. and Ko, Andrew J. and Chau, Duen H.},
title = {Answering Why and Why Not Questions in User Interfaces},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124832},
doi = {10.1145/1124772.1124832},
abstract = {Modern applications such as Microsoft Word have many automatic features and hidden dependencies that are frequently helpful but can be mysterious to both novice and expert users. The ""Crystal"" application framework provides an architecture and interaction techniques that allow programmers to create applications that let the user ask a wide variety of questions about why things did and did not happen, and how to use the related features of the application without using natural language. A user can point to an object or a blank space and get a popup list of questions about it, or the user can ask about recent actions from a temporal list. Parts of a text editor were implemented to show that these techniques are feasible, and a user test suggests that they are helpful and well-liked.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {397–406},
numpages = {10},
keywords = {questions, why, help, natural programming},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124834,
author = {Ducheneaut, Nicolas and Yee, Nicholas and Nickell, Eric and Moore, Robert J.},
title = {"Alone Together?": Exploring the Social Dynamics of Massively Multiplayer Online Games},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124834},
doi = {10.1145/1124772.1124834},
abstract = {Massively Multiplayer Online Games (MMOGs) routinely attract millions of players but little empirical data is available to assess their players' social experiences. In this paper, we use longitudinal data collected directly from the game to examine play and grouping patterns in one of the largest MMOGs: World of Warcraft. Our observations show that the prevalence and extent of social activities in MMOGs might have been previously over-estimated, and that gaming communities face important challenges affecting their cohesion and eventual longevity. We discuss the implications of our findings for the design of future games and other online social spaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {407–416},
numpages = {10},
keywords = {activity metrics, online communities, massively multiplayer online games, social dynamics},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124835,
author = {Bell, Marek and Chalmers, Matthew and Barkhuus, Louise and Hall, Malcolm and Sherwood, Scott and Tennent, Paul and Brown, Barry and Rowland, Duncan and Benford, Steve and Capra, Mauricio and Hampshire, Alastair},
title = {Interweaving Mobile Games with Everyday Life},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124835},
doi = {10.1145/1124772.1124835},
abstract = {We introduce a location--based game called Feeding Yoshi that provides an example of seamful design, in which key characteristics of its underlying technologies-the coverage and security characteristics of WiFi-are exposed as a core element of gameplay. Feeding Yoshi is also a long--term, wide--area game, being played over a week between three different cities during an initial user study. The study, drawing on participant diaries and interviews, supported by observation and analysis of system logs, reveals players' reactions to the game. We see the different ways in which they embedded play into the patterns of their daily lives, augmenting existing practices and creating new ones, and observe the impact of varying location on both the ease and feel of play. We identify potential design extensions to Feeding Yoshi and conclude that seamful design provides a route to creating engaging experiences that are well adapted to their underlying technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {417–426},
numpages = {10},
keywords = {ubiquitous computing, seamful design, mobile multiplayer games},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124836,
author = {Benford, Steve and Crabtree, Andy and Reeves, Stuart and Sheridan, Jennifer and Dix, Alan and Flintham, Martin and Drozd, Adam},
title = {The Frame of the Game: Blurring the Boundary between Fiction and Reality in Mobile Experiences},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124836},
doi = {10.1145/1124772.1124836},
abstract = {Mobile experiences that take place in public settings such as on city streets create new opportunities for interweaving the fictional world of a performance or game with the everyday physical world. A study of a touring performance reveals how designers generated excitement and dramatic tension by implicating bystanders and encouraging the (apparent) crossing of normal boundaries of behaviour. The study also shows how designers dealt with associated risks through a process of careful orchestration. Consequently, we extend an existing framework for designing spectator interfaces with the concept of performance frames, enabling us to distinguish audience from bystanders. We conclude that using ambiguity to blur the frame can be a powerful design tactic, empowering players to willingly suspend disbelief, so long as a safety-net of orchestration ensures that they do not stray into genuine difficulty.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {427–436},
numpages = {10},
keywords = {spectators, mobile games, ambiguity, risk, mixed reality performances, frames, orchestration, awareness},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124838,
author = {Hornecker, Eva and Buur, Jacob},
title = {Getting a Grip on Tangible Interaction: A Framework on Physical Space and Social Interaction},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124838},
doi = {10.1145/1124772.1124838},
abstract = {Our current understanding of human interaction with hybrid or augmented environments is very limited. Here we focus on 'tangible interaction', denoting systems that rely on embodied interaction, tangible manipulation, physical representation of data, and embeddedness in real space. This synthesis of prior 'tangible' definitions enables us to address a larger design space and to integrate approaches from different disciplines. We introduce a framework that focuses on the interweaving of the material/physical and the social, contributes to understanding the (social) user experience of tangible interaction, and provides concepts and perspectives for considering the social aspects of tangible interaction. This understanding lays the ground for evolving knowledge on collaboration-sensitive tangible interaction design. Lastly, we analyze three case studies, using the framework, thereby illustrating the concepts and demonstrating their utility as analytical tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {437–446},
numpages = {10},
keywords = {framework, tangible interaction, analysis, tangible interface, collaboration, design, CSCW, social interaction},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124839,
author = {Fernaeus, Ylva and Tholander, Jakob},
title = {Finding Design Qualities in a Tangible Programming Space},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124839},
doi = {10.1145/1124772.1124839},
abstract = {We reflect upon the process of developing a tangible space for children's collaborative construction of screen-based systems. As in all design work, the design process involved continual refinements of initial ideas and their practical realisation. We discuss how some widely held assumptions often put forward with tangible interfaces were given up in favour of reaching overall goals of interaction. In particular our design involved a shift from a focus on persistent representation and readability of tangible code structures, to instead focus on achieving reusability of programming resources. On a general level, our results illustrate a view on tangibles as resources for action instead of only as alternative forms of data representation. Importantly, this view includes action directed towards the computer as well as off-line socially oriented action conducted with the tangible artefacts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {447–456},
numpages = {10},
keywords = {tangible programming, tangible user interfaces, embodied interaction},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124840,
author = {Consolvo, Sunny and Everitt, Katherine and Smith, Ian and Landay, James A.},
title = {Design Requirements for Technologies That Encourage Physical Activity},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124840},
doi = {10.1145/1124772.1124840},
abstract = {Overweight and obesity are a global epidemic, with over one billion overweight adults worldwide (300+ million of whom are obese). Obesity is linked to several serious health problems and medical conditions. Medical experts agree that physical activity is critical to maintaining fitness, reducing weight, and improving health, yet many people have difficulty increasing and maintaining physical activity in everyday life. Clinical studies have shown that health benefits can occur from simply increasing the number of steps one takes each day and that social support can motivate people to stay active. In this paper, we describe Houston, a prototype mobile phone application for encouraging activity by sharing step count with friends. We also present four design requirements for technologies that encourage physical activity that we derived from a three-week long in situ pilot study that was conducted with women who wanted to increase their physical activity.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {457–466},
numpages = {10},
keywords = {obesity, mobile phone, fitness, social support, physical activity, design requirements, pedometer, overweight},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124842,
author = {Proschowsky, Morten and Schultz, Nette and Jacobsen, Niels Ebbe},
title = {An Intuitive Text Input Method for Touch Wheels},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124842},
doi = {10.1145/1124772.1124842},
abstract = {In this paper we describe a new method for doing text input with touch sensitive wheels. The method is called Transparent User guided Prediction (TUP). With TUP all characters are assigned to fixed positions on the wheel. A language prediction algorithm is used to make it easy to select the most likely characters. The use of the prediction algorithm is transparent for the users, which makes the use of TUP very intuitive. A prototype of TUP is evaluated against the date stamp method for doing wheel text input. Text entry speed for TUP is about 6-7 words per minute for novice users. This is approximately 30% faster than the date stamp method.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {467–470},
numpages = {4},
keywords = {text entry, touch wheel, mobile devices, predictive text},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124843,
author = {Gong, Jun and Tarasewich, Peter},
title = {A New Error Metric for Text Entry Method Evaluation},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124843},
doi = {10.1145/1124772.1124843},
abstract = {On devices such as mobile phones, text is often entered using keypads and predictive text entry techniques. Current metrics used for measuring text entry error rates have limitations in terms of the types of errors they account for, and cannot easily distinguish between different types of errors. This research proposes a new text entry error metric that addresses some of the outstanding issues that exist with current metrics. Specifically, the metric accounts in detail for the way the user handles corrections during text entry, moving beyond current keystroke level error measurement. The feasibility and usefulness of this new metric is shown through the analysis of an experiment that tests an alphabetically constrained keypad design that includes upper and lower case letters, numbers, and punctuation marks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {471–474},
numpages = {4},
keywords = {error metrics, predictive keypad text entry, novice learning and usability, mobile device user interface design},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124844,
author = {Wilson, Andrew D. and Agrawala, Maneesh},
title = {Text Entry Using a Dual Joystick Game Controller},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124844},
doi = {10.1145/1124772.1124844},
abstract = {We present a new bimanual text entry technique designed for today's dual-joystick game controllers. The left and right joysticks are used to independently select characters from the corresponding (left/right) half of an on-screen se-lection keyboard. Our dual-stick approach is analogous to typing on a standard keyboard, where each hand (left/right) presses keys on the corresponding side of the keyboard. We conducted a user study showing that our technique supports keyboarding skills transfer and is thereby readily learnable. Our technique increases entry speed significantly compared to the status quo single stick selection keyboard technique.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {475–478},
numpages = {4},
keywords = {dual control pad, text entry, game controller, dual joystick},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124845,
author = {Wobbrock, Jacob and Myers, Brad},
title = {Trackball Text Entry for People with Motor Impairments},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124845},
doi = {10.1145/1124772.1124845},
abstract = {We present a new gestural text entry method for trackballs. The method uses the mouse cursor and relies on crossing instead of pointing. A user writes in fluid Roman-like unistrokes by ""pulsing"" the trackball in desired letter patterns. We examine this method both theoretically using the Steering Law and empirically in two studies. Our studies show that able-bodied users who were unfamiliar with trackballs could write at about 10 wpm with &lt;4% total errors after 45 minutes. In eight sessions, a motor-impaired trackball user peaked at 7.11 wpm with 0% uncorrected errors, compared to 5.95 wpm with 0% uncorrected errors with an on-screen keyboard. Over sessions, his speeds were significantly faster with our gestural method than with an on-screen keyboard. A former 15-year veteran of on-screen keyboards, he now uses our gestural method instead.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {479–488},
numpages = {10},
keywords = {trackballs, crossing, text input, pointing, Steering Law, Fitts' Law, text entry, unistrokes, gestures, EdgeWrite},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124846,
author = {Wobbrock, Jacob and Myers, Brad and Rothrock, Brandon},
title = {Few-Key Text Entry Revisited: Mnemonic Gestures on Four Keys},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124846},
doi = {10.1145/1124772.1124846},
abstract = {We present a new 4-key text entry method that, unlike most few-key methods, is gestural instead of selection-based. Importantly, its gestures mimic the writing of Roman letters for high learnability. We compare this new 4-key method to predominant 3-key and 5-key methods theoretically using KSPC and empirically using a longitudinal study of 5 subjects over 10 sessions. The study includes an evaluation of the 4-key method without any on-screen visualization-an impossible condition for the selection-based methods. Our results show that the new 4-key method is quickly learned, becoming faster than the 3-key and 5-key methods after just ~10 minutes of writing, although it produces more errors. Interestingly, removing a visualization of the gestures being made causes no detriment to the 4-key method, which is an advantage for eyes-free text entry.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {489–492},
numpages = {4},
keywords = {text entry, text input, unistrokes, EdgeWrite, wearables, mobile devices, date stamp, selection keyboard, gestures},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124848,
author = {Munteanu, Cosmin and Baecker, Ronald and Penn, Gerald and Toms, Elaine and James, David},
title = {The Effect of Speech Recognition Accuracy Rates on the Usefulness and Usability of Webcast Archives},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124848},
doi = {10.1145/1124772.1124848},
abstract = {The widespread availability of broadband connections has led to an increase in the use of Internet broadcasting (webcasting). Most webcasts are archived and accessed numerous times retrospectively. In the absence of transcripts of what was said, users have difficulty searching and scanning for specific topics. This research investigates user needs for transcription accuracy in webcast archives, and measures how the quality of transcripts affects user performance in a question-answering task, and how quality affects overall user experience. We tested 48 subjects in a within-subjects design under 4 conditions: perfect transcripts, transcripts with 25% Word Error Rate (WER), transcripts with 45% WER, and no transcript. Our data reveals that speech recognition accuracy linearly influences both user performance and experience, shows that transcripts with 45% WER are unsatisfactory, and suggests that transcripts having a WER of 25% or less would be useful and usable in webcast archives.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {493–502},
numpages = {10},
keywords = {webcast systems, text transcripts, navigational tools, automatic speech recognition},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124849,
author = {Dillon, Andrew and Kleinman, Lisa and Choi, Gil Ok and Bias, Randolph},
title = {Visual Search and Reading Tasks Using ClearType and Regular Displays: Two Experiments},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124849},
doi = {10.1145/1124772.1124849},
abstract = {Two experiments comparing user performance on ClearType and Regular displays are reported. In the first, 26 participants scanned a series of spreadsheets for target information. Speed of performance was significantly faster with ClearType. In the second experiment, 25 users read two articles for meaning. Reading speed was significantly faster for ClearType. In both experiments no differences in accuracy of performance or visual fatigue scores were observed. The data also reveal substantial individual differences in performance suggesting ClearType may not be universally beneficial to information workers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {503–511},
numpages = {9},
keywords = {ClearType, readability, visual displays, information tasks},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124850,
author = {Medynskiy, Yevgeniy "Eugene" and Ducheneaut, Nicolas and Farahat, Ayman},
title = {Using Hybrid Networks for the Analysis of Online Software Development Communities},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124850},
doi = {10.1145/1124772.1124850},
abstract = {Social network-based systems usually suffer from two major limitations: they tend to rely on a single data source (e.g. email traffic), and the form of network patterns is often privileged over their content. To go beyond these limitations we describe a system we developed to visualize and navigate hybrid networks constructed from multiple data sources - with a direct link between formal representations and the raw content. We illustrate the benefits of our approach by analyzing patterns of collaboration in a large Open Source project, using hybrid networks to uncover important roles that would otherwise have been missed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {513–516},
numpages = {4},
keywords = {online communities, natural language processing, visualization, social networks},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124851,
author = {Wang, Weixin and Wang, Hui and Dai, Guozhong and Wang, Hongan},
title = {Visualization of Large Hierarchical Data by Circle Packing},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124851},
doi = {10.1145/1124772.1124851},
abstract = {In this paper a novel approach is described for tree visualization using nested circles. The brother nodes at the same level are represented by externally tangent circles; the tree nodes at different levels are displayed by using 2D nested circles or 3D nested cylinders. A new layout algorithm for tree structure is described. It provides a good overview for large data sets. It is easy to see all the branches and leaves of the tree. The new method has been applied to the visualization of file systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {517–520},
numpages = {4},
keywords = {tree visualization, nested circles, file system, circle packing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124853,
author = {Wolf, Tracee Vetting and Rode, Jennifer A. and Sussman, Jeremy and Kellogg, Wendy A.},
title = {Dispelling "Design" as the Black Art of CHI},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124853},
doi = {10.1145/1124772.1124853},
abstract = {We discuss the legacy and processes of creative design, and differentiate it from the type of user-centered design commonly found in CHI. We provide an example of this process, and discuss how design practice constitutes an essential mode of inquiry. We argue the complementary nature of creative design and user-centered design practices. Syncretic disciplines shift and drift from their original practice. A key issue is how CHI is to respond to changes in acceptable design practice. A key contribution of this work is an illustrative example showing how designers can communicate their intellectual rigor to the CHI community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {521–530},
numpages = {10},
keywords = {sketching, design, creative design, method, process, theory, prototyping, user centered design},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124854,
author = {Coughlan, Tim and Johnson, Peter},
title = {Interaction in Creative Tasks},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124854},
doi = {10.1145/1124772.1124854},
abstract = {The design of tools for creative activities affects the creative processes and output of users. In this paper we consider how an understanding of creative interaction can inform the design of support tools in a creative domain, and where creative needs cross domain boundaries. Using observations of musical composers we analyse the theoretical approaches to understanding creativity and their use to HCI. Cycles of ideation and evaluation are suggested as atomic elements of creative interactions, with the representation of ideas a central activity for individual and collaborating composers. A model of collaborative composition was developed, along with an analysis of the representational types used in the domain. This led to the design and evaluation of a prototype Sonic Sketchpad for musical idea representation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {531–540},
numpages = {10},
keywords = {composition, collaboration, music, creativity, representation},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124855,
author = {Dourish, Paul},
title = {Implications for Design},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124855},
doi = {10.1145/1124772.1124855},
abstract = {Although ethnography has become a common approach in HCI research and design, considerable confusion still attends both ethnographic practice and the criteria by which it should be evaluated in HCI. Often, ethnography is seen as an approach to field investigation that can generate requirements for systems development; by that token, the major evaluative criterion for an ethnographic study is the implications it can provide for design. Exploring the nature of ethnographic inquiry, this paper suggests that "implications for design" may not be the best metric for evaluation and may, indeed, fail to capture the value of ethnographic investigations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {541–550},
numpages = {10},
keywords = {ethnography, design},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124857,
author = {Parikh, Tapan S. and Javid, Paul and K., Sasikumar and Ghosh, Kaushik and Toyama, Kentaro},
title = {Mobile Phones and Paper Documents: Evaluating a New Approach for Capturing Microfinance Data in Rural India},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124857},
doi = {10.1145/1124772.1124857},
abstract = {CAM is a user interface toolkit that allows a camera-equipped mobile phone to interact with paper documents. It is designed to automate inefficient, paper-intensive information processes in the developing world. In this paper we present a usability evaluation of an application built using CAM for collecting data from microfinance groups in rural India. This application serves an important and immediate need in the microfinance industry. Our quantitative results show that the user interface is efficient, accurate and can quickly be learned by rural users. The results were competitive with an equivalent PC-based UI. Qualitatively, the interface was found easy to use by almost all users. This shows that, with a properly designed user interface, mobile phones can be a preferred platform for many rural computing applications. Voice feedback and numeric data entry were particularly well-received by users. We are conducting a pilot of this application with 400 microfinance groups in India.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {551–560},
numpages = {10},
keywords = {mobile phone, rural development, visual codes, ICT, document processing, microfinance, paper user interface},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124858,
author = {Luff, Paul and Heath, Christian and Kuzuoka, Hideaki and Yamazaki, Keiichi and Yamashita, Jun},
title = {Handling Documents and Discriminating Objects in Hybrid Spaces},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124858},
doi = {10.1145/1124772.1124858},
abstract = {Recently a number of researchers have uncovered various ways in which paper documents support everyday work practice and have suggested how these may be reflected in the design of new technologies. In this paper we consider how activities on and around paper documents may be supported when participants are remote from each other. When we consider the uses of an experimental system that provides a number of resources for supporting work over documents, it becomes apparent how critical it is to support apparently simple pointing and referencing, and how complex such conduct can be. This suggests some considerations both for developers of enhanced media spaces and analysts of everyday conduct.Clarified descriptions of technology and fragments including changes to figures. Added points concerning the scope of the technology the conception of sequence and calrified the requirement regarding redundancy. Revised descriptions of fragments in an atempt to make thsee less dense Corrected several typographic errors including those mentioned by the reviewers' gesture.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {561–570},
numpages = {10},
keywords = {collaboration, video-mediated communication, documents},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124859,
author = {Yeh, Ron and Liao, Chunyuan and Klemmer, Scott and Guimbreti\`{e}re, Fran\c{c}ois and Lee, Brian and Kakaradov, Boyko and Stamberger, Jeannie and Paepcke, Andreas},
title = {ButterflyNet: A Mobile Capture and Access System for Field Biology Research},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124859},
doi = {10.1145/1124772.1124859},
abstract = {Through a study of field biology practices, we observed that biology fieldwork generates a wealth of heterogeneous information, requiring substantial labor to coordinate and distill. To manage this data, biologists leverage a diverse set of tools, organizing their effort in paper notebooks. These observations motivated ButterflyNet, a mobile capture and access system that integrates paper notes with digital photographs captured during field research. Through ButterflyNet, the activity of leafing through a notebook expands to browsing all associated digital photos. ButterflyNet also facilitates the transfer of captured content to spreadsheets, enabling biologists to share their work. A first-use study with 14 biologists found this system to offer rich data capture and transformation, in a manner felicitous with current practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {571–580},
numpages = {10},
keywords = {augmented paper notebook, mobile capture and access},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124861,
author = {Dhamija, Rachna and Tygar, J. D. and Hearst, Marti},
title = {Why Phishing Works},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124861},
doi = {10.1145/1124772.1124861},
abstract = {To build systems shielding users from fraudulent (or phishing) websites, designers need to know which attack strategies work and why. This paper provides the first empirical evidence about which malicious strategies are successful at deceiving general users. We first analyzed a large set of captured phishing attacks and developed a set of hypotheses about why these strategies might work. We then assessed these hypotheses with a usability study in which 22 participants were shown 20 web sites and asked to determine which ones were fraudulent. We found that 23% of the participants did not look at browser-based cues such as the address bar, status bar and the security indicators, leading to incorrect choices 40% of the time. We also found that some visual deception attacks can fool even the most sophisticated users. These results illustrate that standard security indicators are not effective for a substantial fraction of users, and suggest that alternative approaches are needed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {581–590},
numpages = {10},
keywords = {phishing user study, why phishing works, phishing, security usability},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124862,
author = {Gaw, Shirley and Felten, Edward W. and Fernandez-Kelly, Patricia},
title = {Secrecy, Flagging, and Paranoia: Adoption Criteria in Encrypted Email},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124862},
doi = {10.1145/1124772.1124862},
abstract = {We consider the social context behind users' decisions about whether and when to encrypt email, interviewing a sample of users from an organization whose mission requires secrecy. Interview participants varied in their level of technical sophistication and in their involvement with secrets. We found that users saw universal, routine use of encryption as paranoid. Encryption flagged a message not only as confidential but also as urgent, so users found the encryption of mundane messages annoying. In general, decisions about encryption were driven not just by technical issues such as usability, but also by social factors. We argue that understanding these social factors is necessary to guide the design of encryption technologies that can be more widely adopted.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {591–600},
numpages = {10},
keywords = {encrypted e-mail, extended case method, security, activism},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124863,
author = {Wu, Min and Miller, Robert C. and Garfinkel, Simson L.},
title = {Do Security Toolbars Actually Prevent Phishing Attacks?},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124863},
doi = {10.1145/1124772.1124863},
abstract = {Security toolbars in a web browser show security-related information about a website to help users detect phishing attacks. Because the toolbars are designed for humans to use, they should be evaluated for usability -- that is, whether these toolbars really prevent users from being tricked into providing personal information. We conducted two user studies of three security toolbars and other browser security indicators and found them all ineffective at preventing phishing attacks. Even though subjects were asked to pay attention to the toolbar, many failed to look at it; others disregarded or explained away the toolbars' warnings if the content of web pages looked legitimate. We found that many subjects do not understand phishing attacks or realize how sophisticated such attacks can be.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {601–610},
numpages = {10},
keywords = {user interface design, user study, world wide web and hypermedia, e-commerce},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124865,
author = {Nichols, Jeffrey and Myers, Brad A. and Rothrock, Brandon},
title = {UNIFORM: Automatically Generating Consistent Remote Control User Interfaces},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124865},
doi = {10.1145/1124772.1124865},
abstract = {A problem with many of today's appliance interfaces is that they are inconsistent. For example, the procedure for setting the time on alarm clocks and VCRs differs, even among different models made by the same manufacturer. Finding particular functions can also be a challenge, because appliances often organize their features differently. This paper presents a system, called Uniform, which approaches this problem by automatically generating remote control interfaces that take into account previous interfaces that the user has seen during the generation process. Uniform is able to automatically identify similarities between different devices and users may specify additional similarities. The similarity information allows the interface generator to use the same type of controls for similar functions, place similar functions so that they can be found with the same navigation steps, and create interfaces that have a similar visual appearance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {611–620},
numpages = {10},
keywords = {personal universal controller (PUC), familiarity, mobile phone, Pebbles, personal digital assistants, consistency, handheld computers, automatic interface generation},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124866,
author = {Eng, Katherine and Lewis, Richard L. and Tollinger, Irene and Chu, Alina and Howes, Andrew and Vera, Alonso},
title = {Generating Automated Predictions of Behavior Strategically Adapted to Specific Performance Objectives},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124866},
doi = {10.1145/1124772.1124866},
abstract = {It has been well established in Cognitive Psychology that humans are able to strategically adapt performance, even highly skilled performance, to meet explicit task goals such as being accurate (rather than fast). This paper describes a new capability for generating multiple human performance predictions from a single task specification as a function of different performance objective functions. As a demonstration of this capability, the Cognitive Constraint Modeling approach was used to develop models for several tasks across two interfaces from the aviation domain. Performance objectives are explicitly declared as part of the model, and the CORE (Constraint-based Optimal Reasoning Engine) architecture itself formally derives the detailed strategies that are maximally adapted to these objectives. The models are analyzed for emergent strategic variation, comparing those optimized for task time with those optimized for working memory load. The approach has potential application in user interface and procedure design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {621–630},
numpages = {10},
keywords = {interface evaluation, user modeling},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124867,
author = {West, Ryan and Lehman, Katherine},
title = {Automated Summative Usability Studies: An Empirical Evaluation},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124867},
doi = {10.1145/1124772.1124867},
abstract = {This paper evaluates a method for summative usability testing using an automated data collection system. We found automated summative testing to be a simple and effective alternative to lab-based summative testing and could be successfully conducted remotely. In our study, a web-based control window led participants through the summative study, provided tasks to perform, and asked follow up questions about the user experience. Using a within-group comparison, we found no major differences between data collected by a usability engineer and that collected through an automated testing system for performance metrics. Using a between-group comparison, we found automated summative studies could be conducted remotely with minor but acceptable differences in time on task and likelihood to give up on a task compared to lab-based testing. Task success and task satisfaction ratings were not different between remote and lab-based summative testing. Written comments provided by participants through the testing system were sufficient to identify the major usability problems that led to task failure but did not reveal as comprehensive a set of issues as did a usability engineer observing the sessions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {631–639},
numpages = {9},
keywords = {summative testing, remote testing, usability methods, empirical methods, automated testing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124869,
author = {Brewster, Stephen and McGookin, David and Miller, Christopher},
title = {Olfoto: Designing a Smell-Based Interaction},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124869},
doi = {10.1145/1124772.1124869},
abstract = {We present a study into the use of smell for searching digi-tal photo collections. Many people now have large photo libraries on their computers and effective search tools are needed. Smell has a strong link to memory and emotion so may be a good way to cue recall when searching. Our study compared text and smell based tagging. For the first stage we generated a set of smell and tag names from user de-scriptions of photos, participants then used these to tag pho-tos, returning two weeks later to answer questions on their photos. Results showed that participants could tag effec-tively with text labels, as this is a common and familiar task. Performance with smells was lower but participants performed significantly above chance, with some partici-pants using smells well. This suggests that smell has poten-tial. Results also showed that some smells were consistently identified and useful, but some were not and highlighted issues with smell delivery devices. We also discuss some practical issues of using smell for interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {653–662},
numpages = {10},
keywords = {digital photographs, olfaction, smell, searching, tagging},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124870,
author = {Brown, Barry and Barkhuus, Louise},
title = {The Television Will Be Revolutionized: Effects of PVRs and Filesharing on Television Watching},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124870},
doi = {10.1145/1124772.1124870},
abstract = {This paper investigates television-watching practices amongst early adopters of personal hard-disk video recorders (PVRs such as TiVotm) and Internet downloading of shows. Through in-depth interviews with early adopters, we describe how the rhythms of television watching change when decoupled from broadcast TV. For both the PVR users and downloaders TV watching has become less of a passive process, with viewers instead actively gathered shows from the schedules or online, and watching shows from their stored collection. From these results we discuss the 'video media lifecycle', and three new design concepts for supporting TV watching.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {663–666},
numpages = {4},
keywords = {TV watching, BitTorrent, ethnography, TiVo, file sharing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124871,
author = {Bentley, Frank and Metcalf, Crysta and Harboe, Gunnar},
title = {Personal vs. Commercial Content: The Similarities between Consumer Use of Photos and Music},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124871},
doi = {10.1145/1124772.1124871},
abstract = {We describe the results of two ethnographic-style studies that investigated consumer use of photos and music respectively. Although the studies were designed, executed, and analyzed separately, in our findings we discovered striking similarities between the ways in which our participants used personally captured photos and commercially purchased music. These findings have implications for the design of future systems with respect to handling and sharing content in photo or music form. We discuss making allowances for satisficing behavior, sharing media as a way to reminisce or to communicate an experience (tell a story), getting sidetracked while browsing, and similarities in organizing behaviors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {667–676},
numpages = {10},
keywords = {consumer, sharing, music, photo, ethnographic study},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124873,
author = {Park, Duck Gun and Kim, Jin Kyung and Sung, Jin Bong and Hwang, Jung Hwan and Hyung, Chang Hee and Kang, Sung Weon},
title = {TAP: Touch-and-Play},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124873},
doi = {10.1145/1124772.1124873},
abstract = {An intuitive context aware service between two devices is possible using touch with the intrabody communication. Using this technology, users with multimedia devices may simply touch them to establish network connection, transfer data, and provide the required service; hence the name Touch-And-Play (TAP). Using TAP, users can disclose their context by touching the specific device. For instance, a user carrying a digital camera touches the TV to begin a slide show or a printer to print a photo. TAP is expected to enable the provision of intuitive, context-aware service. This paper discusses the feasibility of TAP and its application in user interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {677–680},
numpages = {4},
keywords = {context aware service, tap, touch-and-play, intrabody communication},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124874,
author = {Raffle, Hayes and Parkes, Amanda and Ishii, Hiroshi and Lifton, Joshua},
title = {Beyond Record and Play: Backpacks: Tangible Modulators for Kinetic Behavior},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124874},
doi = {10.1145/1124772.1124874},
abstract = {Digital Manipulatives embed computation in familiar children's toys and provide means for children to design behavior. Some systems use "record and play" as a form of programming by demonstration that is intuitive and easy to learn. With others, children write symbolic programs with a GUI and download them into a toy, an approach that is conceptually extensible, but is inconsistent with the physicality of educational manipulatives. The challenge we address is to create a tangible interface that can retain the immediacy and emotional engagement of "record and play" and incorporate a mechanism for real time and direct modulation of behavior during program execution.We introduce the Backpacks, modular physical components that children can incorporate into robotic creations to modulate frequency, amplitude, phase and orientation of motion recordings. Using Backpacks, children can investigate basic kinematic principles that underly why their specific creations exhibit the specific behaviors they observe. We demonstrate that Backpacks make tangible some of the benefits of symbolic abstraction, and introduce sensors, feedback and behavior modulation to the record and play paradigm. Through our review of user studies with children ages 6-15, we argue that Backpacks extend the conceptual limits of record and play with an interface that is consistent with both the physicality of educational manipulatives and the local-global systems dynamics that are characteristic of complex robots.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {681–690},
numpages = {10},
keywords = {toy, tangible interface, learning, digital manipulative, programming by demonstration, education, children, modular robotics},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124875,
author = {Moher, Tom},
title = {Embedded Phenomena: Supporting Science Learning with Classroom-Sized Distributed Simulations},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124875},
doi = {10.1145/1124772.1124875},
abstract = { 'Embedded phenomena' is a learning technology framework in which simulated scientific phenomena are mapped onto the physical space of classrooms. Students monitor and control the local state of the simulation through distributed media positioned around the room, gathering and aggregating evidence to solve problems or answer questions related to those phenomena. Embedded phenomena are persistent, running continuously over weeks and months, creating information channels that are temporally and physically interleaved with, but asynchronous with respect to, the regular flow of instruction. In this paper, we describe the motivations for the framework, describe classroom experiences with three embedded phenomena in the domains of seismology, insect ecology, and astronomy, and situate embedded phenomena within the context of human-computer interaction research in co-located group interfaces and learning technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {691–700},
numpages = {10},
keywords = {classroom learning, embedded phenomena, science inquiry},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124877,
author = {Kamvar, Maryam and Baluja, Shumeet},
title = {A Large Scale Study of Wireless Search Behavior: Google Mobile Search},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124877},
doi = {10.1145/1124772.1124877},
abstract = {We present a large scale study of search patterns on Google's mobile search interface. Our goal is to understand the current state of wireless search by analyzing over 1 Million hits to Google's mobile search sites. Our study also includes the examination of search queries and the general categories under which they fall. We follow users throughout multiple interactions to determine search behavior; we estimate how long they spend inputting a query, viewing the search results, and how often they click on a search result. We also compare and contrast search patterns between 12-key keypad phones (cellphones), phones with QWERTY keyboards (PDAs) and conventional computers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {701–709},
numpages = {9},
keywords = {wireless, mobile device, search interface, cell phone},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124878,
author = {Karlson, Amy K. and Robertson, George G. and Robbins, Daniel C. and Czerwinski, Mary P. and Smith, Greg R.},
title = {FaThumb: A Facet-Based Interface for Mobile Search},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124878},
doi = {10.1145/1124772.1124878},
abstract = {In this paper we describe a novel approach for searching large data sets from a mobile phone. Existing interfaces for mobile search require keyword text entry and are not suited for browsing. Our alternative uses a hybrid model to de-emphasize tedious keyword entry in favor of iterative data filtering. We propose navigation and selection of hierarchical metadata (facet navigation), with incremental text entry to further narrow the results. We conducted a formative evaluation to understand the relative advantages of keyword entry versus facet navigation for both browse and search tasks on the phone. We found keyword entry to be more powerful when the name of the search target is known, while facet navigation is otherwise more effective and strongly preferred.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {711–720},
numpages = {10},
keywords = {zoomable user interfaces, Piccolo.NET, mobile devices, search interfaces, visual interaction, faceted metadata},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124879,
author = {Ranjan, Abhishek and Balakrishnan, Ravin and Chignell, Mark},
title = {Searching in Audio: The Utility of Transcripts, Dichotic Presentation, and Time-Compression},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124879},
doi = {10.1145/1124772.1124879},
abstract = {Searching audio data can potentially be facilitated by the use of automatic speech recognition (ASR) technology to generate text transcripts which can then be easily queried. However, since current ASR technology cannot reliably generate 100% accurate transcripts, additional techniques for fluid browsing and searching of the audio itself are required. We explore the impact of transcripts of various qualities, dichotic presentation, and time-compression on an audio search task. Results show that dichotic presentation and reasonably accurate transcripts can assist in the search process, but suggest that time-compression and low accuracy transcripts should be used carefully.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {721–730},
numpages = {10},
keywords = {dichotic listening, audio time-compression, transcripts},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124881,
author = {Avrahami, Daniel and Hudson, Scott E.},
title = {Responsiveness in Instant Messaging: Predictive Models Supporting Inter-Personal Communication},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124881},
doi = {10.1145/1124772.1124881},
abstract = {For the majority of us, inter-personal communication is an essential part of our daily lives. Instant Messaging, or IM, has been growing in popularity for personal and work-related communication. The low cost of sending a message, combined with the limited awareness provided by current IM systems result in messages often arriving at inconvenient or disruptive times. In a step towards solving this problem, we created statistical models that successfully predict responsiveness to incoming instant messages -- simply put: whether the receiver is likely to respond to a message within a certain time period. These models were constructed using a large corpus of real IM interaction collected from 16 participants, including over 90,000 messages. The models we present can predict, with accuracy as high as 90.1%, whether a message sent to begin a new session of communication would get a response within 30 seconds, 1, 2, 5, and 10 minutes. This type of prediction can be used, for example, to drive online-status indicators, or in services aimed at finding potential communicators.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {731–740},
numpages = {10},
keywords = {statistical models of human activity, responsiveness, awareness, interruptibility, availability},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124882,
author = {Iqbal, Shamsi T. and Bailey, Brian P.},
title = {Leveraging Characteristics of Task Structure to Predict the Cost of Interruption},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124882},
doi = {10.1145/1124772.1124882},
abstract = {A challenge in building interruption reasoning systems is to compute an accurate cost of interruption (COI). Prior work has used interface events and other cues to predict COI, but ignore characteristics related to the structure of a task. This work investigates how well characteristics of task structure can predict COI, as objectively measured by resumption lag. In an experiment, users were interrupted during task execution at various boundaries to collect a large sample of resumption lag values. Statistical methods were employed to create a parsimonious model that uses characteristics of task structure to predict COI. A subsequent experiment with different tasks showed that the model can predict COI with reasonably high accuracy. Our model can be expediently applied to many goal-directed tasks, allowing systems to make more effective decisions about when to interrupt.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {741–750},
numpages = {10},
keywords = {workload, interruption, learning, task models, attention},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124883,
author = {Faaborg, Alexander and Lieberman, Henry},
title = {A Goal-Oriented Web Browser},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124883},
doi = {10.1145/1124772.1124883},
abstract = {Many users are familiar with the interesting but limited functionality of Data Detector interfaces like Microsoft's Smart Tags and Google's AutoLink. In this paper we significantly expand the breadth and functionality of this type of user interface through the use of large-scale knowledge bases of semantic information. The result is a Web browser that is able to generate personalized semantic hypertext, providing a goal-oriented browsing experience.We present (1) Creo, a Programming by Example system for the Web that allows users to create a general-purpose procedure with a single example, and (2) Miro, a Data Detector that matches the content of a page to high-level user goals.An evaluation with 34 subjects found that they were more efficient using our system, and that the subjects would use features like these if they were integrated into their Web browser.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {751–760},
numpages = {10},
keywords = {TAP, software agents, programming by example, open mind, context aware computing, goal-oriented design, commonsense reasoning, data detectors, ConceptNet},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@dataset{10.1145/review-1124772.1124883_R40952,
author = {Obermeier, Klaus K.},
title = {Review ID:R40952 for DOI: 10.1145/1124772.1124883},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/review-1124772.1124883_R40952}
}

@inproceedings{10.1145/1124772.1124885,
author = {Kirk, David and Sellen, Abigail and Rother, Carsten and Wood, Ken},
title = {Understanding Photowork},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124885},
doi = {10.1145/1124772.1124885},
abstract = {In this paper we introduce the notion of "photowork" as the activities people perform with their digital photos after cap-ture but prior to end use such as sharing. Surprisingly, these processes of reviewing, downloading, organizing, editing, sorting and filing have received little attention in the litera-ture yet they form the context for a large amount of the 'search' and 'browse' activities so commonly referred to in studies of digital photo software. Through a deeper under-standing of photowork using field observation and inter-views, we seek to highlight its significance as an interaction practice. At the same time, we discover how "search" as it is usually defined may have much less relevance than new ways of browsing for the design of new digital photo tools, in particular, browsing in support of the photowork activi-ties we describe.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {761–770},
numpages = {10},
keywords = {photowork, browsing, use of images, digital photo albums, searching, content-based image retrieval},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124886,
author = {Santella, Anthony and Agrawala, Maneesh and DeCarlo, Doug and Salesin, David and Cohen, Michael},
title = {Gaze-Based Interaction for Semi-Automatic Photo Cropping},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124886},
doi = {10.1145/1124772.1124886},
abstract = {We present an interactive method for cropping photographs given minimal information about important content location, provided by eye tracking. Cropping is formulated in a general optimization framework that facilitates adding new composition rules, and adapting the system to particular applications. Our system uses fixation data<!-- to identify important image content and compute the best crop for any given aspect ratio or size, enabling applications such as automatic snapshot recomposition, adaptive documents, and thumbnailing. We validate our approach with studies in which users compare our crops to ones produced by hand and by a completely automatic approach. Experiments show that viewers prefer our gaze-based crops to uncropped images and fully automatic crops.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {771–780},
numpages = {10},
keywords = {visual perception, eye tracking, photography, composition, evaluation, cropping},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124887,
author = {Apted, Trent and Kay, Judy and Quigley, Aaron},
title = {Tabletop Sharing of Digital Photographs for the Elderly},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124887},
doi = {10.1145/1124772.1124887},
abstract = {We have recently begun to see hardware support for the tabletop user interface, offering a number of new ways for humans to interact with computers. Tabletops offer great potential for face-to-face social interaction; advances in touch technology and computer graphics provide natural ways to directly manipulate virtual objects, which we can display on the tabletop surface. Such an interface has the potential to benefit a wide range of the population and it is important that we design for usability and learnability with diverse groups of people.This paper describes the design of SharePic -- a multiuser, multi-touch, gestural, collaborative digital photograph sharing application for a tabletop -- and our evaluation with both young adult and elderly user groups. We describe the guidelines we have developed for the design of tabletop interfaces for a range of adult users, including elders, and the user interface we have built based on them. Novel aspects of the interface include a design strongly influenced by the metaphor of physical photographs placed on the table with interaction techniques designed to be easy to learn and easy to remember. In our evaluation, we gave users the final task of creating a digital postcard from a collage of photographs and performed a realistic think-aloud with pairs of novice participants learning together, from a tutorial script.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {781–790},
numpages = {10},
keywords = {gesture, touch, learnability, digital photograph, photograph sharing, elderly, tabletop interface},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124889,
author = {Adar, Eytan},
title = {GUESS: A Language and Interface for Graph Exploration},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124889},
doi = {10.1145/1124772.1124889},
abstract = {As graph models are applied to more widely varying fields, researchers struggle with tools for exploring and analyzing these structures. We describe GUESS, a novel system for graph exploration that combines an interpreted language with a graphical front end that allows researchers to rapidly prototype and deploy new visualizations. GUESS also contains a novel, interactive interpreter that connects the language and interface in a way that facilities exploratory visualization tasks. Our language, Gython, is a domain-specific embedded language which provides all the advantages of Python with new, graph specific operators, primitives, and shortcuts. We highlight key aspects of the system in the context of a large user survey and specific, real-world, case studies ranging from social and knowledge networks to distributed computer network analysis.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {791–800},
numpages = {10},
keywords = {domain-specific embedded language, graph layout, graph visualization},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124890,
author = {Wright, William and Schroh, David and Proulx, Pascale and Skaburskis, Alex and Cort, Brian},
title = {The Sandbox for Analysis: Concepts and Methods},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124890},
doi = {10.1145/1124772.1124890},
abstract = {The Sandbox is a flexible and expressive thinking environment that supports both ad-hoc and more formal analytical tasks. It is the evidence marshalling and sense-making component for the analytical software environment called nSpace. This paper presents innovative Sandbox human information interaction capabilities and the rationale underlying them including direct observations of analysis work as well as structured interviews. Key capabilities for the Sandbox include "put-this-there" cognition, automatic process model templates, gestures for the fluid expression of thought, assertions with evidence and scalability mechanisms to support larger analysis tasks. The Sandbox integrates advanced computational linguistic functions using a Web Services interface and protocol. An independent third party evaluation experiment with the Sandbox has been completed. The experiment showed that analyst subjects using the Sandbox did higher quality analysis in less time than with standard tools. Usability test results indicated the analysts became proficient in using the Sandbox with three hours of training.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {801–810},
numpages = {10},
keywords = {visual analytics, gestures, information visualization, sense making, user-centered design},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124891,
author = {Wattenberg, Martin},
title = {Visual Exploration of Multivariate Graphs},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124891},
doi = {10.1145/1124772.1124891},
abstract = {This paper introduces PivotGraph, a software tool that uses a new technique for visualizing and analyzing graph structures. The technique is designed specifically for graphs that are "multivariate," i.e., where each node is associated with several attributes. Unlike visualizations which emphasize global graph topology, PivotGraph uses a simple grid-based approach to focus on the relationship between node attributes and connections. The interaction technique is derived from an analogy with methods seen in spreadsheet pivot tables and in online analytical processing (OLAP). Finally, several examples are presented in which PivotGraph was applied to real-world data sets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {811–819},
numpages = {9},
keywords = {information visualization, social networks, graph drawing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124893,
author = {Hawkey, Kirstie and Inkpen, Kori M.},
title = {Keeping up Appearances: Understanding the Dimensions of Incidental Information Privacy},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124893},
doi = {10.1145/1124772.1124893},
abstract = {We conducted a survey of 155 participants to examine privacy concerns relating to the viewing of incidental information (i.e. traces of previous activity unrelated to the task at hand) in web browsers. We have identified several dimensions of privacy for this domain. Results revealed the scope of this problem and how location and device affect web browsing activity and contribute to the types of incidental information that may be visible. We found that there are different privacy comfort levels inherent to the participant and dependent on the context of subsequent viewing of incidental information, including the sensitivity of the content, their relationship to the viewer and the level of control retained over input devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {821–830},
numpages = {10},
keywords = {web browsing, incidental information, survey, privacy, collaboration},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124894,
author = {Robles, Erica and Sukumaran, Abhay and Rickertsen, Kathryn and Nass, Cliff},
title = {Being Watched or Being Special: How I Learned to Stop Worrying and Love Being Monitored, Surveilled, and Assessed},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124894},
doi = {10.1145/1124772.1124894},
abstract = {This paper explores the relationship between display of feedback (public vs. private) and the basis for evaluation (present vs. absent) of that feedback. Using a controlled, laboratory setting, we employ a fundamentally social, interpersonal context (speed-dating). Two participants (one male and one female) receive real-time performance feedback about either only themselves (private) or about both participants (public). We measure participant perceptions of monitoring, conformity, and self-consciousness about themselves and their dating partner. We also assess perceptions of system invasiveness, system competence, and system support. Results reveal a consistent pattern of significant interaction between feedback display and basis for evaluation conditions. In each of these interactions, public feedback with an added, trivial, basis for evaluation creates significantly lower perception of monitoring, conformity, self-consciousness, and system invasiveness, than the other three conditions. Additionally there is a main effect for basis for evaluation with respect to system competence and supportiveness. In each case, the presence of a basis produces more positive assessments than its absence. The experiment shows that reactions to being monitored and evaluated do not differ strictly along the dimension of public vs. private; basis for evaluation of feedback functions as a mediator and thus co-determines participant attitudinal responses. We discuss the implications of this at several levels, and present a broader cultural explanation in terms of the theory of rationalization. We also discuss the issues around and functionality of linking laboratory settings to larger cultural contexts in this and related fields of inquiry.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {831–839},
numpages = {9},
keywords = {evaluation, shared experience, feedback, ubiquitous computing, computer-mediated communication, public, private},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124896,
author = {Hamzah, Muhd Dzulkhiflee and Tano, Shun'ichi and Iwata, Mitsuru and Hashiyama, Tomonori},
title = {Effectiveness of Annotating by Hand for Non-Alphabetical Languages},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124896},
doi = {10.1145/1124772.1124896},
abstract = {Unlike documents, annotation for multimedia information needs to be input as text, not in the form of symbols such as underlines and circles. This is problematic with keyboard input for non-alphabetical languages, especially the East Asian languages such as Chinese and Japanese, because it is labor intensive and imposes a high cognitive load. This study provides a quantitative analysis of the effectiveness of making annotations by hand during a note-taking task in Japanese. Although the lessons learned from this study come from Japanese text input, they are also generally applicable to other East Asian Languages which use ideographic characters such as Chinese. In our study, we focused on both the ergonomic and cognitive aspects and found that during annotation and note-taking task input by hand is more effective than input by keyboard. Finally, we anatomized the keyboard input problem and discuss it in this paper.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {841–850},
numpages = {10},
keywords = {input speed, non-alphabetical languages, handwritten annotation, keyboard input, cognitive load},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124897,
author = {Kurihara, Kazutaka and Goto, Masataka and Ogata, Jun and Igarashi, Takeo},
title = {Speech Pen: Predictive Handwriting Based on Ambient Multimodal Recognition},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124897},
doi = {10.1145/1124772.1124897},
abstract = {It is tedious to handwrite long passages of text by hand. To make this process more efficient, we propose predictive handwriting that provides input predictions when the user writes by hand. A predictive handwriting system presents possible next words as a list and allows the user to select one to skip manual writing. Since it is not clear if people are willing to use prediction, we first run a user study to compare handwriting and selecting from the list. The result shows that, in Japanese, people prefer to select, especially when the expected performance gain from using selection is large. Based on these observations, we designed a multimodal input system, called speech-pen, that assists digital writing during lectures or presentations with background speech and handwriting recognition. The system recognizes speech and handwriting in the background and provides the instructor with predictions for further writing. The speech-pen system also allows the sharing of context information for predictions among the instructor and the audience; the result of the instructor's speech recognition is sent to the audience to support their own note-taking. Our preliminary study shows the effectiveness of this system and the implications for further improvements.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {851–860},
numpages = {10},
keywords = {presentation tool, predictive handwriting, education, context-sharing, speech recognition, multimodal interface, handwriting recognition},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124898,
author = {Grossman, Tovi and Hinckley, Ken and Baudisch, Patrick and Agrawala, Maneesh and Balakrishnan, Ravin},
title = {Hover Widgets: Using the Tracking State to Extend the Capabilities of Pen-Operated Devices},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124898},
doi = {10.1145/1124772.1124898},
abstract = {We present Hover Widgets, a new technique for increasing the capabilities of pen-based interfaces. Hover Widgets are implemented by using the pen movements above the display surface, in the tracking state. Short gestures while hovering, followed by a pen down, access the Hover Widgets, which can be used to activate localized interface widgets. By using the tracking state movements, Hover Widgets create a new command layer which is clearly distinct from the input layer of a pen interface. In a formal experiment Hover Widgets were found to be faster than a more traditional command activation technique, and also reduced errors due to divided attention.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {861–870},
numpages = {10},
keywords = {gestures, hover widgets, pen input, tablets},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124900,
author = {O'Hara, Kenton and Black, Alison and Lipson, Matthew},
title = {Everyday Practices with Mobile Video Telephony},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124900},
doi = {10.1145/1124772.1124900},
abstract = {The mobile phone allowed people to communicate when and where they wanted, dramatically changing how audio telephony was integrated into daily life. With video telephony services now available on everyday mobile phones, comparable arguments are being made that this will change how people relate to and use video telephony. The mobile and personal natures of mobile phones remove factors that previously hindered use of video telephony. Mobility also brings new challenges and concerns that may hinder use of video telephony in particular contexts. With this in mind, the paper revisits the notion of video telephony but within the context of mobile phones. A study is presented of people's everyday use of mobile video telephony using diary techniques and ethnographic interviews. The study uses real episodes to highlight key motivations and circumstances under which mobile video telephony was and wasn't used. Implications for adoption of design of mobile video phones are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {871–880},
numpages = {10},
keywords = {diary study, interviews, video telephony, mobility, mobile phone, privacy, video mediated communication},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124901,
author = {Paulos, Eric and Beckmann, Chris},
title = {Sashay: Designing for Wonderment},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124901},
doi = {10.1145/1124772.1124901},
abstract = {No longer confined to our offices, schools, and homes, technology is expanding at an astonishing rate across our everyday public urban landscapes. From the visible (mobile phones, laptops, and blackberries) to the invisible (GPS, WiFi, GSM, and EVDO), we find the full spectrum of digital technologies transforming nearly every facet of our urban experience. Many current urban computing systems focus on improving our efficiency and productivity in the city by providing "location services" and/or interactive navigation and mapping tools. While agreeing with the need for such systems, we are reminded that urban life spans a much wider range of emotions and experiences. Our claim is that our successful future urban technological tools will be those that incorporate the full range of urban experiences -- from improving productivity and efficiency to promoting wonderment and daydreaming. We discuss intervention as a research strategy for understanding wonderment; demonstrate an example of such a study using a matchbook experiment to expose relationships between locations and emotions within a city; and use the results to develop Sashay -- a mobile phone application that promotes wonderment by visualizing an individual's personal patterns across the invisible, manufactured geography of mobile phone cellular towers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {881–884},
numpages = {4},
keywords = {d\'{e}tournement, locative, mapping, d\'{e}rive, urban computing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124902,
author = {Liu, Christine M. and Donath, Judith S.},
title = {Urbanhermes: Social Signaling with Electronic Fashion},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124902},
doi = {10.1145/1124772.1124902},
abstract = {Humans use fashion signals to indicate access to information. While fashion is typically associated with clothing, fashion also transpires within the domain of electronic media: weblogs, discussion lists, and online communities teem continuously with fresh, digestible content. A fashionable status - well-informed and well-connected - is demonstrated through a consistent, timely, and meaningful display of newly acquired information. While production constraints of material-based fashions limit the signal refresh rate, ephemeral electronic fashions can cycle as quickly as the flow of information. The challenge we present is to develop physical objects that can go beyond the limitations of their materiality, and to signal with the rapidity of electronic fashions. We introduce the design of urbanhermes as a communicative accessory that integrates the fresh, dynamic, fluid nature of electronic-based fashion signals within the tactile, face-to-face environment of a physical space. This paper presents the design discussion within the framework of fashion as a social signal.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {885–888},
numpages = {4},
keywords = {fashion, accessories, urban space, clothing, signaling theory, wearables, identity and expression, social signals, mobile devices},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124903,
author = {Ludford, Pamela J. and Frankowski, Dan and Reily, Ken and Wilms, Kurt and Terveen, Loren},
title = {Because I Carry My Cell Phone Anyway: Functional Location-Based Reminder Applications},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124903},
doi = {10.1145/1124772.1124903},
abstract = {Although they have potential, to date location-based information systems have not radically improved the way we interact with our surroundings. To study related issues, we developed a location-based reminder system, PlaceMail, and demonstrate its utility in supporting everyday tasks through a month-long field study. We identify current tools and practices people use to manage distributed tasks and note problems with current methods, including the common "to-do list". Our field study shows that PlaceMail supports useful location-based reminders and functional place-based lists. The study also sheds rich and surprising light on a new issue: when and where to deliver location-based information. The traditional 'geofence' radius around a place proves insufficient. Instead, effective delivery depends on people's movement patterns through an area and the geographic layout of the space. Our results both provide a compelling demonstration of the utility of location-based information and raise significant new challenges for location-based information distribution.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {889–898},
numpages = {10},
keywords = {ubiquitous computing, cell phone, personal information management (PIM), location-based reminder, mobile computing, everyday task, place, location-based information delivery, mobile device},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124905,
author = {Dey, Anind K. and de Guzman, Ed},
title = {From Awareness to Connectedness: The Design and Deployment of Presence Displays},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124905},
doi = {10.1145/1124772.1124905},
abstract = {Computer displays can be helpful for making users aware of the remote presence of friends and family. In many of the research projects that have explored the use of novel displays, the real goal is to improve a user's sense of connectedness to those remote loved ones. However, very few have leveraged a user-centered design process or empirically studied the effects of using a display on users' sense of awareness and connectedness. In this paper, we present our multi-phase, user-centered design process for building displays that support awareness and connectedness: Presence Displays, which are physical, peripheral awareness displays of online presence of close friends or family. We present evidence, from a 5-week long field study, that these displays provide significantly better awareness of and connectedness to a loved one, than a traditional graphical display of online presence.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {899–908},
numpages = {10},
keywords = {connectedness, field study, design process, peripheral display, awareness},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124906,
author = {Howard, Steve and Kjeldskov, Jesper and Skov, Mikael B. and Garn\ae{}s, Kasper and Gr\"{u}nberger, Olga},
title = {Negotiating Presence-in-Absence: Contact, Content and Context},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124906},
doi = {10.1145/1124772.1124906},
abstract = {On the basis of a longitudinal field study of domestic communication, we report some essential constituents of the user experience of awareness of others who are distant in space or time, i.e. presence-in-absence. We discuss presence-in-absence in terms of its social (Contact) and informational (Content) facets, and the circumstances of the experience (Context). The field evaluation of a prototype, 'The Cube', designed to support presence-in-absence, threw up issues in the interrelationships between contact, content and context; issues that the designers of similar social artifacts will need to address.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {909–912},
numpages = {4},
keywords = {asynchronous, presence-in-absence, intimacy},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124907,
author = {Kramer, Adam D. I. and Oh, Lui Min and Fussell, Susan R.},
title = {Using Linguistic Features to Measure Presence in Computer-Mediated Communication},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124907},
doi = {10.1145/1124772.1124907},
abstract = {We propose a method of measuring people's sense of presence in computer-mediated communication (CMC) systems) based on linguistic features of their dialogues. We create variations in presence by asking participants to collaborate on physical tasks in four CMC conditions. We then correlate self-reported feelings of presence with the use of specific linguistic features. Regression analyses show that 30% of the variance in self-reported presence can be accounted for by a small number of task-independent linguistic features. Even better prediction can be obtained when self-reported coordination is added to the regression equation. We conclude that linguistic measures of presence have value for studies of CMC.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {913–916},
numpages = {4},
keywords = {telepresence, computer-mediated communication, discourse analysis, experimentation, presence, CMC},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124908,
author = {van Nimwegen, Christof C. and Burgos, Daniel D. and van Oostendorp, Herre H. and Schijf, Hermina H. J. M.},
title = {The Paradox of the Assisted User: Guidance Can Be Counterproductive},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124908},
doi = {10.1145/1124772.1124908},
abstract = {This paper investigates the influence of interface styles on problem solving performance. It is often assumed that performance on problem solving tasks improves when users are assisted by externalizing task-related information on the interface. Although externalization requires less recall and relieves working memory, it does not instigate planning, understanding and knowledge acquisition. Without this assistance, task-information must be internalized, stored in the user's memory, leading to more planning and thinking and perhaps to better performance and knowledge. Another variable that can influence behavior is "Need for Cognition" (NFC), the tendency to engage in effortful cognitive tasks. We investigated the effects of interface style and cognitive style on performance using a conference planning application. Interface style influenced behavior and performance, but NFC did not. The internalization interface led to more planful behavior and smarter solutions. When planning and learning are the aim, designers should thus beware of giving a user (too) much assistance. Understanding how people react to interface information can be crucial in designing effective software, especially important in the areas of education and learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {917–926},
numpages = {10},
keywords = {interaction styles, planning, interface design, display-based, externalization, need for cognition, information interfaces and presentation, problem solving, plan-based},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124910,
author = {Mamykina, Lena and Mynatt, Elizabeth D. and Kaufman, David R.},
title = {Investigating Health Management Practices of Individuals with Diabetes},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124910},
doi = {10.1145/1124772.1124910},
abstract = {Chronic diseases, endemic in the rapidly aging population, are stretching the capacity of healthcare resources. Increasingly, individuals need to adopt proactive health attitudes and contribute to the management of their own health. We investigate existing diabetes self-management practices and ways in which reflection on prior actions impacts future lifestyle choices. The findings suggest that individuals generate and evaluate hypotheses regarding health implications of their actions. Thus, health-monitoring applications can assist individuals in making educated choices by facilitating discovery of correlations between their past actions and health states. Deployment of an early prototype of a health-monitoring application demonstrated the need for careful presentation techniques to promote more robust understanding and to avoid reinforcement of biases.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {927–936},
numpages = {10},
keywords = {healthcare, technology probes, home, monitoring, qualitative studies, elderly},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124911,
author = {Hayes, Gillian R. and Abowd, Gregory D.},
title = {Tensions in Designing Capture Technologies for an Evidence-Based Care Community},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124911},
doi = {10.1145/1124772.1124911},
abstract = {Evidence-based care is an increasingly popular process for long term diagnosis and monitoring of education and healthcare disabilities. Because this evidence must also be collected in everyday life, it is a technique that can greatly benefit from automated capture technologies. These solutions, however, can raise significant concerns about privacy, control, and surveillance. In this paper, we present an analysis of these concerns with regard to evidence-based care. This analysis underscores the need to consider community-based risk and reward analyses in addition to the traditionally used analyses for individual users when designing socially appropriate technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {937–946},
numpages = {10},
keywords = {ubicomp, ethnography, capture and access, privacy, evidence-based care},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124912,
author = {Siek, Katie A. and Connelly, Kay H. and Rogers, Yvonne},
title = {Pride and Prejudice: Learning How Chronically Ill People Think about Food},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124912},
doi = {10.1145/1124772.1124912},
abstract = {In this paper, we describe a formative study to learn how one chronically ill population thinks about food, mentally organizes food, and interprets consumption-level icons. We found that many participants let their pride influence their choices, resulting in preferred interfaces that they could not accurately interpret. The results indicate that participants organized food in similar ways, had difficulty reading from their preferred consumption-level icons, and wanted to combine multiple interface designs when searching for food.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {947–950},
numpages = {4},
keywords = {paper prototyping, health care, chronically ill, nutrition},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124914,
author = {Drenner, Sara and Harper, Max and Frankowski, Dan and Riedl, John and Terveen, Loren},
title = {Insert Movie Reference Here: A System to Bridge Conversation and Item-Oriented Web Sites},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124914},
doi = {10.1145/1124772.1124914},
abstract = {Item-oriented Web sites maintain repositories of information about things such as books, games, or products. Many of these Web sites offer discussion forums. However, these forums are often disconnected from the rich data available in the item repositories. We describe a system, movie linking, that bridges a movie recommendation Web site and a movie-oriented discussion forum. Through automatic detection and an interactive component, the system recognizes references to movies in the forum and adds recommendation data to the forums and conversation threads to movie pages. An eight week observational study shows that the system was able to identify movie references with precision of .93 and recall of .78. Though users reported that the feature was useful, their behavior indicates that the feature was more successful at enriching the interface than at integrating the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {951–954},
numpages = {4},
keywords = {user interface, online asynchronous discussion, recommender system},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124915,
author = {Rashid, Al M. and Ling, Kimberly and Tassone, Regina D. and Resnick, Paul and Kraut, Robert and Riedl, John},
title = {Motivating Participation by Displaying the Value of Contribution},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124915},
doi = {10.1145/1124772.1124915},
abstract = {One of the important challenges faced by designers of online communities is eliciting sufficent contributions from community members. Users in online communities may have difficulty either in finding opportunities to add value, or in understanding the value of their contributions to the community. Various social science theories suggest that showing users different perspectives on the value they add to the community will lead to differing amounts of contribution. The present study investigates a design augmentation for an existing community Web site that could benefit from additional contribution. The augmented interface includes individualized opportunities for contribution and an estimate of the value of each contribution to the community. The value is computed in one of four different ways: (1) value to self; (2) value to a small group the user has affinity with; (3) value to a small group the user does not have affinity with; and (4) value to the entire user community. The study compares the effectiveness of the different notions of value to 160 community members.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {955–958},
numpages = {4},
keywords = {identity, under-contribution, value of contributions, motivation, recommender systems},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124916,
author = {Arguello, Jaime and Butler, Brian S. and Joyce, Elisabeth and Kraut, Robert and Ling, Kimberly S. and Ros\'{e}, Carolyn and Wang, Xiaoqing},
title = {Talk to Me: Foundations for Successful Individual-Group Interactions in Online Communities},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124916},
doi = {10.1145/1124772.1124916},
abstract = {People come to online communities seeking information, encouragement, and conversation. When a community responds, participants benefit and become more committed. Yet interactions often fail. In a longitudinal sample of 6,172 messages from 8 Usenet newsgroups, 27% of posts received no response. The information context, posters' prior engagement in the community, and the content of their posts all influenced the likelihood that they received a reply, and, as a result, their willingness to continue active participation. Posters were less likely to get a reply if they were newcomers. Posting ontopic, introducing oneself via autobiographical testimonials, asking questions, using less complex language and other features of the messages, increased replies. Results suggest ways that developers might increase the ability of online communities to support successful individual-group interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {959–968},
numpages = {10},
keywords = {text analysis, responsiveness, online communities, language, contribution, community success, commitment},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124917,
author = {Shklovski, Irina and Kraut, Robert and Cummings, Jonathon},
title = {Routine Patterns of Internet Use &amp; Psychological Well-Being: Coping with a Residential Move},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124917},
doi = {10.1145/1124772.1124917},
abstract = {In this paper we examine how routine uses of the Internet for communication with family and friends and for entertainment may serve as indicators of overall levels of psychological well-being. Changes in psychological well-being in response to a major life event, such as a residential move, can drive changes in routine uses of the Internet, suggesting Internet-based coping strategies. Specifically, women who report high levels of depressive affect, decrease internet use for communication. Men with similar levels of depressive affect increase internet use for entertainment. We discuss implications of these findings for our understanding of the role of the Internet in everyday behavior and instances of coping with stressful situations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {969–978},
numpages = {10},
keywords = {loneliness, depressive affect, residential mobility, gender, stress, internet use},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124919,
author = {Vi\'{e}gas, Fernanda B. and Golder, Scott and Donath, Judith},
title = {Visualizing Email Content: Portraying Relationships from Conversational Histories},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124919},
doi = {10.1145/1124772.1124919},
abstract = {We present Themail, a visualization that portrays relationships using the interaction histories preserved in email archives. Using the content of exchanged messages, it shows the words that characterize one's correspondence with an individual and how they change over the period of the relationship.This paper describes the interface and content-parsing algorithms in Themail. It also presents the results from a user study where two main interaction modes with the visualization emerged: exploration of "big picture" trends and themes in email (haystack mode) and more detail-oriented exploration (needle mode). Finally, the paper discusses the limitations of the content parsing approach in Themail and the implications for further research on email content visualization.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {979–988},
numpages = {10},
keywords = {content, email archive, history, information interface, user interface, visualization},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124920,
author = {Matthews, Tara and Czerwinski, Mary and Robertson, George and Tan, Desney},
title = {Clipping Lists and Change Borders: Improving Multitasking Efficiency with Peripheral Information Design},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124920},
doi = {10.1145/1124772.1124920},
abstract = {Information workers often have to balance many tasks and interruptions. In this work, we explore peripheral display techniques that improve multitasking efficiency by helping users maintain task flow, know when to resume tasks, and more easily reacquire tasks. Specifically, we compare two types of abstraction that provide different task information: semantic content extraction, which displays only the most relevant content in a window, and change detection, which signals when a change has occurred in a window (all de-signed as modifications to Scalable Fabric [17]). Results from our user study suggest that semantic content extraction improves multitasking performance more so than either change detection or our base case of scaling. Results also show that semantic content extraction provides significant benefits to task flow, resumption timing, and reacquisition. We discuss the implication of these findings on the design of peripheral interfaces that support multitasking.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {989–998},
numpages = {10},
keywords = {peripheral displays, multitasking, abstraction, information visualization},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124921,
author = {Furnas, George W.},
title = {A Fisheye Follow-up: Further Reflections on Focus + Context},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124921},
doi = {10.1145/1124772.1124921},
abstract = {Information worlds continue to grow, posing daunting challenges for interfaces. This paper tries to increase our understanding of approaches to the problem, building on the Generalized Fisheye View framework. Three issues are discussed. First a number of existing techniques are unified by the commonality of what they show, certain fisheye-related subsets, with the techniques differing only in how they show those subsets. Then the elevated importance of these subsets, and their generality, is used to discuss the possibility of non-visual fisheye-views, to attack problems not so amenable to visualization. Finally, several models are given for why these subsets might be important in user interactions, with the goal of better informing design rationales.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {999–1008},
numpages = {10},
keywords = {view+overview, bifocal lens, information visualization, generalized fisheye views, ZUI, DOI, zoom, focus+context},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124923,
author = {Iachello, Giovanni and Truong, Khai N. and Abowd, Gregory D. and Hayes, Gillian R. and Stevens, Molly},
title = {Prototyping and Sampling Experience to Evaluate Ubiquitous Computing Privacy in the Real World},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124923},
doi = {10.1145/1124772.1124923},
abstract = {We developed an inquiry technique, which we called "paratype," based on experience prototyping and event-contingent experience sampling, to survey people in real-life situations about ubiquitous computing (ubicomp) technology. We used this tool to probe the opinions of the conversation partners of users of the Personal Audio Loop, a memory aid that can have a strong impact on their privacy. We present the findings of this study and their implications, specifically the need to broaden public awareness of ubicomp applications and the unfitness of traditional data protection guidelines for tackling the privacy issues of many ubicomp applications. We also point out benefits and methodological issues of paratypes and discuss why they are particularly fit for studying certain classes of mobile and ubicomp applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1009–1018},
numpages = {10},
keywords = {mobile computing, privacy, experience sampling, user centered design, paratype, ubiquitous computing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124924,
author = {Li, Yang and Welbourne, Evan and Landay, James A.},
title = {Design and Experimental Analysis of Continuous Location Tracking Techniques for Wizard of Oz Testing},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124924},
doi = {10.1145/1124772.1124924},
abstract = {Wizard of Oz (WOz) testing has shown promise as an effective way to test location-enhanced applications. However, it is challenging to conduct a location-based WOz test because of the dynamic nature of target settings in the field. In particular, continuous location tracking, a major task in such a test, requires a wizard to frequently update a user's location to simulate a location system. This imposes a heavy task load on a wizard. To ease wizards' tasks for location tracking, we designed two techniques, Directional Crossing and Steering, and conducted a field experiment to investigate the performance of the two techniques. A quantitative analysis shows that Directional Crossing and Steering significantly lowered a wizard's task load for location tracking without sacrificing accuracy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1019–1022},
numpages = {4},
keywords = {location-enhanced application, field study, Wizard of Oz},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124925,
author = {Hazlett, Richard L.},
title = {Measuring Emotional Valence during Interactive Experiences: Boys at Video Game Play},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124925},
doi = {10.1145/1124772.1124925},
abstract = {This paper describes the use of facial electromyography (EMG) as a measure of positive and negative emotional valence during interactive experience. Thirteen boys played a car racing video game on an Xbox platform while facial EMG data were collected. Through video review positive and negative events during play were identified. The zygomaticus muscle EMG, which controls smiling, was found to be significantly greater during positive events as compared to negative. The corrugator muscle EMG, which controls frowning, was found to be significantly greater during negative events. The results of this study demonstrate that positive valence can be measured during interactive experiences with physiologic measures. This study also found that the corrugator EMG can still measure negative valence during high intensity interactive play in spite of the confounding factor of mental effort. These methods appear useful for associating the player's emotion with game events, and could be applied to HCI in general.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1023–1026},
numpages = {4},
keywords = {affect, physiological measurements, testing children, evaluation methods, games},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124926,
author = {Mandryk, Regan L. and Atkins, M. Stella and Inkpen, Kori M.},
title = {A Continuous and Objective Evaluation of Emotional Experience with Interactive Play Environments},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124926},
doi = {10.1145/1124772.1124926},
abstract = {Researchers are using emerging technologies to develop novel play environments, while established computer and console game markets continue to grow rapidly. Even so, evaluating the success of interactive play environments is still an open research challenge. Both subjective and objective techniques fall short due to limited evaluative bandwidth; there remains no corollary in play environments to task performance with productivity systems. This paper presents a method of modeling user emotional state, based on a user's physiology, for users interacting with play technologies. Modeled emotions are powerful because they capture usability and playability through metrics relevant to ludic experience; account for user emotion; are quantitative and objective; and are represented continuously over a session. Furthermore, our modeled emotions show the same trends as reported emotions for fun, boredom, and excitement; however, the modeled emotions revealed differences between three play conditions, while the differences between the subjective reports failed to reach significance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1027–1036},
numpages = {10},
keywords = {GSR, fuzzy logic, emotion, physiology, EMG, games, HR, fun, evaluation methodology, play},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124928,
author = {Cosley, Dan and Frankowski, Dan and Terveen, Loren and Riedl, John},
title = {Using Intelligent Task Routing and Contribution Review to Help Communities Build Artifacts of Lasting Value},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124928},
doi = {10.1145/1124772.1124928},
abstract = {Many online communities are emerging that, like Wikipedia, bring people together to build community-maintained artifacts of lasting value (CALVs). Motivating people to contribute is a key problem because the quantity and quality of contributions ultimately determine a CALV's value. We pose two related research questions: 1) How does intelligent task routing---matching people with work---affect the quantity of contributions? 2) How does reviewing contributions before accepting them affect the quality of contributions? A field experiment with 197 contributors shows that simple, intelligent task routing algorithms have large effects. We also model the effect of reviewing contributions on the value of CALVs. The model predicts, and experimental data shows, that value grows more slowly with review before acceptance. It also predicts, surprisingly, that a CALV will reach the same final value whether contributions are reviewed before or after they are made available to the community.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1037–1046},
numpages = {10},
keywords = {member-maintained, online communities, contribution models, Wikipedia, intelligent task routing, editorial review},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124929,
author = {Brzozowski, Mike and Carattini, Kendra and Klemmer, Scott R. and Mihelich, Patrick and Hu, Jiang and Ng, Andrew Y.},
title = {GroupTime: Preference Based Group Scheduling},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124929},
doi = {10.1145/1124772.1124929},
abstract = {As our business, academic, and personal lives continue to move at an ever-faster pace, finding times for busy people to meet has become an art. One of the most perplexing challenges facing groupware is effective asynchronous group scheduling (GS). This paper presents a lightweight interaction model for GS that can extend its reach beyond users of current group calendaring solutions. By expressing availability in terms of preferences, we create a flexible framework for GS that preserves plausible deniability while exerting social pressure to encourage honesty among users. We also propose an ontology that enables us to model user preferences with machine learning, predicting user responses to further lower cognitive load. The combination of visualization/direct manipulation with machine learning allows users to easily and efficiently optimize meeting times. We also suggest resulting design implications for this class of intelligent user interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1047–1056},
numpages = {10},
keywords = {group calendaring, machine learning, group scheduling, intelligent user interfaces, supervised learning},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124930,
author = {Bonhard, Philip and Harries, Clare and McCarthy, John and Sasse, M. Angela},
title = {Accounting for Taste: Using Profile Similarity to Improve Recommender Systems},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124930},
doi = {10.1145/1124772.1124930},
abstract = {Recommender systems have been developed to address the abundance of choice we face in taste domains (films, music, restaurants) when shopping or going out. However, consumers currently struggle to evaluate the appropriateness of recommendations offered. With collaborative filtering, recommendations are based on people's ratings of items. In this paper, we propose that the usefulness of recommender systems can be improved by including more information about recommenders. We conducted a laboratory online experiment with 100 participants simulating a movie recommender system to determine how familiarity of the recommender, profile similarity between decision-maker and recommender, and rating overlap with a particular recommender influence the choices of decision-makers in such a context. While familiarity in this experiment did not affect the participants' choices, profile similarity and rating overlap had a significant influence. These results help us understand the decision-making processes in an online context and form the basis for user-centered social recommender system design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1057–1066},
numpages = {10},
keywords = {social networking, decision-making, recommender systems, social recommender systems, online advice-seeking},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124932,
author = {Ahlstroem, David and Alexandrowicz, Rainer and Hitz, Martin},
title = {Improving Menu Interaction: A Comparison of Standard, Force Enhanced and Jumping Menus},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124932},
doi = {10.1145/1124772.1124932},
abstract = {In this paper we show how a model centered analysis of the usage of the mouse click interaction action in graphical user interfaces can be used to create a new menu system. The analysis identifies a possible new usage of the click action in cascading pull-down menus which can make it easier for the user during menu navigation and selection. A new menu system which is easy to implement, the ""Jumping Menu"", is introduced. The new menu system warps the screen cursor to the right into open sub-menu levels when a mouse click is detected inside a parent item. The Jumping Menu was compared with standard pull-down menus and force enhanced menus in a user experiment. The results show that the Jumping Menu and a force enhanced menu can facilitate menu interaction and that they are promising alternatives to conventional menu systems. Based on the results, a prediction model for selection times in Jumping Menus is developed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1067–1076},
numpages = {10},
keywords = {interaction models, menu navigation, cascading pull-down menus, selection tasks, "force fields", menu enhancement, prediction models},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124933,
author = {Zhao, Shengdong and Agrawala, Maneesh and Hinckley, Ken},
title = {Zone and Polygon Menus: Using Relative Position to Increase the Breadth of Multi-Stroke Marking Menus},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124933},
doi = {10.1145/1124772.1124933},
abstract = {We present Zone and Polygon menus, two new variants of multi-stroke marking menus that consider both the relative position and orientation of strokes. Our menus are designed to increase menu breadth over the 8 item limit of status quo orientation-based marking menus. An experiment shows that Zone and Polygon menus can successfully increase breadth by a factor of 2 or more over orientation-based marking menus, while maintaining high selection speed and accuracy. We also discuss hybrid techniques that may further increase menu breadth and performance. Our techniques offer UI designers new options for balancing menu breadth and depth against selection speed and accuracy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1077–1086},
numpages = {10},
keywords = {pen-based interfaces, position-based menus, marking menus, pie menus},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124934,
author = {Pastel, Robert},
title = {Measuring the Difficulty of Steering through Corners},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124934},
doi = {10.1145/1124772.1124934},
abstract = {The steering law is intended to predict the performance of cursor manipulations in user interfaces, but the law has been verified for only a few path shapes and should be verified for more if it is to be generalized. This study extends the steering law to paths with corners. Two experiments compare the movement times of negotiating paths with corners to straight paths with the same width and movement amplitude. The experimental results show a significant effect on the movement times due to the corners, extending far into the legs of the path's corner. Modeling the results using resource theory, a cognitive theory for divided attention, suggests that steering through corners is two simultaneous tasks: steering along the legs of the corner and aiming at the corner.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1087–1096},
numpages = {10},
keywords = {gesturing, steering law, menu navigation, Fitts' law},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124936,
author = {Wang, Shuo and Xiong, Xiaocao and Xu, Yan and Wang, Chao and Zhang, Weiwei and Dai, Xiaofeng and Zhang, Dongmei},
title = {Face-Tracking as an Augmented Input in Video Games: Enhancing Presence, Role-Playing and Control},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124936},
doi = {10.1145/1124772.1124936},
abstract = {Motion-detection only games have inherent limitations on game experience in that the systems cannot identify the player's existence and identity. A way of improvement is by introducing information such as a player's face or head into the system. We designed and implemented two game prototypes that apply real-time face position information as intrinsic elements of gameplay to enhance game experience. The first prototype augmented a typical motion-detection-based game. Face information was designed to enhance the sense of presence and role-playing. In the second prototype, face tracking is applied as a new axis of control in a First Person Shooter (FPS) game.Although Face detection and tracking technology has started utilizing in game scenarios, there was little systematic research on how user experience is leveraged by applying face information to video games. The results of our user tests on comparing camera-based video games with and without face tracking demonstrated that using face position information can effectively enhance presence and role-playing. In addition, an intuitive control that augmented by face-tracking in the FPS game also got positive feedbacks from the test.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1097–1106},
numpages = {10},
keywords = {first person shooter (FPS), role-playing, camera-based games, motion detection, game control, face tracking, presence},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124937,
author = {Jiang, Hao and Ofek, Eyal and Moraveji, Neema and Shi, Yuanchun},
title = {Direct Pointer: Direct Manipulation for Large-Display Interaction Using Handheld Cameras},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124937},
doi = {10.1145/1124772.1124937},
abstract = {This paper describes the design and evaluation of a technique, Direct Pointer, that enables users to interact intuitively with large displays using cameras equipped on handheld devices, such as mobile phones and personal digital assistant (PDA). In contrast to many existing interaction methods that attempt to address the same problem, ours offers direct manipulation of the pointer position with continuous visual feedback. The primary advantage of this technique is that it only requires equipment that is readily available: an electronic display, a handheld digital camera, and a connection between the two. No special visual markers in the display content are needed, nor are fixed cameras pointing at the display. We evaluated the performance of Direct Pointer as an interaction product, showing that it performs as well as comparable techniques that require more sophisticated equipment.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1107–1110},
numpages = {4},
keywords = {shared display, interaction, remote pointing, large display},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124938,
author = {Eisenstein, Jacob and Mackay, Wendy E.},
title = {Interacting with Communication Appliances: An Evaluation of Two Computer Vision-Based Selection Techniques},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124938},
doi = {10.1145/1124772.1124938},
abstract = {Communication appliances, intended for home settings, require intuitive forms of interaction. Computer vision offers a potential solution, but is not yet sufficiently accurate.As interaction designers, we need to know more than the absolute accuracy of such techniques: we must also be able to compare how they will work in our design settings, especially if we allow users to collaborate in the interpretation of their actions. We conducted a 2x4 within-subjects experiment to compare two interaction techniques based on computer vision: motion sensing, with EyeToy®-like feedback, and object tracking. Both techniques were 100% accurate with 2 or 5 choices. With 21 choices, object-tracking had significantly fewer errors and took less time for an accurate selection. Participants' subjective preferences were divided equally between the two techniques. This study compares these techniques as they would be used in real-world applications, with integrated user feedback, allowing interface designers to choose the one that best suits the specific user requirements for their particular application.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1111–1114},
numpages = {4},
keywords = {MirrorSpace, motion sensing, domestic technologies, communication appliance, object tracking, EyeToy, home settings, computer vision-based selection techniques},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124939,
author = {Biocca, Frank and Tang, Arthur and Owen, Charles and Xiao, Fan},
title = {Attention Funnel: Omnidirectional 3D Cursor for Mobile Augmented Reality Platforms},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124939},
doi = {10.1145/1124772.1124939},
abstract = {The attention funnel is a general purpose AR interface technique that interactively guides the attention of a user to any object, person, or place in space. The technique utilizes dynamic perceptual affordances to draw user attention "down" the funnel to the target location. Attention funnel can be used to cue objects completely out of sight including objects behind the user, or occluded by other objects or walls.An experiment evaluating user performance with the attention funnel and other conventional AR attention directing techniques found that the attention funnel increased the consistency of the user's search by 65%, increased search speed by 22%, and decreased mental workload by 18%. The attention funnel has potential applicability as a general 3D cursor or cue in a wide array of spatially enabled mobile and AR systems, and for applications where systems can support users in visual search, object awareness, and emergency warning in indoor and outdoor spaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1115–1122},
numpages = {8},
keywords = {augmented reality, visual attention, mobile computing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124941,
author = {Wall, Steven and Brewster, Stephen},
title = {Feeling What You Hear: Tactile Feedback for Navigation of Audio Graphs},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124941},
doi = {10.1145/1124772.1124941},
abstract = {Access to digitally stored numerical data is currently very limited for sight impaired people. Graphs and visualizations are often used to analyze relationships between numerical data, but the current methods of accessing them are highly visually mediated. Representing data using audio feedback is a common method of making data more accessible, but methods of navigating and accessing the data are often serial in nature and laborious. Tactile or haptic displays could be used to provide additional feedback to support a point-and-click type interaction for the visually impaired. A requirements capture conducted with sight impaired computer users produced a review of current accessibility technologies, and guidelines were extracted for using tactile feedback to aid navigation. The results of a qualitative evaluation with a prototype interface are also presented. Providing an absolute position input device and tactile feedback allowed the users to explore the graph using tactile and proprioceptive cues in a manner analogous to point-and-click techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1123–1132},
numpages = {10},
keywords = {guidelines, tactile, audio, blind, multimodal, accessibility, navigation, graph},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124942,
author = {Petrie, Helen and Hamilton, Fraser and King, Neil and Pavan, Pete},
title = {Remote Usability Evaluations With Disabled People},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124942},
doi = {10.1145/1124772.1124942},
abstract = {Finding participants for evaluations with specific demographics can be a problem for usability and user experience specialists. In particular, finding participants with disabilities is especially problematic, yet testing with disabled people is becoming increasingly important. Two case studies are presented that explore using asynchronous remote evaluation techniques with disabled participants. These show that while quantitative data are comparable, the amount and richness of qualitative data are not likely to be comparable. The implications for formative and summative evaluations are discussed and a set of principles for local and remote evaluations with disabled users is presented.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1133–1141},
numpages = {9},
keywords = {disabled users, remote evaluation, usability research, usability testing and evaluation},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124943,
author = {Dawe, Melissa},
title = {Desperately Seeking Simplicity: How Young Adults with Cognitive Disabilities and Their Families Adopt Assistive Technologies},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124943},
doi = {10.1145/1124772.1124943},
abstract = {A surprisingly high percentage of assistive technology devices (35% or more) are purchased, but not successfully adopted. Through semi-structured interviews with a dozen families, we have come to understand the role technology plays in the lives of families who have a young adult with cognitive disabilities, and how families find, acquire, and use these technologies. This study addresses gaps in existing research and informs future efforts in assistive technology design. Design implications include the importance of simplicity not only in technology function but in configuration, documentation, maintenance, and upgrade or replacement; as well as the need for designers to use methods that consider the multiple individuals and stages involved in the technology adoption process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1143–1152},
numpages = {10},
keywords = {design, ethnography, coordination, mobile technology, independence, assistive technology, semi-structured interviews, family, safety, cognitive disabilities, technology adoption, home, cell phones},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124945,
author = {Zanbaka, Catherine and Goolkasian, Paula and Hodges, Larry},
title = {Can a Virtual Cat Persuade You? The Role of Gender and Realism in Speaker Persuasiveness},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124945},
doi = {10.1145/1124772.1124945},
abstract = {This study examines the roles of gender and visual realism in the persuasiveness of speakers. Participants were presented with a persuasive passage delivered by a male or female person, virtual human, or virtual character. They were then assessed on attitude change and their ratings of the argument, message, and speaker. The results indicated that the virtual speakers were as effective at changing attitudes as real people. Male participants were more persuaded when the speaker was female than when the speaker was male, whereas female participants were more persuaded when the speaker was male than when the speaker was female. Cross gender interactions occurred across all conditions, suggesting that some of the gender stereotypes that occur with people may carry over to interaction with virtual characters. Ratings of the perceptions of the speaker were more favorable for virtual speakers than for human speakers. We discuss the application of these findings in the design of persuasive human computer interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1153–1162},
numpages = {10},
keywords = {human-computer interaction, virtual characters, virtual humans, persuasion},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124946,
author = {Isbister, Katherine and H\"{o}\"{o}k, Kristina and Sharp, Michael and Laaksolahti, Jarmo},
title = {The Sensual Evaluation Instrument: Developing an Affective Evaluation Tool},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124946},
doi = {10.1145/1124772.1124946},
abstract = {In this paper we describe the development and initial testing of a tool for self-assessment of affect while interacting with computer systems: the Sensual Evaluation Instrument. We discuss our research approach within the context of existing affective and HCI theory, and describe stages of evolution of the tool, and initial testing of its effectiveness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1163–1172},
numpages = {10},
keywords = {gesture-based interaction, ambiguity, affective interaction, user-centered design, embodiment},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124947,
author = {Bhatia, Saurabh and McCrickard, Scott},
title = {Listening to Your Inner Voices: Investigating Means for Voice Notifications},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124947},
doi = {10.1145/1124772.1124947},
abstract = {Our research investigates notification qualities of different types of voices, moving toward interfaces that support optimal allocation of attention to maximize system utility. We conducted an experiment to determine the interruption, reaction, and comprehension values of three different voice categories: the user's voice, a familiar voice, and an unfamiliar voice. Initial testing showed significant and impactful results: unfamiliar voices are the least interruptive, and a user reacts most quickly to one's own voice. Motivated by these findings, we report on the development and deployment of a notification system that exploits the differences in familiarity of a voice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1173–1176},
numpages = {4},
keywords = {notification systems, voice interfaces, interruption},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124948,
author = {Pearson, Jamie and Hu, Jiang and Branigan, Holly P. and Pickering, Martin J. and Nass, Clifford I.},
title = {Adaptive Language Behavior in HCI: How Expectations and Beliefs about a System Affect Users' Word Choice},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124948},
doi = {10.1145/1124772.1124948},
abstract = {People display adaptive language behaviors in face-to-face conversations, but will computer users do the same during HCI? We report an experiment (N=20) demonstrating that users' use of language (in terms of lexical choice) is influenced by their beliefs and expectations about a system: When users believe that the system is unsophisticated and restricted in capability, they adapt their language to match the system's language more than when they believe the system is relatively sophisticated and capable. Moreover, this tendency is based entirely on users' expectations about the system; it is unaffected by the actual behavior that the system exhibits. Our results demonstrate that interface design engenders particular beliefs in users about a system's capabilities, and that these beliefs can determine the extent to which users adapt to the system. We argue that such effects can be leveraged to improve the quality and effectiveness of human-computer interactions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1177–1180},
numpages = {4},
keywords = {adaptation, natural language, HCI, interaction technologies, alignment, language behavior},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124950,
author = {Tang, Anthony and Tory, Melanie and Po, Barry and Neumann, Petra and Carpendale, Sheelagh},
title = {Collaborative Coupling over Tabletop Displays},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124950},
doi = {10.1145/1124772.1124950},
abstract = {Designing collaborative interfaces for tabletops remains difficult because we do not fully understand how groups coordinate their actions when working collaboratively over tables. We present two observational studies of pairs completing independent and shared tasks that investigate collaborative coupling, or the manner in which collaborators are involved and occupied with each other's work. Our results indicate that individuals frequently and fluidly engage and disengage with group activity through several distinct, recognizable states with unique characteristics. We describe these states and explore the consequences of these states for tabletop interface design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1181–1190},
numpages = {10},
keywords = {coordination, mixed focus collaboration, collaborative coupling, single display groupware, collaborative tabletop displays},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124951,
author = {Kirk, David and Stanton Fraser, Danae},
title = {Comparing Remote Gesture Technologies for Supporting Collaborative Physical Tasks},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124951},
doi = {10.1145/1124772.1124951},
abstract = {The design of remote gesturing technologies is an area of growing interest. Current technologies have taken differing approaches to the representation of remote gesture. It is not clear which approach has the most benefit to task performance. This study therefore compared performance in a collaborative physical (assembly) task using remote gesture systems constructed with combinations of three different gesture formats (unmediated hands only, hands and sketch and digital sketch only) and two different gesture output locations (direct projection into a worker's task space or on an external monitor). Results indicated that gesturing with an unmediated representation of the hands leads to faster performance with no loss of accuracy. Comparison of gesture output locations did not find a significant difference between projecting gestures and presenting them on external monitors. These results are discussed in relation to theories of conversational grounding and the design of technologies from a 'mixed ecologies' perspective.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1191–1200},
numpages = {10},
keywords = {CSCW, hands, mixed ecologies, remote gesturing},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124952,
author = {Morris, Meredith Ringel and Huang, Anqi and Paepcke, Andreas and Winograd, Terry},
title = {Cooperative Gestures: Multi-User Gestural Interactions for Co-Located Groupware},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124952},
doi = {10.1145/1124772.1124952},
abstract = {Multi-user, touch-sensing input devices create opportunities for the use of cooperative gestures -- multi-user gestural interactions for single display groupware. Cooperative gestures are interactions where the system interprets the gestures of more than one user as contributing to a single, combined command. Cooperative gestures can be used to enhance users' sense of teamwork, increase awareness of important system events, facilitate reachability and access control on large, shared displays, or add a unique touch to an entertainment-oriented activity. This paper discusses motivating scenarios for the use of cooperative gesturing and describes some initial experiences with CollabDraw, a system for collaborative art and photo manipulation. We identify design issues relevant to cooperative gesturing interfaces, and present a preliminary design framework. We conclude by identifying directions for future research on cooperative gesturing interaction techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1201–1210},
numpages = {10},
keywords = {cooperative gestures, gestures, single display groupware, computer-supported cooperative work},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124954,
author = {Salovaara, Antti and Jacucci, Giulio and Oulasvirta, Antti and Saari, Timo and Kanerva, Pekka and Kurvinen, Esko and Tiitta, Sauli},
title = {Collective Creation and Sense-Making of Mobile Media},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124954},
doi = {10.1145/1124772.1124954},
abstract = {Traditionally, mobile media sharing and messaging has been studied from the perspective of an individual author making media available to other users. With the aim of supporting spectator groups at large-scale events, we developed a messaging application for camera phones with the idea of collectively created albums called Media Stories. The field trial at a rally competition pointed out the collective and participative practices involved in the creation and sense-making of media, challenging the view of individual authorship. Members contributed actively to producing chains of messages in Media Stories, with more than half of the members as authors on average in each story. Observations indicate the centrality of collocated viewing and creation in the use of media. Design implications include providing a ""common space"" and possibilities of creating collective objects, adding features that enrich collocated collective use, and supporting the active construction of awareness and social presence through the created media.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1211–1220},
numpages = {10},
keywords = {mobile group media, computer-mediated communication, collective use, mobile phone applications},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124955,
author = {Esbj\"{o}rnsson, Mattias and Brown, Barry and Juhlin, Oskar and Normark, Daniel and \"{O}stergren, Mattias and Laurier, Eric},
title = {Watching the Cars Go Round and Round: Designing for Active Spectating},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124955},
doi = {10.1145/1124772.1124955},
abstract = {Spectating at sport events is a common and popular leisure activity worldwide. Recently spectating has also become a topic of interest to CHI, particularly the design of technology for both performers and audiences. In this paper we describe an in-depth study of spectating, drawn from fieldwork of outdoor car rallies in the UK and Sweden. We describe three findings with relevance to design: the viewing paradox of spectating, active spectating and the role of sociability. We describe the MySplitTime prototype which address these issues while retaining the active sociable nature of the spectating experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1221–1224},
numpages = {4},
keywords = {spectating, sports, rally, ethnography, mobile services},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124956,
author = {Wyeth, Peta},
title = {Ethnography in the Kindergarten: Examining Children's Play Experiences},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124956},
doi = {10.1145/1124772.1124956},
abstract = {This paper describes an ethnographic study completed within a kindergarten environment with the view of gaining insights into the development of new technology for young children. Ethnography within HCI has primarily focused on studies of work practices. This project explored the effectiveness of ethnography in supporting the design of playful technology for a constantly changing, creative, and (sometimes) messy environment. The study was effective in drawing out patterns in observations and as such provides useful suggestions for the development of technology for kindergarten settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1225–1228},
numpages = {4},
keywords = {children, educational technology, ethnography, kindergarten education},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124957,
author = {Weinberg, Gil and Driscoll, Scott},
title = {Robot-Human Interaction with an Anthropomorphic Percussionist},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124957},
doi = {10.1145/1124772.1124957},
abstract = {The paper presents our approach for human-machine interaction with an anthropomorphic mechanical percussionist that can listen to live players, analyze perceptual musical aspects in real-time, and use the product of this analysis to play along in a collaborative manner. Our robot, named Haile, is designed to combine the benefits of computational power, perceptual modeling, and algorithmic music with the richness, visual interactivity, and expression of acoustic playing. We believe that when interacting with live players, Haile can facilitate a musical experience that is not possible by any other means, inspiring users to collaborate with it in novel and expressive manners. Haile can, therefore, serve a test-bed for novel forms of musical human-machine interaction, bringing perceptual aspects of computer music into the physical world both visually and acoustically.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1229–1232},
numpages = {4},
keywords = {human-robot interaction, music, collaborative systems},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124959,
author = {McCurdy, Michael and Connors, Christopher and Pyrzak, Guy and Kanefsky, Bob and Vera, Alonso},
title = {Breaking the Fidelity Barrier: An Examination of Our Current Characterization of Prototypes and an Example of a Mixed-Fidelity Success},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124959},
doi = {10.1145/1124772.1124959},
abstract = {This paper presents a summary of the space of commonly-used HCI prototyping methods (low-fidelity to high-fidelity) and asserts that with a better understanding of this space, HCI practitioners will be better equipped to direct scarce prototyping resources toward an effort likely to yield specific results. It presents a set of five dimensions along which prototypes can be planned and characterized. The paper then describes an analysis of this space performed by members of the NASA Ames Human-Computer Interaction Group when considering prototyping approaches for a new set of tools for Mars mission planning and scheduling tools. A description is presented of a prototype that demonstrates design solutions that would have been particularly difficult to test given conventional low- or mid- fidelity prototyping methods. The prototype created was "mixed-fidelity," that is, high-fidelity on some dimensions and low-fidelity on others. The prototype is compared to a preexisting tool being redesigned and to a tool that has been developed using the prototype. Experimental data are presented that show the prototype to be a good predictor of eventual user performance with the final application. Given the relative cost of developing prototypes, it is critical to better characterize the space of fidelity in order to more precisely allocate design and development resources.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1233–1242},
numpages = {10},
keywords = {methods, fidelity, prototyping, planning},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124960,
author = {Tohidi, Maryam and Buxton, William and Baecker, Ronald and Sellen, Abigail},
title = {Getting the Right Design and the Design Right},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124960},
doi = {10.1145/1124772.1124960},
abstract = {We present a study comparing usability testing of a single interface versus three functionally equivalent but stylistically distinct designs. We found that when presented with a single design, users give significantly higher ratings and were more reluctant to criticize than when presented with the same design in a group of three. Our results imply that by presenting users with alternative design solutions, subjective ratings are less prone to inflation and give rise to more and stronger criticisms when appropriate. Contrary to our expectations, our results also suggest that usability testing by itself, even when multiple designs are presented, is not an effective vehicle for soliciting constructive suggestions about how to improve the design from end users. It is a means to identify problems, not provide solutions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1243–1252},
numpages = {10},
keywords = {prototyping, evaluation, user centered design, design, usability testing, participatory design, methods},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124961,
author = {Guan, Zhiwei and Lee, Shirley and Cuddihy, Elisabeth and Ramey, Judith},
title = {The Validity of the Stimulated Retrospective Think-Aloud Method as Measured by Eye Tracking},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124961},
doi = {10.1145/1124772.1124961},
abstract = {Retrospective Think aloud (RTA) is a usability method that collects the verbalization of a user's performance after the performance is over. There has been little work done to investigate the validity and reliability of RTA. This paper reports on an experiment investigating these issues with a form of the method called stimulated RTA. By comparing subjects' verbalizations with their eye movements, we support the validity and reliability of stimulated RTA: the method provides a valid account of what people attended to in completing tasks, it has a low risk of introducing fabrications, and its validity isn't affected by task complexity. More detailed analysis of RTA shows that it also provides additional information about user's inferences and strategies in completing tasks. The findings of this study provide valuable support for usability practitioners to use RTA and to trust the users' performance information collected by this method in a usability study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1253–1262},
numpages = {10},
keywords = {retrospective think aloud, validity, eye tracking, reliability, verbalization, usability research},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124963,
author = {Benko, Hrvoje and Wilson, Andrew D. and Baudisch, Patrick},
title = {Precise Selection Techniques for Multi-Touch Screens},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124963},
doi = {10.1145/1124772.1124963},
abstract = {The size of human fingers and the lack of sensing precision can make precise touch screen interactions difficult. We present a set of five techniques, called Dual Finger Selections, which leverage the recent development of multi-touch sensitive displays to help users select very small targets. These techniques facilitate pixel-accurate targeting by adjusting the control-display ratio with a secondary finger while the primary finger controls the movement of the cursor. We also contribute a "clicking" technique, called SimPress, which reduces motion errors during clicking and allows us to simulate a hover state on devices unable to sense proximity. We implemented our techniques on a multi-touch tabletop prototype that offers computer vision-based tracking. In our formal user study, we tested the performance of our three most promising techniques (Stretch, X-Menu, and Slider) against our baseline (Offset), on four target sizes and three input noise levels. All three chosen techniques outperformed the control technique in terms of error rate reduction and were preferred by our participants, with Stretch being the overall performance and preference winner.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1263–1272},
numpages = {10},
keywords = {bi-manual, precise target acquisition, touch screens, interaction techniques, tabletop displays, two-finger},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124964,
author = {Morris, Meredith Ringel and Paepcke, Andreas and Winograd, Terry and Stamberger, Jeannie},
title = {TeamTag: Exploring Centralized versus Replicated Controls for Co-Located Tabletop Groupware},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124964},
doi = {10.1145/1124772.1124964},
abstract = {We explore how the placement of control widgets (such as menus) affects collaboration and usability for co-located tabletop groupware applications. We evaluated two design alternatives: a centralized set of controls shared by all users, and separate per-user controls replicated around the borders of the shared tabletop. We conducted this evaluation in the context of TeamTag, a system for collective annotation of digital photos. Our comparison of the two design alternatives found that users preferred replicated over shared controls. We discuss the cause of this preference, and also present data on the impact of these interface design variants on collaboration, as well as the role that orientation, co-touching, and the use of different regions of the table played in shaping users' behavior and preferences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1273–1282},
numpages = {10},
keywords = {computer-supported cooperative work, tabletop interfaces, single display groupware, co-located groupware},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124965,
author = {Agarawala, Anand and Balakrishnan, Ravin},
title = {Keepin' It Real: Pushing the Desktop Metaphor with Physics, Piles and the Pen},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124965},
doi = {10.1145/1124772.1124965},
abstract = {We explore making virtual desktops behave in a more physically realistic manner by adding physics simulation and using piling instead of filing as the fundamental organizational structure. Objects can be casually dragged and tossed around, influenced by physical characteristics such as friction and mass, much like we would manipulate lightweight objects in the real world. We present a prototype, called BumpTop, that coherently integrates a variety of interaction and visualization techniques optimized for pen input we have developed to support this new style of desktop organization.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1283–1292},
numpages = {10},
keywords = {bumptop, crumple, piles, Lasso'n'Cross, piling metaphor, LassoMenu, pen-based interfaces, physics based desktop, physical interaction, pile widgets, desktop metaphor, fanout},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124967,
author = {Weisz, Justin D. and Erickson, Thomas and Kellogg, Wendy A.},
title = {Synchronous Broadcast Messaging: The Use of ICT},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124967},
doi = {10.1145/1124772.1124967},
abstract = {IBM Community Tools (ICT) is a synchronous broadcast messaging system in use by a very large, globally distributed organization. ICT is interesting for a number of reasons, including its scale of use (thousands of users per day), its usage model of employing large scale broadcast to strangers to initiate small group interactions, and the fact that it is a synchronous system used across multiple time zones. In this paper we characterize the use of ICT in its context, examine the activities for which it is used, the motivations of its users, and the values they derive from it. We also explore problems with the system, and look at the social and technical ways in which users deal with them.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1293–1302},
numpages = {10},
keywords = {instant messaging, IM, broadcast messaging, CMC, CSCW, social computing, chat},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124968,
author = {Gergle, Darren and Kraut, Robert E. and Fussell, Susan R.},
title = {The Impact of Delayed Visual Feedback on Collaborative Performance},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124968},
doi = {10.1145/1124772.1124968},
abstract = {When pairs work together on a physical task, seeing a common workspace benefits their performance and transforms their use of language. Previous results have demonstrated that visual information helps collaborative pairs to understand the current state of their task, ground their conversations, and communicate efficiently. However, collaborative technologies often impinge on the visual information needed to support successful collaboration. One example of this is the introduction of delayed visual feedback in a collaborative environment. We present results from two studies that detail the form of the function that describes the relationship between visual delay and collaborative task performance. The first study precisely demonstrates how a range of visual delays differentially impact performance and the collaborative strategies employed. The second study describes how parameters of the task, such as the dynamics of the visual environment, reduce the amount of delay that can be tolerated.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1303–1312},
numpages = {10},
keywords = {communication, empirical studies, computer-supported cooperative work, language, shared visual space, visual delay},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/1124772.1124969,
author = {Bos, Nathan and Olson, Judith and Nan, Ning and Shami, N Sadat and Hoch, Susannah and Johnston, Erik},
title = {Collocation Blindness in Partially Distributed Groups: Is There a Downside to Being Collocated?},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124969},
doi = {10.1145/1124772.1124969},
abstract = {Under what circumstances might a group member be better off as a long-distance participant rather than collocated? We ran a set of experiments to study how partially-distributed groups collaborate when skill sets are unequally distributed. Partially distributed groups are those where some collaborators work together in the same space (collocated) and some work remotely using computer-mediated communications. Previous experiments had shown that these groups tend to form semi-autonomous 'in-groups'. In this set of experiments the configuration was changed so that some player skills were located only in the collocated space, and some were located only remotely, creating local surplus of some skills and local scarcity of others in the collocated room. Players whose skills were locally in surplus performed significantly worse. They experienced 'collocation blindness' and failed to pay enough attention to collaborators outside of the room. In contrast, the remote players whose skills were scarce inside the collocated room did particularly well because they charged a high price for their skills.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1313–1321},
numpages = {9},
keywords = {distributed work, computer-mediated communication, telework, telecommuting, collaboration networks, virtual teams, co-location, collocation},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

