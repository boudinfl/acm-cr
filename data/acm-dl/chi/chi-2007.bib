@inproceedings{10.1145/1240624.1240626,
author = {Yee, Nick and Bailenson, Jeremy N and Rickertsen, Kathryn},
title = {A Meta-Analysis of the Impact of the Inclusion and Realism of Human-like Faces on User Experiences in Interfaces},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240626},
doi = {10.1145/1240624.1240626},
abstract = {The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questionnaire ratings, interviews) than when analyzing behavioral responses such as task performance and memory. Furthermore, the effects of adding an agent to an interface are larger than the effects of animating an agent to behave more realistically. However, the overall effect sizes were quite small (e.g., across studies, adding a face to an interface only explains approximately 2.5% of the variance in results). We discuss the implications for both designers building interfaces as well as social scientists designing experiments to evaluate those interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {embodied agents, meta-analysis, computer-mediated communication, quantitative methods, realism},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258852,
author = {Anderson, Anne},
title = {Session Details: Faces &amp; Bodies in Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258852},
doi = {10.1145/3258852},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240627,
author = {Stach, Tadeusz and Gutwin, Carl and Pinelle, David and Irani, Pourang},
title = {Improving Recognition and Characterization in Groupware with Rich Embodiments},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240627},
doi = {10.1145/1240624.1240627},
abstract = {Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the feasibility of rich embodiment and their effects on group interaction, we carried out three studies. The first shows that users are able to recall and interpret a large set of variables that are graphically encoded on an embodiment. The second and third studies demonstrated rich embodiments in two groupware systems -- a multiplayer game and a drawing application -- and showed that the enhanced representations do improve recognition and characterization, and that they can enrich interaction in a variety of ways.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {11–20},
numpages = {10},
keywords = {rich embodiment, telepointers, avatars, embodiment},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240628,
author = {Moore, Robert J. and Gathman, E. Cabell Hankinson and Ducheneaut, Nicolas and Nickell, Eric},
title = {Coordinating Joint Activity in Avatar-Mediated Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240628},
doi = {10.1145/1240624.1240628},
abstract = {Massively multiplayer online games (MMOGs) currently represent the most widely used type of social 3D virtual worlds with millions of users worldwide. Although MMOGs take face-to-face conversation as their metaphor for user-to-user interaction, avatars currently give off much less information about what users are doing than real human bodies. Consequently, users routinely encounter slippages in coordination when engaging in joint courses of action. In this study, we analyze screen-capture video of user-to-user interaction in the game, City of Heroes, under two conditions: one with the game's standard awareness cues and the other with enhanced cues. We use conversation analysis to demonstrate interactional slippages caused by the absence of awareness cues, user practices that circumvent such limitations and ways in which enhanced cues can enable tighter coordination.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {21–30},
numpages = {10},
keywords = {massively multiplayer online games, conversation analysis, avatar-mediated interaction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180996,
author = {Gilmore, David and Ashley, Jeremy and Viemeister, Tucker and Wood, Tim},
title = {Industrial Design: Challenges and Successes Towards an Integrated Product Development Process},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180996},
doi = {10.1145/1240624.2180996},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180991,
author = {Kolko, John and Veen, Jeff and Grubb, Jonathan},
title = {Web 2.0 and the Enterprise: The Business Impact of Modern Technological Approaches to Web Application Design},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180991},
doi = {10.1145/1240624.2180991},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180994,
author = {Hearst, Marti},
title = {Faceted Metadata for Information Architecture and Search},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180994},
doi = {10.1145/1240624.2180994},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180958,
author = {Herbsleb, Jim and Olson, Gary},
title = {Introduction to CSCW - 2},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180958},
doi = {10.1145/1240624.2180958},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180959,
author = {Rosson, Mary Beth},
title = {Welcome to CHI},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180959},
doi = {10.1145/1240624.2180959},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180960,
author = {Feldman, Stu},
title = {ACM Welcome},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180960},
doi = {10.1145/1240624.2180960},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180961,
author = {Moggridge, Bill},
title = {Opening Plenary Talk},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180961},
doi = {10.1145/1240624.2180961},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180955,
author = {Herbsleb, Jim and Olson, Gary},
title = {Introduction to CSCW - 1},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180955},
doi = {10.1145/1240624.2180955},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180963,
author = {Barkhuus, Louise and Rode, Jennifer A.},
title = {From Mice to Men - 24 Years of Evaluation in CHI},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180963},
doi = {10.1145/1240624.2180963},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2181020,
author = {Rosson, Mary Beth},
title = {Thanks to Our Sponsors},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2181020},
doi = {10.1145/1240624.2181020},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180965,
author = {Klasnja, Ana},
title = {Public Usability Laboratory},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180965},
doi = {10.1145/1240624.2180965},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2181002,
author = {Czerwinski, Mary and Tan, Desney and Lund, Arnie and Shneiderman, Ben},
title = {CHI 2008 Preview},
year = {2012},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2181002},
doi = {10.1145/1240624.2181002},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180967,
author = {Ramos, Gonzalo},
title = {Tuesday CHI Madness},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180967},
doi = {10.1145/1240624.2180967},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180956,
author = {Butler, Keith and Jacobs, Rob and Kieras, David},
title = {Introduction to HCI - 1},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180956},
doi = {10.1145/1240624.2180956},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180969,
author = {Baudish, Partick},
title = {Monday CHI Madness},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180969},
doi = {10.1145/1240624.2180969},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180997,
author = {John, Bonnie E. and Bass, Len and Golden, Elspeth},
title = {Avoiding We Can't Change THAT! An Introduction to Usability &amp; Software Architecture},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180997},
doi = {10.1145/1240624.2180997},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180988,
author = {Foley, Jim},
title = {Past, Present, and Future of HCC Education: What We Teach, How We Teach},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180988},
doi = {10.1145/1240624.2180988},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180990,
author = {Baudisch, Patrick},
title = {Wednesday CHI Madness},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180990},
doi = {10.1145/1240624.2180990},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2181021,
author = {Wall, Steven and Posner, Ilona},
title = {Introduction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2181021},
doi = {10.1145/1240624.2181021},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180995,
author = {Baudisch, Patrick and Ramos, Gonzalo},
title = {CHI Madness: Summary of Other Entries},
year = {2012},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180995},
doi = {10.1145/1240624.2180995},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180968,
title = {Program Addenda},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180968},
doi = {10.1145/1240624.2180968},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180962,
author = {Kaye, Joseph 'Jofish' and Sengers, Phoebe},
title = {The Evolution of Evaluation},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180962},
doi = {10.1145/1240624.2180962},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2181033,
author = {Wixon, Dennis and Rosson, Mary Beth and Gilmore, David},
title = {CHI 2007 Welcome},
year = {2012},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2181033},
doi = {10.1145/1240624.2181033},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2206886,
author = {John, Bonnie E. and Golden, Elspeth},
title = {Avoiding We Can't Change That Either! Usability Supporting Architectural Patterns},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2206886},
doi = {10.1145/1240624.2206886},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2181000,
author = {Abowd, Gregory D.},
title = {Using Computing Technologies to Face the Challenges of Autism},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2181000},
doi = {10.1145/1240624.2181000},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2181001,
author = {Bhan, Niti},
title = {The Mobile as a Post Industrial Platform for Socio-Economic Development},
year = {2012},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2181001},
doi = {10.1145/1240624.2181001},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180964,
author = {Cockton, Gilbert},
title = {Make Evaluation Poverty History},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180964},
doi = {10.1145/1240624.2180964},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180957,
author = {Butler, Keith and Jacobs, Rob and Kieras, David},
title = {Introduction to HCI - 2},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180957},
doi = {10.1145/1240624.2180957},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180999,
author = {Ramos, Gonzalo},
title = {Thursday CHI Madness},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180999},
doi = {10.1145/1240624.2180999},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180966,
author = {Marsden, Gary},
title = {Doing HCI Differently -- Stories from the Developing World},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180966},
doi = {10.1145/1240624.2180966},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.2180987,
author = {Lucas, Bill and Ishii, Hiroshi and Kolojejchick, Jake and Lucas, Peter and Rose, David},
title = {Along the Path of Pervasive Computing: Selected Works in GUI and TUI Design},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.2180987},
doi = {10.1145/1240624.2180987},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258853,
author = {Bailey, Brian},
title = {Session Details: Attention &amp; Interruption},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258853},
doi = {10.1145/3258853},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240630,
author = {Tullio, Joe and Dey, Anind K. and Chalecki, Jason and Fogarty, James},
title = {How It Works: A Field Study of Non-Technical Users Interacting with an Intelligent System},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240630},
doi = {10.1145/1240624.1240630},
abstract = {In order to develop intelligent systems that attain the trust of their users, it is important to understand how users perceive such systems and develop those perceptions over time. We present an investigation into how users come to understand an intelligent system as they use it in their daily work. During a six-week field study, we interviewed eight office workers regarding the operation of a system that predicted their managers' interruptibility, comparing their mental models to the actual system model. Our results show that by the end of the study, participants were able to discount some of their initial misconceptions about what information the system used for reasoning about interruptibility. However, the overarching structures of their mental models stayed relatively stable over the course of the study. Lastly, we found that participants were able to give lay descriptions attributing simple machine learning concepts to the system despite their lack of technical knowledge. Our findings suggest an appropriate level of feedback for user interfaces of intelligent systems, provide a baseline level of complexity for user understanding, and highlight the challenges of making users aware of sensed inputs for such systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {31–40},
numpages = {10},
keywords = {qualitative research, intelligent systems, mental models, field study, context-aware, machine learning},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240631,
author = {Gluck, Jennifer and Bunt, Andrea and McGrenere, Joanna},
title = {Matching Attentional Draw with Utility in Interruption},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240631},
doi = {10.1145/1240624.1240631},
abstract = {This research examines a design guideline that aims to increase the positive perception of interruptions. The guideline advocates matching the amount of attention attracted by an interruption's notification method (attentional draw) to the utility of the interruption content. Our first experiment examined a set of 10 visual notification signals in terms of their detection times and established a set of three significantly different signals along the spectrum of attentional draw. Our second experiment investigated matching these different signals to interruption content with different levels of utility. Results indicate that the matching strategy decreases annoyance and increases perception of benefit compared to a strategy that uses the same signal regardless of interruption utility, with no significant impact on workload or performance. Design implications arising from the second experiment as well as recommendations for future work are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {41–50},
numpages = {10},
keywords = {interruption, detection, utility, attention, benefit, annoyance, mental workload},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240632,
author = {Avrahami, Daniel and Fogarty, James and Hudson, Scott E.},
title = {Biases in Human Estimation of Interruptibility: Effects and Implications for Practice},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240632},
doi = {10.1145/1240624.1240632},
abstract = {People have developed a variety of conventions for negotiating face to face interruptions. The physical distribution of teams, however, together with the use of computer mediated communication and awareness systems, fundamentally alters what information is available to a person considering an interruption of a remote collaborator. This paper presents a detailed comparison between self-reports of interruptibility, collected from participants over extended periods in their actual work environment, and estimates of this interruptibility, provided by a second set of participants based on audio and video recordings. Our results identify activities and environmental cues that affect participants' ability to correctly estimate interruptibility. We show, for example, that a closed office door had a significant effect on observers' estimation of interruptibility, but did not have an effect on participants' reports of their own interruptibility. We discuss our findings and their importance for successful design of computer-mediated communication and awareness systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {50–60},
numpages = {11},
keywords = {interruptibility, awareness, context aware computing, computer mediated communication, availability, ubiquitous computing},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258854,
author = {Kiesler, Sara},
title = {Session Details: Capturing Life Experiences},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258854},
doi = {10.1145/3258854},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240634,
author = {Kirk, David and Sellen, Abigail and Harper, Richard and Wood, Ken},
title = {Understanding Videowork},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240634},
doi = {10.1145/1240624.1240634},
abstract = {In this paper we elucidate the patterns of behavior of home movie makers through a study of 12 families and a separate focus group of 7 teenagers. Analogous to a similar study of photowork [13], the goal is to provide a deeper understanding of what people currently do with video technologies, balancing the preponderence of techno-centric work in the area with appropriate user-centric insight. From our analysis, we derive a videowork lifecycle to frame the practices users engage in when working with video technologies in the home, and uncover two broad types of video usage therein. This has implications for how we conceive of and devise tools to support these practices, as we discuss.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {61–70},
numpages = {10},
keywords = {user research, video, editing, home movies},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240635,
author = {Kalnikait\'{e}, Vaiva and Whittaker, Steve},
title = {Software or Wetware? Discovering When and Why People Use Digital Prosthetic Memory},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240635},
doi = {10.1145/1240624.1240635},
abstract = {Our lives are full of memorable and important moments, as well as important items of information. The last few years have seen the proliferation of digital devices intended to support prosthetic memory (PM), to help users recall experiences, conversations and retrieve personal information. We nevertheless have little systematic understanding of when and why people might use such devices, in preference to their own organic memory (OM). Although OM is fallible, it may be more efficient than accessing information from a complex PM device. We report a controlled lab study which investigates when and why people use PM and OM. We found that PM use depended on users' evaluation of the quality of their OM, as well as PM device properties. In particular, we found that users trade-off Accuracy and Efficiency, preferring rapid access to potentially inaccurate information over laborious access to accurate information. We discuss the implications of these results for future PM design and theory. Rather than replacing OM, future PM designs need to focus on allowing OM and PM to work in synergy.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {71–80},
numpages = {10},
keywords = {speech browsing, prosthetic memory, memory, speech retrieval, remembering, notes, digital memory},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240636,
author = {Sellen, Abigail J. and Fogg, Andrew and Aitken, Mike and Hodges, Steve and Rother, Carsten and Wood, Ken},
title = {Do Life-Logging Technologies Support Memory for the Past? An Experimental Study Using Sensecam},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240636},
doi = {10.1145/1240624.1240636},
abstract = {We report on the results of a study using SenseCam, a "life-logging" technology in the form of a wearable camera, which aims to capture data about everyday life in order to support people's memory for past, personal events. We find evidence that SenseCam images do facilitate people's ability to connect to their past, but that images do this in different ways. We make a distinction between "remembering" the past, and "knowing" about it, and provide evidence that SenseCam images work differently over time in these capacities. We also compare the efficacy of user-captured images with automatically captured images and discuss the implications of these findings and others for how we conceive of and make claims about life-logging technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {81–90},
numpages = {10},
keywords = {capture, SenseCam, life-logging, episodic or autobiographical memory, personal digital archives, images},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258855,
author = {Czerwinski, Mary},
title = {Session Details: Large Displays},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258855},
doi = {10.1145/3258855},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240638,
author = {Birnholtz, Jeremy P. and Grossman, Tovi and Mak, Clarissa and Balakrishnan, Ravin},
title = {An Exploratory Study of Input Configuration and Group Process in a Negotiation Task Using a Large Display},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240638},
doi = {10.1145/1240624.1240638},
abstract = {This paper reports on an exploratory study of the effects of input configuration on group behavior and performance in a collaborative task performed by a collocated group using a large display. Twelve groups completed a mixed-motive negotiation task under two conditions: a single, shared mouse and one mouse per person. Results suggest that the multiple mouse condition allowed for more parallel work, but the quality of discussion was higher in the single mouse condition. Moreover, participants were more likely to act in their own best interest in the multiple mouse condition.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {91–100},
numpages = {10},
keywords = {large displays, input, collaboration, negotiation},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240639,
author = {Yost, Beth and Haciahmetoglu, Yonca and North, Chris},
title = {Beyond Visual Acuity: The Perceptual Scalability of Information Visualizations for Large Displays},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240639},
doi = {10.1145/1240624.1240639},
abstract = {The scalability of information visualizations has typically been limited by the number of available display pixels. As displays become larger, the scalability limit may shift away from the number of pixels and toward human perceptual abilities. This work explores the effect of using large, high resolution displays to scale up information visualizations beyond potential visual acuity limitations. Displays that are beyond visual acuity require physical navigation to see all of the pixels. Participants performed various information visualization tasks using display sizes with a sufficient number of pixels to be within, equal to, or beyond visual acuity. Results showed that performance on most tasks was more efficient and sometimes more accurate because of the additional data that could be displayed, despite the physical navigation that was required. Visualization design issues on large displays are also discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {101–110},
numpages = {10},
keywords = {information visualization, large displays, visual acuity},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240640,
author = {Reilly, Derek F. and Inkpen, Kori M.},
title = {White Rooms and Morphing Don't Mix: Setting and the Evaluation of Visualization Techniques},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240640},
doi = {10.1145/1240624.1240640},
abstract = {The results presented in this paper illustrate how a specific map visualization technique is sensitive to setting: a comparative evaluation of the technique gives conflicting results depending on where it takes place. While prior research has explored the impact of factors other than basic visual perception on visualization techniques, relatively little attention has been directed toward the physical setting in which the technique is used. We present results from a study involving 120 participants, comparing the effectiveness of two different geovisualization techniques in promoting recall of map layout. Recall was shown to be sensitive to setting, such that one technique in particular was more effective in a noisy public space than in a controlled, 'white-room' environment. The results have implications for the validation and measurement of information visualization techniques as a whole, and in particular for those employing motion as a communicative attribute.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {111–120},
numpages = {10},
keywords = {contextual evaluation, morphing, methodology, external validity, GIS, ecological validity, geographic visualization, information visualization},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258856,
author = {Holmquist, Lars Erik},
title = {Session Details: Shake, Rattle and Roll: New Forms of Input and Output},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258856},
doi = {10.1145/3258856},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240642,
author = {Williamson, John and Murray-Smith, Roderick and Hughes, Stephen},
title = {Shoogle: Excitatory Multimodal Interaction on Mobile Devices},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240642},
doi = {10.1145/1240624.1240642},
abstract = {Shoogle is a novel, intuitive interface for sensing data withina mobile device, such as presence and properties of textmessages or remaining resources. It is based around activeexploration: devices are shaken, revealing the contents rattlingaround "inside". Vibrotactile display and realistic impactsonification create a compelling system. Inertial sensingis used for completely eyes-free, single-handed interactionthat is entirely natural. Prototypes are described runningboth on a PDA and on a mobile phone with a wireless sensorpack. Scenarios of use are explored where active sensing ismore appropriate than the dominant alert paradigm.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {121–124},
numpages = {4},
keywords = {accelerometer, multimodal, mobile, vibrotactile, audio},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258857,
author = {Harrison, Beverly},
title = {Session Details: Ubicomp Tools},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258857},
doi = {10.1145/3258857},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240644,
author = {Carter, Scott and Mankoff, Jennifer and Heer, Jeffrey},
title = {Momento: Support for Situated Ubicomp Experimentation},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240644},
doi = {10.1145/1240624.1240644},
abstract = {We present the iterative design of Momento, a tool that providesintegrated support for situated evaluation of ubiquitouscomputing applications. We derived requirements for Momento from a user-centered design process that includedinterviews, observations and field studies of early versionsof the tool. Motivated by our findings, Momento supportsremote testing of ubicomp applications, helps with participantadoption and retention by minimizing the need for newhardware, and supports mid-to-long term studies to addressinfrequently occurring data. Also, Momento can gather logdata, experience sampling, diary, and other qualitative data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {125–134},
numpages = {10},
keywords = {experience sampling, rapid prototyping, mobile devices, Wizard of Oz, diary sudies},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240645,
author = {Fogarty, James and Hudson, Scott E.},
title = {Toolkit Support for Developing and Deploying Sensor-Based Statistical Models of Human Situations},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240645},
doi = {10.1145/1240624.1240645},
abstract = {Sensor based statistical models promise to support a variety of advances in human computer interaction, but building applications that use them is currently difficult and potential advances go unexplored. We present Subtle, a toolkit that removes some of the obstacles to developing and deploying applications using sensor based statistical models of human situations. Subtle provides an appropriate and extensible sensing library, continuous learning of personalized models, fully automated high level feature generation, and support for using learned models in deployed applications. By removing obstacles to developing and deploying sensor based statistical models, Subtle makes it easier to explore the design space surrounding sensor based statistical models of human situations. Subtle thus helps to move the focus of human computer interaction research onto applications and datasets, instead of the difficulties of developing and deploying sensor based statistical models.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {135–144},
numpages = {10},
keywords = {context-aware computing, toolkit, sensor-based statistical model, subtle, machine-learning},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240646,
author = {Hartmann, Bj\"{o}rn and Abdulla, Leith and Mittal, Manas and Klemmer, Scott R.},
title = {Authoring Sensor-Based Interactions by Demonstration with Direct Manipulation and Pattern Recognition},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240646},
doi = {10.1145/1240624.1240646},
abstract = {Sensors are becoming increasingly important in interaction design. Authoring a sensor-based interaction comprises three steps: choosing and connecting the appropriate hardware, creating application logic, and specifying the relationship between sensor values and application logic. Recent research has successfully addressed the first two issues. However, linking sensor input data to application logic remains an exercise in patience and trial-and-error testing for most designers. This paper introduces techniques for authoring sensor-based interactions by demonstration. A combination of direct manipulation and pattern recognition techniques enables designers to control how demonstrated examples are generalized to interaction rules. This approach emphasizes design exploration by enabling very rapid iterative demonstrate-edit-review cycles. This paper describes the manifestation of these techniques in a design tool, Exemplar, and presents evaluations through a first-use lab study and a theoretical analysis using the Cognitive Dimensions of Notation framework.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {145–154},
numpages = {10},
keywords = {physical computing, pbd, sensors, design tools},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258858,
author = {Inkpen, Kori},
title = {Session Details: Mobile Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258858},
doi = {10.1145/3258858},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240648,
author = {Jones, Matt and Buchanan, George and Harper, Richard and Xech, Pierre-Louis},
title = {<i>Questions</i> Not <i>Answers</i>: A Novel Mobile Search Technique},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240648},
doi = {10.1145/1240624.1240648},
abstract = {Mobile search is becoming an increasingly important user activity. In this paper, instead of investigating the most efficient and effective ways of providing search results, the answers, we consider the value of giving access to previous queries, the questions, relating to a user's location. By exposing what other people have searched for, the aim is to provide useful insights into a location's character. To consider the value of the approach we deployed two mobile probes in a large-scale field study involving 391 participants. Our experiences suggest that presenting users with other people's in situ queries influences their information seeking interactions positively.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {155–158},
numpages = {4},
keywords = {social software, mobile search, location},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240649,
author = {Brewster, Stephen and Chohan, Faraz and Brown, Lorna},
title = {Tactile Feedback for Mobile Interactions},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240649},
doi = {10.1145/1240624.1240649},
abstract = {We present a study investigating the use of vibrotactile feedback for touch-screen keyboards on PDAs. Such key-boards are hard to use when mobile as keys are very small. We conducted a laboratory study comparing standard but-tons to ones with tactile feedback added. Results showed that with tactile feedback users entered significantly more text, made fewer errors and corrected more of the errors they did make. We ran the study again with users seated on an underground train to see if the positive effects trans-ferred to realistic use. There were fewer beneficial effects, with only the number of errors corrected significantly im-proved by the tactile feedback. However, we found strong subjective feedback in favour of the tactile display. The results suggest that tactile feedback has a key role to play in improving interactions with touch screens.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {159–162},
numpages = {4},
keywords = {touch screen buttons, tactons, mobility, tactile icons},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240650,
author = {Clarkson, Edward and Lyons, Kent and Clawson, James and Starner, Thad},
title = {Revisiting and Validating a Model of Two-Thumb Text Entry},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240650},
doi = {10.1145/1240624.1240650},
abstract = {MacKenzie and Soukoreff have previously introduced a Fitts' Law-based performance model of expert two-thumb text entry on mini-QWERTY keyboards [4]. In this work we validate the original model using results from a longitudinal study of mini-QWERTY keyboards, and update the model to account for observed inter-key time data.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {163–166},
numpages = {4},
keywords = {Fitts' Law, mobile text entry, Mini-QWERTY},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240651,
author = {Hachet, Martin and Pouderoux, Joachim and Tyndiuk, Florence and Guitton, Pascal},
title = {"Jump and Refine" for Rapid Pointing on Mobile Phones},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240651},
doi = {10.1145/1240624.1240651},
abstract = {Standard input devices for mobile phones are directional keys and discrete thumb-joysticks. These devices are dedicated to the discrete GUIs of the phones (eg. scroll lists and small icons arrays). Today, new mobile applications are arising and require adapted interfaces. In particular, the widespread of 3D applications will be favored if users can efficiently point on any part of thescreen. In this paper, we propose a new interaction technique called Jump and Refine for selection tasks on mobile phones. This technique is based on two levels of cursor displacement in order to reduce the number of keystrokes. The first level allows fast movements into an underlying grid. The second one can be used for accurate positioning into the selected area. We present a user study which shows that using a first coarse jump level decreases the selection completion times. The study also shows that the technique is widely accepted by the users. Finally, we discuss the optimal grid sizes.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {167–170},
numpages = {4},
keywords = {keystroke interaction, mobile device, pointing task, selection},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258859,
author = {Forlizzi, Jodi},
title = {Session Details: Politics &amp; Activism},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258859},
doi = {10.1145/3258859},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240653,
author = {Byrne, Michael D. and Greene, Kristen K. and Everett, Sarah P.},
title = {Usability of Voting Systems: Baseline Data for Paper, Punch Cards, and Lever Machines},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240653},
doi = {10.1145/1240624.1240653},
abstract = {In the United States, computer-based voting machines are rapidly replacing other older technologies. While there is potential for this to be a usability improvement, particularly in terms of accessibility, the only way it is possible to know if usability has improved is to have baseline data on the usability of traditional technologies. We report an experiment assessing the usability of punch cards, lever machines, and two forms of paper ballot. There were no differences in ballot completion time between the four methods, but there were substantial effects on error rate, with the paper ballots superior to the other methods as well as an interaction with age of voters. Subjective usability was assessed with the System Usability Scale and showed a slight advantage for bubble-style paper ballots. Overall, paper ballots were found to be particularly usable, which raises important technological and policy issues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {171–180},
numpages = {10},
keywords = {effectiveness, voting, DRE, efficiency, subjective usability},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240654,
author = {Flanagan, Mary and Nissenbaum, Helen},
title = {A Game Design Methodology to Incorporate Social Activist Themes},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240654},
doi = {10.1145/1240624.1240654},
abstract = {Can a set of articulated and tested methodologies be created whose endpoint is the reliable capacity for taking activist social themes into account? In this paper we explore a variety of educational and activist game approaches, and look specifically at the themes emerging from recent projects involving game design for young women. We articulate here design practices in a methodology, Values at Play (VAP), that could be used in the creation of games as well as the teaching of game design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {181–190},
numpages = {10},
keywords = {game design, values, activist games, design methods},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258860,
author = {Baudisch, Patrick},
title = {Session Details: Navigation &amp; Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258860},
doi = {10.1145/3258860},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240656,
author = {Ball, Robert and North, Chris and Bowman, Doug A.},
title = {Move to Improve: Promoting Physical Navigation to Increase User Performance with Large Displays},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240656},
doi = {10.1145/1240624.1240656},
abstract = {In navigating large information spaces, previous work indicates potential advantages of physical navigation (moving eyes, head, body) over virtual navigation (zooming, panning, flying). However, there is also indication of users preferring or settling into the less efficient virtual navigation. We present a study that examines these issues in the context of large, high resolution displays. The study identifies specific relationships between display size, amount of physical and virtual navigation, and user task performance. Increased physical navigation on larger displays correlates with reduced virtual navigation and improved user performance. Analyzing the differences between this study and previous results helps to identify design factors that afford and promote the use of physical navigation in the user interface.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {191–200},
numpages = {10},
keywords = {large displays, physical navigation, virtual navigation, embodied interaction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240657,
author = {Chapuis, Olivier and Roussel, Nicolas},
title = {Copy-and-Paste between Overlapping Windows},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240657},
doi = {10.1145/1240624.1240657},
abstract = {Copy-and-paste, one of the fundamental operations of modern userinterfaces, can be performed through various means (e.g. using the keyboard, mouse-based direct manipulation or menus). When users copy-and-paste between two different windows, the process is complicated by window management tasks. In this paper, we propose two new window management techniques to facilitate these tasks in the particular case of partially overlapping windows. We describe an experiment comparing four commonly-used copy-and-paste techniques under four window management conditions -- non-overlapping windows, partially overlapping windows, and partially overlapping ones with one of our two window management techniques. Results show that our new window management techniques significantly reduce task completion time for all copy-and-paste techniques. They also show that X Window copy-and-paste is faster than the other three techniques under all four window management conditions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {201–210},
numpages = {10},
keywords = {window management, copy-and-paste, overlapping windows},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240658,
author = {Hutchings, Dugald Ralph and Stasko, John},
title = {Consistency, Multiple Monitors, and Multiple Windows},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240658},
doi = {10.1145/1240624.1240658},
abstract = {We present an evaluation of mudibo, a prototype system for determining the position of dialog boxes in a multiple-monitor system. The analysis shows that, when compared to a standard approach, mudibo offered a 24% decrease in time needed to begin interaction in a dialog box. Analysis of participant behavior in the evaluation provides insight into the way users perceive and act in multiple-monitor environments. Specifically, the notion of consistency changes for multiple-monitor systems and the prospect of adaptive algorithms becomes further complicated and intricate, especially for window management.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {211–214},
numpages = {4},
keywords = {window management, consistency, multiple monitors},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240659,
author = {Tse, Edward and Shen, Chia and Greenberg, Saul and Forlines, Clifton},
title = {How Pairs Interact over a Multimodal Digital Table},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240659},
doi = {10.1145/1240624.1240659},
abstract = {Co-located collaborators often work over physical tabletops using combinations of expressive hand gestures and verbal utterances. This paper provides the first observations of how pairs of people communicated and interacted in a multimodal digital table environment built atop existing single user applications. We contribute to the understanding of these environments in two ways. First, we saw that speech and gesture commands served double duty as both commands to the computer, and as implicit communication to others. Second, in spite of limitations imposed by the underlying single-user application, people were able to work together simultaneously, and they performed interleaving acts: the graceful mixing of inter-person speech and gesture actions as commands to the system. This work contributes to the intricate understanding of multi-user multimodal digital table interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {215–218},
numpages = {4},
keywords = {gestures, speech, digital tables, multimodal interaction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258861,
author = {McDonald, David},
title = {Session Details: Medical},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258861},
doi = {10.1145/3258861},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240661,
author = {Tang, Charlotte and Carpendale, Sheelagh},
title = {An Observational Study on Information Flow during Nurses' Shift Change},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240661},
doi = {10.1145/1240624.1240661},
abstract = {We present an observational study that was conducted to guide the design and development of technologies to support information flow during nurses' shift change in a hospital ward. Our goal is to find out how the complex information sharing processes during nurses' brief shift change unfold in a hospital setting. Our study shows the multitude of information media that nurses access during the parallel processes of information assembly and disassembly: digital, paper-based, displayed and verbal media. An initial analysis reveals how the common information spaces, where information media are positioned and accessible by all participants, are actively used and how they interact with the personal information spaces ephemerally constructed by the participants. Several types of information are consistently transposed from the common information spaces to the personal information space including: demographics, historical data, reminders and to-dos, alerts, prompts, scheduling and reporting information. Information types are often enhanced with a variety of visual cues to help nurses carry out their tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {219–228},
numpages = {10},
keywords = {common information space, information disassembly, shift change, personal information space, observational study, nursing, information assembly, information flow},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240662,
author = {Billman, Dorrit and Bier, Eric A.},
title = {Medical Sensemaking with Entity Workspace},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240662},
doi = {10.1145/1240624.1240662},
abstract = {Knowledge workers making sense of a topic divide their time among activities including searching for information, reading, and taking notes. We have built a software system that supports and integrates these activities. To test its effectiveness, we conducted a study where subjects used it to perform medical question-answering tasks. Initial results indicate that subjects could use the system, but that the nature of this use depended on the subject's overall question-answering strategy. Two dominant strategies emerged that we call the Reader and Searcher strategies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {229–232},
numpages = {4},
keywords = {highlighting, search, sensemaking, note-taking, quick click},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258862,
author = {Hornof, Anthony},
title = {Session Details: Task &amp; Attention},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258862},
doi = {10.1145/3258862},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240664,
author = {Brumby, Duncan P. and Howes, Andrew and Salvucci, Dario D.},
title = {A Cognitive Constraint Model of Dual-Task Trade-Offs in a Highly Dynamic Driving Task},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240664},
doi = {10.1145/1240624.1240664},
abstract = {The paper describes an approach to modeling the strategic variations in performing secondary tasks while driving. In contrast to previous efforts that are based on simulation of a cognitive architecture interacting with a task environment, we take an approach that develops a cognitive constraint model of the interaction between the driver and the task environment in order to make inferences about dual-task performance. Analyses of driving performance data reveal that a set of simple equations can be used to accurately model changes in the lateral position of the vehicle within the lane. The model quantifies how the vehicle's deviation from lane center increases during periods of inattention, and how the vehicle returns to lane center during periods of active steering. We demonstrate the benefits of the approach by modeling the dialing of a cellular phone while driving, where drivers balance the speed in performing the dial task with accuracy (or safety) in keeping the vehicle centered in the roadway. In particular, we show how understanding, rather than simulating, the constraints imposed by the task environment can help to explain the costs and benefits of a range of strategies for interleaving dialing and steering. We show how particular strategies are sensitive to a combination of internal constraints (including switch costs) and the trade-off between the amount of time allocated to secondary task and the risk of extreme lane deviation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {233–242},
numpages = {10},
keywords = {user modeling, multitasking, driver distraction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240665,
author = {Salvucci, Dario D. and Markley, Daniel and Zuber, Mark and Brumby, Duncan P.},
title = {IPod Distraction: Effects of Portable Music-Player Use on Driver Performance},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240665},
doi = {10.1145/1240624.1240665},
abstract = {Portable music players such as Apple's iPod have become ubiquitous in many environments, but one environment in particular has elicited new safety concerns and challenges -- in-vehicle use while driving. We present the first study of portable music-player interaction while driving, examining the effects of iPod interaction by drivers navigating a typical roadway in a driving simulator. Results showed that selecting media on the iPod had a significant effect on driver performance as measured by lateral deviation from lane center; the effect was comparable to previously reported effects of dialing a cellular phone. In addition, selecting media and watching videos had a significant effect on car-following speed, resulting in speed reductions that presumably compensated for impaired lateral performance. Given that iPod interaction has become increasingly common while driving, these results serve as a first step toward understanding the potential effects of portable music-player interaction on driver behavior and performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {243–250},
numpages = {8},
keywords = {driver distraction, driving, iPod, mobile computing},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240666,
author = {Hinckley, Ken and Zhao, Shengdong and Sarin, Raman and Baudisch, Patrick and Cutrell, Edward and Shilman, Michael and Tan, Desney},
title = {InkSeine: <i>In Situ</i> Search for Active Note Taking},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240666},
doi = {10.1145/1240624.1240666},
abstract = {Using a notebook to sketch designs, reflect on a topic, or capture and extend creative ideas are examples of active note taking tasks. Optimal experience for such tasks demands concentration without interruption. Yet active note taking may also require reference documents or emails from team members. InkSeine is a Tablet PC application that supports active note taking by coupling a pen-and-ink interface with an in situ search facility that flows directly from a user's ink notes (Fig. 1). InkSeine integrates four key concepts: it leverages preexisting ink to initiate a search; it provides tight coupling of search queries with application content; it persists search queries as first class objects that can be commingled with ink notes; and it enables a quick and flexible workflow where the user may freely interleave inking, searching, and gathering content. InkSeine offers these capabilities in an interface that is tailored to the unique demands of pen input, and that maintains the primacy of inking above all other tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {251–260},
numpages = {10},
keywords = {gestures, handwriting, pen, input, ink, search, tablet},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258863,
author = {Aoki, Paul},
title = {Session Details: Expert/Novice},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258863},
doi = {10.1145/3258863},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240668,
author = {Wong, Jeffrey and Oh, Lui Min and Ou, Jiazhi and Ros\'{e}, Carolyn P. and Yang, Jie and Fussell, Susan R.},
title = {Sharing a Single Expert among Multiple Partners},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240668},
doi = {10.1145/1240624.1240668},
abstract = {Expertise to assist people on complex tasks is often in short supply. One solution to this problem is to design systems that allow remote experts to help multiple people in simultaneously. As a first step towards building such a system, we studied experts' attention and communication as they assisted two novices at the same time in a co-located setting. We compared simultaneous instruction when the novices are being instructed to do the same task or different tasks. Using machine learning, we attempted to identify speech markers of upcoming attention shifts that could serve as input to a remote assistance system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {261–270},
numpages = {10},
keywords = {video-mediated communication, grounding, multi-tasking, focus-of-attention, multi-party conversation, remote expertise, remote collaborative physical tasks},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240669,
author = {Hurst, Amy and Hudson, Scott E. and Mankoff, Jennifer},
title = {Dynamic Detection of Novice vs. Skilled Use without a Task Model},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240669},
doi = {10.1145/1240624.1240669},
abstract = {If applications were able to detect a user's expertise, then software could automatically adapt to better match exper-tise. Detecting expertise is difficult because a user's skill changes as the user interacts with an application and differs across applications. This means that expertise must be sensed dynamically, continuously, and unobtrusively so as not to burden the user. We present an approach to this prob-lem that can operate without a task model based on low-level mouse and menu data which can typically be sensed across applications at the operating systems level. We have implemented and trained a classifier that can detect "nov-ice" or "skilled" use of an image editing program, the GNU Image Manipulation Program (GIMP), at 91% accuracy, and tested it against real use. In particular, we developed and tested a prototype application that gives the user dy-namic application information that differs depending on her performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {271–280},
numpages = {10},
keywords = {statistical models, intelligent user interfaces},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240670,
author = {Dickinson, Anna and Smith, Michael J. and Arnott, John L. and Newell, Alan F. and Hill, Robin L.},
title = {Approaches to Web Search and Navigation for Older Computer Novices},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240670},
doi = {10.1145/1240624.1240670},
abstract = {A proof of concept web search and navigation system was developed for older people for whom the Internet is seen as an alien territory. A joint industry/academia team deployed User Sensitive Inclusive Design principles, focusing on the usability of the interface for this user group. The search and navigation system that was developed was significantly preferred by the user group to that provided by a standard commercial (Internet Service Provider) system; it scored highly for ease of use and the participants reported increased confidence in their ability to master the Internet. Recorded quantitative measures showed fewer task errors. The outcome of the development was a successful "proof of concept" search and navigation system for older novice computer users together with approaches to design and development for those who wish to design for this user group.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {281–290},
numpages = {10},
keywords = {web browser, usability, web search, older people, human factors, interface layering, web portal, accessibility},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258864,
author = {McCrickard, Scott},
title = {Session Details: Mobile Applications},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258864},
doi = {10.1145/3258864},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240672,
author = {White, Sean Michael and Marino, Dominic and Feiner, Steven},
title = {Designing a Mobile User Interface for Automated Species Identification},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240672},
doi = {10.1145/1240624.1240672},
abstract = {Biological research in the field is constrained by the speed and difficulty of species determination, as well as by access to relevant information about the species encountered. However, recent work on vision-based algorithms raises the promise of rapid botanical species identification. The potential for mobile vision-based identification provides opportunities for new user interface techniques. To explore these issues, we present LeafView, a Tablet-PC-based user interface for an electronic field guide that supports automated identification of botanical species in the field. We describe a user interface design based on an ethnographic study of botanists, field tests of working prototypes by botanists at the Smithsonian Institution on Plummers Island, Maryland, and observations at an internal exhibition at the Smithsonian at which other staff members tried the prototypes. We present functionality specific to mobile identification and collection in the electronic field guide and use this to motivate discussion of mobile identification in general.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {291–294},
numpages = {4},
keywords = {mobile computing, computer vision, electronic field guide, botanical species identification, pen-based computing, ecoinformatics},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240673,
author = {Liu, Alan L. and Li, Yang},
title = {BrickRoad: A Light-Weight Tool for Spontaneous Design of Location-Enhanced Applications},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240673},
doi = {10.1145/1240624.1240673},
abstract = {It is difficult to design and test location-enhancedapplications. A large part of this difficulty is due to the added complexity of supporting location. Wizard of Oz (WOz) has become an effective technique for the early stage design of location-enhanced applications because it allows designers to test an application prototype bysimulating nonexistent components such as location sensing. However, existing WOz tools 1) require nontrivial effort from designers to specify how a prototype should behave before it can be tested with end users, and 2)support only limited control over application behavior during a test. BrickRoad is a WOz tool for spontaneousdesign of location-enhanced applications. It lowers the threshold to acquiring user feedback and exploring a design space. With BrickRoad, a designer does not need to specify any interaction logic and can experiment on-the-fly with different designs during testing. BrickRoad is a valuable complement to existing tool support for the early stage design of location-enhanced applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {295–298},
numpages = {4},
keywords = {prototyping, location-enhanced computing, ubiquitous computing, Wizard of Oz},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240674,
author = {Dunne, Lucy E. and Smyth, Barry},
title = {Psychophysical Elements of Wearability},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240674},
doi = {10.1145/1240624.1240674},
abstract = {Wearable technology presents a wealth of new HCI issues. In particular, this paper addresses the impact of the physical interaction between the user's body and the device's physical form on the user's mental representation of self and cognitive abilities, a blend of HCI and ergonomics that is unique to wearable computing. We explore the human sensory mechanisms that facilitate perception of worn objects and the elements of sensation that influence the comfort of worn objects, and discuss the psychological elements that may cause worn objects to be forgotten or detected, wearable or not. We discuss the implications of un-wearability on attention and cognitive capability.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {299–302},
numpages = {4},
keywords = {wearable technology, wearable computing, wearability, psychophysics},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240675,
author = {Tian, Feng and Ao, Xiang and Wang, Hongan and Setlur, Vidya and Dai, Guozhong},
title = {The Tilt Cursor: Enhancing Stimulus-Response Compatibility by Providing 3d Orientation Cue of Pen},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240675},
doi = {10.1145/1240624.1240675},
abstract = {In order to improve stimulus-response compatibility of touchpad in pen-based user interface, we present the tilt cursor, i.e. a cursor dynamically reshapes itself to providing the 3D orientation cue of pen. We also present two experiments that evaluate the tilt cursor's performance in circular menu selection and specific marking menu selection tasks. Results show that in a specific marking menu selection task, the tilt cursor significantly outperforms the shape-fixed arrow cursor and the live cursor [4]. In addition, results show that by using the tilt cursor, the response latencies for adjusting drawing directions are smaller than that by using the other two kinds of cursors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {303–306},
numpages = {4},
keywords = {orientation, pen, cursor, stimulus-response compatibility},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240676,
author = {Ziefle, Martina and Schroeder, Ulrik and Strenk, Judith and Michel, Thomas},
title = {How Younger and Older Adults Master the Usage of Hyperlinks in Small Screen Devices},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240676},
doi = {10.1145/1240624.1240676},
abstract = {In this paper we describe an experiment, in which we examined older and younger adults when interacting with a simulated PDA (personal digital assistant). Independent variables were users' age (young vs. older) and device interface (hyperlink vs. no hyperlink). Dependent variables were the effectiveness and efficiency of menu navigation. To understand how user characteristics influence performance, spatial ability, verbal memory, computer expertise and technical self-confidence were determined. Technology experienced young and older adults (benchmark testing) took part. They had to solve four tasks either with hyperlink interface or without hyperlinks in the interface. The method to collect, to automatically analyze and to structure the data according to interaction sequences and presumed user intentions is a novel approach supported by the open source software tool Clever [12]. The tool is briefly described; more details can be found in [23]. Results revealed that hyperlink interfaces showed overall higher effectiveness. However, the impact of hyperlinks for efficiency was age-related. Younger adults strongly benefit from having hyperlinks. The contrary was the case for older adults, who showed higher menu disorientation when using hyperlinks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {307–316},
numpages = {10},
keywords = {cognitive user characteristics, qualitative user data analysis, small screen devices, hyperlinks, navigation performance, aging},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258865,
author = {Jacob, Robert},
title = {Session Details: Navigation},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258865},
doi = {10.1145/3258865},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240678,
author = {Kattinakere, Raghavendra S. and Grossman, Tovi and Subramanian, Sriram},
title = {Modeling Steering within Above-the-Surface Interaction Layers},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240678},
doi = {10.1145/1240624.1240678},
abstract = {Interaction techniques that utilize the space above the display surface to extend the functionalities of digitized surfaces continue to emerge. In such techniques, movements are constrained by the bounds of a layer. In addition, constraints imposed on the direction of movement within the layer may be present. Despite the presence of such techniques, there is limited understanding of human capabilities for performing the required steering task. In this paper we study and model user performance when steering through constrained and unconstrained paths in above-the-surface layers. Through a series of experiments we validate the derivation and applicability of our proposed models.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {317–326},
numpages = {10},
keywords = {3D, command layers, 3D steering, digital table},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240679,
author = {Guiard, Yves and Du, Yangzhou and Chapuis, Olivier},
title = {Quantifying Degree of Goal Directedness in Document Navigation: Application to the Evaluation of the Perspective-Drag Technique},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240679},
doi = {10.1145/1240624.1240679},
abstract = {This article pursues a two-fold goal. First we introduce degree of goal directedness (DGD), a novel quantitative dimension for the taxonomy of navigation tasks in general. As an attempt to operationalize the DGD concept in the context of electronic documents navigation, we introduce the serial target-acquisition (STA) experimental paradigm. We suggest that DGD and the STA paradigm may usefully enrich the conceptual toolkit of HCI research for the evaluation of navigation techniques. Our second goal is to illustrate the utility of the DGD concept by showing with a concrete example, Perspective Drag, the refinement it allows in evaluating navigation techniques. We report data obtained from two experiments with the STA paradigm that cast light on what Perspective Drag is specifically good for: it is particularly suitable in realistic task contexts where navigation is less than 100% directed by its terminal goal, that is, where the user wants not only to reach a particular item but also to pick up information from the document during document traversal.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {327–336},
numpages = {10},
keywords = {Fitts' law, interactive multi-scale visualization, document navigation, perspective viewing, goal-directed behavior, task taxonomies},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240680,
author = {Tabard, Aur\'{e}lien and Mackay, Wendy and Roussel, Nicolas and Letondal, Catherine},
title = {PageLinker: Integrating Contextual Bookmarks within a Browser},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240680},
doi = {10.1145/1240624.1240680},
abstract = {PageLinker is a browser extension that allows to contextualise navigation by linking web pages together and to navigate through a network of related web pages without prior planning. The design is based on extensive interviews with biologists, which highlighted their difficulties finding previously visited web pages. They found current browser tools inadequate, resulting in poorly organised bookmarks and rarely used history lists. In a four-week controlled field experiment, PageLinker significantly reduced time, page loads and mouse clicks. By presenting links in context, PageLinker facilitates web page revisitation, is less prone to bookmark overload and is highly robust to change.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {337–346},
numpages = {10},
keywords = {WWW, browsers, PageLinker, web navigation, participatory design, bookmarks, contextual bookmarks, biologists},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258866,
author = {Bardram, Jakob},
title = {Session Details: Photo Sharing},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258866},
doi = {10.1145/3258866},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240682,
author = {Miller, Andrew D. and Edwards, W. Keith},
title = {Give and Take: A Study of Consumer Photo-Sharing Culture and Practice},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240682},
doi = {10.1145/1240624.1240682},
abstract = {In this paper, we present initial findings from the study of a digital photo-sharing website: Flickr.com. In particular, we argue that Flickr.com appears to support-for some people-a different set of photography practices, socialization styles, and perspectives on privacy that are unlike those described in previous research on consumer and amateur photographers. Further, through our examination of digital photographers' photowork activities-organizing, finding, sharing and receiving-we suggest that privacy concerns and lack of integration with existing communication channels have the potential to prevent the 'Kodak Culture' from fully adopting current photo-sharing solutions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {347–356},
numpages = {10},
keywords = {consumer photography, media sharing, photowork, domestic and leisure computing, digital photography},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240683,
author = {Ahern, Shane and Eckles, Dean and Good, Nathaniel S. and King, Simon and Naaman, Mor and Nair, Rahul},
title = {Over-Exposed? Privacy Patterns and Considerations in Online and Mobile Photo Sharing},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240683},
doi = {10.1145/1240624.1240683},
abstract = {As sharing personal media online becomes easier and widely spread, new privacy concerns emerge - especially when the persistent nature of the media and associated context reveals details about the physical and social context in which the media items were created. In a first-of-its-kind study, we use context-aware camerephone devices to examine privacy decisions in mobile and online photo sharing. Through data analysis on a corpus of privacy decisions and associated context data from a real-world system, we identify relationships between location of photo capture and photo privacy settings. Our data analysis leads to further questions which we investigate through a set of interviews with 15 users. The interviews reveal common themes in privacy considerations: security, social disclosure, identity and convenience. Finally, we highlight several implications and opportunities for design of media sharing applications, including using past privacy patterns to prevent oversights and errors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {357–366},
numpages = {10},
keywords = {photo sharing, privacy, photos, context-aware, social software, online content, location-aware},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240684,
author = {Cui, Jingyu and Wen, Fang and Xiao, Rong and Tian, Yuandong and Tang, Xiaoou},
title = {EasyAlbum: An Interactive Photo Annotation System Based on Face Clustering and Re-Ranking},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240684},
doi = {10.1145/1240624.1240684},
abstract = {Digital photo management is becoming indispensable for the explosively growing family photo albums due to the rapid popularization of digital cameras and mobile phone cameras. In an effective photo management system photo annotation is the most challenging task. In this paper, we develop several innovative interaction techniques for semi-automatic photo annotation. Compared with traditional annotation systems, our approach provides the following new features: "cluster annotation" puts similar faces or photos with similar scene together, and enables user label them in one operation; "contextual re-ranking" boosts the labeling productivity by guessing the user intention; "ad hoc annotation" allows user label photos while they are browsing or searching, and improves system performance progressively through learning propagation. Our results show that these technologies provide a more user friendly interface for the annotation of person name, location, and event, and thus substantially improve the annotation performance especially for a large photo album.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {367–376},
numpages = {10},
keywords = {annotation, photo tagging, cluster annotation, face tagging, face recognition},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258867,
author = {McGrenere, Joanna},
title = {Session Details: Empirical Studies of Web Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258867},
doi = {10.1145/3258867},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240686,
author = {Kellar, Melanie and Watters, Carolyn and Inkpen, Kori M.},
title = {An Exploration of Web-Based Monitoring: Implications for Design},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240686},
doi = {10.1145/1240624.1240686},
abstract = {Monitoring occurs when users return to previously viewed web pages to view new or updated information. While tools exist to support web-based monitoring, we know little about the monitoring activities users engage in and the nature of the support needed. We have conducted 40 semi-structured interviews in order to better understand the types of information users monitor and the characteristics of different monitoring activities. Using the data collected during the interviews, we characterized monitoring as an activity within six web information tasks: Browsing, Communications, Fact Finding, Information Gathering, Maintenance, and Transactions. The results of our study have been used to provide general, as well as task specific, recommendations for the design of monitoring tools.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {377–386},
numpages = {10},
keywords = {revisitation, task, semi-structured interviews, user behaviour, web, monitoring},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240687,
author = {Hartmann, Jan and Sutcliffe, Alistair and De Angeli, Antonella},
title = {Investigating Attractiveness in Web User Interfaces},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240687},
doi = {10.1145/1240624.1240687},
abstract = {A theoretical framework for assessing the attractiveness of websites based on Adaptive Decision Making theory is introduced. The framework was developed into a questionnaire and used to evaluate three websites which shared the same brand and topic but differed in aesthetic design. The DSchool site was favoured overall and was best for aesthetics and usability. The subjective ratings of the sites were in conflict with the subject-reported comments on usability problems. Subjects were given two scenarios for their preference. They changed their preference from the DSchool to the HCI Group's site for the more serious (PhD study) scenario; however, design background students remained loyal to the DSchool. The implications of framing and halo effects on users' judgement of aesthetics are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {387–396},
numpages = {10},
keywords = {aesthetics, judgement biases, websites, attractiveness, usability},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240688,
author = {Petrie, Helen and Kheir, Omar},
title = {The Relationship between Accessibility and Usability of Websites},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240688},
doi = {10.1145/1240624.1240688},
abstract = {Accessibility and usability are well established concepts for user interfaces and websites. Usability is precisely defined, but there are different approaches to accessibility. In addition, different possible relationships could exist between problems encountered by disabled and non-disabled users, yet little empirical data have been gathered on this question. Guidelines for accessibility and usability of websites provide ratings of the importance of problems for users, yet little empirical data have been gathered to validate these ratings. A study investigated the accessibility of two websites with 6 disabled (blind) and 6 non-disabled (sighted) people. Problems encountered by the two groups comprised two intersecting sets, with approximately 15% overlap. For one of the two websites, blind people rated problems significantly more severely than sighted people. There was high agreement between participants as to the severity of problems, and agreement between participants and researchers. However, there was no significant agreement between either participants or researchers and the importance/priority ratings provided by accessibility and usability guidelines. Practical and theoretical implications of these results are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {397–406},
numpages = {10},
keywords = {accessibility, guidelines, severity ratings, user testing, usability},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258868,
author = {North, Chris},
title = {Session Details: Gaze &amp; Eye Tracking},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258868},
doi = {10.1145/3258868},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240690,
author = {Cutrell, Edward and Guan, Zhiwei},
title = {What Are You Looking for? An Eye-Tracking Study of Information Usage in Web Search},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240690},
doi = {10.1145/1240624.1240690},
abstract = {Web search services are among the most heavily used applications on the World Wide Web. Perhaps because search is used in such a huge variety of tasks and contexts, the user interface must strike a careful balance to meet all user needs. We describe a study that used eye tracking methodologies to explore the effects of changes in the presentation of search results. We found that adding information to the contextual snippet significantly improved performance for informational tasks but degraded performance for navigational tasks. We discuss possible reasons for this difference and the design implications for better presentation of search results.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {407–416},
numpages = {10},
keywords = {user studies, web search, contextual snippets, eye tracking},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240691,
author = {Guan, Zhiwei and Cutrell, Edward},
title = {An Eye Tracking Study of the Effect of Target Rank on Web Search},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240691},
doi = {10.1145/1240624.1240691},
abstract = {Web search engines present search results in a rank ordered list. This works when what a user wants is near the top, but sometimes the information that the user really wants is located at the bottom of the page. This study examined how users' search behaviors vary when target results were displayed at various positions for informational and navigational tasks. We found that when targets were placed relatively low in the first page of search results, people spent more time searching and were less successful in finding the target, especially for informational tasks. Further analysis of eye movements showed that the decrease in search performance was partially due to the fact that users rarely looked at lower ranking results. The large decrease in performance for informational search is probably because users have high confidence in the search engine's ranking; in contrast to navigational tasks, where the target is more obvious from information presented in the results, in informational tasks, users try out the top ranked results even if these results are perceived as less relevant for the task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {417–420},
numpages = {4},
keywords = {target position, trust, web search, eye tracking},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240692,
author = {Kumar, Manu and Paepcke, Andreas and Winograd, Terry},
title = {EyePoint: Practical Pointing and Selection Using Gaze and Keyboard},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240692},
doi = {10.1145/1240624.1240692},
abstract = {We present a practical technique for pointing and selection using a combination of eye gaze and keyboard triggers. EyePoint uses a two-step progressive refinement process fluidly stitched together in a look-press-look-release action, which makes it possible to compensate for the accuracy limitations of the current state-of-the-art eye gaze trackers. While research in gaze-based pointing has traditionally focused on disabled users, EyePoint makes gaze-based pointing effective and simple enough for even able-bodied users to use for their everyday computing tasks. As the cost of eye gaze tracking devices decreases, it will become possible for such gaze-based techniques to be used as a viable alternative for users who choose not to use a mouse depending on their abilities, tasks and preferences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {421–430},
numpages = {10},
keywords = {eye pointing, pointing and selection, eye tracking, gaze-enhanced user interface design},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240693,
author = {Halverson, Tim and Hornof, Anthony J.},
title = {A Minimal Model for Predicting Visual Search in Human-Computer Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240693},
doi = {10.1145/1240624.1240693},
abstract = {Visual search is an important part of human-computer interaction. It is critical that we build theory about how people visually search displays in order to better support the users' visual capabilities and limitations in everyday tasks. One way of building such theory is through computational cognitive modeling. The ultimate promise for cognitive modeling in HCI it to provide the science base needed for predictive interface analysis tools. This paper discusses computational cognitive modeling of the perceptual, strategic, and oculomotor processes people used in a visual search task. This work refines and rounds out previously reported cognitive modeling and eye tracking analysis. A revised "minimal model" of visual search is presented that explains a variety of eye movement data better than the original model. The revised model uses a parsimonious strategy that is not tied to a particular visual structure or feature beyond the location of objects. Three characteristics of the minimal strategy are discussed in detail.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {431–434},
numpages = {4},
keywords = {EPIC, screen design, cognitive modeling, visual search, cognitive strategies, eye movements},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258869,
author = {Brush, A. J.},
title = {Session Details: Online Representation of Self},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258869},
doi = {10.1145/3258869},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240695,
author = {Lampe, Cliff A.C. and Ellison, Nicole and Steinfield, Charles},
title = {A Familiar Face(Book): Profile Elements as Signals in an Online Social Network},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240695},
doi = {10.1145/1240624.1240695},
abstract = {Using data from a popular online social network site, this paper explores the relationship between profile structure (namely, which fields are completed) and number of friends, giving designers insight into the importance of the profile and how it works to encourage connections and articulated relationships between users. We describe a theoretical framework that draws on aspects of signaling theory, common ground theory, and transaction costs theory to generate an understanding of why certain profile fields may be more predictive of friendship articulation on the site. Using a dataset consisting of 30,773 Facebook profiles, we determine which profile elements are most likely to predict friendship links and discuss the theoretical and design implications of our findings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {435–444},
numpages = {10},
keywords = {online social networks, social capital, signaling theory, profiles},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240696,
author = {Vasalou, Asimina and Joinson, Adam N. and Pitt, Jeremy},
title = {Constructing My Online Self: Avatars That Increase Self-Focused Attention},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240696},
doi = {10.1145/1240624.1240696},
abstract = {Three studies investigated whether users' strategies for customising online avatars increase their self-focused attention, also known as private self-awareness. Study 1 showed that a high number of users adapt their avatars toreflect their own appearance. Study 2 demonstrated that users who perceive their avatars to be similar to their own appearance experience as a result heightened private self-awareness. In Study 3, private self-awareness pervadedsocial interaction taking place over time when users with representative avatars, compared to a control group, reported increased private self-awareness. Drawing from research in interpersonal communication, we suggest that avatars which increase their owners' self-focus may have an influence on online behavior in the context of social computing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {445–448},
numpages = {4},
keywords = {interpersonal communication, avatars, self-awareness},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240697,
author = {Hancock, Jeffrey T. and Toma, Catalina and Ellison, Nicole},
title = {The Truth about Lying in Online Dating Profiles},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240697},
doi = {10.1145/1240624.1240697},
abstract = {Online dating is a popular new tool for initiating romantic relationships, although recent research and media reports suggest that it may also be fertile ground for deception. Unlike previous studies that rely solely on self-report data, the present study establishes ground truth for 80 online daters' height, weight and age, and compares ground truth data to the information provided in online dating profiles. The results suggest that deception is indeed frequently observed, but that the magnitude of the deceptions is usually small. As expected, deceptions differ by gender. Results are discussed in light of the Hyperpersonal model and the self-presentational tensions experienced by online dating participants.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {449–452},
numpages = {4},
keywords = {online dating, deception, self-presentation, lying, computer-mediated communication},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240698,
author = {Kittur, Aniket and Suh, Bongwon and Pendleton, Bryan A. and Chi, Ed H.},
title = {He Says, She Says: Conflict and Coordination in Wikipedia},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240698},
doi = {10.1145/1240624.1240698},
abstract = {Wikipedia, a wiki-based encyclopedia, has become one of the most successful experiments in collaborative knowledge building on the Internet. As Wikipedia continues to grow, the potential for conflict and the need for coordination increase as well. This article examines the growth of such non-direct work and describes the development of tools to characterize conflict and coordination costs in Wikipedia. The results may inform the design of new collaborative knowledge systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {453–462},
numpages = {10},
keywords = {user model, visualization, collaboration, Wiki, web-based interaction, conflict, Wikipedia},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258870,
author = {Smith, Ian},
title = {Session Details: Innovative Interactions},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258870},
doi = {10.1145/3258870},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240700,
author = {Grossman, Tovi and Kong, Nicholas and Balakrishnan, Ravin},
title = {Modeling Pointing at Targets of Arbitrary Shapes},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240700},
doi = {10.1145/1240624.1240700},
abstract = {We investigate pointing at graphical targets of arbitrary shapes. We first describe a previously proposed probabilistic Fitts' law model [7] which, unlike previous models that only account for rectangular targets, has the potential to handle arbitrary shapes. Three methods of defining the centers of arbitrarily shaped targets for use within the model are developed. We compare these methods of defining target centers, and validate the model using a pointing experiment in which the targets take on various shapes. Results show that the model can accurately account for the varying target shapes. We discuss the implications of our results to interface design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {463–472},
numpages = {10},
keywords = {arbitrary shapes, Fitts' Law, probabilistic model, pointing},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240701,
author = {Wigdor, Daniel and Shen, Chia and Forlines, Clifton and Balakrishnan, Ravin},
title = {Perception of Elementary Graphical Elements in Tabletop and Multi-Surface Environments},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240701},
doi = {10.1145/1240624.1240701},
abstract = {Information shown on a tabletop display can appear distorted when viewed by a seated user. Even worse, the impact of this distortion is different depending on the location of the information on the display. In this paper, we examine how this distortion affects the perception of the basic graphical elements of information visualization shown on displays at various angles. We first examine perception of these elements on a single display, and then compare this to perception across displays, in order to evaluate the effectiveness of various elements for use in a tabletop and multi-display environment. We found that the perception of some graphical elements is more robust to distortion than others. We then develop recommendations for building data visualizations for these environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {473–482},
numpages = {10},
keywords = {visualization, multi-display, tabletop, multi-surface},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240702,
author = {Grossman, Tovi and Wigdor, Daniel and Balakrishnan, Ravin},
title = {Exploring and Reducing the Effects of Orientation on Text Readability in Volumetric Displays},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240702},
doi = {10.1145/1240624.1240702},
abstract = {Volumetric displays, which provide a 360° view of imagery illuminated in true 3D space, are a promising platform for interactive 3D applications. However, presenting text in volumetric displays can be a challenge, as the text may not be oriented towards the user. This is especially problematic with multiple viewers, as the text could, for example, appear forwards to one user, and backwards to another. In a first experiment we determined the effects of 3D rotations on text readability. Based on the results, we developed and evaluated a new technique which optimizes text orientation for multiple viewers. This technique provided 33% faster group reading times in a collaborative experimental task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {483–492},
numpages = {10},
keywords = {text orientation, reading speed, volumetric displays},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258871,
author = {Kolko, Jon},
title = {Session Details: Design Theory},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258871},
doi = {10.1145/3258871},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240704,
author = {Zimmerman, John and Forlizzi, Jodi and Evenson, Shelley},
title = {Research through Design as a Method for Interaction Design Research in HCI},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240704},
doi = {10.1145/1240624.1240704},
abstract = {For years the HCI community has struggled to integrate design in research and practice. While design has gained a strong foothold in practice, it has had much less impact on the HCI research community. In this paper we propose a new model for interaction design research within HCI. Following a research through design approach, designers produce novel integrations of HCI research in an attempt to make the right thing: a product that transforms the world from its current state to a preferred state. This model allows interaction designers to make research contributions based on their strength in addressing under-constrained problems. To formalize this model, we provide a set of four lenses for evaluating the research contribution and a set of three examples to illustrate the benefits of this type of research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {493–502},
numpages = {10},
keywords = {HCI research, design, wicked problems, design theory, design method, interaction design, research through design, interaction design research},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240705,
author = {Blevis, Eli},
title = {Sustainable Interaction Design: Invention &amp; Disposal, Renewal &amp; Reuse},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240705},
doi = {10.1145/1240624.1240705},
abstract = {This paper presents the perspective that sustainability can and should be a central focus of interaction design-a perspective that is termed Sustainable Interaction Design (SID). As a starting point for a perspective of sustainability, design is defined as an act of choosing among or informing choices of future ways of being. This perspective of sustainability is presented in terms of design values, methods, and reasoning. The paper proposes (i) a rubric for understanding the material effects of particular interaction design cases in terms of forms of use, reuse, and disposal, and (ii) several principles to guide SID. The paper illustrates--with particular examples of design critique for interactive products and appeals to secondary research--how two of these principles may be applied to move the effects of designs from less preferred forms of use to more preferred ones. Finally, a vision for incorporating sustainability into the research and practice of interaction design is described.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {503–512},
numpages = {10},
keywords = {design theory, interaction design, design, sustainability, sustainable interaction design},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240706,
author = {Vallg\r{a}rda, Anna and Redstr\"{o}m, Johan},
title = {Computational Composites},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240706},
doi = {10.1145/1240624.1240706},
abstract = {Computational composite is introduced as a new type of composite material. Arguing that this is not just a metaphorical maneuver, we provide an analysis of computational technology as material in design, which shows how computers share important characteristics with other materials used in design and architecture. We argue that the notion of computational composites provides a precise understanding of the computer as material, and of how computations need to be combined with other materials to come to expression as material. Besides working as an analysis of computers from a designer's point of view, the notion of computational composites may also provide a link for computer science and human-computer interaction to an increasingly rapid development and use of new materials in design and architecture.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {513–522},
numpages = {10},
keywords = {aesthetics, interaction design, material, architecture, computational composites},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258872,
author = {Goodman, Elizabeth},
title = {Session Details: Play &amp; Exercise},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258872},
doi = {10.1145/3258872},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240708,
author = {O'Brien, Shannon and Mueller, Florian "Floyd"},
title = {Jogging the Distance},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240708},
doi = {10.1145/1240624.1240708},
abstract = {People enjoy jogging with others for social and motivational reasons. However, as reported by forum participants, finding a compatible, local jogging partner who shares the ability to jog at the same pace for the same duration is not always easy. One possible way to overcome this challenge is to expand the range of potential jogging partners by allowing for interaction with remote joggers. We investigated whether a jogging experience supporting conversation between remote partners could be desirable and motivating. We conducted an experiment with 18 volunteers using conventional mobile phones with headsets to support conversations as participants jogged in disjoint, outdoor areas. Results show that a simple audio connection supports participants' need to socialize and allows partners to encourage each other.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {523–526},
numpages = {4},
keywords = {mobile phones, community forums, social support, jogging},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258873,
author = {Muller, Michael},
title = {Session Details: Home Spirituality},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258873},
doi = {10.1145/3258873},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240710,
author = {Woodruff, Allison and Augustin, Sally and Foucault, Brooke},
title = {Sabbath Day Home Automation: "It's like Mixing Technology and Religion"},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240710},
doi = {10.1145/1240624.1240710},
abstract = {We present a qualitative study of 20 American Orthodox Jewish families' use of home automation for religious purposes. These lead users offer insight into real-life, long-term experience with home automation technologies. We discuss how automation was seen by participants to contribute to spiritual experience and how participants oriented to the use of automation as a religious custom. We also discuss the relationship of home automation to family life. We draw design implications for the broader population, including surrender of control as a design resource, home technologies that support long-term goals and lifestyle choices, and respite from technology.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {527–536},
numpages = {10},
keywords = {ubiquitous computing, smart homes, family life, religious technology, domestic technology, home automation},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240711,
author = {Gaver, William and Sengers, Phoebe and Kerridge, Tobie and Kaye, Joseph and Bowers, John},
title = {Enhancing Ubiquitous Computing with User Interpretation: Field Testing the Home Health Horoscope},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240711},
doi = {10.1145/1240624.1240711},
abstract = {Domestic ubiquitous computing systems often rely on inferences about activities in the home, but the open-ended, dynamic and heterogeneous nature of the home poses serious problems for such systems. In this paper, we propose that by shifting the responsibility for interpretation from the system to the user, we can build systems that interact with people at humanly meaningful levels, preserve privacy, and encourage engagement with suggested topics. We describe a system that embodies this hypothesis, using sensors and inferencing software to assess 'domestic wellbeing' and presenting the results to inhabitants through an output chosen for its ambiguity. In a three-month field study of the system, customised for a particular volunteer household, users engaged extensively with the system, discussing and challenging its outputs and responding to the particular topics it raised.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {537–546},
numpages = {10},
keywords = {ubiquitous computing, interpretation, home},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240712,
author = {Shehan, Erika and Edwards, W. Keith},
title = {Home Networking and HCI: What Hath God Wrought?},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240712},
doi = {10.1145/1240624.1240712},
abstract = {For much of the industrialized world, network connectivity in the home is commonplace. Despite the large number of networked homes, even the most technically savvy people can have difficulties with home network installation and maintenance. We contend that these problems will not disappear over time as the networking industry matures, but rather are due to structural usability flaws inherent in the design of existing network infrastructure, devices, and protocols. The HCI community can offer a unique perspective to overcoming the challenges associated with home networking. This paper discusses why home networking is difficult, based on analysis of historical, social, and technical factors. It explores how the designs of existing home networking technologies have implications for usability, and examines a range of models for addressing these usability challenges. The paper concludes with a discussion of how these models may impact future research efforts in both HCI and networking.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {547–556},
numpages = {10},
keywords = {infrastructure, ubiquitous computing, home networking, computer networking, home computing, troubleshooting},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258874,
author = {Burnett, Margaret},
title = {Session Details: Programming by Professionals},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258874},
doi = {10.1145/3258874},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240714,
author = {Cherubini, Mauro and Venolia, Gina and DeLine, Rob and Ko, Andrew J.},
title = {Let's Go to the Whiteboard: How and Why Software Developers Use Drawings},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240714},
doi = {10.1145/1240624.1240714},
abstract = {Software developers are rooted in the written form of their code, yet they often draw diagrams representing their code. Unfortunately, we still know little about how and why they create these diagrams, and so there is little research to inform the design of visual tools to support developers' work. This paper presents findings from semi-structured interviews that have been validated with a structured survey. Results show that most of the diagrams had a transient nature because of the high cost of changing whiteboard sketches to electronic renderings. Diagrams that documented design decisions were often externalized in these temporary drawings and then subsequently lost. Current visualization tools and the software development practices that we observed do not solve these issues, but these results suggest several directions for future research.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {557–566},
numpages = {10},
keywords = {diagrams, software visualization, exploratory/field study},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240715,
author = {Boshernitsan, Marat and Graham, Susan L. and Hearst, Marti A.},
title = {Aligning Development Tools with the Way Programmers Think about Code Changes},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240715},
doi = {10.1145/1240624.1240715},
abstract = {Software developers must modify their programs to keepup with changing requirements and designs. Often, aconceptually simple change can require numerous editsthat are similar but not identical, leading to errors andomissions. Researchers have designed programming environmentsto address this problem, but most of thesesystems are counter-intuitive and difficult to use.By applying a task-centered design process, we developeda visual tool that allows programmers to makecomplex code transformations in an intuitive manner.This approach uses a representation that aligns wellwith programmers' mental models of programming structures.The visual language combines textual and graphicalelements and is expressive enough to support a broadrange of code-changing tasks. To simplify learning thesystem, its user interface scaffolds construction and executionof transformations. An evaluation with Java programmerssuggests that the interface is intuitive, easyto learn, and effective on a representative editing task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {567–576},
numpages = {10},
keywords = {visual languages, cognitive dimensions, transformations},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240716,
author = {Ellis, Jason B. and Wahid, Shahtab and Danis, Catalina and Kellogg, Wendy A.},
title = {Task and Social Visualization in Software Development: Evaluation of a Prototype},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240716},
doi = {10.1145/1240624.1240716},
abstract = {As open source development has evolved, differentiation of roles and increased sophistication of collaborative processes has occurred. Recently, we described coordination issues in software development and an interactive visualization tool called the Social Health Overview (SHO) developed to address them [12]. This paper presents an empirical evaluation of SHO intended to identify its strengths and weaknesses. Eleven informants in various open source roles were interviewed about their work practices. Eight of these participated in an evaluation comparing three change management tasks in SHO and Bugzilla. Results are discussed with respect to task strategy with each tool and participants' roles.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {577–586},
numpages = {10},
keywords = {coordination of work, task visualization, change tracking systems, software development, social visualization, information visualization},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258875,
author = {Chi, Ed},
title = {Session Details: Web Usability},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258875},
doi = {10.1145/3258875},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240718,
author = {Wang, Shuo and Jing, Feng and He, Jibo and Du, Qixing and Zhang, Lei},
title = {IGroup: Presenting Web Image Search Results in Semantic Clusters},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240718},
doi = {10.1145/1240624.1240718},
abstract = {Current web image search engines still rely on user typing textual description: query word(s) for visual targets. As the queries are often short, general or even ambiguous, the images in resulting pages vary in content and style. Thus, browsing with these results is likely to be tedious, frustrating and unpredictable.IGroup, a proposed image search engine addresses these problems by presenting the result in semantic clusters. The original result set was clustered in semantic groups with a cluster name relevant to user typed queries. Instead of looking through the result pages or modifying queries, IGroup users can refine findings to the interested sub-result sets with a navigational panel, where each cluster (sub-result set) was listed with a cluster name and representative thumbnails of the cluster.We compared IGroup with a general web image search engine: MSN, in term of efficiency, coverage, and satisfaction with a substantial user study. Our tool shows significant improvement in such criteria.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {587–596},
numpages = {10},
keywords = {image search result clustering (ISRC), user test, image search interface, search result clustering (SRC)},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240719,
author = {Obendorf, Hartmut and Weinreich, Harald and Herder, Eelco and Mayer, Matthias},
title = {Web Page Revisitation Revisited: Implications of a Long-Term Click-Stream Study of Browser Usage},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240719},
doi = {10.1145/1240624.1240719},
abstract = {This paper presents results of an extensive long-term click-stream study of Web browser usage. Focusing on character and challenges of page revisitation, previous findings from seven to thirteen years ago are updated. The term page re-visit had to be differentiated, since the recurrence rate--the key measure for the share of page revisits--turns out to strongly depend on interpretation. We identify different types of revisitation that allow assessing the quality of current user support and developing concepts for new tools.Individual navigation strategies differ dramatically and are strongly influenced by personal habits and type of site visited. Based on user action logs and interviews, we distinguished short-term revisits (backtrack or undo) from medium-term (re-utilize or observe) and long-term revisits (rediscover). We analyze current problems and provide suggestions for improving support for different revisitation types.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {597–606},
numpages = {10},
keywords = {navigation, history, recurrence rate, web browsing, revisitation, hypertext, WWW, web browser interfaces},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240720,
author = {Good, Nathaniel S. and Grossklags, Jens and Mulligan, Deirdre K. and Konstan, Joseph A.},
title = {Noticing Notice: A Large-Scale Experiment on the Timing of Software License Agreements},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240720},
doi = {10.1145/1240624.1240720},
abstract = {Spyware is an increasing problem. Interestingly, many programs carrying spyware honestly disclose the activities of the software, but users install the software anyway. We report on a study of software installation to assess the effectiveness of different notices for helping people make better decisions on which software to install. Our study of 222 users showed that providing a short summary notice, in addition to the End User License Agreement (EULA), before the installation reduced the number of software installations significantly. We also found that providing the short summary notice after installation led to a significant number of uninstalls. However, even with the short notices, many users installed the program and later expressed regret for doing so. These results, along with a detailed analysis of installation, regret, and survey data about user behaviors informs our recommendations to policymakers and designers for assessing the "adequacy" of consent in the context of software that exhibits behaviors associated with spyware.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {607–616},
numpages = {10},
keywords = {notice, security, end user license agreement, timing, privacy, spyware},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258876,
author = {Blandford, Ann},
title = {Session Details: Empirical Models},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258876},
doi = {10.1145/3258876},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240722,
author = {Hornb\ae{}k, Kasper and Law, Effie Lai-Chong},
title = {Meta-Analysis of Correlations among Usability Measures},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240722},
doi = {10.1145/1240624.1240722},
abstract = {Understanding the relation between usability measures seems crucial to deepen our conception of usability and to select the right measures for usability studies. We present a meta-analysis of correlations among usability measures calculated from the raw data of 73 studies. Correlations are generally low: effectiveness measures (e.g., errors) and efficiency measures (e.g., time) have a correlation of .247 ± .059 (Pearson's product-moment correlation with 95% confidence interval), efficiency and satisfaction (e.g., preference) one of .196 ± .064, and effectiveness and satisfaction one of .164 ± .062. Changes in task complexity do not influence these correlations, but use of more complex measures attenuates them. Standard questionnaires for measuring satisfaction appear more reliable than homegrown ones. Measures of users' perceptions of phenomena are generally not correlated with objective measures of the phenomena. Implications for how to measure usability are drawn and common models of usability are criticized.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {617–626},
numpages = {10},
keywords = {subjective satisfaction, usability measures, meta analysis, usability evaluation, ISO 9241},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240723,
author = {Cockburn, Andy and Gutwin, Carl and Greenberg, Saul},
title = {A Predictive Model of Menu Performance},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240723},
doi = {10.1145/1240624.1240723},
abstract = {Menus are a primary control in current interfaces, but there has been relatively little theoretical work to model their performance. We propose a model of menu performance that goes beyond previous work by incorporating components for Fitts' Law pointing time, visual search time when novice, Hick-Hyman Law decision time when expert, and for the transition from novice to expert behaviour. The model is able to predict performance for many different menu designs, including adaptive split menus, items with different frequencies and sizes, and multi-level menus. We tested the model by comparing predictions for four menu designs (traditional menus, recency and frequency based split menus, and an adaptive 'morphing' design) with empirical measures. The empirical data matched the predictions extremely well, suggesting that the model can be used to explore a wide range of menu possibilities before implementation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {627–636},
numpages = {10},
keywords = {menus, adaptive behaviour, Hick-Hyman Law, performance modelling, Fitts' Law},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240724,
author = {Lank, Edward and Cheng, Yi-Chun Nikko and Ruiz, Jaime},
title = {Endpoint Prediction Using Motion Kinematics},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240724},
doi = {10.1145/1240624.1240724},
abstract = {Recently proposed novel interaction techniques such as cursor jumping [1] and target expansion for tiled arrangements [13] are predicated on an ability to effectively estimate the endpoint of an input gesture prior to its completion. However, current endpoint estimation techniques lack the precision to make these interaction techniques possible. To address a recognized lack of effective endpoint prediction mechanisms, we propose a new technique for endpoint prediction that applies established laws of motion kinematics in a novel way to the identification of motion endpoint. The technique derives a model of speed over distance that permits extrapolation. We verify our model experimentally using stylus targeting tasks, and demonstrate that our endpoint prediction is almost twice as accurate as the previously tested technique [13] at points more than twice as distant from motion endpoint.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {637–646},
numpages = {10},
keywords = {minimum jerk, kinematics, cursor prediction, Fitts' Law, motion},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258877,
author = {Brewster, Stephen},
title = {Session Details: Mobile Interaction Techniques I},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258877},
doi = {10.1145/3258877},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240726,
author = {Forlines, Clifton and Wigdor, Daniel and Shen, Chia and Balakrishnan, Ravin},
title = {Direct-Touch vs. Mouse Input for Tabletop Displays},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240726},
doi = {10.1145/1240624.1240726},
abstract = {We investigate the differences -- in terms of bothquantitative performance and subjective preference -- between direct-touch and mouse input for unimanual andbimanual tasks on tabletop displays. The results of twoexperiments show that for bimanual tasks performed ontabletops, users benefit from direct-touch input. However,our results also indicate that mouse input may be moreappropriate for a single user working on tabletop tasksrequiring only single-point interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {647–656},
numpages = {10},
keywords = {tabletop computing, multiple mice, direct-touch interfaces, bimanual input},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240727,
author = {Vogel, Daniel and Baudisch, Patrick},
title = {Shift: A Technique for Operating Pen-Based Interfaces Using Touch},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240727},
doi = {10.1145/1240624.1240727},
abstract = {Retrieving the stylus of a pen-based device takes time and requires a second hand. Especially for short intermittent interactions many users therefore choose to use their bare fingers. Although convenient, this increases targeting times and error rates. We argue that the main reasons are the occlusion of the target by the user's finger and ambiguity about which part of the finger defines the selection point. We propose a pointing technique we call Shift that is designed to address these issues. When the user touches the screen, Shift creates a callout showing a copy of the occluded screen area and places it in a non-occluded location. The callout also shows a pointer representing the selection point of the finger. Using this visual feedback, users guide the pointer into the target by moving their finger on the screen surface and commit the target acquisition by lifting the finger. Unlike existing techniques, Shift is only invoked when necessary--over large targets no callout is created and users enjoy the full performance of an unaltered touch screen. We report the results of a user study showing that with Shift participants can select small targets with much lower error rates than an unaided touch screen and that Shift is faster than Offset Cursor for larger targets.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {657–666},
numpages = {10},
keywords = {touch-screens, interaction techniques, occlusion, precise target acquisition, mobile devices},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240728,
author = {Wobbrock, Jacob O. and Chau, Duen Horng and Myers, Brad A.},
title = {An Alternative to Push, Press, and Tap-Tap-Tap: Gesturing on an Isometric Joystick for Mobile Phone Text Entry},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240728},
doi = {10.1145/1240624.1240728},
abstract = {A gestural text entry method for mobile is presented. Unlike most mobile phone text entry methods, which rely on repeatedly pressing buttons, our gestural method uses an isometric joystick and the EdgeWrite alphabet to allow users to write by making letter-like "pressure strokes." In a 15-session study comparing character-level EdgeWrite to Multitap, subjects' speeds were statistically indistinguishable, reaching about 10 WPM. In a second 15-session study comparing word-level EdgeWrite to T9, the same subjects were again statistically indistinguishable, reaching about 16 WPM. Uncorrected errors were low, around 1% or less for each method. In addition, subjective results favored EdgeWrite. Overall, results indicate that our isometric joystick-based method is highly competitive with two commercial keypad-based methods, opening the way for keypad-less designs and text entry on tiny devices. Additional results showed that a joystick on the back could be used at about 70% of the speed of the front, and the front joystick could be used eyes-free at about 80% of the speed of normal use.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {667–676},
numpages = {10},
keywords = {gestures, unistrokes, multitap, pointing, text input, smartphones, isometric joysticks, mobile phones, EdgeWrite, T9},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258878,
author = {Klemmer, Scott},
title = {Session Details: Tasks},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258878},
doi = {10.1145/3258878},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240730,
author = {Iqbal, Shamsi T. and Horvitz, Eric},
title = {Disruption and Recovery of Computing Tasks: Field Study, Analysis, and Directions},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240730},
doi = {10.1145/1240624.1240730},
abstract = {We report on a field study of the multitasking behavior of computer users focused on the suspension and resumption of tasks. Data was collected with a tool that logged users' interactions with software applications and their associated windows, as well as incoming instant messaging and email alerts. We describe methods, summarize results, and discuss design guidelines suggested by the findings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {677–686},
numpages = {10},
keywords = {notifications, interruption, task switching, attention},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240731,
author = {Rattenbury, Tye and Canny, John},
title = {CAAD: An Automatic Task Support System},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240731},
doi = {10.1145/1240624.1240731},
abstract = {Recent HCI research shows strong interest in task management systems (e.g. [19, 27]) that support the multi-tasked nature of information work [13]. These systems either require users to manually create and maintain task representations or they depend on explicit user cues to guide the creation and maintenance process. To access and use the task representations in these systems, users must also specify their current task. This interaction overhead inhibits the adoption of these systems. In this paper, we present a novel approach to task management that automates the creation and maintenance of task representations. Our system supports the user by making commonly used information more "ready-at-hand" through an intuitive visualization of their task representations. Users can correct and organize their task representations by directly manipulating the visualization; however, this interaction is not required. We describe a feasibility study that demonstrates the actual utility (in terms of overhead reduction) and perceived utility of our system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {687–696},
numpages = {10},
keywords = {information work, task, activity, context},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240732,
author = {Iqbal, Shamsi T. and Bailey, Brian P.},
title = {Understanding and Developing Models for Detecting and Differentiating Breakpoints during Interactive Tasks},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240732},
doi = {10.1145/1240624.1240732},
abstract = {The ability to detect and differentiate breakpoints during task execution is critical for enabling defer-to-breakpoint policies within interruption management. In this work, we examine the feasibility of building statistical models that can detect and differentiate three granularities (types) of perceptually meaningful breakpoints during task execution, without having to recognize the underlying tasks. We collected ecological samples of task execution data, and asked observers to review the interaction in the collected videos and identify any perceived breakpoints and their type. Statistical methods were applied to learn models that map features of the interaction to each type of breakpoint. Results showed that the models were able to detect and differentiate breakpoints with reasonably high accuracy across tasks. Among many uses, our resulting models can enable interruption management systems to better realize defer-to-breakpoint policies for interactive, free-form tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {697–706},
numpages = {10},
keywords = {breakpoints, interruption, attention, statistical models},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258879,
author = {Carroll, John},
title = {Session Details: Emergency Action},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258879},
doi = {10.1145/3258879},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240734,
author = {Toups, Zachary O. and Kerne, Andruid},
title = {Implicit Coordination in Firefighting Practice: Design Implications for Teaching Fire Emergency Responders},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240734},
doi = {10.1145/1240624.1240734},
abstract = {Fire emergency response requires rapidly processing and communicating information to coordinate teams that protect lives and property. Students studying to become fire emergency responders must learn to communicate, process, and integrate information during dangerous, stressful, and time-sensitive work. We are performing an ethnographic investigation that includes interviews with experienced fire emergency responders and observations of team burn training exercises with students. We distill salient components of firefighting practice, which are relevant to the design of fire emergency response education systems. We derive design implications for systems that teach fire emergency responders to deal with issues surrounding the communication and integration of fireground information: the mixing of communication modalities, the distribution of information acquisition sources to create information differential and uncertainty, and audible clues.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {707–716},
numpages = {10},
keywords = {emergency response, firefighting, distributed cognition, team cognition, implicit coordination, ethnography},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240735,
author = {Aoki, Paul M.},
title = {Back Stage on the Front Lines: Perspectives and Performance in the Combat Information Center},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240735},
doi = {10.1145/1240624.1240735},
abstract = {While tactical command. control and communication environments might appear to be entirely instrumental in nature, they nevertheless provide a setting for social interaction. This paper describes how such interaction occurs in a particular naval tactical command and control system, focusing on the shared perspectives created by the organizational, administrative and professional aspects of the environment and on issues of self-presentation. It is argued that the complexity and multiplicity of interactional regions in this environment lead to problematic situations for key actors, and that these problems may have relevance to future computing environments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {717–726},
numpages = {10},
keywords = {self-presentation, social worlds, tactical data systems, command, control and communication},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240736,
author = {Palen, Leysia and Liu, Sophia B.},
title = {Citizen Communications in Crisis: Anticipating a Future of ICT-Supported Public Participation},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240736},
doi = {10.1145/1240624.1240736},
abstract = {Recent world-wide crisis events have drawn new attention to the role information communication technology (ICT) can play in warning and response activities. Drawing on disaster social science, we consider a critical aspect of post-impact disaster response that does not yet receive much information science research attention. Public participation is an emerging, large-scale arena for computer-mediated interaction that has implications for both informal and formal response. With a focus on persistent citizen communications as one form of interaction in this arena, we describe their spatial and temporal arrangements, and how the emerging information pathways that result serve different post-impact functions. However, command-and-control models do not easily adapt to the expanding data-generating and -seeking activities by the public. ICT in disaster contexts will give further rise to improvised activities and temporary organizations with which formal response organizations need to align.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {727–736},
numpages = {10},
keywords = {crisis, volunteerism, peer to peer, crises, NIMS, disasters, extreme events, policy, grassroots},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258880,
author = {Harrison, Steve},
title = {Session Details: Design Methods},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258880},
doi = {10.1145/3258880},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240738,
author = {Ljungblad, Sara and Holmquist, Lars Erik},
title = {Transfer Scenarios: Grounding Innovation with Marginal Practices},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240738},
doi = {10.1145/1240624.1240738},
abstract = {Transfer scenarios is a method developed to support the design of innovative interactive technology. Such a method should help the designer to come up with inventive ideas, and at the same time provide grounding in real human needs. In transfer scenarios, we use marginal practices to encourage a changed mindset throughout the design process. A marginal practice consists of individuals who share an activity that they find meaningful. We regard these individuals not as end-users, but as valuable input in the design process. We applied this method when designing novel applications for autonomous embodied agents, e.g. robots. Owners of unusual pets, such as snakes and spiders, were interviewed - not with the intention to design robot pets, but to determine underlying needs and interests of their practice. The results were then used to design a set of applications for more general users, including a dynamic living-room wall and a set of communicating hobby robots.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {737–746},
numpages = {10},
keywords = {grounded innovation, transfer scenarios, marginal practice, design methods},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240739,
author = {Butler, Keith A. and Zhang, Jiajie and Esposito, Chris and Bahrami, Ali and Hebron, Ron and Kieras, David},
title = {Work-Centered Design: A Case Study of a Mixed-Initiative Scheduler},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240739},
doi = {10.1145/1240624.1240739},
abstract = {We present the case study of a complex, mixed-initiative scheduling system to illustrate Work-Centered Design (WCD), a new approach for the design of information systems. WCD is based on theory of distributed cognition and extends established user-centered methods with abstract task modeling, using innovative techniques for work ontology and top-level algorithms to capture the logic of a human-computer interaction paradigm. WCD addresses a long-standing need for more effective methods of function allocation. The illustrating case study succeeded on a large, difficult problem for aircraft scheduling where prior expensive attempts failed. The new system, called Solver, reduces scheduling labor from 9 person-days a week to about 1 person-hour. These results were obtained from the first user test, demonstrating notable effectiveness of WCD. Further, the value of Solver's higher quality schedules is far-reaching. WCD extends HCI methods to fill an important need for technical problem-solving systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {747–756},
numpages = {10},
keywords = {design, methodology, business process reengineering, requirements analysis, mixed-initiative, work ontology, scheduling, top-level algorithm, work-centered, user interface},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258881,
author = {Zhai, Shumin},
title = {Session Details: Mobile Interaction Techniques II},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258881},
doi = {10.1145/3258881},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240741,
author = {Ramos, Gonzalo and Cockburn, Andy and Balakrishnan, Ravin and Beaudouin-Lafon, Michel},
title = {Pointing Lenses: Facilitating Stylus Input through Visual-and Motor-Space Magnification},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240741},
doi = {10.1145/1240624.1240741},
abstract = {Using a stylus on a tablet computer to acquire small targets can be challenging. In this paper we present pointing lenses -- interaction techniques that help users acquire and select targets by presenting them with an enlarged visual and interaction area. We present and study three pointing lenses for pen-based systems and find that our proposed Pressure-Activated Lens is the top overall performer in terms of speed, accuracy and user preference. In addition, our experimental results not only show that participants find all pointing lenses beneficial for targets smaller than 5 pixels, but they also suggest that this benefit may extend to larger targets as well.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {757–766},
numpages = {10},
keywords = {zooming, pen input, lenses, pressure widgets},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240742,
author = {Seager, Will and Fraser, Danae Stanton},
title = {Comparing Physical, Automatic and Manual Map Rotation for Pedestrian Navigation},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240742},
doi = {10.1145/1240624.1240742},
abstract = {It is well-established finding that people find maps easier to use when they are aligned so that "up" on the map corresponds to the user's forward direction. With map-based applications on handheld mobile devices, this forward/up correspondence can be maintained in several ways: the device can be physically rotated within the user's hands or the user can manually operate buttons to digitally rotate the map; alternatively, the map can be rotated automatically using data from an electronic compass. This paper examines all three options. In a field experiment, each method is compared against a baseline north-up condition. The study provides strong evidence that physical rotation is the most effective with applications that present the user with a wider map. The paper concludes with some suggestions for design improvements.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {767–776},
numpages = {10},
keywords = {automatic rotation, mobile computing, egocentric maps},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258882,
author = {Shen, Chia},
title = {Session Details: Tangibility},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258882},
doi = {10.1145/3258882},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240744,
author = {LeClerc, Vincent and Parkes, Amanda and Ishii, Hiroshi},
title = {Senspectra: A Computationally Augmented Physical Modeling Toolkit for Sensing and Visualization of Structural Strain},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240744},
doi = {10.1145/1240624.1240744},
abstract = {We present Senspectra, a computationally augmented physical modeling toolkit designed for sensing and visualization of structural strain. Senspectra seeks to explore a new direction in computational materiality, incorporating the material quality of malleable elements of an interface into its digital control structure. The system functions as a decentralized sensor network consisting of nodes, embedded with computational capabilities and a full spectrum LED, and flexible joints. Each joint functions as an omnidirectional bend sensing mechanism to sense and communicate mechanical strain between neighboring nodes.Using Senspectra, a user incrementally assembles and refines a physical 3D model of discrete elements with a real-time visualization of structural strain. While the Senspectra infrastructure provides a flexible modular sensor network platform, its primary application derives from the need to couple physical modeling techniques utilized in architecture and design disciplines with systems for structural engineering analysis. This offers direct manipulation augmented with visual feedback for an intuitive approach to physical real-time finite element analysis, particularly for organic forms.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {801–804},
numpages = {4},
keywords = {structural analysis, 3D visualization, materiality, tangible user interface},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240745,
author = {Fjeld, Morten and Fredriksson, Jonas and Ejdestig, Martin and Duca, Florin and B\"{o}tschi, Kristina and Voegtli, Benedikt and Juchli, Patrick},
title = {Tangible User Interface for Chemistry Education: Comparative Evaluation and Re-Design},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240745},
doi = {10.1145/1240624.1240745},
abstract = {Augmented Chemistry (AC) is an application that utilizes a tangible user interface (TUI) for organic chemistry education. The empirical evaluation described in this paper compares learning effectiveness and user acceptance of AC versus the more traditional ball-and-stick model (BSM). Learning effectiveness results were almost the same for both learning environments. User preference and rankings, using NASA-TLX and SUMI, showed more differences and it was therefore decided to focus mainly on improving these aspects in a re-design of the AC system. For enhanced interaction, keyboard-free system configuration, and internal/external database (DB) access, a graphical user interface (GUI) has been incorporated into the TUI. Three-dimensional (3D) rendering has also been improved using shadows and related effects, thereby enhancing depth perception. The re-designed AC system was then compared to the old system by means of a small qualitative user study. This user study showed an improvement in subjective opinions a out the system's ease of use and ease of learning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {805–808},
numpages = {4},
keywords = {comparison, augmented reality, evaluation, education, octet rule, tangible user interface},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240746,
author = {Patten, James and Ishii, Hiroshi},
title = {Mechanical Constraints as Computational Constraints in Tabletop Tangible Interfaces},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240746},
doi = {10.1145/1240624.1240746},
abstract = {This paper presents a new type of human-computer interface called Pico (Physical Intervention in Computational Optimization) based on mechanical constraints that combines some of the tactile feedback and affordances of mechanical systems with the abstract computational power of modern computers. The interface is based on a tabletop interaction surface that can sense and move small objects on top of it. The positions of these physical objects represent and control parameters inside a software application, such as a system for optimizing the configuration of radio towers in a cellular telephone network. The computer autonomously attempts to optimize the network, moving the objects on the table as it changes their corresponding parameters in software. As these objects move, the user can constrain their motion with his or her hands, or many other kinds of physical objects. The interface provides ample opportunities for improvisation by allowing the user to employ a rich variety of everyday physical objects as mechanical constraints. This approach leverages the user's mechanical intuition for how objects respond to physical forces. As well, it allows the user to balance the numerical optimization performed by the computer with other goals that are difficult to quantify. Subjects in an evaluation were more effective at solving a complex spatial layout problem using this system than with either of two alternative interfaces that did not feature actuation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {809–818},
numpages = {10},
keywords = {physical interaction, actuation, interactive surface, improvisation, tangible interfaces},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240747,
author = {Costanza, Enrico and Inverso, Samuel A. and Allen, Rebecca and Maes, Pattie},
title = {Intimate Interfaces in Action: Assessing the Usability and Subtlety of Emg-Based Motionless Gestures},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240747},
doi = {10.1145/1240624.1240747},
abstract = {Mobile communication devices, such as mobile phones and networked personal digital assistants (PDAs), allow users to be constantly connected and communicate anywhere and at any time, often resulting in personal and private communication taking place in public spaces. This private -- public contrast can be problematic. As a remedy, we promote intimate interfaces: interfaces that allow subtle and minimal mobile interaction, without disruption of the surrounding environment. In particular, motionless gestures sensed through the electromyographic (EMG) signal have been proposed as a solution to allow subtle input in a mobile context. In this paper we present an expansion of the work on EMG-based motionless gestures including (1) a novel study of their usability in a mobile context for controlling a realistic, multimodal interface and (2) a formal assessment of how noticeable they are to informed observers. Experimental results confirm that subtle gestures can be profitably used within a multimodal interface and that it is difficult for observers to guess when someone is performing a gesture, confirming the hypothesis of subtlety.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {819–828},
numpages = {10},
keywords = {subtle interaction, mobile computing, wearable computing, social acceptance, intimate interface, motionless gestures, electromyogram},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258883,
author = {Gutwin, Carl},
title = {Session Details: Games},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258883},
doi = {10.1145/3258883},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240749,
author = {Seay, A. Fleming and Kraut, Robert E.},
title = {Project Massive: Self-Regulation and Problematic Use of Online Gaming},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240749},
doi = {10.1145/1240624.1240749},
abstract = {A longitudinal design was employed to collect three waves of survey data over a 14 month period from 2790 online gamers. Respondents were asked questions about their gaming activity, motivations, personality, social and emotional environment, and the effect gaming has had on their lives. Prospective analysis was used to establish causal and temporal linkages among the repeatedly measured factors. While the data provide some indication that a player's reasons for playing do influence the development of problematic usage, these effects are overshadowed by the central importance of self-regulation in managing both the timing and amount of play. An individual's level of self-regulatory activity is shown to be very important in allowing them to avoid negative outcomes like problematic use. The role of depression is also discussed. With responsible use, online gaming appears to be a healthy recreational activity that provides millions of people with hours of social entertainment and adaptive diversion. However, failure to manage play behavior can lead to feelings of dependency.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {829–838},
numpages = {10},
keywords = {self-regulation, addiction, online games, play motivation, MMORPG, depression, social integration},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240750,
author = {Ducheneaut, Nicolas and Yee, Nicholas and Nickell, Eric and Moore, Robert J.},
title = {The Life and Death of Online Gaming Communities: A Look at Guilds in World of Warcraft},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240750},
doi = {10.1145/1240624.1240750},
abstract = {Massively multiplayer online games (MMOGs) can be fascinating laboratories to observe group dynamics online. In particular, players must form persistent associations or "guilds" to coordinate their actions and accomplish the games' toughest objectives. Managing a guild, however, is notoriously difficult and many do not survive very long. In this paper, we examine some of the factors that could explain the success or failure of a game guild based on more than a year of data collected from five World of Warcraft servers. Our focus is on structural properties of these groups, as represented by their social networks and other variables. We use this data to discuss what games can teach us about group dynamics online and, in particular, what tools and techniques could be used to better support gaming communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {839–848},
numpages = {10},
keywords = {social networks, group dynamics, data analysis tools, massively multiplayer online games, online communities},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240751,
author = {Batcheller, Archer L. and Hilligoss, Brian and Nam, Kevin and Rader, Emilee and Rey-Babarro, Marta and Zhou, Xiaomu},
title = {Testing the Technology: Playing Games with Video Conferencing},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240751},
doi = {10.1145/1240624.1240751},
abstract = {Video connections can establish a media space in which games may be played, just as people play games while collocated. Experiments with participants playing the game 'Mafia' indicate that people in a video condition have similar levels of satisfaction, fun, and frustration, to those that play while collocated. This finding holds for both those with prior experience using video systems and those without, suggesting it is not merely a "novelty effect." Results differ about whether there exist differences in focus of attention, suspicion/trust, and pointing for people playing the game while using a video system. Implications for both fun and work uses of video are suggested.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {849–852},
numpages = {4},
keywords = {games, video mediated communication, social interaction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240752,
author = {Nenonen, Ville and Lindblad, Aleksi and H\"{a}kkinen, Ville and Laitinen, Toni and Jouhtio, Mikko and H\"{a}m\"{a}l\"{a}inen, Perttu},
title = {Using Heart Rate to Control an Interactive Game},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240752},
doi = {10.1145/1240624.1240752},
abstract = {This paper presents a novel way of using real-time heart rate information to control a physically interactive biathlon (skiing and shooting) computer game. Instead of interfacing the game to an exercise bike or other equipment with speed output, the skiing speed is directly proportional to heart rate. You can freely choose the form of physical exercise, which makes it easier for people with different skill levels and backgrounds to play together. The system can be used with any exercise machine or form. To make playing meaningful instead of simply exercising as hard as you can, a high heart rate impedes the shooting part of the game by making the sight less steady. This balancing mechanism lets the player try out different tactics, varying from very slow skiing and sharp shooting to fast skiing and random shooting. The game has been evaluated in a user study with eight participants. The results show that heart rate interaction is fun and usable interaction method.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {853–856},
numpages = {4},
keywords = {physically interactive computer game, unconventional computer human interfaces, heart rate interaction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258884,
author = {Mackay, Wendy},
title = {Session Details: Video},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258884},
doi = {10.1145/3258884},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240754,
author = {O'Hara, Kenton and Mitchell, April Slayden and Vorbau, Alex},
title = {Consuming Video on Mobile Devices},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240754},
doi = {10.1145/1240624.1240754},
abstract = {Mobile video is now an everyday possibility with a wide array of commercially available devices, services and content. These technologies promise to transform the way that people can consume video media in their lives beyond the familiar behaviours associated with fixed TV and video technologies. Building upon earlier studies of mobile video, this paper reports on a study using diary techniques and ethnographic interviews to better understand how people are using commercially available mobile video technologies in their everyday lives. Drawing on reported episodes of mobile video behaviour, the study identifies the social motivations and values underpinning these behaviours that help characterise mobile video consumption beyond the simplistic notion of viewing TV to kill time wherever you may be. Implications for adoption and design of mobile video technologies and services are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {857–866},
numpages = {10},
keywords = {mobile video, interviews, mobility, mobile TV, diary study},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240755,
author = {Song, Yaxiao and Marchionini, Gary},
title = {Effects of Audio and Visual Surrogates for Making Sense of Digital Video},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240755},
doi = {10.1145/1240624.1240755},
abstract = {Video surrogates are meant to help people quickly make sense of the content of a video before downloading or seeking more detailed information. In this paper we present the results of a study comparing the effectiveness of three different surrogates for objects in digital video libraries. Thirty-six people participated in a within subjects user study in which they did five tasks for each of three surrogate alternatives: visual alone (a storyboard), audio alone (spoken description), and combined visual and audio (a storyboard augmented with spoken description). The results show that combined surrogates are more effective, strongly preferred, and do not penalize efficiency. The results also demonstrate that spoken descriptions alone lead to better understanding of the video segments than do visual storyboards alone, although people like to have visual surrogates and use them to confirm interpretations and add context. Participants were able to easily use the combined surrogates even though they were not synchronized, suggesting that synchronization of different media channels may not be necessary in surrogates as it is in full video. The results suggest that multimodal surrogates should be incorporated into video retrieval user interfaces and audio surrogates should be used in small display interfaces. The study also raises questions about the need to synchronize different information channels in multimedia surrogates.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {867–876},
numpages = {10},
keywords = {dual coding, video surrogates, multimedia},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240756,
author = {Weisz, Justin D. and Kiesler, Sara and Zhang, Hui and Ren, Yuqing and Kraut, Robert E. and Konstan, Joseph A.},
title = {Watching Together: Integrating Text Chat with Video},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240756},
doi = {10.1145/1240624.1240756},
abstract = {Watching video online is becoming increasingly popular, and new video streaming technologies have the potential to transform video watching from a passive, isolating experience into an active, socially engaging experience. However, the viability of an active social experience is unclear: both chatting and watching video require attention, and may interfere with one another and detract from the experience. In this paper, we empirically examine the activity of chatting while watching video online. We examine how groups of friends and strangers interact, and find that chat has a positive influence on social relationships, and people chat despite being distracted. We discuss the benefits and opportunities provided by mixing chat and video, uncover some of the attentional and social challenges inherent in this combination of media, and provide guidance for structuring the viewing experience.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {877–886},
numpages = {10},
keywords = {interactive television, social TV, friends, chat, strangers, video},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258885,
author = {Jensen, Carlos},
title = {Session Details: Security},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258885},
doi = {10.1145/3258885},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240758,
author = {Moncur, Wendy and Lepl\^{a}tre, Gr\'{e}gory},
title = {Pictures at the ATM: Exploring the Usability of Multiple Graphical Passwords},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240758},
doi = {10.1145/1240624.1240758},
abstract = {Users gain access to cash, confidential information and services at Automated Teller Machines (ATMs) via an authentication process involving a Personal Identification Number (PIN). These users frequently have many different PINs, and fail to remember them without recourse to insecure behaviours. This is not a failing of users. It is a usability failing in the ATM authentication mechanism. This paper describes research executed to evaluate whether users find multiple graphical passwords more memorable than multiple PINs. The research also investigates the success of two memory augmentation strategies in increasing memorability of graphical passwords. The results demonstrate that multiple graphical passwords are substantially more effective than multiple PIN numbers. Memorability is further improved by the use of mnemonics to aid their recall.This study will be of interest to HCI practitioners and information security researchers exploring approaches to usable security.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {887–894},
numpages = {8},
keywords = {graphical passwords, usable security, ATMs, user authentication, authentication mechanisms},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240759,
author = {Singh, Supriya and Cabraal, Anuja and Demosthenous, Catherine and Astbrink, Gunela and Furlong, Michele},
title = {Password Sharing: Implications for Security Design Based on Social Practice},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240759},
doi = {10.1145/1240624.1240759},
abstract = {Current systems for banking authentication require that customers not reveal their access codes, even to members of the family. A study of banking and security in Australia shows that the practice of sharing passwords does not conform to this requirement. For married and de facto couples, password sharing is seen as a practical way of managing money and a demonstration of trust. Sharing Personal Identification Numbers (PINs) is a common practice among remote indigenous communities in Australia. In areas with poor banking access, this is the only way to access cash. People with certain disabilities have to share passwords with carers, and PIN numbers with retail clerks. In this paper we present the findings of a qualitative user study of banking and money management. We suggest design criteria for banking security systems, based on observed social and cultural practices of password and PIN number sharing.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {895–904},
numpages = {10},
keywords = {social and cultural centered design, Australia, banking, UCD, security, sharing passwords},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240760,
author = {Kumaraguru, Ponnurangam and Rhee, Yong and Acquisti, Alessandro and Cranor, Lorrie Faith and Hong, Jason and Nunge, Elizabeth},
title = {Protecting People from Phishing: The Design and Evaluation of an Embedded Training Email System},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240760},
doi = {10.1145/1240624.1240760},
abstract = {Phishing attacks, in which criminals lure Internet users to websites that impersonate legitimate sites, are occurring with increasing frequency and are causing considerable harm to victims. In this paper we describe the design and evaluation of an embedded training email system that teaches people about phishing during their normal use of email. We conducted lab experiments contrasting the effectiveness of standard security notices about phishing with two embedded training designs we developed. We found that embedded training works better than the current practice of sending security notices. We also derived sound design principles for embedded training systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {905–914},
numpages = {10},
keywords = {phishing, situated learning, email, embedded training, usable privacy and security},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258886,
author = {Schiano, Diane},
title = {Session Details: Emotion &amp; Empathy},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258886},
doi = {10.1145/3258886},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240762,
author = {Mahlke, Sascha and Th\"{u}ring, Manfred},
title = {Studying Antecedents of Emotional Experiences in Interactive Contexts},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240762},
doi = {10.1145/1240624.1240762},
abstract = {This paper describes a research approach to the experimental study of emotional experiences and their connections to other components of user experience in human-technology interaction. We present a model of user experience that integrates interaction characteristics, instrumental and non-instrumental quality perceptions, emotional user reactions and overall judgments of system quality. An experiment is reported to illustrate the application of our approach. System properties of an interactive prototype were varied to produce versions of different usability and aesthetics which in turn led to different perceptions of instrumental and non-instrumental qualities. The results indicate that both quality aspects significantly influence emotional reactions with respect to subjective feelings, facial expressions and physiological responses. These findings are consistent with the users' overall judgments of the systems and show that the perception of both, instrumental and non-instrumental qualities influences the appraisal of interactive systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {915–918},
numpages = {4},
keywords = {aesthetics, user experience, emotions, usability, physiological methods},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240763,
author = {Pfeil, Ulrike and Zaphiris, Panayiotis},
title = {Patterns of Empathy in Online Communication},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240763},
doi = {10.1145/1240624.1240763},
abstract = {This article presents an investigation of empathy within an online community for older people (SeniorNet). Qualitative content analysis of 400 messages from a discussion board about depression was used to determine how empathy is expressed and facilitated in online communication. Special emphasis was placed on determining the components of online empathy. A code scheme that we developed to analyse online empathy is also presented. The findings were compared to offline studies about empathy in order to investigate the influence that the mediating technology has on the phenomenon.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {919–928},
numpages = {10},
keywords = {older people, computer-mediated communication, inclusive design, online community, social aspects of computing, empathy},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240764,
author = {Hancock, Jeffrey T. and Landrigan, Christopher and Silver, Courtney},
title = {Expressing Emotion in Text-Based Communication},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240764},
doi = {10.1145/1240624.1240764},
abstract = {Our ability to express and accurately assess emotional states is central to human life. The present study examines how people express and detect emotions during text-based communication, an environment that eliminates the nonverbal cues typically associated with emotion. The results from 40 dyadic interactions suggest that users relied on four strategies to express happiness versus sadness, including disagreement, negative affect terms, punctuation, and verbosity. Contrary to conventional wisdom, communication partners readily distinguished between positive and negative valence emotional communicators in this text-based context. The results are discussed with respect to the Social Information Processing model of strategic relational adaptation in mediated communication.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {929–932},
numpages = {4},
keywords = {affect, computer-mediated communication, emotion, linguistic},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240765,
author = {Swindells, Colin and MacLean, Karon E. and Booth, Kellogg S. and Meitner, Michael J.},
title = {Exploring Affective Design for Physical Controls},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240765},
doi = {10.1145/1240624.1240765},
abstract = {Physical controls such as knobs, sliders, and buttons are experiencing a revival as many computing systems progress from personal computing architectures towards ubiquitous computing architectures. We demonstrate a process for measuring and comparing visceral emotional responses of a physical control to performance results of a target acquisition task. In our user study, participants experienced mechanical and rendered friction, inertia, and detent dynamics as they turned a haptic knob towards graphical targets of two different widths and amplitudes. Together, this process and user study provide novel affect- and performance-based design guidance to developers of physical controls for emerging ubiquitous computing environments. Our work bridges extensive human factors work in mechanical systems that peaked in the 1960's, to contemporary trends, with a goal of integrating mechatronic controls into emerging ubiquitous computing systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {933–942},
numpages = {10},
keywords = {physical control, rotary Fitts-like task, knob, affect, haptic display, design process},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258887,
author = {Kellogg, Wendy},
title = {Session Details: Collaboration at Work},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258887},
doi = {10.1145/3258887},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240767,
author = {Little, Greg and Lau, Tessa A. and Cypher, Allen and Lin, James and Haber, Eben M. and Kandogan, Eser},
title = {Koala: Capture, Share, Automate, Personalize Business Processes on the Web},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240767},
doi = {10.1145/1240624.1240767},
abstract = {We present Koala, a system that enables users to capture, share, automate, and personalize business processes on the web. Koala is a collaborative programming-by-demonstration system that records, edits, and plays back user interactions as pseudo-natural language scripts that are both human- and machine-interpretable. Unlike previous programming by demonstration systems, Koala leverages sloppy programming that interprets pseudo-natural language instructions (as opposed to formal syntactic statements) in the context of a given web page's elements and actions. Koala scripts are automatically stored in the Koalescence wiki, where a community of users can share, run, and collaboratively develop their "how-to" knowledge. Koala also takes advantage of corporate and personal data stores to automatically generalize and instantiate user-specific data, so that scripts created by one user are automatically personalized for others. Our initial experiences suggest that Koala is surprisingly effective at interpreting instructions originally written for people.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {943–946},
numpages = {4},
keywords = {Wiki, programming by demonstration, end-user programming, automation},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240768,
author = {Brush, A.J. Bernheim and Meyers, Brian R. and Tan, Desney S. and Czerwinski, Mary},
title = {Understanding Memory Triggers for Task Tracking},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240768},
doi = {10.1145/1240624.1240768},
abstract = {Software can now track which computer applications and documents you use. This provides us with the potential to help end-users recall past activities for tasks such as status reporting. We describe findings from field observations of eight participants writing their status reports. We observed interesting trends, including the reliance on memory triggers, which were either retrieved from explicit self-reminders, from implicit breadcrumbs left while performing their tasks or directly from memory. Participants perceived spending relatively short amounts of time composing their status reports, suggesting that any technology solution must offer dramatic improvements over current practice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {947–950},
numpages = {4},
keywords = {office, field study, status reports, information worker},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240769,
author = {Tang, John C. and Drews, Clemens and Smith, Mark and Wu, Fei and Sue, Alison and Lau, Tessa},
title = {Exploring Patterns of Social Commonality among File Directories at Work},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240769},
doi = {10.1145/1240624.1240769},
abstract = {We studied files stored by members of a work organization for patterns of social commonality. Discovering identical or similar documents, applications, developer libraries, or other files may suggest shared interests or experience among users. Examining actual file data revealed a number of individual and aggregate practices around file storage. For example, pairs of users typically have many (over 13,000) files in common. A prototype called LiveWire exploits this commonality to make file backup and restore more efficient for a work organization. We removed commonly shared files and focused on specific filetypes that represent user activity to find more meaningful files in common. The Consolidarity project explores how patterns of file commonality could encourage social networking in an organizational context. Mechanisms for addressing the privacy concerns raised by this approach are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {951–960},
numpages = {10},
keywords = {social networking, usage logs, file management, enterprise work setting, social recommendation, CSCW},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240770,
author = {Perugini, Saverio and Anderson, Taylor J. and Moroney, William F.},
title = {A Study of Out-of-Turn Interaction in Menu-Based, IVR, Voicemail Systems},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240770},
doi = {10.1145/1240624.1240770},
abstract = {We present the first user study of out-of-turn interaction inmenu-based, interactive voice-response systems. Out-of-turn interaction is atechnique which empowers the user (unable to respond to the current prompt) totake the conversational initiative by supplying information that is currentlyunsolicited, but expected later in the dialog. The technique permits the userto circumvent any flows of navigation hardwired into the design and navigatethe menus in a manner which reflects their model of the task. We conducted alaboratory experiment to measure the effect of the use of out-of-turninteraction on user performance and preference in a menu-based, voice interfaceto voicemail. Specifically, we compared two interfaces with the exact samehierarchical menu design: one with the capability of accepting out-of-turnutterances and one without this feature. The results indicate that out-of-turninteraction significantly reduces task completion time, improves usability, andis preferred to the baseline. This research studies an unexplored dimension ofthe design space for automated telephone services, namely the nature ofuser-addressable input (utterance) supplied (in-turn vs. out-of-turn), incontrast to more traditional dimensions such as input modality (touch-tone vs.text vs. voice) and style of interaction (menu-based vs. natural language).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {961–970},
numpages = {10},
keywords = {usability, speech user interfaces, user studies, out-of-turn interaction, mixed-initiative interaction, interactive voice-response systems (IVRs), automatic speech recognition (ASR), automated telephone services (ATS)},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258888,
author = {Venolia, Gina},
title = {Session Details: Tags, Tagging &amp; Notetaking},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258888},
doi = {10.1145/3258888},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240772,
author = {Ames, Morgan and Naaman, Mor},
title = {Why We Tag: Motivations for Annotation in Mobile and Online Media},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240772},
doi = {10.1145/1240624.1240772},
abstract = {Why do people tag? Users have mostly avoided annotating media such as photos -- both in desktop and mobile environments -- despite the many potential uses for annotations, including recall and retrieval. We investigate the incentives for annotation in Flickr, a popular web-based photo-sharing system, and ZoneTag, a cameraphone photo capture and annotation tool that uploads images to Flickr. In Flickr, annotation (as textual tags) serves both personal and social purposes, increasing incentives for tagging and resulting in a relatively high number of annotations. ZoneTag, in turn, makes it easier to tag cameraphone photos that are uploaded to Flickr by allowing annotation and suggesting relevant tags immediately after capture.A qualitative study of ZoneTag/Flickr users exposed various tagging patterns and emerging motivations for photo annotation. We offer a taxonomy of motivations for annotation in this system along two dimensions (sociality and function), and explore the various factors that people consider when tagging their photos. Our findings suggest implications for the design of digital photo organization and sharing applications, as well as other applications that incorporate user-based annotation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {971–980},
numpages = {10},
keywords = {motivations, collection organization, incentives, CSCW, tagging, location-aware, cameraphone, digital photographs, photo sharing, annotation},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240773,
author = {Bauer, Aaron and Koedinger, Kenneth R.},
title = {Selection-Based Note-Taking Applications},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240773},
doi = {10.1145/1240624.1240773},
abstract = {The increasing integration of education and technology has led to the development of a range of note-taking applications. Our project's goal is to provide empirical data to guide the design of such note-taking applications by evaluating the behavioral and learning outcomes of different note-taking functionality. The study reported here compares note-taking using a text editor and four interaction techniques. The two standard techniques are typing and copy-paste. The two novel techniques are restricted copy-paste and menu-selection, intended to increase attention and processing respectively. Hypothesized learning gains from the novel techniques were not observed. As implemented these techniques were less efficient and appeared to be more frustrating to use. However, data regarding differences in both note-taking efficiency and learning suggest several important implications for selection-based note-taking applications, such as pasting and highlighting. Our results also indicate that students have strong opinions regarding their note-taking practices, which may complicate potentially beneficial interventions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {981–990},
numpages = {10},
keywords = {annotation, note-taking, copy-paste, education},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240774,
author = {M\"{a}kel\"{a}, Kaj and Belt, Sara and Greenblatt, Dan and H\"{a}kkil\"{a}, Jonna},
title = {Mobile Interaction with Visual and RFID Tags: A Field Study on User Perceptions},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240774},
doi = {10.1145/1240624.1240774},
abstract = {In this paper, we present a study of user perceptions on mobile interaction with visual and RFID tags. Although mobile interaction with tags has been proposed in several earlier studies, user perceptions and usability comparisons of different tag technologies have not been intensively investigated. In contrast to earlier studies, which report on user studies with evaluating new concepts or interaction techniques, we take another approach and examine the current understanding of the techniques and user perceptions on them. Our field study of 50 users charts currently existing user perceptions and reveals potential usability risks that are due to the limited or erroneous understanding of the interaction technique.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {991–994},
numpages = {4},
keywords = {RFID, mobile interaction, user studies, visual tags},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240775,
author = {Rivadeneira, A. W. and Gruen, Daniel M. and Muller, Michael J. and Millen, David R.},
title = {Getting Our Head in the Clouds: Toward Evaluation Studies of Tagclouds},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240775},
doi = {10.1145/1240624.1240775},
abstract = {Tagclouds are visual presentations of a set of words, typically a set of "tags" selected by some rationale, in which attributes of the text such as size, weight, or color are used to represent features, such as frequency, of the associated terms. This note describes two studies to evaluate the effectiveness of differently constructed tagclouds for the various tasks they can be used to support, including searching, browsing, impression formation and recognition. Based on these studies, we propose a paradigm for evaluating tagclouds and ultimately guidelines for tagcloud construction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {995–998},
numpages = {4},
keywords = {evaluation, visualization, tagcloud, tagging, folksonomy, social software},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258889,
author = {Cuttrell, Ed},
title = {Session Details: Multimodal Interactions},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258889},
doi = {10.1145/3258889},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240777,
author = {Shoemaker, Garth and Gutwin, Carl},
title = {Supporting Multi-Point Interaction in Visual Workspaces},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240777},
doi = {10.1145/1240624.1240777},
abstract = {Multi-point interaction tasks involve the manipulation of several mutually-dependent control points in a visual workspace -- for example, adjusting a selection rectangle in a drawing application. Multi-point interactions place conflicting requirements on the interface: the system must display objects at sufficient scale for detailed manipulation, but it must also provide an efficient means of navigating from one control point to another. Current interfaces lack any explicit support for tasks that combine these two requirements, forcing users to carry out sequences of zoom and pan actions. In this paper, we describe three novel mechanisms for view control that explicitly support multi-point interactions with a single mouse, and preserve both visibility and scale for multiple regions of interest. We carried out a study to compare two of the designs against standard zoom and pan techniques, and found that task completion time was significantly reduced with the new approaches. The study shows the potential of interfaces that combine support for both scale and navigation.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {999–1008},
numpages = {10},
keywords = {visual workspaces, fisheye views, multi-point interaction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240778,
author = {Kaiser, Edward C. and Barthelmess, Paulo and Erdmann, Candice and Cohen, Phil},
title = {Multimodal Redundancy across Handwriting and Speech during Computer Mediated Human-Human Interactions},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240778},
doi = {10.1145/1240624.1240778},
abstract = {Lecturers, presenters and meeting participants often say what they publicly handwrite. In this paper, we report on three empirical explorations of such multimodal redundancy -- during whiteboard presentations, during a spontaneous brainstorming meeting, and during the informal annotation and discussion of photographs. We show that redundantly presented words, compared to other words used during a presentation or meeting, tend to be topic specific and thus are likely to be out-of-vocabulary. We also show that they have significantly higher tf-idf (term frequency-inverse document frequency) weights than other words, which we argue supports the hypothesis that they are dialogue-critical words. We frame the import of these empirical findings by describing SHACER, our recently introduced Speech and HAndwriting reCognizER, which can combine information from instances of redundant handwriting and speech to dynamically learn new vocabulary.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1009–1018},
numpages = {10},
keywords = {speech, handwriting, multimodal},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258890,
author = {Fussell, Susan},
title = {Session Details: Distributed Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258890},
doi = {10.1145/3258890},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240780,
author = {Ding, Xianghua and Erickson, Thomas and Kellogg, Wendy A. and Levy, Stephen and Christensen, James E. and Sussman, Jeremy and Wolf, Tracee Vetting and Bennett, William E.},
title = {An Empirical Study of the Use of Visually Enhanced Voip Audio Conferencing: The Case of IEAC},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240780},
doi = {10.1145/1240624.1240780},
abstract = {IBM Enhanced Audio Conferencing (IEAC) is a VoIP-based audio conferencing system that, like several other systems, provides a visualization showing who is present and their states (e.g., speaking, muted). This paper presents the first study of the use of such a system. Drawing on log files collected over six weeks of use by over 1300 corporate employees, and interviews with 10 of them, we look at how and why various features of the system are used and what sorts of practices are supported. Our findings shed light on the factors that drive the use of visual enhancements to audio conferencing, and suggest further research topics.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1019–1028},
numpages = {10},
keywords = {telephony, voice, social translucence, conference call, audio conferencing, social visualization, VoIP, social proxy},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240781,
author = {Heer, Jeffrey and Vi\'{e}gas, Fernanda B. and Wattenberg, Martin},
title = {Voyagers and Voyeurs: Supporting Asynchronous Collaborative Information Visualization},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240781},
doi = {10.1145/1240624.1240781},
abstract = {This paper describes mechanisms for asynchronous collaboration in the context of information visualization, recasting visualizations as not just analytic tools, but social spaces. We contribute the design and implementation of sense.us, a web site supporting asynchronous collaboration across a variety of visualization types. The site supports view sharing, discussion, graphical annotation, and social navigation and includes novel interaction elements. We report the results of user studies of the system, observing emergent patterns of social data analysis, including cycles of observation and hypothesis, and the complementary roles of social navigation and data-driven exploration.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1029–1038},
numpages = {10},
keywords = {annotation, communication-minded visualization, social data analysis, bookmarks, information visualization, groupware, asynchronous collaboration},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240782,
author = {Kirk, David and Rodden, Tom and Fraser, Dana\"{e} Stanton},
title = {Turn It <u class="uu">this</u> Way: Grounding Collaborative Action with Remote Gestures},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240782},
doi = {10.1145/1240624.1240782},
abstract = {Remote gesture systems have been shown to provide a significant enhancement to performance in collaborative physical tasks, an effect ascribed to the ability of remote gestures to help ground deictic references. The argument that this effect works by replacing complex referential descriptions with simple pointing behaviours has been drawn into question by recent research. In this paper we significantly unpack the effects of remote gesturing on collaborative language, arguing for a more complex role for remote gestures in interaction. We demonstrate how remote gestures influence the structure of collaborative discourse, and how their use can also influence the temporal nature of the grounding process. Through generating a deeper understanding of these effects of remote gesturing on collaborative language we derive implications for the development and deployment of these technologies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1039–1048},
numpages = {10},
keywords = {CSCW, overlaps, conversational grounding, remote gesturing, language use},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258891,
author = {Tatar, Deborah},
title = {Session Details: Learning &amp; Education},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258891},
doi = {10.1145/3258891},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240784,
author = {Johnsen, Kyle and Raij, Andrew and Stevens, Amy and Lind, D. Scott and Lok, Benjamin},
title = {The Validity of a Virtual Human Experience for Interpersonal Skills Education},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240784},
doi = {10.1145/1240624.1240784},
abstract = {Any new tool introduced for education needs to be validated. We developed a virtual human experience called the Virtual Objective Structured Clinical Examination (VOSCE). In the VOSCE, a medical student examines a life-size virtual human who is presenting symptoms of an illness. The student is then graded on interview skills. As part of a medical school class requirement, thirty three second year medical students participated in a user study designed to determine the validity of the VOSCE for testing interview skills. In the study, participant performance in the VOSCE is compared to participant performance in the OSCE, an interview with a trained actor. There was a significant correlation (r(33)=.49, p&lt;.005) between overall score in the VOSCE and overall score in the OSCE. This means that the interaction skills used with a virtual human translate to the interaction skills used with a real human. Comparing the experience of virtual human interaction to real human interaction is the critical validation step towards using virtual humans for interpersonal skills education.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1049–1058},
numpages = {10},
keywords = {validation, virtual reality, multimodal interfaces, virtual humans, virtual characters, medicine},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240785,
author = {Baker, Ryan S.J.d.},
title = {Modeling and Understanding Students' off-Task Behavior in Intelligent Tutoring Systems},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240785},
doi = {10.1145/1240624.1240785},
abstract = {We present a machine-learned model that can automatically detect when a student using an intelligent tutoring system is off-task, i.e., engaged in behavior which does not involve the system or a learning task. This model was developed using only log files of system usage (i.e. no screen capture or audio/video data). We show that this model can both accurately identify each student's prevalence of off-task behavior and can distinguish off-task behavior from when the student is talking to the teacher or another student about the subject matter. We use this model in combination with motivational and attitudinal instruments, developing a profile of the attitudes and motivations associated with off-task behavior, and compare this profile to the attitudes and motivations associated with other behaviors in intelligent tutoring systems. We discuss how the model of off-task behavior can be used within interactive learning environments which respond to when students are off-task.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1059–1068},
numpages = {10},
keywords = {user attitudes, intelligent tutoring systems, off-task behavior, motivation, user modeling},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240786,
author = {Gerber, Elizabeth},
title = {Improvisation Principles and Techniques for Design},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240786},
doi = {10.1145/1240624.1240786},
abstract = {Existing research addresses how designers create tools to support improvisation, yet little research explores how improvisation offers tools to support design work. This paper explores the potential relationship between improvisation and design, examining how design can benefit from improvisation. The paper argues that improvisation can build perspectives and skills that are critical for designers, such as creative collaboration, fostering innovation, supporting spontaneity, learning through error, and presenting ideas. The paper reviews the use of improvisation activities by designers in a multi-case study. The applications are analyzed to demonstrate individual and group level outcomes in design work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1069–1072},
numpages = {4},
keywords = {collaboration, improvisation, design},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240787,
author = {Adamczyk, Piotr D. and Twidale, Michael B.},
title = {Supporting Multidisciplinary Collaboration: Requirements from Novel HCI Education},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240787},
doi = {10.1145/1240624.1240787},
abstract = {Many collaborative design tools may suffer from being too generic to address the specific complexities inherent in multidisciplinary collaboration. We provide accounts of several multidisciplinary HCI courses at our institution, elaborating on the challenges student teams face when integrating design practice from a wide variety of disciplines. Of particular interest are the distinct approaches that these multidisciplinary teams adopt that differ from more common forms of collaborative design. We suggest reasons for the poor rate of adoption of existing collaborative support tools and outline specific suggestions for directions in both ethnographic studies of multidisciplinary collaboration and collaborative systems design.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1073–1076},
numpages = {4},
keywords = {low fidelity prototyping, multidisciplinary collaboration, social bookmarking, design education, design tools},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258892,
author = {Thomas, John},
title = {Session Details: Designing for Specific Cultures},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258892},
doi = {10.1145/3258892},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240789,
author = {Boehner, Kirsten and Vertesi, Janet and Sengers, Phoebe and Dourish, Paul},
title = {How HCI Interprets the Probes},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240789},
doi = {10.1145/1240624.1240789},
abstract = {We trace how cultural probes have been adopted and adapted by the HCI community. The flexibility of probes has been central to their uptake, resulting in a proliferation of divergent uses and derivatives. The varying patterns of adaptation of the probes reveal important underlying issues in HCI, suggesting underacknowledged disagreements about valid interpretation and the relationship between methods and their underlying methodology. With this analysis, we aim to clarify discussions around probes, and, more importantly, around how we define and evaluate methods in HCI, especially those grounded in unfamiliar conceptions of how research should be done.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1077–1086},
numpages = {10},
keywords = {reflective HCI, probes, cultural probes},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240790,
author = {Ramachandran, Divya and Kam, Matthew and Chiu, Jane and Canny, John and Frankel, James F.},
title = {Social Dynamics of Early Stage Co-Design in Developing Regions},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240790},
doi = {10.1145/1240624.1240790},
abstract = {Technology arguably has the potential to play a key role in improving the lives of people in developing regions. However, these communities are not well understood and designers must thoroughly investigate possibilities for technological innovations in these contexts. We describe findings from two field studies in India and one in Uganda where we explore technological solutions in the domains of communication, microfinance and education. Two common underlying themes emerge from these studies: (1) local stakeholders can contribute cultural information relevant to design such as needs and practices through interaction with technology artifacts and (2) unique social network structures embedded within communities are crucial to the acceptance and potential adoption of technology. We end with a synthesis of the three experiences that draws some practical lessons for ICT designers to elicit meaningful feedback and participation from local stakeholders in developing regions communities.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1087–1096},
numpages = {10},
keywords = {ICT4D, digital divide, developing regions},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240791,
author = {Kam, Matthew and Ramachandran, Divya and Devanathan, Varun and Tewari, Anuj and Canny, John},
title = {Localized Iterative Design for Language Learning in Underdeveloped Regions: The PACE Framework},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240791},
doi = {10.1145/1240624.1240791},
abstract = {Poor literacy remains a decisive barrier to the economic empowerment of many people in the developing world. Of particular importance is literacy in a widely spoken "world language" such as English, which is typically a second language for these speakers. For complex reasons, schools are often not effective as vehicles for second language learning. In this paper we explore game-like language learning on cell phones. We argue that phones are an excellent technology platform in the typical ecologies of developing countries. We present the PACE framework that is intended to support the rapid, scalable development of language learning software localized for a particular community of learners. These learners are usually skeptical of formal education and of cultural biases they encounter in learning "remote" languages in particular. Localization of content is crucial to make the language relevant to them and to encourage them to adopt it.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1097–1106},
numpages = {10},
keywords = {language learning, literacy, localization, content development, developing world, third world, digital divide},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258893,
author = {Rogers, Yvonne},
title = {Session Details: Mobile Kits &amp; Stuff},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258893},
doi = {10.1145/3258893},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240793,
author = {Ballagas, Rafael and Memon, Faraz and Reiners, Rene and Borchers, Jan},
title = {IStuff Mobile: Rapidly Prototyping New Mobile Phone Interfaces for Ubiquitous Computing},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240793},
doi = {10.1145/1240624.1240793},
abstract = {iStuff Mobile is the first rapid prototyping framework that helps explore new sensor-based interfaces with existing mobile phones. It focuses on sensor-enhanced physical interfaces for ubiquitous computing scenarios. The framework includes sensor network platforms, mobile phone software, and a proven rapid prototyping framework. Interaction designers can use iStuff Mobile to quickly create and test functional prototypes of novel interfaces without making internal hardware or software modifications to the handset. A visual programming paradigm provides a low threshold for prototyping activities: the system is not difficult to learn. At the same time, the range of examples built using the toolkit demonstrates a high ceiling for prototyping activities: the toolkit places few limits on prototype complexity. A user study shows that the visual programming metaphor enables prototypes to be built faster and encourages more iterations than a previous approach.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1107–1116},
numpages = {10},
keywords = {quartz composer, sensor networks, mobile phone, rapid prototyping, visual programming, design, cell phone},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240794,
author = {Salovaara, Antti},
title = {Appropriation of a MMS-Based Comic Creator: From System Functionalities to Resources for Action},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240794},
doi = {10.1145/1240624.1240794},
abstract = {Technologies can be used - or appropriated - in different ways by different users, but how do the use patterns evolve, and how can design facilitate such evolution? This paper approaches these questions in light of a case study in which a group of 8 high school students used Comeks, a mobile comic strip creator that enables users to exchange rich, expressive multimedia messages. A qualitative analysis of the use processes shows how users turned the functionalities embodied in Comeks into particular resources for communication during the 9-week trial period. The paper discusses the relationship of functionalities of the artifact and the development of resources by presenting how functionalities can be designed to support three ways to appropriate communication technologies: increasing technical mastery, re-channeling existing communication into the new medium and inventing new communicative acts between users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1117–1126},
numpages = {10},
keywords = {temporal analysis, resources, appropriation, mobile technology, interpersonal communication, evolving use},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240795,
author = {Oulasvirta, Antti and Sumari, Lauri},
title = {Mobile Kits and Laptop Trays: Managing Multiple Devices in Mobile Information Work},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240795},
doi = {10.1145/1240624.1240795},
abstract = {A study at a large IT company shows that mobile information workers frequently migrate work across devices (here: smartphones, desktop PCs, laptops). While having multiple devices provides new opportunities to work in the face of changing resource deprivations, the management of devices is often problematic. The most salient problems are posed by 1) the physical effort demanded by various management tasks, 2) anticipating what data or functionality will be needed, and 3) aligning these efforts with work, mobility, and social situations. Workers' strategies of coping with these problems center on two interwoven activities: the physical handling of devices and cross-device synchronization. These aim at balancing risk and effort in immediate and subsequent use. Workers also exhibit subtle ways to handle devices in situ, appropriating their physical and operational properties. The design implications are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1127–1136},
numpages = {10},
keywords = {user strategies, mobile information work, personal information management, synchronization, multiple devices},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258894,
author = {Dey, Anind},
title = {Session Details: Novel Navigation},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258894},
doi = {10.1145/3258894},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240797,
author = {Kristensson, Per Ola and Zhai, Shumin},
title = {Command Strokes with and without Preview: Using Pen Gestures on Keyboard for Command Selection},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240797},
doi = {10.1145/1240624.1240797},
abstract = {This paper presents a new command selection method that provides an alternative to pull-down menus in pen-based mobile interfaces. Its primary advantage is the ability forusers to directly select commands from a very large set without the need to traverse menu hierarchies. The proposed method maps the character strings representing the commands onto continuous pen-traces on a stylus keyboard. The user enters a command by stroking part of its character string. We call this method "command strokes." We present the results of three experiments assessing the usefulness of the technique. The first experiment shows that command strokes are 1.6 times faster than the de-facto standard pull-down menus and that users find command strokes more fun to use. The second and third experiments investigate the effect of displaying a visual preview of the currently recognized command while the user is still articulating the command stroke. These experiments show that visual preview does not slow users down and leads to significantly lower error rates and shorter gestures when users enter new unpracticed commands.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1137–1146},
numpages = {10},
keywords = {keyboard shortcuts, command, shorthand, pen gesture},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240798,
author = {Hancock, Mark and Carpendale, Sheelagh and Cockburn, Andy},
title = {Shallow-Depth 3d Interaction: Design and Evaluation of One-, Two- and Three-Touch Techniques},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240798},
doi = {10.1145/1240624.1240798},
abstract = {On traditional tables, people frequently use the third dimension to pile, sort and store objects. However, while effective and informative for organization, this use of the third dimension does not usually extend far above the table. To enrich interaction with digital tables, we present the concept of shallow-depth 3D -- 3D interaction with limited depth. Within this shallow-depth 3D environment several common interaction methods need to be reconsidered. Starting from any of one, two and three touch points, we present interaction techniques that provide control of all types of 3D rotation coupled with translation (6DOF) on a direct-touch tabletop display. The different techniques exemplify a wide range of interaction possibilities: from the one-touch technique, which is designed to be simple and natural, but inherits a degree of imprecision from its simplicity; through to three-touch interaction, which allows precise bimanual simultaneous control of multiple degrees of freedom, but at the cost of simplicity. To understand how these techniques support interaction in shallow-depth 3D, we present a user study that examines the efficiency of, and preferences for, the techniques developed. Results show that users are fastest and most accurate when using the three-touch technique and that their preferences were also strongly in favour of the expressive power available from three-touch.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1147–1156},
numpages = {10},
keywords = {direct-touch, translation, tabletop display, rotation, shallow-depth 3D},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240799,
author = {Terrenghi, Lucia and Kirk, David and Sellen, Abigail and Izadi, Shahram},
title = {Affordances for Manipulation of Physical versus Digital Media on Interactive Surfaces},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240799},
doi = {10.1145/1240624.1240799},
abstract = {This work presents the results of a comparative study in which we investigate the ways manipulation of physical versus digital media are fundamentally different from one another. Participants carried out both a puzzle task and a photo sorting task in two different modes: in a physical 3-dimensional space and on a multi-touch, interactive tabletop in which the digital items resembled their physical counterparts in terms of appearance and behavior. By observing the interaction behaviors of 12 participants, we explore the main differences and discuss what this means for designing interactive surfaces which use aspects of the physical world as a design resource.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1157–1166},
numpages = {10},
keywords = {physical, digital, tabletop, interactive surfaces, manipulation, affordances, interface design},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258895,
author = {Danis, Catalina},
title = {Session Details: People, Looking at People},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258895},
doi = {10.1145/3258895},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240801,
author = {Girgensohn, Andreas and Shipman, Frank and Turner, Thea and Wilcox, Lynn},
title = {Effects of Presenting Geographic Context on Tracking Activity between Cameras},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240801},
doi = {10.1145/1240624.1240801},
abstract = {A common video surveillance task is to keep track of people moving around the space being monitored. It is often difficult to track activity between cameras because locations such as hallways in office buildings can look quite similar and do not indicate the spatial proximity of the cameras. We describe a spatial video player that orients nearby video feeds with the field of view of the main playing video to aid in tracking between cameras. This is compared with the traditional bank of cameras with and without interactive maps for identifying and selecting cameras. We additionally explore the value of static and rotating maps for tracking activity between cameras. The study results show that both the spatial video player and the map improve user performance when compared to the camera-bank interface. Also, subjects change cameras more often with the spatial player than either the camera bank or the map, when available.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1167–1176},
numpages = {10},
keywords = {geographic context, security cameras, multiple video streams, video surveillance, activity tracking},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240802,
author = {Ranjan, Abhishek and Birnholtz, Jeremy P. and Balakrishnan, Ravin},
title = {Dynamic Shared Visual Spaces: Experimenting with Automatic Camera Control in a Remote Repair Task},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240802},
doi = {10.1145/1240624.1240802},
abstract = {We present an experimental study of automatic camera control in the performance of collaborative remote repair tasks using video-mediated communication. Twelve pairs of participants, one "helper" and one "worker," completed a series of Lego puzzle tasks using both a static camera and an automatic camera system that was guided in part by tracking the worker's hand position. Results show substantial performance benefits for the automatic system, particularly for complex tasks. The implications of these results are discussed, along with some lessons for the use of motion tracking as a driver for camera control.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1177–1186},
numpages = {10},
keywords = {video mediated communication, collaboration, empirical studies, camera control, video conferencing, computer-supported cooperative work, motion tracking},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240803,
author = {Schrammel, Johann and Geven, Arjan and Sefelin, Reinhard and Tscheligi, Manfred},
title = {"Look!": Using the Gaze Direction of Embodied Agents},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240803},
doi = {10.1145/1240624.1240803},
abstract = {This paper describes the results of three studies investigating an embodied agent that supports its interaction with the user by gazing at corresponding objects within its close environment. Three experiments were conducted in order to research whether users can detect an agent's line of sight, whether the agent's gaze direction can help to guide the users' attention towards designated locations and whether such a setup can be used to improve realistic interaction situations. The results show that a) users can detect the agent's gaze direction quickly (within 200 ms) but not very exactly, b) the use of the agent's gaze direction can speed up but also slow down the detection of objects in dependence on their location and c) that the agent's gaze towards corresponding objects during the interaction can have counterproductive effects in realistic settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1187–1190},
numpages = {4},
keywords = {computer vision, gaze direction, embodied agent},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240804,
author = {Kuno, Yoshinori and Sadazuka, Kazuhisa and Kawashima, Michie and Yamazaki, Keiichi and Yamazaki, Akiko and Kuzuoka, Hideaki},
title = {Museum Guide Robot Based on Sociological Interaction Analysis},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240804},
doi = {10.1145/1240624.1240804},
abstract = {We are currently working on a museum guide robot with an emphasis on "friendly" human-robot interaction displayed through nonverbal behaviors. In this paper, we focus on head gestures during explanations of exhibits. The outline of our research is as follows. We first examined human head gestures through an experimental, sociological approach. From this research, we have discovered how human guides coordinate their head movement along with their talk when explaining exhibits. Second, we developed a robot system based on these findings. Third, we evaluated human-robot interaction, again using an experimental, sociological approach, and then modified the robot based on the results. Our experimental results suggest that robot head turning may lead to heightened engagement of museum visitors with the robot. Based on our preliminary findings, we will describe a museum guide robot that first works autonomously and, if necessary, can turn into remote-control mode operated by a human to engage in more complex interaction with visitors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1191–1194},
numpages = {4},
keywords = {ethnomethodology, guide robot, computer vision, nonverbal behavior},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258896,
author = {Ramos, Gonzalo},
title = {Session Details: Input Techniques},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258896},
doi = {10.1145/3258896},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240806,
author = {Tsandilas, Theophanis and schraefel, m. c.},
title = {Bubbling Menus: A Selective Mechanism for Accessing Hierarchical Drop-down Menus},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240806},
doi = {10.1145/1240624.1240806},
abstract = {This paper introduces bubbling menus, a new design for cascading drop-down menus. Bubbling menus combine the bubble cursor [10] with directional mouse-gesture techniques to facilitate the access of certain items in a menu, such as frequently selected items. Through an extensive iterative design process, we explore bubbling menus in the context of adaptive and customizable user interfaces. Unlike other adaptation and customization techniques such as split menus, bubbling menus do not disrupt the original structure of menus and enable the activation of menus far from a menu bar. Results from two evaluation studies presented in the paper show that bubbling menus provide an effective alternative to accelerate menu selections tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1195–1204},
numpages = {10},
keywords = {adaptive/-able user interfaces, mouse gestures, cascading menus, customization},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240807,
author = {Thompson, Ramona Su and Rantanen, Esa M. and Yurcik, William and Bailey, Brian P.},
title = {Command Line or Pretty Lines? Comparing Textual and Visual Interfaces for Intrusion Detection},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240807},
doi = {10.1145/1240624.1240807},
abstract = {Intrusion detection (ID) is one of network security engineers' most important tasks. Textual (command-line) and visual interfaces are two common modalities used to support engineers in ID. We conducted a controlled experiment comparing a representative textual and visual interface for ID to develop a deeper understanding about the relative strengths and weaknesses of each. We found that the textual interface allows users to better control the analysis of details of the data through the use of rich, powerful, and flexible commands while the visual interface allows better discovery of new attacks by offering an overview of the current state of the network. With this understanding, we recommend designing a hybrid interface that combines the strengths of textual and visual interfaces for the next generation of tools used for intrusion detection.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1205},
numpages = {10},
keywords = {intrusion detection, visual interfaces, user study, textual interfaces, network security},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240808,
author = {Pietriga, Emmanuel and Appert, Caroline and Beaudouin-Lafon, Michel},
title = {Pointing and beyond: An Operationalization and Preliminary Evaluation of Multi-Scale Searching},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240808},
doi = {10.1145/1240624.1240808},
abstract = {A number of experimental studies based on domain-specific tasks have evaluated the efficiency of navigation techniques for searching multi-scale worlds. The discrepancies among their results call for a more generic framework similar in spirit to Fitts' reciprocal pointing task, but adapted to a task that significantly differs from pure pointing. We introduce such a framework based on an abstract task and evaluate how four multi-scale navigation techniques perform in one particular multi-scale world configuration. Experimental findings indicate that, in this context, pan &amp; zoom combined with an overview is the most efficient technique of all four, and that focus + context techniques perform better than classical pan &amp; zoom. We relate these findings to more realistic situations, discuss their applicability, and how the framework can be used to cover a broad range of situations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1215–1224},
numpages = {10},
keywords = {overview + detail, multi-scale interfaces, searching task, controlled experiment, zoom, focus + context},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258897,
author = {Murray, Dianne},
title = {Session Details: Location Aware Systems},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258897},
doi = {10.1145/3258897},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240810,
author = {O'Hara, Kenton and Kindberg, Tim and Glancy, Maxine and Baptista, Luciana and Sukumaran, Byju and Kahana, Gil and Rowbotham, Julie},
title = {Social Practices in Location-Based Collecting},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240810},
doi = {10.1145/1240624.1240810},
abstract = {The use of location-based technology to augment visitor experiences has received considerable attention over the years. In this paper, we take an alternative perspective on these kinds of location-based experiences by focussing on the collecting and keeping of location-based content as opposed to simply the in situ consumption of content. We describe a trial of a location-based experience at London zoo in which mobile camera phones were used to access digital content at particular animal enclosures around the zoo. Through the fieldwork we demonstrate ways in which collecting and keeping have important social values over and above simply consuming the content in situ. More specifically, the role of the collection of location-based content in identity work; in developing a sense of challenge and achievement; in defining a sense of group camaraderie; and in creating a playful sense of competition among group members. Further, we see how narratives told around the collected location-based content over time imbue it with additional value. These narratives become part of the resources through which relationships with family and friends get actively constructed. We discuss how these aspects have different design implications from the in-situ consumption model of location-based experiences and tensions this introduces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1225–1234},
numpages = {10},
keywords = {zoo, 2D barcodes, collecting, mobile phones, location-based computing, situated displays, visitor experience},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240811,
author = {Ludford, Pamela J. and Priedhorsky, Reid and Reily, Ken and Terveen, Loren},
title = {Capturing, Sharing, and Using Local Place Information},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240811},
doi = {10.1145/1240624.1240811},
abstract = {With new technology, people can share information about everyday places they go; the resulting data helps others find and evaluate places. Recent applications like Dodgeball and Sharescape repurpose everyday place information: users create local place data for personal use, and the systems display it for public use. We explore both the opportunities -- new local knowledge, and concerns -- privacy risks, raised by this implicit information sharing. We conduct two empirical studies: subjects create place data when using PlaceMail, a location-based reminder system, and elect whether to share it on Sharescape, a community map-building system. We contribute by: (1) showing location-based reminders yield new local knowledge about a variety of places, (2) identifying heuristics people use when deciding what place-related information to share (and their prevalence), (3) detailing how these decision heuristics can inform local knowledge sharing system design, and (4) identifying new uses of shared place information, notably opportunistic errand planning.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1235–1244},
numpages = {10},
keywords = {location privacy, local knowledge, map-based interface, location-based reminder, local search, disclosure interface},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240812,
author = {Strachan, Steven and Williamson, John and Murray-Smith, Roderick},
title = {Show Me the Way to Monte Carlo: Density-Based Trajectory Navigation},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240812},
doi = {10.1145/1240624.1240812},
abstract = {We demonstrate the use of uncertain prediction in asystem for pedestrian navigation via audio with a combination ofGlobal Positioning System data, a music player, inertial sensing,magnetic bearing data and Monte Carlo sampling for a densityfollowing task, where a listener's music is modulated according tothe changing predictions of user position with respect to a targetdensity, in this case a trajectory or path. We show that this system enables eyes-free navigation around set trajectories or paths unfamiliar to the user and demonstrate that the system may be used effectively for varying trajectory width and context.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1245–1248},
numpages = {4},
keywords = {uncertainty, GPS, Monte Carlo, audio, control, eyes-free, feedback, navigation, probabilistic display, tracking},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240813,
author = {DiSalvo, Carl and Maki, Jeff and Martin, Nathan},
title = {Mapmover: A Case Study of Design-Oriented Research into Collective Expression and Constructed Publics},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240813},
doi = {10.1145/1240624.1240813},
abstract = {In this paper we present the MapMover project as a case study into the use and design of an interactive system for collective expression. Informed by analysis and reflection we advance the concept of constructed publics: publics that are established, shaped, and maintained through the actions and influence of others. We conclude by discussing the relevance of constructed publics as a theorectical frame for the analysis and evaluation of projects in the domains of urban computing and exploratory design in HCI.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1249–1252},
numpages = {4},
keywords = {constructed publics, collective expression, design},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258898,
author = {Fisher, Danyel},
title = {Session Details: Social Network Sharing},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258898},
doi = {10.1145/3258898},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240815,
author = {Lampe, Cliff A.C. and Johnston, Erik and Resnick, Paul},
title = {Follow the Reader: Filtering Comments on Slashdot},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240815},
doi = {10.1145/1240624.1240815},
abstract = {Large-scale online communities need to manage the tension between critical mass and information overload. Slashdot is a news and discussion site that has used comment rating to allow massive participation while providing a mechanism for users to filter content. By default, comments with low ratings are hidden. Of users who changed the defaults, more than three times as many chose to use ratings for filtering or sorting as chose to suppress the use of comment ratings. Nearly half of registered users, however, never strayed from the default filtering settings, suggesting that the costs of exploring and selecting custom filter settings exceeds the expected benefit for many users. We recommend leveraging the efforts of the users that actively choose filter settings to reduce the cost of changing settings for all other users. One strategy is to create static schemas that capture the filtering preferences of different groups of readers. Another strategy is to dynamically set filtering thresholds for each conversation thread, based in part on the choices of previous readers. For predicting later readers' choices, the choices of previous readers are far more useful than content features such as the number of comments or the ratings of those comments.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1253–1262},
numpages = {10},
keywords = {customization, rating systems, online discussion},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240816,
author = {Tang, John C. and Lin, James and Pierce, Jeffrey and Whittaker, Steve and Drews, Clemens},
title = {Recent Shortcuts: Using Recent Interactions to Support Shared Activities},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240816},
doi = {10.1145/1240624.1240816},
abstract = {We present an empirical study of teams that revealed the amount of extraneous individual work needed to enable collaboration: finding references to other people, finding files to attach to email, managing incoming email attachments, managing the variety of files used in shared activities, and tracking what work is owed to others. Much of this work involves finding recently accessed objects that are needed again in the user's current task focus. These observations led to the design of Recent Shortcuts, a tool to help support coordination by making recently used objects easily accessible. Recent Shortcuts enables quick access to people (including groups of people), received attachments, files, and file folders that the user interacted with recently for re-use in the user's current context. Recent Shortcuts makes it easy to use these objects across applications with no additional user input and minimal changes to the user's applications or work practice. Early user experiences with a working prototype led to an extension that integrates recently accessed objects across multiple devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1263–1272},
numpages = {10},
keywords = {recent documents, recent shortcuts, empirical study, coordination, multi-device interaction, recent context},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240817,
author = {Jacucci, Giulio and Oulasvirta, Antti and Ilmonen, Tommi and Evans, John and Salovaara, Antti},
title = {Comedia: Mobile Group Media for Active Spectatorship},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240817},
doi = {10.1145/1240624.1240817},
abstract = {Previous attempts to support spectators at large-scale events have concentrated separately on real-time event information, awareness cues, or media-sharing applications. CoMedia combines a group media space with event information and integrates reusable awareness elements throughout. In two field trials, one at a rally and the other at a music festival, we found that CoMedia facilitated onsite reporting to offsite members, coordination of group action, keeping up to date with others, spectating remotely, and joking. In these activities, media, awareness cues, and event information were often used in concert, albeit assuming differing roles. We show that the integrated approach better supports continuous interweaving of use with the changing interests and occurrences in large-scale events.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1273–1282},
numpages = {10},
keywords = {awareness systems, field evaluation, spectatorship, mobile applications, large-scale events, groups},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258899,
author = {Blackwell, Alan},
title = {Session Details: Augmentation, Automation &amp; Agents},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258899},
doi = {10.1145/3258899},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240819,
author = {Nichols, Jeffrey and Chau, Duen Horng and Myers, Brad A.},
title = {Demonstrating the Viability of Automatically Generated User Interfaces},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240819},
doi = {10.1145/1240624.1240819},
abstract = {We conducted a user study that demonstrates that automatically generated interfaces can support better usability through increased flexibility in two dimensions. First, we show that automatic generation can improve usability by moving interfaces that are constrained by cost and poor interaction primitives to another device with better interactive capabilities: subjects were twice as fast and four times as successful at completing tasks with automatically generated interfaces on a PocketPC device as with the actual appliance interfaces. Second, we show that an automatic generator can improve usability by automatically ensuring that new interfaces are generated to be consistent with users' previous experience: subjects were also twice as fast using interfaces consistent with their experiences as compared to normally generated interfaces. These two results demonstrate that automatic interface generation is now viable and especially desirable where users will benefit from individualized interfaces or where human designers are constrained by cost and other factors.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1283–1292},
numpages = {10},
keywords = {personal digital assistants, pebbles, handheld computers, mobile phone, personal universal controller (PUC), automatic interface generation, consistency},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240820,
author = {Xiao, Jun and Stasko, John and Catrambone, Richard},
title = {The Role of Choice and Customization on Users' Interaction with Embodied Conversational Agents: Effects on Perception and Performance},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240820},
doi = {10.1145/1240624.1240820},
abstract = {We performed an empirical study exploring people's interactions with an embodied conversational agent (ECA) while performing two tasks. Conditions varied with respect to 1) whether participants were allowed to choose an agent and its characteristics and 2) the putative quality or appropriateness of the agent for the tasks. For both tasks, selection combined with the illusion of further customization significantly improved participants' overall subjective impressions of the ECAs while putative quality had little or no effect. Additionally, performance data revealed that the ECA's motivation and persuasion effects were significantly enhanced when participants chose agents to use. We found that user expectations about and perceptions of the interaction between themselves and an ECA depended very much on the individual's preconceived notions and preferences of various ECA characteristics and might deviate greatly from the models that ECA designers intend to portray.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1293–1302},
numpages = {10},
keywords = {interface assistants, qualitative analysis, controlled experiment, personalization, embodied conversational agents, customization, empirical evaluation},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258900,
author = {Tang, John},
title = {Session Details: Distributed Coordination},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258900},
doi = {10.1145/3258900},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240822,
author = {Fraser, Mike and McCarthy, Michael R. and Shaukat, Muneeb and Smith, Phillip},
title = {Seconds Matter: Improving Distributed Coordination Bytracking and Visualizing Display Trajectories},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240822},
doi = {10.1145/1240624.1240822},
abstract = {Pauses in distributed groupware activity can indicate anything from technical latency through infrastructure failure to a participant's thoughtful contemplation. Unraveling these ambiguities highlights mismatches between unseen off-screen activities and on-screen cursor behaviors. In this paper we suggest that groupware systems have typically been poor at representing off-screen activities, and introduce the concept of display trajectories to bridge the sensor gap between the display and its surrounding space. We consider requirements for display trajectories using the distributed social scientific analysis of video data as an example domain. Drawing on these requirements, we prototype a freeform whiteboard pen tracking and visualization technique around displays using ultrasound. We describe an experiment which inspects the impact of display trajectories on remote response efficiency. Our findings show that visualization of the display trajectory improves participants' ability to coordinate their actions by one second per interaction turn, reducing latency in organizing turn taking by a 'standard maximum' conversation pause.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1303–1312},
numpages = {10},
keywords = {groupware, pen-based interaction, display trajectory, off-screen tracking},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240823,
author = {Biehl, Jacob T. and Czerwinski, Mary and Smith, Greg and Robertson, George G.},
title = {FASTDash: A Visual Dashboard for Fostering Awareness in Software Teams},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240823},
doi = {10.1145/1240624.1240823},
abstract = {Software developers spend significant time gaining and maintaining awareness of fellow developers' activities. FASTDash is a new interactive visualization that seeks to improve team activity awareness using a spatial representation of the shared code base that highlights team members' current activities. With FASTDash, a developer can quickly determine which team members have source files checked out, which files are being viewed, and what methods and classes are currently being changed. The visualization can be annotated, allowing programmers to supplement activity information with additional status details. It provides immediate awareness of potential conflict situations, such as two programmers editing the same source file. FASTDash was developed through user-centered design, including surveys, team interviews, and in situ observation. Results from a field study show that FASTDash improved team awareness, reduced reliance on shared artifacts, and increased project-related communication. Additionally, the team that participated in our field study continues to use FASTDash.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1313–1322},
numpages = {10},
keywords = {large display, field study, visualization, collaborative programming, awareness},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240824,
author = {Landgren, Jonas and Nulden, Urban},
title = {A Study of Emergency Response Work: Patterns of Mobile Phone Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240824},
doi = {10.1145/1240624.1240824},
abstract = {This paper presents descriptive accounts of time-critical organizing in the domain of emergency response. Patterns of mobile phone interaction in such work is analyzed showing how the dyadic exchange of mobile phone numbers between the actors plays an important role in the social interactions in the organizing and sensemaking of the emergency. Enacted sensemaking is used as an analytical framework. Implications for design of emergency response information technology are outlined and discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1323–1332},
numpages = {10},
keywords = {collaboration, mobile phones, emergency response, enacted sensemaking, ethnography},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258901,
author = {Wixon, Dennis},
title = {Session Details: Usability},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258901},
doi = {10.1145/3258901},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240826,
author = {Guimbreti\'{e}re, Fran\c{c}ois and Dixon, Morgan and Hinckley, Ken},
title = {ExperiScope: An Analysis Tool for Interaction Data},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240826},
doi = {10.1145/1240624.1240826},
abstract = {We present ExperiScope, an analytical tool to help designers and experimenters explore the results of quantitative evaluations of interaction techniques. ExperiScope combines a new visualization incorporating aspects of the KLM and the three-state model with an interface helping users to rapidly cluster similar patterns of interactions. The tool makes it easy to identify and compare key patterns of use encountered during data collection. This promotes a deeper understanding of the results of a given evaluation.We illustrate the advantages of this tool by revisiting the data collected for an experiment conducted by Hinckley et al. [19] which compared different mode switching techniques. Our results show that our tool complements the previously reported results by offering insights about error behavior and the impact of mode switching on user performance.By providing a more fine-grained analysis of the data gathered during empirical evaluations, we hope that our tool will improve researchers' understanding of existing and newly developed interaction techniques.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1333–1342},
numpages = {10},
keywords = {empirical evaluation, interaction design, ExperiScope, data analysis tool},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240827,
author = {Hu, Jiang and Winterboer, Andi and Nass, Clifford I. and Moore, Johanna D. and Illowsky, Rebecca},
title = {Context &amp; Usability Testing: User-Modeled Information Presentation in Easy and Difficult Driving Conditions},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240827},
doi = {10.1145/1240624.1240827},
abstract = {A 2x2 enhanced Wizard-of-Oz experiment (N = 32) was conducted to compare two different approaches to presenting information to drivers in easy and difficult driving conditions. Data of driving safety, evaluation of the spoken dialogue system, and perception of self were analyzed. Results show that the user-modeled summarize-and-refine (UMSR) approach led to more efficient information retrieval than did the summarize-and-refine (SR) approach. However, depending on driving condition, higher efficiency did not always translate into pleasant subjective experience. Implications for usability testing and interface design were presented, followed by discussions of future research directions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1343–1346},
numpages = {4},
keywords = {driving simulator, spoken dialogue system, usability testing, user modeling, context of use, information presentation},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240828,
author = {Atterer, Richard and Schmidt, Albrecht},
title = {Tracking the Interaction of Users with AJAX Applications for Usability Testing},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240828},
doi = {10.1145/1240624.1240828},
abstract = {In this paper, we introduce an implementation for detailed monitoring of user actions on web pages. It addresses the problem that the log data recorded by standard web servers is not sufficient for the tracking of users on AJAX websites, e.g. to conduct a usability test. Using standard web technologies, our HTTP proxy can record very detailed usage information, such as mouse movements, clicks, key presses and scrolling, together with the exact HTML DOM tree objects involved. As we show in several case studies, the tracking also works across multiple websites, none of which needs to be under our control. This approach is much less invasive than previous efforts: The test person does not need to install software on her computer, and in certain operation modes, no configuration changes at all are required on her computer. Our research indicates that if the technology described in this paper is employed, arbitrary visitors of a website are more likely to take part in a usability test offered by that site -- this facilitates recruiting test participants over the Internet.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1347–1350},
numpages = {4},
keywords = {HTTP proxy, website usability evaluation, UsaProxy, RIA, AJAX application interaction logging, mouse tracking},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258902,
author = {Zimmerman, John},
title = {Session Details: Kids &amp; Family},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258902},
doi = {10.1145/3258902},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240830,
author = {Kientz, Julie A. and Arriaga, Rosa I. and Chetty, Marshini and Hayes, Gillian R. and Richardson, Jahmeilah and Patel, Shwetak N. and Abowd, Gregory D.},
title = {Grow and Know: Understanding Record-Keeping Needs for Tracking the Development of Young Children},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240830},
doi = {10.1145/1240624.1240830},
abstract = {From birth through age five, children undergo rapid development and learn skills that will influence them their entire lives. Regular visits to the pediatrician and detailed record-keeping can ensure that children are progressing and can identify early warning signs of developmental delay or disability. However, new parents are often overwhelmed with new responsibilities, and we believe there is an opportunity for computing technology to assist in this process. In this paper, we present a qualitative study aimed at uncovering some specific needs for record-keeping and analysis for new parents and their network of caregivers. Through interviews and focus groups, we have confirmed assumptions about the rationales parents have and the functions required for using technology for record-keeping. We also identify new themes, potential prototypes, and design guidelines for this domain.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1351–1360},
numpages = {10},
keywords = {qualitative study, healthcare, children, developmental delay, design requirements},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240831,
author = {Bentley, Frank R. and Metcalf, Crysta J.},
title = {Sharing Motion Information with Close Family and Friends},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240831},
doi = {10.1145/1240624.1240831},
abstract = {We present the Motion Presence application, an augmented phone book style application that allows close friends and family to view each other's current motion status ("moving" or "not moving") on their mobile phones. We performed a two week long field trial with 10 participants to observe usage and investigate any privacy concerns that might arise. We found that our participants used the motion information to infer location and activity as well as to plan communication, to help in coordinating in-person get-togethers, and to stay connected to patterns in each others' lives. Participants saw the motion data as mostly confirming their existing thoughts about the locations and activities of others and expressed few privacy concerns. In fact, they frequently asked for more information to be shared to make the application more compelling.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1361–1370},
numpages = {10},
keywords = {awareness, mobile presence, motion detection, privacy},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240832,
author = {Moraveji, Neema and Li, Jason and Ding, Jiarong and O'Kelley, Patrick and Woolf, Suze},
title = {Comicboarding: Using Comics as Proxies for Participatory Design with Children},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240832},
doi = {10.1145/1240624.1240832},
abstract = {Comicboarding is a participatory design method that uses specially created comic books to generate engaging, productive brainstorming sessions with children. By leveraging known plot formats, interaction styles, and characters in comics, researchers can elicit ideas even from children who are not accustomed to brainstorming, such as those from schools were rote learning is the norm. We conducted an experiment using two variants of the comicboarding methodology with 17 children in China, where traditional participatory design may fail in the face of local cultural practices. The results suggest that comicboarding holds promise for co-design with children.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1371–1374},
numpages = {4},
keywords = {methodology, participatory design, children, comic books},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258903,
author = {Beaudouin-Lafon, Michel},
title = {Session Details: Alternative Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258903},
doi = {10.1145/3258903},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240834,
author = {Ramos, Gonzalo A. and Balakrishnan, Ravin},
title = {Pressure Marks},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240834},
doi = {10.1145/1240624.1240834},
abstract = {Selections and actions in GUI's are often separated -- i.e. an action or command typically follows a selection. This sequence imposes a lower bound on the interaction time that is equal to or greater than the sum of its parts. In this paper, we introduce pressure marks -- pen strokes where the variations in pressure make it possible to indicate both a selection and an action simultaneously. We propose a series of design guidelines from which we develop a set of four basictypes of pressure marks. We first assess the viability of this set through an exploratory study that looks at the way users draw straight and lasso pressure marks of different sizes and orientations. We then present the results of a quantitative experiment that shows that users perform faster selection-action interactions with pressure marks than with a combination of lassos and pigtails. Based on these results, we present and discuss a number of interaction designs that incorporate pressure marks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1375–1384},
numpages = {10},
keywords = {human factors, pressure widgets, experimentation, pen input, design},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240835,
author = {Cechanowicz, Jared and Irani, Pourang and Subramanian, Sriram},
title = {Augmenting the Mouse with Pressure Sensitive Input},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240835},
doi = {10.1145/1240624.1240835},
abstract = {In this paper we investigate the use of a uni-pressure and dual-pressure augmented mouse. With a pressure augmented mouse users can simultaneously control cursor positions as well as multiple levels of discrete selection modes for common desktop application tasks. Two or more independent pressure sensors can be mounted onto several locations on the body of the mouse. To highlight the design potential of a pressure augmented mouse we conducted a multi-part study. In the first part we identified the number of maximum discrete levels controllable with a uni-pressure augmented mouse, the most appropriate locations for installing pressure sensors on the mouse, and the design of new interaction techniques to support selection with pressure-based input. In a follow-up design we introduced an additional sensor and two different types of selection techniques to control a larger number of discrete levels with two pressure sensors. Our results show that users can comfortably control up to 64 modes with a dual-pressure augmented mouse. We discuss the findings of our results in the context of several desktop interaction techniques and identify several design recommendations.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1385–1394},
numpages = {10},
keywords = {interaction technique, mouse, input device, pressure-based interaction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240836,
author = {Zhao, Shengdong and Dragicevic, Pierre and Chignell, Mark and Balakrishnan, Ravin and Baudisch, Patrick},
title = {Earpod: Eyes-Free Menu Selection Using Touch Input and Reactive Audio Feedback},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240836},
doi = {10.1145/1240624.1240836},
abstract = {We present the design and evaluation of earPod: an eyes-free menu technique using touch input and reactive auditory feedback. Studies comparing earPod with an iPod-like visual menu technique on reasonably-sized static menus indicate that they are comparable in accuracy. In terms of efficiency (speed), earPod is initially slower, but outperforms the visual technique within 30 minutes of practice. Our results indicate that earPod is potentially a reasonable eyes-free menu technique for general use, and is a particularly exciting technique for use in mobile device interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1395–1404},
numpages = {10},
keywords = {auditory menu, gestural interaction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258904,
author = {Jeffries, Robin},
title = {Session Details: Usability Evaluation},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258904},
doi = {10.1145/3258904},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240838,
author = {Andreasen, Morten Sieker and Nielsen, Henrik Villemann and Schr\o{}der, Simon Ormholt and Stage, Jan},
title = {What Happened to Remote Usability Testing? An Empirical Study of Three Methods},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240838},
doi = {10.1145/1240624.1240838},
abstract = {The idea of conducting usability tests remotely emerged ten years ago. Since then, it has been studied empirically, and some software organizations employ remote methods. Yet there are still few comparisons involving more than one remote method. This paper presents results from a systematic empirical comparison of three methods for remote usability testing and a conventional laboratory-based think-aloud method. The three remote methods are a remote synchronous condition, where testing is conducted in real time but the test monitor is separated spatially from the test subjects, and two remote asynchronous conditions, where the test monitor and the test subjects are separated both spatially and temporally. The results show that the remote synchronous method is virtually equivalent to the conventional method. Thereby, it has the potential to conveniently involve broader user groups in usability testing and support new development approaches. The asynchronous methods are considerably more time-consuming for the test subjects and identify fewer usability problems, yet they may still be worthwhile.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1405–1414},
numpages = {10},
keywords = {usability testing, remote testing, empirical study},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240839,
author = {Lindgaard, Gitte and Chattratichart, Jarinee},
title = {Usability Testing: What Have We Overlooked?},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240839},
doi = {10.1145/1240624.1240839},
abstract = {For more than a decade, the number of usability test participants has been a major theme of debate among usability practitioners and researchers keen to improve usability test performance. This paper provides evidence suggesting that the focus be shifted to task coverage instead. Our data analysis of nine commercial usability test teams participating in the CUE-4 study revealed no significant correlation between the percentage of problems found or of new problems and number of test users, but correlations of both variables and number of user tasks used by each usability team were significant. The role of participant recruitment on usability test performance and future research directions are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1415–1424},
numpages = {10},
keywords = {participant recruitment, metrics, UEM, usability testing},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240840,
author = {Mackay, Wendy E. and Appert, Caroline and Beaudouin-Lafon, Michel and Chapuis, Olivier and Du, Yangzhou and Fekete, Jean-Daniel and Guiard, Yves},
title = {Touchstone: Exploratory Design of Experiments},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240840},
doi = {10.1145/1240624.1240840},
abstract = {Touchstone is an open-source experiment design platform designed to help establish a solid research foundation for HCI in the area of novel interaction techniques. Touchstone includes a design platform for exploring alternative designs of controlled laboratory experiments, a run platform for running subjects and a limited analysis platform for advice and access to on-line statistics packages. Designed for HCI researchers and their students, Touchstone facilitates the process of creating new experiments, as well as replicating and extending experiments in the research literature. We tested Touchstone by designing two controlled experiments. One illustrates how to create a new experiment from scratch. The other replicates and extends a previous study of multiscale pointing interaction techniques: OrthoZoom was fastest, followed by bi-manual Pan &amp; Zoom; SDAZ and traditional Pan &amp; Zoom were consistently slower.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1425–1434},
numpages = {10},
keywords = {touchstone, experimental design, interaction techniques, benchmarking},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258905,
author = {Nelson, Les},
title = {Session Details: Programming by &amp; with End-Users},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258905},
doi = {10.1145/3258905},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240842,
author = {Wong, Jeffrey and Hong, Jason I.},
title = {Making Mashups with Marmite: Towards End-User Programming for the Web},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240842},
doi = {10.1145/1240624.1240842},
abstract = {There is a tremendous amount of web content available today, but it is not always in a form that supports end-users' needs. In many cases, all of the data and services needed to accomplish a goal already exist, but are not in a form amenable to an end-user. To address this problem, we have developed an end-user programming tool called Marmite, which lets end-users create so-called mashups that re-purpose and combine existing web content and services. In this paper, we present the design, implementation, and evaluation of Marmite. An informal user study found that programmers and some spreadsheet users had little difficulty using the system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1435–1444},
numpages = {10},
keywords = {end-user programming, spreadsheet, mashup, web services},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240843,
author = {Zimmerman, John and Tomasic, Anthony and Simmons, Isaac and Hargraves, Ian and Mohnkern, Ken and Cornwell, Jason and McGuire, Robert Martin},
title = {Vio: A Mixed-Initiative Approach to Learning and Automating Procedural Update Tasks},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240843},
doi = {10.1145/1240624.1240843},
abstract = {Today many workers spend too much of their time translating their co-workers' requests into structures that information systems can understand. This paper presents the novel interaction design and evaluation of VIO, an agent that helps workers trans late request. VIO monitors requests and makes suggestions to speed up the translation. VIO allows users to quickly correct agent errors. These corrections are used to improve agent performance as it learns to automate work. Our evaluations demonstrate that this type of agent can significantly reduce task completion time, freeing workers from mundane tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1445–1454},
numpages = {10},
keywords = {mixed initiative, agents, interaction design},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240844,
author = {Kelleher, Caitlin and Pausch, Randy and Kiesler, Sara},
title = {Storytelling Alice Motivates Middle School Girls to Learn Computer Programming},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240844},
doi = {10.1145/1240624.1240844},
abstract = {We describe Storytelling Alice, a programming environment that introduces middle school girls to computer programming as a means to the end of creating 3D animated stories. Storytelling Alice supports story creation by providing 1) a set of high-level animations, that support the use of social characters who can interact with one another, 2) a collection of 3D characters and scenery designed to spark story ideas, and 3) a tutorial that introduces users to writing Alice programs using story-based examples. In a study comparing girls' experiences learning to program using Storytelling Alice and a version of Alice without storytelling support (Generic Alice), we found that users of Storytelling Alice and Generic Alice were equally successful at learning basic programming constructs. Participants found Storytelling Alice and Generic Alice equally easy to use and entertaining. Users of Storytelling Alice were more motivated to program; they spent 42% more time programming, were more than 3 times as likely to sneak extra time to work on their programs, and expressed stronger interest in future use of Alice than users of Generic Alice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1455–1464},
numpages = {10},
keywords = {children, Alice, motivation, programming environments, gender, programming, computer science education},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258906,
author = {Winograd, Terry},
title = {Session Details: Trust &amp; Engagement},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258906},
doi = {10.1145/3258906},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240846,
author = {Nguyen, David T. and Canny, John},
title = {Multiview: Improving Trust in Group Video Conferencing through Spatial Faithfulness},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240846},
doi = {10.1145/1240624.1240846},
abstract = {Video conferencing is still considered a poor alternative to face-to-face meetings. In the business setting, where these systems are most prevalent, the misuse of video conferencing systems can have detrimental results, especially in high-stakes communications. Prior work suggests that spatial distortions of nonverbal cues, particularly gaze and deixis, negatively impact many aspects of effective communication in dyadic communications. However, video conferencing systems are often used for group-to-group meetings where spatial distortions are exacerbated. Meanwhile, its effects on the group dynamic are not well understood. In this study, we examine the effects that spatial distortions of nonverbal cues have on inter-group trust formation. We conducted a large (169 participant) study of group conferencing under various conditions. We found that the use of systems that introduce spatial distortions negatively affect trust formation patterns. On the other hand, these effects are essentially eliminated by using a spatially faithful video conferencing system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1465–1474},
numpages = {10},
keywords = {prisoner's dilemma, video conferencing, CSCW, eye contact, trust, spatial faithfulness, CMC, social dilemmas, gaze awareness},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240847,
author = {Dow, Steven and Mehta, Manish and Harmon, Ellie and MacIntyre, Blair and Mateas, Michael},
title = {Presence and Engagement in an Interactive Drama},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240847},
doi = {10.1145/1240624.1240847},
abstract = {In this paper we present the results of a qualitative, empirical study exploring the impact of immersive technologies on presence and engagement, using the interactive drama Fa\c{c}ade as the object of study. In this drama, players are situated in a married couple's apartment, and interact primarily through conversation with the characters and manipulation of objects in the space. We present participants' experiences across three different versions of Fa\c{c}ade -- augmented reality (AR) and two desktop computing based implementations, one where players communicate using speech and the other using typed keyboard input. Through interviews and observations of players, we find that immersive AR can create an increased sense of presence, confirming generally held expectations. However, we demonstrate that increased presence does not necessarily lead to more engagement. Rather, mediation may be necessary for some players to fully engage with certain interactive media experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1475–1484},
numpages = {10},
keywords = {presence, qualitative study, virtual or augmented reality experiences, engagement, interactive drama, cross-media study},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240848,
author = {vom Lehn, Dirk and Hindmarsh, Jon and Luff, Paul and Heath, Christian},
title = {Engaging Constable: Revealing Art with New Technology},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240848},
doi = {10.1145/1240624.1240848},
abstract = {Museums increasingly deploy new technologies to enhance visitors' experience of their exhibitions. They primarily rely on touch-screen computer systems, PDAs and digital audio-guides. Tate Britain recently employed two innovative systems in one of their major exhibitions of John Constable's work; a gestural interface and a touch-screen panel, both connected to large projection screens. This paper reports on the analysis of video-recordings and field observations of visitors' action and interaction. It explores how people interact with and around the systems, how they configure the space around the installation and how they examine and discover their properties. It suggests that designers of interfaces and installations developed for museum exhibitions face particular challenges, such as the transparency of the relationship between people's actions and the system' response, the provision of opportunities for individual and collaborative experiences and the interweaving of technological and aesthetic experiences.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1485–1494},
numpages = {10},
keywords = {touch-screen system, social interaction, museums, video analysis, gestural interface, ethnomethodology},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258907,
author = {St. Amant, Robert},
title = {Session Details: Models of Mobile Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258907},
doi = {10.1145/3258907},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240850,
author = {Cao, Xiang and Zhai, Shumin},
title = {Modeling Human Performance of Pen Stroke Gestures},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240850},
doi = {10.1145/1240624.1240850},
abstract = {This paper presents a quantitative human performance model of making single-stroke pen gestures within certain error constraints in terms of production time. Computed from the properties of Curves, Line segments, and Corners (CLC) in a gesture stroke, the model may serve as a foundation for the design and evaluation of existing and future gesture-based user interfaces at the basic motor control efficiency level, similar to the role of previous "laws of action" played to pointing, crossing or steering-based user interfaces. We report and discuss our experimental results on establishing and validating the CLC model, together with other basic empirical findings in stroke gesture production.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1495–1504},
numpages = {10},
keywords = {experimental study, pen stroke gestures, pen input},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240851,
author = {Holleis, Paul and Otto, Friederike and Hussmann, Heinrich and Schmidt, Albrecht},
title = {Keystroke-Level Model for Advanced Mobile Phone Interaction},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240851},
doi = {10.1145/1240624.1240851},
abstract = {The design of applications using mobile devices needs a different quality assessment than those known for desktop applications. Of the many aspects that have to be taken into account, one important criterion is the average time users need to complete a task. For interactions with the mouse, keyboard or touch screens, there exist models that predict interaction times like Fitts' law or the Keystroke-Level Model (KLM). This paper shows parallels to these models for advanced interactions with mobile phones targeted at pervasive services, including near field communication as well as built-in cameras and sensors. Applications can be evaluated with respect to user performance time without having a prototype running on the phone. To accomplish that, we extend the known KLM by identifying basic interaction elements for mobile phones and give estimates for expert user performance derived from several user tests.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1505–1514},
numpages = {10},
keywords = {mobile phone interaction, design decisions, user performance, keystroke-level model (KLM), real world interaction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240852,
author = {Pettitt, Michael and Burnett, Gary and Stevens, Alan},
title = {An Extended Keystroke Level Model (KLM) for Predicting the Visual Demand of in-Vehicle Information Systems},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240852},
doi = {10.1145/1240624.1240852},
abstract = {To assess the potential distraction of In-Vehicle Information Systems (IVIS), simple, low cost evaluation methods are required for use in early design stages. The occlusion technique evaluates IVIS tasks in interrupted vision conditions, aiming to predict likely visual demand. However, the technique necessitates performance-focused user trials utilising robust prototypes, and consequently has limitations as an economic evaluation method. HCI practitioners view the Keystroke Level Model (KLM) as a reliable and valid means of modelling human performance, not requiring empirical trials or working prototypes. This paper proposes an extended KLM, which aims to predict measures based on the occlusion protocol. To validate the new method, we compared results of an occlusion study with predictions based on the assumptions of the extended KLM. Analysis revealed significant correlations between observed and predicted results (R=0.93-0.98) and low error rates (7-13%). In conclusion, the extended KLM shows considerable merit as a first-pass design tool.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1515–1524},
numpages = {10},
keywords = {in-vehicle information systems, HCI, keystroke level model, occlusion, driver distraction},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258908,
author = {Feiner, Steve},
title = {Session Details: Color/Blind},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258908},
doi = {10.1145/3258908},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240854,
author = {Kuber, Ravi and Yu, Wai and McAllister, Graham},
title = {Towards Developing Assistive Haptic Feedback for Visually Impaired Internet Users},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240854},
doi = {10.1145/1240624.1240854},
abstract = {Haptic technologies are thought to have the potential to help blind individuals overcome the challenges experienced when accessing the Web. This paper proposes a structured participatory-based approach for developing targeted haptic sensations for purposes of web page exploration, and reports preliminary results showing how HTML elements can be represented through the use of force-feedback. Findings are then compared with mappings from previous studies, demonstrating the need for providing tailored haptic sensations for blind Internet users. This research aims to culminate in a framework, encompassing a vocabulary of haptic sensations with accompanying recommendations for designers to reference when developing inclusive web solutions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1525–1534},
numpages = {10},
keywords = {participatory design, web accessibility, design methodology, haptic, scenarios, blind},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240855,
author = {Jefferson, Luke and Harvey, Richard},
title = {An Interface to Support Color Blind Computer Users},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240855},
doi = {10.1145/1240624.1240855},
abstract = {A new method for adapting digital images so that they are suitable for color blind viewers is presented. In contrast to earlier automatic methods which formulate the problem of adapting images for color blind observers as one of optimization, we demonstrate how it is possible to allow a user to compute a very wide range of adaptations in reasonable time under the control of a single variable. We demonstrate how the algorithm can be delivered as an adaptive technology via a simple interface, and evaluate the efficacy of our method using psychovisual experiments with simulated color blind users and a standard color vision test.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1535–1538},
numpages = {4},
keywords = {interface support, color blindness, adaptive technology},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240856,
author = {Tan, Chui Chui and Yu, Wai and McAllister, Graham},
title = {An Adaptive &amp; Adaptable Approach to Enhance Web Graphics Accessibility for Visually Impaired People},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240856},
doi = {10.1145/1240624.1240856},
abstract = {To date, efforts have been made to enable visually impaired people to gain access to graphics on the Internet. However, these studies only offer a solution for a specific type of graphic by using a fixed set of hardware. To address this, a design approach of an adaptive and adaptable architecture is introduced which adapts to different graphical content, input/output devices (including assistive technologies) and user's profile and preferences. This system brings the opportunity to visually impaired people to gain access to graphics via different modalities by providing an adequate accessibility interface and interaction based on their profiles and needs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1539–1542},
numpages = {4},
keywords = {graphics, adaptable, visually impaired, adaptive, context information},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258909,
author = {Churchill, Elizabeth},
title = {Session Details: Social Influence},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258909},
doi = {10.1145/3258909},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240858,
author = {Gergle, Darren and Rose, Carolyn P. and Kraut, Robert E.},
title = {Modeling the Impact of Shared Visual Information on Collaborative Reference},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240858},
doi = {10.1145/1240624.1240858},
abstract = {A number of recent studies have demonstrated that groups benefit considerably from access to shared visual information. This is due, in part, to the communicative efficiencies provided by the shared visual context. However, a large gap exists between our current theoretical understanding and our existing models. We address this gap by developing a computational model that integrates linguistic cues with visual cues in a way that effectively models reference during tightly-coupled, task-oriented interactions. The results demonstrate that an integrated model significantly outperforms existing language-only and visual-only models. The findings can be used to inform and augment the development of conversational agents, applications that dynamically track discourse and collaborative interactions, and dialogue managers for natural language interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1543–1552},
numpages = {10},
keywords = {communication, multimodal interaction, shared visual information, modeling, discourse, language use},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240859,
author = {Dahlb\"{a}ck, Nils and Wang, QianYing and Nass, Clifford and Alwin, Jenny},
title = {Similarity is More Important than Expertise: Accent Effects in Speech Interfaces},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240859},
doi = {10.1145/1240624.1240859},
abstract = {In a balanced between-participants experiment (N = 96) American and Swedish participants listened to tourist information on a website about an American or Swedish city presented in English with either an American or Swedish accent and evaluated the speakers' knowledge of the topic, the voice characteristics, and the information characteristics. Users preferred accents similar to their own. Similarity-attraction effects were so powerful that same-accents speakers were viewed as being more knowledgeable than different-accent speakers even when the information would be much better-known by the opposite-accent speaker. Implications for similarity-attraction overwhelming expertise are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1553–1556},
numpages = {4},
keywords = {trust and liking, speech based systems, cross-cultural communication},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240860,
author = {Foucault, Brooke and Mentis, Helena M. and Sengers, Phoebe and Welles, Devon},
title = {Provoking Sociability},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240860},
doi = {10.1145/1240624.1240860},
abstract = {In this study, we explore the potential usefulness of disturbing, uncomfortable systems, demonstrating that provocative technology can have a positive effect on social relationships. We designed and evaluated an agent-based system that collects user information by asking seemingly benign questions, and then uses it to spread false, strange gossip throughout an office space. We show that provocative interaction on-line can improve off-line sociability.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1557–1560},
numpages = {4},
keywords = {design noir, sociability, emotion, CMC, negative affect},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240861,
author = {Zanbaka, Catherine Amine and Ulinski, Amy Catherine and Goolkasian, Paula and Hodges, Larry F.},
title = {Social Responses to Virtual Humans: Implications for Future Interface Design},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240861},
doi = {10.1145/1240624.1240861},
abstract = {Do human-human social interactions carry over to human-virtual human social interactions? How does this affect future interface designers? We replicated classical tests of social influence known as the social facilitation and inhibition effects. Social facilitation/inhibition theory states that when in the presence of others, people perform simple tasks better and complex tasks worse. Participants were randomly assigned to perform both simple and complex tasks alone and in the presence of either a real human, a projected virtual human, or a virtual human in a head-mounted display. Our results showed participants were inhibited by the presence of others, whether real or virtual. That is, participants performed worse on the complex task, both in terms of percent correct and reaction times, when in the presence of others than when alone. Social facilitation did not occur with the real or virtual human. We discuss these results and their implications for future interface designers.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1561–1570},
numpages = {10},
keywords = {interface agents, avatars, virtual humans, social influence, experimental studies, human-computer interaction, social facilitation and inhibition, social psychology},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/3258910,
author = {Twidale, Michael},
title = {Session Details: Learning},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3258910},
doi = {10.1145/3258910},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
numpages = {1},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240863,
author = {Cockburn, Andy and Kristensson, Per Ola and Alexander, Jason and Zhai, Shumin},
title = {Hard Lessons: Effort-Inducing Interfaces Benefit Spatial Learning},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240863},
doi = {10.1145/1240624.1240863},
abstract = {Interface designers normally strive for a design that minimises the user's effort. However, when the design's objective is to train users to interact with interfaces that are highly dependent on spatial properties (e.g. keypad layout or gesture shapes) we contend that designers should consider explicitly increasing the mental effort of interaction. To test the hypothesis that effort aids spatial memory, we designed a "frost-brushing" interface that forces the user to mentally retrieve spatial information, or to physically brush away the frost to obtain visual guidance. We report results from two experiments using virtual keypad interfaces -- the first concerns spatial location learning of buttons on the keypad, and the second concerns both location and trajectory learning of gesture shape. The results support our hypothesis, showing that the frost-brushing design improved spatial learning. The participants' subjective responses emphasised the connections between effort, engagement, boredom, frustration, and enjoyment, suggesting that effort requires careful parameterisation to maximise its effectiveness.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1571–1580},
numpages = {10},
keywords = {gesture stroke, skill acquisition, training, pen input, text entry, education, learning, spatial memory},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240864,
author = {Pawar, Udai Singh and Pal, Joyojeet and Gupta, Rahul and Toyama, Kentaro},
title = {Multiple Mice for Retention Tasks in Disadvantaged Schools},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240864},
doi = {10.1145/1240624.1240864},
abstract = {This study evaluates single-mouse and multiple-mice configurations for computer-aided learning in schools where access to computers is limited due to resource constraints. Multimouse, a single display groupware solution, developed to allow multiple mice to be used simultaneously on a single PC, is compared with single-user-single-mouse and multiple-user-single-mouse scenarios. Multimouse itself is trialed with two unique interaction designs -- one where competitive interaction among students is encouraged, and another where more collaborative interaction is expected. Experiments were conducted with 238 schoolchildren from underprivileged households in rural India on an English vocabulary retention task. On the whole, Multimouse configurations (five users each) were found to be at par with single-user scenarios in terms of actual words learned by students. This suggests that the value of a PC can be inexpensively multiplied by employing a multi-input shared-use design. Gender effects were found, where boys show significant differences in learning depending on interaction modality, whereas girls learned at similar rates across configurations. In addition, a comparison of the two Multimouse modes -- collaborative and competitive -- showed the striking difference in learning outcomes and user behavior that is possible due to even slight variations in interaction designs for multiple-mice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1581–1590},
numpages = {10},
keywords = {developing nations, single display groupware, shared computers, education, multiple mice},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240624.1240865,
author = {Grossman, Tovi and Dragicevic, Pierre and Balakrishnan, Ravin},
title = {Strategies for Accelerating On-Line Learning of Hotkeys},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240865},
doi = {10.1145/1240624.1240865},
abstract = {Hotkeys are extremely useful in leveraging expert performance, but learning them is a slow process. This paper investigates alternative menu designs that can motivate and help users remember associations between menu commands and hotkeys. Building upon previous work on paired-associate learning, we suggest that the transition to expert use can be accelerated by manipulating feedback and cost associated with menu selection. We evaluate five designs in a pilot study and then two of the most promising ones in a formal experiment, showing that the speed of hotkey learning can indeed be significantly increased with little modifications to the standard menu/hotkey paradigm.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1591–1600},
numpages = {10},
keywords = {hotkeys, learning},
location = {San Jose, California, USA},
series = {CHI '07}
}

